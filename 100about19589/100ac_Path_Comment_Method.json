[{
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.linked.FrequentlyUsedPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config,EvictionPolicy policy){\r\n    BasicSettings settings = new BasicSettings(config);\r\n    return settings.admission().stream().map(admission -> new FrequentlyUsedPolicy(admission, policy, config)).collect(toSet());\r\n}"
}, {
	"Path": "org.apache.commons.cli.CommandLine.getParsedOptionValue",
	"Comment": "return a version of this option converted to a particular type.",
	"Method": "Object getParsedOptionValue(String opt){\r\n    String res = getOptionValue(opt);\r\n    Option option = resolveOption(opt);\r\n    if (option == null || res == null) {\r\n        return null;\r\n    }\r\n    return TypeHandler.createValue(res, option.getType());\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.NERFeatureFactory.getCliqueFeatures",
	"Comment": "extracts all the features from the input data at a certain index.",
	"Method": "Collection<String> getCliqueFeatures(PaddedList<IN> cInfo,int loc,Clique clique){\r\n    Collection<String> features = Generics.newHashSet();\r\n    String domain = cInfo.get(0).get(CoreAnnotations.DomainAnnotation.class);\r\n    final boolean doFE = domain != null;\r\n    Collection<String> c;\r\n    String suffix;\r\n    if (clique == cliqueC) {\r\n        c = featuresC(cInfo, loc);\r\n        suffix = \"C\";\r\n    } else if (clique == cliqueCpC) {\r\n        c = featuresCpC(cInfo, loc);\r\n        suffix = \"CpC\";\r\n        addAllInterningAndSuffixing(features, c, suffix);\r\n        if (doFE) {\r\n            addAllInterningAndSuffixing(features, c, domain + '-' + suffix);\r\n        }\r\n        c = featuresCnC(cInfo, loc - 1);\r\n        suffix = \"CnC\";\r\n    } else if (clique == cliqueCp2C) {\r\n        c = featuresCp2C(cInfo, loc);\r\n        suffix = \"Cp2C\";\r\n    } else if (clique == cliqueCp3C) {\r\n        c = featuresCp3C(cInfo, loc);\r\n        suffix = \"Cp3C\";\r\n    } else if (clique == cliqueCp4C) {\r\n        c = featuresCp4C(cInfo, loc);\r\n        suffix = \"Cp4C\";\r\n    } else if (clique == cliqueCp5C) {\r\n        c = featuresCp5C(cInfo, loc);\r\n        suffix = \"Cp5C\";\r\n    } else if (clique == cliqueCpCp2C) {\r\n        c = featuresCpCp2C(cInfo, loc);\r\n        suffix = \"CpCp2C\";\r\n        addAllInterningAndSuffixing(features, c, suffix);\r\n        if (doFE) {\r\n            addAllInterningAndSuffixing(features, c, domain + '-' + suffix);\r\n        }\r\n        c = featuresCpCnC(cInfo, loc - 1);\r\n        suffix = \"CpCnC\";\r\n    } else if (clique == cliqueCpCp2Cp3C) {\r\n        c = featuresCpCp2Cp3C(cInfo, loc);\r\n        suffix = \"CpCp2Cp3C\";\r\n    } else if (clique == cliqueCpCp2Cp3Cp4C) {\r\n        c = featuresCpCp2Cp3Cp4C(cInfo, loc);\r\n        suffix = \"CpCp2Cp3Cp4C\";\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown clique: \" + clique);\r\n    }\r\n    addAllInterningAndSuffixing(features, c, suffix);\r\n    if (doFE) {\r\n        addAllInterningAndSuffixing(features, c, domain + '-' + suffix);\r\n    }\r\n    return features;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.LoadingCacheProxy.getAll",
	"Comment": "returns the entries, loading if necessary, and optionally updates their access expiry time.",
	"Method": "Map<K, V> getAll(Set<? extends K> keys,Map<K, V> getAll,Set<? extends K> keys,boolean updateAccessTime){\r\n    requireNotClosed();\r\n    boolean statsEnabled = statistics.isEnabled();\r\n    long start = statsEnabled ? ticker.read() : 0L;\r\n    try {\r\n        Map<K, Expirable<V>> entries = getAndFilterExpiredEntries(keys, updateAccessTime);\r\n        if (entries.size() != keys.size()) {\r\n            List<K> keysToLoad = keys.stream().filter(key -> !entries.containsKey(key)).collect(Collectors.<K>toList());\r\n            entries.putAll(cache.getAll(keysToLoad));\r\n        }\r\n        Map<K, V> result = copyMap(entries);\r\n        if (statsEnabled) {\r\n            statistics.recordGetTime(ticker.read() - start);\r\n        }\r\n        return result;\r\n    } catch (NullPointerException | IllegalStateException | ClassCastException | CacheException e) {\r\n        throw e;\r\n    } catch (RuntimeException e) {\r\n        throw new CacheException(e);\r\n    } finally {\r\n        dispatcher.awaitSynchronous();\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.consent.LdapConsentRepository.mergeDecision",
	"Comment": "merges a new decision into existing decisions.decisions are matched by id.",
	"Method": "Set<String> mergeDecision(LdapAttribute ldapConsent,ConsentDecision decision){\r\n    if (decision.getId() < 0) {\r\n        decision.setId(System.currentTimeMillis());\r\n    }\r\n    if (ldapConsent != null) {\r\n        val result = removeDecision(ldapConsent, decision.getId());\r\n        val json = mapToJson(decision);\r\n        if (StringUtils.isBlank(json)) {\r\n            throw new IllegalArgumentException(\"Could not map consent decision to JSON\");\r\n        }\r\n        result.add(json);\r\n        LOGGER.debug(\"Merged consent decision [{}] with LDAP attribute [{}]\", decision, ldapConsent.getName());\r\n        return CollectionUtils.wrap(result);\r\n    }\r\n    val result = new HashSet<String>();\r\n    val json = mapToJson(decision);\r\n    if (StringUtils.isBlank(json)) {\r\n        throw new IllegalArgumentException(\"Could not map consent decision to JSON\");\r\n    }\r\n    result.add(json);\r\n    return result;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.BasicBlockList.catchesEqual",
	"Comment": "compares the catches of two blocks for equality. this includesboth the catch types and target labels.",
	"Method": "boolean catchesEqual(BasicBlock block1,BasicBlock block2){\r\n    TypeList catches1 = block1.getExceptionHandlerTypes();\r\n    TypeList catches2 = block2.getExceptionHandlerTypes();\r\n    if (!StdTypeList.equalContents(catches1, catches2)) {\r\n        return false;\r\n    }\r\n    IntList succ1 = block1.getSuccessors();\r\n    IntList succ2 = block2.getSuccessors();\r\n    int size = succ1.size();\r\n    int primary1 = block1.getPrimarySuccessor();\r\n    int primary2 = block2.getPrimarySuccessor();\r\n    if (((primary1 == -1) || (primary2 == -1)) && (primary1 != primary2)) {\r\n        return false;\r\n    }\r\n    for (int i = 0; i < size; i++) {\r\n        int label1 = succ1.get(i);\r\n        int label2 = succ2.get(i);\r\n        if (label1 == primary1) {\r\n            if (label2 != primary2) {\r\n                return false;\r\n            }\r\n            continue;\r\n        }\r\n        if (label1 != label2) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.objectweb.asm.Label.addToSubroutine",
	"Comment": "marks this basic block as belonging to the given subroutine.",
	"Method": "void addToSubroutine(long id,int nbSubroutines){\r\n    if ((status & VISITED) == 0) {\r\n        status |= VISITED;\r\n        srcAndRefPositions = new int[nbSubroutines / 32 + 1];\r\n    }\r\n    srcAndRefPositions[(int) (id >>> 32)] |= (int) id;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.LocalLoadingCache.hasLoadAll",
	"Comment": "returns whether the supplied cache loader has bulk load functionality.",
	"Method": "boolean hasLoadAll(CacheLoader<? super K, V> loader){\r\n    try {\r\n        Method classLoadAll = loader.getClass().getMethod(\"loadAll\", Iterable.class);\r\n        Method defaultLoadAll = CacheLoader.class.getMethod(\"loadAll\", Iterable.class);\r\n        return !classLoadAll.equals(defaultLoadAll);\r\n    } catch (NoSuchMethodException | SecurityException e) {\r\n        logger.log(Level.WARNING, \"Cannot determine if CacheLoader can bulk load\", e);\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaMethod.isRegALocal",
	"Comment": "checks to see if the given ssa reg is ever associated with a locallocal variable. each ssa reg may be associated with at most onelocal var.",
	"Method": "boolean isRegALocal(RegisterSpec spec){\r\n    SsaInsn defn = getDefinitionForRegister(spec.getReg());\r\n    if (defn == null) {\r\n        return false;\r\n    }\r\n    if (defn.getLocalAssignment() != null)\r\n        return true;\r\n    for (SsaInsn use : getUseListForRegister(spec.getReg())) {\r\n        Insn insn = use.getOriginalRopInsn();\r\n        if (insn != null && insn.getOpcode().getOpcode() == RegOps.MARK_LOCAL) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.AbstractLinkedDeque.linkFirst",
	"Comment": "links the element to the front of the deque so that it becomes the first element.",
	"Method": "void linkFirst(E e){\r\n    final E f = first;\r\n    first = e;\r\n    if (f == null) {\r\n        last = e;\r\n    } else {\r\n        setPrevious(f, e);\r\n        setNext(e, f);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.configuration.DefaultCasConfigurationPropertiesSourceLocator.scanForConfigurationResources",
	"Comment": "get all possible configuration files for config directory that actually exist as files.",
	"Method": "List<Resource> scanForConfigurationResources(File config,List<String> profiles){\r\n    val possibleFiles = getAllPossibleExternalConfigDirFilenames(config, profiles);\r\n    return possibleFiles.stream().filter(File::exists).filter(File::isFile).map(FileSystemResource::new).collect(Collectors.toList());\r\n}"
}, {
	"Path": "org.apereo.cas.util.RandomUtils.getNativeInstance",
	"Comment": "get strong enough securerandom instance and of the checked exception.",
	"Method": "SecureRandom getNativeInstance(){\r\n    try {\r\n        return SecureRandom.getInstance(NATIVE_NON_BLOCKING_ALGORITHM);\r\n    } catch (final NoSuchAlgorithmException e) {\r\n        LOGGER.trace(e.getMessage(), e);\r\n        return new SecureRandom();\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.SsaToRop.verifyValidExitPredecessor",
	"Comment": "validates that a basic block is a valid end predecessor. it mustend in a return or a throw. throws a runtime exception on error.",
	"Method": "void verifyValidExitPredecessor(SsaBasicBlock b){\r\n    ArrayList<SsaInsn> insns = b.getInsns();\r\n    SsaInsn lastInsn = insns.get(insns.size() - 1);\r\n    Rop opcode = lastInsn.getOpcode();\r\n    if (opcode.getBranchingness() != Rop.BRANCH_RETURN && opcode != Rops.THROW) {\r\n        throw new RuntimeException(\"Exit predecessor must end\" + \" in valid exit statement.\");\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.linked.FrequentlyUsedPolicy.nextVictim",
	"Comment": "returns the next victim, excluding the newly added candidate. this exclusion is required sothat a candidate has a fair chance to be used, rather than always rejected due to existingentries having a high frequency from the distant past.",
	"Method": "Node nextVictim(Node candidate){\r\n    if (policy == EvictionPolicy.MFU) {\r\n        return freq0.prev.nextNode.next;\r\n    }\r\n    Node victim = freq0.next.nextNode.next;\r\n    if (victim == candidate) {\r\n        victim = (victim.next == victim.prev) ? victim.freq.next.nextNode.next : victim.next;\r\n    }\r\n    return victim;\r\n}"
}, {
	"Path": "org.apereo.cas.support.oauth.web.endpoints.OAuth20IntrospectionEndpointController.createIntrospectionValidResponse",
	"Comment": "create introspection response oauth introspection access token response.",
	"Method": "OAuth20IntrospectionAccessTokenResponse createIntrospectionValidResponse(OAuthRegisteredService service,AccessToken ticket){\r\n    val introspect = new OAuth20IntrospectionAccessTokenResponse();\r\n    introspect.setClientId(service.getClientId());\r\n    introspect.setScope(\"CAS\");\r\n    introspect.setAud(service.getServiceId());\r\n    introspect.setIss(casProperties.getAuthn().getOidc().getIssuer());\r\n    if (ticket != null) {\r\n        introspect.setActive(true);\r\n        val authentication = ticket.getAuthentication();\r\n        val subject = authentication.getPrincipal().getId();\r\n        introspect.setSub(subject);\r\n        introspect.setUniqueSecurityName(subject);\r\n        introspect.setExp(ticket.getExpirationPolicy().getTimeToLive());\r\n        introspect.setIat(ticket.getCreationTime().toInstant().getEpochSecond());\r\n        val methods = authentication.getAttributes().get(AuthenticationManager.AUTHENTICATION_METHOD_ATTRIBUTE);\r\n        val realmNames = CollectionUtils.toCollection(methods).stream().map(Object::toString).collect(Collectors.joining(\",\"));\r\n        introspect.setRealmName(realmNames);\r\n        introspect.setTokenType(OAuth20Constants.TOKEN_TYPE_BEARER);\r\n        val grant = authentication.getAttributes().getOrDefault(OAuth20Constants.GRANT_TYPE, StringUtils.EMPTY).toString().toLowerCase();\r\n        introspect.setGrantType(grant);\r\n    } else {\r\n        introspect.setActive(false);\r\n    }\r\n    return introspect;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifierITest.testCRF",
	"Comment": "i made this all one test or else you get problems in memory use if the junit stuff tries to run tests in parallel....",
	"Method": "void testCRF(){\r\n    CRFClassifier<CoreLabel> crf = CRFClassifier.getClassifierNoExceptions(System.getProperty(\"ner.model\", nerPath));\r\n    runCRFTest(crf);\r\n    crf = CRFClassifier.getDefaultClassifier();\r\n    runCRFTest(crf);\r\n    final boolean isStoredAnswer = Boolean.valueOf(System.getProperty(\"ner.useStoredAnswer\", \"false\"));\r\n    String txt1 = \"Jenny Finkel works for Mixpanel in San Francisco .\";\r\n    if (isStoredAnswer) {\r\n        crf = CRFClassifier.getClassifierNoExceptions(nerPath2);\r\n    }\r\n    runKBestTest(crf, txt1, isStoredAnswer);\r\n    runZeroOrder(crf, txt1);\r\n    CRFClassifier<CoreLabel> crfCaseless = CRFClassifier.getClassifierNoExceptions(System.getProperty(\"ner.caseless.model\", caselessPath));\r\n    try {\r\n        Triple<Double, Double, Double> prf = crfCaseless.classifyAndWriteAnswers(\"/u/nlp/data/ner/column_data/ritter.3class.test\", true);\r\n        Counter<String> results = new ClassicCounter();\r\n        results.setCount(\"NER F1\", prf.third());\r\n        Counter<String> lowResults = new ClassicCounter();\r\n        lowResults.setCount(\"NER F1\", 53.0);\r\n        Counter<String> highResults = new ClassicCounter();\r\n        highResults.setCount(\"NER F1\", 53.5);\r\n        BenchmarkingHelper.benchmarkResults(results, lowResults, highResults, null);\r\n    } catch (IOException ioe) {\r\n        Assert.fail(\"IOError on CRF test file\");\r\n    }\r\n    runSimpleCRFTest(crfCaseless, caselessTests);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.copy.AbstractCopier.isImmutable",
	"Comment": "returns if the class is an immutable type and does not need to be copied.",
	"Method": "boolean isImmutable(Class<?> clazz){\r\n    return immutableClasses.contains(clazz) || clazz.isEnum();\r\n}"
}, {
	"Path": "org.apereo.cas.util.RegexUtils.concatenate",
	"Comment": "concatenate all elements in the given collection to form a regex pattern.",
	"Method": "Pattern concatenate(Collection<?> requiredValues,boolean caseInsensitive){\r\n    val pattern = requiredValues.stream().map(Object::toString).collect(Collectors.joining(\"|\", \"(\", \")\"));\r\n    return createPattern(pattern, caseInsensitive ? Pattern.CASE_INSENSITIVE : 0);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.product.Ehcache3Policy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new Ehcache3Policy(config));\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.RelationMention.getEntityMentionArgs",
	"Comment": "fetches the arguments of this relation that are entity mentions",
	"Method": "List<EntityMention> getEntityMentionArgs(){\r\n    List<EntityMention> ents = new ArrayList();\r\n    for (ExtractionObject o : args) {\r\n        if (o instanceof EntityMention) {\r\n            ents.add((EntityMention) o);\r\n        }\r\n    }\r\n    return ents;\r\n}"
}, {
	"Path": "org.apache.commons.cli.Parser.updateRequiredOptions",
	"Comment": "removes the option or its group from the list of expected elements.",
	"Method": "void updateRequiredOptions(Option opt){\r\n    if (opt.isRequired()) {\r\n        getRequiredOptions().remove(opt.getKey());\r\n    }\r\n    if (getOptions().getOptionGroup(opt) != null) {\r\n        OptionGroup group = getOptions().getOptionGroup(opt);\r\n        if (group.isRequired()) {\r\n            getRequiredOptions().remove(group);\r\n        }\r\n        group.setSelected(opt);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.product.CollisionPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    CollisionSettings settings = new CollisionSettings(config);\r\n    return settings.density().map(density -> new CollisionPolicy(settings, density)).collect(toSet());\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpecList.withOffset",
	"Comment": "returns an instance that is identical to this one, except thatall register numbers are offset by the given amount. mutabilityof the result is inherited from the original.",
	"Method": "RegisterSpecList withOffset(int delta){\r\n    int sz = size();\r\n    if (sz == 0) {\r\n        return this;\r\n    }\r\n    RegisterSpecList result = new RegisterSpecList(sz);\r\n    for (int i = 0; i < sz; i++) {\r\n        RegisterSpec one = (RegisterSpec) get0(i);\r\n        if (one != null) {\r\n            result.set0(i, one.withOffset(delta));\r\n        }\r\n    }\r\n    if (isImmutable()) {\r\n        result.setImmutable();\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.trigger.PrincipalAttributeMultifactorAuthenticationTrigger.getPrincipalForMultifactorAuthentication",
	"Comment": "gets principal attributes for multifactor authentication.",
	"Method": "Principal getPrincipalForMultifactorAuthentication(Authentication authentication){\r\n    return authentication.getPrincipal();\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.data.Document.mergeIncompatibles",
	"Comment": "update incompatibles for two clusters that are about to be merged",
	"Method": "void mergeIncompatibles(CorefCluster to,CorefCluster from){\r\n    List<Pair<Pair<Integer, Integer>, Pair<Integer, Integer>>> replacements = new ArrayList();\r\n    for (Pair<Integer, Integer> p : incompatibleClusters) {\r\n        Integer other = null;\r\n        if (p.first == from.clusterID) {\r\n            other = p.second;\r\n        } else if (p.second == from.clusterID) {\r\n            other = p.first;\r\n        }\r\n        if (other != null && other != to.clusterID) {\r\n            int cid1 = Math.min(other, to.clusterID);\r\n            int cid2 = Math.max(other, to.clusterID);\r\n            replacements.add(Pair.makePair(p, Pair.makePair(cid1, cid2)));\r\n        }\r\n    }\r\n    for (Pair<Pair<Integer, Integer>, Pair<Integer, Integer>> r : replacements) {\r\n        incompatibleClusters.remove(r.first);\r\n        incompatibleClusters.add(r.second);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.util.RegexUtils.isValidRegex",
	"Comment": "check to see if the specified pattern is a valid regular expression.",
	"Method": "boolean isValidRegex(String pattern){\r\n    try {\r\n        if (pattern != null) {\r\n            Pattern.compile(pattern);\r\n            return true;\r\n        }\r\n    } catch (final PatternSyntaxException exception) {\r\n        LOGGER.debug(\"Pattern [{}] is not a valid regex.\", pattern);\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.apereo.cas.services.BaseRegisteredServiceUsernameAttributeProvider.initialize",
	"Comment": "initializes the registered service with default valuesfor fields that are unspecified. only triggered by jpa.",
	"Method": "void initialize(){\r\n    setCanonicalizationMode(CaseCanonicalizationMode.NONE.name());\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.loadInsn",
	"Comment": "generates the instruction to push a local variable on the stack.",
	"Method": "void loadInsn(Type type,int index){\r\n    mv.visitVarInsn(type.getOpcode(Opcodes.ILOAD), index);\r\n}"
}, {
	"Path": "org.apereo.cas.support.saml.SamlIdPUtils.determineEndpointForRequest",
	"Comment": "determine assertion consumer service assertion consumer service.",
	"Method": "Endpoint determineEndpointForRequest(RequestAbstractType authnRequest,SamlRegisteredServiceServiceProviderMetadataFacade adaptor,String binding){\r\n    var endpoint = (Endpoint) null;\r\n    if (authnRequest instanceof LogoutRequest) {\r\n        endpoint = adaptor.getSingleLogoutService(binding);\r\n    } else {\r\n        val endpointReq = getAssertionConsumerServiceFromRequest(authnRequest, binding);\r\n        endpoint = endpointReq == null ? adaptor.getAssertionConsumerService(binding) : endpointReq;\r\n    }\r\n    if (endpoint == null || StringUtils.isBlank(endpoint.getBinding())) {\r\n        throw new SamlException(\"Assertion consumer service does not define a binding\");\r\n    }\r\n    val location = StringUtils.isBlank(endpoint.getResponseLocation()) ? endpoint.getLocation() : endpoint.getResponseLocation();\r\n    if (StringUtils.isBlank(location)) {\r\n        throw new SamlException(\"Assertion consumer service does not define a target location\");\r\n    }\r\n    return endpoint;\r\n}"
}, {
	"Path": "me.konloch.kontainer.io.HTTPRequest.setTimeout",
	"Comment": "sets the seconds till timeout, default 30,000 milliseconds",
	"Method": "void setTimeout(int timeout){\r\n    this.timeout = timeout;\r\n}"
}, {
	"Path": "org.objectweb.asm.util.CheckClassAdapter.checkFormalTypeParameter",
	"Comment": "checks a formal type parameter of a class or method signature.",
	"Method": "int checkFormalTypeParameter(String signature,int pos){\r\n    pos = checkIdentifier(signature, pos);\r\n    pos = checkChar(':', signature, pos);\r\n    if (\"L[T\".indexOf(getChar(signature, pos)) != -1) {\r\n        pos = checkFieldTypeSignature(signature, pos);\r\n    }\r\n    while (getChar(signature, pos) == ':') {\r\n        pos = checkFieldTypeSignature(signature, pos + 1);\r\n    }\r\n    return pos;\r\n}"
}, {
	"Path": "com.android.dx.ssa.BasicRegisterMapper.addMapping",
	"Comment": "adds a mapping to the mapper. if oldreg has already been mapped,overwrites previous mapping with new mapping.",
	"Method": "void addMapping(int oldReg,int newReg,int category){\r\n    if (oldReg >= oldToNew.size()) {\r\n        for (int i = oldReg - oldToNew.size(); i >= 0; i--) {\r\n            oldToNew.add(-1);\r\n        }\r\n    }\r\n    oldToNew.set(oldReg, newReg);\r\n    if (runningCountNewRegisters < (newReg + category)) {\r\n        runningCountNewRegisters = newReg + category;\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.annotate",
	"Comment": "annotate an extractiondataset with entities. this will modify theextractiondataset in place.",
	"Method": "void annotate(Annotation doc){\r\n    if (SAVE_CONLL_2003) {\r\n        try {\r\n            PrintStream os = new PrintStream(new FileOutputStream(\"test.conll\"));\r\n            List<List<CoreLabel>> labels = AnnotationUtils.entityMentionsToCoreLabels(doc, annotationsToSkip, useSubTypes, useBIO);\r\n            BasicEntityExtractor.saveCoNLL(os, labels, true);\r\n            os.close();\r\n        } catch (IOException e) {\r\n            e.printStackTrace();\r\n            System.exit(1);\r\n        }\r\n    }\r\n    List<CoreMap> sents = doc.get(CoreAnnotations.SentencesAnnotation.class);\r\n    int sentCount = 1;\r\n    for (CoreMap sentence : sents) {\r\n        if (useNERTags) {\r\n            this.makeAnnotationFromAllNERTags(sentence);\r\n        } else\r\n            extractEntities(sentence, sentCount);\r\n        sentCount++;\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.extractDatumSequence",
	"Comment": "creates a new crfdatum from the preprocessed alldata format, given thedocument number, position number, and a list of object labels.",
	"Method": "List<CRFDatum<? extends Collection<String>, ? extends CharSequence>> extractDatumSequence(int[][][] allData,int beginPosition,int endPosition,List<IN> labeledWordInfos){\r\n    List<CRFDatum<? extends Collection<String>, ? extends CharSequence>> result = new ArrayList();\r\n    int beginContext = beginPosition - windowSize + 1;\r\n    if (beginContext < 0) {\r\n        beginContext = 0;\r\n    }\r\n    for (int position = beginContext; position < beginPosition; position++) {\r\n        List<Collection<String>> cliqueFeatures = new ArrayList();\r\n        List<double[]> featureVals = new ArrayList();\r\n        for (int i = 0; i < windowSize; i++) {\r\n            cliqueFeatures.add(Collections.emptyList());\r\n            featureVals.add(null);\r\n        }\r\n        CRFDatum<Collection<String>, String> datum = new CRFDatum(cliqueFeatures, labeledWordInfos.get(position).get(CoreAnnotations.AnswerAnnotation.class), featureVals);\r\n        result.add(datum);\r\n    }\r\n    for (int position = beginPosition; position <= endPosition; position++) {\r\n        List<Collection<String>> cliqueFeatures = new ArrayList();\r\n        List<double[]> featureVals = new ArrayList();\r\n        for (int i = 0; i < windowSize; i++) {\r\n            Collection<String> features = new ArrayList();\r\n            for (int j = 0; j < allData[position][i].length; j++) {\r\n                features.add(featureIndex.get(allData[position][i][j]));\r\n            }\r\n            cliqueFeatures.add(features);\r\n            featureVals.add(null);\r\n        }\r\n        CRFDatum<Collection<String>, String> datum = new CRFDatum(cliqueFeatures, labeledWordInfos.get(position).get(CoreAnnotations.AnswerAnnotation.class), featureVals);\r\n        result.add(datum);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.BasicRelationExtractor.train",
	"Comment": "train on a list of extractionsentence containing labeled relationmention objects",
	"Method": "void train(Annotation sentences){\r\n    GeneralDataset<String, String> trainSet = createDataset(sentences);\r\n    trainMulticlass(trainSet);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.MatchRatingApproachEncoder.removeVowels",
	"Comment": "deletes all vowels unless the vowel begins the word.api usageconsider this method private, it is package protected for unit testing only.",
	"Method": "String removeVowels(String name){\r\n    final String firstLetter = name.substring(0, 1);\r\n    name = name.replaceAll(\"A\", EMPTY);\r\n    name = name.replaceAll(\"E\", EMPTY);\r\n    name = name.replaceAll(\"I\", EMPTY);\r\n    name = name.replaceAll(\"O\", EMPTY);\r\n    name = name.replaceAll(\"U\", EMPTY);\r\n    name = name.replaceAll(\"\\\\s{2,}\\\\b\", SPACE);\r\n    if (isVowel(firstLetter)) {\r\n        return firstLetter + name;\r\n    } else {\r\n        return name;\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.management.JCacheStatisticsMXBean.recordGetTime",
	"Comment": "records the time to execute get operations. this time does not include the time it takes toload an entry on a cache miss, as specified by the specification.",
	"Method": "void recordGetTime(long durationNanos){\r\n    if (enabled && (durationNanos != 0)) {\r\n        getTimeNanos.add(durationNanos);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.DefaultAuthenticationTransaction.of",
	"Comment": "wrap credentials into an authentication transaction, as a factory method,and return the final result.",
	"Method": "DefaultAuthenticationTransaction of(Service service,Credential credentials,DefaultAuthenticationTransaction of,Credential credentials){\r\n    return of(null, credentials);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.getDefaultClassifier",
	"Comment": "used to get the default supplied classifier inside the jar file. thisfunction will only work if the code was loaded from a jar file which has aserialized classifier stored inside it.",
	"Method": "CRFClassifier<INN> getDefaultClassifier(CRFClassifier<INN> getDefaultClassifier,Properties props){\r\n    CRFClassifier<INN> crf = new CRFClassifier();\r\n    crf.loadDefaultClassifier(props);\r\n    return crf;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.documentLogProbability",
	"Comment": "compute the log probability of the document given the model with the parameters x.",
	"Method": "double documentLogProbability(int[][][] docData,int docIndex,CRFCliqueTree<String> cliqueTree){\r\n    int[] docLabels = labels[docIndex];\r\n    int[] given = new int[window - 1];\r\n    Arrays.fill(given, classIndex.indexOf(backgroundSymbol));\r\n    if (docLabels.length > docData.length) {\r\n        System.arraycopy(docLabels, 0, given, 0, given.length);\r\n        int[] newDocLabels = new int[docData.length];\r\n        System.arraycopy(docLabels, docLabels.length - newDocLabels.length, newDocLabels, 0, newDocLabels.length);\r\n        docLabels = newDocLabels;\r\n    }\r\n    double startPosLogProb = cliqueTree.logProbStartPos();\r\n    if (VERBOSE) {\r\n        System.err.printf(\"P_-1(Background) = % 5.3f%n\", startPosLogProb);\r\n    }\r\n    double prob = startPosLogProb;\r\n    for (int i = 0; i < docData.length; i++) {\r\n        int label = docLabels[i];\r\n        double p = cliqueTree.condLogProbGivenPrevious(i, label, given);\r\n        if (VERBOSE) {\r\n            log.info(\"P(\" + label + \"|\" + ArrayMath.toString(given) + \")=\" + p);\r\n        }\r\n        prob += p;\r\n        System.arraycopy(given, 1, given, 0, given.length - 1);\r\n        given[given.length - 1] = label;\r\n    }\r\n    return prob;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.EventMention.getParents",
	"Comment": "if this eventmention is a subevent, this will return the parent event.",
	"Method": "Set<ExtractionObject> getParents(){\r\n    return parents;\r\n}"
}, {
	"Path": "com.facebook.buck.tools.consistency.TargetsDiffer.printDiff",
	"Comment": "prints the differences between two target graphs, including newly added, removed, and changedtargets and hashes",
	"Method": "DifferState.DiffResult printDiff(ParsedTargetsFile originalFile,ParsedTargetsFile newFile){\r\n    Set<String> targetsInOriginal = originalFile.targetsToHash.keySet();\r\n    Set<String> targetsInNew = newFile.targetsToHash.keySet();\r\n    Set<String> targetsOnlyInOriginal = Sets.difference(targetsInOriginal, targetsInNew);\r\n    Set<String> targetsOnlyInNew = Sets.difference(targetsInNew, targetsInOriginal);\r\n    Set<String> targetsInBoth = Sets.intersection(targetsInOriginal, targetsInNew);\r\n    printRemoved(originalFile, targetsOnlyInOriginal);\r\n    printAdded(newFile, targetsOnlyInNew);\r\n    printChanged(originalFile, newFile, targetsInBoth);\r\n    return differState.hasChanges();\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.ClassifierCombiner.classify",
	"Comment": "generates the answerannotation labels of the combined model for the giventokens, storing them in place in the tokens.",
	"Method": "List<IN> classify(List<IN> tokens){\r\n    if (baseClassifiers.isEmpty()) {\r\n        return tokens;\r\n    }\r\n    List<List<IN>> baseOutputs = new ArrayList();\r\n    List<IN> output = baseClassifiers.get(0).classifySentence(tokens);\r\n    for (int i = 0, sz = output.size(); i < sz; i++) {\r\n        tokens.get(i).set(CoreAnnotations.AnswerAnnotation.class, output.get(i).get(CoreAnnotations.AnswerAnnotation.class));\r\n        tokens.get(i).set(CoreAnnotations.AnswerProbAnnotation.class, output.get(i).get(CoreAnnotations.AnswerProbAnnotation.class));\r\n    }\r\n    baseOutputs.add(tokens);\r\n    for (int i = 1, sz = baseClassifiers.size(); i < sz; i++) {\r\n        output = baseClassifiers.get(i).classifySentence(tokens);\r\n        baseOutputs.add(output);\r\n    }\r\n    assert (baseOutputs.size() == baseClassifiers.size());\r\n    List<IN> finalAnswer = mergeDocuments(baseOutputs);\r\n    return finalAnswer;\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getClassName",
	"Comment": "returns the binary name of the class corresponding to this type. thismethod must not be used on method types.",
	"Method": "String getClassName(){\r\n    switch(sort) {\r\n        case VOID:\r\n            return \"void\";\r\n        case BOOLEAN:\r\n            return \"boolean\";\r\n        case CHAR:\r\n            return \"char\";\r\n        case BYTE:\r\n            return \"byte\";\r\n        case SHORT:\r\n            return \"short\";\r\n        case INT:\r\n            return \"int\";\r\n        case FLOAT:\r\n            return \"float\";\r\n        case LONG:\r\n            return \"long\";\r\n        case DOUBLE:\r\n            return \"double\";\r\n        case ARRAY:\r\n            StringBuilder sb = new StringBuilder(getElementType().getClassName());\r\n            for (int i = getDimensions(); i > 0; --i) {\r\n                sb.append(\"[]\");\r\n            }\r\n            return sb.toString();\r\n        case OBJECT:\r\n            return new String(buf, off, len).replace('/', '.');\r\n        default:\r\n            return null;\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.logProbabilityOf",
	"Comment": "returns a counter for the log probability of each of the classes.looking at the the sum of e^v for each count v, should give 1.",
	"Method": "Counter<L> logProbabilityOf(Datum<L, F> example,Counter<L> logProbabilityOf,int[] features,Counter<L> logProbabilityOf,RVFDatum<L, F> example){\r\n    Counter<L> scores = scoresOf(example);\r\n    Counters.logNormalizeInPlace(scores);\r\n    return scores;\r\n}"
}, {
	"Path": "org.apache.commons.codec.net.QuotedPrintableCodec.getUnsignedOctet",
	"Comment": "return the byte at position index of the byte array andmake sure it is unsigned.",
	"Method": "int getUnsignedOctet(int index,byte[] bytes){\r\n    int b = bytes[index];\r\n    if (b < 0) {\r\n        b = 256 + b;\r\n    }\r\n    return b;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.GenericDataSetReader.convertToCoreLabels",
	"Comment": "converts the tree labels to corelabels.we need this because we store additional info in the corelabel, like token span.",
	"Method": "void convertToCoreLabels(Tree tree){\r\n    Label l = tree.label();\r\n    if (!(l instanceof CoreLabel)) {\r\n        CoreLabel cl = new CoreLabel();\r\n        cl.setValue(l.value());\r\n        tree.setLabel(cl);\r\n    }\r\n    for (Tree kid : tree.children()) {\r\n        convertToCoreLabels(kid);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.AuthenticationHandler.getName",
	"Comment": "gets a unique name for this authentication handler within the spring context that contains it.for implementations that allow setting a unique name, deployers must take care to ensure that everyhandler instance has a unique name.",
	"Method": "String getName(){\r\n    return this.getClass().getSimpleName();\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.analysis.Analyzer.getFrames",
	"Comment": "returns the symbolic stack frame for each instruction of the lastrecently analyzed method.",
	"Method": "Frame<V>[] getFrames(){\r\n    return frames;\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.actions.select.BuckTestAtCursorAction.findNearestTestElement",
	"Comment": "walk up the psi tree to find the nearest method or class runnable as a test.",
	"Method": "PsiElement findNearestTestElement(PsiFile psiFile,PsiElement psiElement){\r\n    PsiElement currentElement = psiElement;\r\n    boolean seenAtLeastOneClass = false;\r\n    while (currentElement != null) {\r\n        if (currentElement instanceof PsiMethod) {\r\n            PsiMethod psiMethod = (PsiMethod) currentElement;\r\n            PsiClass psiClass = ((PsiMethod) currentElement).getContainingClass();\r\n            if (psiClass != null && BuckTestDetector.isTestMethod(psiMethod)) {\r\n                return psiMethod;\r\n            }\r\n        } else if (currentElement instanceof PsiClass) {\r\n            seenAtLeastOneClass = true;\r\n            PsiClass psiClass = (PsiClass) currentElement;\r\n            if (BuckTestDetector.isTestClass(psiClass)) {\r\n                return psiClass;\r\n            }\r\n        }\r\n        currentElement = currentElement.getParent();\r\n    }\r\n    if (!seenAtLeastOneClass && psiFile != null) {\r\n        for (PsiClass psiClass : PsiTreeUtil.findChildrenOfType(psiFile, PsiClass.class)) {\r\n            if (BuckTestDetector.isTestClass(psiClass)) {\r\n                return psiClass;\r\n            }\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.BasicBlockList.withRegisterOffset",
	"Comment": "returns an instance that is identical to this one, except thatthe registers in each instruction are offset by the givenamount. mutability of the result is inherited from theoriginal.",
	"Method": "BasicBlockList withRegisterOffset(int delta){\r\n    int sz = size();\r\n    BasicBlockList result = new BasicBlockList(sz);\r\n    for (int i = 0; i < sz; i++) {\r\n        BasicBlock one = (BasicBlock) get0(i);\r\n        if (one != null) {\r\n            result.set(i, one.withRegisterOffset(delta));\r\n        }\r\n    }\r\n    if (isImmutable()) {\r\n        result.setImmutable();\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "jsr166.JSR166TestCase.newStartedThread",
	"Comment": "returns a new started daemon thread running the given runnable.",
	"Method": "Thread newStartedThread(Runnable runnable){\r\n    Thread t = new Thread(runnable);\r\n    t.setDaemon(true);\r\n    t.start();\r\n    return t;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.PRCurve.optimalCwaArray",
	"Comment": "confidence weighted accuracy assuming the scores are probabilities and using .5 as threshold",
	"Method": "int[] optimalCwaArray(){\r\n    int[] arr = new int[numSamples()];\r\n    for (int recall = 1; recall <= numSamples(); recall++) {\r\n        arr[recall - 1] = precision(recall);\r\n    }\r\n    return arr;\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassVisitor.visitOuterClass",
	"Comment": "visits the enclosing class of the class. this method must be called onlyif the class has an enclosing class.",
	"Method": "void visitOuterClass(String owner,String name,String desc){\r\n    if (cv != null) {\r\n        cv.visitOuterClass(owner, name, desc);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.GeneralDataset.addAll",
	"Comment": "adds all datums in the given collection of data to this dataset",
	"Method": "void addAll(Iterable<? extends Datum<L, F>> data){\r\n    for (Datum<L, F> d : data) {\r\n        add(d);\r\n    }\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMapTest.testGenericComparable",
	"Comment": "elements of classes with erased generic type parameters basedon comparable can be inserted and found.",
	"Method": "void testGenericComparable(){\r\n    int size = 120;\r\n    ConcurrentMap<Object, Boolean> m = map();\r\n    for (int i = 0; i < size; i++) {\r\n        BI bi = new BI(i);\r\n        BS bs = new BS(String.valueOf(i));\r\n        LexicographicList<BI> bis = new LexicographicList<BI>(bi);\r\n        LexicographicList<BS> bss = new LexicographicList<BS>(bs);\r\n        assertTrue(m.putIfAbsent(bis, true) == null);\r\n        assertTrue(m.containsKey(bis));\r\n        if (m.putIfAbsent(bss, true) == null) {\r\n            assertTrue(m.containsKey(bss));\r\n        }\r\n        assertTrue(m.containsKey(bis));\r\n    }\r\n    for (int i = 0; i < size; i++) {\r\n        assertTrue(m.containsKey(Collections.singletonList(new BI(i))));\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.climbing.HillClimberWindowTinyLfuPolicy.onMiss",
	"Comment": "adds the entry to the admission window, evicting if necessary.",
	"Method": "void onMiss(long key){\r\n    Node node = new Node(key, WINDOW);\r\n    node.appendToTail(headWindow);\r\n    data.put(key, node);\r\n    sizeWindow++;\r\n    evict();\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.pattern",
	"Comment": "attempts to compile the regex into direct string ops, falling back to pattern and matcher in the worst case.",
	"Method": "RPattern pattern(String regex){\r\n    final boolean startsWith = regex.startsWith(\"^\");\r\n    final boolean endsWith = regex.endsWith(\"$\");\r\n    final String content = regex.substring(startsWith ? 1 : 0, endsWith ? regex.length() - 1 : regex.length());\r\n    final boolean boxes = content.contains(\"[\");\r\n    if (!boxes) {\r\n        if (startsWith && endsWith) {\r\n            if (content.length() == 0) {\r\n                return new RPattern() {\r\n                    @Override\r\n                    public boolean isMatch(final CharSequence input) {\r\n                        return input.length() == 0;\r\n                    }\r\n                };\r\n            } else {\r\n                return new RPattern() {\r\n                    @Override\r\n                    public boolean isMatch(final CharSequence input) {\r\n                        return input.equals(content);\r\n                    }\r\n                };\r\n            }\r\n        } else if ((startsWith || endsWith) && content.length() == 0) {\r\n            return ALL_STRINGS_RMATCHER;\r\n        } else if (startsWith) {\r\n            return new RPattern() {\r\n                @Override\r\n                public boolean isMatch(final CharSequence input) {\r\n                    return startsWith(input, content);\r\n                }\r\n            };\r\n        } else if (endsWith) {\r\n            return new RPattern() {\r\n                @Override\r\n                public boolean isMatch(final CharSequence input) {\r\n                    return endsWith(input, content);\r\n                }\r\n            };\r\n        }\r\n    } else {\r\n        final boolean startsWithBox = content.startsWith(\"[\");\r\n        final boolean endsWithBox = content.endsWith(\"]\");\r\n        if (startsWithBox && endsWithBox) {\r\n            String boxContent = content.substring(1, content.length() - 1);\r\n            if (!boxContent.contains(\"[\")) {\r\n                final boolean negate = boxContent.startsWith(\"^\");\r\n                if (negate) {\r\n                    boxContent = boxContent.substring(1);\r\n                }\r\n                final String bContent = boxContent;\r\n                final boolean shouldMatch = !negate;\r\n                if (startsWith && endsWith) {\r\n                    return new RPattern() {\r\n                        @Override\r\n                        public boolean isMatch(final CharSequence input) {\r\n                            return input.length() == 1 && contains(bContent, input.charAt(0)) == shouldMatch;\r\n                        }\r\n                    };\r\n                } else if (startsWith) {\r\n                    return new RPattern() {\r\n                        @Override\r\n                        public boolean isMatch(final CharSequence input) {\r\n                            return input.length() > 0 && contains(bContent, input.charAt(0)) == shouldMatch;\r\n                        }\r\n                    };\r\n                } else if (endsWith) {\r\n                    return new RPattern() {\r\n                        @Override\r\n                        public boolean isMatch(final CharSequence input) {\r\n                            return input.length() > 0 && contains(bContent, input.charAt(input.length() - 1)) == shouldMatch;\r\n                        }\r\n                    };\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return new RPattern() {\r\n        Pattern pattern = Pattern.compile(regex);\r\n        @Override\r\n        public boolean isMatch(final CharSequence input) {\r\n            final Matcher matcher = pattern.matcher(input);\r\n            return matcher.find();\r\n        }\r\n    };\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.pattern",
	"Comment": "attempts to compile the regex into direct string ops, falling back to pattern and matcher in the worst case.",
	"Method": "RPattern pattern(String regex){\r\n    return input.length() == 0;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.pattern",
	"Comment": "attempts to compile the regex into direct string ops, falling back to pattern and matcher in the worst case.",
	"Method": "RPattern pattern(String regex){\r\n    return input.equals(content);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.pattern",
	"Comment": "attempts to compile the regex into direct string ops, falling back to pattern and matcher in the worst case.",
	"Method": "RPattern pattern(String regex){\r\n    return startsWith(input, content);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.pattern",
	"Comment": "attempts to compile the regex into direct string ops, falling back to pattern and matcher in the worst case.",
	"Method": "RPattern pattern(String regex){\r\n    return endsWith(input, content);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.pattern",
	"Comment": "attempts to compile the regex into direct string ops, falling back to pattern and matcher in the worst case.",
	"Method": "RPattern pattern(String regex){\r\n    return input.length() == 1 && contains(bContent, input.charAt(0)) == shouldMatch;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.pattern",
	"Comment": "attempts to compile the regex into direct string ops, falling back to pattern and matcher in the worst case.",
	"Method": "RPattern pattern(String regex){\r\n    return input.length() > 0 && contains(bContent, input.charAt(0)) == shouldMatch;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.pattern",
	"Comment": "attempts to compile the regex into direct string ops, falling back to pattern and matcher in the worst case.",
	"Method": "RPattern pattern(String regex){\r\n    return input.length() > 0 && contains(bContent, input.charAt(input.length() - 1)) == shouldMatch;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.pattern",
	"Comment": "attempts to compile the regex into direct string ops, falling back to pattern and matcher in the worst case.",
	"Method": "RPattern pattern(String regex){\r\n    final Matcher matcher = pattern.matcher(input);\r\n    return matcher.find();\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.DefaultAuthenticationAttributeReleasePolicy.decideIfCredentialPasswordShouldBeReleasedAsAttribute",
	"Comment": "decide if credential password should be released as attribute.the credential must have been cached as an authentication attributeand the attribute release policy must be allowed to release theattribute.",
	"Method": "void decideIfCredentialPasswordShouldBeReleasedAsAttribute(Map<String, Object> attributes,Authentication authentication,RegisteredService service){\r\n    val policy = service.getAttributeReleasePolicy();\r\n    val isAuthorized = policy != null && policy.isAuthorizedToReleaseCredentialPassword() && isAttributeAllowedForRelease(CasViewConstants.MODEL_ATTRIBUTE_NAME_PRINCIPAL_CREDENTIAL);\r\n    val element = CollectionUtils.firstElement(authentication.getAttributes().get(CasViewConstants.MODEL_ATTRIBUTE_NAME_PRINCIPAL_CREDENTIAL));\r\n    val credential = element.map(Object::toString).orElse(null);\r\n    decideAttributeReleaseBasedOnServiceAttributePolicy(attributes, credential, CasViewConstants.MODEL_ATTRIBUTE_NAME_PRINCIPAL_CREDENTIAL, service, isAuthorized);\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.TokensRegexNERAnnotatorITest.testPriority",
	"Comment": "in the mapping file, christianity is assigned a higher priority than early christianity,and so early should not be marked as religion.",
	"Method": "void testPriority(){\r\n    String str = \"Christianity is of higher regex priority than Early Christianity . \";\r\n    Annotation document = createDocument(str);\r\n    annotator.annotate(document);\r\n    List<CoreLabel> tokens = document.get(CoreAnnotations.TokensAnnotation.class);\r\n    checkNerTags(tokens, \"RELIGION\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"RELIGION\", \"O\");\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.BinaryCodec.toAsciiString",
	"Comment": "converts an array of raw binary data into a string of ascii 0 and 1 characters.",
	"Method": "String toAsciiString(byte[] raw){\r\n    return new String(toAsciiChars(raw));\r\n}"
}, {
	"Path": "org.apereo.cas.services.RegisteredServiceDelegatedAuthenticationPolicy.isProviderAllowed",
	"Comment": "is provider allowed to process the request for this service.",
	"Method": "boolean isProviderAllowed(String provider,RegisteredService registeredService){\r\n    return true;\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMapTest.testComparableFamily",
	"Comment": "inserted elements that are subclasses of the same comparableclass are found.",
	"Method": "void testComparableFamily(){\r\n    int size = 500;\r\n    ConcurrentMap<BI, Boolean> m = map();\r\n    for (int i = 0; i < size; i++) {\r\n        assertTrue(m.put(new CI(i), true) == null);\r\n    }\r\n    for (int i = 0; i < size; i++) {\r\n        assertTrue(m.containsKey(new CI(i)));\r\n        assertTrue(m.containsKey(new DI(i)));\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.makeSerializationProxy",
	"Comment": "creates a serialization proxy based on the common configuration shared by all cache types.",
	"Method": "SerializationProxy<K, V> makeSerializationProxy(BoundedLocalCache<?, ?> cache,boolean isWeighted){\r\n    SerializationProxy<K, V> proxy = new SerializationProxy();\r\n    proxy.weakKeys = cache.collectKeys();\r\n    proxy.weakValues = cache.nodeFactory.weakValues();\r\n    proxy.softValues = cache.nodeFactory.softValues();\r\n    proxy.isRecordingStats = cache.isRecordingStats();\r\n    proxy.removalListener = cache.removalListener();\r\n    proxy.ticker = cache.expirationTicker();\r\n    proxy.writer = cache.writer;\r\n    if (cache.expiresAfterAccess()) {\r\n        proxy.expiresAfterAccessNanos = cache.expiresAfterAccessNanos();\r\n    }\r\n    if (cache.expiresAfterWrite()) {\r\n        proxy.expiresAfterWriteNanos = cache.expiresAfterWriteNanos();\r\n    }\r\n    if (cache.expiresVariable()) {\r\n        proxy.expiry = cache.expiry();\r\n    }\r\n    if (cache.evicts()) {\r\n        if (isWeighted) {\r\n            proxy.weigher = cache.weigher;\r\n            proxy.maximumWeight = cache.maximum();\r\n        } else {\r\n            proxy.maximumSize = cache.maximum();\r\n        }\r\n    }\r\n    return proxy;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.AuthenticationPostProcessor.supports",
	"Comment": "determines whether the processor has the capability to perform tasks on the given credential.",
	"Method": "boolean supports(Credential credential){\r\n    return true;\r\n}"
}, {
	"Path": "com.android.dx.util.TwoColumnOutput.flushRight",
	"Comment": "flushes the right column buffer, printing it and clearing the buffer.if the buffer is already empty, this does nothing.",
	"Method": "void flushRight(){\r\n    appendNewlineIfNecessary(rightBuf, rightColumn);\r\n    while (rightBuf.length() != 0) {\r\n        leftColumn.write('\\n');\r\n        outputFullLines();\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.cli.Parser.parse",
	"Comment": "parse the arguments according to the specified options andproperties.",
	"Method": "CommandLine parse(Options options,String[] arguments,CommandLine parse,Options options,String[] arguments,Properties properties,CommandLine parse,Options options,String[] arguments,boolean stopAtNonOption,CommandLine parse,Options options,String[] arguments,Properties properties,boolean stopAtNonOption){\r\n    for (Option opt : options.helpOptions()) {\r\n        opt.clearValues();\r\n    }\r\n    for (OptionGroup group : options.getOptionGroups()) {\r\n        group.setSelected(null);\r\n    }\r\n    setOptions(options);\r\n    cmd = new CommandLine();\r\n    boolean eatTheRest = false;\r\n    if (arguments == null) {\r\n        arguments = new String[0];\r\n    }\r\n    List<String> tokenList = Arrays.asList(flatten(getOptions(), arguments, stopAtNonOption));\r\n    ListIterator<String> iterator = tokenList.listIterator();\r\n    while (iterator.hasNext()) {\r\n        String t = iterator.next();\r\n        if (\"--\".equals(t)) {\r\n            eatTheRest = true;\r\n        } else if (\"-\".equals(t)) {\r\n            if (stopAtNonOption) {\r\n                eatTheRest = true;\r\n            } else {\r\n                cmd.addArg(t);\r\n            }\r\n        } else if (t.startsWith(\"-\")) {\r\n            if (stopAtNonOption && !getOptions().hasOption(t)) {\r\n                eatTheRest = true;\r\n                cmd.addArg(t);\r\n            } else {\r\n                processOption(t, iterator);\r\n            }\r\n        } else {\r\n            cmd.addArg(t);\r\n            if (stopAtNonOption) {\r\n                eatTheRest = true;\r\n            }\r\n        }\r\n        if (eatTheRest) {\r\n            while (iterator.hasNext()) {\r\n                String str = iterator.next();\r\n                if (!\"--\".equals(str)) {\r\n                    cmd.addArg(str);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    processProperties(properties);\r\n    checkRequiredOptions();\r\n    return cmd;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.justificationOfRVFDatum",
	"Comment": "print all features active for a particular datum and the weight thatthe classifier assigns to each class for those features.",
	"Method": "void justificationOfRVFDatum(RVFDatum<L, F> example,PrintWriter pw){\r\n    int featureLength = 0;\r\n    int labelLength = 6;\r\n    NumberFormat nf = NumberFormat.getNumberInstance();\r\n    nf.setMinimumFractionDigits(2);\r\n    nf.setMaximumFractionDigits(2);\r\n    if (nf instanceof DecimalFormat) {\r\n        ((DecimalFormat) nf).setPositivePrefix(\" \");\r\n    }\r\n    Counter<F> features = example.asFeaturesCounter();\r\n    for (F f : features.keySet()) {\r\n        featureLength = Math.max(featureLength, f.toString().length() + 2 + nf.format(features.getCount(f)).length());\r\n    }\r\n    featureLength = Math.max(featureLength, \"Total:\".length());\r\n    featureLength = Math.min(featureLength, MAX_FEATURE_ALIGN_WIDTH);\r\n    for (L l : labels()) {\r\n        labelLength = Math.max(labelLength, l.toString().length());\r\n    }\r\n    StringBuilder header = new StringBuilder();\r\n    for (int s = 0; s < featureLength; s++) {\r\n        header.append(' ');\r\n    }\r\n    for (L l : labels()) {\r\n        header.append(' ');\r\n        header.append(StringUtils.pad(l, labelLength));\r\n    }\r\n    pw.println(header);\r\n    for (F f : features.keySet()) {\r\n        String fStr = f.toString();\r\n        StringBuilder line = new StringBuilder(fStr);\r\n        line.append('[').append(nf.format(features.getCount(f))).append(']');\r\n        fStr = line.toString();\r\n        for (int s = fStr.length(); s < featureLength; s++) {\r\n            line.append(' ');\r\n        }\r\n        for (L l : labels()) {\r\n            String lStr = nf.format(weight(f, l));\r\n            line.append(' ');\r\n            line.append(lStr);\r\n            for (int s = lStr.length(); s < labelLength; s++) {\r\n                line.append(' ');\r\n            }\r\n        }\r\n        pw.println(line);\r\n    }\r\n    Counter<L> scores = scoresOfRVFDatum(example);\r\n    StringBuilder footer = new StringBuilder(\"Total:\");\r\n    for (int s = footer.length(); s < featureLength; s++) {\r\n        footer.append(' ');\r\n    }\r\n    for (L l : labels()) {\r\n        footer.append(' ');\r\n        String str = nf.format(scores.getCount(l));\r\n        footer.append(str);\r\n        for (int s = str.length(); s < labelLength; s++) {\r\n            footer.append(' ');\r\n        }\r\n    }\r\n    pw.println(footer);\r\n    Distribution<L> distr = Distribution.distributionFromLogisticCounter(scores);\r\n    footer = new StringBuilder(\"Prob:\");\r\n    for (int s = footer.length(); s < featureLength; s++) {\r\n        footer.append(' ');\r\n    }\r\n    for (L l : labels()) {\r\n        footer.append(' ');\r\n        String str = nf.format(distr.getCount(l));\r\n        footer.append(str);\r\n        for (int s = str.length(); s < labelLength; s++) {\r\n            footer.append(' ');\r\n        }\r\n    }\r\n    pw.println(footer);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.probabilityOfRVFDatum",
	"Comment": "returns a counter mapping from each class name to the probability ofthat class for a certain example.looking at the the sum of each count v, should be 1.0.",
	"Method": "Counter<L> probabilityOfRVFDatum(RVFDatum<L, F> example){\r\n    Counter<L> scores = logProbabilityOfRVFDatum(example);\r\n    for (L label : scores.keySet()) {\r\n        scores.setCount(label, Math.exp(scores.getCount(label)));\r\n    }\r\n    return scores;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.irr.FrdPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new FrdPolicy(config));\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.MachineReading.keepPercentage",
	"Comment": "keeps only the first percentage sentences from the given corpus",
	"Method": "Annotation keepPercentage(Annotation corpus,double percentage){\r\n    log.info(\"Using fraction of train: \" + percentage);\r\n    if (percentage >= 1.0) {\r\n        return corpus;\r\n    }\r\n    Annotation smaller = new Annotation(\"\");\r\n    List<CoreMap> sents = new ArrayList();\r\n    List<CoreMap> fullSents = corpus.get(SentencesAnnotation.class);\r\n    double smallSize = (double) fullSents.size() * percentage;\r\n    for (int i = 0; i < smallSize; i++) {\r\n        sents.add(fullSents.get(i));\r\n    }\r\n    log.info(\"TRAIN corpus size reduced from \" + fullSents.size() + \" to \" + sents.size());\r\n    smaller.set(SentencesAnnotation.class, sents);\r\n    return smaller;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.CacheWriterVerifier.verifyWriter",
	"Comment": "runs the verification block iff the cache writer is enabled.",
	"Method": "void verifyWriter(CacheContext context,BiConsumer<CacheWriterVerifier, CacheWriter<Integer, Integer>> consumer){\r\n    boolean mayVerify = context.isCaffeine() && context.isStrongKeys() && !context.isAsync();\r\n    if (mayVerify) {\r\n        consumer.accept(new CacheWriterVerifier(context), context.cacheWriter());\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.membership.bloom.BloomFilter.seeded",
	"Comment": "applies the independent hash function for the given seed index.",
	"Method": "int seeded(int item,int i){\r\n    long hash = SEED[i] * item;\r\n    hash += hash >> 32;\r\n    return (int) hash;\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.BaseNCodecInputStream.read",
	"Comment": "attempts to read len bytes into the specified b array starting at offsetfrom this inputstream.",
	"Method": "int read(int read,byte b,int offset,int len){\r\n    if (b == null) {\r\n        throw new NullPointerException();\r\n    } else if (offset < 0 || len < 0) {\r\n        throw new IndexOutOfBoundsException();\r\n    } else if (offset > b.length || offset + len > b.length) {\r\n        throw new IndexOutOfBoundsException();\r\n    } else if (len == 0) {\r\n        return 0;\r\n    } else {\r\n        int readLen = 0;\r\n        while (readLen == 0) {\r\n            if (!baseNCodec.hasData(context)) {\r\n                final byte[] buf = new byte[doEncode ? 4096 : 8192];\r\n                final int c = in.read(buf);\r\n                if (doEncode) {\r\n                    baseNCodec.encode(buf, 0, c, context);\r\n                } else {\r\n                    baseNCodec.decode(buf, 0, c, context);\r\n                }\r\n            }\r\n            readLen = baseNCodec.readResults(b, offset, len, context);\r\n        }\r\n        return readLen;\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpec.withType",
	"Comment": "returns an instance that is identical to this one, except thatthe type is replaced by the given one.",
	"Method": "RegisterSpec withType(TypeBearer newType){\r\n    return makeLocalOptional(reg, newType, local);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.Metaphone.encode",
	"Comment": "encodes an object using the metaphone algorithm.this methodis provided in order to satisfy the requirements of theencoder interface, and will throw an encoderexception if thesupplied object is not of type java.lang.string.",
	"Method": "Object encode(Object obj,String encode,String str){\r\n    return metaphone(str);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.NaiveBayesClassifierFactory.trainClassifier",
	"Comment": "the examples are assumed to be a list of rfvdatum.the datums are assumed to not contain the zeroes and then they are added to each instance.",
	"Method": "NaiveBayesClassifier<L, F> trainClassifier(int[][] data,int[] labels,int numFeatures,int numClasses,Index<L> labelIndex,Index<F> featureIndex,NaiveBayesClassifier<L, F> trainClassifier,GeneralDataset<L, F> examples,Set<F> featureSet,NaiveBayesClassifier<L, F> trainClassifier,GeneralDataset<L, F> dataset){\r\n    if (dataset instanceof RVFDataset) {\r\n        throw new RuntimeException(\"Not sure if RVFDataset runs correctly in this method. Please update this code if it does.\");\r\n    }\r\n    return trainClassifier(dataset.getDataArray(), dataset.labels, dataset.numFeatures(), dataset.numClasses(), dataset.labelIndex, dataset.featureIndex);\r\n}"
}, {
	"Path": "org.apereo.cas.web.support.WebUtils.getHttpServletRequestFromExternalWebflowContext",
	"Comment": "gets the http servlet request from the current servlet context.",
	"Method": "HttpServletRequest getHttpServletRequestFromExternalWebflowContext(RequestContext context,HttpServletRequest getHttpServletRequestFromExternalWebflowContext){\r\n    val servletExternalContext = (ServletExternalContext) ExternalContextHolder.getExternalContext();\r\n    if (servletExternalContext != null) {\r\n        return (HttpServletRequest) servletExternalContext.getNativeRequest();\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.irr.IndicatorFrdPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new IndicatorFrdPolicy(config));\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpecSet.withOffset",
	"Comment": "returns an instance that is identical to this one, except thatall register numbers are offset by the given amount. mutabilityof the result is inherited from the original.",
	"Method": "RegisterSpecSet withOffset(int delta){\r\n    int len = specs.length;\r\n    RegisterSpecSet result = new RegisterSpecSet(len + delta);\r\n    for (int i = 0; i < len; i++) {\r\n        RegisterSpec spec = specs[i];\r\n        if (spec != null) {\r\n            result.put(spec.withOffset(delta));\r\n        }\r\n    }\r\n    result.size = size;\r\n    if (isImmutable()) {\r\n        result.setImmutable();\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.AbstractInsnNode.acceptAnnotations",
	"Comment": "makes the given visitor visit the annotations of this instruction.",
	"Method": "void acceptAnnotations(MethodVisitor mv){\r\n    int n = visibleTypeAnnotations == null ? 0 : visibleTypeAnnotations.size();\r\n    for (int i = 0; i < n; ++i) {\r\n        TypeAnnotationNode an = visibleTypeAnnotations.get(i);\r\n        an.accept(mv.visitInsnAnnotation(an.typeRef, an.typePath, an.desc, true));\r\n    }\r\n    n = invisibleTypeAnnotations == null ? 0 : invisibleTypeAnnotations.size();\r\n    for (int i = 0; i < n; ++i) {\r\n        TypeAnnotationNode an = invisibleTypeAnnotations.get(i);\r\n        an.accept(mv.visitInsnAnnotation(an.typeRef, an.typePath, an.desc, false));\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.couchbase.core.CouchbaseClientFactory.shutdown",
	"Comment": "inverse of connectbucket, shuts down the client, cancelling connectiontask if not completed.",
	"Method": "void shutdown(){\r\n    if (this.cluster != null) {\r\n        LOGGER.debug(\"Disconnecting from Couchbase cluster\");\r\n        this.cluster.disconnect();\r\n    }\r\n}"
}, {
	"Path": "jsr166.JSR166TestCase.sleep",
	"Comment": "sleeps until the given time has elapsed.throws assertionfailederror if interrupted.",
	"Method": "void sleep(long millis){\r\n    try {\r\n        delay(millis);\r\n    } catch (InterruptedException fail) {\r\n        AssertionFailedError afe = new AssertionFailedError(\"Unexpected InterruptedException\");\r\n        afe.initCause(fail);\r\n        throw afe;\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.Registry.policy",
	"Comment": "returns all of the policy variations that have been configured.",
	"Method": "Set<Policy> policy(BasicSettings settings,String name){\r\n    Function<Config, Set<Policy>> factory = FACTORIES.get(name.toLowerCase(US));\r\n    checkNotNull(factory, \"%s not found\", name);\r\n    return factory.apply(settings.config());\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.hybrid.sieve.DeterministicCorefSieve.sortMentionsForPronoun",
	"Comment": "divides a sentence into clauses and sort the antecedents for pronoun matching",
	"Method": "List<Mention> sortMentionsForPronoun(List<Mention> l,Mention m1){\r\n    List<Mention> sorted = new ArrayList();\r\n    Tree tree = m1.contextParseTree;\r\n    Tree current = m1.mentionSubTree;\r\n    if (tree == null || current == null)\r\n        return l;\r\n    while (true) {\r\n        current = current.ancestor(1, tree);\r\n        if (current.label().value().startsWith(\"S\")) {\r\n            for (Mention m : l) {\r\n                if (!sorted.contains(m) && current.dominates(m.mentionSubTree))\r\n                    sorted.add(m);\r\n            }\r\n        }\r\n        if (current.ancestor(1, tree) == null)\r\n            break;\r\n    }\r\n    if (l.size() != sorted.size()) {\r\n        sorted = l;\r\n    } else if (!l.equals(sorted)) {\r\n        for (int i = 0; i < l.size(); i++) {\r\n            Mention ml = l.get(i);\r\n            Mention msorted = sorted.get(i);\r\n        }\r\n    } else {\r\n    }\r\n    return sorted;\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.hybrid.HybridCorefSystem.postProcessing",
	"Comment": "remove singletons, appositive, predicate nominatives, relative pronouns.",
	"Method": "void postProcessing(Document document){\r\n    Set<Mention> removeSet = Generics.newHashSet();\r\n    Set<Integer> removeClusterSet = Generics.newHashSet();\r\n    for (CorefCluster c : document.corefClusters.values()) {\r\n        Set<Mention> removeMentions = Generics.newHashSet();\r\n        for (Mention m : c.getCorefMentions()) {\r\n            if (HybridCorefProperties.REMOVE_APPOSITION_PREDICATENOMINATIVES && ((m.appositions != null && m.appositions.size() > 0) || (m.predicateNominatives != null && m.predicateNominatives.size() > 0) || (m.relativePronouns != null && m.relativePronouns.size() > 0))) {\r\n                removeMentions.add(m);\r\n                removeSet.add(m);\r\n                m.corefClusterID = m.mentionID;\r\n            }\r\n        }\r\n        c.corefMentions.removeAll(removeMentions);\r\n        if (HybridCorefProperties.REMOVE_SINGLETONS && c.getCorefMentions().size() == 1) {\r\n            removeClusterSet.add(c.clusterID);\r\n        }\r\n    }\r\n    for (int removeId : removeClusterSet) {\r\n        document.corefClusters.remove(removeId);\r\n    }\r\n    for (Mention m : removeSet) {\r\n        document.positions.remove(m);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.Options.fromSystemProperties",
	"Comment": "returns the test options from system property configuration.",
	"Method": "Options fromSystemProperties(){\r\n    return new Options();\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.FactorTable.conditionalLogProbGivenPrevious",
	"Comment": "computes the probability of the tag of being at the end of the table giventhat the previous tag sequence in table is given. given is at the beginning,of is at the end.",
	"Method": "double conditionalLogProbGivenPrevious(int[] given,int of){\r\n    if (given.length != windowSize - 1) {\r\n        throw new IllegalArgumentException(\"conditionalLogProbGivenPrevious requires given one less than clique size (\" + windowSize + \") but was \" + Arrays.toString(given));\r\n    }\r\n    int startIndex = indicesFront(given);\r\n    double z = ArrayMath.logSum(table, startIndex, startIndex + numClasses);\r\n    int i = startIndex + of;\r\n    return table[i] - z;\r\n}"
}, {
	"Path": "org.apereo.cas.web.DelegatingController.handleRequestInternal",
	"Comment": "handles the request.ask all delegates if they can handle the current request.the first to answer true is elected as the delegate that will process the request.if no controller answers true, we redirect to the error page.",
	"Method": "ModelAndView handleRequestInternal(HttpServletRequest request,HttpServletResponse response){\r\n    for (val delegate : this.delegates) {\r\n        if (delegate.canHandle(request, response)) {\r\n            return delegate.handleRequestInternal(request, response);\r\n        }\r\n    }\r\n    return generateErrorView(CasProtocolConstants.ERROR_CODE_INVALID_REQUEST, null);\r\n}"
}, {
	"Path": "com.android.dx.rop.annotation.Annotations.getAnnotations",
	"Comment": "gets the set of annotations contained in this instance. theresult is always unmodifiable.",
	"Method": "Collection<Annotation> getAnnotations(){\r\n    return Collections.unmodifiableCollection(annotations.values());\r\n}"
}, {
	"Path": "org.apereo.cas.support.openid.web.mvc.SmartOpenIdController.getAssociationResponse",
	"Comment": "gets the association response. determines the mode first.if mode is set to associate, will set the response. thenbuilds the response parameters next and returns.",
	"Method": "Map<String, String> getAssociationResponse(HttpServletRequest request){\r\n    val parameters = new ParameterList(request.getParameterMap());\r\n    val mode = parameters.hasParameter(OpenIdProtocolConstants.OPENID_MODE) ? parameters.getParameterValue(OpenIdProtocolConstants.OPENID_MODE) : null;\r\n    val response = FunctionUtils.doIf(StringUtils.equals(mode, OpenIdProtocolConstants.ASSOCIATE), () -> this.serverManager.associationResponse(parameters), () -> null).get();\r\n    val responseParams = new HashMap<String, String>();\r\n    if (response != null) {\r\n        responseParams.putAll(response.getParameterMap());\r\n    }\r\n    return responseParams;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateCL",
	"Comment": "calculate the conditional likelihood of this data by multiplyingconditional estimates. full dataset batch estimation.",
	"Method": "void calculateCL(double[] x){\r\n    if (values != null) {\r\n        rvfcalculate(x);\r\n    } else if (dataIterable != null) {\r\n        calculateCLiterable(x);\r\n    } else {\r\n        calculateCLbatch(x);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.parser.wikipedia.WikipediaTraceReader.isRead",
	"Comment": "returns whether the request resulted in a write to the database.",
	"Method": "boolean isRead(String line){\r\n    return line.charAt(line.length() - 1) == '-';\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpecList.subset",
	"Comment": "returns a new instance, which contains a subset of the elementsspecified by the given bitset. indexes in the bitset with a zeroare included, while indexes with a one are excluded. mutabilityof the result is inherited from the original.",
	"Method": "RegisterSpecList subset(BitSet exclusionSet){\r\n    int newSize = size() - exclusionSet.cardinality();\r\n    if (newSize == 0) {\r\n        return EMPTY;\r\n    }\r\n    RegisterSpecList result = new RegisterSpecList(newSize);\r\n    int newIndex = 0;\r\n    for (int oldIndex = 0; oldIndex < size(); oldIndex++) {\r\n        if (!exclusionSet.get(oldIndex)) {\r\n            result.set0(newIndex, get0(oldIndex));\r\n            newIndex++;\r\n        }\r\n    }\r\n    if (isImmutable()) {\r\n        result.setImmutable();\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RopMethod.calcPredecessors",
	"Comment": "calculates the predecessor sets for each block as well as for theexit.",
	"Method": "void calcPredecessors(){\r\n    int maxLabel = blocks.getMaxLabel();\r\n    IntList[] predecessors = new IntList[maxLabel];\r\n    IntList exitPredecessors = new IntList(10);\r\n    int sz = blocks.size();\r\n    for (int i = 0; i < sz; i++) {\r\n        BasicBlock one = blocks.get(i);\r\n        int label = one.getLabel();\r\n        IntList successors = one.getSuccessors();\r\n        int ssz = successors.size();\r\n        if (ssz == 0) {\r\n            exitPredecessors.add(label);\r\n        } else {\r\n            for (int j = 0; j < ssz; j++) {\r\n                int succLabel = successors.get(j);\r\n                IntList succPreds = predecessors[succLabel];\r\n                if (succPreds == null) {\r\n                    succPreds = new IntList(10);\r\n                    predecessors[succLabel] = succPreds;\r\n                }\r\n                succPreds.add(label);\r\n            }\r\n        }\r\n    }\r\n    for (int i = 0; i < maxLabel; i++) {\r\n        IntList preds = predecessors[i];\r\n        if (preds != null) {\r\n            preds.sort();\r\n            preds.setImmutable();\r\n        }\r\n    }\r\n    exitPredecessors.sort();\r\n    exitPredecessors.setImmutable();\r\n    if (predecessors[firstLabel] == null) {\r\n        predecessors[firstLabel] = IntList.EMPTY;\r\n    }\r\n    this.predecessors = predecessors;\r\n    this.exitPredecessors = exitPredecessors;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.getRContext",
	"Comment": "gets the right context. this is a regular expression that must match to the right of the pattern.",
	"Method": "RPattern getRContext(){\r\n    return this.rContext;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.refreshAfterWrite",
	"Comment": "returns if the cache refreshes entries after an write time threshold.",
	"Method": "boolean refreshAfterWrite(Optional<Expiration<K, V>> refreshAfterWrite){\r\n    return false;\r\n}"
}, {
	"Path": "org.apache.commons.codec.net.BCodec.getDefaultCharset",
	"Comment": "gets the default charset name used for string decoding and encoding.",
	"Method": "String getDefaultCharset(){\r\n    return this.charset.name();\r\n}"
}, {
	"Path": "org.objectweb.asm.signature.SignatureVisitor.visitClassBound",
	"Comment": "visits the class bound of the last visited formal type parameter.",
	"Method": "SignatureVisitor visitClassBound(){\r\n    return this;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.AuthenticationCredentialsThreadLocalBinder.getCurrentCredentialIdsAsString",
	"Comment": "get credential ids string representation from threadlocal.",
	"Method": "String getCurrentCredentialIdsAsString(){\r\n    return getCurrentCredentialIds() != null ? String.join(\", \", getCurrentCredentialIds()) : null;\r\n}"
}, {
	"Path": "org.objectweb.asm.Attribute.getCount",
	"Comment": "returns the length of the attribute list that begins with this attribute.",
	"Method": "int getCount(){\r\n    int count = 0;\r\n    Attribute attr = this;\r\n    while (attr != null) {\r\n        count += 1;\r\n        attr = attr.next;\r\n    }\r\n    return count;\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.POSTaggerAnnotatorITest.testMultipleSentencesAnnotation",
	"Comment": "test that multiple sentences work for the sentenceannotation.",
	"Method": "void testMultipleSentencesAnnotation(){\r\n    List<CoreLabel> firstLabels = makeSentence(testSentences[0]);\r\n    List<CoreLabel> secondLabels = makeSentence(testSentences[1]);\r\n    CoreMap firstSentence = new ArrayCoreMap();\r\n    firstSentence.set(CoreAnnotations.TokensAnnotation.class, firstLabels);\r\n    CoreMap secondSentence = new ArrayCoreMap();\r\n    secondSentence.set(CoreAnnotations.TokensAnnotation.class, secondLabels);\r\n    List<CoreMap> sentences = new ArrayList();\r\n    sentences.add(firstSentence);\r\n    sentences.add(secondSentence);\r\n    Annotation annotation = new Annotation(longText);\r\n    annotation.set(CoreAnnotations.SentencesAnnotation.class, sentences);\r\n    tagger.annotate(annotation);\r\n    checkLabels(firstLabels, \"PRP$\", \"NN\", \"VBZ\", \"JJ\", \"CC\", \"JJ\", \".\");\r\n    checkLabels(secondLabels, \"DT\", \"VBZ\", \"DT\", \"JJ\", \"NN\", \".\");\r\n}"
}, {
	"Path": "org.apache.commons.cli.Options.getOptionGroups",
	"Comment": "lists the optiongroups that are members of this options instance.",
	"Method": "Collection<OptionGroup> getOptionGroups(){\r\n    return new HashSet<OptionGroup>(optionGroups.values());\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.analysis.Frame.getLocals",
	"Comment": "returns the maximum number of local variables of this frame.",
	"Method": "int getLocals(){\r\n    return locals;\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.InsnList.resetLabels",
	"Comment": "reset all labels in the instruction list. this method should be calledbefore reusing same instructions list between severalclasswriters.",
	"Method": "void resetLabels(){\r\n    AbstractInsnNode insn = first;\r\n    while (insn != null) {\r\n        if (insn instanceof LabelNode) {\r\n            ((LabelNode) insn).resetLabel();\r\n        }\r\n        insn = insn.next;\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LogisticClassifier.justificationOf",
	"Comment": "returns the weights assigned by the classifier to each feature",
	"Method": "Counter<F> justificationOf(Counter<F> features,Counter<F> justificationOf,Collection<F> features){\r\n    Counter<F> fWts = new ClassicCounter();\r\n    for (F feature : features) {\r\n        int f = featureIndex.indexOf(feature);\r\n        if (f >= 0) {\r\n            fWts.incrementCount(feature, weights[f]);\r\n        }\r\n    }\r\n    return fWts;\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.putField",
	"Comment": "generates the instruction to store the top stack value in a non staticfield.",
	"Method": "void putField(Type owner,String name,Type type){\r\n    fieldInsn(Opcodes.PUTFIELD, owner, name, type);\r\n}"
}, {
	"Path": "org.apache.commons.codec.net.QuotedPrintableCodec.getDefaultCharset",
	"Comment": "gets the default charset name used for string decoding and encoding.",
	"Method": "String getDefaultCharset(){\r\n    return this.charset.name();\r\n}"
}, {
	"Path": "org.objectweb.asm.xml.ASMContentHandler.pop",
	"Comment": "pop the top object off of the stack, and return it. if there are noobjects on the stack, return null.",
	"Method": "Object pop(){\r\n    int size = stack.size();\r\n    return size == 0 ? null : stack.remove(size - 1);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.excelify",
	"Comment": "process string to be a cell in excel file.escape any quotes in the string and enclose the whole string with quotes.",
	"Method": "String excelify(String s){\r\n    return '\"' + s.replace(\"\\\"\", \"\\\"\\\"\") + '\"';\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.Dataset.readSVMLightFormat",
	"Comment": "constructs a dataset by reading in a file in svm light format.the created dataset has the same feature and label index as given",
	"Method": "Dataset<String, String> readSVMLightFormat(String filename,Dataset<String, String> readSVMLightFormat,String filename,List<String> lines,Dataset<String, String> readSVMLightFormat,String filename,Index<String> featureIndex,Index<String> labelIndex,Dataset<String, String> readSVMLightFormat,String filename,Index<String> featureIndex,Index<String> labelIndex,List<String> lines){\r\n    Dataset<String, String> dataset;\r\n    try {\r\n        dataset = new Dataset(10, featureIndex, labelIndex);\r\n        for (String line : ObjectBank.getLineIterator(new File(filename))) {\r\n            if (lines != null)\r\n                lines.add(line);\r\n            dataset.add(svmLightLineToDatum(line));\r\n        }\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n    return dataset;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.stats.StatsCounter.disabledStatsCounter",
	"Comment": "returns an accumulator that does not record any cache events.",
	"Method": "StatsCounter disabledStatsCounter(){\r\n    return DisabledStatsCounter.INSTANCE;\r\n}"
}, {
	"Path": "org.apache.commons.cli.HelpFormatter.renderOptions",
	"Comment": "render the specified options and return the rendered optionsin a stringbuffer.",
	"Method": "StringBuffer renderOptions(StringBuffer sb,int width,Options options,int leftPad,int descPad){\r\n    final String lpad = createPadding(leftPad);\r\n    final String dpad = createPadding(descPad);\r\n    int max = 0;\r\n    List<StringBuffer> prefixList = new ArrayList<StringBuffer>();\r\n    List<Option> optList = options.helpOptions();\r\n    if (getOptionComparator() != null) {\r\n        Collections.sort(optList, getOptionComparator());\r\n    }\r\n    for (Option option : optList) {\r\n        StringBuffer optBuf = new StringBuffer();\r\n        if (option.getOpt() == null) {\r\n            optBuf.append(lpad).append(\"   \").append(getLongOptPrefix()).append(option.getLongOpt());\r\n        } else {\r\n            optBuf.append(lpad).append(getOptPrefix()).append(option.getOpt());\r\n            if (option.hasLongOpt()) {\r\n                optBuf.append(',').append(getLongOptPrefix()).append(option.getLongOpt());\r\n            }\r\n        }\r\n        if (option.hasArg()) {\r\n            String argName = option.getArgName();\r\n            if (argName != null && argName.length() == 0) {\r\n                optBuf.append(' ');\r\n            } else {\r\n                optBuf.append(option.hasLongOpt() ? longOptSeparator : \" \");\r\n                optBuf.append(\"<\").append(argName != null ? option.getArgName() : getArgName()).append(\">\");\r\n            }\r\n        }\r\n        prefixList.add(optBuf);\r\n        max = optBuf.length() > max ? optBuf.length() : max;\r\n    }\r\n    int x = 0;\r\n    for (Iterator<Option> it = optList.iterator(); it.hasNext(); ) {\r\n        Option option = it.next();\r\n        StringBuilder optBuf = new StringBuilder(prefixList.get(x++).toString());\r\n        if (optBuf.length() < max) {\r\n            optBuf.append(createPadding(max - optBuf.length()));\r\n        }\r\n        optBuf.append(dpad);\r\n        int nextLineTabStop = max + descPad;\r\n        if (option.getDescription() != null) {\r\n            optBuf.append(option.getDescription());\r\n        }\r\n        renderWrappedText(sb, width, nextLineTabStop, optBuf.toString());\r\n        if (it.hasNext()) {\r\n            sb.append(getNewLine());\r\n        }\r\n    }\r\n    return sb;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.two_queue.TuQueuePolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new TuQueuePolicy(config));\r\n}"
}, {
	"Path": "com.android.dx.rop.code.LocalVariableInfo.getStarts0",
	"Comment": "helper method, to get the starts for a label, throwing theright exception for range problems.",
	"Method": "RegisterSpecSet getStarts0(int label){\r\n    try {\r\n        return blockStarts[label];\r\n    } catch (ArrayIndexOutOfBoundsException ex) {\r\n        throw new IllegalArgumentException(\"bogus label\");\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.InsnList.get",
	"Comment": "returns the instruction whose index is given. this method builds a cacheof the instructions in this list to avoid scanning the whole list eachtime it is called. once the cache is built, this method run in constanttime. this cache is invalidated by all the methods that modify the list.",
	"Method": "AbstractInsnNode get(int index){\r\n    if (index < 0 || index >= size) {\r\n        throw new IndexOutOfBoundsException();\r\n    }\r\n    if (cache == null) {\r\n        cache = toArray();\r\n    }\r\n    return cache[index];\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.newString",
	"Comment": "adds a string to the constant pool of the class being build. does nothingif the constant pool already contains a similar item.",
	"Method": "Item newString(String value){\r\n    key2.set(STR, value, null, null);\r\n    Item result = get(key2);\r\n    if (result == null) {\r\n        pool.put12(STR, newUTF8(value));\r\n        result = new Item(index++, key2);\r\n        put(result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.sievepasses.DeterministicCorefSieve.coreferent",
	"Comment": "checks if two clusters are coreferent according to our sieve pass constraints.",
	"Method": "boolean coreferent(Document document,CorefCluster mentionCluster,CorefCluster potentialAntecedent,Mention mention2,Mention ant,Dictionaries dict,Set<Mention> roleSet,Semantics semantics){\r\n    boolean ret = false;\r\n    Mention mention = mentionCluster.getRepresentativeMention();\r\n    if (flags.USE_INCOMPATIBLES) {\r\n        if (document.isIncompatible(mentionCluster, potentialAntecedent)) {\r\n            SieveCoreferenceSystem.logger.finest(\"INCOMPATIBLE clusters: not match: \" + ant.spanToString() + \"(\" + ant.mentionID + \") :: \" + mention.spanToString() + \"(\" + mention.mentionID + \") -> \" + (mention.goldCorefClusterID != ant.goldCorefClusterID));\r\n            return false;\r\n        }\r\n    }\r\n    if (flags.DO_PRONOUN && Math.abs(mention2.sentNum - ant.sentNum) > 3 && mention2.person != Person.I && mention2.person != Person.YOU) {\r\n        return false;\r\n    }\r\n    if (mention2.lowercaseNormalizedSpanString().equals(\"this\") && Math.abs(mention2.sentNum - ant.sentNum) > 3) {\r\n        return false;\r\n    }\r\n    if (mention2.person == Person.YOU && document.docType == DocType.ARTICLE && mention2.headWord.get(CoreAnnotations.SpeakerAnnotation.class).equals(\"PER0\")) {\r\n        return false;\r\n    }\r\n    if (document.conllDoc != null) {\r\n        if (ant.generic && ant.person == Person.YOU)\r\n            return false;\r\n        if (mention2.generic)\r\n            return false;\r\n    }\r\n    if (mention2.insideIn(ant) || ant.insideIn(mention2))\r\n        return false;\r\n    if (flags.USE_DISCOURSEMATCH) {\r\n        String mString = mention.lowercaseNormalizedSpanString();\r\n        String antString = ant.lowercaseNormalizedSpanString();\r\n        if (mention.speakerInfo != null && mention.speakerInfo == ant.speakerInfo) {\r\n            SieveCoreferenceSystem.logger.finest(\"discourse match: maps to same speaker: \" + mention.spanToString() + \"\\tmatched\\t\" + ant.spanToString());\r\n            return true;\r\n        }\r\n        if (mention.number == Number.SINGULAR && dict.firstPersonPronouns.contains(mString) && ant.number == Number.SINGULAR && dict.firstPersonPronouns.contains(antString) && Rules.entitySameSpeaker(document, mention, ant)) {\r\n            SieveCoreferenceSystem.logger.finest(\"discourse match: 1st person same speaker: \" + mention.spanToString() + \"\\tmatched\\t\" + ant.spanToString());\r\n            return true;\r\n        }\r\n        if ((mention.number == Number.SINGULAR && dict.firstPersonPronouns.contains(mString)) && Rules.antecedentIsMentionSpeaker(document, mention, ant, dict)) {\r\n            SieveCoreferenceSystem.logger.finest(\"discourse match: 1st person mention speaker match antecedent: \" + mention.spanToString() + \"\\tmatched\\t\" + ant.spanToString());\r\n            if (mention.speakerInfo == null && ant.speakerInfo != null) {\r\n                mention.speakerInfo = ant.speakerInfo;\r\n            }\r\n            return true;\r\n        }\r\n        if ((ant.number == Number.SINGULAR && dict.firstPersonPronouns.contains(antString)) && Rules.antecedentIsMentionSpeaker(document, ant, mention, dict)) {\r\n            SieveCoreferenceSystem.logger.finest(\"discourse match: 1st person antecedent speaker match mention: \" + mention.spanToString() + \"\\tmatched\\t\" + ant.spanToString());\r\n            if (ant.speakerInfo == null && mention.speakerInfo != null) {\r\n                ant.speakerInfo = mention.speakerInfo;\r\n            }\r\n            return true;\r\n        }\r\n        if (dict.secondPersonPronouns.contains(mString) && dict.secondPersonPronouns.contains(antString) && Rules.entitySameSpeaker(document, mention, ant)) {\r\n            SieveCoreferenceSystem.logger.finest(\"discourse match: 2nd person same speaker: \" + mention.spanToString() + \"\\tmatched\\t\" + ant.spanToString());\r\n            return true;\r\n        }\r\n        if (((mention.person == Person.I && ant.person == Person.YOU || (mention.person == Person.YOU && ant.person == Person.I)) && (mention.headWord.get(CoreAnnotations.UtteranceAnnotation.class) - ant.headWord.get(CoreAnnotations.UtteranceAnnotation.class) == 1) && document.docType == DocType.CONVERSATION)) {\r\n            SieveCoreferenceSystem.logger.finest(\"discourse match: between two person: \" + mention.spanToString() + \"\\tmatched\\t\" + ant.spanToString());\r\n            return true;\r\n        }\r\n        if (dict.reflexivePronouns.contains(mention.headString) && Rules.entitySubjectObject(mention, ant)) {\r\n            SieveCoreferenceSystem.logger.finest(\"discourse match: reflexive pronoun: \" + ant.spanToString() + \"(\" + ant.mentionID + \") :: \" + mention.spanToString() + \"(\" + mention.mentionID + \") -> \" + (mention.goldCorefClusterID == ant.goldCorefClusterID));\r\n            return true;\r\n        }\r\n    }\r\n    if (Constants.USE_DISCOURSE_CONSTRAINTS && !flags.USE_EXACTSTRINGMATCH && !flags.USE_RELAXED_EXACTSTRINGMATCH && !flags.USE_APPOSITION && !flags.USE_WORDS_INCLUSION) {\r\n        for (Mention m : mentionCluster.getCorefMentions()) {\r\n            for (Mention a : potentialAntecedent.getCorefMentions()) {\r\n                if (m.person != Person.I && a.person != Person.I && (Rules.antecedentIsMentionSpeaker(document, m, a, dict) || Rules.antecedentIsMentionSpeaker(document, a, m, dict))) {\r\n                    SieveCoreferenceSystem.logger.finest(\"Incompatibles: not match(speaker): \" + ant.spanToString() + \"(\" + ant.mentionID + \") :: \" + mention.spanToString() + \"(\" + mention.mentionID + \") -> \" + (mention.goldCorefClusterID != ant.goldCorefClusterID));\r\n                    document.addIncompatible(m, a);\r\n                    return false;\r\n                }\r\n                int dist = Math.abs(m.headWord.get(CoreAnnotations.UtteranceAnnotation.class) - a.headWord.get(CoreAnnotations.UtteranceAnnotation.class));\r\n                if (document.docType != DocType.ARTICLE && dist == 1 && !Rules.entitySameSpeaker(document, m, a)) {\r\n                    String mSpeaker = document.speakers.get(m.headWord.get(CoreAnnotations.UtteranceAnnotation.class));\r\n                    String aSpeaker = document.speakers.get(a.headWord.get(CoreAnnotations.UtteranceAnnotation.class));\r\n                    if (m.person == Person.I && a.person == Person.I) {\r\n                        SieveCoreferenceSystem.logger.finest(\"Incompatibles: neighbor I: \" + ant.spanToString() + \"(\" + ant.mentionID + \",\" + aSpeaker + \") :: \" + mention.spanToString() + \"(\" + mention.mentionID + \",\" + mSpeaker + \") -> \" + (mention.goldCorefClusterID != ant.goldCorefClusterID));\r\n                        document.addIncompatible(m, a);\r\n                        return false;\r\n                    }\r\n                    if (m.person == Person.YOU && a.person == Person.YOU) {\r\n                        SieveCoreferenceSystem.logger.finest(\"Incompatibles: neighbor YOU: \" + ant.spanToString() + \"(\" + ant.mentionID + \",\" + aSpeaker + \") :: \" + mention.spanToString() + \"(\" + mention.mentionID + \",\" + mSpeaker + \") -> \" + (mention.goldCorefClusterID != ant.goldCorefClusterID));\r\n                        document.addIncompatible(m, a);\r\n                        return false;\r\n                    }\r\n                    if (m.person == Person.WE && a.person == Person.WE) {\r\n                        SieveCoreferenceSystem.logger.finest(\"Incompatibles: neighbor WE: \" + ant.spanToString() + \"(\" + ant.mentionID + \",\" + aSpeaker + \") :: \" + mention.spanToString() + \"(\" + mention.mentionID + \",\" + mSpeaker + \") -> \" + (mention.goldCorefClusterID != ant.goldCorefClusterID));\r\n                        document.addIncompatible(m, a);\r\n                        return false;\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        if (document.docType == DocType.ARTICLE) {\r\n            for (Mention m : mentionCluster.getCorefMentions()) {\r\n                for (Mention a : potentialAntecedent.getCorefMentions()) {\r\n                    if (Rules.entitySubjectObject(m, a)) {\r\n                        SieveCoreferenceSystem.logger.finest(\"Incompatibles: subject-object: \" + ant.spanToString() + \"(\" + ant.mentionID + \") :: \" + mention.spanToString() + \"(\" + mention.mentionID + \") -> \" + (mention.goldCorefClusterID != ant.goldCorefClusterID));\r\n                        document.addIncompatible(m, a);\r\n                        return false;\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n    if (flags.USE_iwithini && Rules.entityIWithinI(mention, ant, dict)) {\r\n        SieveCoreferenceSystem.logger.finest(\"Incompatibles: iwithini: \" + ant.spanToString() + \"(\" + ant.mentionID + \") :: \" + mention.spanToString() + \"(\" + mention.mentionID + \") -> \" + (mention.goldCorefClusterID != ant.goldCorefClusterID));\r\n        document.addIncompatible(mention, ant);\r\n        return false;\r\n    }\r\n    if (flags.USE_EXACTSTRINGMATCH && Rules.entityExactStringMatch(mentionCluster, potentialAntecedent, dict, roleSet)) {\r\n        return true;\r\n    }\r\n    if (flags.USE_NAME_MATCH && checkEntityMatch(document, mentionCluster, potentialAntecedent, dict, roleSet)) {\r\n        ret = true;\r\n    }\r\n    if (flags.USE_RELAXED_EXACTSTRINGMATCH && Rules.entityRelaxedExactStringMatch(mentionCluster, potentialAntecedent, mention, ant, dict, roleSet)) {\r\n        return true;\r\n    }\r\n    if (flags.USE_APPOSITION && Rules.entityIsApposition(mentionCluster, potentialAntecedent, mention, ant)) {\r\n        SieveCoreferenceSystem.logger.finest(\"Apposition: \" + mention.spanToString() + \"\\tvs\\t\" + ant.spanToString());\r\n        return true;\r\n    }\r\n    if (flags.USE_PREDICATENOMINATIVES && Rules.entityIsPredicateNominatives(mentionCluster, potentialAntecedent, mention, ant)) {\r\n        SieveCoreferenceSystem.logger.finest(\"Predicate nominatives: \" + mention.spanToString() + \"\\tvs\\t\" + ant.spanToString());\r\n        return true;\r\n    }\r\n    if (flags.USE_ACRONYM && Rules.entityIsAcronym(document, mentionCluster, potentialAntecedent)) {\r\n        SieveCoreferenceSystem.logger.finest(\"Acronym: \" + mention.spanToString() + \"\\tvs\\t\" + ant.spanToString());\r\n        return true;\r\n    }\r\n    if (flags.USE_RELATIVEPRONOUN && Rules.entityIsRelativePronoun(mention, ant)) {\r\n        SieveCoreferenceSystem.logger.finest(\"Relative pronoun: \" + mention.spanToString() + \"\\tvs\\t\" + ant.spanToString());\r\n        return true;\r\n    }\r\n    if (flags.USE_DEMONYM && mention.isDemonym(ant, dict)) {\r\n        SieveCoreferenceSystem.logger.finest(\"Demonym: \" + mention.spanToString() + \"\\tvs\\t\" + ant.spanToString());\r\n        return true;\r\n    }\r\n    if (flags.USE_ROLEAPPOSITION && lang != Locale.CHINESE && Rules.entityIsRoleAppositive(mentionCluster, potentialAntecedent, mention, ant, dict)) {\r\n        SieveCoreferenceSystem.logger.finest(\"Role Appositive: \" + mention.spanToString() + \"\\tvs\\t\" + ant.spanToString());\r\n        ret = true;\r\n    }\r\n    if (flags.USE_INCLUSION_HEADMATCH && Rules.entityHeadsAgree(mentionCluster, potentialAntecedent, mention, ant, dict)) {\r\n        SieveCoreferenceSystem.logger.finest(\"Entity heads agree: \" + mention.spanToString() + \"\\tvs\\t\" + ant.spanToString());\r\n        ret = true;\r\n    }\r\n    if (flags.USE_RELAXED_HEADMATCH && Rules.entityRelaxedHeadsAgreeBetweenMentions(mentionCluster, potentialAntecedent, mention, ant)) {\r\n        ret = true;\r\n    }\r\n    if (flags.USE_WORDS_INCLUSION && ret && !Rules.entityWordsIncluded(mentionCluster, potentialAntecedent, mention, ant)) {\r\n        return false;\r\n    }\r\n    if (flags.USE_INCOMPATIBLE_MODIFIER && ret && Rules.entityHaveIncompatibleModifier(mentionCluster, potentialAntecedent)) {\r\n        return false;\r\n    }\r\n    if (flags.USE_PROPERHEAD_AT_LAST && ret && !Rules.entitySameProperHeadLastWord(mentionCluster, potentialAntecedent, mention, ant)) {\r\n        return false;\r\n    }\r\n    if (flags.USE_ATTRIBUTES_AGREE && !Rules.entityAttributesAgree(mentionCluster, potentialAntecedent)) {\r\n        return false;\r\n    }\r\n    if (flags.USE_DIFFERENT_LOCATION && Rules.entityHaveDifferentLocation(mention, ant, dict)) {\r\n        if (flags.USE_PROPERHEAD_AT_LAST && ret && mention.goldCorefClusterID != ant.goldCorefClusterID) {\r\n            SieveCoreferenceSystem.logger.finest(\"DIFFERENT LOCATION: \" + ant.spanToString() + \" :: \" + mention.spanToString());\r\n        }\r\n        return false;\r\n    }\r\n    if (flags.USE_NUMBER_IN_MENTION && Rules.entityNumberInLaterMention(mention, ant)) {\r\n        if (flags.USE_PROPERHEAD_AT_LAST && ret && mention.goldCorefClusterID != ant.goldCorefClusterID) {\r\n            SieveCoreferenceSystem.logger.finest(\"NEW NUMBER : \" + ant.spanToString() + \" :: \" + mention.spanToString());\r\n        }\r\n        return false;\r\n    }\r\n    if (flags.USE_WN_HYPERNYM) {\r\n        Method meth = semantics.wordnet.getClass().getMethod(\"checkHypernym\", CorefCluster.class, CorefCluster.class, Mention.class, Mention.class);\r\n        if ((Boolean) meth.invoke(semantics.wordnet, mentionCluster, potentialAntecedent, mention, ant)) {\r\n            ret = true;\r\n        } else if (mention.goldCorefClusterID == ant.goldCorefClusterID && !mention.isPronominal() && !ant.isPronominal()) {\r\n            SieveCoreferenceSystem.logger.finest(\"not hypernym in WN\");\r\n            SieveCoreferenceSystem.logger.finest(\"False Negatives:: \" + ant.spanToString() + \" <= \" + mention.spanToString());\r\n        }\r\n    }\r\n    if (flags.USE_WN_SYNONYM) {\r\n        Method meth = semantics.wordnet.getClass().getMethod(\"checkSynonym\", new Class[] { Mention.class, Mention.class });\r\n        if ((Boolean) meth.invoke(semantics.wordnet, mention, ant)) {\r\n            ret = true;\r\n        } else if (mention.goldCorefClusterID == ant.goldCorefClusterID && !mention.isPronominal() && !ant.isPronominal()) {\r\n            SieveCoreferenceSystem.logger.finest(\"not synonym in WN\");\r\n            SieveCoreferenceSystem.logger.finest(\"False Negatives:: \" + ant.spanToString() + \" <= \" + mention.spanToString());\r\n        }\r\n    }\r\n    try {\r\n        if (flags.USE_ALIAS && Rules.entityAlias(mentionCluster, potentialAntecedent, semantics, dict)) {\r\n            return true;\r\n        }\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n    if (flags.USE_DISTANCE && Rules.entityTokenDistance(mention2, ant)) {\r\n        return false;\r\n    }\r\n    if (flags.USE_COREF_DICT) {\r\n        if (ant.headWord.lemma().equals(mention2.headWord.lemma()))\r\n            return false;\r\n        if (ant.mentionType != MentionType.PROPER && (mention2.headWord.get(CoreAnnotations.PartOfSpeechAnnotation.class).startsWith(\"NNP\") || !mention2.headWord.word().substring(1).equals(mention2.headWord.word().substring(1).toLowerCase()))) {\r\n            return false;\r\n        }\r\n        if (ant.headWord.get(CoreAnnotations.PartOfSpeechAnnotation.class).equals(\"NNS\") && mention2.headWord.get(CoreAnnotations.PartOfSpeechAnnotation.class).equals(\"NNS\"))\r\n            return false;\r\n        if (dict.indefinitePronouns.contains(ant.originalSpan.get(0).lemma()) || dict.indefinitePronouns.contains(mention2.originalSpan.get(0).lemma()))\r\n            return false;\r\n        if (ant.isCoordinated() || mention2.isCoordinated())\r\n            return false;\r\n        if (Rules.contextIncompatible(mention2, ant, dict))\r\n            return false;\r\n        if (Rules.sentenceContextIncompatible(mention2, ant, dict))\r\n            return false;\r\n        if (Rules.entityClusterAllCorefDictionary(mentionCluster, potentialAntecedent, dict, 1, 8))\r\n            return true;\r\n        if (Rules.entityCorefDictionary(mention, ant, dict, 2, 2))\r\n            return true;\r\n        if (Rules.entityCorefDictionary(mention, ant, dict, 3, 2))\r\n            return true;\r\n        if (Rules.entityCorefDictionary(mention, ant, dict, 4, 2))\r\n            return true;\r\n    }\r\n    if (flags.DO_PRONOUN) {\r\n        Mention m;\r\n        if (mention.predicateNominatives != null && mention.predicateNominatives.contains(mention2)) {\r\n            m = mention2;\r\n        } else {\r\n            m = mention;\r\n        }\r\n        if ((m.isPronominal() || dict.allPronouns.contains(m.toString())) && Rules.entityAttributesAgree(mentionCluster, potentialAntecedent)) {\r\n            if (dict.demonymSet.contains(ant.lowercaseNormalizedSpanString()) && dict.notOrganizationPRP.contains(m.headString)) {\r\n                document.addIncompatible(m, ant);\r\n                return false;\r\n            }\r\n            if (Constants.USE_DISCOURSE_CONSTRAINTS && Rules.entityPersonDisagree(document, mentionCluster, potentialAntecedent, dict)) {\r\n                SieveCoreferenceSystem.logger.finest(\"Incompatibles: Person Disagree: \" + ant.spanToString() + \"(\" + ant.mentionID + \") :: \" + mention.spanToString() + \"(\" + mention.mentionID + \") -> \" + (mention.goldCorefClusterID != ant.goldCorefClusterID));\r\n                document.addIncompatible(m, ant);\r\n                return false;\r\n            }\r\n            return true;\r\n        }\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sampled.SampledPolicy.removeFromTable",
	"Comment": "removes the node from the table and adds the index to the free list.",
	"Method": "void removeFromTable(Node node){\r\n    int last = data.size() - 1;\r\n    table[node.index] = table[last];\r\n    table[node.index].index = node.index;\r\n    table[last] = null;\r\n}"
}, {
	"Path": "org.apereo.cas.support.wsfederation.WsFederationHelper.createCredentialFromToken",
	"Comment": "createcredentialfromtoken converts a saml 1.1 assertion to a wsfederationcredential.",
	"Method": "WsFederationCredential createCredentialFromToken(Assertion assertion){\r\n    val retrievedOn = ZonedDateTime.now();\r\n    LOGGER.debug(\"Retrieved on [{}]\", retrievedOn);\r\n    val credential = new WsFederationCredential();\r\n    credential.setRetrievedOn(retrievedOn);\r\n    credential.setId(assertion.getID());\r\n    credential.setIssuer(assertion.getIssuer());\r\n    credential.setIssuedOn(ZonedDateTime.parse(assertion.getIssueInstant().toDateTimeISO().toString()));\r\n    val conditions = assertion.getConditions();\r\n    if (conditions != null) {\r\n        credential.setNotBefore(ZonedDateTime.parse(conditions.getNotBefore().toDateTimeISO().toString()));\r\n        credential.setNotOnOrAfter(ZonedDateTime.parse(conditions.getNotOnOrAfter().toDateTimeISO().toString()));\r\n        if (!conditions.getAudienceRestrictionConditions().isEmpty()) {\r\n            credential.setAudience(conditions.getAudienceRestrictionConditions().get(0).getAudiences().get(0).getUri());\r\n        }\r\n    }\r\n    if (!assertion.getAuthenticationStatements().isEmpty()) {\r\n        credential.setAuthenticationMethod(assertion.getAuthenticationStatements().get(0).getAuthenticationMethod());\r\n    }\r\n    val attributes = new HashMap<String, List<Object>>();\r\n    assertion.getAttributeStatements().stream().flatMap(attributeStatement -> attributeStatement.getAttributes().stream()).forEach(item -> {\r\n        LOGGER.debug(\"Processed attribute: [{}]\", item.getAttributeName());\r\n        final List<Object> itemList = item.getAttributeValues().stream().map(xmlObject -> ((XSAny) xmlObject).getTextContent()).collect(Collectors.toList());\r\n        if (!itemList.isEmpty()) {\r\n            attributes.put(item.getAttributeName(), itemList);\r\n        }\r\n    });\r\n    credential.setAttributes(attributes);\r\n    LOGGER.debug(\"Credential: [{}]\", credential);\r\n    return credential;\r\n}"
}, {
	"Path": "org.apereo.cas.util.function.ComposableFunction.andNext",
	"Comment": "chain this function with a consumer that expects the same type.",
	"Method": "Consumer<T> andNext(Consumer<R> after){\r\n    Objects.requireNonNull(after);\r\n    return t -> after.accept(apply(t));\r\n}"
}, {
	"Path": "com.android.dx.rop.code.SourcePosition.sameLineAndFile",
	"Comment": "returns whether the lines and files match between this instance andthe one given.",
	"Method": "boolean sameLineAndFile(SourcePosition other){\r\n    return (line == other.line) && ((sourceFile == other.sourceFile) || ((sourceFile != null) && sourceFile.equals(other.sourceFile)));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.CacheProxy.getAndFilterExpiredEntries",
	"Comment": "returns all of the mappings present, expiring as required, and optionally updates their accessexpiry time.",
	"Method": "Map<K, Expirable<V>> getAndFilterExpiredEntries(Set<? extends K> keys,boolean updateAccessTime){\r\n    Map<K, Expirable<V>> result = new HashMap(cache.getAllPresent(keys));\r\n    int[] expired = { 0 };\r\n    long[] millis = { 0L };\r\n    result.entrySet().removeIf(entry -> {\r\n        if (!entry.getValue().isEternal() && (millis[0] == 0L)) {\r\n            millis[0] = currentTimeMillis();\r\n        }\r\n        if (entry.getValue().hasExpired(millis[0])) {\r\n            cache.asMap().computeIfPresent(entry.getKey(), (k, expirable) -> {\r\n                if (expirable == entry.getValue()) {\r\n                    dispatcher.publishExpired(this, entry.getKey(), entry.getValue().get());\r\n                    expired[0]++;\r\n                    return null;\r\n                }\r\n                return expirable;\r\n            });\r\n            return true;\r\n        }\r\n        if (updateAccessTime) {\r\n            setAccessExpirationTime(entry.getValue(), millis[0]);\r\n        }\r\n        return false;\r\n    });\r\n    statistics.recordHits(result.size());\r\n    statistics.recordMisses(keys.size() - result.size());\r\n    statistics.recordEvictions(expired[0]);\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.client.LdapSpnegoKnownClientSystemsFilterAction.createConnection",
	"Comment": "create and open a connection to ldapvia the given config and provider.",
	"Method": "Connection createConnection(){\r\n    LOGGER.debug(\"Establishing a connection...\");\r\n    val connection = this.connectionFactory.getConnection();\r\n    connection.open();\r\n    return connection;\r\n}"
}, {
	"Path": "com.facebook.buck.tools.consistency.CliArgs.wasHelpRequested",
	"Comment": "determines whether something went wrong, or whether we are just showing the help message asrequested",
	"Method": "boolean wasHelpRequested(List<String> args){\r\n    return this.showHelp || (this.cmd != null && this.cmd.showHelp) || args.contains(\"--help\");\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.BeiderMorseEncoder.setConcat",
	"Comment": "sets how multiple possible phonetic encodings are combined.",
	"Method": "void setConcat(boolean concat){\r\n    this.engine = new PhoneticEngine(this.engine.getNameType(), this.engine.getRuleType(), concat, this.engine.getMaxPhonemes());\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.GeneralizedExpectationObjectiveFunction.valueOfFeature",
	"Comment": "this method assumes the feature already exists in the datum.",
	"Method": "double valueOfFeature(F feature,Datum<L, F> datum){\r\n    if (datum instanceof RVFDatum)\r\n        return ((RVFDatum<L, F>) datum).asFeaturesCounter().getCount(feature);\r\n    else\r\n        return 1.0;\r\n}"
}, {
	"Path": "org.objectweb.asm.util.CheckClassAdapter.checkAccess",
	"Comment": "checks that the given access flags do not contain invalid flags. thismethod also checks that mutually incompatible flags are not setsimultaneously.",
	"Method": "void checkAccess(int access,int possibleAccess){\r\n    if ((access & ~possibleAccess) != 0) {\r\n        throw new IllegalArgumentException(\"Invalid access flags: \" + access);\r\n    }\r\n    int pub = (access & Opcodes.ACC_PUBLIC) == 0 ? 0 : 1;\r\n    int pri = (access & Opcodes.ACC_PRIVATE) == 0 ? 0 : 1;\r\n    int pro = (access & Opcodes.ACC_PROTECTED) == 0 ? 0 : 1;\r\n    if (pub + pri + pro > 1) {\r\n        throw new IllegalArgumentException(\"public private and protected are mutually exclusive: \" + access);\r\n    }\r\n    int fin = (access & Opcodes.ACC_FINAL) == 0 ? 0 : 1;\r\n    int abs = (access & Opcodes.ACC_ABSTRACT) == 0 ? 0 : 1;\r\n    if (fin + abs > 1) {\r\n        throw new IllegalArgumentException(\"final and abstract are mutually exclusive: \" + access);\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.digest.HmacUtils.getHmacSha384",
	"Comment": "returns an initialized mac for the hmacsha384 algorithm.every implementation of the java platform is not required to support this mac algorithm.",
	"Method": "Mac getHmacSha384(byte[] key){\r\n    return getInitializedMac(HmacAlgorithms.HMAC_SHA_384, key);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.product.GuavaPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new GuavaPolicy(config));\r\n}"
}, {
	"Path": "org.objectweb.asm.MethodVisitor.visitAnnotationDefault",
	"Comment": "visits the default value of this annotation interface method.",
	"Method": "AnnotationVisitor visitAnnotationDefault(){\r\n    if (mv != null) {\r\n        return mv.visitAnnotationDefault();\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.node.AddDeques.addFieldAndGetter",
	"Comment": "adds a simple field, accessor, and mutator for the variable.",
	"Method": "void addFieldAndGetter(String varName){\r\n    context.nodeSubtype.addField(NODE, varName).addMethod(newGetter(Strength.STRONG, NODE, varName, Visibility.IMMEDIATE)).addMethod(newSetter(NODE, varName, Visibility.IMMEDIATE));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.tinycache.TinyCacheWithGhostCachePolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new TinyCacheWithGhostCachePolicy(config));\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.principal.PersistentIdGenerator.generate",
	"Comment": "generates a persistentid based on some algorithm plus the principal.",
	"Method": "String generate(String principal,String service,String generate,Principal principal,Service service,String generate,Principal principal){\r\n    return generate(principal, null);\r\n}"
}, {
	"Path": "org.apache.commons.cli.Options.addOption",
	"Comment": "add an option that only contains a short name.the option does not take an argument.",
	"Method": "Options addOption(String opt,String description,Options addOption,String opt,boolean hasArg,String description,Options addOption,String opt,String longOpt,boolean hasArg,String description,Options addOption,Option opt){\r\n    String key = opt.getKey();\r\n    if (opt.hasLongOpt()) {\r\n        longOpts.put(opt.getLongOpt(), opt);\r\n    }\r\n    if (opt.isRequired()) {\r\n        if (requiredOpts.contains(key)) {\r\n            requiredOpts.remove(requiredOpts.indexOf(key));\r\n        }\r\n        requiredOpts.add(key);\r\n    }\r\n    shortOpts.put(key, opt);\r\n    return this;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.PRCurve.cwa",
	"Comment": "confidence weighted accuracy assuming the scores are probabilities and using .5 as treshold",
	"Method": "double cwa(){\r\n    double acc = 0;\r\n    for (int recall = 1; recall <= numSamples(); recall++) {\r\n        acc += logPrecision(recall) / (double) recall;\r\n    }\r\n    return acc / numSamples();\r\n}"
}, {
	"Path": "org.apereo.cas.web.AbstractServiceValidateController.augmentSuccessViewModelObjects",
	"Comment": "augment success view model objects. providesa way for extension of this controller to dynamicallypopulate the model object with attributesthat describe a custom nature of the validation protocol.",
	"Method": "Map<String, ?> augmentSuccessViewModelObjects(Assertion assertion){\r\n    return new HashMap(0);\r\n}"
}, {
	"Path": "org.apereo.cas.adaptors.x509.authentication.ResourceCRLFetcher.fetch",
	"Comment": "fetch the resource. designed so that extensionscan decide how the resource should be retrieved.",
	"Method": "Collection<X509CRL> fetch(Collection<Resource> crls,X509CRL fetch,String crl,X509CRL fetch,Resource crl,X509CRL fetch,URI crl,X509CRL fetch,URL crl){\r\n    return fetch(new UrlResource(crl));\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.RelationMention.replaceGoldArgsWithPredicted",
	"Comment": "replaces the arguments of this relations with equivalent mentions from the predictedmentions listthis works only for arguments that are entitymention!",
	"Method": "boolean replaceGoldArgsWithPredicted(List<EntityMention> predictedMentions){\r\n    List<ExtractionObject> newArgs = new ArrayList();\r\n    for (ExtractionObject arg : args) {\r\n        if (!(arg instanceof EntityMention)) {\r\n            continue;\r\n        }\r\n        EntityMention goldEnt = (EntityMention) arg;\r\n        EntityMention newArg = null;\r\n        for (EntityMention pred : predictedMentions) {\r\n            if (goldEnt.textEquals(pred)) {\r\n                newArg = pred;\r\n                break;\r\n            }\r\n        }\r\n        if (newArg != null) {\r\n            newArgs.add(newArg);\r\n            logger.info(\"Replacing relation argument: [\" + goldEnt + \"] with predicted mention [\" + newArg + \"]\");\r\n        } else {\r\n            newArgs.add(goldEnt);\r\n            predictedMentions.add(goldEnt);\r\n            logger.info(\"Failed to match relation argument, so keeping gold: \" + goldEnt);\r\n        }\r\n    }\r\n    this.args = newArgs;\r\n    return true;\r\n}"
}, {
	"Path": "org.apache.commons.cli.Util.stripLeadingHyphens",
	"Comment": "remove the hyphens from the beginning of str andreturn the new string.",
	"Method": "String stripLeadingHyphens(String str){\r\n    if (str == null) {\r\n        return null;\r\n    }\r\n    if (str.startsWith(\"--\")) {\r\n        return str.substring(2, str.length());\r\n    } else if (str.startsWith(\"-\")) {\r\n        return str.substring(1, str.length());\r\n    }\r\n    return str;\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getType",
	"Comment": "returns the java type corresponding to the given type descriptor. formethod descriptors, buf is supposed to contain nothing more than thedescriptor itself.",
	"Method": "Type getType(String typeDescriptor,Type getType,Class<?> c,Type getType,Constructor<?> c,Type getType,Method m,Type getType,char[] buf,int off){\r\n    int len;\r\n    switch(buf[off]) {\r\n        case 'V':\r\n            return VOID_TYPE;\r\n        case 'Z':\r\n            return BOOLEAN_TYPE;\r\n        case 'C':\r\n            return CHAR_TYPE;\r\n        case 'B':\r\n            return BYTE_TYPE;\r\n        case 'S':\r\n            return SHORT_TYPE;\r\n        case 'I':\r\n            return INT_TYPE;\r\n        case 'F':\r\n            return FLOAT_TYPE;\r\n        case 'J':\r\n            return LONG_TYPE;\r\n        case 'D':\r\n            return DOUBLE_TYPE;\r\n        case '[':\r\n            len = 1;\r\n            while (buf[off + len] == '[') {\r\n                ++len;\r\n            }\r\n            if (buf[off + len] == 'L') {\r\n                ++len;\r\n                while (buf[off + len] != ';') {\r\n                    ++len;\r\n                }\r\n            }\r\n            return new Type(ARRAY, buf, off, len + 1);\r\n        case 'L':\r\n            len = 1;\r\n            while (buf[off + len] != ';') {\r\n                ++len;\r\n            }\r\n            return new Type(OBJECT, buf, off + 1, len - 1);\r\n        default:\r\n            return new Type(METHOD, buf, off, buf.length - off);\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.util.CheckClassAdapter.checkFormalTypeParameters",
	"Comment": "checks the formal type parameters of a class or method signature.",
	"Method": "int checkFormalTypeParameters(String signature,int pos){\r\n    pos = checkChar('<', signature, pos);\r\n    pos = checkFormalTypeParameter(signature, pos);\r\n    while (getChar(signature, pos) != '>') {\r\n        pos = checkFormalTypeParameter(signature, pos);\r\n    }\r\n    return pos + 1;\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.insertExceptionThrow",
	"Comment": "replaces instructions that trigger an arrayindexoutofbounds exceptionwith an actual throw of the exception.",
	"Method": "void insertExceptionThrow(SsaInsn insn,RegisterSpec index,HashSet<SsaInsn> deletedInsns){\r\n    CstType exception = new CstType(Exceptions.TYPE_ArrayIndexOutOfBoundsException);\r\n    insertThrowingInsnBefore(insn, RegisterSpecList.EMPTY, null, RegOps.NEW_INSTANCE, exception);\r\n    SsaBasicBlock currBlock = insn.getBlock();\r\n    SsaBasicBlock newBlock = currBlock.insertNewSuccessor(currBlock.getPrimarySuccessor());\r\n    SsaInsn newInsn = newBlock.getInsns().get(0);\r\n    RegisterSpec newReg = RegisterSpec.make(ssaMeth.makeNewSsaReg(), exception);\r\n    insertPlainInsnBefore(newInsn, RegisterSpecList.EMPTY, newReg, RegOps.MOVE_RESULT_PSEUDO, null);\r\n    SsaBasicBlock newBlock2 = newBlock.insertNewSuccessor(newBlock.getPrimarySuccessor());\r\n    SsaInsn newInsn2 = newBlock2.getInsns().get(0);\r\n    CstNat newNat = new CstNat(new CstString(\"<init>\"), new CstString(\"(I)V\"));\r\n    CstMethodRef newRef = new CstMethodRef(exception, newNat);\r\n    insertThrowingInsnBefore(newInsn2, RegisterSpecList.make(newReg, index), null, RegOps.INVOKE_DIRECT, newRef);\r\n    deletedInsns.add(newInsn2);\r\n    SsaBasicBlock newBlock3 = newBlock2.insertNewSuccessor(newBlock2.getPrimarySuccessor());\r\n    SsaInsn newInsn3 = newBlock3.getInsns().get(0);\r\n    insertThrowingInsnBefore(newInsn3, RegisterSpecList.make(newReg), null, RegOps.THROW, null);\r\n    newBlock3.replaceSuccessor(newBlock3.getPrimarySuccessorIndex(), ssaMeth.getExitBlock().getIndex());\r\n    deletedInsns.add(newInsn3);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.Synthetic.exponential",
	"Comment": "returns a sequence of events based on an exponential distribution. smaller intervals are morefrequent than larger ones, and there is no bound on the length of an interval.",
	"Method": "LongStream exponential(double mean,int events){\r\n    return generate(new ExponentialGenerator(mean), events);\r\n}"
}, {
	"Path": "the.bytecode.club.bytecodeviewer.searching.RegexInsnFinder.findAll",
	"Comment": "searches a regex in an instruction list and returns all matches.",
	"Method": "List<AbstractInsnNode[]> findAll(String regex){\r\n    final List<AbstractInsnNode[]> results = new ArrayList<AbstractInsnNode[]>();\r\n    try {\r\n        final Matcher regexMatcher = Pattern.compile(processRegex(regex), Pattern.MULTILINE).matcher(insnString);\r\n        while (regexMatcher.find()) {\r\n            results.add(makeResult(regexMatcher.start(), regexMatcher.end()));\r\n        }\r\n    } catch (final PatternSyntaxException ex) {\r\n        new the.bytecode.club.bytecodeviewer.api.ExceptionUI(ex);\r\n    }\r\n    return results;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.TimerWheel.findBucket",
	"Comment": "determines the bucket that the timer event should be added to.",
	"Method": "Node<K, V> findBucket(long time){\r\n    long duration = time - nanos;\r\n    int length = wheel.length - 1;\r\n    for (int i = 0; i < length; i++) {\r\n        if (duration < SPANS[i + 1]) {\r\n            int ticks = (int) (time >> SHIFT[i]);\r\n            int index = ticks & (wheel[i].length - 1);\r\n            return wheel[i][index];\r\n        }\r\n    }\r\n    return wheel[length][0];\r\n}"
}, {
	"Path": "org.apereo.cas.ticket.registry.BaseTicketRegistryTests.isIterableRegistry",
	"Comment": "determine whether the tested registry is able to iterate its tickets.",
	"Method": "boolean isIterableRegistry(){\r\n    return true;\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.resolver.impl.ServiceTicketRequestWebflowEventResolver.grantServiceTicket",
	"Comment": "grant service ticket for the given credential based on the service and tgtthat are found in the request context.",
	"Method": "Event grantServiceTicket(RequestContext context){\r\n    val ticketGrantingTicketId = WebUtils.getTicketGrantingTicketId(context);\r\n    val credential = getCredentialFromContext(context);\r\n    try {\r\n        val service = WebUtils.getService(context);\r\n        val authn = ticketRegistrySupport.getAuthenticationFrom(ticketGrantingTicketId);\r\n        val registeredService = this.servicesManager.findServiceBy(service);\r\n        if (authn != null && registeredService != null) {\r\n            LOGGER.debug(\"Enforcing access strategy policies for registered service [{}] and principal [{}]\", registeredService, authn.getPrincipal());\r\n            val audit = AuditableContext.builder().service(service).authentication(authn).registeredService(registeredService).retrievePrincipalAttributesFromReleasePolicy(Boolean.TRUE).build();\r\n            val accessResult = this.registeredServiceAccessStrategyEnforcer.execute(audit);\r\n            accessResult.throwExceptionIfNeeded();\r\n        }\r\n        val authenticationResult = this.authenticationSystemSupport.handleAndFinalizeSingleAuthenticationTransaction(service, credential);\r\n        val serviceTicketId = this.centralAuthenticationService.grantServiceTicket(ticketGrantingTicketId, service, authenticationResult);\r\n        WebUtils.putServiceTicketInRequestScope(context, serviceTicketId);\r\n        WebUtils.putWarnCookieIfRequestParameterPresent(this.warnCookieGenerator, context);\r\n        return newEvent(CasWebflowConstants.TRANSITION_ID_WARN);\r\n    } catch (final AuthenticationException | AbstractTicketException e) {\r\n        return newEvent(CasWebflowConstants.TRANSITION_ID_AUTHENTICATION_FAILURE, e);\r\n    }\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.actions.select.AbstractBuckTestAction.truncateName",
	"Comment": "use the same truncating strategy as the junit method action.",
	"Method": "String truncateName(String name){\r\n    if (name.length() >= 21) {\r\n        name = name.substring(0, 18) + \"...\";\r\n    }\r\n    return name;\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.analysis.Frame.getStackSize",
	"Comment": "returns the number of values in the operand stack of this frame. long anddouble values are treated as single values.",
	"Method": "int getStackSize(){\r\n    return top;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.Insn.toStringWithInline",
	"Comment": "returns the string form of this instance, with the given bit added inthe standard location for an inline argument.",
	"Method": "String toStringWithInline(String extra){\r\n    StringBuffer sb = new StringBuffer(80);\r\n    sb.append(\"Insn{\");\r\n    sb.append(position);\r\n    sb.append(' ');\r\n    sb.append(opcode);\r\n    if (extra != null) {\r\n        sb.append(' ');\r\n        sb.append(extra);\r\n    }\r\n    sb.append(\" :: \");\r\n    if (result != null) {\r\n        sb.append(result);\r\n        sb.append(\" <- \");\r\n    }\r\n    sb.append(sources);\r\n    sb.append('}');\r\n    return sb.toString();\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.lang.psi.BuckPsiUtils.findTargetsInPsiTree",
	"Comment": "returns a mapping from rule names that start with the given prefix to their target elements.",
	"Method": "Map<String, PsiElement> findTargetsInPsiTree(PsiFile psiFile,String namePrefix){\r\n    Map<String, PsiElement> targetsByName = new HashMap();\r\n    for (BuckFunctionCall buckRuleBlock : PsiTreeUtil.findChildrenOfType(psiFile, BuckFunctionCall.class)) {\r\n        BuckFunctionCallSuffix buckRuleBody = buckRuleBlock.getFunctionCallSuffix();\r\n        for (BuckArgument buckArgument : PsiTreeUtil.findChildrenOfType(buckRuleBody, BuckArgument.class)) {\r\n            BuckPropertyLvalue propertyLvalue = buckArgument.getPropertyLvalue();\r\n            if (propertyLvalue == null || !\"name\".equals(propertyLvalue.getText())) {\r\n                continue;\r\n            }\r\n            String name = BuckPsiUtils.getStringValueFromExpression(buckArgument.getSingleExpression());\r\n            if (name != null) {\r\n                if (name.startsWith(namePrefix)) {\r\n                    targetsByName.put(name, buckRuleBlock);\r\n                }\r\n                break;\r\n            }\r\n        }\r\n    }\r\n    return targetsByName;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sampled.SampledPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config,EvictionPolicy policy){\r\n    BasicSettings settings = new BasicSettings(config);\r\n    return settings.admission().stream().map(admission -> new SampledPolicy(admission, policy, config)).collect(toSet());\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.principal.NullPrincipal.getInstance",
	"Comment": "returns the single instance of this class. will createone if none exists.",
	"Method": "NullPrincipal getInstance(){\r\n    if (INSTANCE == null) {\r\n        INSTANCE = new NullPrincipal();\r\n    }\r\n    return INSTANCE;\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.not",
	"Comment": "generates the instructions to compute the bitwise negation of the topstack value.",
	"Method": "void not(){\r\n    mv.visitInsn(Opcodes.ICONST_1);\r\n    mv.visitInsn(Opcodes.IXOR);\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.monitorExit",
	"Comment": "generates the instruction to release the monitor of the top stack value.",
	"Method": "void monitorExit(){\r\n    mv.visitInsn(Opcodes.MONITOREXIT);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.product.Cache2kPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new Cache2kPolicy(config));\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.entityMentionsToCoreLabels",
	"Comment": "converts the labels of all entity mentions in this dataset to sequences of corelabels",
	"Method": "List<List<CoreLabel>> entityMentionsToCoreLabels(CoreMap dataset,Set<String> annotationsToSkip,boolean useSubTypes,boolean useBIO){\r\n    List<List<CoreLabel>> retVal = new ArrayList();\r\n    List<CoreMap> sentences = dataset.get(CoreAnnotations.SentencesAnnotation.class);\r\n    for (CoreMap sentence : sentences) {\r\n        List<CoreLabel> labeledSentence = sentenceEntityMentionsToCoreLabels(sentence, true, annotationsToSkip, null, useSubTypes, useBIO);\r\n        assert (labeledSentence != null);\r\n        retVal.add(labeledSentence);\r\n    }\r\n    return retVal;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.SVMLightClassifierFactory.readModel",
	"Comment": "reads in a model file in svm light format.it needs to know if its multiclass or notbecause it affects the number of header lines.maybe there is another way to tell and wecan remove this flag?",
	"Method": "Pair<Double, ClassicCounter<Integer>> readModel(File modelFile,boolean multiclass){\r\n    int modelLineCount = 0;\r\n    try {\r\n        int numLinesToSkip = multiclass ? 13 : 10;\r\n        String stopToken = \"#\";\r\n        BufferedReader in = new BufferedReader(new FileReader(modelFile));\r\n        for (int i = 0; i < numLinesToSkip; i++) {\r\n            in.readLine();\r\n            modelLineCount++;\r\n        }\r\n        List<Pair<Double, ClassicCounter<Integer>>> supportVectors = new ArrayList();\r\n        String thresholdLine = in.readLine();\r\n        modelLineCount++;\r\n        String[] pieces = thresholdLine.split(\"\\\\s+\");\r\n        double threshold = Double.parseDouble(pieces[0]);\r\n        while (in.ready()) {\r\n            String svLine = in.readLine();\r\n            modelLineCount++;\r\n            pieces = svLine.split(\"\\\\s+\");\r\n            double alpha = Double.parseDouble(pieces[0]);\r\n            ClassicCounter<Integer> supportVector = new ClassicCounter();\r\n            for (int i = 1; i < pieces.length; ++i) {\r\n                String piece = pieces[i];\r\n                if (piece.equals(stopToken))\r\n                    break;\r\n                String[] indexNum = piece.split(\":\");\r\n                String featureIndex = indexNum[0];\r\n                if (!featureIndex.equals(\"qid\")) {\r\n                    double count = Double.parseDouble(indexNum[1]);\r\n                    supportVector.incrementCount(Integer.valueOf(featureIndex), count);\r\n                }\r\n            }\r\n            supportVectors.add(new Pair(alpha, supportVector));\r\n        }\r\n        in.close();\r\n        return new Pair(threshold, getWeights(supportVectors));\r\n    } catch (Exception e) {\r\n        e.printStackTrace();\r\n        throw new RuntimeException(\"Error reading SVM model (line \" + modelLineCount + \" in file \" + modelFile.getAbsolutePath() + \")\");\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.cli.HelpFormatter.appendOptionGroup",
	"Comment": "appends the usage clause for an optiongroup to a stringbuffer.the clause is wrapped in square brackets if the group is required.the display of the options is handled by appendoption",
	"Method": "void appendOptionGroup(StringBuffer buff,OptionGroup group){\r\n    if (!group.isRequired()) {\r\n        buff.append(\"[\");\r\n    }\r\n    List<Option> optList = new ArrayList<Option>(group.getOptions());\r\n    if (getOptionComparator() != null) {\r\n        Collections.sort(optList, getOptionComparator());\r\n    }\r\n    for (Iterator<Option> it = optList.iterator(); it.hasNext(); ) {\r\n        appendOption(buff, it.next(), true);\r\n        if (it.hasNext()) {\r\n            buff.append(\" | \");\r\n        }\r\n    }\r\n    if (!group.isRequired()) {\r\n        buff.append(\"]\");\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.makeDatum",
	"Comment": "makes a crfdatum by producing features and a label from input data at aspecific position, using the provided factory.",
	"Method": "CRFDatum<List<String>, CRFLabel> makeDatum(List<IN> info,int loc,List<FeatureFactory<IN>> featureFactories){\r\n    PaddedList<IN> pInfo = new PaddedList(info, pad);\r\n    ArrayList<List<String>> features = new ArrayList();\r\n    List<double[]> featureVals = new ArrayList();\r\n    Collection<Clique> done = Generics.newHashSet();\r\n    for (int i = 0; i < windowSize; i++) {\r\n        List<String> featuresC = new ArrayList();\r\n        List<Clique> windowCliques = FeatureFactory.getCliques(i, 0);\r\n        windowCliques.removeAll(done);\r\n        done.addAll(windowCliques);\r\n        double[] featureValArr = null;\r\n        if (flags.useEmbedding && i == 0) {\r\n            featureValArr = makeDatumUsingEmbedding(info, loc, featureFactories, pInfo, featuresC, windowCliques);\r\n        } else {\r\n            for (Clique c : windowCliques) {\r\n                for (FeatureFactory<IN> featureFactory : featureFactories) {\r\n                    featuresC.addAll(featureFactory.getCliqueFeatures(pInfo, loc, c));\r\n                }\r\n            }\r\n        }\r\n        features.add(featuresC);\r\n        featureVals.add(featureValArr);\r\n    }\r\n    int[] labels = new int[windowSize];\r\n    for (int i = 0; i < windowSize; i++) {\r\n        String answer = pInfo.get(loc + i - windowSize + 1).get(CoreAnnotations.AnswerAnnotation.class);\r\n        labels[i] = classIndex.indexOf(answer);\r\n    }\r\n    printFeatureLists(pInfo.get(loc), features);\r\n    CRFDatum<List<String>, CRFLabel> d = new CRFDatum(features, new CRFLabel(labels), featureVals);\r\n    return d;\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.util.BuckCellFinder.findBuckCell",
	"Comment": "returns the buck cell for the given target, starting from the given sourcefile.",
	"Method": "Optional<BuckCell> findBuckCell(VirtualFile file,Optional<BuckCell> findBuckCell,Path path,Optional<BuckCell> findBuckCell,File file,Optional<BuckCell> findBuckCell,VirtualFile sourceFile,String cellName){\r\n    if (\"\".equals(cellName)) {\r\n        return findBuckCell(sourceFile);\r\n    } else {\r\n        return findBuckCellByName(cellName);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.adaptive.ArcPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new ArcPolicy(config));\r\n}"
}, {
	"Path": "com.android.dx.rop.annotation.Annotations.addAll",
	"Comment": "adds all of the elements of the given instance to this one. theinstances must not have any duplicate types.",
	"Method": "void addAll(Annotations toAdd){\r\n    throwIfImmutable();\r\n    if (toAdd == null) {\r\n        throw new NullPointerException(\"toAdd == null\");\r\n    }\r\n    for (Annotation a : toAdd.annotations.values()) {\r\n        add(a);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.DeadCodeRemover.isCircularNoSideEffect",
	"Comment": "returns true if the only uses of this register form a circle ofoperations with no side effects.",
	"Method": "boolean isCircularNoSideEffect(int regV,BitSet set){\r\n    if ((set != null) && set.get(regV)) {\r\n        return true;\r\n    }\r\n    for (SsaInsn use : useList[regV]) {\r\n        if (hasSideEffect(use)) {\r\n            return false;\r\n        }\r\n    }\r\n    if (set == null) {\r\n        set = new BitSet(regCount);\r\n    }\r\n    set.set(regV);\r\n    for (SsaInsn use : useList[regV]) {\r\n        RegisterSpec result = use.getResult();\r\n        if (result == null || !isCircularNoSideEffect(result.getReg(), set)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.LdapAuthenticationHandler.createPrincipal",
	"Comment": "creates a cas principal with attributes if the ldap entry contains principal attributes.",
	"Method": "Principal createPrincipal(String username,LdapEntry ldapEntry){\r\n    LOGGER.debug(\"Creating LDAP principal for [{}] based on [{}] and attributes [{}]\", username, ldapEntry.getDn(), ldapEntry.getAttributeNames());\r\n    val id = getLdapPrincipalIdentifier(username, ldapEntry);\r\n    LOGGER.debug(\"LDAP principal identifier created is [{}]\", id);\r\n    val attributeMap = collectAttributesForLdapEntry(ldapEntry, id);\r\n    LOGGER.debug(\"Created LDAP principal for id [{}] and [{}] attributes\", id, attributeMap.size());\r\n    return this.principalFactory.createPrincipal(id, attributeMap);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceCharSeq.match",
	"Comment": "matches this char seq against the full token stream as a result of thismethod mtokenoffset is initialized",
	"Method": "void match(Vector<AceToken> tokens){\r\n    int start = -1;\r\n    int end = -1;\r\n    for (int i = 0; i < tokens.size(); i++) {\r\n        if (tokens.get(i).getByteOffset().start() == mByteOffset.start()) {\r\n            start = i;\r\n        } else if (mByteOffset.start() > tokens.get(i).getByteOffset().start() && mByteOffset.start() < tokens.get(i).getByteOffset().end()) {\r\n            start = i;\r\n        }\r\n        if (tokens.get(i).getByteOffset().end() == mByteOffset.end() + 1) {\r\n            end = i;\r\n            break;\r\n        } else if (mByteOffset.end() >= tokens.get(i).getByteOffset().start() && mByteOffset.end() < tokens.get(i).getByteOffset().end() - 1) {\r\n            end = i;\r\n            break;\r\n        }\r\n    }\r\n    if (start >= 0 && end >= 0) {\r\n        mTokenOffset = new Span(start, end);\r\n    } else {\r\n        throw new MatchException(\"Match failed!\");\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.util.AopUtils.unWrapJoinPoint",
	"Comment": "unwraps a join point that may be nested due to layered proxies.",
	"Method": "JoinPoint unWrapJoinPoint(JoinPoint point){\r\n    var naked = point;\r\n    while (naked.getArgs() != null && naked.getArgs().length > 0 && naked.getArgs()[0] instanceof JoinPoint) {\r\n        naked = (JoinPoint) naked.getArgs()[0];\r\n    }\r\n    return naked;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFDatum.asFeatures",
	"Comment": "returns the collection that this basicdatum was constructed with.",
	"Method": "List<FEAT> asFeatures(){\r\n    return features;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.admission.countmin4.CountMin4.spread",
	"Comment": "applies a supplemental hash function to a given hashcode, which defends against poor qualityhash functions.",
	"Method": "int spread(int x){\r\n    x = ((x >>> 16) ^ x) * 0x45d9f3b;\r\n    x = ((x >>> 16) ^ x) * randomSeed;\r\n    return (x >>> 16) ^ x;\r\n}"
}, {
	"Path": "com.android.dx.ssa.NormalSsaInsn.setNewSources",
	"Comment": "changes the source list of the insn. new source list should be thesame size and consist of sources of identical types.",
	"Method": "void setNewSources(RegisterSpecList newSources){\r\n    RegisterSpecList origSources = insn.getSources();\r\n    if (origSources.size() != newSources.size()) {\r\n        throw new RuntimeException(\"Sources counts don't match\");\r\n    }\r\n    insn = insn.withNewRegisters(getResult(), newSources);\r\n}"
}, {
	"Path": "org.apache.commons.cli.Option.getValues",
	"Comment": "return the values of this option as a string array or null if there are no values",
	"Method": "String[] getValues(){\r\n    return hasNoValues() ? null : values.toArray(new String[values.size()]);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.expireEntries",
	"Comment": "expires entries that have expired by access, write, or variable.",
	"Method": "void expireEntries(){\r\n    long now = expirationTicker().read();\r\n    expireAfterAccessEntries(now);\r\n    expireAfterWriteEntries(now);\r\n    expireVariableEntries(now);\r\n}"
}, {
	"Path": "org.objectweb.asm.util.CheckMethodAdapter.checkOpcode",
	"Comment": "checks that the type of the given opcode is equal to the given type.",
	"Method": "void checkOpcode(int opcode,int type){\r\n    if (opcode < 0 || opcode > 199 || TYPE[opcode] != type) {\r\n        throw new IllegalArgumentException(\"Invalid opcode: \" + opcode);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.weightedSize",
	"Comment": "returns the uncorrected combined weight of the values in the cache.",
	"Method": "long weightedSize(OptionalLong weightedSize){\r\n    throw new UnsupportedOperationException();\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.DaitchMokotoffSoundex.cleanup",
	"Comment": "performs a cleanup of the input string before the actual soundex transformation.removes all whitespace characters and performs ascii folding if enabled.",
	"Method": "String cleanup(String input){\r\n    final StringBuilder sb = new StringBuilder();\r\n    for (char ch : input.toCharArray()) {\r\n        if (Character.isWhitespace(ch)) {\r\n            continue;\r\n        }\r\n        ch = Character.toLowerCase(ch);\r\n        if (folding && FOLDINGS.containsKey(ch)) {\r\n            ch = FOLDINGS.get(ch);\r\n        }\r\n        sb.append(ch);\r\n    }\r\n    return sb.toString();\r\n}"
}, {
	"Path": "org.objectweb.asm.Handle.getOwner",
	"Comment": "returns the internal name of the class that owns the field or methoddesignated by this handle.",
	"Method": "String getOwner(){\r\n    return owner;\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.Rules.entityTokenDistance",
	"Comment": "return true if the two mentions are less than n mentions apart in the same sent",
	"Method": "boolean entityTokenDistance(Mention m1,Mention m2){\r\n    if ((m2.sentNum == m1.sentNum) && (m1.startIndex - m2.startIndex < 6))\r\n        return true;\r\n    return false;\r\n}"
}, {
	"Path": "org.apache.commons.cli.Option.getId",
	"Comment": "returns the id of this option.this is only set when theoption shortopt is a single character.this is used for switchstatements.",
	"Method": "int getId(){\r\n    return getKey().charAt(0);\r\n}"
}, {
	"Path": "org.apereo.cas.web.AbstractServiceValidateController.getServiceCredentialsFromRequest",
	"Comment": "overrideable method to determine which credentials to use to grant aproxy granting ticket. default is to use the pgturl.",
	"Method": "Credential getServiceCredentialsFromRequest(WebApplicationService service,HttpServletRequest request){\r\n    val pgtUrl = request.getParameter(CasProtocolConstants.PARAMETER_PROXY_CALLBACK_URL);\r\n    if (StringUtils.isNotBlank(pgtUrl)) {\r\n        try {\r\n            val registeredService = this.servicesManager.findServiceBy(service);\r\n            verifyRegisteredServiceProperties(registeredService, service);\r\n            return new HttpBasedServiceCredential(new URL(pgtUrl), registeredService);\r\n        } catch (final Exception e) {\r\n            LOGGER.error(\"Error constructing [{}]\", CasProtocolConstants.PARAMETER_PROXY_CALLBACK_URL, e);\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionNoisyLabel.calculate",
	"Comment": "calculates both value and partial derivatives at the point x, and save them internally.",
	"Method": "void calculate(double[] x){\r\n    clear2D(Ehat);\r\n    super.calculate(x);\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassReader.readParameterAnnotations",
	"Comment": "reads parameter annotations and makes the given visitor visit them.",
	"Method": "void readParameterAnnotations(MethodVisitor mv,Context context,int v,boolean visible){\r\n    int i;\r\n    int n = b[v++] & 0xFF;\r\n    int synthetics = Type.getArgumentTypes(context.desc).length - n;\r\n    AnnotationVisitor av;\r\n    for (i = 0; i < synthetics; ++i) {\r\n        av = mv.visitParameterAnnotation(i, \"Ljava/lang/Synthetic;\", false);\r\n        if (av != null) {\r\n            av.visitEnd();\r\n        }\r\n    }\r\n    char[] c = context.buffer;\r\n    for (; i < n + synthetics; ++i) {\r\n        int j = readUnsignedShort(v);\r\n        v += 2;\r\n        for (; j > 0; --j) {\r\n            av = mv.visitParameterAnnotation(i, readUTF8(v, c), visible);\r\n            v = readAnnotationValues(v + 2, c, true, av);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMap8Test.testAddAll2",
	"Comment": "keyset.addall adds each element from the given collection that did notalready exist in the set",
	"Method": "void testAddAll2(){\r\n    Set full = populatedSet(3);\r\n    assertTrue(full.addAll(Arrays.asList(three, four, one)));\r\n    assertEquals(5, full.size());\r\n    assertFalse(full.addAll(Arrays.asList(three, four, one)));\r\n    assertEquals(5, full.size());\r\n}"
}, {
	"Path": "com.android.dx.rop.type.Type.asUninitialized",
	"Comment": "returns a new interned instance which is identical to this one, exceptit is indicated as uninitialized and allocated at the given bytecodeindex. this instance must be an initialized object type.",
	"Method": "Type asUninitialized(int newAt){\r\n    if (newAt < 0) {\r\n        throw new IllegalArgumentException(\"newAt < 0\");\r\n    }\r\n    if (!isReference()) {\r\n        throw new IllegalArgumentException(\"not a reference type: \" + descriptor);\r\n    }\r\n    if (isUninitialized()) {\r\n        throw new IllegalArgumentException(\"already uninitialized: \" + descriptor);\r\n    }\r\n    String newDesc = 'N' + Hex.u2(newAt) + descriptor;\r\n    Type result = new Type(newDesc, BT_OBJECT, newAt);\r\n    result.initializedType = this;\r\n    return putIntern(result);\r\n}"
}, {
	"Path": "org.apereo.cas.consent.LdapConsentRepository.readConsentEntries",
	"Comment": "fetches all user entries that contain consent attributes along with these.",
	"Method": "Collection<LdapEntry> readConsentEntries(){\r\n    try {\r\n        val att = this.ldap.getConsentAttributeName();\r\n        val filter = LdapUtils.newLdaptiveSearchFilter('(' + att + \"=*)\");\r\n        LOGGER.debug(\"Locating consent LDAP entries via filter [{}] based on attribute [{}]\", filter, att);\r\n        val response = LdapUtils.executeSearchOperation(this.connectionFactory, this.ldap.getBaseDn(), filter, att);\r\n        if (LdapUtils.containsResultEntry(response)) {\r\n            val results = response.getResult().getEntries();\r\n            LOGGER.debug(\"Locating [{}] consent LDAP entries\", results.size());\r\n            return results;\r\n        }\r\n    } catch (final LdapException e) {\r\n        LOGGER.debug(e.getMessage(), e);\r\n    }\r\n    return new HashSet(0);\r\n}"
}, {
	"Path": "me.konloch.kontainer.io.HTTPRequest.getLastConnectionHeaders",
	"Comment": "used to get the headers the webserver sent on our last connection",
	"Method": "Set<Entry<String, List<String>>> getLastConnectionHeaders(){\r\n    return lastConnectionHeaders;\r\n}"
}, {
	"Path": "com.android.dx.ssa.LiteralOpUpgrader.replacePlainInsn",
	"Comment": "replaces an ssainsn containing a plaininsn with a new plaininsn. thenew plaininsn is constructed with a new regop and new sources.todo move this somewhere else.",
	"Method": "void replacePlainInsn(NormalSsaInsn insn,RegisterSpecList newSources,int newOpcode,Constant cst){\r\n    Insn originalRopInsn = insn.getOriginalRopInsn();\r\n    Rop newRop = Rops.ropFor(newOpcode, insn.getResult(), newSources, cst);\r\n    Insn newRopInsn;\r\n    if (cst == null) {\r\n        newRopInsn = new PlainInsn(newRop, originalRopInsn.getPosition(), insn.getResult(), newSources);\r\n    } else {\r\n        newRopInsn = new PlainCstInsn(newRop, originalRopInsn.getPosition(), insn.getResult(), newSources, cst);\r\n    }\r\n    NormalSsaInsn newInsn = new NormalSsaInsn(newRopInsn, insn.getBlock());\r\n    List<SsaInsn> insns = insn.getBlock().getInsns();\r\n    ssaMeth.onInsnRemoved(insn);\r\n    insns.set(insns.lastIndexOf(insn), newInsn);\r\n    ssaMeth.onInsnAdded(newInsn);\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.newFloat",
	"Comment": "adds a float to the constant pool of the class being build. does nothingif the constant pool already contains a similar item.",
	"Method": "Item newFloat(float value){\r\n    key.set(value);\r\n    Item result = get(key);\r\n    if (result == null) {\r\n        pool.putByte(FLOAT).putInt(key.intVal);\r\n        result = new Item(index++, key);\r\n        put(result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.configurer.AbstractMultifactorTrustedDeviceWebflowConfigurer.registerMultifactorTrustedAuthentication",
	"Comment": "register multifactor trusted authentication into webflow.",
	"Method": "void registerMultifactorTrustedAuthentication(FlowDefinitionRegistry flowDefinitionRegistry){\r\n    validateFlowDefinitionConfiguration(flowDefinitionRegistry);\r\n    LOGGER.debug(\"Flow definitions found in the registry are [{}]\", (Object[]) flowDefinitionRegistry.getFlowDefinitionIds());\r\n    val flowId = Arrays.stream(flowDefinitionRegistry.getFlowDefinitionIds()).findFirst().get();\r\n    LOGGER.debug(\"Processing flow definition [{}]\", flowId);\r\n    val flow = (Flow) flowDefinitionRegistry.getFlowDefinition(flowId);\r\n    val state = getState(flow, CasWebflowConstants.STATE_ID_INIT_LOGIN_FORM, ActionState.class);\r\n    val transition = (Transition) state.getTransition(CasWebflowConstants.TRANSITION_ID_SUCCESS);\r\n    val targetStateId = transition.getTargetStateId();\r\n    transition.setTargetStateResolver(new DefaultTargetStateResolver(CasWebflowConstants.STATE_ID_VERIFY_TRUSTED_DEVICE));\r\n    val verifyAction = createActionState(flow, CasWebflowConstants.STATE_ID_VERIFY_TRUSTED_DEVICE, createEvaluateAction(MFA_VERIFY_TRUST_ACTION_BEAN_ID));\r\n    if (enableDeviceRegistration) {\r\n        createTransitionForState(verifyAction, CasWebflowConstants.TRANSITION_ID_YES, CasWebflowConstants.STATE_ID_FINISH_MFA_TRUSTED_AUTH);\r\n    } else {\r\n        createTransitionForState(verifyAction, CasWebflowConstants.TRANSITION_ID_YES, CasWebflowConstants.STATE_ID_REAL_SUBMIT);\r\n    }\r\n    createTransitionForState(verifyAction, CasWebflowConstants.TRANSITION_ID_NO, targetStateId);\r\n    createDecisionState(flow, CasWebflowConstants.DECISION_STATE_REQUIRE_REGISTRATION, isDeviceRegistrationRequired(), CasWebflowConstants.VIEW_ID_REGISTER_DEVICE, CasWebflowConstants.STATE_ID_REAL_SUBMIT);\r\n    val submit = getState(flow, CasWebflowConstants.STATE_ID_REAL_SUBMIT, ActionState.class);\r\n    val success = (Transition) submit.getTransition(CasWebflowConstants.TRANSITION_ID_SUCCESS);\r\n    if (enableDeviceRegistration) {\r\n        success.setTargetStateResolver(new DefaultTargetStateResolver(CasWebflowConstants.VIEW_ID_REGISTER_DEVICE));\r\n    } else {\r\n        success.setTargetStateResolver(new DefaultTargetStateResolver(CasWebflowConstants.STATE_ID_REGISTER_TRUSTED_DEVICE));\r\n    }\r\n    val viewRegister = createViewState(flow, CasWebflowConstants.VIEW_ID_REGISTER_DEVICE, \"casMfaRegisterDeviceView\");\r\n    val viewRegisterTransition = createTransition(CasWebflowConstants.TRANSITION_ID_SUBMIT, CasWebflowConstants.STATE_ID_REGISTER_TRUSTED_DEVICE);\r\n    viewRegister.getTransitionSet().add(viewRegisterTransition);\r\n    val registerAction = createActionState(flow, CasWebflowConstants.STATE_ID_REGISTER_TRUSTED_DEVICE, createEvaluateAction(MFA_SET_TRUST_ACTION_BEAN_ID));\r\n    createStateDefaultTransition(registerAction, CasWebflowConstants.STATE_ID_SUCCESS);\r\n    if (submit.getActionList().size() == 0) {\r\n        throw new IllegalArgumentException(\"There are no actions defined for the final submission event of \" + flowId);\r\n    }\r\n    val act = submit.getActionList().iterator().next();\r\n    val finishMfaTrustedAuth = createActionState(flow, CasWebflowConstants.STATE_ID_FINISH_MFA_TRUSTED_AUTH, act);\r\n    val finishedTransition = createTransition(CasWebflowConstants.TRANSITION_ID_SUCCESS, CasWebflowConstants.STATE_ID_SUCCESS);\r\n    finishMfaTrustedAuth.getTransitionSet().add(finishedTransition);\r\n    createStateDefaultTransition(finishMfaTrustedAuth, CasWebflowConstants.STATE_ID_SUCCESS);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.MachineReading.makeResultsPrinters",
	"Comment": "creates resultsprinter instances based on the resultsprinters argument",
	"Method": "void makeResultsPrinters(String[] args,Set<ResultsPrinter> makeResultsPrinters,String classes,String[] args){\r\n    MachineReadingProperties.logger.info(\"Making result printers from \" + classes);\r\n    String[] printerClassNames = classes.trim().split(\",\\\\s*\");\r\n    HashSet<ResultsPrinter> printers = new HashSet();\r\n    for (String printerClassName : printerClassNames) {\r\n        if (printerClassName.isEmpty())\r\n            continue;\r\n        ResultsPrinter rp;\r\n        try {\r\n            rp = (ResultsPrinter) Class.forName(printerClassName).getConstructor().newInstance();\r\n            printers.add(rp);\r\n        } catch (Exception e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n    }\r\n    return printers;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.membership.bloom.BloomFilter.spread",
	"Comment": "applies a supplemental hash function to a given hashcode, which defends against poor qualityhash functions.",
	"Method": "int spread(int x){\r\n    x = ((x >>> 16) ^ x) * 0x45d9f3b;\r\n    x = ((x >>> 16) ^ x) * randomSeed;\r\n    return (x >>> 16) ^ x;\r\n}"
}, {
	"Path": "org.apereo.cas.adaptors.x509.authentication.revocation.policy.DenyRevocationPolicy.apply",
	"Comment": "policy application throws generalsecurityexception to stop execution ofwhatever process invoked application of this policy.",
	"Method": "void apply(Void nothing){\r\n    throw new GeneralSecurityException(\"Aborting since DenyRevocationPolicy is in effect.\");\r\n}"
}, {
	"Path": "com.facebook.buck.tools.consistency.RuleKeyLogFileReader.readFile",
	"Comment": "reads a file in and runs a predicate on each deserialized rule key",
	"Method": "void readFile(Path filename,Predicate<FullRuleKey> visitor){\r\n    ByteBuffer lengthBuf = ByteBuffer.allocate(4);\r\n    try (FileInputStream fileInputStream = new FileInputStream(filename.toFile())) {\r\n        while (fileInputStream.available() >= 4) {\r\n            fileInputStream.read(lengthBuf.array());\r\n            int length = lengthBuf.getInt();\r\n            lengthBuf.rewind();\r\n            byte[] serialized = new byte[length];\r\n            int bytesRead = fileInputStream.read(serialized);\r\n            if (bytesRead != length) {\r\n                throw new ParseException(filename, \"Invalid length specified. Expected %s bytes, only got %s\", length, bytesRead);\r\n            }\r\n            TDeserializer deserializer = new TDeserializer(new TCompactProtocol.Factory());\r\n            FullRuleKey ruleKey = new FullRuleKey();\r\n            deserializer.deserialize(ruleKey, serialized);\r\n            if (ruleKey.key == null) {\r\n                throw new ParseException(filename, \"Could not deserialize array of size %s\", serialized.length);\r\n            }\r\n            if (visitor.test(ruleKey)) {\r\n                return;\r\n            }\r\n        }\r\n    } catch (TException | IOException e) {\r\n        throw new ParseException(e, filename, \"Error reading file: %s\", e.getMessage());\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.MultifactorAuthenticationProviderBypass.updateAuthenticationToForgetBypass",
	"Comment": "method will remove any previous bypass set in the authentication.",
	"Method": "void updateAuthenticationToForgetBypass(Authentication authentication){\r\n    authentication.addAttribute(AUTHENTICATION_ATTRIBUTE_BYPASS_MFA, Boolean.FALSE);\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.math",
	"Comment": "generates the instruction to do the specified mathematical or logicaloperation.",
	"Method": "void math(int op,Type type){\r\n    mv.visitInsn(type.getOpcode(op));\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFCliqueTree.scoresOf",
	"Comment": "computes the unnormalized log conditional distribution over values of theelement at position pos in the sequence, conditioned on the values of theelements in all other positions of the provided sequence.",
	"Method": "double[] scoresOf(int[] sequence,int position){\r\n    if (position >= factorTables.length)\r\n        throw new RuntimeException(\"Index out of bounds: \" + position);\r\n    double[] probThisGivenPrev = new double[numClasses];\r\n    double[] probNextGivenThis = new double[numClasses];\r\n    int prevLength = windowSize - 1;\r\n    int[] prev = new int[prevLength + 1];\r\n    int i = 0;\r\n    for (; i < prevLength - position; i++) {\r\n        prev[i] = classIndex.indexOf(backgroundSymbol);\r\n    }\r\n    for (; i < prevLength; i++) {\r\n        prev[i] = sequence[position - prevLength + i];\r\n    }\r\n    for (int label = 0; label < numClasses; label++) {\r\n        prev[prev.length - 1] = label;\r\n        probThisGivenPrev[label] = factorTables[position].unnormalizedLogProb(prev);\r\n    }\r\n    int nextLength = windowSize - 1;\r\n    if (position + nextLength >= length()) {\r\n        nextLength = length() - position - 1;\r\n    }\r\n    FactorTable nextFactorTable = factorTables[position + nextLength];\r\n    if (nextLength != windowSize - 1) {\r\n        for (int j = 0; j < windowSize - 1 - nextLength; j++) {\r\n            nextFactorTable = nextFactorTable.sumOutFront();\r\n        }\r\n    }\r\n    if (nextLength == 0) {\r\n        Arrays.fill(probNextGivenThis, 1.0);\r\n    } else {\r\n        int[] next = new int[nextLength];\r\n        System.arraycopy(sequence, position + 1, next, 0, nextLength);\r\n        for (int label = 0; label < numClasses; label++) {\r\n            probNextGivenThis[label] = nextFactorTable.unnormalizedConditionalLogProbGivenFirst(label, next);\r\n        }\r\n    }\r\n    return ArrayMath.pairwiseAdd(probThisGivenPrev, probNextGivenThis);\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.MentionExtractor.nextDoc",
	"Comment": "extracts the info relevant for coref from the next document in the corpus",
	"Method": "Document nextDoc(){\r\n    return null;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.expireAfterUpdate",
	"Comment": "returns the expiration time for the entry after being updated.",
	"Method": "long expireAfterUpdate(Node<K, V> node,K key,V value,Expiry<K, V> expiry,long now){\r\n    if (expiresVariable() && (key != null) && (value != null)) {\r\n        long currentDuration = Math.max(1, node.getVariableTime() - now);\r\n        long duration = expiry.expireAfterUpdate(key, value, now, currentDuration);\r\n        return isAsync ? (now + duration) : (now + Math.min(duration, MAXIMUM_EXPIRY));\r\n    }\r\n    return 0L;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFCliqueTree.getConditionalDistribution",
	"Comment": "computes the distribution over values of the element at position pos in thesequence, conditioned on the values of the elements in all other positionsof the provided sequence.",
	"Method": "double[] getConditionalDistribution(int[] sequence,int position){\r\n    double[] result = scoresOf(sequence, position);\r\n    ArrayMath.logNormalize(result);\r\n    result = ArrayMath.exp(result);\r\n    return result;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.AbstractSequenceClassifier.printResults",
	"Comment": "given counters of true positives, false positives, and falsenegatives, prints out precision, recall, and f1 for each key.",
	"Method": "Triple<Double, Double, Double> printResults(Counter<String> entityTP,Counter<String> entityFP,Counter<String> entityFN){\r\n    Set<String> entities = new TreeSet();\r\n    entities.addAll(entityTP.keySet());\r\n    entities.addAll(entityFP.keySet());\r\n    entities.addAll(entityFN.keySet());\r\n    log.info(\"         Entity\\tP\\tR\\tF1\\tTP\\tFP\\tFN\");\r\n    for (String entity : entities) {\r\n        double tp = entityTP.getCount(entity);\r\n        double fp = entityFP.getCount(entity);\r\n        double fn = entityFN.getCount(entity);\r\n        printPRLine(entity, tp, fp, fn);\r\n    }\r\n    double tp = entityTP.totalCount();\r\n    double fp = entityFP.totalCount();\r\n    double fn = entityFN.totalCount();\r\n    return printPRLine(\"Totals\", tp, fp, fn);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.event.EventDispatcher.deregister",
	"Comment": "deregisters a cache entry listener based on the supplied configuration.",
	"Method": "void deregister(CacheEntryListenerConfiguration<K, V> configuration){\r\n    requireNonNull(configuration);\r\n    dispatchQueues.keySet().removeIf(registration -> configuration.equals(registration.getConfiguration()));\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaMethod.indexListFromLabelList",
	"Comment": "builds an intlist of block indices from a basic block list and a listof labels taken from rop form.",
	"Method": "IntList indexListFromLabelList(BasicBlockList ropBlocks,IntList labelList){\r\n    IntList result = new IntList(labelList.size());\r\n    for (int i = 0, sz = labelList.size(); i < sz; i++) {\r\n        result.add(ropBlocks.indexOfLabel(labelList.get(i)));\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.CacheProxy.loadAllAndReplaceExisting",
	"Comment": "performs the bulk load where the existing entries are replace.",
	"Method": "void loadAllAndReplaceExisting(Set<? extends K> keys){\r\n    int[] ignored = { 0 };\r\n    Map<K, V> loaded = cacheLoader.get().loadAll(keys);\r\n    for (Map.Entry<? extends K, ? extends V> entry : loaded.entrySet()) {\r\n        putNoCopyOrAwait(entry.getKey(), entry.getValue(), false, ignored);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.rop.code.Rops.pickBinaryOp",
	"Comment": "returns the appropriate binary arithmetic rop for the given typeand arguments. the result is a shared instance.",
	"Method": "Rop pickBinaryOp(TypeList types,Rop int1,Rop long1,Rop float1,Rop double1,Rop int2,Rop long2,Rop float2,Rop double2){\r\n    int bt1 = types.getType(0).getBasicFrameType();\r\n    Rop result = null;\r\n    switch(types.size()) {\r\n        case 1:\r\n            {\r\n                switch(bt1) {\r\n                    case Type.BT_INT:\r\n                        return int1;\r\n                    case Type.BT_LONG:\r\n                        return long1;\r\n                    case Type.BT_FLOAT:\r\n                        result = float1;\r\n                        break;\r\n                    case Type.BT_DOUBLE:\r\n                        result = double1;\r\n                        break;\r\n                }\r\n                break;\r\n            }\r\n        case 2:\r\n            {\r\n                switch(bt1) {\r\n                    case Type.BT_INT:\r\n                        return int2;\r\n                    case Type.BT_LONG:\r\n                        return long2;\r\n                    case Type.BT_FLOAT:\r\n                        result = float2;\r\n                        break;\r\n                    case Type.BT_DOUBLE:\r\n                        result = double2;\r\n                        break;\r\n                }\r\n                break;\r\n            }\r\n    }\r\n    if (result == null) {\r\n        return throwBadTypes(types);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.DefaultMultifactorAuthenticationProviderBypass.locateMatchingAttributeBasedOnPrincipalAttributes",
	"Comment": "skip bypass and support event based on principal attributes.",
	"Method": "boolean locateMatchingAttributeBasedOnPrincipalAttributes(MultifactorAuthenticationProviderBypassProperties bypass,Principal principal){\r\n    return locateMatchingAttributeValue(bypass.getPrincipalAttributeName(), bypass.getPrincipalAttributeValue(), principal.getAttributes());\r\n}"
}, {
	"Path": "org.apache.commons.codec.net.URLCodec.decode",
	"Comment": "decodes a url safe object into its original form. escaped characters are converted back to their originalrepresentation.",
	"Method": "byte[] decode(byte[] bytes,String decode,String str,String charset,String decode,String str,Object decode,Object obj){\r\n    if (obj == null) {\r\n        return null;\r\n    } else if (obj instanceof byte[]) {\r\n        return decode((byte[]) obj);\r\n    } else if (obj instanceof String) {\r\n        return decode((String) obj);\r\n    } else {\r\n        throw new DecoderException(\"Objects of type \" + obj.getClass().getName() + \" cannot be URL decoded\");\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.TokensRegexNERAnnotatorITest.checkNerTags",
	"Comment": "helper method, checks that each token is tagged with the expected ner type.",
	"Method": "void checkNerTags(List<CoreLabel> tokens,String tags){\r\n    Assert.assertEquals(tags.length, tokens.size());\r\n    for (int i = 0; i < tags.length; ++i) {\r\n        Assert.assertEquals(\"Mismatch for token tag NER \" + i + ' ' + tokens.get(i), tags[i], tokens.get(i).get(CoreAnnotations.NamedEntityTagAnnotation.class));\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.util.RegexUtils.createPattern",
	"Comment": "creates the pattern. matching is by defaultcase insensitive.",
	"Method": "Pattern createPattern(String pattern,Pattern createPattern,String pattern,int flags){\r\n    if (pattern == null) {\r\n        LOGGER.debug(\"Pattern cannot be null\");\r\n        return MATCH_NOTHING_PATTERN;\r\n    }\r\n    try {\r\n        return Pattern.compile(pattern, flags);\r\n    } catch (final PatternSyntaxException exception) {\r\n        LOGGER.debug(\"Pattern [{}] is not a valid regex.\", pattern);\r\n        return MATCH_NOTHING_PATTERN;\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.data.Mention.insideIn",
	"Comment": "returns true if this mention is contained inside m. that is, it is a subspan of the same sentence.",
	"Method": "boolean insideIn(Mention m){\r\n    return this.sentNum == m.sentNum && m.startIndex <= this.startIndex && this.endIndex <= m.endIndex;\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.hybrid.sieve.DeterministicCorefSieve.coreferent",
	"Comment": "checks if two clusters are coreferent according to our sieve pass constraints",
	"Method": "boolean coreferent(Document document,CorefCluster mentionCluster,CorefCluster potentialAntecedent,Mention mention2,Mention ant,Dictionaries dict,Set<Mention> roleSet){\r\n    boolean ret = false;\r\n    Mention mention = mentionCluster.getRepresentativeMention();\r\n    if (flags.USE_INCOMPATIBLES) {\r\n        if (document.isIncompatible(mentionCluster, potentialAntecedent)) {\r\n            return false;\r\n        }\r\n    }\r\n    if (flags.DO_PRONOUN && Math.abs(mention2.sentNum - ant.sentNum) > 3 && mention2.person != Person.I && mention2.person != Person.YOU) {\r\n        return false;\r\n    }\r\n    if (mention2.lowercaseNormalizedSpanString().equals(\"this\") && Math.abs(mention2.sentNum - ant.sentNum) > 3) {\r\n        return false;\r\n    }\r\n    if (mention2.person == Person.YOU && document.docType == DocType.ARTICLE && mention2.headWord.get(CoreAnnotations.SpeakerAnnotation.class).equals(\"PER0\")) {\r\n        return false;\r\n    }\r\n    if (document.conllDoc != null) {\r\n        if (ant.generic && ant.person == Person.YOU)\r\n            return false;\r\n        if (mention2.generic)\r\n            return false;\r\n    }\r\n    if (lang != Locale.CHINESE || document.docInfo == null || !document.docInfo.getOrDefault(\"DOC_ID\", \"\").contains(\"nw\")) {\r\n        if (mention2.insideIn(ant) || ant.insideIn(mention2))\r\n            return false;\r\n    }\r\n    if (flags.USE_SPEAKERMATCH) {\r\n        String mSpeaker = mention2.headWord.get(SpeakerAnnotation.class);\r\n        String aSpeaker = ant.headWord.get(SpeakerAnnotation.class);\r\n        if (mention2.person == Person.I && ant.person == Person.I)\r\n            return (mSpeaker.equals(aSpeaker));\r\n        if ((mention2.person == Person.I && mSpeaker.equals(Integer.toString(ant.mentionID))) || (ant.person == Person.I && aSpeaker.equals(Integer.toString(mention2.mentionID))))\r\n            return true;\r\n    }\r\n    if (flags.USE_DISCOURSEMATCH) {\r\n        String mString = mention.lowercaseNormalizedSpanString();\r\n        String antString = ant.lowercaseNormalizedSpanString();\r\n        if (mention.speakerInfo != null && mention.speakerInfo == ant.speakerInfo) {\r\n            return true;\r\n        }\r\n        if (mention.number == Number.SINGULAR && dict.firstPersonPronouns.contains(mString) && ant.number == Number.SINGULAR && dict.firstPersonPronouns.contains(antString) && CorefRules.entitySameSpeaker(document, mention, ant)) {\r\n            return true;\r\n        }\r\n        if ((mention.number == Number.SINGULAR && dict.firstPersonPronouns.contains(mString)) && CorefRules.antecedentIsMentionSpeaker(document, mention, ant, dict)) {\r\n            if (mention.speakerInfo == null && ant.speakerInfo != null) {\r\n                mention.speakerInfo = ant.speakerInfo;\r\n            }\r\n            return true;\r\n        }\r\n        if ((ant.number == Number.SINGULAR && dict.firstPersonPronouns.contains(antString)) && CorefRules.antecedentIsMentionSpeaker(document, ant, mention, dict)) {\r\n            if (ant.speakerInfo == null && mention.speakerInfo != null) {\r\n                ant.speakerInfo = mention.speakerInfo;\r\n            }\r\n            return true;\r\n        }\r\n        if (dict.secondPersonPronouns.contains(mString) && dict.secondPersonPronouns.contains(antString) && CorefRules.entitySameSpeaker(document, mention, ant)) {\r\n            return true;\r\n        }\r\n        if (((mention.person == Person.I && ant.person == Person.YOU || (mention.person == Person.YOU && ant.person == Person.I)) && (mention.headWord.get(CoreAnnotations.UtteranceAnnotation.class) - ant.headWord.get(CoreAnnotations.UtteranceAnnotation.class) == 1) && document.docType == DocType.CONVERSATION)) {\r\n            return true;\r\n        }\r\n        if (dict.reflexivePronouns.contains(mention.headString) && CorefRules.entitySubjectObject(mention, ant)) {\r\n            return true;\r\n        }\r\n    }\r\n    if (!flags.USE_EXACTSTRINGMATCH && !flags.USE_RELAXED_EXACTSTRINGMATCH && !flags.USE_APPOSITION && !flags.USE_WORDS_INCLUSION) {\r\n        for (Mention m : mentionCluster.getCorefMentions()) {\r\n            for (Mention a : potentialAntecedent.getCorefMentions()) {\r\n                if (m.person != Person.I && a.person != Person.I && (CorefRules.antecedentIsMentionSpeaker(document, m, a, dict) || CorefRules.antecedentIsMentionSpeaker(document, a, m, dict))) {\r\n                    document.addIncompatible(m, a);\r\n                    return false;\r\n                }\r\n                int dist = Math.abs(m.headWord.get(CoreAnnotations.UtteranceAnnotation.class) - a.headWord.get(CoreAnnotations.UtteranceAnnotation.class));\r\n                if (document.docType != DocType.ARTICLE && dist == 1 && !CorefRules.entitySameSpeaker(document, m, a)) {\r\n                    String mSpeaker = document.speakers.get(m.headWord.get(CoreAnnotations.UtteranceAnnotation.class));\r\n                    String aSpeaker = document.speakers.get(a.headWord.get(CoreAnnotations.UtteranceAnnotation.class));\r\n                    if (m.person == Person.I && a.person == Person.I) {\r\n                        document.addIncompatible(m, a);\r\n                        return false;\r\n                    }\r\n                    if (m.person == Person.YOU && a.person == Person.YOU) {\r\n                        document.addIncompatible(m, a);\r\n                        return false;\r\n                    }\r\n                    if (m.person == Person.WE && a.person == Person.WE) {\r\n                        document.addIncompatible(m, a);\r\n                        return false;\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        if (document.docType == DocType.ARTICLE) {\r\n            for (Mention m : mentionCluster.getCorefMentions()) {\r\n                for (Mention a : potentialAntecedent.getCorefMentions()) {\r\n                    if (CorefRules.entitySubjectObject(m, a)) {\r\n                        document.addIncompatible(m, a);\r\n                        return false;\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n    if (flags.USE_iwithini && CorefRules.entityIWithinI(mention, ant, dict)) {\r\n        document.addIncompatible(mention, ant);\r\n        return false;\r\n    }\r\n    if (flags.USE_EXACTSTRINGMATCH && CorefRules.entityExactStringMatch(mention, ant, dict, roleSet)) {\r\n        return true;\r\n    }\r\n    if (flags.USE_NAME_MATCH && checkEntityMatch(document, mentionCluster, potentialAntecedent, dict, roleSet)) {\r\n        ret = true;\r\n    }\r\n    if (flags.USE_RELAXED_EXACTSTRINGMATCH && CorefRules.entityRelaxedExactStringMatch(mentionCluster, potentialAntecedent, mention, ant, dict, roleSet)) {\r\n        return true;\r\n    }\r\n    if (flags.USE_APPOSITION && CorefRules.entityIsApposition(mentionCluster, potentialAntecedent, mention, ant)) {\r\n        return true;\r\n    }\r\n    if (flags.USE_PREDICATENOMINATIVES && CorefRules.entityIsPredicateNominatives(mentionCluster, potentialAntecedent, mention, ant)) {\r\n        return true;\r\n    }\r\n    if (flags.USE_ACRONYM && CorefRules.entityIsAcronym(document, mentionCluster, potentialAntecedent)) {\r\n        return true;\r\n    }\r\n    if (flags.USE_RELATIVEPRONOUN && CorefRules.entityIsRelativePronoun(mention, ant)) {\r\n        return true;\r\n    }\r\n    if (flags.USE_DEMONYM && mention.isDemonym(ant, dict)) {\r\n        return true;\r\n    }\r\n    if (flags.USE_ROLEAPPOSITION) {\r\n        if (lang == Locale.CHINESE)\r\n            ret = false;\r\n        else if (CorefRules.entityIsRoleAppositive(mentionCluster, potentialAntecedent, mention, ant, dict))\r\n            ret = true;\r\n    }\r\n    if (flags.USE_INCLUSION_HEADMATCH && CorefRules.entityHeadsAgree(mentionCluster, potentialAntecedent, mention, ant, dict)) {\r\n        ret = true;\r\n    }\r\n    if (flags.USE_RELAXED_HEADMATCH && CorefRules.entityRelaxedHeadsAgreeBetweenMentions(mentionCluster, potentialAntecedent, mention, ant)) {\r\n        ret = true;\r\n    }\r\n    if (flags.USE_WORDS_INCLUSION && ret && !CorefRules.entityWordsIncluded(mentionCluster, potentialAntecedent, mention, ant)) {\r\n        return false;\r\n    }\r\n    if (flags.USE_INCOMPATIBLE_MODIFIER && ret && CorefRules.entityHaveIncompatibleModifier(mentionCluster, potentialAntecedent)) {\r\n        return false;\r\n    }\r\n    if (flags.USE_PROPERHEAD_AT_LAST && ret && !CorefRules.entitySameProperHeadLastWord(mentionCluster, potentialAntecedent, mention, ant)) {\r\n        return false;\r\n    }\r\n    if (flags.USE_ATTRIBUTES_AGREE && !CorefRules.entityAttributesAgree(mentionCluster, potentialAntecedent)) {\r\n        return false;\r\n    }\r\n    if (flags.USE_DIFFERENT_LOCATION && CorefRules.entityHaveDifferentLocation(mention, ant, dict)) {\r\n        if (flags.USE_PROPERHEAD_AT_LAST && ret && mention.goldCorefClusterID != ant.goldCorefClusterID) {\r\n        }\r\n        return false;\r\n    }\r\n    if (flags.USE_NUMBER_IN_MENTION && CorefRules.entityNumberInLaterMention(mention, ant)) {\r\n        if (flags.USE_PROPERHEAD_AT_LAST && ret && mention.goldCorefClusterID != ant.goldCorefClusterID) {\r\n        }\r\n        return false;\r\n    }\r\n    if (flags.USE_DISTANCE && CorefRules.entityTokenDistance(mention2, ant)) {\r\n        return false;\r\n    }\r\n    if (flags.USE_COREF_DICT) {\r\n        if (ant.headWord.lemma().equals(mention2.headWord.lemma()))\r\n            return false;\r\n        if (ant.mentionType != MentionType.PROPER && (mention2.headWord.get(CoreAnnotations.PartOfSpeechAnnotation.class).startsWith(\"NNP\") || !mention2.headWord.word().substring(1).equals(mention2.headWord.word().substring(1).toLowerCase()))) {\r\n            return false;\r\n        }\r\n        if (ant.headWord.get(CoreAnnotations.PartOfSpeechAnnotation.class).equals(\"NNS\") && mention2.headWord.get(CoreAnnotations.PartOfSpeechAnnotation.class).equals(\"NNS\"))\r\n            return false;\r\n        if (dict.indefinitePronouns.contains(ant.originalSpan.get(0).lemma()) || dict.indefinitePronouns.contains(mention2.originalSpan.get(0).lemma()))\r\n            return false;\r\n        if (ant.isCoordinated() || mention2.isCoordinated())\r\n            return false;\r\n        if (CorefRules.contextIncompatible(mention2, ant, dict))\r\n            return false;\r\n        if (CorefRules.sentenceContextIncompatible(mention2, ant, dict))\r\n            return false;\r\n        if (CorefRules.entityClusterAllCorefDictionary(mentionCluster, potentialAntecedent, dict, 1, 8))\r\n            return true;\r\n        if (CorefRules.entityCorefDictionary(mention, ant, dict, 2, 2))\r\n            return true;\r\n        if (CorefRules.entityCorefDictionary(mention, ant, dict, 3, 2))\r\n            return true;\r\n        if (CorefRules.entityCorefDictionary(mention, ant, dict, 4, 2))\r\n            return true;\r\n    }\r\n    if (flags.DO_PRONOUN) {\r\n        Mention m;\r\n        if (mention.predicateNominatives != null && mention.predicateNominatives.contains(mention2)) {\r\n            m = mention2;\r\n        } else {\r\n            m = mention;\r\n        }\r\n        boolean mIsPronoun = (m.isPronominal() || dict.allPronouns.contains(m.toString()));\r\n        boolean attrAgree = HybridCorefProperties.useDefaultPronounAgreement(props) ? CorefRules.entityAttributesAgree(mentionCluster, potentialAntecedent) : CorefRules.entityAttributesAgree(mentionCluster, potentialAntecedent, lang);\r\n        if (mIsPronoun && attrAgree) {\r\n            if (dict.demonymSet.contains(ant.lowercaseNormalizedSpanString()) && dict.notOrganizationPRP.contains(m.headString)) {\r\n                document.addIncompatible(m, ant);\r\n                return false;\r\n            }\r\n            if (CorefRules.entityPersonDisagree(document, mentionCluster, potentialAntecedent, dict)) {\r\n                document.addIncompatible(m, ant);\r\n                return false;\r\n            }\r\n            return true;\r\n        }\r\n    }\r\n    if (flags.USE_CHINESE_HEAD_MATCH) {\r\n        if (mention2.headWord == ant.headWord && mention2.insideIn(ant)) {\r\n            if (!document.isCoref(mention2, ant)) {\r\n            }\r\n            return true;\r\n        }\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.ParserAnnotatorITest.testTimeout",
	"Comment": "tests that if you run a parser annotator with an absurdly lowtimeout, all sentences are successfully labeled with x trees, asopposed to null trees or not timing out",
	"Method": "void testTimeout(){\r\n    Annotation document = new Annotation(TEXT);\r\n    timeoutPipeline.annotate(document);\r\n    verifyAnswers(document, XPARSES);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.documentToDataAndLabels",
	"Comment": "convert a document list into arrays storing the data features and labels.this is used at test time.",
	"Method": "Triple<int[][][], int[], double[][][]> documentToDataAndLabels(List<IN> document){\r\n    int docSize = document.size();\r\n    int[][][] data = new int[docSize][windowSize][];\r\n    double[][][] featureVals = new double[docSize][windowSize][];\r\n    int[] labels = new int[docSize];\r\n    if (flags.useReverse) {\r\n        Collections.reverse(document);\r\n    }\r\n    for (int j = 0; j < docSize; j++) {\r\n        CRFDatum<List<String>, CRFLabel> d = makeDatum(document, j, featureFactories);\r\n        List<List<String>> features = d.asFeatures();\r\n        List<double[]> featureValList = d.asFeatureVals();\r\n        for (int k = 0, fSize = features.size(); k < fSize; k++) {\r\n            Collection<String> cliqueFeatures = features.get(k);\r\n            data[j][k] = new int[cliqueFeatures.size()];\r\n            if (featureValList != null) {\r\n                featureVals[j][k] = featureValList.get(k);\r\n            }\r\n            int m = 0;\r\n            for (String feature : cliqueFeatures) {\r\n                int index = featureIndex.indexOf(feature);\r\n                if (index >= 0) {\r\n                    data[j][k][m] = index;\r\n                    m++;\r\n                } else {\r\n                }\r\n            }\r\n            if (m < data[j][k].length) {\r\n                int[] f = new int[m];\r\n                System.arraycopy(data[j][k], 0, f, 0, m);\r\n                data[j][k] = f;\r\n                if (featureVals[j][k] != null) {\r\n                    double[] fVal = new double[m];\r\n                    System.arraycopy(featureVals[j][k], 0, fVal, 0, m);\r\n                    featureVals[j][k] = fVal;\r\n                }\r\n            }\r\n        }\r\n        IN wi = document.get(j);\r\n        labels[j] = classIndex.indexOf(wi.get(CoreAnnotations.AnswerAnnotation.class));\r\n    }\r\n    if (flags.useReverse) {\r\n        Collections.reverse(document);\r\n    }\r\n    return new Triple(data, labels, featureVals);\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.autodeps.BuckDeps.tryToAddDepsToTarget",
	"Comment": "given the contents of a buck file, try to modify the contents to add the given dependency tothe given target.",
	"Method": "String tryToAddDepsToTarget(String buckContents,String dependencyString,String targetString){\r\n    BuckTarget target = BuckTarget.parse(targetString).orElse(null);\r\n    BuckTarget dependency = BuckTarget.parse(dependencyString).orElse(null);\r\n    if (target == null || dependency == null) {\r\n        return buckContents;\r\n    }\r\n    int[] targetOffset = findRuleInBuckFileContents(buckContents, target.getRuleName());\r\n    if (targetOffset == null) {\r\n        LOG.warn(\"Couldn't find target definition for \" + target);\r\n        return buckContents;\r\n    }\r\n    String targetDef = buckContents.substring(targetOffset[0], targetOffset[1]);\r\n    if (autodepsPattern.matcher(targetDef).find()) {\r\n        return buckContents;\r\n    }\r\n    BuckTarget relativeDependency = target.relativize(dependency);\r\n    Matcher exportedDepsMatcher = exportedDepsPattern.matcher(targetDef);\r\n    if (exportedDepsMatcher.find()) {\r\n        String exportedDeps = exportedDepsMatcher.group(1);\r\n        if (exportedDeps.contains(relativeDependency.toString())) {\r\n            return buckContents;\r\n        }\r\n    }\r\n    Matcher depsMatcher = depsPattern.matcher(targetDef);\r\n    if (!depsMatcher.find()) {\r\n        LOG.warn(\"Couldn't figure out where to add new dependency on \" + dependency + \" in definition for \" + target);\r\n        return buckContents;\r\n    }\r\n    if (depsMatcher.group(1).contains(relativeDependency.toString())) {\r\n        return buckContents;\r\n    }\r\n    int offset = targetOffset[0] + depsMatcher.start(1);\r\n    return buckContents.substring(0, offset) + \"\\n\\t\\t\\\"\" + relativeDependency.toString() + \"\\\",\" + buckContents.substring(offset);\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.instanceOf",
	"Comment": "generates the instruction to test if the top stack value is of the giventype.",
	"Method": "void instanceOf(Type type){\r\n    typeInsn(Opcodes.INSTANCEOF, type);\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.FirstFitLocalCombiningAllocator.ssaSetToSpecs",
	"Comment": "converts a bit set of ssa registers into a registerspeclist containingthe definition specs of all the registers.",
	"Method": "RegisterSpecList ssaSetToSpecs(IntSet ssaSet){\r\n    RegisterSpecList result = new RegisterSpecList(ssaSet.elements());\r\n    IntIterator iter = ssaSet.iterator();\r\n    int i = 0;\r\n    while (iter.hasNext()) {\r\n        result.set(i++, getDefinitionSpecForSsaReg(iter.next()));\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.Hex.encodeHex",
	"Comment": "converts a byte buffer into an array of characters representing the hexadecimal values of each byte in order.the returned array will be double the length of the passed array, as it takes two characters to represent anygiven byte.",
	"Method": "char[] encodeHex(byte[] data,char[] encodeHex,ByteBuffer data,char[] encodeHex,byte[] data,boolean toLowerCase,char[] encodeHex,ByteBuffer data,boolean toLowerCase,char[] encodeHex,byte[] data,char[] toDigits,char[] encodeHex,ByteBuffer data,char[] toDigits){\r\n    return encodeHex(data.array(), toDigits);\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.Method.getReturnType",
	"Comment": "returns the return type of the method described by this object.",
	"Method": "Type getReturnType(){\r\n    return Type.getReturnType(desc);\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.support.DefaultLdapAccountStateHandler.handleError",
	"Comment": "handle an account state error produced by ldaptive account state machinery.override this method to provide custom error handling.",
	"Method": "void handleError(AccountState.Error error,AuthenticationResponse response,PasswordPolicyConfiguration configuration,List<MessageDescriptor> messages){\r\n    LOGGER.debug(\"Handling LDAP account state error [{}]\", error);\r\n    if (errorMap.containsKey(error)) {\r\n        throw errorMap.get(error);\r\n    }\r\n    LOGGER.debug(\"No LDAP error mapping defined for [{}]\", error);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.RVFDataset.randomize",
	"Comment": "randomizes the data array in place. needs to be redefined here because weneed to randomize the values as well.",
	"Method": "void randomize(long randomSeed){\r\n    Random rand = new Random(randomSeed);\r\n    for (int j = size - 1; j > 0; j--) {\r\n        int randIndex = rand.nextInt(j);\r\n        int[] tmp = data[randIndex];\r\n        data[randIndex] = data[j];\r\n        data[j] = tmp;\r\n        int tmpl = labels[randIndex];\r\n        labels[randIndex] = labels[j];\r\n        labels[j] = tmpl;\r\n        double[] tmpv = values[randIndex];\r\n        values[randIndex] = values[j];\r\n        values[j] = tmpv;\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.Specifications.newFieldOffset",
	"Comment": "creates a public static field with an unsafe address offset.",
	"Method": "FieldSpec newFieldOffset(String className,String varName){\r\n    String fieldName = CaseFormat.LOWER_CAMEL.to(CaseFormat.UPPER_UNDERSCORE, varName);\r\n    return FieldSpec.builder(long.class, offsetName(varName), Modifier.PROTECTED, Modifier.STATIC, Modifier.FINAL).initializer(\"$T.objectFieldOffset($T.class, $L.$L)\", UNSAFE_ACCESS, ClassName.bestGuess(className), LOCAL_CACHE_FACTORY, fieldName).build();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.admission.bloom.MembershipTest.falsePositives",
	"Comment": "returns the false positives based on an input of unique elements.",
	"Method": "int falsePositives(Membership filter,long[] input){\r\n    int falsePositives = 0;\r\n    int truePositives = 0;\r\n    int i = 0;\r\n    for (; i < (input.length / 2); i++) {\r\n        filter.put(input[i]);\r\n    }\r\n    for (int k = 0; k < i; k++) {\r\n        truePositives += filter.mightContain(input[k]) ? 1 : 0;\r\n    }\r\n    assertThat(truePositives, is(input.length / 2));\r\n    for (; i < input.length; i++) {\r\n        falsePositives += filter.mightContain(input[i]) ? 1 : 0;\r\n    }\r\n    return falsePositives;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.BasicBlock.withRegisterOffset",
	"Comment": "returns an instance that is identical to this one, except thatthe registers in each instruction are offset by the givenamount.",
	"Method": "BasicBlock withRegisterOffset(int delta){\r\n    return new BasicBlock(label, insns.withRegisterOffset(delta), successors, primarySuccessor);\r\n}"
}, {
	"Path": "the.bytecode.club.bytecodeviewer.BytecodeViewer.getJavaCommand",
	"Comment": "returns the java command it can use to launch the decompilers",
	"Method": "String getJavaCommand(){\r\n    try {\r\n        sm.stopBlocking();\r\n        ProcessBuilder pb = new ProcessBuilder(\"java\", \"-version\");\r\n        Process p = pb.start();\r\n        sm.setBlocking();\r\n        if (p != null)\r\n            return \"java\";\r\n    } catch (Exception e) {\r\n        sm.setBlocking();\r\n        boolean empty = java.isEmpty();\r\n        while (empty) {\r\n            showMessage(\"You need to set your Java path, this requires the JRE to be downloaded.\" + BytecodeViewer.nl + \"(C:/programfiles/Java/JRE_xx/bin/java.exe)\");\r\n            viewer.java();\r\n            empty = java.isEmpty();\r\n        }\r\n    }\r\n    return java;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.ner.CMMClassifier.getDefaultClassifier",
	"Comment": "used to obtain the default classifier which isstored inside a jar file.this functionwill only work if run inside a jar file.",
	"Method": "CMMClassifier<? extends CoreLabel> getDefaultClassifier(){\r\n    CMMClassifier<? extends CoreLabel> cmm = new CMMClassifier();\r\n    cmm.loadDefaultClassifier();\r\n    return cmm;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.adaptive.geo.GeoLocationRequest.isValid",
	"Comment": "check whether the geolocation contains enough data to proceed.",
	"Method": "boolean isValid(){\r\n    return StringUtils.isNotBlank(this.latitude) && StringUtils.isNotBlank(this.longitude) && StringUtils.isNotBlank(this.accuracy) && StringUtils.isNotBlank(this.timestamp);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.PhoneticEngine.encode",
	"Comment": "encodes an input string into an output phonetic representation, given a set of possible origin languages.",
	"Method": "String encode(String input,String encode,String input,Languages.LanguageSet languageSet){\r\n    final Map<String, List<Rule>> rules = Rule.getInstanceMap(this.nameType, RuleType.RULES, languageSet);\r\n    final Map<String, List<Rule>> finalRules1 = Rule.getInstanceMap(this.nameType, this.ruleType, \"common\");\r\n    final Map<String, List<Rule>> finalRules2 = Rule.getInstanceMap(this.nameType, this.ruleType, languageSet);\r\n    input = input.toLowerCase(Locale.ENGLISH).replace('-', ' ').trim();\r\n    if (this.nameType == NameType.GENERIC) {\r\n        if (input.length() >= 2 && input.substring(0, 2).equals(\"d'\")) {\r\n            final String remainder = input.substring(2);\r\n            final String combined = \"d\" + remainder;\r\n            return \"(\" + encode(remainder) + \")-(\" + encode(combined) + \")\";\r\n        }\r\n        for (final String l : NAME_PREFIXES.get(this.nameType)) {\r\n            if (input.startsWith(l + \" \")) {\r\n                final String remainder = input.substring(l.length() + 1);\r\n                final String combined = l + remainder;\r\n                return \"(\" + encode(remainder) + \")-(\" + encode(combined) + \")\";\r\n            }\r\n        }\r\n    }\r\n    final List<String> words = Arrays.asList(input.split(\"\\\\s+\"));\r\n    final List<String> words2 = new ArrayList<String>();\r\n    switch(this.nameType) {\r\n        case SEPHARDIC:\r\n            for (final String aWord : words) {\r\n                final String[] parts = aWord.split(\"'\");\r\n                final String lastPart = parts[parts.length - 1];\r\n                words2.add(lastPart);\r\n            }\r\n            words2.removeAll(NAME_PREFIXES.get(this.nameType));\r\n            break;\r\n        case ASHKENAZI:\r\n            words2.addAll(words);\r\n            words2.removeAll(NAME_PREFIXES.get(this.nameType));\r\n            break;\r\n        case GENERIC:\r\n            words2.addAll(words);\r\n            break;\r\n        default:\r\n            throw new IllegalStateException(\"Unreachable case: \" + this.nameType);\r\n    }\r\n    if (this.concat) {\r\n        input = join(words2, \" \");\r\n    } else if (words2.size() == 1) {\r\n        input = words.iterator().next();\r\n    } else {\r\n        final StringBuilder result = new StringBuilder();\r\n        for (final String word : words2) {\r\n            result.append(\"-\").append(encode(word));\r\n        }\r\n        return result.substring(1);\r\n    }\r\n    PhonemeBuilder phonemeBuilder = PhonemeBuilder.empty(languageSet);\r\n    for (int i = 0; i < input.length(); ) {\r\n        final RulesApplication rulesApplication = new RulesApplication(rules, input, phonemeBuilder, i, maxPhonemes).invoke();\r\n        i = rulesApplication.getI();\r\n        phonemeBuilder = rulesApplication.getPhonemeBuilder();\r\n    }\r\n    phonemeBuilder = applyFinalRules(phonemeBuilder, finalRules1);\r\n    phonemeBuilder = applyFinalRules(phonemeBuilder, finalRules2);\r\n    return phonemeBuilder.makeString();\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMap8Test.testKeySetSpliterator",
	"Comment": "keysetview.spliterator returns spliterator over the elements in this set",
	"Method": "void testKeySetSpliterator(){\r\n    LongAdder adder = new LongAdder();\r\n    ConcurrentMap map = map5();\r\n    Set set = map.keySet();\r\n    Spliterator<Integer> sp = set.spliterator();\r\n    checkSpliteratorCharacteristics(sp, CONCURRENT | DISTINCT | NONNULL);\r\n    assertEquals(sp.estimateSize(), map.size());\r\n    Spliterator<Integer> sp2 = sp.trySplit();\r\n    sp.forEachRemaining((Integer x) -> adder.add(x.longValue()));\r\n    long v = adder.sumThenReset();\r\n    sp2.forEachRemaining((Integer x) -> adder.add(x.longValue()));\r\n    long v2 = adder.sum();\r\n    assertEquals(v + v2, 15);\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.client.LdapSpnegoKnownClientSystemsFilterAction.verifySpnegoAttributeValue",
	"Comment": "verify spnego attribute value.this impl simply makes sure the attribute exists and has a value.",
	"Method": "boolean verifySpnegoAttributeValue(LdapAttribute attribute){\r\n    return attribute != null && StringUtils.isNotBlank(attribute.getStringValue());\r\n}"
}, {
	"Path": "org.objectweb.asm.util.CheckMethodAdapter.checkLabel",
	"Comment": "checks that the given label is not null. this method can also check thatthe label has been visited.",
	"Method": "void checkLabel(Label label,boolean checkVisited,String msg){\r\n    if (label == null) {\r\n        throw new IllegalArgumentException(\"Invalid \" + msg + \" (must not be null)\");\r\n    }\r\n    if (checkVisited && labels.get(label) == null) {\r\n        throw new IllegalArgumentException(\"Invalid \" + msg + \" (must be visited first)\");\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.Frame.set",
	"Comment": "sets the output frame local variable type at the given index.",
	"Method": "void set(int local,int type){\r\n    if (outputLocals == null) {\r\n        outputLocals = new int[10];\r\n    }\r\n    int n = outputLocals.length;\r\n    if (local >= n) {\r\n        int[] t = new int[Math.max(local + 1, 2 * n)];\r\n        System.arraycopy(outputLocals, 0, t, 0, n);\r\n        outputLocals = t;\r\n    }\r\n    outputLocals[local] = type;\r\n}"
}, {
	"Path": "org.objectweb.asm.Handle.getDesc",
	"Comment": "returns the descriptor of the field or method designated by this handle.",
	"Method": "String getDesc(){\r\n    return desc;\r\n}"
}, {
	"Path": "org.apereo.cas.couchdb.consent.ConsentDecisionCouchDbRepository.findConsentDecision",
	"Comment": "find all consent decisions for a given principal, service pair. should only be one.",
	"Method": "List<CouchDbConsentDecision> findConsentDecision(String principal,String service){\r\n    val view = createQuery(\"by_consent_decision\").key(ComplexKey.of(principal, service)).includeDocs(true);\r\n    return db.queryView(view, CouchDbConsentDecision.class);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.getSpan",
	"Comment": "returns the smallest span that covers the extent of all these objects",
	"Method": "Span getSpan(ExtractionObject objs){\r\n    int left = Integer.MAX_VALUE;\r\n    int right = Integer.MIN_VALUE;\r\n    for (ExtractionObject obj : objs) {\r\n        if (obj.getExtentTokenStart() < left) {\r\n            left = obj.getExtentTokenStart();\r\n        }\r\n        if (obj.getExtentTokenEnd() > right) {\r\n            right = obj.getExtentTokenEnd();\r\n        }\r\n    }\r\n    assert (left < Integer.MAX_VALUE);\r\n    assert (right > Integer.MIN_VALUE);\r\n    return new Span(left, right);\r\n}"
}, {
	"Path": "com.android.dx.rop.annotation.AnnotationsList.combine",
	"Comment": "constructs an immutable instance which is the combination ofthe two given instances. the two instances must each have thesame number of elements, and each pair of elements must containdisjoint sets of types.",
	"Method": "AnnotationsList combine(AnnotationsList list1,AnnotationsList list2){\r\n    int size = list1.size();\r\n    if (size != list2.size()) {\r\n        throw new IllegalArgumentException(\"list1.size() != list2.size()\");\r\n    }\r\n    AnnotationsList result = new AnnotationsList(size);\r\n    for (int i = 0; i < size; i++) {\r\n        Annotations a1 = list1.get(i);\r\n        Annotations a2 = list2.get(i);\r\n        result.set(i, Annotations.combine(a1, a2));\r\n    }\r\n    result.setImmutable();\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.util.cipher.AbstractCipherExecutor.sign",
	"Comment": "sign the array by first turning it into a base64 encoded string.",
	"Method": "byte[] sign(byte[] value){\r\n    if (this.signingKey == null) {\r\n        return value;\r\n    }\r\n    if (\"RSA\".equalsIgnoreCase(this.signingKey.getAlgorithm())) {\r\n        return EncodingUtils.signJwsRSASha512(this.signingKey, value);\r\n    }\r\n    return EncodingUtils.signJwsHMACSha512(this.signingKey, value);\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.SieveCoreferenceSystem.optimizeSieveOrdering",
	"Comment": "given a set of sieves, select an optimal ordering for the sievesby iterating over sieves, and selecting the one that gives the best score andadding sieves one at a time until no more sieves left",
	"Method": "void optimizeSieveOrdering(MentionExtractor mentionExtractor,Properties props,String timestamp){\r\n    logger.info(\"=============SIEVE OPTIMIZATION START ====================\");\r\n    logger.info(\"Optimize sieves using score: \" + optimizeScoreType);\r\n    FileFilter scoreFilesFilter = new FileFilter() {\r\n        @Override\r\n        public boolean accept(File file) {\r\n            return file.getAbsolutePath().endsWith(\".score\");\r\n        }\r\n        public String toString() {\r\n            return \".score\";\r\n        }\r\n    };\r\n    Pattern scoreFilePattern = Pattern.compile(\".*sieves\\\\.(\\\\d+)\\\\.(\\\\d+).score\");\r\n    String runDistributedCmd = props.getProperty(Constants.RUN_DIST_CMD_PROP);\r\n    String mainWorkDirPath = props.getProperty(Constants.RUN_DIST_CMD_WORK_DIR, \"workdir\") + \"-\" + timestamp + File.separator;\r\n    DeterministicCorefSieve[] origSieves = sieves;\r\n    String[] origSieveNames = sieveClassNames;\r\n    Set<Integer> remainingSieveIndices = Generics.newHashSet();\r\n    for (int i = 0; i < origSieves.length; i++) {\r\n        remainingSieveIndices.add(i);\r\n    }\r\n    List<Integer> optimizedOrdering = new ArrayList();\r\n    while (!remainingSieveIndices.isEmpty()) {\r\n        int curSievesNumber = optimizedOrdering.size();\r\n        sieves = new DeterministicCorefSieve[curSievesNumber + 1];\r\n        sieveClassNames = new String[curSievesNumber + 1];\r\n        for (int i = 0; i < curSievesNumber; i++) {\r\n            sieves[i] = origSieves[optimizedOrdering.get(i)];\r\n            sieveClassNames[i] = origSieveNames[optimizedOrdering.get(i)];\r\n        }\r\n        logger.info(\"*** Optimizing Sieve ordering for pass \" + curSievesNumber + \" ***\");\r\n        Set<Integer> selectableSieveIndices = new TreeSet(remainingSieveIndices);\r\n        if (sievesKeepOrder != null) {\r\n            for (Pair<Integer, Integer> ko : sievesKeepOrder) {\r\n                if (ko.second() < 0) {\r\n                    if (remainingSieveIndices.contains(ko.first())) {\r\n                        logger.info(\"Restrict selection to \" + origSieveNames[ko.first()] + \" because of constraint \" + toSieveOrderConstraintString(ko, origSieveNames));\r\n                        selectableSieveIndices = Generics.newHashSet(1);\r\n                        selectableSieveIndices.add(ko.first());\r\n                        break;\r\n                    }\r\n                } else if (ko.first() < 0 && remainingSieveIndices.size() > 1) {\r\n                    if (remainingSieveIndices.contains(ko.second())) {\r\n                        logger.info(\"Remove selection \" + origSieveNames[ko.second()] + \" because of constraint \" + toSieveOrderConstraintString(ko, origSieveNames));\r\n                        selectableSieveIndices.remove(ko.second());\r\n                    }\r\n                } else if (remainingSieveIndices.contains(ko.first())) {\r\n                    if (remainingSieveIndices.contains(ko.second())) {\r\n                        logger.info(\"Remove selection \" + origSieveNames[ko.second()] + \" because of constraint \" + toSieveOrderConstraintString(ko, origSieveNames));\r\n                        selectableSieveIndices.remove(ko.second());\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        if (selectableSieveIndices.isEmpty()) {\r\n            throw new RuntimeException(\"Unable to find sieve ordering to satisfy all ordering constraints!!!!\");\r\n        }\r\n        int selected = -1;\r\n        if (selectableSieveIndices.size() > 1) {\r\n            List<Pair<Double, Integer>> scores = new ArrayList();\r\n            if (runDistributedCmd != null) {\r\n                String workDirPath = mainWorkDirPath + curSievesNumber + File.separator;\r\n                File workDir = new File(workDirPath);\r\n                workDir.mkdirs();\r\n                workDirPath = workDir.getAbsolutePath() + File.separator;\r\n                for (int potentialSieveIndex : selectableSieveIndices) {\r\n                    String sieveSelectionId = curSievesNumber + \".\" + potentialSieveIndex;\r\n                    String jobDirPath = workDirPath + sieveSelectionId + File.separator;\r\n                    File jobDir = new File(jobDirPath);\r\n                    jobDir.mkdirs();\r\n                    Properties newProps = new Properties();\r\n                    for (String key : props.stringPropertyNames()) {\r\n                        String value = props.getProperty(key);\r\n                        value = value.replaceAll(\"\\\\$\\\\{JOBDIR\\\\}\", jobDirPath);\r\n                        newProps.setProperty(key, value);\r\n                    }\r\n                    sieves[curSievesNumber] = origSieves[potentialSieveIndex];\r\n                    sieveClassNames[curSievesNumber] = origSieveNames[potentialSieveIndex];\r\n                    newProps.setProperty(Constants.OPTIMIZE_SIEVES_PROP, \"false\");\r\n                    newProps.setProperty(Constants.SCORE_PROP, \"true\");\r\n                    newProps.setProperty(Constants.SIEVES_PROP, StringUtils.join(sieveClassNames, \",\"));\r\n                    newProps.setProperty(Constants.LOG_PROP, jobDirPath + \"sieves.\" + sieveSelectionId + \".log\");\r\n                    newProps.setProperty(Constants.SCORE_FILE_PROP, workDirPath + \"sieves.\" + sieveSelectionId + \".score\");\r\n                    if (Constants.PRINT_CONLL_OUTPUT || replicateCoNLL) {\r\n                        newProps.setProperty(Constants.CONLL_OUTPUT_PROP, jobDirPath + \"sieves.\" + sieveSelectionId + \".conlloutput\");\r\n                    }\r\n                    String distCmd = newProps.getProperty(Constants.RUN_DIST_CMD_PROP, runDistributedCmd);\r\n                    runAndScoreCorefDist(distCmd, newProps, workDirPath + \"sieves.\" + sieveSelectionId + \".props\");\r\n                }\r\n                waitForFiles(workDir, scoreFilesFilter, selectableSieveIndices.size());\r\n                File[] scoreFiles = workDir.listFiles(scoreFilesFilter);\r\n                for (File file : scoreFiles) {\r\n                    Matcher m = scoreFilePattern.matcher(file.getName());\r\n                    if (m.matches()) {\r\n                        int potentialSieveIndex = Integer.parseInt(m.group(2));\r\n                        String text = IOUtils.slurpFile(file);\r\n                        double score = Double.parseDouble(text);\r\n                        scores.add(new Pair(score, potentialSieveIndex));\r\n                    } else {\r\n                        throw new RuntimeException(\"Bad score file name: \" + file);\r\n                    }\r\n                }\r\n            } else {\r\n                for (int potentialSieveIndex : selectableSieveIndices) {\r\n                    sieves[curSievesNumber] = origSieves[potentialSieveIndex];\r\n                    sieveClassNames[curSievesNumber] = origSieveNames[potentialSieveIndex];\r\n                    logger.info(\"Trying sieve \" + curSievesNumber + \"=\" + sieveClassNames[curSievesNumber] + \": \");\r\n                    logger.info(\" Trying sieves: \" + StringUtils.join(sieveClassNames, \",\"));\r\n                    double score = runAndScoreCoref(this, mentionExtractor, props, timestamp);\r\n                    scores.add(new Pair(score, potentialSieveIndex));\r\n                    logger.info(\" Trying sieves: \" + StringUtils.join(sieveClassNames, \",\"));\r\n                    logger.info(\" Trying sieves score: \" + score);\r\n                }\r\n            }\r\n            double bestScore = -1;\r\n            for (Pair<Double, Integer> p : scores) {\r\n                if (selected < 0 || p.first() > bestScore) {\r\n                    bestScore = p.first();\r\n                    selected = p.second();\r\n                }\r\n            }\r\n            Collections.sort(scores);\r\n            Collections.reverse(scores);\r\n            logger.info(\"Ordered sieves\");\r\n            for (Pair<Double, Integer> p : scores) {\r\n                logger.info(\"Sieve optimization pass \" + curSievesNumber + \" scores: Sieve=\" + origSieveNames[p.second()] + \", score=\" + p.first());\r\n            }\r\n        } else {\r\n            logger.info(\"Only one choice for next sieve\");\r\n            selected = selectableSieveIndices.iterator().next();\r\n        }\r\n        sieves[curSievesNumber] = origSieves[selected];\r\n        sieveClassNames[curSievesNumber] = origSieveNames[selected];\r\n        logger.info(\"Adding sieve \" + curSievesNumber + \"=\" + sieveClassNames[curSievesNumber] + \" to existing sieves: \");\r\n        logger.info(\" Current Sieves: \" + StringUtils.join(sieveClassNames, \",\"));\r\n        optimizedOrdering.add(selected);\r\n        remainingSieveIndices.remove(selected);\r\n    }\r\n    logger.info(\"Final Sieve Ordering: \" + StringUtils.join(sieveClassNames, \",\"));\r\n    logger.info(\"=============SIEVE OPTIMIZATION DONE ====================\");\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.SieveCoreferenceSystem.optimizeSieveOrdering",
	"Comment": "given a set of sieves, select an optimal ordering for the sievesby iterating over sieves, and selecting the one that gives the best score andadding sieves one at a time until no more sieves left",
	"Method": "void optimizeSieveOrdering(MentionExtractor mentionExtractor,Properties props,String timestamp){\r\n    return file.getAbsolutePath().endsWith(\".score\");\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.SieveCoreferenceSystem.optimizeSieveOrdering",
	"Comment": "given a set of sieves, select an optimal ordering for the sievesby iterating over sieves, and selecting the one that gives the best score andadding sieves one at a time until no more sieves left",
	"Method": "void optimizeSieveOrdering(MentionExtractor mentionExtractor,Properties props,String timestamp){\r\n    return \".score\";\r\n}"
}, {
	"Path": "edu.stanford.nlp.io.IOUtilsITest.testSlurpFile",
	"Comment": "tests that slurpfile can get files from within the classpath",
	"Method": "void testSlurpFile(){\r\n    String contents;\r\n    try {\r\n        contents = IOUtils.slurpFile(\"edu/stanford/nlp/io/test.txt\", \"utf-8\");\r\n    } catch (IOException e) {\r\n        throw new RuntimeIOException(e);\r\n    }\r\n    assertEquals(\"This is a test sentence.\", contents.trim());\r\n    try {\r\n        contents = IOUtils.slurpFile(\"edu/stanford/nlp/io/test.txt\");\r\n    } catch (IOException e) {\r\n        throw new RuntimeIOException(e);\r\n    }\r\n    assertEquals(\"This is a test sentence.\", contents.trim());\r\n    try {\r\n        contents = IOUtils.slurpFile(\"edu/stanford/nlp/io/test.txtzzz\");\r\n        throw new AssertionError(\"Should not have found unknown file\");\r\n    } catch (IOException e) {\r\n    }\r\n    contents = IOUtils.slurpFileNoExceptions(\"edu/stanford/nlp/io/test.txt\");\r\n    assertEquals(\"This is a test sentence.\", contents.trim());\r\n    try {\r\n        contents = IOUtils.slurpFileNoExceptions(\"edu/stanford/nlp/io/test.txtzzz\");\r\n        throw new AssertionError(\"Should not have found unknown file\");\r\n    } catch (RuntimeIOException e) {\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.util.IntList.makeImmutable",
	"Comment": "constructs a new immutable instance with the given elements.",
	"Method": "IntList makeImmutable(int value,IntList makeImmutable,int value0,int value1){\r\n    IntList result = new IntList(2);\r\n    result.add(value0);\r\n    result.add(value1);\r\n    result.setImmutable();\r\n    return result;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.getPhoneme",
	"Comment": "gets the phoneme. if the rule matches, this is the phoneme associated with the pattern match.",
	"Method": "PhonemeExpr getPhoneme(){\r\n    return this.phoneme;\r\n}"
}, {
	"Path": "org.apereo.cas.services.AbstractServiceRegistryTests.initializeServiceInstance",
	"Comment": "method to prepare registered service for testing.implementing classes may override this if more is necessary.",
	"Method": "AbstractRegisteredService initializeServiceInstance(AbstractRegisteredService rs){\r\n    val propertyMap = new HashMap<String, RegisteredServiceProperty>();\r\n    val property = new DefaultRegisteredServiceProperty();\r\n    val values = new HashSet<String>();\r\n    values.add(\"value1\");\r\n    values.add(\"value2\");\r\n    property.setValues(values);\r\n    propertyMap.put(\"field1\", property);\r\n    rs.setProperties(propertyMap);\r\n    return rs;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.CacheProxy.putIfAbsentNoAwait",
	"Comment": "associates the specified value with the specified key in the cache if there is no existingmapping.",
	"Method": "boolean putIfAbsentNoAwait(K key,V value,boolean publishToWriter){\r\n    boolean[] absent = { false };\r\n    cache.asMap().compute(copyOf(key), (k, expirable) -> {\r\n        if ((expirable != null) && !expirable.isEternal() && expirable.hasExpired(currentTimeMillis())) {\r\n            dispatcher.publishExpired(this, key, expirable.get());\r\n            statistics.recordEvictions(1L);\r\n            expirable = null;\r\n        }\r\n        if (expirable != null) {\r\n            return expirable;\r\n        }\r\n        absent[0] = true;\r\n        long expireTimeMS = getWriteExpireTimeMS(true);\r\n        if (expireTimeMS == 0) {\r\n            return null;\r\n        }\r\n        if (publishToWriter) {\r\n            publishToCacheWriter(writer::write, () -> new EntryProxy(key, value));\r\n        }\r\n        V copy = copyOf(value);\r\n        dispatcher.publishCreated(this, key, copy);\r\n        return new Expirable(copy, expireTimeMS);\r\n    });\r\n    return absent[0];\r\n}"
}, {
	"Path": "com.android.dx.util.IntList.contains",
	"Comment": "returns whether or not the given value appears in the list.this will do a binary search if the list is sorted or a linearsearch if not.",
	"Method": "boolean contains(int value){\r\n    return indexOf(value) >= 0;\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getSize",
	"Comment": "returns the size of values of this type. this method must not be used formethod types.",
	"Method": "int getSize(){\r\n    return buf == null ? (off & 0xFF) : 1;\r\n}"
}, {
	"Path": "jsr166.JSR166TestCase.tearDown",
	"Comment": "extra checks that get done for all test cases.triggers test case failure if any thread assertions have failed,by rethrowing, in the test harness thread, any exception recordedearlier by threadrecordfailure.triggers test case failure if interrupt status is set in the main thread.",
	"Method": "void tearDown(){\r\n    Throwable t = threadFailure.getAndSet(null);\r\n    if (t != null) {\r\n        if (t instanceof Error) {\r\n            throw (Error) t;\r\n        } else if (t instanceof RuntimeException) {\r\n            throw (RuntimeException) t;\r\n        } else if (t instanceof Exception) {\r\n            throw (Exception) t;\r\n        } else {\r\n            AssertionFailedError afe = new AssertionFailedError(t.toString());\r\n            afe.initCause(t);\r\n            throw afe;\r\n        }\r\n    }\r\n    if (Thread.interrupted()) {\r\n        throw new AssertionFailedError(\"interrupt status set in main thread\");\r\n    }\r\n    checkForkJoinPoolThreadLeaks();\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.scoreOfRVFDatum",
	"Comment": "returns the score of the rvfdatum for the specified label. ignores the true label of the rvfdatum.",
	"Method": "double scoreOfRVFDatum(RVFDatum<L, F> example,L label,double scoreOfRVFDatum,Counter<Integer> features,L label){\r\n    int iLabel = labelIndex.indexOf(label);\r\n    double score = 0.0;\r\n    for (Map.Entry<Integer, Double> entry : features.entrySet()) {\r\n        score += weight(entry.getKey(), iLabel) * entry.getValue();\r\n    }\r\n    return score + thresholds[iLabel];\r\n}"
}, {
	"Path": "org.apereo.cas.adaptors.x509.authentication.handler.support.X509CredentialsAuthenticationHandler.isCritical",
	"Comment": "checks if critical extension oids contain the extension oid.",
	"Method": "boolean isCritical(X509Certificate certificate,String extensionOid){\r\n    val criticalOids = certificate.getCriticalExtensionOIDs();\r\n    if (criticalOids == null || criticalOids.isEmpty()) {\r\n        return false;\r\n    }\r\n    return criticalOids.contains(extensionOid);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.TestSequenceModel.labelProb",
	"Comment": "get the probability of label with labelindex for the token at position",
	"Method": "double labelProb(int position,int labelIndex){\r\n    return cliqueTree.prob(position, labelIndex);\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.MethodNode.check",
	"Comment": "checks that this method node is compatible with the given asm apiversion. this methods checks that this node, and all its nodesrecursively, do not contain elements that were introduced in more recentversions of the asm api than the given version.",
	"Method": "void check(int api){\r\n    if (api == Opcodes.ASM4) {\r\n        if (visibleTypeAnnotations != null && visibleTypeAnnotations.size() > 0) {\r\n            throw new RuntimeException();\r\n        }\r\n        if (invisibleTypeAnnotations != null && invisibleTypeAnnotations.size() > 0) {\r\n            throw new RuntimeException();\r\n        }\r\n        int n = tryCatchBlocks == null ? 0 : tryCatchBlocks.size();\r\n        for (int i = 0; i < n; ++i) {\r\n            TryCatchBlockNode tcb = tryCatchBlocks.get(i);\r\n            if (tcb.visibleTypeAnnotations != null && tcb.visibleTypeAnnotations.size() > 0) {\r\n                throw new RuntimeException();\r\n            }\r\n            if (tcb.invisibleTypeAnnotations != null && tcb.invisibleTypeAnnotations.size() > 0) {\r\n                throw new RuntimeException();\r\n            }\r\n        }\r\n        for (int i = 0; i < instructions.size(); ++i) {\r\n            AbstractInsnNode insn = instructions.get(i);\r\n            if (insn.visibleTypeAnnotations != null && insn.visibleTypeAnnotations.size() > 0) {\r\n                throw new RuntimeException();\r\n            }\r\n            if (insn.invisibleTypeAnnotations != null && insn.invisibleTypeAnnotations.size() > 0) {\r\n                throw new RuntimeException();\r\n            }\r\n            if (insn instanceof MethodInsnNode) {\r\n                boolean itf = ((MethodInsnNode) insn).itf;\r\n                if (itf != (insn.opcode == Opcodes.INVOKEINTERFACE)) {\r\n                    throw new RuntimeException();\r\n                }\r\n            }\r\n        }\r\n        if (visibleLocalVariableAnnotations != null && visibleLocalVariableAnnotations.size() > 0) {\r\n            throw new RuntimeException();\r\n        }\r\n        if (invisibleLocalVariableAnnotations != null && invisibleLocalVariableAnnotations.size() > 0) {\r\n            throw new RuntimeException();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.actions.AuthenticationExceptionHandlerAction.handle",
	"Comment": "maps an authentication exception onto a state name.also sets an error severity message in the message context.",
	"Method": "String handle(Exception e,RequestContext requestContext){\r\n    val messageContext = requestContext.getMessageContext();\r\n    if (e instanceof AuthenticationException) {\r\n        return handleAuthenticationException((AuthenticationException) e, requestContext);\r\n    }\r\n    if (e instanceof AbstractTicketException) {\r\n        return handleAbstractTicketException((AbstractTicketException) e, requestContext);\r\n    }\r\n    LOGGER.trace(\"Unable to translate errors of the authentication exception [{}]. Returning [{}]\", e, UNKNOWN);\r\n    val messageCode = this.messageBundlePrefix + UNKNOWN;\r\n    messageContext.addMessage(new MessageBuilder().error().code(messageCode).build());\r\n    return UNKNOWN;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.PhoneticEngine.getMaxPhonemes",
	"Comment": "gets the maximum number of phonemes the engine will calculate for a given input.",
	"Method": "int getMaxPhonemes(){\r\n    return this.maxPhonemes;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.adaptive.CarPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new CarPolicy(config));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.scheduleAfterWrite",
	"Comment": "conditionally schedules the asynchronous maintenance task after a write operation. if thetask status was idle or required then the maintenance task is scheduled immediately. if itis already processing then it is set to transition to required upon completion so that a newexecution is triggered by the next operation.",
	"Method": "void scheduleAfterWrite(){\r\n    for (; ; ) {\r\n        switch(drainStatus()) {\r\n            case IDLE:\r\n                casDrainStatus(IDLE, REQUIRED);\r\n                scheduleDrainBuffers();\r\n                return;\r\n            case REQUIRED:\r\n                scheduleDrainBuffers();\r\n                return;\r\n            case PROCESSING_TO_IDLE:\r\n                if (casDrainStatus(PROCESSING_TO_IDLE, PROCESSING_TO_REQUIRED)) {\r\n                    return;\r\n                }\r\n                continue;\r\n            case PROCESSING_TO_REQUIRED:\r\n                return;\r\n            default:\r\n                throw new IllegalStateException();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.POSTaggerAnnotatorITest.testMulticoreAnnotation",
	"Comment": "check that tagging multiple sentences with different numbers of threads works",
	"Method": "void testMulticoreAnnotation(){\r\n    Properties props = new Properties();\r\n    POSTaggerAnnotator localTagger = new POSTaggerAnnotator(\"pos\", props);\r\n    Annotation ann = makeAnnotation(testSentences);\r\n    localTagger.annotate(ann);\r\n    Annotation shortAnn = makeAnnotation(testSentences[0], testSentences[1]);\r\n    localTagger.annotate(shortAnn);\r\n    props.setProperty(\"nthreads\", \"4\");\r\n    localTagger = new POSTaggerAnnotator(\"pos\", props);\r\n    Annotation ann2 = makeAnnotation(testSentences);\r\n    localTagger.annotate(ann2);\r\n    Annotation shortAnn2 = makeAnnotation(testSentences[0], testSentences[1]);\r\n    localTagger.annotate(shortAnn2);\r\n    assertEquals(ann, ann2);\r\n    assertEquals(shortAnn, shortAnn2);\r\n    shortAnn.get(CoreAnnotations.SentencesAnnotation.class).get(0).get(CoreAnnotations.TokensAnnotation.class).get(0).set(CoreAnnotations.PartOfSpeechAnnotation.class, \"foo\");\r\n    assertFalse(shortAnn.equals(shortAnn2));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.event.EventDispatcher.publishCreated",
	"Comment": "publishes a creation event for the entry to all of the interested listeners.",
	"Method": "void publishCreated(Cache<K, V> cache,K key,V value){\r\n    publish(cache, EventType.CREATED, key, null, value, false);\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaMethod.makeNewSsaReg",
	"Comment": "makes a new ssa register. for use after renaming has completed.",
	"Method": "int makeNewSsaReg(){\r\n    int reg = registerCount++;\r\n    spareRegisterBase = registerCount;\r\n    onInsnsChanged();\r\n    return reg;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.linked.LinkedPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config,EvictionPolicy policy){\r\n    BasicSettings settings = new BasicSettings(config);\r\n    return settings.admission().stream().map(admission -> new LinkedPolicy(admission, policy, config)).collect(toSet());\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.JSRInlinerAdapter.visitEnd",
	"Comment": "if any jsrs were seen, triggers the inlining process. otherwise, forwardsthe byte codes untouched.",
	"Method": "void visitEnd(){\r\n    if (!subroutineHeads.isEmpty()) {\r\n        markSubroutines();\r\n        if (LOGGING) {\r\n            log(mainSubroutine.toString());\r\n            Iterator<BitSet> it = subroutineHeads.values().iterator();\r\n            while (it.hasNext()) {\r\n                BitSet sub = it.next();\r\n                log(sub.toString());\r\n            }\r\n        }\r\n        emitCode();\r\n    }\r\n    if (mv != null) {\r\n        accept(mv);\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.cli.Parser.processOption",
	"Comment": "process the option specified by arg using the valuesretrieved from the specified iterator iter.",
	"Method": "void processOption(String arg,ListIterator<String> iter){\r\n    boolean hasOption = getOptions().hasOption(arg);\r\n    if (!hasOption) {\r\n        throw new UnrecognizedOptionException(\"Unrecognized option: \" + arg, arg);\r\n    }\r\n    Option opt = (Option) getOptions().getOption(arg).clone();\r\n    updateRequiredOptions(opt);\r\n    if (opt.hasArg()) {\r\n        processArgs(opt, iter);\r\n    }\r\n    cmd.addOption(opt);\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.SingletonPredictor.saveToSerialized",
	"Comment": "saves the singleton predictor model to the given filename.if there is an error, a runtimeioexception is thrown.",
	"Method": "void saveToSerialized(LogisticClassifier<String, String> predictor,String filename){\r\n    try {\r\n        log.info(\"Writing singleton predictor in serialized format to file \" + filename + ' ');\r\n        ObjectOutputStream out = IOUtils.writeStreamFromString(filename);\r\n        out.writeObject(predictor);\r\n        out.close();\r\n        log.info(\"done.\");\r\n    } catch (IOException ioe) {\r\n        throw new RuntimeIOException(ioe);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.management.JmxRegistration.sanitize",
	"Comment": "returns a sanatized string for use as a management bean name.",
	"Method": "String sanitize(String name){\r\n    return (name == null) ? \"\" : name.replaceAll(\",|:|=|\\n\", \".\");\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.SieveCoreferenceSystem.postProcessing",
	"Comment": "remove singletons, appositive, predicate nominatives, relative pronouns",
	"Method": "void postProcessing(Document document){\r\n    Set<Mention> removeSet = Generics.newHashSet();\r\n    Set<Integer> removeClusterSet = Generics.newHashSet();\r\n    for (CorefCluster c : document.corefClusters.values()) {\r\n        Set<Mention> removeMentions = Generics.newHashSet();\r\n        for (Mention m : c.getCorefMentions()) {\r\n            if (Constants.REMOVE_APPOSITION_PREDICATENOMINATIVES && ((m.appositions != null && m.appositions.size() > 0) || (m.predicateNominatives != null && m.predicateNominatives.size() > 0) || (m.relativePronouns != null && m.relativePronouns.size() > 0))) {\r\n                removeMentions.add(m);\r\n                removeSet.add(m);\r\n                m.corefClusterID = m.mentionID;\r\n            }\r\n        }\r\n        c.corefMentions.removeAll(removeMentions);\r\n        if (Constants.REMOVE_SINGLETONS && c.getCorefMentions().size() == 1) {\r\n            removeClusterSet.add(c.clusterID);\r\n        }\r\n    }\r\n    for (int removeId : removeClusterSet) {\r\n        document.corefClusters.remove(removeId);\r\n    }\r\n    for (Mention m : removeSet) {\r\n        document.positions.remove(m);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.EntityCachingAbstractSequencePrior.otherOccurrences",
	"Comment": "finds other locations in the sequence where the sequence ofwords in this entity occurs.",
	"Method": "int[] otherOccurrences(Entity entity){\r\n    List<Integer> other = new ArrayList();\r\n    for (int i = 0; i < doc.size(); i++) {\r\n        if (i == entity.startPosition) {\r\n            continue;\r\n        }\r\n        if (matches(entity, i)) {\r\n            other.add(Integer.valueOf(i));\r\n        }\r\n    }\r\n    return toArray(other);\r\n}"
}, {
	"Path": "org.apache.commons.codec.digest.HmacUtils.getHmacMd5",
	"Comment": "returns an initialized mac for the hmacmd5 algorithm.every implementation of the java platform is required to support this standard mac algorithm.",
	"Method": "Mac getHmacMd5(byte[] key){\r\n    return getInitializedMac(HmacAlgorithms.HMAC_MD5, key);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.makeDead",
	"Comment": "atomically transitions the node to the dead state and decrements theweightedsize.",
	"Method": "void makeDead(Node<K, V> node){\r\n    synchronized (node) {\r\n        if (node.isDead()) {\r\n            return;\r\n        }\r\n        if (evicts()) {\r\n            if (node.inEden()) {\r\n                lazySetEdenWeightedSize(edenWeightedSize() - node.getWeight());\r\n            } else if (node.inMainProtected()) {\r\n                lazySetMainProtectedWeightedSize(mainProtectedWeightedSize() - node.getWeight());\r\n            }\r\n            lazySetWeightedSize(weightedSize() - node.getWeight());\r\n        }\r\n        node.die();\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaInsn.changeResultReg",
	"Comment": "changes the result register if this insn has a result. this is usedduring renaming.",
	"Method": "void changeResultReg(int reg){\r\n    if (result != null) {\r\n        result = result.withReg(reg);\r\n    }\r\n}"
}, {
	"Path": "com.facebook.buck.tools.consistency.RuleKeyLogFilePrinter.printFile",
	"Comment": "prints out a file to the given stream in a human friendly format",
	"Method": "void printFile(Path filename){\r\n    int[] linesVisited = { 0 };\r\n    Consumer<FullRuleKey> filterLambda = ruleKey -> printRuleKey(linesVisited, ruleKey);\r\n    if (namesFilter.isPresent()) {\r\n        filterLambda = ruleKey -> {\r\n            if (namesFilter.get().matcher(ruleKey.name != null ? ruleKey.name : \"\").matches()) {\r\n                printRuleKey(linesVisited, ruleKey);\r\n            }\r\n        };\r\n    } else if (keysFilter.isPresent()) {\r\n        filterLambda = ruleKey -> {\r\n            if (keysFilter.get().equals(ruleKey.key)) {\r\n                printRuleKey(linesVisited, ruleKey);\r\n            }\r\n        };\r\n    }\r\n    Consumer<FullRuleKey> finalFilterLambda = filterLambda;\r\n    reader.readFile(filename, ruleKey -> {\r\n        finalFilterLambda.accept(ruleKey);\r\n        return linesVisited[0] >= limit;\r\n    });\r\n}"
}, {
	"Path": "com.android.dx.ssa.LocalVariableInfo.getStarts",
	"Comment": "gets the register set associated with the start of the blockwith the given index. this returns an empty set with the appropriatemax size if no set was associated with the block in question.",
	"Method": "RegisterSpecSet getStarts(int index,RegisterSpecSet getStarts,SsaBasicBlock block){\r\n    return getStarts(block.getIndex());\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.CacheWriterVerifier.writes",
	"Comment": "checks that the expected number of write operations occurred.",
	"Method": "void writes(int count){\r\n    verify(context.cacheWriter(), times(count)).write(any(), any());\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.Node.casWriteTime",
	"Comment": "atomically sets the write time to the given updated value if the current value equals theexpected value and returns if the update was successful.",
	"Method": "boolean casWriteTime(long expect,long update){\r\n    throw new UnsupportedOperationException();\r\n}"
}, {
	"Path": "edu.stanford.nlp.fsm.TransducerGraph.addOnePathToGraph",
	"Comment": "assumes that the path already has epsilon as the last element.",
	"Method": "void addOnePathToGraph(List path,double count,int markovOrder,TransducerGraph graph){\r\n    Object source = graph.getStartNode();\r\n    for (int j = 0; j < path.size(); j++) {\r\n        Object input = path.get(j);\r\n        Arc a = graph.getArcBySourceAndInput(source, input);\r\n        if (a != null) {\r\n            a.output = new Double(((Double) a.output).doubleValue() + count);\r\n        } else {\r\n            Object target;\r\n            if (input.equals(TransducerGraph.EPSILON_INPUT)) {\r\n                target = \"END\";\r\n            } else if (markovOrder == 0) {\r\n                target = source;\r\n            } else if (markovOrder > 0) {\r\n                target = path.subList((j < markovOrder ? 0 : j - markovOrder + 1), j + 1);\r\n            } else {\r\n                target = path.subList(0, j + 1);\r\n            }\r\n            Double output = new Double(count);\r\n            a = new Arc(source, target, input, output);\r\n            graph.addArc(a);\r\n        }\r\n        source = a.getTargetNode();\r\n    }\r\n    graph.setEndNode(source);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.FactorTable.conditionalLogProbsGivenPrevious",
	"Comment": "computes the probabilities of the tag at the end of the table given thatthe previous tag sequence in table is given. given is at the beginning,position in question is at the end",
	"Method": "double[] conditionalLogProbsGivenPrevious(int[] given){\r\n    if (given.length != windowSize - 1) {\r\n        throw new IllegalArgumentException(\"conditionalLogProbsGivenPrevious requires given one less than clique size (\" + windowSize + \") but was \" + Arrays.toString(given));\r\n    }\r\n    double[] result = new double[numClasses];\r\n    for (int i = 0; i < numClasses; i++) {\r\n        int index = indexOf(given, i);\r\n        result[i] = table[index];\r\n    }\r\n    ArrayMath.logNormalize(result);\r\n    return result;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.patternAndContextMatches",
	"Comment": "decides if the pattern and context match the input starting at a position. it is a match if thelcontext matches input up to i, pattern matches at i andrcontext matches from the end of the match of pattern to the end of input.",
	"Method": "boolean patternAndContextMatches(CharSequence input,int i){\r\n    if (i < 0) {\r\n        throw new IndexOutOfBoundsException(\"Can not match pattern at negative indexes\");\r\n    }\r\n    final int patternLength = this.pattern.length();\r\n    final int ipl = i + patternLength;\r\n    if (ipl > input.length()) {\r\n        return false;\r\n    }\r\n    if (!input.subSequence(i, ipl).equals(this.pattern)) {\r\n        return false;\r\n    } else if (!this.rContext.isMatch(input.subSequence(ipl, input.length()))) {\r\n        return false;\r\n    }\r\n    return this.lContext.isMatch(input.subSequence(0, i));\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassReader.readFrameType",
	"Comment": "reads a stack map frame type and stores it at the given index in thegiven array.",
	"Method": "int readFrameType(Object[] frame,int index,int v,char[] buf,Label[] labels){\r\n    int type = b[v++] & 0xFF;\r\n    switch(type) {\r\n        case 0:\r\n            frame[index] = Opcodes.TOP;\r\n            break;\r\n        case 1:\r\n            frame[index] = Opcodes.INTEGER;\r\n            break;\r\n        case 2:\r\n            frame[index] = Opcodes.FLOAT;\r\n            break;\r\n        case 3:\r\n            frame[index] = Opcodes.DOUBLE;\r\n            break;\r\n        case 4:\r\n            frame[index] = Opcodes.LONG;\r\n            break;\r\n        case 5:\r\n            frame[index] = Opcodes.NULL;\r\n            break;\r\n        case 6:\r\n            frame[index] = Opcodes.UNINITIALIZED_THIS;\r\n            break;\r\n        case 7:\r\n            frame[index] = readClass(v, buf);\r\n            v += 2;\r\n            break;\r\n        default:\r\n            frame[index] = readLabel(readUnsignedShort(v), labels);\r\n            v += 2;\r\n    }\r\n    return v;\r\n}"
}, {
	"Path": "jsr166.JSR166TestCase.main",
	"Comment": "runs all jsr166 unit tests using junit.textui.testrunner.optional command line arg provides the number of iterations torepeat running the tests.",
	"Method": "void main(String[] args){\r\n    if (useSecurityManager) {\r\n        System.err.println(\"Setting a permissive security manager\");\r\n        Policy.setPolicy(permissivePolicy());\r\n        System.setSecurityManager(new SecurityManager());\r\n    }\r\n    int iters = (args.length == 0) ? 1 : Integer.parseInt(args[0]);\r\n    Test s = suite();\r\n    for (int i = 0; i < iters; ++i) {\r\n        junit.textui.TestRunner.run(s);\r\n        System.gc();\r\n        System.runFinalization();\r\n    }\r\n    System.exit(0);\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.hybrid.HybridCorefSystem.makeCorefOutput",
	"Comment": "extract final coreference output from coreference document format.",
	"Method": "Map<Integer, CorefChain> makeCorefOutput(Document document){\r\n    Map<Integer, CorefChain> result = Generics.newHashMap();\r\n    for (CorefCluster c : document.corefClusters.values()) {\r\n        result.put(c.clusterID, new CorefChain(c, document.positions));\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.MatchRatingApproachEncoder.removeDoubleConsonants",
	"Comment": "replaces any double consonant pair with the single letter equivalent.api usageconsider this method private, it is package protected for unit testing only.",
	"Method": "String removeDoubleConsonants(String name){\r\n    String replacedName = name.toUpperCase();\r\n    for (final String dc : DOUBLE_CONSONANT) {\r\n        if (replacedName.contains(dc)) {\r\n            final String singleLetter = dc.substring(0, 1);\r\n            replacedName = replacedName.replace(dc, singleLetter);\r\n        }\r\n    }\r\n    return replacedName;\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.getCommonSuperClass",
	"Comment": "returns the common super type of the two given types. the defaultimplementation of this method loads the two given classes and usesthe java.lang.class methods to find the common super class. it can beoverridden to compute this common super type in other ways, in particularwithout actually loading any class, or to take into account the classthat is currently being generated by this classwriter, which can ofcourse not be loaded since it is under construction.",
	"Method": "String getCommonSuperClass(String type1,String type2){\r\n    Class<?> c, d;\r\n    ClassLoader classLoader = getClass().getClassLoader();\r\n    try {\r\n        c = Class.forName(type1.replace('/', '.'), false, classLoader);\r\n        d = Class.forName(type2.replace('/', '.'), false, classLoader);\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e.toString());\r\n    }\r\n    if (c.isAssignableFrom(d)) {\r\n        return type1;\r\n    }\r\n    if (d.isAssignableFrom(c)) {\r\n        return type2;\r\n    }\r\n    if (c.isInterface() || d.isInterface()) {\r\n        return \"java/lang/Object\";\r\n    } else {\r\n        do {\r\n            c = c.getSuperclass();\r\n        } while (!c.isAssignableFrom(d));\r\n        return c.getName().replace('.', '/');\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.FirstFitLocalCombiningAllocator.canMapRegs",
	"Comment": "checks to see if a list of ssa registers can all be mapped intothe same rop reg. ignores registers that have already been mapped,and checks the interference graph and ensures the range does notcross the parameter range.",
	"Method": "boolean canMapRegs(ArrayList<RegisterSpec> specs,int ropReg){\r\n    for (RegisterSpec spec : specs) {\r\n        if (ssaRegsMapped.get(spec.getReg()))\r\n            continue;\r\n        if (!canMapReg(spec, ropReg))\r\n            return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.api.BuckTargetPattern.asPackageMatchingPattern",
	"Comment": "returns a pattern like this pattern, but matching all targets in the given package.",
	"Method": "BuckTargetPattern asPackageMatchingPattern(){\r\n    return new BuckTargetPattern(cellName, cellPath, \":\");\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMapTest.testGet",
	"Comment": "get returns the correct element at the given key,or null if not present",
	"Method": "void testGet(){\r\n    ConcurrentMap map = map5();\r\n    assertEquals(\"A\", (String) map.get(one));\r\n    ConcurrentMap empty = map();\r\n    assertNull(map.get(\"anything\"));\r\n    assertNull(empty.get(\"anything\"));\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.data.Mention.isListMemberOf",
	"Comment": "check list member? true if this mention is inside the other mention and the other mention is a list",
	"Method": "boolean isListMemberOf(Mention m){\r\n    if (this.equals(m))\r\n        return false;\r\n    if (m.mentionType == MentionType.LIST && this.mentionType == MentionType.LIST)\r\n        return false;\r\n    if (m.mentionType == MentionType.LIST) {\r\n        return this.includedIn(m);\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.apereo.cas.adaptors.x509.authentication.revocation.checker.ResourceCRLRevocationChecker.init",
	"Comment": "initializes the process that periodically fetches crl data.",
	"Method": "void init(){\r\n    if (!validateConfiguration()) {\r\n        return;\r\n    }\r\n    val results = this.fetcher.fetch(getResources());\r\n    ResourceCRLRevocationChecker.this.addCrls(results);\r\n    final Runnable scheduledFetcher = () -> {\r\n        try {\r\n            val fetchedResults = getFetcher().fetch(getResources());\r\n            ResourceCRLRevocationChecker.this.addCrls(fetchedResults);\r\n        } catch (final Exception e) {\r\n            LOGGER.debug(e.getMessage(), e);\r\n        }\r\n    };\r\n    this.scheduler.scheduleAtFixedRate(scheduledFetcher, this.refreshInterval, this.refreshInterval, TimeUnit.SECONDS);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.scoreOf",
	"Comment": "returns of the score of the datum for the specified label. ignores the true label of the datum.",
	"Method": "double scoreOf(Datum<L, F> example,L label,double scoreOf,int[] feats,L label){\r\n    int iLabel = labelIndex.indexOf(label);\r\n    assert iLabel >= 0;\r\n    double score = 0.0;\r\n    for (int feat : feats) {\r\n        score += weight(feat, iLabel);\r\n    }\r\n    return score + thresholds[iLabel];\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifierFactory.trainClassifierV",
	"Comment": "train a classifier with a sigma tuned on a validation set.in this case we are fitting on the last 30% of the training data.",
	"Method": "LinearClassifier<L, F> trainClassifierV(GeneralDataset<L, F> train,GeneralDataset<L, F> validation,double min,double max,boolean accuracy,LinearClassifier<L, F> trainClassifierV,GeneralDataset<L, F> train,double min,double max,boolean accuracy){\r\n    labelIndex = train.labelIndex();\r\n    featureIndex = train.featureIndex();\r\n    tuneSigmaHeldOut = true;\r\n    this.min = min;\r\n    this.max = max;\r\n    heldOutSetSigma(train);\r\n    double[][] weights = trainWeights(train);\r\n    return new LinearClassifier(weights, train.featureIndex(), train.labelIndex());\r\n}"
}, {
	"Path": "com.facebook.buck.tools.consistency.RuleKeyStressRunner.verifyNoChanges",
	"Comment": "verifies that there are no changes between several rulekeys files",
	"Method": "void verifyNoChanges(Path firstOutputFile,List<Path> outputFiles){\r\n    RuleKeyFileParser parser = new RuleKeyFileParser(new RuleKeyLogFileReader());\r\n    ImmutableSet<String> immutableTargets = ImmutableSet.copyOf(targets);\r\n    ParsedRuleKeyFile originalFile = parser.parseFile(firstOutputFile.toAbsolutePath(), immutableTargets);\r\n    for (Path file : outputFiles) {\r\n        ParsedRuleKeyFile newRuleKeyFile = parser.parseFile(file, immutableTargets);\r\n        RuleKeyDiffer ruleKeyDiffer = null;\r\n        try {\r\n            ruleKeyDiffer = differFactory.call();\r\n        } catch (Exception e) {\r\n            throw new RuleKeyStressRunException(String.format(\"Error creating differ: %s\", e.getMessage()), e);\r\n        }\r\n        if (ruleKeyDiffer.printDiff(originalFile, newRuleKeyFile) == DiffResult.CHANGES_FOUND) {\r\n            throw new RuleKeyStressRunException(String.format(\"Found differences between %s and %s\", originalFile.filename, newRuleKeyFile.filename));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.documentsToDataAndLabelsList",
	"Comment": "convert an objectbank to corresponding collection of data features andlabels. this version is used at test time.",
	"Method": "List<Triple<int[][][], int[], double[][][]>> documentsToDataAndLabelsList(Collection<List<IN>> documents){\r\n    int numDatums = 0;\r\n    List<Triple<int[][][], int[], double[][][]>> docList = new ArrayList();\r\n    for (List<IN> doc : documents) {\r\n        Triple<int[][][], int[], double[][][]> docTriple = documentToDataAndLabels(doc);\r\n        docList.add(docTriple);\r\n        numDatums += doc.size();\r\n    }\r\n    log.info(\"numClasses: \" + classIndex.size() + ' ' + classIndex);\r\n    log.info(\"numDocuments: \" + docList.size());\r\n    log.info(\"numDatums: \" + numDatums);\r\n    log.info(\"numFeatures: \" + featureIndex.size());\r\n    return docList;\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getOpcode",
	"Comment": "returns a jvm instruction opcode adapted to this java type. this methodmust not be used for method types.",
	"Method": "int getOpcode(int opcode){\r\n    if (opcode == Opcodes.IALOAD || opcode == Opcodes.IASTORE) {\r\n        return opcode + (buf == null ? (off & 0xFF00) >> 8 : 4);\r\n    } else {\r\n        return opcode + (buf == null ? (off & 0xFF0000) >> 16 : 4);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.handler.support.AbstractPreAndPostProcessingAuthenticationHandler.createHandlerResult",
	"Comment": "helper method to construct a handler resulton successful authentication events.",
	"Method": "AuthenticationHandlerExecutionResult createHandlerResult(Credential credential,Principal principal,List<MessageDescriptor> warnings,AuthenticationHandlerExecutionResult createHandlerResult,Credential credential,Principal principal){\r\n    return new DefaultAuthenticationHandlerExecutionResult(this, new BasicCredentialMetaData(credential), principal, new ArrayList(0));\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.box",
	"Comment": "generates the instructions to box the top stack value. this value isreplaced by its boxed equivalent on top of the stack.",
	"Method": "void box(Type type){\r\n    if (type.getSort() == Type.OBJECT || type.getSort() == Type.ARRAY) {\r\n        return;\r\n    }\r\n    if (type == Type.VOID_TYPE) {\r\n        push((String) null);\r\n    } else {\r\n        Type boxed = getBoxedType(type);\r\n        newInstance(boxed);\r\n        if (type.getSize() == 2) {\r\n            dupX2();\r\n            dupX2();\r\n            pop();\r\n        } else {\r\n            dupX1();\r\n            swap();\r\n        }\r\n        invokeConstructor(boxed, new Method(\"<init>\", Type.VOID_TYPE, new Type[] { type }));\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.services.AbstractRegisteredServiceAttributeReleasePolicy.returnFinalAttributesCollection",
	"Comment": "return the final attributes collection.subclasses may override this minute to impose last minute rules.",
	"Method": "Map<String, Object> returnFinalAttributesCollection(Map<String, Object> attributesToRelease,RegisteredService service){\r\n    LOGGER.debug(\"Final collection of attributes allowed are: [{}]\", attributesToRelease);\r\n    return attributesToRelease;\r\n}"
}, {
	"Path": "org.objectweb.asm.Frame.init",
	"Comment": "replaces the given type with the appropriate type if it is one of thetypes on which a constructor is invoked in the basic block.",
	"Method": "void init(int var,int init,ClassWriter cw,int t){\r\n    int s;\r\n    if (t == UNINITIALIZED_THIS) {\r\n        s = OBJECT | cw.addType(cw.thisName);\r\n    } else if ((t & (DIM | BASE_KIND)) == UNINITIALIZED) {\r\n        String type = cw.typeTable[t & BASE_VALUE].strVal1;\r\n        s = OBJECT | cw.addType(type);\r\n    } else {\r\n        return t;\r\n    }\r\n    for (int j = 0; j < initializationCount; ++j) {\r\n        int u = initializations[j];\r\n        int dim = u & DIM;\r\n        int kind = u & KIND;\r\n        if (kind == LOCAL) {\r\n            u = dim + inputLocals[u & VALUE];\r\n        } else if (kind == STACK) {\r\n            u = dim + inputStack[inputStack.length - (u & VALUE)];\r\n        }\r\n        if (t == u) {\r\n            return s;\r\n        }\r\n    }\r\n    return t;\r\n}"
}, {
	"Path": "org.apereo.cas.util.LdapUtils.createConnection",
	"Comment": "gets connection from the factory.opens the connection if needed.",
	"Method": "Connection createConnection(ConnectionFactory connectionFactory){\r\n    val c = connectionFactory.getConnection();\r\n    if (!c.isOpen()) {\r\n        c.open();\r\n    }\r\n    return c;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.CacheProvider.expirationPolicy",
	"Comment": "returns the fixed expiration policy for the given parameter.",
	"Method": "Policy.Expiration<Integer, Integer> expirationPolicy(Parameter parameter,Cache<Integer, Integer> cache){\r\n    if (parameter.isAnnotationPresent(ExpireAfterAccess.class)) {\r\n        return cache.policy().expireAfterAccess().get();\r\n    } else if (parameter.isAnnotationPresent(ExpireAfterWrite.class)) {\r\n        return cache.policy().expireAfterWrite().get();\r\n    } else if (parameter.isAnnotationPresent(RefreshAfterWrite.class)) {\r\n        return cache.policy().refreshAfterWrite().get();\r\n    }\r\n    throw new AssertionError(\"Expiration parameter must have a qualifier annotation\");\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RopMethod.labelToPredecessors",
	"Comment": "gets the predecessors associated with the given block. this throwsan exception if there is no block with the given label.",
	"Method": "IntList labelToPredecessors(int label){\r\n    if (exitPredecessors == null) {\r\n        calcPredecessors();\r\n    }\r\n    IntList result = predecessors[label];\r\n    if (result == null) {\r\n        throw new RuntimeException(\"no such block: \" + Hex.u2(label));\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.util.CompressionUtils.decompress",
	"Comment": "first decode base64 string to byte array, then use zipinputstream to revert the byte array to astring.",
	"Method": "String decompress(String zippedBase64Str){\r\n    val bytes = EncodingUtils.decodeBase64(zippedBase64Str);\r\n    try (val zi = new GZIPInputStream(new ByteArrayInputStream(bytes))) {\r\n        return IOUtils.toString(zi, Charset.defaultCharset());\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.util.spring.boot.AbstractCasBanner.collectEnvironmentInfo",
	"Comment": "collect environment info withdetails on the java and os deploymentversions.",
	"Method": "String collectEnvironmentInfo(Environment environment,Class<?> sourceClass){\r\n    val properties = System.getProperties();\r\n    if (properties.containsKey(\"CAS_BANNER_SKIP\")) {\r\n        try (val formatter = new Formatter()) {\r\n            formatter.format(\"CAS Version: %s%n\", CasVersion.getVersion());\r\n            return formatter.toString();\r\n        }\r\n    }\r\n    try (val formatter = new Formatter()) {\r\n        val sysInfo = SystemUtils.getSystemInfo();\r\n        sysInfo.forEach((k, v) -> {\r\n            if (k.startsWith(SEPARATOR_CHAR)) {\r\n                formatter.format(\"%s%n\", LINE_SEPARATOR);\r\n            } else {\r\n                formatter.format(\"%s: %s%n\", k, v);\r\n            }\r\n        });\r\n        formatter.format(\"%s%n\", LINE_SEPARATOR);\r\n        injectEnvironmentInfoIntoBanner(formatter, environment, sourceClass);\r\n        return formatter.toString();\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.prettify",
	"Comment": "prepare a string for printing in a spreadsheet for mechanical turk input.",
	"Method": "String prettify(String s){\r\n    if (s == null)\r\n        return \"\";\r\n    return s.replace(\" ,\", \",\").replace(\" .\", \".\").replace(\" :\", \":\").replace(\"( \", \"(\").replace(\"[ \", \"[\").replace(\" )\", \")\").replace(\" ]\", \"]\").replace(\" - \", \"-\").replace(\" '\", \"'\").replace(\"-LRB- \", \"(\").replace(\" -RRB-\", \")\").replace(\"` ` \", \"\\\"\").replace(\" ' '\", \"\\\"\").replace(\" COMMA\", \",\");\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.ParserAnnotatorITest.testThreadedTimeout",
	"Comment": "tests that if you run a threaded parser annotator on input text,all sentences get successfully converted into x trees after theytime out.incidentally, this sort of tests that the threadedparser annotator adds output in the right order.",
	"Method": "void testThreadedTimeout(){\r\n    for (int i = 0; i < 20; ++i) {\r\n        Annotation document = new Annotation(TEXT + TEXT);\r\n        threaded3TimeoutPipeline.annotate(document);\r\n        verifyAnswers(document, XPARSES);\r\n        document = new Annotation(TEXT + TEXT + TEXT + TEXT + TEXT);\r\n        threaded4TimeoutPipeline.annotate(document);\r\n        verifyAnswers(document, XPARSES);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.EntityMention.getValue",
	"Comment": "get the text value of this entity.the headtokenspan must be set before calling this method!",
	"Method": "String getValue(){\r\n    List<CoreLabel> tokens = sentence.get(CoreAnnotations.TokensAnnotation.class);\r\n    StringBuilder sb = new StringBuilder();\r\n    for (int i = headTokenSpan.start(); i < headTokenSpan.end(); i++) {\r\n        CoreLabel token = tokens.get(i);\r\n        if (i > headTokenSpan.start())\r\n            sb.append(\" \");\r\n        sb.append(token.word());\r\n    }\r\n    return sb.toString();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.LocalAsyncLoadingCache.canBulkLoad",
	"Comment": "returns whether the supplied cache loader has bulk load functionality.",
	"Method": "boolean canBulkLoad(AsyncCacheLoader<?, ?> loader){\r\n    try {\r\n        Class<?> defaultLoaderClass = AsyncCacheLoader.class;\r\n        if (loader instanceof CacheLoader<?, ?>) {\r\n            defaultLoaderClass = CacheLoader.class;\r\n            Method classLoadAll = loader.getClass().getMethod(\"loadAll\", Iterable.class);\r\n            Method defaultLoadAll = CacheLoader.class.getMethod(\"loadAll\", Iterable.class);\r\n            if (!classLoadAll.equals(defaultLoadAll)) {\r\n                return true;\r\n            }\r\n        }\r\n        Method classAsyncLoadAll = loader.getClass().getMethod(\"asyncLoadAll\", Iterable.class, Executor.class);\r\n        Method defaultAsyncLoadAll = defaultLoaderClass.getMethod(\"asyncLoadAll\", Iterable.class, Executor.class);\r\n        return !classAsyncLoadAll.equals(defaultAsyncLoadAll);\r\n    } catch (NoSuchMethodException | SecurityException e) {\r\n        logger.log(Level.WARNING, \"Cannot determine if CacheLoader can bulk load\", e);\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpecList.withExpandedRegisters",
	"Comment": "returns an instance that is identical to this one, except thatall incompatible register numbers are renumbered sequentially fromthe given base, with the first number duplicated if indicated. ifa null bitset is given, it indicates all registers are incompatible.",
	"Method": "RegisterSpecList withExpandedRegisters(int base,boolean duplicateFirst,BitSet compatRegs){\r\n    int sz = size();\r\n    if (sz == 0) {\r\n        return this;\r\n    }\r\n    Expander expander = new Expander(this, compatRegs, base, duplicateFirst);\r\n    for (int regIdx = 0; regIdx < sz; regIdx++) {\r\n        expander.expandRegister(regIdx);\r\n    }\r\n    return expander.getResult();\r\n}"
}, {
	"Path": "org.apereo.cas.config.HazelcastSessionConfiguration.hazelcastInstance",
	"Comment": "hazelcast instance that is used by the spring sessionrepository to broadcast session events. the nameof this bean must be left untouched.",
	"Method": "HazelcastInstance hazelcastInstance(){\r\n    val hzConfigResource = casProperties.getWebflow().getSession().getHzLocation();\r\n    val configUrl = hzConfigResource.getURL();\r\n    val config = new XmlConfigBuilder(hzConfigResource.getInputStream()).build();\r\n    config.setConfigurationUrl(configUrl);\r\n    config.setInstanceName(this.getClass().getSimpleName()).setProperty(\"hazelcast.logging.type\", \"slf4j\").setProperty(\"hazelcast.max.no.heartbeat.seconds\", \"300\");\r\n    return Hazelcast.newHazelcastInstance(config);\r\n}"
}, {
	"Path": "com.android.dx.rop.code.LocalVariableInfo.getStarts",
	"Comment": "gets the register set associated with the start of the blockwith the given label. this returns an empty set with the appropriatemax size if no set was associated with the block in question.",
	"Method": "RegisterSpecSet getStarts(int label,RegisterSpecSet getStarts,BasicBlock block){\r\n    return getStarts(block.getLabel());\r\n}"
}, {
	"Path": "org.apache.commons.codec.digest.DigestUtils.digest",
	"Comment": "read through an inputstream and returns the digest for the data",
	"Method": "byte[] digest(MessageDigest messageDigest,ByteBuffer data,byte[] digest,MessageDigest digest,InputStream data){\r\n    return updateDigest(digest, data).digest();\r\n}"
}, {
	"Path": "org.apache.commons.codec.digest.DigestUtils.md5Hex",
	"Comment": "calculates the md5 digest and returns the value as a 32 character hex string.",
	"Method": "String md5Hex(byte[] data,String md5Hex,ByteBuffer data,String md5Hex,InputStream data,String md5Hex,String data){\r\n    return Hex.encodeHexString(md5(data));\r\n}"
}, {
	"Path": "org.apereo.cas.services.PrincipalAttributeRegisteredServiceUsernameProvider.getPrincipalAttributesFromReleasePolicy",
	"Comment": "gets principal attributes. will attempt to locate the principalattribute repository from the context if one is defined to usethat instance to locate attributes. if none is available,will use the default principal attributes.",
	"Method": "Map<String, Object> getPrincipalAttributesFromReleasePolicy(Principal p,Service service,RegisteredService registeredService){\r\n    if (registeredService != null && registeredService.getAccessStrategy().isServiceAccessAllowed()) {\r\n        LOGGER.debug(\"Located service [{}] in the registry. Attempting to resolve attributes for [{}]\", registeredService, p.getId());\r\n        if (registeredService.getAttributeReleasePolicy() == null) {\r\n            LOGGER.debug(\"No attribute release policy is defined for [{}]. Returning default principal attributes\", service.getId());\r\n            return p.getAttributes();\r\n        }\r\n        return registeredService.getAttributeReleasePolicy().getAttributes(p, service, registeredService);\r\n    }\r\n    LOGGER.debug(\"Could not locate service [{}] in the registry.\", service.getId());\r\n    throw new UnauthorizedServiceException(UnauthorizedServiceException.CODE_UNAUTHZ_SERVICE);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.fastpath",
	"Comment": "returns if an access to an entry can skip notifying the eviction policy.",
	"Method": "boolean fastpath(){\r\n    return false;\r\n}"
}, {
	"Path": "org.objectweb.asm.Frame.initInputFrame",
	"Comment": "initializes the input frame of the first basic block from the methoddescriptor.",
	"Method": "void initInputFrame(ClassWriter cw,int access,Type[] args,int maxLocals){\r\n    inputLocals = new int[maxLocals];\r\n    inputStack = new int[0];\r\n    int i = 0;\r\n    if ((access & Opcodes.ACC_STATIC) == 0) {\r\n        if ((access & MethodWriter.ACC_CONSTRUCTOR) == 0) {\r\n            inputLocals[i++] = OBJECT | cw.addType(cw.thisName);\r\n        } else {\r\n            inputLocals[i++] = UNINITIALIZED_THIS;\r\n        }\r\n    }\r\n    for (int j = 0; j < args.length; ++j) {\r\n        int t = type(cw, args[j].getDescriptor());\r\n        inputLocals[i++] = t;\r\n        if (t == LONG || t == DOUBLE) {\r\n            inputLocals[i++] = TOP;\r\n        }\r\n    }\r\n    while (i < maxLocals) {\r\n        inputLocals[i++] = TOP;\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.InsnList.toArray",
	"Comment": "returns an array containing all of the instructions in this list.",
	"Method": "AbstractInsnNode[] toArray(){\r\n    int i = 0;\r\n    AbstractInsnNode elem = first;\r\n    AbstractInsnNode[] insns = new AbstractInsnNode[size];\r\n    while (elem != null) {\r\n        insns[i] = elem;\r\n        elem.index = i++;\r\n        elem = elem.next;\r\n    }\r\n    return insns;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.configuration.TypesafeConfigurator.defaults",
	"Comment": "retrieves the default cache settings from the configuration resource.",
	"Method": "CaffeineConfiguration<K, V> defaults(Config config){\r\n    return new Configurator<K, V>(config, \"default\").configure();\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.JSRInlinerAdapter.emitCode",
	"Comment": "creates the new instructions, inlining each instantiation of eachsubroutine until the code is fully elaborated.",
	"Method": "void emitCode(){\r\n    LinkedList<Instantiation> worklist = new LinkedList<Instantiation>();\r\n    worklist.add(new Instantiation(null, mainSubroutine));\r\n    InsnList newInstructions = new InsnList();\r\n    List<TryCatchBlockNode> newTryCatchBlocks = new ArrayList<TryCatchBlockNode>();\r\n    List<LocalVariableNode> newLocalVariables = new ArrayList<LocalVariableNode>();\r\n    while (!worklist.isEmpty()) {\r\n        Instantiation inst = worklist.removeFirst();\r\n        emitSubroutine(inst, worklist, newInstructions, newTryCatchBlocks, newLocalVariables);\r\n    }\r\n    instructions = newInstructions;\r\n    tryCatchBlocks = newTryCatchBlocks;\r\n    localVariables = newLocalVariables;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent",
	"Comment": "returns the current value from a computeifabsent invocation.",
	"Method": "V doComputeIfAbsent(K key,Object keyRef,Function<? super K, ? extends V> mappingFunction,long[] now){\r\n    @SuppressWarnings(\"unchecked\")\r\n    V[] oldValue = (V[]) new Object[1];\r\n    @SuppressWarnings(\"unchecked\")\r\n    V[] newValue = (V[]) new Object[1];\r\n    @SuppressWarnings(\"unchecked\")\r\n    K[] nodeKey = (K[]) new Object[1];\r\n    @SuppressWarnings({ \"unchecked\", \"rawtypes\" })\r\n    Node<K, V>[] removed = new Node[1];\r\n    int[] weight = new int[2];\r\n    RemovalCause[] cause = new RemovalCause[1];\r\n    Node<K, V> node = data.compute(keyRef, (k, n) -> {\r\n        if (n == null) {\r\n            newValue[0] = mappingFunction.apply(key);\r\n            if (newValue[0] == null) {\r\n                return null;\r\n            }\r\n            now[0] = expirationTicker().read();\r\n            weight[1] = weigher.weigh(key, newValue[0]);\r\n            n = nodeFactory.newNode(key, keyReferenceQueue(), newValue[0], valueReferenceQueue(), weight[1], now[0]);\r\n            setVariableTime(n, expireAfterCreate(key, newValue[0], expiry(), now[0]));\r\n            return n;\r\n        }\r\n        synchronized (n) {\r\n            nodeKey[0] = n.getKey();\r\n            weight[0] = n.getWeight();\r\n            oldValue[0] = n.getValue();\r\n            if ((nodeKey[0] == null) || (oldValue[0] == null)) {\r\n                cause[0] = RemovalCause.COLLECTED;\r\n            } else if (hasExpired(n, now[0])) {\r\n                cause[0] = RemovalCause.EXPIRED;\r\n            } else {\r\n                return n;\r\n            }\r\n            writer.delete(nodeKey[0], oldValue[0], cause[0]);\r\n            newValue[0] = mappingFunction.apply(key);\r\n            if (newValue[0] == null) {\r\n                removed[0] = n;\r\n                n.retire();\r\n                return null;\r\n            }\r\n            weight[1] = weigher.weigh(key, newValue[0]);\r\n            n.setValue(newValue[0], valueReferenceQueue());\r\n            n.setWeight(weight[1]);\r\n            now[0] = expirationTicker().read();\r\n            setVariableTime(n, expireAfterCreate(key, newValue[0], expiry(), now[0]));\r\n            setAccessTime(n, now[0]);\r\n            setWriteTime(n, now[0]);\r\n            return n;\r\n        }\r\n    });\r\n    if (node == null) {\r\n        if (removed[0] != null) {\r\n            afterWrite(new RemovalTask(removed[0]));\r\n        }\r\n        return null;\r\n    }\r\n    if (cause[0] != null) {\r\n        if (hasRemovalListener()) {\r\n            notifyRemoval(nodeKey[0], oldValue[0], cause[0]);\r\n        }\r\n        statsCounter().recordEviction(weight[0]);\r\n    }\r\n    if (newValue[0] == null) {\r\n        if (!isComputingAsync(node)) {\r\n            setVariableTime(node, expireAfterRead(node, key, oldValue[0], expiry(), now[0]));\r\n            setAccessTime(node, now[0]);\r\n        }\r\n        afterRead(node, now[0], true);\r\n        return oldValue[0];\r\n    }\r\n    if ((oldValue[0] == null) && (cause[0] == null)) {\r\n        afterWrite(new AddTask(node, weight[1]));\r\n    } else {\r\n        int weightedDifference = (weight[1] - weight[0]);\r\n        afterWrite(new UpdateTask(node, weightedDifference));\r\n    }\r\n    return newValue[0];\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaBasicBlock.isReachable",
	"Comment": "returns true if this block was last calculated to be reachable.recalculates reachability if value has never been computed.",
	"Method": "boolean isReachable(){\r\n    if (reachable == -1) {\r\n        parent.computeReachability();\r\n    }\r\n    return (reachable == 1);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.admission.countmin4.CountMin4.ensureCapacity",
	"Comment": "increases the capacity of this frequencysketch instance, if necessary, to ensure thatit can accurately estimate the popularity of elements given the maximum size of the cache. thisoperation forgets all previous counts when resizing.",
	"Method": "void ensureCapacity(long maximumSize){\r\n    checkArgument(maximumSize >= 0);\r\n    int maximum = (int) Math.min(maximumSize, Integer.MAX_VALUE >>> 1);\r\n    if ((table != null) && (table.length >= maximum)) {\r\n        return;\r\n    }\r\n    table = new long[(maximum == 0) ? 1 : ceilingNextPowerOfTwo(maximum)];\r\n    tableMask = Math.max(0, table.length - 1);\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.Mention.attributesAgree",
	"Comment": "detects if the mention and candidate antecedent agree on all attributes respectively.",
	"Method": "boolean attributesAgree(Mention potentialAntecedent,Dictionaries dict){\r\n    return (this.animaciesAgree(potentialAntecedent) && this.entityTypesAgree(potentialAntecedent, dict) && this.gendersAgree(potentialAntecedent) && this.numbersAgree(potentialAntecedent));\r\n}"
}, {
	"Path": "org.objectweb.asm.signature.SignatureVisitor.visitInterfaceBound",
	"Comment": "visits an interface bound of the last visited formal type parameter.",
	"Method": "SignatureVisitor visitInterfaceBound(){\r\n    return this;\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.newMethodItem",
	"Comment": "adds a method reference to the constant pool of the class being build.does nothing if the constant pool already contains a similar item.",
	"Method": "Item newMethodItem(String owner,String name,String desc,boolean itf){\r\n    int type = itf ? IMETH : METH;\r\n    key3.set(type, owner, name, desc);\r\n    Item result = get(key3);\r\n    if (result == null) {\r\n        put122(type, newClass(owner), newNameType(name, desc));\r\n        result = new Item(index++, key3);\r\n        put(result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.getMoveForInsn",
	"Comment": "finds the corresponding move result for a given instruction",
	"Method": "SsaInsn getMoveForInsn(SsaInsn insn){\r\n    int succ = insn.getBlock().getSuccessors().nextSetBit(0);\r\n    ArrayList<SsaInsn> succInsns = ssaMeth.getBlocks().get(succ).getInsns();\r\n    return succInsns.get(0);\r\n}"
}, {
	"Path": "org.objectweb.asm.ByteVector.putShort",
	"Comment": "puts a short into this byte vector. the byte vector is automaticallyenlarged if necessary.",
	"Method": "ByteVector putShort(int s){\r\n    int length = this.length;\r\n    if (length + 2 > data.length) {\r\n        enlarge(2);\r\n    }\r\n    byte[] data = this.data;\r\n    data[length++] = (byte) (s >>> 8);\r\n    data[length++] = (byte) s;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "org.objectweb.asm.Attribute.put",
	"Comment": "writes all the attributes of this attribute list in the given bytevector.",
	"Method": "void put(ClassWriter cw,byte[] code,int len,int maxStack,int maxLocals,ByteVector out){\r\n    Attribute attr = this;\r\n    while (attr != null) {\r\n        ByteVector b = attr.write(cw, code, len, maxStack, maxLocals);\r\n        out.putShort(cw.newUTF8(attr.type)).putInt(b.length);\r\n        out.putByteArray(b.data, 0, b.length);\r\n        attr = attr.next;\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.AbstractSequenceClassifier.printPRLine",
	"Comment": "print a line of precision, recall, and f1 scores, titled by entity.",
	"Method": "Triple<Double, Double, Double> printPRLine(String entity,double tp,double fp,double fn){\r\n    double precision = (tp == 0.0 && fp == 0.0) ? 0.0 : tp / (tp + fp);\r\n    double recall = (tp == 0.0 && fn == 0.0) ? 1.0 : tp / (tp + fn);\r\n    double f1 = ((precision == 0.0 || recall == 0.0) ? 0.0 : 2.0 / (1.0 / precision + 1.0 / recall));\r\n    log.info(String.format(\"s\\t%.4f\\t%.4f\\t%.4f\\t%.0f\\t%.0f\\t%.0f%n\", entity, precision, recall, f1, tp, fp, fn));\r\n    return new Triple(precision * 100, recall * 100, f1 * 100);\r\n}"
}, {
	"Path": "com.android.dx.util.BitIntSet.ensureCapacity",
	"Comment": "ensures that the bit set has the capacity to represent the given value.",
	"Method": "void ensureCapacity(int value){\r\n    if (value >= Bits.getMax(bits)) {\r\n        int[] newBits = Bits.makeBitSet(Math.max(value + 1, 2 * Bits.getMax(bits)));\r\n        System.arraycopy(bits, 0, newBits, 0, bits.length);\r\n        bits = newBits;\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.support.wsfederation.WsFederationConfiguration.getSigningCredential",
	"Comment": "getsigningcredential loads up an x509credential from a file.",
	"Method": "Credential getSigningCredential(Resource resource){\r\n    try (val inputStream = resource.getInputStream()) {\r\n        val certificateFactory = CertificateFactory.getInstance(\"X.509\");\r\n        val certificate = (X509Certificate) certificateFactory.generateCertificate(inputStream);\r\n        val publicCredential = new BasicX509Credential(certificate);\r\n        LOGGER.debug(\"Signing credential key retrieved from [{}].\", resource);\r\n        return publicCredential;\r\n    } catch (final Exception ex) {\r\n        LOGGER.error(ex.getMessage(), ex);\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.getCliqueTrees",
	"Comment": "want to make arbitrary probability queries? then this is the method foryou. given the filename, it reads it in and breaks it into documents, andthen makes a crfcliquetree for each document. you can then ask the cliquetree for marginals and conditional probabilities of almost anything you want.",
	"Method": "List<CRFCliqueTree<String>> getCliqueTrees(String filename,DocumentReaderAndWriter<IN> readerAndWriter){\r\n    List<CRFCliqueTree<String>> cts = new ArrayList();\r\n    ObjectBank<List<IN>> docs = makeObjectBankFromFile(filename, readerAndWriter);\r\n    for (List<IN> doc : docs) {\r\n        cts.add(getCliqueTree(doc));\r\n    }\r\n    return cts;\r\n}"
}, {
	"Path": "org.objectweb.asm.TypeReference.getValue",
	"Comment": "returns the int encoded value of this type reference, suitable for use invisit methods related to type annotations, like visittypeannotation.",
	"Method": "int getValue(){\r\n    return value;\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.newLong",
	"Comment": "adds a long to the constant pool of the class being build. does nothingif the constant pool already contains a similar item.",
	"Method": "Item newLong(long value){\r\n    key.set(value);\r\n    Item result = get(key);\r\n    if (result == null) {\r\n        pool.putByte(LONG).putLong(value);\r\n        result = new Item(index, key);\r\n        index += 2;\r\n        put(result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.digest.util.DigestAuthenticationUtils.createAuthenticateHeader",
	"Comment": "create authenticate header, containing the realm, nonce, opaque, etc.",
	"Method": "String createAuthenticateHeader(String realm,String authMethod,String nonce){\r\n    val stringBuilder = new StringBuilder(\"Digest realm=\\\"\").append(realm).append(\"\\\",\");\r\n    if (StringUtils.isNotBlank(authMethod)) {\r\n        stringBuilder.append(\"qop=\").append(authMethod).append(',');\r\n    }\r\n    return stringBuilder.append(\"nonce=\\\"\").append(nonce).append(\"\\\",opaque=\\\"\").append(createOpaque(realm, nonce)).append('\"').toString();\r\n}"
}, {
	"Path": "org.apache.commons.cli.Option.hasArgName",
	"Comment": "returns whether the display name for the argument value has been set.",
	"Method": "boolean hasArgName(){\r\n    return argName != null && argName.length() > 0;\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.AbstractInsnNode.getPrevious",
	"Comment": "returns the previous instruction in the list to which this instructionbelongs, if any.",
	"Method": "AbstractInsnNode getPrevious(){\r\n    return prev;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.DefaultAuthenticationBuilder.setCredentials",
	"Comment": "sets the list of metadata about credentials presented for authentication.",
	"Method": "AuthenticationBuilder setCredentials(List<CredentialMetaData> credentials){\r\n    this.credentials.clear();\r\n    this.credentials.addAll(credentials);\r\n    return this;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.MachineReading.loadOrMakeSerializedSentences",
	"Comment": "gets the serialized sentences for a data set. if the serialized sentencesare already on disk, it loads them from there. otherwise, the data set isread with the corpus reader and the serialized sentences are saved to disk.",
	"Method": "Annotation loadOrMakeSerializedSentences(String sentencesPath,GenericDataSetReader reader,File serializedSentences){\r\n    Annotation corpusSentences;\r\n    if (MachineReadingProperties.serializeCorpora && serializedSentences.exists() && !forceParseSentences) {\r\n        MachineReadingProperties.logger.info(\"Loaded serialized sentences from \" + serializedSentences.getAbsolutePath() + \"...\");\r\n        corpusSentences = IOUtils.readObjectFromFile(serializedSentences);\r\n        MachineReadingProperties.logger.info(\"Done. Loaded \" + corpusSentences.get(CoreAnnotations.SentencesAnnotation.class).size() + \" sentences.\");\r\n    } else {\r\n        MachineReadingProperties.logger.info(\"Parsing corpus sentences...\");\r\n        if (MachineReadingProperties.serializeCorpora)\r\n            MachineReadingProperties.logger.info(\"These sentences will be serialized to \" + serializedSentences.getAbsolutePath());\r\n        corpusSentences = reader.parse(sentencesPath);\r\n        MachineReadingProperties.logger.info(\"Done. Parsed \" + AnnotationUtils.sentenceCount(corpusSentences) + \" sentences.\");\r\n        if (MachineReadingProperties.serializeCorpora) {\r\n            MachineReadingProperties.logger.info(\"Serializing parsed sentences to \" + serializedSentences.getAbsolutePath() + \"...\");\r\n            IOUtils.writeObjectToFile(corpusSentences, serializedSentences);\r\n            MachineReadingProperties.logger.info(\"Done. Serialized \" + AnnotationUtils.sentenceCount(corpusSentences) + \" sentences.\");\r\n        }\r\n    }\r\n    return corpusSentences;\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.StringUtils.newString",
	"Comment": "constructs a new string by decoding the specified array of bytes using the given charset.",
	"Method": "String newString(byte[] bytes,Charset charset,String newString,byte[] bytes,String charsetName){\r\n    if (bytes == null) {\r\n        return null;\r\n    }\r\n    try {\r\n        return new String(bytes, charsetName);\r\n    } catch (final UnsupportedEncodingException e) {\r\n        throw StringUtils.newIllegalStateException(charsetName, e);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.CacheContext.original",
	"Comment": "the initial entries in the cache, iterable in insertion order.",
	"Method": "Map<Integer, Integer> original(){\r\n    initialSize();\r\n    return original;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.RVFDataset.applyFeatureMaxCountThreshold",
	"Comment": "applies a feature max count threshold to the rvfdataset. all features thatoccur greater than k times are expunged.",
	"Method": "void applyFeatureMaxCountThreshold(int k){\r\n    float[] counts = getFeatureCounts();\r\n    HashIndex<F> newFeatureIndex = new HashIndex();\r\n    int[] featMap = new int[featureIndex.size()];\r\n    for (int i = 0; i < featMap.length; i++) {\r\n        F feat = featureIndex.get(i);\r\n        if (counts[i] <= k) {\r\n            int newIndex = newFeatureIndex.size();\r\n            newFeatureIndex.add(feat);\r\n            featMap[i] = newIndex;\r\n        } else {\r\n            featMap[i] = -1;\r\n        }\r\n    }\r\n    featureIndex = newFeatureIndex;\r\n    for (int i = 0; i < size; i++) {\r\n        List<Integer> featList = new ArrayList(data[i].length);\r\n        List<Double> valueList = new ArrayList(values[i].length);\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            if (featMap[data[i][j]] >= 0) {\r\n                featList.add(featMap[data[i][j]]);\r\n                valueList.add(values[i][j]);\r\n            }\r\n        }\r\n        data[i] = new int[featList.size()];\r\n        values[i] = new double[valueList.size()];\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            data[i][j] = featList.get(j);\r\n            values[i][j] = valueList.get(j);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.support.openid.authentication.principal.OpenIdServiceResponseBuilder.build",
	"Comment": "generates an openid response.if no ticketid is found, response is negative.if we have a ticket id, then we check if we have an association.if so, we ask openid server manager to generate the answer according with the existing association.if not, we send back an answer with the ticket id as association handle.this will force the consumer to ask a verification, which will validate the service ticket.",
	"Method": "Response build(WebApplicationService webApplicationService,String ticketId,Authentication authentication){\r\n    val service = (OpenIdService) webApplicationService;\r\n    val parameterList = new ParameterList(HttpRequestUtils.getHttpServletRequestFromRequestAttributes().getParameterMap());\r\n    val parameters = new HashMap<String, String>();\r\n    if (StringUtils.isBlank(ticketId)) {\r\n        parameters.put(OpenIdProtocolConstants.OPENID_MODE, OpenIdProtocolConstants.CANCEL);\r\n        return buildRedirect(service, parameters);\r\n    }\r\n    val association = getAssociation(serverManager, parameterList);\r\n    val associated = association != null;\r\n    val associationValid = isAssociationValid(association);\r\n    var successFullAuthentication = true;\r\n    var assertion = (Assertion) null;\r\n    try {\r\n        if (associated && associationValid) {\r\n            assertion = centralAuthenticationService.validateServiceTicket(ticketId, service);\r\n            LOGGER.debug(\"Validated openid ticket [{}] for [{}]\", ticketId, service);\r\n        } else if (!associated) {\r\n            LOGGER.debug(\"Responding to non-associated mode. Service ticket [{}] must be validated by the RP\", ticketId);\r\n        } else {\r\n            LOGGER.warn(\"Association does not exist or is not valid\");\r\n            successFullAuthentication = false;\r\n        }\r\n    } catch (final AbstractTicketException e) {\r\n        LOGGER.error(\"Could not validate ticket : [{}]\", e.getMessage(), e);\r\n        successFullAuthentication = false;\r\n    }\r\n    val id = determineIdentity(service, assertion);\r\n    return buildAuthenticationResponse(service, parameters, successFullAuthentication, id, parameterList);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.ner.CMMClassifier.loglikelihood",
	"Comment": "returns the log conditional likelihood of the given dataset.",
	"Method": "double loglikelihood(List<IN> lineInfos){\r\n    double cll = 0.0;\r\n    for (int i = 0; i < lineInfos.size(); i++) {\r\n        Datum<String, String> d = makeDatum(lineInfos, i, featureFactories);\r\n        Counter<String> c = classifier.logProbabilityOf(d);\r\n        double total = Double.NEGATIVE_INFINITY;\r\n        for (String s : c.keySet()) {\r\n            total = SloppyMath.logAdd(total, c.getCount(s));\r\n        }\r\n        cll -= c.getCount(d.label()) - total;\r\n    }\r\n    if (classifier instanceof LinearClassifier) {\r\n        double sigmaSq = flags.sigma * flags.sigma;\r\n        LinearClassifier<String, String> lc = (LinearClassifier<String, String>) classifier;\r\n        for (String feature : lc.features()) {\r\n            for (String classLabel : classIndex) {\r\n                double w = lc.weight(feature, classLabel);\r\n                cll += w * w / 2.0 / sigmaSq;\r\n            }\r\n        }\r\n    }\r\n    return cll;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.Dataset.selectFeatures",
	"Comment": "generic method to select features based on the feature scores vector provided as an argument.",
	"Method": "void selectFeatures(int numFeatures,double[] scores){\r\n    List<ScoredObject<F>> scoredFeatures = new ArrayList();\r\n    for (int i = 0; i < scores.length; i++) {\r\n        scoredFeatures.add(new ScoredObject(featureIndex.get(i), scores[i]));\r\n    }\r\n    Collections.sort(scoredFeatures, ScoredComparator.DESCENDING_COMPARATOR);\r\n    Index<F> newFeatureIndex = new HashIndex();\r\n    for (int i = 0; i < scoredFeatures.size() && i < numFeatures; i++) {\r\n        newFeatureIndex.add(scoredFeatures.get(i).object());\r\n    }\r\n    for (int i = 0; i < size; i++) {\r\n        int[] newData = new int[data[i].length];\r\n        int curIndex = 0;\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            int index;\r\n            if ((index = newFeatureIndex.indexOf(featureIndex.get(data[i][j]))) != -1) {\r\n                newData[curIndex++] = index;\r\n            }\r\n        }\r\n        int[] newDataTrimmed = new int[curIndex];\r\n        synchronized (System.class) {\r\n            System.arraycopy(newData, 0, newDataTrimmed, 0, curIndex);\r\n        }\r\n        data[i] = newDataTrimmed;\r\n    }\r\n    featureIndex = newFeatureIndex;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.StripedBuffer.getProbe",
	"Comment": "returns the probe value for the current thread. duplicated from threadlocalrandom because ofpackaging restrictions.",
	"Method": "int getProbe(){\r\n    return UnsafeAccess.UNSAFE.getInt(Thread.currentThread(), PROBE);\r\n}"
}, {
	"Path": "org.apereo.cas.web.AbstractServiceValidateController.generateSuccessView",
	"Comment": "generate the success view. the result will contain the assertion and the proxy iou.",
	"Method": "ModelAndView generateSuccessView(Assertion assertion,String proxyIou,WebApplicationService service,HttpServletRequest request,Optional<MultifactorAuthenticationProvider> contextProvider,TicketGrantingTicket proxyGrantingTicket){\r\n    val modelAndView = getModelAndView(request, true, service);\r\n    modelAndView.addObject(CasViewConstants.MODEL_ATTRIBUTE_NAME_ASSERTION, assertion);\r\n    modelAndView.addObject(CasViewConstants.MODEL_ATTRIBUTE_NAME_SERVICE, service);\r\n    if (StringUtils.isNotBlank(proxyIou)) {\r\n        modelAndView.addObject(CasViewConstants.MODEL_ATTRIBUTE_NAME_PROXY_GRANTING_TICKET_IOU, proxyIou);\r\n    }\r\n    if (proxyGrantingTicket != null) {\r\n        modelAndView.addObject(CasViewConstants.MODEL_ATTRIBUTE_NAME_PROXY_GRANTING_TICKET, proxyGrantingTicket.getId());\r\n    }\r\n    contextProvider.ifPresent(provider -> modelAndView.addObject(this.authnContextAttribute, provider.getId()));\r\n    val augmentedModelObjects = augmentSuccessViewModelObjects(assertion);\r\n    if (augmentedModelObjects != null) {\r\n        modelAndView.addAllObjects(augmentedModelObjects);\r\n    }\r\n    return modelAndView;\r\n}"
}, {
	"Path": "edu.stanford.nlp.graph.DirectedMultiGraph.isEmpty",
	"Comment": "false if there are any vertices in the graph, true otherwise. does not careabout the number of edges.",
	"Method": "boolean isEmpty(){\r\n    return outgoingEdges.isEmpty();\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.Soundex.encode",
	"Comment": "encodes an object using the soundex algorithm. this method is provided in order to satisfy the requirements ofthe encoder interface, and will throw an encoderexception if the supplied object is not of type java.lang.string.",
	"Method": "Object encode(Object obj,String encode,String str){\r\n    return soundex(str);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.AbstractLinkedDeque.linkLast",
	"Comment": "links the element to the back of the deque so that it becomes the last element.",
	"Method": "void linkLast(E e){\r\n    final E l = last;\r\n    last = e;\r\n    if (l == null) {\r\n        first = e;\r\n    } else {\r\n        setNext(l, e);\r\n        setPrevious(e, l);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.grouper.GrouperFacade.getGrouperGroupAttribute",
	"Comment": "construct grouper group attribute.this is the name of every individual group attributetransformed into a cas attribute value.",
	"Method": "String getGrouperGroupAttribute(GrouperGroupField groupField,WsGroup group){\r\n    switch(groupField) {\r\n        case DISPLAY_EXTENSION:\r\n            return group.getDisplayExtension();\r\n        case DISPLAY_NAME:\r\n            return group.getDisplayName();\r\n        case EXTENSION:\r\n            return group.getExtension();\r\n        case NAME:\r\n        default:\r\n            return group.getName();\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.toDistributionString",
	"Comment": "similar to histogram but exact values of the weightsto see whether there are many equal weights.",
	"Method": "String toDistributionString(int threshold){\r\n    Counter<Double> weightCounts = new ClassicCounter();\r\n    StringBuilder s = new StringBuilder();\r\n    s.append(\"Total number of weights: \").append(totalSize());\r\n    for (double[] weightArray : weights) {\r\n        for (double weight : weightArray) {\r\n            weightCounts.incrementCount(weight);\r\n        }\r\n    }\r\n    s.append(\"Counts of weights\\n\");\r\n    Set<Double> keys = Counters.keysAbove(weightCounts, threshold);\r\n    s.append(keys.size()).append(\" keys occur more than \").append(threshold).append(\" times \");\r\n    return s.toString();\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.FactorTable.unnormalizedConditionalLogProbGivenFirst",
	"Comment": "computes the probability of the sequence of being at the end of the tablegiven that the first tag in table is given. given is at the beginning, of isat the end.",
	"Method": "double unnormalizedConditionalLogProbGivenFirst(int given,int[] of){\r\n    if (of.length != windowSize - 1) {\r\n        throw new IllegalArgumentException(\"unnormalizedConditionalLogProbGivenFirst requires of one less than clique size (\" + windowSize + \") but was \" + Arrays.toString(of));\r\n    }\r\n    int[] labels = new int[windowSize];\r\n    labels[0] = given;\r\n    System.arraycopy(of, 0, labels, 1, windowSize - 1);\r\n    double probAll = unnormalizedLogProb(labels);\r\n    return probAll;\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.hybrid.sieve.Sieve.sortMentionsByClause",
	"Comment": "divides a sentence into clauses and sort the antecedents for pronoun matching",
	"Method": "List<Mention> sortMentionsByClause(List<Mention> l,Mention m1){\r\n    List<Mention> sorted = new ArrayList();\r\n    Tree tree = m1.contextParseTree;\r\n    Tree current = m1.mentionSubTree;\r\n    if (tree == null || current == null)\r\n        return l;\r\n    while (true) {\r\n        current = current.ancestor(1, tree);\r\n        String curLabel = current.label().value();\r\n        if (\"TOP\".equals(curLabel) || curLabel.startsWith(\"S\") || curLabel.equals(\"NP\")) {\r\n            for (Mention m : l) {\r\n                if (!sorted.contains(m) && current.dominates(m.mentionSubTree))\r\n                    sorted.add(m);\r\n            }\r\n        }\r\n        if (current.ancestor(1, tree) == null)\r\n            break;\r\n    }\r\n    return sorted;\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.md.DependencyCorefMentionFinder.findMentions",
	"Comment": "main method of mention detection. extract all np, prp or ne, and filter out by manually written patterns.",
	"Method": "List<List<Mention>> findMentions(Annotation doc,Dictionaries dict,Properties props){\r\n    List<List<Mention>> predictedMentions = new ArrayList();\r\n    Set<String> neStrings = Generics.newHashSet();\r\n    List<Set<IntPair>> mentionSpanSetList = Generics.newArrayList();\r\n    List<CoreMap> sentences = doc.get(CoreAnnotations.SentencesAnnotation.class);\r\n    for (CoreMap s : sentences) {\r\n        List<Mention> mentions = new ArrayList();\r\n        predictedMentions.add(mentions);\r\n        Set<IntPair> mentionSpanSet = Generics.newHashSet();\r\n        Set<IntPair> namedEntitySpanSet = Generics.newHashSet();\r\n        extractPremarkedEntityMentions(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        HybridCorefMentionFinder.extractNamedEntityMentions(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        extractNPorPRPFromDependency(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        addNamedEntityStrings(s, neStrings, namedEntitySpanSet);\r\n        mentionSpanSetList.add(mentionSpanSet);\r\n    }\r\n    for (int i = 0; i < sentences.size(); i++) {\r\n        findHead(sentences.get(i), predictedMentions.get(i));\r\n    }\r\n    removeSpuriousMentions(doc, predictedMentions, dict, CorefProperties.removeNestedMentions(props), lang);\r\n    if (!CorefProperties.isMentionDetectionTraining(props)) {\r\n        mdClassifier.classifyMentions(predictedMentions, dict, props);\r\n    }\r\n    return predictedMentions;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionForLOP.calculate",
	"Comment": "calculates both value and partial derivatives at the point x, and save them internally.",
	"Method": "void calculate(double[] x){\r\n    double prob = 0.0;\r\n    double[][][] E = empty2D();\r\n    double[] eScales = new double[numLopExpert];\r\n    double[] rawScales = separateLopScales(x);\r\n    double[] scales = ArrayMath.softmax(rawScales);\r\n    double[][][] learnedLopExpertWeights2D = lopExpertWeights2D;\r\n    if (backpropTraining) {\r\n        learnedLopExpertWeights2D = separateLopExpertWeights2D(x);\r\n        logPotential(learnedLopExpertWeights2D);\r\n    }\r\n    double[][] combinedWeights2D = combineAndScaleLopWeights2D(numLopExpert, learnedLopExpertWeights2D, scales);\r\n    for (int m = 0; m < data.length; m++) {\r\n        int[][][] docData = data[m];\r\n        int[] docLabels = labels[m];\r\n        double[][][][] sumOfELPm = sumOfExpectedLogPotential[m];\r\n        CliquePotentialFunction cliquePotentialFunc = new LinearCliquePotentialFunction(combinedWeights2D);\r\n        CRFCliqueTree<String> cliqueTree = CRFCliqueTree.getCalibratedCliqueTree(docData, labelIndices, numClasses, classIndex, backgroundSymbol, cliquePotentialFunc, null);\r\n        int[] given = new int[window - 1];\r\n        Arrays.fill(given, classIndex.indexOf(backgroundSymbol));\r\n        if (docLabels.length > docData.length) {\r\n            System.arraycopy(docLabels, 0, given, 0, given.length);\r\n            int[] newDocLabels = new int[docData.length];\r\n            System.arraycopy(docLabels, docLabels.length - newDocLabels.length, newDocLabels, 0, newDocLabels.length);\r\n            docLabels = newDocLabels;\r\n        }\r\n        for (int i = 0; i < docData.length; i++) {\r\n            int label = docLabels[i];\r\n            double p = cliqueTree.condLogProbGivenPrevious(i, label, given);\r\n            if (VERBOSE) {\r\n                log.info(\"P(\" + label + \"|\" + ArrayMath.toString(given) + \")=\" + p);\r\n            }\r\n            prob += p;\r\n            System.arraycopy(given, 1, given, 0, given.length - 1);\r\n            given[given.length - 1] = label;\r\n        }\r\n        for (int i = 0; i < docData.length; i++) {\r\n            double[][][] sumOfELPmi = sumOfELPm[i];\r\n            for (int j = 0; j < docData[i].length; j++) {\r\n                double[][] sumOfELPmij = sumOfELPmi[j];\r\n                Index<CRFLabel> labelIndex = labelIndices.get(j);\r\n                for (int l = 0; l < labelIndex.size(); l++) {\r\n                    int[] label = labelIndex.get(l).getLabel();\r\n                    double p = cliqueTree.prob(i, label);\r\n                    for (int lopIter = 0; lopIter < numLopExpert; lopIter++) {\r\n                        Set<Integer> indicesSet = featureIndicesSetArray.get(lopIter);\r\n                        double scale = scales[lopIter];\r\n                        double expected = sumOfELPmij[lopIter][l];\r\n                        for (int innerLopIter = 0; innerLopIter < numLopExpert; innerLopIter++) {\r\n                            expected -= scales[innerLopIter] * sumOfELPmij[innerLopIter][l];\r\n                        }\r\n                        expected *= scale;\r\n                        eScales[lopIter] += (p * expected);\r\n                        double[][] eOfIter = E[lopIter];\r\n                        if (backpropTraining) {\r\n                            for (int k = 0; k < docData[i][j].length; k++) {\r\n                                int featureIdx = docData[i][j][k];\r\n                                if (indicesSet.contains(featureIdx)) {\r\n                                    eOfIter[featureIdx][l] += p;\r\n                                }\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n    if (Double.isNaN(prob)) {\r\n        throw new RuntimeException(\"Got NaN for prob in CRFLogConditionalObjectiveFunctionForLOP.calculate()\");\r\n    }\r\n    value = -prob;\r\n    if (VERBOSE) {\r\n        log.info(\"value is \" + value);\r\n    }\r\n    for (int lopIter = 0; lopIter < numLopExpert; lopIter++) {\r\n        double scale = scales[lopIter];\r\n        double observed = sumOfObservedLogPotential[lopIter];\r\n        for (int j = 0; j < numLopExpert; j++) {\r\n            observed -= scales[j] * sumOfObservedLogPotential[j];\r\n        }\r\n        observed *= scale;\r\n        double expected = eScales[lopIter];\r\n        derivative[lopIter] = (expected - observed);\r\n        if (VERBOSE) {\r\n            log.info(\"deriv(\" + lopIter + \") = \" + expected + \" - \" + observed + \" = \" + derivative[lopIter]);\r\n        }\r\n    }\r\n    if (backpropTraining) {\r\n        int dIndex = numLopExpert;\r\n        for (int lopIter = 0; lopIter < numLopExpert; lopIter++) {\r\n            double scale = scales[lopIter];\r\n            double[][] eOfExpert = E[lopIter];\r\n            double[][] ehatOfExpert = Ehat[lopIter];\r\n            List<Integer> featureIndicesList = featureIndicesListArray.get(lopIter);\r\n            for (int fIndex : featureIndicesList) {\r\n                for (int j = 0; j < eOfExpert[fIndex].length; j++) {\r\n                    derivative[dIndex++] = scale * (eOfExpert[fIndex][j] - ehatOfExpert[fIndex][j]);\r\n                    if (VERBOSE) {\r\n                        log.info(\"deriv[\" + lopIter + \"](\" + fIndex + \",\" + j + \") = \" + scale + \" * (\" + eOfExpert[fIndex][j] + \" - \" + ehatOfExpert[fIndex][j] + \") = \" + derivative[dIndex - 1]);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        assert (dIndex == domainDimension());\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.Label.getFirst",
	"Comment": "returns the first label of the series to which this label belongs. for anisolated label or for the first label in a series of successive labels,this method returns the label itself. for other labels it returns thefirst label of the series.",
	"Method": "Label getFirst(){\r\n    return !ClassReader.FRAMES || frame == null ? this : frame.owner;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.Classifier.evaluatePrecisionAndRecall",
	"Comment": "evaluates the precision and recall of this classifier against a dataset, and the target label.",
	"Method": "Pair<Double, Double> evaluatePrecisionAndRecall(GeneralDataset<L, F> testData,L targetLabel){\r\n    if (targetLabel == null) {\r\n        throw new IllegalArgumentException(\"Must supply a target label to compute precision and recall against\");\r\n    }\r\n    int numCorrectAndTarget = 0;\r\n    int numTargetGuess = 0;\r\n    int numTargetGold = 0;\r\n    for (RVFDatum<L, F> datum : testData) {\r\n        L label = datum.label();\r\n        if (label == null) {\r\n            throw new IllegalArgumentException(\"Cannot compute precision and recall on unlabelled dataset. Offending datum: \" + datum);\r\n        }\r\n        L guess = classOf(datum);\r\n        if (label.equals(targetLabel)) {\r\n            numTargetGold += 1;\r\n        }\r\n        if (guess.equals(targetLabel)) {\r\n            numTargetGuess += 1;\r\n            if (guess.equals(label)) {\r\n                numCorrectAndTarget += 1;\r\n            }\r\n        }\r\n    }\r\n    double precision = numTargetGuess == 0 ? 0.0 : ((double) numCorrectAndTarget) / ((double) numTargetGuess);\r\n    double recall = numTargetGold == 0 ? 1.0 : ((double) numCorrectAndTarget) / ((double) numTargetGold);\r\n    return Pair.makePair(precision, recall);\r\n}"
}, {
	"Path": "org.apereo.cas.web.support.WebUtils.getHttpServletRequestGeoLocationFromRequestContext",
	"Comment": "gets http servlet request geo location from request context.",
	"Method": "GeoLocationRequest getHttpServletRequestGeoLocationFromRequestContext(GeoLocationRequest getHttpServletRequestGeoLocationFromRequestContext,RequestContext context){\r\n    val servletRequest = getHttpServletRequestFromExternalWebflowContext(context);\r\n    return getHttpServletRequestGeoLocation(servletRequest);\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaMethod.onInsnsChanged",
	"Comment": "indicates that the instruction list has changed or the ssa registercount has increased, so that internal datastructures that rely onit should be rebuild. in general, the various other on methodsshould be called in preference when changes occur if they areapplicable.",
	"Method": "void onInsnsChanged(){\r\n    definitionList = null;\r\n    useList = null;\r\n    unmodifiableUseList = null;\r\n}"
}, {
	"Path": "org.apereo.cas.util.HttpRequestUtils.getService",
	"Comment": "gets the service from the request based on given extractors.",
	"Method": "WebApplicationService getService(List<ArgumentExtractor> argumentExtractors,HttpServletRequest request){\r\n    return argumentExtractors.stream().map(argumentExtractor -> argumentExtractor.extractService(request)).filter(Objects::nonNull).findFirst().orElse(null);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.sentenceEntityMentionsToCoreLabels",
	"Comment": "converts the labels of all entity mentions in this sentence to sequences of corelabels",
	"Method": "List<CoreLabel> sentenceEntityMentionsToCoreLabels(CoreMap sentence,boolean addAnswerAnnotation,Set<String> annotationsToSkip,Set<String> mentionTypesToUse,boolean useSubTypes,boolean useBIO){\r\n    List<CoreLabel> labels = new ArrayList();\r\n    for (CoreLabel l : sentence.get(CoreAnnotations.TokensAnnotation.class)) {\r\n        CoreLabel nl = new CoreLabel(l);\r\n        if (addAnswerAnnotation) {\r\n            nl.set(CoreAnnotations.AnswerAnnotation.class, SeqClassifierFlags.DEFAULT_BACKGROUND_SYMBOL);\r\n        }\r\n        labels.add(nl);\r\n    }\r\n    if (addAnswerAnnotation) {\r\n        List<EntityMention> entities = sentence.get(MachineReadingAnnotations.EntityMentionsAnnotation.class);\r\n        if (entities != null) {\r\n            for (EntityMention entity : entities) {\r\n                if (annotationsToSkip != null && annotationsToSkip.contains(entity.getType()))\r\n                    continue;\r\n                if (mentionTypesToUse != null && !mentionTypesToUse.contains(entity.getMentionType()))\r\n                    continue;\r\n                if (entity.getHead() != null) {\r\n                    for (int i = entity.getHeadTokenStart(); i < entity.getHeadTokenEnd(); i++) {\r\n                        String tag = entity.getType();\r\n                        if (useSubTypes && entity.getSubType() != null)\r\n                            tag += \"-\" + entity.getSubType();\r\n                        if (useBIO) {\r\n                            if (i == entity.getHeadTokenStart())\r\n                                tag = \"B-\" + tag;\r\n                            else\r\n                                tag = \"I-\" + tag;\r\n                        }\r\n                        labels.get(i).set(CoreAnnotations.AnswerAnnotation.class, tag);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return labels;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.EntityCachingAbstractSequencePriorBIO.otherOccurrences",
	"Comment": "finds other locations in the sequence where the sequence ofwords in this entity occurs.",
	"Method": "int[] otherOccurrences(EntityBIO entity){\r\n    List<Integer> other = new ArrayList();\r\n    for (int i = 0; i < wordDoc.size(); i++) {\r\n        if (i == entity.startPosition) {\r\n            continue;\r\n        }\r\n        if (matches(entity, i)) {\r\n            other.add(Integer.valueOf(i));\r\n        }\r\n    }\r\n    return toArray(other);\r\n}"
}, {
	"Path": "org.apereo.cas.util.MockWebServer.start",
	"Comment": "starts the web server so it can accept requests on the listening port.",
	"Method": "void start(){\r\n    this.workerThread = new Thread(this.worker, \"MockWebServer.Worker\");\r\n    this.workerThread.start();\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.DefaultMultifactorAuthenticationProviderBypass.locateMatchingHttpRequest",
	"Comment": "locate matching http request and determine if bypass should be enabled.",
	"Method": "boolean locateMatchingHttpRequest(Authentication authentication,HttpServletRequest request){\r\n    if (StringUtils.isNotBlank(bypassProperties.getHttpRequestRemoteAddress())) {\r\n        if (httpRequestRemoteAddressPattern.matcher(request.getRemoteAddr()).find()) {\r\n            LOGGER.debug(\"Http request remote address [{}] matches [{}]\", bypassProperties.getHttpRequestRemoteAddress(), request.getRemoteAddr());\r\n            return true;\r\n        }\r\n        if (httpRequestRemoteAddressPattern.matcher(request.getRemoteHost()).find()) {\r\n            LOGGER.debug(\"Http request remote host [{}] matches [{}]\", bypassProperties.getHttpRequestRemoteAddress(), request.getRemoteHost());\r\n            return true;\r\n        }\r\n    }\r\n    if (StringUtils.isNotBlank(bypassProperties.getHttpRequestHeaders())) {\r\n        val headerNames = Collections.list(request.getHeaderNames());\r\n        val matched = this.httpRequestHeaderPatterns.stream().anyMatch(pattern -> headerNames.stream().anyMatch(name -> pattern.matcher(name).matches()));\r\n        if (matched) {\r\n            LOGGER.debug(\"Http request remote headers [{}] match [{}]\", headerNames, bypassProperties.getHttpRequestHeaders());\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.apereo.cas.util.cipher.AbstractCipherExecutor.configureSigningKey",
	"Comment": "sets signing key. if the key provided is resolved as a private key,then will create use the private key as is, and will sign valuesusing rsa. otherwise, aes is used.",
	"Method": "void configureSigningKey(String signingSecretKey){\r\n    try {\r\n        if (ResourceUtils.doesResourceExist(signingSecretKey)) {\r\n            configureSigningKeyFromPrivateKeyResource(signingSecretKey);\r\n        }\r\n    } catch (final Exception e) {\r\n        LOGGER.error(e.getMessage(), e);\r\n    } finally {\r\n        if (this.signingKey == null) {\r\n            setSigningKey(new AesKey(signingSecretKey.getBytes(StandardCharsets.UTF_8)));\r\n            LOGGER.trace(\"Created signing key instance [{}] based on provided secret key\", this.signingKey.getClass().getSimpleName());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.sentiment.SentimentTrainingITest.testRegularizationGradientCheck",
	"Comment": "because the regularizations are typically set to be 0.001 of thetotal cost, it is important to test those gradients with the regvalues turned up a lot.",
	"Method": "void testRegularizationGradientCheck(){\r\n    List<Tree> trainingTrees = SentimentUtils.readTreesWithGoldLabels(TRAIN_PATH);\r\n    RNNOptions op = new RNNOptions();\r\n    op.numHid = 5;\r\n    op.trainOptions.regTransformMatrix = 10.0;\r\n    op.trainOptions.regTransformTensor = 10.0;\r\n    op.trainOptions.regClassification = 10.0;\r\n    op.trainOptions.regWordVector = 10.0;\r\n    SentimentModel model = new SentimentModel(op, trainingTrees);\r\n    Assert.assertTrue(\"Gradient check failed with random seed of \" + op.randomSeed, SentimentTraining.runGradientCheck(model, trainingTrees));\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.MultifactorAuthenticationProvider.createUniqueId",
	"Comment": "creates a unique mark that identifies this provider instance.",
	"Method": "String createUniqueId(){\r\n    return getId().concat(String.valueOf(hashCode()));\r\n}"
}, {
	"Path": "org.apereo.cas.util.CollectionUtils.firstElement",
	"Comment": "converts the provided object into a collectionand return the first element, or empty.",
	"Method": "Optional<Object> firstElement(Object obj){\r\n    val object = CollectionUtils.toCollection(obj);\r\n    if (object.isEmpty()) {\r\n        return Optional.empty();\r\n    }\r\n    return Optional.of(object.iterator().next());\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.GenerateServiceTicketAction.newEvent",
	"Comment": "new event based on the id, which contains an error attribute referring to the exception occurred.",
	"Method": "Event newEvent(String id,Exception error){\r\n    return new EventFactorySupport().event(this, id, new LocalAttributeMap(\"error\", error));\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.BeiderMorseEncoder.setRuleType",
	"Comment": "sets the rule type to apply. this will widen or narrow the range of phonetic encodings considered.",
	"Method": "void setRuleType(RuleType ruleType){\r\n    this.engine = new PhoneticEngine(this.engine.getNameType(), ruleType, this.engine.isConcat(), this.engine.getMaxPhonemes());\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFCliqueTree.scoreOf",
	"Comment": "returns the log probability of this sequence given the crf. does so bycomputing the marginal of the first windowsize tags, and then computing theconditional probability for the rest of them, conditioned on the previoustags.",
	"Method": "double scoreOf(int[] sequence,int pos,double scoreOf,int[] sequence){\r\n    int[] given = new int[window() - 1];\r\n    Arrays.fill(given, classIndex.indexOf(backgroundSymbol));\r\n    double logProb = 0.0;\r\n    for (int i = 0, length = length(); i < length; i++) {\r\n        int label = sequence[i];\r\n        logProb += condLogProbGivenPrevious(i, label, given);\r\n        System.arraycopy(given, 1, given, 0, given.length - 1);\r\n        given[given.length - 1] = label;\r\n    }\r\n    return logProb;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.scheduleDrainBuffers",
	"Comment": "attempts to schedule an asynchronous task to apply the pending operations to the pagereplacement policy. if the executor rejects the task then it is run directly.",
	"Method": "void scheduleDrainBuffers(){\r\n    if (drainStatus() >= PROCESSING_TO_IDLE) {\r\n        return;\r\n    }\r\n    if (evictionLock.tryLock()) {\r\n        try {\r\n            int drainStatus = drainStatus();\r\n            if (drainStatus >= PROCESSING_TO_IDLE) {\r\n                return;\r\n            }\r\n            lazySetDrainStatus(PROCESSING_TO_IDLE);\r\n            executor().execute(drainBuffersTask);\r\n        } catch (Throwable t) {\r\n            logger.log(Level.WARNING, \"Exception thrown when submitting maintenance task\", t);\r\n            maintenance(null);\r\n        } finally {\r\n            evictionLock.unlock();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.digest.HmacUtils.getHmacSha512",
	"Comment": "returns an initialized mac for the hmacsha512 algorithm.every implementation of the java platform is not required to support this mac algorithm.",
	"Method": "Mac getHmacSha512(byte[] key){\r\n    return getInitializedMac(HmacAlgorithms.HMAC_SHA_512, key);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.RVFDataset.shuffleWithSideInformation",
	"Comment": "randomizes the data array in place. needs to be redefined here because weneed to randomize the values as well.",
	"Method": "void shuffleWithSideInformation(long randomSeed,List<E> sideInformation){\r\n    if (size != sideInformation.size()) {\r\n        throw new IllegalArgumentException(\"shuffleWithSideInformation: sideInformation not of same size as Dataset\");\r\n    }\r\n    Random rand = new Random(randomSeed);\r\n    for (int j = size - 1; j > 0; j--) {\r\n        int randIndex = rand.nextInt(j);\r\n        int[] tmp = data[randIndex];\r\n        data[randIndex] = data[j];\r\n        data[j] = tmp;\r\n        int tmpl = labels[randIndex];\r\n        labels[randIndex] = labels[j];\r\n        labels[j] = tmpl;\r\n        double[] tmpv = values[randIndex];\r\n        values[randIndex] = values[j];\r\n        values[j] = tmpv;\r\n        E tmpE = sideInformation.get(randIndex);\r\n        sideInformation.set(randIndex, sideInformation.get(j));\r\n        sideInformation.set(j, tmpE);\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.Attribute.getSize",
	"Comment": "returns the size of all the attributes in this attribute list.",
	"Method": "int getSize(ClassWriter cw,byte[] code,int len,int maxStack,int maxLocals){\r\n    Attribute attr = this;\r\n    int size = 0;\r\n    while (attr != null) {\r\n        cw.newUTF8(attr.type);\r\n        size += attr.write(cw, code, len, maxStack, maxLocals).length + 6;\r\n        attr = attr.next;\r\n    }\r\n    return size;\r\n}"
}, {
	"Path": "org.apereo.cas.services.DefaultRegisteredServiceAccessStrategy.requiredAttributesFoundInMap",
	"Comment": "check whether required attributes are found in the given map.",
	"Method": "boolean requiredAttributesFoundInMap(Map<String, Object> principalAttributes,Map<String, Set<String>> requiredAttributes){\r\n    val difference = requiredAttributes.keySet().stream().filter(a -> principalAttributes.keySet().contains(a)).collect(Collectors.toSet());\r\n    if (this.requireAllAttributes && difference.size() < requiredAttributes.size()) {\r\n        return false;\r\n    }\r\n    return difference.stream().anyMatch(key -> {\r\n        val values = requiredAttributes.get(key);\r\n        val availableValues = CollectionUtils.toCollection(principalAttributes.get(key));\r\n        val pattern = RegexUtils.concatenate(values, this.caseInsensitive);\r\n        if (pattern != RegexUtils.MATCH_NOTHING_PATTERN) {\r\n            return availableValues.stream().map(Object::toString).anyMatch(pattern.asPredicate());\r\n        }\r\n        return availableValues.stream().anyMatch(values::contains);\r\n    });\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.Caverphone.encode",
	"Comment": "encodes an object using the caverphone algorithm. this method is provided in order to satisfy the requirements ofthe encoder interface, and will throw an encoderexception if the supplied object is not of type java.lang.string.",
	"Method": "Object encode(Object obj,String encode,String str){\r\n    return this.caverphone(str);\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.Base64.isArrayByteBase64",
	"Comment": "tests a given byte array to see if it contains only valid characters within the base64 alphabet. currently themethod treats whitespace as valid.",
	"Method": "boolean isArrayByteBase64(byte[] arrayOctet){\r\n    return isBase64(arrayOctet);\r\n}"
}, {
	"Path": "com.google.common.cache.CacheLoadingTest.testLoadingExceptionWithCause",
	"Comment": "make sure loadingcache correctly wraps executionexceptions and uncheckedexecutionexceptions.",
	"Method": "void testLoadingExceptionWithCause(){\r\n    final Exception cause = new Exception();\r\n    final UncheckedExecutionException uee = new UncheckedExecutionException(cause);\r\n    final ExecutionException ee = new ExecutionException(cause);\r\n    LoadingCache<Object, Object> cacheUnchecked = CaffeinatedGuava.build(Caffeine.newBuilder(), exceptionLoader(uee));\r\n    LoadingCache<Object, Object> cacheChecked = CaffeinatedGuava.build(Caffeine.newBuilder(), exceptionLoader(ee));\r\n    try {\r\n        cacheUnchecked.get(new Object());\r\n        fail();\r\n    } catch (UncheckedExecutionException caughtEe) {\r\n        assertSame(uee, caughtEe.getCause());\r\n    }\r\n    try {\r\n        cacheUnchecked.getUnchecked(new Object());\r\n        fail();\r\n    } catch (UncheckedExecutionException caughtUee) {\r\n        assertSame(uee, caughtUee.getCause());\r\n    }\r\n    cacheUnchecked.refresh(new Object());\r\n    checkLoggedCause(uee);\r\n    try {\r\n        cacheUnchecked.getAll(asList(new Object()));\r\n        fail();\r\n    } catch (UncheckedExecutionException caughtEe) {\r\n        assertSame(uee, caughtEe.getCause());\r\n    }\r\n    try {\r\n        cacheChecked.get(new Object());\r\n        fail();\r\n    } catch (ExecutionException caughtEe) {\r\n        assertSame(ee, caughtEe.getCause());\r\n    }\r\n    try {\r\n        cacheChecked.getUnchecked(new Object());\r\n        fail();\r\n    } catch (UncheckedExecutionException caughtUee) {\r\n        assertSame(ee, caughtUee.getCause());\r\n    }\r\n    cacheChecked.refresh(new Object());\r\n    checkLoggedCause(ee);\r\n    try {\r\n        cacheChecked.getAll(asList(new Object()));\r\n        fail();\r\n    } catch (ExecutionException caughtEe) {\r\n        assertSame(ee, caughtEe.getCause());\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.loadAuxiliaryData",
	"Comment": "load auxiliary data to be used in constructing features and labelsintended to be overridden by subclasses",
	"Method": "Collection<List<IN>> loadAuxiliaryData(Collection<List<IN>> docs,DocumentReaderAndWriter<IN> readerAndWriter){\r\n    return docs;\r\n}"
}, {
	"Path": "org.apereo.cas.support.spnego.authentication.handler.support.JcifsSpnegoAuthenticationHandler.getPrincipal",
	"Comment": "gets the principal from the given name. the principalis created by the factory instance.",
	"Method": "Principal getPrincipal(String name,boolean isNtlm){\r\n    if (this.principalWithDomainName) {\r\n        return this.principalFactory.createPrincipal(name);\r\n    }\r\n    if (isNtlm) {\r\n        if (Pattern.matches(\"\\\\S+\\\\\\\\\\\\S+\", name)) {\r\n            val splitList = Splitter.on(Pattern.compile(\"\\\\\\\\\")).splitToList(name);\r\n            if (splitList.size() == 2) {\r\n                return this.principalFactory.createPrincipal(splitList.get(1));\r\n            }\r\n        }\r\n        return this.principalFactory.createPrincipal(name);\r\n    }\r\n    val splitList = Splitter.on(\"@\").splitToList(name);\r\n    return this.principalFactory.createPrincipal(splitList.get(0));\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.FirstFitLocalCombiningAllocator.processPhiInsn",
	"Comment": "attempts to map the sources and result of a phi to a common register.will try existing mappings first, from most to least common. if noneof the registers have mappings yet, a new mapping is created.",
	"Method": "void processPhiInsn(PhiInsn insn){\r\n    RegisterSpec result = insn.getResult();\r\n    int resultReg = result.getReg();\r\n    int category = result.getCategory();\r\n    RegisterSpecList sources = insn.getSources();\r\n    int sourcesSize = sources.size();\r\n    ArrayList<RegisterSpec> ssaRegs = new ArrayList<RegisterSpec>();\r\n    Multiset mapSet = new Multiset(sourcesSize + 1);\r\n    if (ssaRegsMapped.get(resultReg)) {\r\n        mapSet.add(mapper.oldToNew(resultReg));\r\n    } else {\r\n        ssaRegs.add(result);\r\n    }\r\n    for (int i = 0; i < sourcesSize; i++) {\r\n        RegisterSpec source = sources.get(i);\r\n        SsaInsn def = ssaMeth.getDefinitionForRegister(source.getReg());\r\n        RegisterSpec sourceDef = def.getResult();\r\n        int sourceReg = sourceDef.getReg();\r\n        if (ssaRegsMapped.get(sourceReg)) {\r\n            mapSet.add(mapper.oldToNew(sourceReg));\r\n        } else {\r\n            ssaRegs.add(sourceDef);\r\n        }\r\n    }\r\n    for (int i = 0; i < mapSet.getSize(); i++) {\r\n        int maxReg = mapSet.getAndRemoveHighestCount();\r\n        tryMapRegs(ssaRegs, maxReg, category, false);\r\n    }\r\n    int mapReg = findNextUnreservedRopReg(paramRangeEnd, category);\r\n    while (!tryMapRegs(ssaRegs, mapReg, category, false)) {\r\n        mapReg = findNextUnreservedRopReg(mapReg + 1, category);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.process",
	"Comment": "performs escape analysis on a method. finds scalar replaceable arrays andreplaces them with equivalent registers.",
	"Method": "void process(SsaMethod ssaMethod){\r\n    new EscapeAnalysis(ssaMethod).run();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.stats.CacheStats.empty",
	"Comment": "returns a statistics instance where no cache events have been recorded.",
	"Method": "CacheStats empty(){\r\n    return EMPTY_STATS;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.CacheFactory.isDefinedExternally",
	"Comment": "returns a if the cache definition is found in the external settings file.",
	"Method": "boolean isDefinedExternally(String cacheName){\r\n    return TypesafeConfigurator.cacheNames(rootConfig).contains(cacheName);\r\n}"
}, {
	"Path": "com.android.dx.ssa.PhiInsn.getSources",
	"Comment": "gets sources. constructed lazily from phi operand data structures andthen cached.",
	"Method": "RegisterSpecList getSources(){\r\n    if (sources != null) {\r\n        return sources;\r\n    }\r\n    if (operands.size() == 0) {\r\n        return RegisterSpecList.EMPTY;\r\n    }\r\n    int szSources = operands.size();\r\n    sources = new RegisterSpecList(szSources);\r\n    for (int i = 0; i < szSources; i++) {\r\n        Operand o = operands.get(i);\r\n        sources.set(i, o.regSpec);\r\n    }\r\n    sources.setImmutable();\r\n    return sources;\r\n}"
}, {
	"Path": "com.facebook.buck.tools.consistency.DiffPrinter.printHeader",
	"Comment": "prints out two pieces of text to a line and potentially formats them with bolding",
	"Method": "void printHeader(String bolded,String nonBold){\r\n    outStream.print(boldColor);\r\n    outStream.print(bolded);\r\n    outStream.print(resetColors);\r\n    outStream.println(nonBold);\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.BinaryCodec.toAsciiChars",
	"Comment": "converts an array of raw binary data into an array of ascii 0 and 1 characters.",
	"Method": "char[] toAsciiChars(byte[] raw){\r\n    if (isEmpty(raw)) {\r\n        return EMPTY_CHAR_ARRAY;\r\n    }\r\n    final char[] l_ascii = new char[raw.length << 3];\r\n    for (int ii = 0, jj = l_ascii.length - 1; ii < raw.length; ii++, jj -= 8) {\r\n        for (int bits = 0; bits < BITS.length; ++bits) {\r\n            if ((raw[ii] & BITS[bits]) == 0) {\r\n                l_ascii[jj - bits] = '0';\r\n            } else {\r\n                l_ascii[jj - bits] = '1';\r\n            }\r\n        }\r\n    }\r\n    return l_ascii;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.admission.countmin4.CountMin4.conservativeIncrement",
	"Comment": "increments the associated counters that are at the observed minimum.",
	"Method": "void conservativeIncrement(long e){\r\n    int hash = spread(Long.hashCode(e));\r\n    int start = (hash & 3) << 2;\r\n    int[] index = new int[4];\r\n    int[] count = new int[4];\r\n    int min = Integer.MAX_VALUE;\r\n    for (int i = 0; i < 4; i++) {\r\n        index[i] = indexOf(hash, i);\r\n        count[i] = (int) ((table[index[i]] >>> ((start + i) << 2)) & 0xfL);\r\n        min = Math.min(min, count[i]);\r\n    }\r\n    if (min == 15) {\r\n        tryReset(false);\r\n        return;\r\n    }\r\n    for (int i = 0; i < 4; i++) {\r\n        if (count[i] == min) {\r\n            incrementAt(index[i], start + i, step);\r\n        }\r\n    }\r\n    tryReset(true);\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.newDouble",
	"Comment": "adds a double to the constant pool of the class being build. does nothingif the constant pool already contains a similar item.",
	"Method": "Item newDouble(double value){\r\n    key.set(value);\r\n    Item result = get(key);\r\n    if (result == null) {\r\n        pool.putByte(DOUBLE).putLong(key.longVal);\r\n        result = new Item(index, key);\r\n        index += 2;\r\n        put(result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "me.konloch.kontainer.io.DiskWriter.insertFileName",
	"Comment": "used to insert a difference string with preserving the file extension",
	"Method": "String insertFileName(String fileName,String difference){\r\n    String[] babe = fileName.split(\"\\\\.\");\r\n    int count = 0;\r\n    int math = babe.length;\r\n    String m = \"\";\r\n    for (String s2 : babe) {\r\n        m += s2;\r\n        if (math - 2 == count)\r\n            m += difference + \".\";\r\n        else if (math - 1 != count)\r\n            m += \".\";\r\n        count++;\r\n    }\r\n    return m;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.tinycache.WindowTinyCachePolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new WindowTinyCachePolicy(config));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.two_queue.TwoQueuePolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new TwoQueuePolicy(config));\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.Document.mergeIncompatibles",
	"Comment": "update incompatibles for two clusters that are about to be merged",
	"Method": "void mergeIncompatibles(CorefCluster to,CorefCluster from){\r\n    List<Pair<Pair<Integer, Integer>, Pair<Integer, Integer>>> replacements = new ArrayList();\r\n    for (Pair<Integer, Integer> p : incompatibleClusters) {\r\n        Integer other = null;\r\n        if (p.first == from.clusterID) {\r\n            other = p.second;\r\n        } else if (p.second == from.clusterID) {\r\n            other = p.first;\r\n        }\r\n        if (other != null && other != to.clusterID) {\r\n            int cid1 = Math.min(other, to.clusterID);\r\n            int cid2 = Math.max(other, to.clusterID);\r\n            replacements.add(Pair.makePair(p, Pair.makePair(cid1, cid2)));\r\n        }\r\n    }\r\n    for (Pair<Pair<Integer, Integer>, Pair<Integer, Integer>> r : replacements) {\r\n        incompatibleClusters.remove(r.first.first(), r.first.second());\r\n        incompatibleClusters.add(r.second.first(), r.second.second());\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.AbstractSequenceClassifier.segmentString",
	"Comment": "it also seems like it should be using the plaintextreaderandwriter, not default?",
	"Method": "List<String> segmentString(String sentence,List<String> segmentString,String sentence,DocumentReaderAndWriter<IN> readerAndWriter){\r\n    ObjectBank<List<IN>> docs = makeObjectBankFromString(sentence, readerAndWriter);\r\n    StringWriter stringWriter = new StringWriter();\r\n    PrintWriter stringPrintWriter = new PrintWriter(stringWriter);\r\n    for (List<IN> doc : docs) {\r\n        classify(doc);\r\n        readerAndWriter.printAnswers(doc, stringPrintWriter);\r\n        stringPrintWriter.println();\r\n    }\r\n    stringPrintWriter.close();\r\n    String segmented = stringWriter.toString();\r\n    return Arrays.asList(segmented.split(\"\\\\s\"));\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.RVFDataset.selectFeaturesFromSet",
	"Comment": "removes all features from the dataset that are not in featureset.",
	"Method": "void selectFeaturesFromSet(Set<F> featureSet){\r\n    HashIndex<F> newFeatureIndex = new HashIndex();\r\n    int[] featMap = new int[featureIndex.size()];\r\n    Arrays.fill(featMap, -1);\r\n    for (F feature : featureSet) {\r\n        int oldID = featureIndex.indexOf(feature);\r\n        if (oldID >= 0) {\r\n            int newID = newFeatureIndex.addToIndex(feature);\r\n            featMap[oldID] = newID;\r\n        }\r\n    }\r\n    featureIndex = newFeatureIndex;\r\n    for (int i = 0; i < size; i++) {\r\n        List<Integer> featList = new ArrayList(data[i].length);\r\n        List<Double> valueList = new ArrayList(values[i].length);\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            if (featMap[data[i][j]] >= 0) {\r\n                featList.add(featMap[data[i][j]]);\r\n                valueList.add(values[i][j]);\r\n            }\r\n        }\r\n        data[i] = new int[featList.size()];\r\n        values[i] = new double[valueList.size()];\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            data[i][j] = featList.get(j);\r\n            values[i][j] = valueList.get(j);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.Base64.encodeBase64Chunked",
	"Comment": "encodes binary data using the base64 algorithm and chunks the encoded output into 76 character blocks",
	"Method": "byte[] encodeBase64Chunked(byte[] binaryData){\r\n    return encodeBase64(binaryData, true);\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.ContextualAuthenticationPolicy.getCode",
	"Comment": "return an optional message code to use when this is unsatisfied.",
	"Method": "Optional<String> getCode(){\r\n    return Optional.empty();\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifierFactory.getHighPrecisionFeatures",
	"Comment": "returns a list of featured thresholded by minprecision and sorted by their frequency of occurrence.precision in this case, is defined as the frequency of majority label over total frequency for that feature.",
	"Method": "List<F> getHighPrecisionFeatures(GeneralDataset<L, F> dataset,double minPrecision,int maxNumFeatures){\r\n    int[][] feature2label = new int[dataset.numFeatures()][dataset.numClasses()];\r\n    int[][] data = dataset.data;\r\n    int[] labels = dataset.labels;\r\n    for (int d = 0; d < data.length; d++) {\r\n        int label = labels[d];\r\n        if (data[d] != null) {\r\n            for (int n = 0; n < data[d].length; n++) {\r\n                feature2label[data[d][n]][label]++;\r\n            }\r\n        }\r\n    }\r\n    Counter<F> feature2freq = new ClassicCounter();\r\n    for (int f = 0; f < dataset.numFeatures(); f++) {\r\n        int maxF = ArrayMath.max(feature2label[f]);\r\n        int total = ArrayMath.sum(feature2label[f]);\r\n        double precision = ((double) maxF) / total;\r\n        F feature = dataset.featureIndex.get(f);\r\n        if (precision >= minPrecision) {\r\n            feature2freq.incrementCount(feature, total);\r\n        }\r\n    }\r\n    if (feature2freq.size() > maxNumFeatures) {\r\n        Counters.retainTop(feature2freq, maxNumFeatures);\r\n    }\r\n    return Counters.toSortedList(feature2freq);\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.sievepasses.DeterministicCorefSieve.sortMentionsForPronoun",
	"Comment": "divides a sentence into clauses and sorts the antecedents for pronoun matching.",
	"Method": "List<Mention> sortMentionsForPronoun(List<Mention> l,Mention m1,boolean sameSentence){\r\n    List<Mention> sorted = new ArrayList();\r\n    if (sameSentence) {\r\n        Tree tree = m1.contextParseTree;\r\n        Tree current = m1.mentionSubTree;\r\n        current = current.parent(tree);\r\n        while (current != null) {\r\n            if (current.label().value().startsWith(\"S\")) {\r\n                for (Mention m : l) {\r\n                    if (!sorted.contains(m) && current.dominates(m.mentionSubTree)) {\r\n                        sorted.add(m);\r\n                    }\r\n                }\r\n            }\r\n            current = current.parent(tree);\r\n        }\r\n        if (SieveCoreferenceSystem.logger.isLoggable(Level.FINEST)) {\r\n            if (l.size() != sorted.size()) {\r\n                SieveCoreferenceSystem.logger.finest(\"sorting failed!!! -> parser error?? \\tmentionID: \" + m1.mentionID + \" \" + m1.spanToString());\r\n                sorted = l;\r\n            } else if (!l.equals(sorted)) {\r\n                SieveCoreferenceSystem.logger.finest(\"sorting succeeded & changed !! \\tmentionID: \" + m1.mentionID + \" \" + m1.spanToString());\r\n                for (int i = 0; i < l.size(); i++) {\r\n                    Mention ml = l.get(i);\r\n                    Mention msorted = sorted.get(i);\r\n                    SieveCoreferenceSystem.logger.finest(\"\\t[\" + ml.spanToString() + \"]\\t[\" + msorted.spanToString() + \"]\");\r\n                }\r\n            } else {\r\n                SieveCoreferenceSystem.logger.finest(\"no changed !! \\tmentionID: \" + m1.mentionID + \" \" + m1.spanToString());\r\n            }\r\n        }\r\n    }\r\n    return sorted;\r\n}"
}, {
	"Path": "com.android.dx.ssa.SCCP.simulateBranch",
	"Comment": "simulates branch insns, if possible. adds reachable successor blocksto the cfg worklists.",
	"Method": "void simulateBranch(SsaInsn insn){\r\n    Rop opcode = insn.getOpcode();\r\n    RegisterSpecList sources = insn.getSources();\r\n    boolean constantBranch = false;\r\n    boolean constantSuccessor = false;\r\n    if (opcode.getBranchingness() == Rop.BRANCH_IF) {\r\n        Constant cA = null;\r\n        Constant cB = null;\r\n        RegisterSpec specA = sources.get(0);\r\n        int regA = specA.getReg();\r\n        if (!ssaMeth.isRegALocal(specA) && latticeValues[regA] == CONSTANT) {\r\n            cA = latticeConstants[regA];\r\n        }\r\n        if (sources.size() == 2) {\r\n            RegisterSpec specB = sources.get(1);\r\n            int regB = specB.getReg();\r\n            if (!ssaMeth.isRegALocal(specB) && latticeValues[regB] == CONSTANT) {\r\n                cB = latticeConstants[regB];\r\n            }\r\n        }\r\n        if (cA != null && sources.size() == 1) {\r\n            switch(((TypedConstant) cA).getBasicType()) {\r\n                case Type.BT_INT:\r\n                    constantBranch = true;\r\n                    int vA = ((CstInteger) cA).getValue();\r\n                    switch(opcode.getOpcode()) {\r\n                        case RegOps.IF_EQ:\r\n                            constantSuccessor = (vA == 0);\r\n                            break;\r\n                        case RegOps.IF_NE:\r\n                            constantSuccessor = (vA != 0);\r\n                            break;\r\n                        case RegOps.IF_LT:\r\n                            constantSuccessor = (vA < 0);\r\n                            break;\r\n                        case RegOps.IF_GE:\r\n                            constantSuccessor = (vA >= 0);\r\n                            break;\r\n                        case RegOps.IF_LE:\r\n                            constantSuccessor = (vA <= 0);\r\n                            break;\r\n                        case RegOps.IF_GT:\r\n                            constantSuccessor = (vA > 0);\r\n                            break;\r\n                        default:\r\n                            throw new RuntimeException(\"Unexpected op\");\r\n                    }\r\n                    break;\r\n                default:\r\n            }\r\n        } else if (cA != null && cB != null) {\r\n            switch(((TypedConstant) cA).getBasicType()) {\r\n                case Type.BT_INT:\r\n                    constantBranch = true;\r\n                    int vA = ((CstInteger) cA).getValue();\r\n                    int vB = ((CstInteger) cB).getValue();\r\n                    switch(opcode.getOpcode()) {\r\n                        case RegOps.IF_EQ:\r\n                            constantSuccessor = (vA == vB);\r\n                            break;\r\n                        case RegOps.IF_NE:\r\n                            constantSuccessor = (vA != vB);\r\n                            break;\r\n                        case RegOps.IF_LT:\r\n                            constantSuccessor = (vA < vB);\r\n                            break;\r\n                        case RegOps.IF_GE:\r\n                            constantSuccessor = (vA >= vB);\r\n                            break;\r\n                        case RegOps.IF_LE:\r\n                            constantSuccessor = (vA <= vB);\r\n                            break;\r\n                        case RegOps.IF_GT:\r\n                            constantSuccessor = (vA > vB);\r\n                            break;\r\n                        default:\r\n                            throw new RuntimeException(\"Unexpected op\");\r\n                    }\r\n                    break;\r\n                default:\r\n            }\r\n        }\r\n    }\r\n    SsaBasicBlock block = insn.getBlock();\r\n    if (constantBranch) {\r\n        int successorBlock;\r\n        if (constantSuccessor) {\r\n            successorBlock = block.getSuccessorList().get(1);\r\n        } else {\r\n            successorBlock = block.getSuccessorList().get(0);\r\n        }\r\n        addBlockToWorklist(ssaMeth.getBlocks().get(successorBlock));\r\n        branchWorklist.add(insn);\r\n    } else {\r\n        for (int i = 0; i < block.getSuccessorList().size(); i++) {\r\n            int successorBlock = block.getSuccessorList().get(i);\r\n            addBlockToWorklist(ssaMeth.getBlocks().get(successorBlock));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.support.saml.web.idp.profile.builders.enc.SamlIdPObjectEncrypter.encode",
	"Comment": "encode a given saml object by invoking a number of outbound security handlers on the context.",
	"Method": "EncryptedAssertion encode(Assertion samlObject,SamlRegisteredService service,SamlRegisteredServiceServiceProviderMetadataFacade adaptor,EncryptedID encode,NameID samlObject,SamlRegisteredService service,SamlRegisteredServiceServiceProviderMetadataFacade adaptor,EncryptedAttribute encode,Attribute samlObject,SamlRegisteredService service,SamlRegisteredServiceServiceProviderMetadataFacade adaptor){\r\n    val encrypter = buildEncrypterForSamlObject(samlObject, service, adaptor);\r\n    return encrypter.encrypt(samlObject);\r\n}"
}, {
	"Path": "org.apereo.cas.aup.BaseAcceptableUsagePolicyRepositoryTests.hasLiveUpdates",
	"Comment": "repository can update the state of the aup acceptance without reloading the principal. mostly for testing purposes.",
	"Method": "boolean hasLiveUpdates(){\r\n    return false;\r\n}"
}, {
	"Path": "com.android.dx.util.IntList.top",
	"Comment": "returns the last element in the array without modifying the array",
	"Method": "int top(){\r\n    return get(size - 1);\r\n}"
}, {
	"Path": "org.apereo.cas.web.support.WebUtils.putResolvedMultifactorAuthenticationProviders",
	"Comment": "put resolved multifactor authentication providers into scope.",
	"Method": "void putResolvedMultifactorAuthenticationProviders(RequestContext context,Collection<MultifactorAuthenticationProvider> value){\r\n    val providerIds = value.stream().map(MultifactorAuthenticationProvider::getId).collect(Collectors.toSet());\r\n    context.getConversationScope().put(\"resolvedMultifactorAuthenticationProviders\", providerIds);\r\n}"
}, {
	"Path": "org.apache.commons.cli.OptionBuilder.withDescription",
	"Comment": "the next option created will have the specified description",
	"Method": "OptionBuilder withDescription(String newDescription){\r\n    OptionBuilder.description = newDescription;\r\n    return INSTANCE;\r\n}"
}, {
	"Path": "org.objectweb.asm.ByteVector.putInt",
	"Comment": "puts an int into this byte vector. the byte vector is automaticallyenlarged if necessary.",
	"Method": "ByteVector putInt(int i){\r\n    int length = this.length;\r\n    if (length + 4 > data.length) {\r\n        enlarge(4);\r\n    }\r\n    byte[] data = this.data;\r\n    data[length++] = (byte) (i >>> 24);\r\n    data[length++] = (byte) (i >>> 16);\r\n    data[length++] = (byte) (i >>> 8);\r\n    data[length++] = (byte) i;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.feedback.FeedbackTinyLfuPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new FeedbackTinyLfuPolicy(config));\r\n}"
}, {
	"Path": "org.apereo.cas.services.RegisteredServiceAttributeReleasePolicy.isAuthorizedToReleaseAuthenticationAttributes",
	"Comment": "is authorized to release authentication attributes boolean.",
	"Method": "boolean isAuthorizedToReleaseAuthenticationAttributes(){\r\n    return true;\r\n}"
}, {
	"Path": "org.apereo.cas.web.view.ChainingTemplateViewResolver.initialize",
	"Comment": "initialize and sort resolvers here before computing templates.",
	"Method": "void initialize(){\r\n    AnnotationAwareOrderComparator.sortIfNecessary(this.resolvers);\r\n}"
}, {
	"Path": "org.apereo.cas.adaptors.x509.authentication.handler.support.X509CredentialsAuthenticationHandler.isCertificateAllowed",
	"Comment": "checks if is certificate allowed based no the pattern given.",
	"Method": "boolean isCertificateAllowed(X509Certificate cert){\r\n    return doesNameMatchPattern(cert.getSubjectDN(), this.regExSubjectDnPattern);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.edenWeightedSize",
	"Comment": "returns the uncorrected combined weight of the values in the eden space.",
	"Method": "long edenWeightedSize(){\r\n    throw new UnsupportedOperationException();\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.PRCurve.optimalCwa",
	"Comment": "optimal confidence weighted accuracy assuming for each recall we can fit an optimal monotonic function",
	"Method": "double optimalCwa(){\r\n    double acc = 0;\r\n    for (int recall = 1; recall <= numSamples(); recall++) {\r\n        acc += precision(recall) / (double) recall;\r\n    }\r\n    return acc / numSamples();\r\n}"
}, {
	"Path": "org.apereo.cas.web.support.WebUtils.getTicketGrantingTicketId",
	"Comment": "gets the ticket granting ticket id from the request and flow scopes.",
	"Method": "String getTicketGrantingTicketId(RequestContext context){\r\n    val tgtFromRequest = getTicketGrantingTicketIdFrom(context.getRequestScope());\r\n    val tgtFromFlow = getTicketGrantingTicketIdFrom(context.getFlowScope());\r\n    return tgtFromRequest != null ? tgtFromRequest : tgtFromFlow;\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.RequirementsCorrectSlowITest.testAnnotatorSequence",
	"Comment": "ensures that the given sequence of annotators actually abides by its stated requirements,at least in a default invocation of corenlp.",
	"Method": "void testAnnotatorSequence(List<String> annotators){\r\n    final Set<Class<? extends TypesafeMap.Key<?>>> keysRead = new HashSet();\r\n    ArrayCoreMap.listener = keysRead::add;\r\n    Annotation ann = new Annotation(dummyString);\r\n    for (int annotatorI = 0; annotatorI < annotators.size(); ++annotatorI) {\r\n        keysRead.clear();\r\n        String annotatorName = annotators.get(annotatorI);\r\n        System.err.println(\"Running \" + annotatorName);\r\n        StanfordCoreNLP corenlp = new StanfordCoreNLP(new Properties() {\r\n            {\r\n                setProperty(\"annotators\", annotatorName);\r\n                setProperty(\"enforceRequirements\", \"false\");\r\n            }\r\n        });\r\n        corenlp.annotate(ann);\r\n        Annotator annotator = StanfordCoreNLP.getExistingAnnotator(annotatorName);\r\n        assertNotNull(annotator);\r\n        Set declared = annotator.requires();\r\n        Set used = new HashSet(keysRead);\r\n        used.removeAll(annotator.requirementsSatisfied());\r\n        if (annotatorName.equals(\"ner\")) {\r\n            used.remove(CoreAnnotations.GoldAnswerAnnotation.class);\r\n            used.remove(CoreAnnotations.NamedEntityTagProbsAnnotation.class);\r\n            used.remove(CoreAnnotations.AnswerProbAnnotation.class);\r\n        }\r\n        if (annotatorName.equals(\"quote\")) {\r\n            used.remove(CoreAnnotations.SentenceBeginAnnotation.class);\r\n            used.remove(CoreAnnotations.SentenceEndAnnotation.class);\r\n        }\r\n        if (annotatorName.equals(\"coref\")) {\r\n            used.remove(CorefCoreAnnotations.CorefMentionsAnnotation.class);\r\n            used.remove(CoreAnnotations.ParagraphAnnotation.class);\r\n            used.remove(CoreAnnotations.SpeakerAnnotation.class);\r\n            used.remove(CoreAnnotations.UtteranceAnnotation.class);\r\n            used.remove(TreeCoreAnnotations.TreeAnnotation.class);\r\n            used.remove(CoreAnnotations.CategoryAnnotation.class);\r\n            used.remove(CorefCoreAnnotations.CorefMentionIndexesAnnotation.class);\r\n            used.remove(CoreAnnotations.EntityMentionToCorefMentionMappingAnnotation.class);\r\n            used.remove(CoreAnnotations.CorefMentionToEntityMentionMappingAnnotation.class);\r\n            if (!used.contains(CoreAnnotations.ValueAnnotation.class))\r\n                used.add(CoreAnnotations.ValueAnnotation.class);\r\n        }\r\n        if (annotatorI > 0) {\r\n            if (!declared.equals(used)) {\r\n                System.err.println(\"ANNOTATOR \" + annotatorName);\r\n                System.err.println(\"Used but not declared:\");\r\n                for (Object key : CollectionUtils.diffAsSet(used, declared)) {\r\n                    System.err.println(\"  \" + key);\r\n                }\r\n                System.err.println(\"Declared but not Used:\");\r\n                for (Object key : CollectionUtils.diffAsSet(declared, used)) {\r\n                    System.err.println(\"  \" + key);\r\n                }\r\n            }\r\n            assertEquals(declared, used);\r\n        }\r\n    }\r\n    StanfordCoreNLP corenlp = new StanfordCoreNLP(new Properties() {\r\n        {\r\n            setProperty(\"annotators\", StringUtils.join(annotators, \",\"));\r\n        }\r\n    });\r\n    corenlp.annotate(ann);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.probabilityOf",
	"Comment": "returns a counter mapping from each class name to the probability ofthat class for a certain example.looking at the the sum of each count v, should be 1.0.",
	"Method": "Counter<L> probabilityOf(Datum<L, F> example,Counter<L> probabilityOf,RVFDatum<L, F> example,Counter<L> probabilityOf,int[] features){\r\n    Counter<L> scores = logProbabilityOf(features);\r\n    for (L label : scores.keySet()) {\r\n        scores.setCount(label, Math.exp(scores.getCount(label)));\r\n    }\r\n    return scores;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.getClassifier",
	"Comment": "new method for getting a crfclassifier from an objectinputstream",
	"Method": "CRFClassifier<INN> getClassifier(File file,CRFClassifier<INN> getClassifier,InputStream in,CRFClassifier<INN> getClassifier,ObjectInputStream ois,CRFClassifier<CoreLabel> getClassifier,String loadPath,CRFClassifier<INN> getClassifier,String loadPath,Properties props,CRFClassifier<INN> getClassifier,ObjectInputStream ois,Properties props){\r\n    CRFClassifier<INN> crf = new CRFClassifier();\r\n    crf.loadClassifier(ois, props);\r\n    return crf;\r\n}"
}, {
	"Path": "org.apereo.cas.support.saml.web.idp.profile.builders.authn.DefaultAuthnContextClassRefBuilder.getAuthenticationContextByAssertion",
	"Comment": "gets authentication context by assertion.this is more of a template method for the time being,and may be enhanced later to support more advanced parsing of classesfrom the assertion.",
	"Method": "String getAuthenticationContextByAssertion(Object assertion,RequestedAuthnContext requestedAuthnContext,List<AuthnContextClassRef> authnContextClassRefs){\r\n    LOGGER.debug(\"AuthN Context comparison is requested to use [{}]\", requestedAuthnContext.getComparison());\r\n    authnContextClassRefs.forEach(c -> LOGGER.debug(\"Requested AuthN Context [{}]\", c.getAuthnContextClassRef()));\r\n    return null;\r\n}"
}, {
	"Path": "org.apereo.cas.ticket.support.BaseDelegatingExpirationPolicy.getTimeToLive",
	"Comment": "checks the given ticketstate and gets the timetolive for the relevant expiration policy.",
	"Method": "Long getTimeToLive(TicketState ticketState,Long getTimeToLive){\r\n    if (this.defaultExpirationPolicy == null) {\r\n        return 0L;\r\n    }\r\n    return this.defaultExpirationPolicy.getTimeToLive();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.linked.FrequentlyUsedPolicy.onHit",
	"Comment": "moves the entry to the next higher frequency list, creating it if necessary.",
	"Method": "void onHit(Node node){\r\n    policyStats.recordHit();\r\n    int newCount = node.freq.count + 1;\r\n    FrequencyNode freqN = (node.freq.next.count == newCount) ? node.freq.next : new FrequencyNode(newCount, node.freq);\r\n    node.remove();\r\n    if (node.freq.isEmpty()) {\r\n        node.freq.remove();\r\n    }\r\n    node.freq = freqN;\r\n    node.append();\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaInsn.isRegASource",
	"Comment": "indicates whether the specified register is amongst the registersused as sources for this instruction.",
	"Method": "boolean isRegASource(int reg){\r\n    return null != getSources().specForRegister(reg);\r\n}"
}, {
	"Path": "org.apache.commons.cli.OptionBuilder.hasArgs",
	"Comment": "the next option created can have unlimited argument values.",
	"Method": "OptionBuilder hasArgs(OptionBuilder hasArgs,int num){\r\n    OptionBuilder.numberOfArgs = num;\r\n    return INSTANCE;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.getRelation",
	"Comment": "return the relation that holds between the given entities.return a relation of type unrelated if this sentence contains no relation between the entities.",
	"Method": "RelationMention getRelation(RelationMentionFactory factory,CoreMap sentence,ExtractionObject args){\r\n    return getRelations(factory, sentence, args).get(0);\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.SerialVersionUIDAdder.visitField",
	"Comment": "gets class field information for step 4 of the algorithm. also determinesif the class already has a svuid.",
	"Method": "FieldVisitor visitField(int access,String name,String desc,String signature,Object value){\r\n    if (computeSVUID) {\r\n        if (\"serialVersionUID\".equals(name)) {\r\n            computeSVUID = false;\r\n            hasSVUID = true;\r\n        }\r\n        if ((access & Opcodes.ACC_PRIVATE) == 0 || (access & (Opcodes.ACC_STATIC | Opcodes.ACC_TRANSIENT)) == 0) {\r\n            int mods = access & (Opcodes.ACC_PUBLIC | Opcodes.ACC_PRIVATE | Opcodes.ACC_PROTECTED | Opcodes.ACC_STATIC | Opcodes.ACC_FINAL | Opcodes.ACC_VOLATILE | Opcodes.ACC_TRANSIENT);\r\n            svuidFields.add(new Item(name, mods, desc));\r\n        }\r\n    }\r\n    return super.visitField(access, name, desc, signature, value);\r\n}"
}, {
	"Path": "org.apache.commons.cli.OptionBuilder.withType",
	"Comment": "the next option created will have a value that will be an instanceof type.",
	"Method": "OptionBuilder withType(Object newType,OptionBuilder withType,Class<?> newType){\r\n    OptionBuilder.type = newType;\r\n    return INSTANCE;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.LabelDictionary.isConstrained",
	"Comment": "true if this observation is constrained, and false otherwise.",
	"Method": "boolean isConstrained(String observation){\r\n    return observationIndex.indexOf(observation) >= 0;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.CacheFactory.resolveConfigurationFor",
	"Comment": "copies the configuration and overlays it on top of the default settings.",
	"Method": "CaffeineConfiguration<K, V> resolveConfigurationFor(Configuration<K, V> configuration){\r\n    if (configuration instanceof CaffeineConfiguration<?, ?>) {\r\n        return new CaffeineConfiguration((CaffeineConfiguration<K, V>) configuration);\r\n    }\r\n    CaffeineConfiguration<K, V> template = TypesafeConfigurator.defaults(rootConfig);\r\n    if (configuration instanceof CompleteConfiguration<?, ?>) {\r\n        CompleteConfiguration<K, V> complete = (CompleteConfiguration<K, V>) configuration;\r\n        template.setReadThrough(complete.isReadThrough());\r\n        template.setWriteThrough(complete.isWriteThrough());\r\n        template.setManagementEnabled(complete.isManagementEnabled());\r\n        template.setStatisticsEnabled(complete.isStatisticsEnabled());\r\n        template.getCacheEntryListenerConfigurations().forEach(template::removeCacheEntryListenerConfiguration);\r\n        complete.getCacheEntryListenerConfigurations().forEach(template::addCacheEntryListenerConfiguration);\r\n        template.setCacheLoaderFactory(complete.getCacheLoaderFactory());\r\n        template.setCacheWriterFactory(complete.getCacheWriterFactory());\r\n        template.setExpiryPolicyFactory(complete.getExpiryPolicyFactory());\r\n    }\r\n    template.setTypes(configuration.getKeyType(), configuration.getValueType());\r\n    template.setStoreByValue(configuration.isStoreByValue());\r\n    return template;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.RefinedSoundex.getMappingCode",
	"Comment": "returns the mapping code for a given character. the mapping codes aremaintained in an internal char array named soundexmapping, and thedefault values of these mappings are us english.",
	"Method": "char getMappingCode(char c){\r\n    if (!Character.isLetter(c)) {\r\n        return 0;\r\n    }\r\n    return this.soundexMapping[Character.toUpperCase(c) - 'A'];\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.putStatic",
	"Comment": "generates the instruction to store the top stack value in a static field.",
	"Method": "void putStatic(Type owner,String name,Type type){\r\n    fieldInsn(Opcodes.PUTSTATIC, owner, name, type);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.climbing.HillClimberWindowTinyLfuPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    HillClimberWindowTinyLfuSettings settings = new HillClimberWindowTinyLfuSettings(config);\r\n    Set<Policy> policies = new HashSet();\r\n    for (HillClimberType climber : settings.strategy()) {\r\n        for (double percentMain : settings.percentMain()) {\r\n            policies.add(new HillClimberWindowTinyLfuPolicy(climber, percentMain, settings));\r\n        }\r\n    }\r\n    return policies;\r\n}"
}, {
	"Path": "org.apereo.cas.adaptors.x509.authentication.principal.AbstractX509PrincipalResolver.getAlternatePrincipal",
	"Comment": "get alternate principal if alternate attribute configured.",
	"Method": "String getAlternatePrincipal(X509Certificate certificate){\r\n    if (alternatePrincipalAttribute == null) {\r\n        return null;\r\n    }\r\n    val attributes = extractPersonAttributes(certificate);\r\n    val attribute = attributes.get(alternatePrincipalAttribute);\r\n    if (attribute == null) {\r\n        LOGGER.debug(\"Attempt to get alternate principal with attribute {} was unsuccessful.\", alternatePrincipalAttribute);\r\n        return null;\r\n    }\r\n    val optionalAttribute = CollectionUtils.firstElement(attribute);\r\n    if (optionalAttribute.isEmpty()) {\r\n        LOGGER.debug(\"Alternate attribute list for {} was empty.\", alternatePrincipalAttribute);\r\n        return null;\r\n    }\r\n    val alternatePrincipal = optionalAttribute.get().toString();\r\n    if (StringUtils.isNotEmpty(alternatePrincipal)) {\r\n        LOGGER.debug(\"Using alternate principal attribute {} \", alternatePrincipal);\r\n        return alternatePrincipal;\r\n    }\r\n    LOGGER.debug(\"Returning null principal id...\");\r\n    return null;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.readClassifier",
	"Comment": "loads a classifier from a file.simple convenience wrapper for ioutils.readfromstring.",
	"Method": "LinearClassifier<L, F> readClassifier(String loadPath){\r\n    logger.info(\"Deserializing classifier from \" + loadPath + \"...\");\r\n    try {\r\n        ObjectInputStream ois = IOUtils.readStreamFromString(loadPath);\r\n        LinearClassifier<L, F> classifier = ErasureUtils.<LinearClassifier<L, F>>uncheckedCast(ois.readObject());\r\n        ois.close();\r\n        return classifier;\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(\"Deserialization failed: \" + e.getMessage(), e);\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.MethodWriter.noSuccessor",
	"Comment": "ends the current basic block. this method must be used in the case wherethe current basic block does not have any successor.",
	"Method": "void noSuccessor(){\r\n    if (compute == FRAMES) {\r\n        Label l = new Label();\r\n        l.frame = new Frame();\r\n        l.frame.owner = l;\r\n        l.resolve(this, code.length, code.data);\r\n        previousBlock.successor = l;\r\n        previousBlock = l;\r\n    } else {\r\n        currentBlock.outputStackMax = maxStackSize;\r\n    }\r\n    currentBlock = null;\r\n}"
}, {
	"Path": "org.apereo.cas.audit.spi.config.CasCoreAuditConfiguration.customAuditActionResolverMap",
	"Comment": "extension point for deployers to define custom auditactionresolvers to extend the stock resolvers.",
	"Method": "Map<String, AuditActionResolver> customAuditActionResolverMap(){\r\n    return new HashMap(0);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.MatchRatingApproachEncoder.getMinRating",
	"Comment": "obtains the min rating of the length sum of the 2 names. in essence the larger the sum length the smaller themin rating. values strictly from documentation.api usageconsider this method private, it is package protected for unit testing only.",
	"Method": "int getMinRating(int sumLength){\r\n    int minRating = 0;\r\n    if (sumLength <= FOUR) {\r\n        minRating = FIVE;\r\n    } else if (sumLength >= FIVE && sumLength <= SEVEN) {\r\n        minRating = FOUR;\r\n    } else if (sumLength >= EIGHT && sumLength <= ELEVEN) {\r\n        minRating = THREE;\r\n    } else if (sumLength == TWELVE) {\r\n        minRating = TWO;\r\n    } else {\r\n        minRating = ONE;\r\n    }\r\n    return minRating;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.getFeatureCountLabelIndices",
	"Comment": "returns number of features with weight above a certain threshold.",
	"Method": "int getFeatureCountLabelIndices(Set<Integer> iLabels,double threshold,boolean useMagnitude){\r\n    int n = 0;\r\n    for (double[] weightArray : weights) {\r\n        for (int labIndex : iLabels) {\r\n            double thisWeight = (useMagnitude) ? Math.abs(weightArray[labIndex]) : weightArray[labIndex];\r\n            if (thisWeight > threshold) {\r\n                n++;\r\n            }\r\n        }\r\n    }\r\n    return n;\r\n}"
}, {
	"Path": "org.objectweb.asm.Frame.get",
	"Comment": "returns the output frame local variable type at the given index.",
	"Method": "int get(int local){\r\n    if (outputLocals == null || local >= outputLocals.length) {\r\n        return LOCAL | local;\r\n    } else {\r\n        int type = outputLocals[local];\r\n        if (type == 0) {\r\n            type = outputLocals[local] = LOCAL | local;\r\n        }\r\n        return type;\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.support.wsfederation.WsFederationHelper.validateSignature",
	"Comment": "validatesignature checks to see if the signature on an assertion is valid.",
	"Method": "boolean validateSignature(Pair<Assertion, WsFederationConfiguration> resultPair){\r\n    if (resultPair == null) {\r\n        LOGGER.warn(\"No assertion or its configuration was provided to validate signatures\");\r\n        return false;\r\n    }\r\n    val configuration = resultPair.getValue();\r\n    val assertion = resultPair.getKey();\r\n    if (assertion == null || configuration == null) {\r\n        LOGGER.warn(\"No signature or configuration was provided to validate signatures\");\r\n        return false;\r\n    }\r\n    val signature = assertion.getSignature();\r\n    if (signature == null) {\r\n        LOGGER.warn(\"No signature is attached to the assertion to validate\");\r\n        return false;\r\n    }\r\n    try {\r\n        LOGGER.debug(\"Validating the signature...\");\r\n        val validator = new SAMLSignatureProfileValidator();\r\n        validator.validate(signature);\r\n        val criteriaSet = new CriteriaSet();\r\n        criteriaSet.add(new UsageCriterion(UsageType.SIGNING));\r\n        criteriaSet.add(new EntityRoleCriterion(IDPSSODescriptor.DEFAULT_ELEMENT_NAME));\r\n        criteriaSet.add(new ProtocolCriterion(SAMLConstants.SAML20P_NS));\r\n        criteriaSet.add(new EntityIdCriterion(configuration.getIdentityProviderIdentifier()));\r\n        try {\r\n            val engine = buildSignatureTrustEngine(configuration);\r\n            LOGGER.debug(\"Validating signature via trust engine for [{}]\", configuration.getIdentityProviderIdentifier());\r\n            return engine.validate(signature, criteriaSet);\r\n        } catch (final SecurityException e) {\r\n            LOGGER.warn(e.getMessage(), e);\r\n        }\r\n    } catch (final SignatureException e) {\r\n        LOGGER.error(\"Failed to validate assertion signature\", e);\r\n    }\r\n    SamlUtils.logSamlObject(this.configBean, assertion);\r\n    LOGGER.error(\"Signature doesn't match any signing credential and cannot be validated.\");\r\n    return false;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.BasicBlock.getSecondarySuccessor",
	"Comment": "gets the secondary successor of this block. it is only valid to callthis method on blocks that have exactly two successors.",
	"Method": "int getSecondarySuccessor(){\r\n    if (successors.size() != 2) {\r\n        throw new UnsupportedOperationException(\"block doesn't have exactly two successors\");\r\n    }\r\n    int succ = successors.get(0);\r\n    if (succ == primarySuccessor) {\r\n        succ = successors.get(1);\r\n    }\r\n    return succ;\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.Hex.decodeHex",
	"Comment": "converts an array of characters representing hexadecimal values into an array of bytes of those same values. thereturned array will be half the length of the passed array, as it takes two characters to represent any givenbyte. an exception is thrown if the passed char array has an odd number of elements.",
	"Method": "byte[] decodeHex(char[] data){\r\n    final int len = data.length;\r\n    if ((len & 0x01) != 0) {\r\n        throw new DecoderException(\"Odd number of characters.\");\r\n    }\r\n    final byte[] out = new byte[len >> 1];\r\n    for (int i = 0, j = 0; j < len; i++) {\r\n        int f = toDigit(data[j], j) << 4;\r\n        j++;\r\n        f = f | toDigit(data[j], j);\r\n        j++;\r\n        out[i] = (byte) (f & 0xFF);\r\n    }\r\n    return out;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.MultifactorAuthenticationUtils.getAvailableMultifactorAuthenticationProviders",
	"Comment": "gets all multifactor authentication providers from application context.",
	"Method": "Map<String, MultifactorAuthenticationProvider> getAvailableMultifactorAuthenticationProviders(ApplicationContext applicationContext){\r\n    try {\r\n        return applicationContext.getBeansOfType(MultifactorAuthenticationProvider.class, false, true);\r\n    } catch (final Exception e) {\r\n        LOGGER.trace(\"No beans of type [{}] are available in the application context. \" + \"CAS may not be configured to handle multifactor authentication requests in absence of a provider\", MultifactorAuthenticationProvider.class);\r\n    }\r\n    return new HashMap(0);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.calculateStochasticGradient",
	"Comment": "performs stochastic gradient update basedon samples indexed by batch, but does not apply regularization.",
	"Method": "void calculateStochasticGradient(double[] x,int[] batch){\r\n    if (derivative == null) {\r\n        derivative = new double[domainDimension()];\r\n    }\r\n    to2D(x, weights);\r\n    setWeights(weights);\r\n    List<Integer> docIDs = new ArrayList(batch.length);\r\n    for (int item : batch) {\r\n        docIDs.add(item);\r\n    }\r\n    multiThreadGradient(docIDs, true);\r\n    int index = 0;\r\n    for (int i = 0; i < E.length; i++) {\r\n        for (int j = 0; j < E[i].length; j++) {\r\n            derivative[index++] = (E[i][j] - Ehat[i][j]);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.segment.S4WindowTinyLfuPolicy.onMiss",
	"Comment": "adds the entry to the admission window, evicting if necessary.",
	"Method": "void onMiss(long key){\r\n    Node node = new Node(key, Status.EDEN);\r\n    node.appendToTail(headEden);\r\n    data.put(key, node);\r\n    sizeEden++;\r\n    evict();\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.toString",
	"Comment": "print out a partial representation of a linear classifier in one ofseveral ways.",
	"Method": "String toString(String toString,String style,int param){\r\n    if (style == null || style.isEmpty()) {\r\n        return \"LinearClassifier with \" + featureIndex.size() + \" features, \" + labelIndex.size() + \" classes, and \" + labelIndex.size() * featureIndex.size() + \" parameters.\\n\";\r\n    } else if (style.equalsIgnoreCase(\"HighWeight\")) {\r\n        return toBiggestWeightFeaturesString(false, param, true);\r\n    } else if (style.equalsIgnoreCase(\"HighMagnitude\")) {\r\n        return toBiggestWeightFeaturesString(true, param, true);\r\n    } else if (style.equalsIgnoreCase(\"AllWeights\")) {\r\n        return toAllWeightsString();\r\n    } else if (style.equalsIgnoreCase(\"WeightHistogram\")) {\r\n        return toHistogramString();\r\n    } else if (style.equalsIgnoreCase(\"WeightDistribution\")) {\r\n        return toDistributionString(param);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown style: \" + style);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEntityMention.before",
	"Comment": "verifies if this mention appears before the parameter in textual order",
	"Method": "boolean before(AceEntityMention em){\r\n    if (mHead.getByteEnd() < em.mHead.getByteStart())\r\n        return true;\r\n    return false;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFNonLinearLogConditionalObjectiveFunction.calculate",
	"Comment": "calculates both value and partial derivatives at the point x, and save them internally.",
	"Method": "void calculate(double[] x){\r\n    double prob = 0.0;\r\n    Triple<double[][], double[][], double[][]> allParams = separateWeights(x);\r\n    double[][] linearWeights = allParams.first();\r\n    double[][] W = allParams.second();\r\n    double[][] U = allParams.third();\r\n    double[][] Y = null;\r\n    if (flags.softmaxOutputLayer) {\r\n        Y = new double[U.length][];\r\n        for (int i = 0; i < U.length; i++) {\r\n            Y[i] = ArrayMath.softmax(U[i]);\r\n        }\r\n    }\r\n    double[][] What = emptyW();\r\n    double[][] Uhat = emptyU();\r\n    double[][] E = empty2D();\r\n    double[][] eW = emptyW();\r\n    double[][] eU = emptyU();\r\n    for (int m = 0; m < data.length; m++) {\r\n        int[][][] docData = data[m];\r\n        int[] docLabels = labels[m];\r\n        double[][][] featureVal3DArr = null;\r\n        if (featureVal != null)\r\n            featureVal3DArr = featureVal[m];\r\n        if (DEBUG)\r\n            log.info(\"processing doc \" + m);\r\n        NonLinearCliquePotentialFunction cliquePotentialFunction = new NonLinearCliquePotentialFunction(linearWeights, W, U, flags);\r\n        CRFCliqueTree<String> cliqueTree = CRFCliqueTree.getCalibratedCliqueTree(docData, labelIndices, numClasses, classIndex, backgroundSymbol, cliquePotentialFunction, featureVal3DArr);\r\n        int[] given = new int[window - 1];\r\n        if (!gradientsOnly)\r\n            Arrays.fill(given, classIndex.indexOf(backgroundSymbol));\r\n        int[] windowLabels = new int[window];\r\n        Arrays.fill(windowLabels, classIndex.indexOf(backgroundSymbol));\r\n        if (docLabels.length > docData.length) {\r\n            System.arraycopy(docLabels, 0, given, 0, given.length);\r\n            System.arraycopy(docLabels, 0, windowLabels, 0, windowLabels.length);\r\n            int[] newDocLabels = new int[docData.length];\r\n            System.arraycopy(docLabels, docLabels.length - newDocLabels.length, newDocLabels, 0, newDocLabels.length);\r\n            docLabels = newDocLabels;\r\n        }\r\n        if (!gradientsOnly) {\r\n            for (int i = 0; i < docData.length; i++) {\r\n                int label = docLabels[i];\r\n                double p = cliqueTree.condLogProbGivenPrevious(i, label, given);\r\n                if (VERBOSE) {\r\n                    log.info(\"P(\" + label + \"|\" + ArrayMath.toString(given) + \")=\" + p);\r\n                }\r\n                prob += p;\r\n                System.arraycopy(given, 1, given, 0, given.length - 1);\r\n                given[given.length - 1] = label;\r\n            }\r\n        }\r\n        for (int i = 0; i < docData.length; i++) {\r\n            System.arraycopy(windowLabels, 1, windowLabels, 0, window - 1);\r\n            windowLabels[window - 1] = docLabels[i];\r\n            for (int j = 0; j < docData[i].length; j++) {\r\n                Index<CRFLabel> labelIndex = labelIndices.get(j);\r\n                int[] cliqueFeatures = docData[i][j];\r\n                double[] As = null;\r\n                double[] fDeriv = null;\r\n                double[][] yTimesA = null;\r\n                double[] sumOfYTimesA = null;\r\n                if (DEBUG)\r\n                    log.info(\"calculating Ehat[\" + i + \"]\");\r\n                if (j == 0) {\r\n                    double[] featureValArr = null;\r\n                    if (featureVal3DArr != null)\r\n                        featureValArr = featureVal3DArr[i][j];\r\n                    As = cliquePotentialFunction.hiddenLayerOutput(W, cliqueFeatures, flags, featureValArr);\r\n                    fDeriv = new double[inputLayerSize];\r\n                    double fD = 0;\r\n                    for (int q = 0; q < inputLayerSize; q++) {\r\n                        if (useSigmoid) {\r\n                            fD = As[q] * (1 - As[q]);\r\n                        } else {\r\n                            fD = 1 - As[q] * As[q];\r\n                        }\r\n                        fDeriv[q] = fD;\r\n                    }\r\n                    if (flags.softmaxOutputLayer) {\r\n                        double val = 0;\r\n                        yTimesA = new double[outputLayerSize][numHiddenUnits];\r\n                        for (int ii = 0; ii < outputLayerSize; ii++) {\r\n                            yTimesA[ii] = new double[numHiddenUnits];\r\n                        }\r\n                        sumOfYTimesA = new double[outputLayerSize];\r\n                        for (int k = 0; k < outputLayerSize; k++) {\r\n                            double[] Yk = null;\r\n                            if (flags.tieOutputLayer) {\r\n                                Yk = Y[0];\r\n                            } else {\r\n                                Yk = Y[k];\r\n                            }\r\n                            double sum = 0;\r\n                            for (int q = 0; q < inputLayerSize; q++) {\r\n                                if (q % outputLayerSize == k) {\r\n                                    int hiddenUnitNo = q / outputLayerSize;\r\n                                    val = As[q] * Yk[hiddenUnitNo];\r\n                                    yTimesA[k][hiddenUnitNo] = val;\r\n                                    sum += val;\r\n                                }\r\n                            }\r\n                            sumOfYTimesA[k] = sum;\r\n                        }\r\n                    }\r\n                    int[] cliqueLabel = new int[j + 1];\r\n                    System.arraycopy(windowLabels, window - 1 - j, cliqueLabel, 0, j + 1);\r\n                    CRFLabel crfLabel = new CRFLabel(cliqueLabel);\r\n                    int givenLabelIndex = labelIndex.indexOf(crfLabel);\r\n                    double[] Uk = null;\r\n                    double[] UhatK = null;\r\n                    double[] Yk = null;\r\n                    double[] yTimesAK = null;\r\n                    double sumOfYTimesAK = 0;\r\n                    if (flags.tieOutputLayer) {\r\n                        Uk = U[0];\r\n                        UhatK = Uhat[0];\r\n                        if (flags.softmaxOutputLayer) {\r\n                            Yk = Y[0];\r\n                        }\r\n                    } else {\r\n                        Uk = U[givenLabelIndex];\r\n                        UhatK = Uhat[givenLabelIndex];\r\n                        if (flags.softmaxOutputLayer) {\r\n                            Yk = Y[givenLabelIndex];\r\n                        }\r\n                    }\r\n                    if (flags.softmaxOutputLayer) {\r\n                        yTimesAK = yTimesA[givenLabelIndex];\r\n                        sumOfYTimesAK = sumOfYTimesA[givenLabelIndex];\r\n                    }\r\n                    for (int k = 0; k < inputLayerSize; k++) {\r\n                        double deltaK = 1;\r\n                        if (flags.sparseOutputLayer || flags.tieOutputLayer) {\r\n                            if (k % outputLayerSize == givenLabelIndex) {\r\n                                int hiddenUnitNo = k / outputLayerSize;\r\n                                if (flags.softmaxOutputLayer) {\r\n                                    UhatK[hiddenUnitNo] += (yTimesAK[hiddenUnitNo] - Yk[hiddenUnitNo] * sumOfYTimesAK);\r\n                                    deltaK *= Yk[hiddenUnitNo];\r\n                                } else {\r\n                                    UhatK[hiddenUnitNo] += As[k];\r\n                                    deltaK *= Uk[hiddenUnitNo];\r\n                                }\r\n                            }\r\n                        } else {\r\n                            UhatK[k] += As[k];\r\n                            if (useOutputLayer) {\r\n                                deltaK *= Uk[k];\r\n                            }\r\n                        }\r\n                        if (useHiddenLayer)\r\n                            deltaK *= fDeriv[k];\r\n                        if (useOutputLayer) {\r\n                            if (flags.sparseOutputLayer || flags.tieOutputLayer) {\r\n                                if (k % outputLayerSize == givenLabelIndex) {\r\n                                    double[] WhatK = What[k];\r\n                                    for (int n = 0; n < cliqueFeatures.length; n++) {\r\n                                        double fVal = 1.0;\r\n                                        if (featureVal3DArr != null)\r\n                                            fVal = featureVal3DArr[i][j][n];\r\n                                        WhatK[cliqueFeatures[n]] += deltaK * fVal;\r\n                                    }\r\n                                }\r\n                            } else {\r\n                                double[] WhatK = What[k];\r\n                                double fVal = 1.0;\r\n                                for (int n = 0; n < cliqueFeatures.length; n++) {\r\n                                    fVal = 1.0;\r\n                                    if (featureVal3DArr != null)\r\n                                        fVal = featureVal3DArr[i][j][n];\r\n                                    WhatK[cliqueFeatures[n]] += deltaK * fVal;\r\n                                }\r\n                            }\r\n                        } else {\r\n                            if (k == givenLabelIndex) {\r\n                                double[] WhatK = What[k];\r\n                                double fVal = 1.0;\r\n                                for (int n = 0; n < cliqueFeatures.length; n++) {\r\n                                    fVal = 1.0;\r\n                                    if (featureVal3DArr != null)\r\n                                        fVal = featureVal3DArr[i][j][n];\r\n                                    WhatK[cliqueFeatures[n]] += deltaK * fVal;\r\n                                }\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n                if (DEBUG)\r\n                    log.info(\" done!\");\r\n                if (DEBUG)\r\n                    log.info(\"calculating E[\" + i + \"]\");\r\n                for (int k = 0; k < labelIndex.size(); k++) {\r\n                    int[] label = labelIndex.get(k).getLabel();\r\n                    double p = cliqueTree.prob(i, label);\r\n                    if (j == 0) {\r\n                        double[] Uk = null;\r\n                        double[] eUK = null;\r\n                        double[] Yk = null;\r\n                        if (flags.tieOutputLayer) {\r\n                            Uk = U[0];\r\n                            eUK = eU[0];\r\n                            if (flags.softmaxOutputLayer) {\r\n                                Yk = Y[0];\r\n                            }\r\n                        } else {\r\n                            Uk = U[k];\r\n                            eUK = eU[k];\r\n                            if (flags.softmaxOutputLayer) {\r\n                                Yk = Y[k];\r\n                            }\r\n                        }\r\n                        if (useOutputLayer) {\r\n                            for (int q = 0; q < inputLayerSize; q++) {\r\n                                double deltaQ = 1;\r\n                                if (flags.sparseOutputLayer || flags.tieOutputLayer) {\r\n                                    if (q % outputLayerSize == k) {\r\n                                        int hiddenUnitNo = q / outputLayerSize;\r\n                                        if (flags.softmaxOutputLayer) {\r\n                                            eUK[hiddenUnitNo] += (yTimesA[k][hiddenUnitNo] - Yk[hiddenUnitNo] * sumOfYTimesA[k]) * p;\r\n                                            deltaQ = Yk[hiddenUnitNo];\r\n                                        } else {\r\n                                            eUK[hiddenUnitNo] += As[q] * p;\r\n                                            deltaQ = Uk[hiddenUnitNo];\r\n                                        }\r\n                                    }\r\n                                } else {\r\n                                    eUK[q] += As[q] * p;\r\n                                    deltaQ = Uk[q];\r\n                                }\r\n                                if (useHiddenLayer)\r\n                                    deltaQ *= fDeriv[q];\r\n                                if (flags.sparseOutputLayer || flags.tieOutputLayer) {\r\n                                    if (q % outputLayerSize == k) {\r\n                                        double[] eWq = eW[q];\r\n                                        double fVal = 1.0;\r\n                                        for (int n = 0; n < cliqueFeatures.length; n++) {\r\n                                            fVal = 1.0;\r\n                                            if (featureVal3DArr != null)\r\n                                                fVal = featureVal3DArr[i][j][n];\r\n                                            eWq[cliqueFeatures[n]] += deltaQ * p * fVal;\r\n                                        }\r\n                                    }\r\n                                } else {\r\n                                    double[] eWq = eW[q];\r\n                                    double fVal = 1.0;\r\n                                    for (int n = 0; n < cliqueFeatures.length; n++) {\r\n                                        fVal = 1.0;\r\n                                        if (featureVal3DArr != null)\r\n                                            fVal = featureVal3DArr[i][j][n];\r\n                                        eWq[cliqueFeatures[n]] += deltaQ * p * fVal;\r\n                                    }\r\n                                }\r\n                            }\r\n                        } else {\r\n                            double deltaK = 1;\r\n                            if (useHiddenLayer)\r\n                                deltaK *= fDeriv[k];\r\n                            double[] eWK = eW[k];\r\n                            double fVal = 1.0;\r\n                            for (int n = 0; n < cliqueFeatures.length; n++) {\r\n                                fVal = 1.0;\r\n                                if (featureVal3DArr != null)\r\n                                    fVal = featureVal3DArr[i][j][n];\r\n                                eWK[cliqueFeatures[n]] += deltaK * p * fVal;\r\n                            }\r\n                        }\r\n                    } else {\r\n                        for (int cliqueFeature : cliqueFeatures) {\r\n                            E[cliqueFeature][k] += p;\r\n                        }\r\n                    }\r\n                }\r\n                if (DEBUG)\r\n                    log.info(\" done!\");\r\n            }\r\n        }\r\n    }\r\n    if (Double.isNaN(prob)) {\r\n        throw new RuntimeException(\"Got NaN for prob in CRFNonLinearLogConditionalObjectiveFunction.calculate()\");\r\n    }\r\n    value = -prob;\r\n    if (VERBOSE) {\r\n        log.info(\"value is \" + value);\r\n    }\r\n    if (DEBUG)\r\n        log.info(\"calculating derivative \");\r\n    int index = 0;\r\n    for (int i = 0; i < E.length; i++) {\r\n        for (int j = 0; j < E[i].length; j++) {\r\n            derivative[index++] = (E[i][j] - Ehat[i][j]);\r\n            if (VERBOSE) {\r\n                log.info(\"linearWeights deriv(\" + i + \",\" + j + \") = \" + E[i][j] + \" - \" + Ehat[i][j] + \" = \" + derivative[index - 1]);\r\n            }\r\n        }\r\n    }\r\n    if (index != edgeParamCount)\r\n        throw new RuntimeException(\"after edge derivative, index(\" + index + \") != edgeParamCount(\" + edgeParamCount + \")\");\r\n    for (int i = 0; i < eW.length; i++) {\r\n        for (int j = 0; j < eW[i].length; j++) {\r\n            derivative[index++] = (eW[i][j] - What[i][j]);\r\n            if (VERBOSE) {\r\n                log.info(\"inputLayerWeights deriv(\" + i + \",\" + j + \") = \" + eW[i][j] + \" - \" + What[i][j] + \" = \" + derivative[index - 1]);\r\n            }\r\n        }\r\n    }\r\n    if (index != beforeOutputWeights)\r\n        throw new RuntimeException(\"after W derivative, index(\" + index + \") != beforeOutputWeights(\" + beforeOutputWeights + \")\");\r\n    if (useOutputLayer) {\r\n        for (int i = 0; i < eU.length; i++) {\r\n            for (int j = 0; j < eU[i].length; j++) {\r\n                if (flags.hardcodeSoftmaxOutputWeights)\r\n                    derivative[index++] = 0;\r\n                else\r\n                    derivative[index++] = (eU[i][j] - Uhat[i][j]);\r\n                if (VERBOSE) {\r\n                    log.info(\"outputLayerWeights deriv(\" + i + \",\" + j + \") = \" + eU[i][j] + \" - \" + Uhat[i][j] + \" = \" + derivative[index - 1]);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    if (index != x.length)\r\n        throw new RuntimeException(\"after W derivative, index(\" + index + \") != x.length(\" + x.length + \")\");\r\n    int regSize = x.length;\r\n    if (flags.skipOutputRegularization || flags.softmaxOutputLayer || flags.hardcodeSoftmaxOutputWeights) {\r\n        regSize = beforeOutputWeights;\r\n    }\r\n    if (DEBUG)\r\n        log.info(\"done!\");\r\n    if (DEBUG)\r\n        log.info(\"incorporating priors ...\");\r\n    if (prior == QUADRATIC_PRIOR) {\r\n        double sigmaSq = sigma * sigma;\r\n        double twoSigmaSq = 2.0 * sigmaSq;\r\n        double w = 0;\r\n        double valueSum = 0;\r\n        for (int i = 0; i < regSize; i++) {\r\n            w = x[i];\r\n            valueSum += w * w;\r\n            derivative[i] += w / sigmaSq;\r\n        }\r\n        value += valueSum / twoSigmaSq;\r\n    } else if (prior == L1_PRIOR) {\r\n    } else if (prior == HUBER_PRIOR) {\r\n        double sigmaSq = sigma * sigma;\r\n        for (int i = 0; i < regSize; i++) {\r\n            double w = x[i];\r\n            double wabs = Math.abs(w);\r\n            if (wabs < epsilon) {\r\n                value += w * w / 2.0 / epsilon / sigmaSq;\r\n                derivative[i] += w / epsilon / sigmaSq;\r\n            } else {\r\n                value += (wabs - epsilon / 2) / sigmaSq;\r\n                derivative[i] += ((w < 0.0) ? -1.0 : 1.0) / sigmaSq;\r\n            }\r\n        }\r\n    } else if (prior == QUARTIC_PRIOR) {\r\n        double sigmaQu = sigma * sigma * sigma * sigma;\r\n        for (int i = 0; i < regSize; i++) {\r\n            double k = 1.0;\r\n            double w = x[i];\r\n            value += k * w * w * w * w / 2.0 / sigmaQu;\r\n            derivative[i] += k * w / sigmaQu;\r\n        }\r\n    }\r\n    if (flags.regularizeSoftmaxTieParam && flags.softmaxOutputLayer && !flags.hardcodeSoftmaxOutputWeights) {\r\n        double softmaxLambda = flags.softmaxTieLambda;\r\n        double oneDividedByTwoSigmaSq = softmaxLambda * 2;\r\n        double y = 0;\r\n        double mean = 1.0 / numHiddenUnits;\r\n        int count = 0;\r\n        for (double[] aU : U) {\r\n            for (int j = 0; j < aU.length; j++) {\r\n                y = aU[j];\r\n                value += (y - mean) * (y - mean) * softmaxLambda;\r\n                double grad = (y - mean) * oneDividedByTwoSigmaSq;\r\n                derivative[beforeOutputWeights + count] += grad;\r\n                count++;\r\n            }\r\n        }\r\n    }\r\n    if (DEBUG)\r\n        log.info(\"done!\");\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.DefaultAuthenticationAttributeReleasePolicy.decideAttributeReleaseBasedOnServiceAttributePolicy",
	"Comment": "decide attribute release based on service attribute policy.",
	"Method": "void decideAttributeReleaseBasedOnServiceAttributePolicy(Map<String, Object> attributes,String attributeValue,String attributeName,RegisteredService service,boolean doesAttributePolicyAllow){\r\n    if (StringUtils.isNotBlank(attributeValue)) {\r\n        LOGGER.debug(\"Obtained [{}] as an authentication attribute\", attributeName);\r\n        if (doesAttributePolicyAllow) {\r\n            LOGGER.debug(\"Obtained [{}] is passed to the CAS validation payload\", attributeName);\r\n            attributes.put(attributeName, CollectionUtils.wrap(attributeValue));\r\n        } else {\r\n            LOGGER.debug(\"Attribute release policy for [{}] does not authorize the release of [{}]\", service.getServiceId(), attributeName);\r\n            attributes.remove(attributeName);\r\n        }\r\n    } else {\r\n        LOGGER.trace(\"[{}] is not available and will not be released to the validation response.\", attributeName);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaInsn.setResultLocal",
	"Comment": "sets the local association for the result of this insn. this issometimes updated during the ssarenamer process.",
	"Method": "void setResultLocal(LocalItem local){\r\n    LocalItem oldItem = result.getLocalItem();\r\n    if (local != oldItem && (local == null || !local.equals(result.getLocalItem()))) {\r\n        result = RegisterSpec.makeLocalOptional(result.getReg(), result.getType(), local);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.rop.code.InsnList.withRegisterOffset",
	"Comment": "returns an instance that is identical to this one, except thatthe registers in each instruction are offset by the givenamount. mutability of the result is inherited from theoriginal.",
	"Method": "InsnList withRegisterOffset(int delta){\r\n    int sz = size();\r\n    InsnList result = new InsnList(sz);\r\n    for (int i = 0; i < sz; i++) {\r\n        Insn one = (Insn) get0(i);\r\n        if (one != null) {\r\n            result.set0(i, one.withRegisterOffset(delta));\r\n        }\r\n    }\r\n    if (isImmutable()) {\r\n        result.setImmutable();\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.SVMLightClassifierFactory.fitSigmoid",
	"Comment": "builds a sigmoid model to turn the classifier outputs into probabilities.",
	"Method": "LinearClassifier<L, L> fitSigmoid(SVMLightClassifier<L, F> classifier,GeneralDataset<L, F> dataset){\r\n    RVFDataset<L, L> plattDataset = new RVFDataset();\r\n    for (int i = 0; i < dataset.size(); i++) {\r\n        RVFDatum<L, F> d = dataset.getRVFDatum(i);\r\n        Counter<L> scores = classifier.scoresOf((Datum<L, F>) d);\r\n        scores.incrementCount(null);\r\n        plattDataset.add(new RVFDatum(scores, d.label()));\r\n    }\r\n    LinearClassifierFactory<L, L> factory = new LinearClassifierFactory();\r\n    factory.setPrior(new LogPrior(LogPrior.LogPriorType.NULL));\r\n    return factory.trainClassifier(plattDataset);\r\n}"
}, {
	"Path": "com.facebook.buck.tools.consistency.RuleKeyDiffPrinter.valueAsReadableString",
	"Comment": "gets a string representation of a value to use when printing diffs",
	"Method": "String valueAsReadableString(ParsedRuleKeyFile file,Value value){\r\n    switch(value.getSetField()) {\r\n        case STRING_VALUE:\r\n            return value.getStringValue();\r\n        case NUMBER_VALUE:\r\n            return String.valueOf(value.getNumberValue());\r\n        case BOOL_VALUE:\r\n            return String.valueOf(value.getBoolValue());\r\n        case NULL_VALUE:\r\n            return \"null\";\r\n        case HASHED_PATH:\r\n            return String.format(\"Path: %s, hash: %s\", value.getHashedPath().path, value.getHashedPath().hash);\r\n        case PATH:\r\n            return String.format(\"Path: %s\", value.getPath().path);\r\n        case SHA1_HASH:\r\n            return String.format(\"Sha1: %s\", value.getSha1Hash().sha1);\r\n        case PATTERN:\r\n            return String.format(\"Regex Pattern: %s\", value.getPattern().pattern);\r\n        case BYTE_ARRAY:\r\n            return String.format(\"Byte array length: %s\", value.getByteArray().length);\r\n        case CONTAINER_MAP:\r\n            return String.format(\"Map: Length: %s\", value.getContainerMap().size());\r\n        case CONTAINER_LIST:\r\n            return String.format(\"List: Length: %s\", value.getContainerList().size());\r\n        case RULE_KEY_HASH:\r\n            RuleKeyNode rule = file.rules.get(value.getRuleKeyHash().sha1);\r\n            if (rule == null) {\r\n                return String.format(\"RuleKey: %s\", value.getRuleKeyHash().sha1);\r\n            } else {\r\n                return String.format(\"RuleKey(%s) %s\", value.getRuleKeyHash().sha1, getRuleKeyName(file, rule.ruleKey));\r\n            }\r\n        case ARCHIVE_MEMBER_PATH:\r\n            return String.format(\"ArchiveMemberPath: %s!%s, hash: %s\", value.getArchiveMemberPath().archivePath, value.getArchiveMemberPath().memberPath, value.getArchiveMemberPath().hash);\r\n        case SOURCE_ROOT:\r\n            return String.format(\"SourceRoot: %s\", value.getSourceRoot().path);\r\n        case BUILD_RULE_TYPE:\r\n            return String.format(\"BuildRuleType: %s\", value.getBuildRuleType().type);\r\n        case WRAPPER:\r\n            return String.format(\"Wrapper: %s/%s\", value.getWrapper().type, valueAsReadableString(file, value.getWrapper().value));\r\n        case BUILD_TARGET:\r\n            return String.format(\"BuildTarget: %s\", value.getBuildTarget().name);\r\n        case TARGET_PATH:\r\n            return String.format(\"TargetPath: %s\", value.getTargetPath().path);\r\n        case KEY:\r\n            break;\r\n    }\r\n    return value.getSetField().getFieldName();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.testing.Threads.shuffle",
	"Comment": "based on the passed in working set, creates n shuffled variants.",
	"Method": "List<List<T>> shuffle(int samples,Collection<T> baseline){\r\n    List<List<T>> workingSets = new ArrayList(samples);\r\n    for (int i = 0; i < samples; i++) {\r\n        List<T> workingSet = new ArrayList(baseline);\r\n        Collections.shuffle(workingSet);\r\n        workingSets.add(ImmutableList.copyOf(workingSet));\r\n    }\r\n    return ImmutableList.copyOf(workingSets);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.MachineReading.makeAuxReader",
	"Comment": "constructs the corpus reader class and sets it as the reader for this machinereading instance.",
	"Method": "GenericDataSetReader makeAuxReader(){\r\n    try {\r\n        if (auxReader == null) {\r\n            if (MachineReadingProperties.datasetAuxReaderClass != null) {\r\n                auxReader = MachineReadingProperties.datasetAuxReaderClass.getConstructor().newInstance();\r\n            }\r\n        }\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n    return auxReader;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpec.getLocalItem",
	"Comment": "gets the variable info associated with this instance, if any.",
	"Method": "LocalItem getLocalItem(){\r\n    return local;\r\n}"
}, {
	"Path": "org.apereo.cas.ticket.registry.RedisTicketRegistry.getTimeout",
	"Comment": "if not time out value is specified, expire the ticket immediately.",
	"Method": "Long getTimeout(Ticket ticket){\r\n    val ttl = ticket.getExpirationPolicy().getTimeToLive();\r\n    if (ttl <= 0) {\r\n        return 1L;\r\n    }\r\n    return ttl;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.linked.MultiQueuePolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new MultiQueuePolicy(config));\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.data.DocumentPreprocessor.preprocess",
	"Comment": "fill missing information in document including mention id, mention attributes, syntactic relation, etc.",
	"Method": "void preprocess(Document doc,Dictionaries dict,LogisticClassifier<String, String> singletonPredictor,HeadFinder headFinder){\r\n    initializeMentions(doc, dict, singletonPredictor, headFinder);\r\n    mentionReordering(doc, headFinder);\r\n    fillSyntacticInfo(doc);\r\n    setParagraphAnnotation(doc);\r\n    processDiscourse(doc, dict);\r\n    initializeClusters(doc);\r\n    if (doc.goldMentions != null) {\r\n        extractGoldClusters(doc);\r\n        int foundGoldCount = 0;\r\n        for (Mention g : doc.goldMentionsByID.values()) {\r\n            if (g.hasTwin)\r\n                foundGoldCount++;\r\n        }\r\n        Redwood.log(\"debug-md\", \"# of found gold mentions: \" + foundGoldCount + \" / # of gold mentions: \" + doc.goldMentionsByID.size());\r\n    }\r\n    assignMentionNumbers(doc);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.getLContext",
	"Comment": "gets the left context. this is a regular expression that must match to the left of the pattern.",
	"Method": "RPattern getLContext(){\r\n    return this.lContext;\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.api.BuckTargetPattern.getRuleName",
	"Comment": "return a rule name if the pattern implicitly or explicit identifies one.",
	"Method": "Optional<String> getRuleName(){\r\n    return Optional.ofNullable(ruleName);\r\n}"
}, {
	"Path": "org.apereo.cas.ticket.ExpirationPolicy.getTimeToLive",
	"Comment": "describes the time duration where this policy should consider the item alive.once this time passes, the item is considered expired and dead.",
	"Method": "Long getTimeToLive(TicketState ticketState,Long getTimeToLive){\r\n    return getTimeToLive();\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.FactorTable.conditionalLogProbGivenFirst",
	"Comment": "computes the probability of the sequence of being at the end of the tablegiven that the first tag in table is given. given is at the beginning, of isat the end",
	"Method": "double conditionalLogProbGivenFirst(int given,int[] of){\r\n    if (of.length != windowSize - 1) {\r\n        throw new IllegalArgumentException(\"conditionalLogProbGivenFirst requires of one less than clique size (\" + windowSize + \") but was \" + Arrays.toString(of));\r\n    }\r\n    int[] labels = new int[windowSize];\r\n    labels[0] = given;\r\n    System.arraycopy(of, 0, labels, 1, windowSize - 1);\r\n    double probAll = unnormalizedLogProb(labels);\r\n    double probGiven = unnormalizedLogProbFront(given);\r\n    return probAll - probGiven;\r\n}"
}, {
	"Path": "org.objectweb.asm.ByteVector.putLong",
	"Comment": "puts a long into this byte vector. the byte vector is automaticallyenlarged if necessary.",
	"Method": "ByteVector putLong(long l){\r\n    int length = this.length;\r\n    if (length + 8 > data.length) {\r\n        enlarge(8);\r\n    }\r\n    byte[] data = this.data;\r\n    int i = (int) (l >>> 32);\r\n    data[length++] = (byte) (i >>> 24);\r\n    data[length++] = (byte) (i >>> 16);\r\n    data[length++] = (byte) (i >>> 8);\r\n    data[length++] = (byte) i;\r\n    i = (int) l;\r\n    data[length++] = (byte) (i >>> 24);\r\n    data[length++] = (byte) (i >>> 16);\r\n    data[length++] = (byte) (i >>> 8);\r\n    data[length++] = (byte) i;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "org.apache.commons.cli.PosixParser.init",
	"Comment": "resets the members to their original state i.e. removeall of tokens entries and set eattherestto false.",
	"Method": "void init(){\r\n    eatTheRest = false;\r\n    tokens.clear();\r\n}"
}, {
	"Path": "jsr166.JSR166TestCase.timeoutMillis",
	"Comment": "returns a timeout in milliseconds to be used in tests thatverify that operations block or time out.",
	"Method": "long timeoutMillis(){\r\n    return SHORT_DELAY_MS / 4;\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMapTest.testReplaceValue",
	"Comment": "replace value fails when the given key not mapped to expected value",
	"Method": "void testReplaceValue(){\r\n    ConcurrentMap map = map5();\r\n    assertEquals(\"A\", map.get(one));\r\n    assertFalse(map.replace(one, \"Z\", \"Z\"));\r\n    assertEquals(\"A\", map.get(one));\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.NaiveBayesClassifierFactory.trainWeights",
	"Comment": "here the data is assumed to be for every instance, array of length numfeaturesand the value of the feature is stored including zeroes.",
	"Method": "NBWeights trainWeights(int[][] data,int[] labels,int numFeatures,int numClasses){\r\n    if (kind == JL) {\r\n        return trainWeightsJL(data, labels, numFeatures, numClasses);\r\n    }\r\n    if (kind == UCL) {\r\n        return trainWeightsUCL(data, labels, numFeatures, numClasses);\r\n    }\r\n    if (kind == CL) {\r\n        return trainWeightsCL(data, labels, numFeatures, numClasses);\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.Options.compute",
	"Comment": "compute indicates if an async or sync cache variation should be use, or both if unset.",
	"Method": "Optional<Compute> compute(){\r\n    return Optional.ofNullable(Enums.getIfPresent(Compute.class, System.getProperty(\"compute\", \"\").toUpperCase()).orNull());\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.FieldNode.check",
	"Comment": "checks that this field node is compatible with the given asm api version.this methods checks that this node, and all its nodes recursively, do notcontain elements that were introduced in more recent versions of the asmapi than the given version.",
	"Method": "void check(int api){\r\n    if (api == Opcodes.ASM4) {\r\n        if (visibleTypeAnnotations != null && visibleTypeAnnotations.size() > 0) {\r\n            throw new RuntimeException();\r\n        }\r\n        if (invisibleTypeAnnotations != null && invisibleTypeAnnotations.size() > 0) {\r\n            throw new RuntimeException();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.addEdge",
	"Comment": "creates a link in the lattice between two escapesets due to a putinstruction. the object being put is the child and the object being putinto is the parent. a child set must always have an escape state atleast as high as its parent.",
	"Method": "void addEdge(EscapeSet parentSet,EscapeSet childSet){\r\n    if (!childSet.parentSets.contains(parentSet)) {\r\n        childSet.parentSets.add(parentSet);\r\n    }\r\n    if (!parentSet.childSets.contains(childSet)) {\r\n        parentSet.childSets.add(childSet);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.FrequencySketch.ensureCapacity",
	"Comment": "initializes and increases the capacity of this frequencysketch instance, if necessary,to ensure that it can accurately estimate the popularity of elements given the maximum size ofthe cache. this operation forgets all previous counts when resizing.",
	"Method": "void ensureCapacity(long maximumSize){\r\n    requireArgument(maximumSize >= 0);\r\n    int maximum = (int) Math.min(maximumSize, Integer.MAX_VALUE >>> 1);\r\n    if ((table != null) && (table.length >= maximum)) {\r\n        return;\r\n    }\r\n    table = new long[(maximum == 0) ? 1 : ceilingNextPowerOfTwo(maximum)];\r\n    tableMask = Math.max(0, table.length - 1);\r\n    sampleSize = (maximumSize == 0) ? 10 : (10 * maximum);\r\n    if (sampleSize <= 0) {\r\n        sampleSize = Integer.MAX_VALUE;\r\n    }\r\n    size = 0;\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaMethod.bitSetFromLabelList",
	"Comment": "builds a bitset of block indices from a basic block list and a listof labels taken from rop form.",
	"Method": "BitSet bitSetFromLabelList(BasicBlockList blocks,IntList labelList){\r\n    BitSet result = new BitSet(blocks.size());\r\n    for (int i = 0, sz = labelList.size(); i < sz; i++) {\r\n        result.set(blocks.indexOfLabel(labelList.get(i)));\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.android.dx.ssa.LocalVariableInfo.getAssignment",
	"Comment": "gets the named register being assigned by the given instruction, ifpreviously stored in this instance.",
	"Method": "RegisterSpec getAssignment(SsaInsn insn){\r\n    return insnAssignments.get(insn);\r\n}"
}, {
	"Path": "org.apereo.cas.DefaultCentralAuthenticationServiceTests.verifyDestroyRemoteRegistry",
	"Comment": "this test checks that the tgt destruction happens properly for a remote registry.it previously failed when the deletion happens before the ticket was marked expired because an update was necessary for that.",
	"Method": "void verifyDestroyRemoteRegistry(){\r\n    val registry = new MockOnlyOneTicketRegistry();\r\n    val tgt = new TicketGrantingTicketImpl(\"TGT-1\", mock(Authentication.class), mock(ExpirationPolicy.class));\r\n    val logoutManager = mock(LogoutManager.class);\r\n    when(logoutManager.performLogout(any(TicketGrantingTicket.class))).thenAnswer(invocation -> {\r\n        tgt.markTicketExpired();\r\n        registry.updateTicket(tgt);\r\n        return null;\r\n    });\r\n    registry.addTicket(tgt);\r\n    val cas = new DefaultCentralAuthenticationService(mock(ApplicationEventPublisher.class), registry, null, logoutManager, null, null, null, null, null, mock(AuditableExecution.class));\r\n    cas.destroyTicketGrantingTicket(tgt.getId());\r\n}"
}, {
	"Path": "the.bytecode.club.bytecodeviewer.searching.RegexInsnFinder.find",
	"Comment": "searches for a regex in the instruction list and returns the first match.",
	"Method": "AbstractInsnNode[] find(String regex){\r\n    try {\r\n        final Matcher regexMatcher = Pattern.compile(processRegex(regex), Pattern.MULTILINE).matcher(insnString);\r\n        if (regexMatcher.find())\r\n            return makeResult(regexMatcher.start(), regexMatcher.end());\r\n    } catch (final PatternSyntaxException ex) {\r\n    }\r\n    return new AbstractInsnNode[0];\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.unbox",
	"Comment": "generates the instructions to unbox the top stack value. this value isreplaced by its unboxed equivalent on top of the stack.",
	"Method": "void unbox(Type type){\r\n    Type t = NUMBER_TYPE;\r\n    Method sig = null;\r\n    switch(type.getSort()) {\r\n        case Type.VOID:\r\n            return;\r\n        case Type.CHAR:\r\n            t = CHARACTER_TYPE;\r\n            sig = CHAR_VALUE;\r\n            break;\r\n        case Type.BOOLEAN:\r\n            t = BOOLEAN_TYPE;\r\n            sig = BOOLEAN_VALUE;\r\n            break;\r\n        case Type.DOUBLE:\r\n            sig = DOUBLE_VALUE;\r\n            break;\r\n        case Type.FLOAT:\r\n            sig = FLOAT_VALUE;\r\n            break;\r\n        case Type.LONG:\r\n            sig = LONG_VALUE;\r\n            break;\r\n        case Type.INT:\r\n        case Type.SHORT:\r\n        case Type.BYTE:\r\n            sig = INT_VALUE;\r\n    }\r\n    if (sig == null) {\r\n        checkCast(type);\r\n    } else {\r\n        checkCast(t);\r\n        invokeVirtual(t, sig);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.irr.LirsPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new LirsPolicy(config));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.LocalAsyncLoadingCache.composeResult",
	"Comment": "returns a future that waits for all of the dependent futures to complete and returns thecombined mapping if successful. if any future fails then it is automatically removed fromthe cache if still present.",
	"Method": "CompletableFuture<Map<K, V>> composeResult(Map<K, CompletableFuture<V>> futures){\r\n    if (futures.isEmpty()) {\r\n        return CompletableFuture.completedFuture(Collections.emptyMap());\r\n    }\r\n    @SuppressWarnings(\"rawtypes\")\r\n    CompletableFuture<?>[] array = futures.values().toArray(new CompletableFuture[0]);\r\n    return CompletableFuture.allOf(array).thenApply(ignored -> {\r\n        Map<K, V> result = new LinkedHashMap(futures.size());\r\n        futures.forEach((key, future) -> {\r\n            V value = future.getNow(null);\r\n            if (value != null) {\r\n                result.put(key, value);\r\n            }\r\n        });\r\n        return Collections.unmodifiableMap(result);\r\n    });\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaRenamer.isBelowThresholdRegister",
	"Comment": "returns true if this ssa register is below the specified threshold.used when most code is already in ssa form, and renaming is needed onlyfor registers above a certain threshold.",
	"Method": "boolean isBelowThresholdRegister(int ssaReg){\r\n    return ssaReg < threshold;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.PRCurve.cwaArray",
	"Comment": "confidence weighted accuracy assuming the scores are probabilities and using .5 as treshold",
	"Method": "int[] cwaArray(){\r\n    int[] arr = new int[numSamples()];\r\n    for (int recall = 1; recall <= numSamples(); recall++) {\r\n        arr[recall - 1] = logPrecision(recall);\r\n    }\r\n    return arr;\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.getField",
	"Comment": "generates the instruction to push the value of a non static field on thestack.",
	"Method": "void getField(Type owner,String name,Type type){\r\n    fieldInsn(Opcodes.GETFIELD, owner, name, type);\r\n}"
}, {
	"Path": "org.objectweb.asm.MethodVisitor.visitTypeInsn",
	"Comment": "visits a type instruction. a type instruction is an instruction thattakes the internal name of a class as parameter.",
	"Method": "void visitTypeInsn(int opcode,String type){\r\n    if (mv != null) {\r\n        mv.visitTypeInsn(opcode, type);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.services.RegisteredService.getFriendlyName",
	"Comment": "gets friendly name of this service.typically describes the purpose of this serviceand the return value is usually used for display purposes.",
	"Method": "String getFriendlyName(){\r\n    return this.getClass().getSimpleName();\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.SerialVersionUIDAdder.writeItems",
	"Comment": "sorts the items in the collection and writes it to the data output stream",
	"Method": "void writeItems(Collection<Item> itemCollection,DataOutput dos,boolean dotted){\r\n    int size = itemCollection.size();\r\n    Item[] items = itemCollection.toArray(new Item[size]);\r\n    Arrays.sort(items);\r\n    for (int i = 0; i < size; i++) {\r\n        dos.writeUTF(items[i].name);\r\n        dos.writeInt(items[i].access);\r\n        dos.writeUTF(dotted ? items[i].desc.replace('/', '.') : items[i].desc);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.CorefRules.entityHaveExtraProperNoun",
	"Comment": "have extra proper noun except strings involved in semantic match",
	"Method": "boolean entityHaveExtraProperNoun(Mention m,Mention a,Set<String> exceptWords){\r\n    Set<String> mProper = Generics.newHashSet();\r\n    Set<String> aProper = Generics.newHashSet();\r\n    String mString = m.spanToString();\r\n    String aString = a.spanToString();\r\n    for (CoreLabel w : m.originalSpan) {\r\n        if (w.get(CoreAnnotations.PartOfSpeechAnnotation.class).startsWith(\"NNP\")) {\r\n            mProper.add(w.get(CoreAnnotations.TextAnnotation.class));\r\n        }\r\n    }\r\n    for (CoreLabel w : a.originalSpan) {\r\n        if (w.get(CoreAnnotations.PartOfSpeechAnnotation.class).startsWith(\"NNP\")) {\r\n            aProper.add(w.get(CoreAnnotations.TextAnnotation.class));\r\n        }\r\n    }\r\n    boolean mHasExtra = false;\r\n    boolean aHasExtra = false;\r\n    for (String s : mProper) {\r\n        if (!aString.contains(s) && !exceptWords.contains(s.toLowerCase())) {\r\n            mHasExtra = true;\r\n            break;\r\n        }\r\n    }\r\n    for (String s : aProper) {\r\n        if (!mString.contains(s) && !exceptWords.contains(s.toLowerCase())) {\r\n            aHasExtra = true;\r\n            break;\r\n        }\r\n    }\r\n    if (mHasExtra && aHasExtra) {\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.apereo.cas.couchdb.consent.ConsentDecisionCouchDbRepository.findFirstConsentDecision",
	"Comment": "find the first consent decision for a given principal, service pair. should only be one of them anyway.",
	"Method": "CouchDbConsentDecision findFirstConsentDecision(String principal,String service,CouchDbConsentDecision findFirstConsentDecision,ConsentDecision consent){\r\n    return findFirstConsentDecision(consent.getPrincipal(), consent.getService());\r\n}"
}, {
	"Path": "org.apache.commons.codec.net.URLCodec.encode",
	"Comment": "encodes an object into its url safe form. unsafe characters are escaped.",
	"Method": "byte[] encode(byte[] bytes,String encode,String str,String charset,String encode,String str,Object encode,Object obj){\r\n    if (obj == null) {\r\n        return null;\r\n    } else if (obj instanceof byte[]) {\r\n        return encode((byte[]) obj);\r\n    } else if (obj instanceof String) {\r\n        return encode((String) obj);\r\n    } else {\r\n        throw new EncoderException(\"Objects of type \" + obj.getClass().getName() + \" cannot be URL encoded\");\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.util.ISOStandardDateFormat.getCurrentDateAndTime",
	"Comment": "gets the current date and timeformatted by the pattern specified.",
	"Method": "String getCurrentDateAndTime(){\r\n    return format(ZonedDateTime.now(ZoneOffset.UTC));\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.Method.getDescriptor",
	"Comment": "returns the descriptor of the method described by this object.",
	"Method": "String getDescriptor(){\r\n    return desc;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.AbstractCaverphone.encode",
	"Comment": "encodes an object using the caverphone algorithm. this method is provided in order to satisfy the requirements ofthe encoder interface, and will throw an encoderexception if the supplied object is not of type java.lang.string.",
	"Method": "Object encode(Object source){\r\n    if (!(source instanceof String)) {\r\n        throw new EncoderException(\"Parameter supplied to Caverphone encode is not of type java.lang.String\");\r\n    }\r\n    return this.encode((String) source);\r\n}"
}, {
	"Path": "com.android.dx.rop.code.Insn.toHumanWithInline",
	"Comment": "returns the human string form of this instance, with the givenbit added in the standard location for an inline argument.",
	"Method": "String toHumanWithInline(String extra){\r\n    StringBuffer sb = new StringBuffer(80);\r\n    sb.append(position);\r\n    sb.append(\": \");\r\n    sb.append(opcode.getNickname());\r\n    if (extra != null) {\r\n        sb.append(\"(\");\r\n        sb.append(extra);\r\n        sb.append(\")\");\r\n    }\r\n    if (result == null) {\r\n        sb.append(\" .\");\r\n    } else {\r\n        sb.append(\" \");\r\n        sb.append(result.toHuman());\r\n    }\r\n    sb.append(\" <-\");\r\n    int sz = sources.size();\r\n    if (sz == 0) {\r\n        sb.append(\" .\");\r\n    } else {\r\n        for (int i = 0; i < sz; i++) {\r\n            sb.append(\" \");\r\n            sb.append(sources.get(i).toHuman());\r\n        }\r\n    }\r\n    return sb.toString();\r\n}"
}, {
	"Path": "com.google.common.cache.EmptyCachesTest.caches",
	"Comment": "most of the tests in this class run against every one of these caches.",
	"Method": "Iterable<LoadingCache<Object, Object>> caches(){\r\n    CacheBuilderFactory factory = cacheFactory();\r\n    return Iterables.transform(factory.buildAllPermutations(), new Function<Caffeine<Object, Object>, LoadingCache<Object, Object>>() {\r\n        @Override\r\n        public LoadingCache<Object, Object> apply(Caffeine<Object, Object> builder) {\r\n            return CaffeinatedGuava.build(builder, identityLoader());\r\n        }\r\n    });\r\n}"
}, {
	"Path": "com.google.common.cache.EmptyCachesTest.caches",
	"Comment": "most of the tests in this class run against every one of these caches.",
	"Method": "Iterable<LoadingCache<Object, Object>> caches(){\r\n    return CaffeinatedGuava.build(builder, identityLoader());\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.Expirable.hasExpired",
	"Comment": "returns if the value has expired and is eligible for eviction.",
	"Method": "boolean hasExpired(long currentTimeMS){\r\n    return (currentTimeMS - expireTimeMS) >= 0;\r\n}"
}, {
	"Path": "org.apereo.cas.services.util.RegisteredServicePublicKeyCipherExecutor.encode",
	"Comment": "encrypt using the given cipher associated with the service,and encode the data in base 64.",
	"Method": "String encode(String data,Optional<RegisteredService> service){\r\n    try {\r\n        if (service.isPresent()) {\r\n            val registeredService = service.get();\r\n            val publicKey = createRegisteredServicePublicKey(registeredService);\r\n            val result = encodeInternal(data, publicKey, registeredService);\r\n            if (result != null) {\r\n                return EncodingUtils.encodeBase64(result);\r\n            }\r\n        }\r\n    } catch (final Exception e) {\r\n        LOGGER.warn(e.getMessage(), e);\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "org.apache.commons.codec.digest.DigestUtils.updateDigest",
	"Comment": "reads through an inputstream and updates the digest for the data",
	"Method": "MessageDigest updateDigest(MessageDigest messageDigest,byte[] valueToDigest,MessageDigest updateDigest,MessageDigest messageDigest,ByteBuffer valueToDigest,MessageDigest updateDigest,MessageDigest digest,InputStream data,MessageDigest updateDigest,MessageDigest messageDigest,String valueToDigest){\r\n    messageDigest.update(StringUtils.getBytesUtf8(valueToDigest));\r\n    return messageDigest;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.PhoneticEngine.isConcat",
	"Comment": "gets if multiple phonetic encodings are concatenated or if just the first one is kept.",
	"Method": "boolean isConcat(){\r\n    return this.concat;\r\n}"
}, {
	"Path": "org.objectweb.asm.FieldVisitor.visitEnd",
	"Comment": "visits the end of the field. this method, which is the last one to becalled, is used to inform the visitor that all the annotations andattributes of the field have been visited.",
	"Method": "void visitEnd(){\r\n    if (fv != null) {\r\n        fv.visitEnd();\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.support.saml.web.idp.metadata.SamlIdPMetadataController.generateMetadataForIdp",
	"Comment": "displays the identity provider metadata.checks to make sure metadata exists, and if not, generates it first.",
	"Method": "void generateMetadataForIdp(HttpServletResponse response){\r\n    this.metadataAndCertificatesGenerationService.generate();\r\n    val md = this.samlIdPMetadataLocator.getMetadata().getInputStream();\r\n    val contents = IOUtils.toString(md, StandardCharsets.UTF_8);\r\n    response.setContentType(CONTENT_TYPE);\r\n    response.setStatus(HttpServletResponse.SC_OK);\r\n    try (val writer = response.getWriter()) {\r\n        LOGGER.debug(\"Producing metadata for the response\");\r\n        writer.write(contents);\r\n        writer.flush();\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils.getRelations",
	"Comment": "return all the relations that holds between the given entities.returns a list containing a relation of type unrelated if this sentence contains no relation between the entities.",
	"Method": "List<RelationMention> getRelations(RelationMentionFactory factory,CoreMap sentence,ExtractionObject args){\r\n    List<RelationMention> relationMentions = sentence.get(MachineReadingAnnotations.RelationMentionsAnnotation.class);\r\n    List<RelationMention> matchingRelationMentions = new ArrayList();\r\n    if (relationMentions != null) {\r\n        for (RelationMention rel : relationMentions) {\r\n            if (rel.argsMatch(args)) {\r\n                matchingRelationMentions.add(rel);\r\n            }\r\n        }\r\n    }\r\n    if (matchingRelationMentions.size() == 0) {\r\n        matchingRelationMentions.add(RelationMention.createUnrelatedRelation(factory, args));\r\n    }\r\n    return matchingRelationMentions;\r\n}"
}, {
	"Path": "com.android.dx.util.TwoColumnOutput.flushLeft",
	"Comment": "flushes the left column buffer, printing it and clearing the buffer.if the buffer is already empty, this does nothing.",
	"Method": "void flushLeft(){\r\n    appendNewlineIfNecessary(leftBuf, leftColumn);\r\n    while (leftBuf.length() != 0) {\r\n        rightColumn.write('\\n');\r\n        outputFullLines();\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.ClassNode.check",
	"Comment": "checks that this class node is compatible with the given asm api version.this methods checks that this node, and all its nodes recursively, do notcontain elements that were introduced in more recent versions of the asmapi than the given version.",
	"Method": "void check(int api){\r\n    if (api == Opcodes.ASM4) {\r\n        if (visibleTypeAnnotations != null && visibleTypeAnnotations.size() > 0) {\r\n            throw new RuntimeException();\r\n        }\r\n        if (invisibleTypeAnnotations != null && invisibleTypeAnnotations.size() > 0) {\r\n            throw new RuntimeException();\r\n        }\r\n        for (FieldNode f : fields) {\r\n            f.check(api);\r\n        }\r\n        for (MethodNode m : methods) {\r\n            m.check(api);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.SetFactory.makeInterferenceSet",
	"Comment": "make intset for the interference graph sets. public becauseinterferencegraph is in another package.",
	"Method": "IntSet makeInterferenceSet(int countRegs){\r\n    return countRegs <= INTERFERENCE_SET_THRESHOLD_SIZE ? new BitIntSet(countRegs) : new ListIntSet();\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.autodeps.BuckAddDependencyIntention.queryBuckForTargets",
	"Comment": "queries buck for targets that own the editsourcefile and the importsourcefile.",
	"Method": "void queryBuckForTargets(Editor editor){\r\n    BuckTargetLocator buckTargetLocator = BuckTargetLocator.getInstance(project);\r\n    String editPath = editSourceFile.getPath();\r\n    String importPath = importSourceFile.getPath();\r\n    BuckJsonCommandHandler<List<TargetMetadata>> handler = new BuckJsonCommandHandler(project, BuckCommand.QUERY, new Callback<List<TargetMetadata>>() {\r\n        @Override\r\n        public List<TargetMetadata> deserialize(JsonElement jsonElement) throws IOException {\r\n            Type type = new TypeToken<Map<String, JsonObject>>() {\r\n            }.getType();\r\n            Map<String, JsonObject> raw = new Gson().fromJson(jsonElement, type);\r\n            List<TargetMetadata> results = new ArrayList();\r\n            for (Entry<String, JsonObject> entry : raw.entrySet()) {\r\n                BuckTarget.parse(entry.getKey()).map(buckTargetLocator::resolve).map(target -> TargetMetadata.from(buckTargetLocator, target, entry.getValue())).ifPresent(results::add);\r\n            }\r\n            return results;\r\n        }\r\n        @Override\r\n        public void onSuccess(List<TargetMetadata> results, String stderr) {\r\n            List<TargetMetadata> editTargets = new ArrayList();\r\n            List<TargetMetadata> importTargets = new ArrayList();\r\n            for (TargetMetadata targetMetadata : results) {\r\n                if (targetMetadata.contains(editSourceTarget)) {\r\n                    editTargets.add(targetMetadata);\r\n                }\r\n                if (targetMetadata.contains(importSourceTarget)) {\r\n                    importTargets.add(targetMetadata);\r\n                }\r\n            }\r\n            updateDependencies(editor, editTargets, importTargets);\r\n        }\r\n        @Override\r\n        public void onFailure(String stdout, String stderr, @Nullable Integer exitCode, @Nullable Throwable throwable) {\r\n            BuckNotification.getInstance(project).showWarningBalloon(\"Could not determine owners for \" + editSourceFile + \" and/or \" + importSourceFile);\r\n            return;\r\n        }\r\n    });\r\n    handler.command().addParameters(\"owner(%s)\", editPath, importPath, \"--output-attributes=deps|srcs|visibility|resources\");\r\n    handler.runInCurrentThreadPostEnd(() -> {\r\n    });\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.autodeps.BuckAddDependencyIntention.queryBuckForTargets",
	"Comment": "queries buck for targets that own the editsourcefile and the importsourcefile.",
	"Method": "void queryBuckForTargets(Editor editor){\r\n    Type type = new TypeToken<Map<String, JsonObject>>() {\r\n    }.getType();\r\n    Map<String, JsonObject> raw = new Gson().fromJson(jsonElement, type);\r\n    List<TargetMetadata> results = new ArrayList();\r\n    for (Entry<String, JsonObject> entry : raw.entrySet()) {\r\n        BuckTarget.parse(entry.getKey()).map(buckTargetLocator::resolve).map(target -> TargetMetadata.from(buckTargetLocator, target, entry.getValue())).ifPresent(results::add);\r\n    }\r\n    return results;\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.autodeps.BuckAddDependencyIntention.queryBuckForTargets",
	"Comment": "queries buck for targets that own the editsourcefile and the importsourcefile.",
	"Method": "void queryBuckForTargets(Editor editor){\r\n    List<TargetMetadata> editTargets = new ArrayList();\r\n    List<TargetMetadata> importTargets = new ArrayList();\r\n    for (TargetMetadata targetMetadata : results) {\r\n        if (targetMetadata.contains(editSourceTarget)) {\r\n            editTargets.add(targetMetadata);\r\n        }\r\n        if (targetMetadata.contains(importSourceTarget)) {\r\n            importTargets.add(targetMetadata);\r\n        }\r\n    }\r\n    updateDependencies(editor, editTargets, importTargets);\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.autodeps.BuckAddDependencyIntention.queryBuckForTargets",
	"Comment": "queries buck for targets that own the editsourcefile and the importsourcefile.",
	"Method": "void queryBuckForTargets(Editor editor){\r\n    BuckNotification.getInstance(project).showWarningBalloon(\"Could not determine owners for \" + editSourceFile + \" and/or \" + importSourceFile);\r\n    return;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.CacheProxy.deleteAllToCacheWriter",
	"Comment": "deletes all of the entries using the cache writer, retaining only the keys that succeeded.",
	"Method": "CacheWriterException deleteAllToCacheWriter(Set<? extends K> keys){\r\n    if (!configuration.isWriteThrough() || keys.isEmpty()) {\r\n        return null;\r\n    }\r\n    List<K> keysToDelete = new ArrayList(keys);\r\n    try {\r\n        writer.deleteAll(keysToDelete);\r\n        return null;\r\n    } catch (CacheWriterException e) {\r\n        keys.removeAll(keysToDelete);\r\n        throw e;\r\n    } catch (RuntimeException e) {\r\n        keys.removeAll(keysToDelete);\r\n        return new CacheWriterException(\"Exception in CacheWriter\", e);\r\n    }\r\n}"
}, {
	"Path": "com.google.common.cache.CacheLoadingTest.disabled_testInvalidateDuringLoading",
	"Comment": "concurrenthashmap does not support this, as it must return back the removed entry",
	"Method": "void disabled_testInvalidateDuringLoading(){\r\n    final CountDownLatch computationStarted = new CountDownLatch(2);\r\n    final CountDownLatch letGetFinishSignal = new CountDownLatch(1);\r\n    final CountDownLatch getFinishedSignal = new CountDownLatch(2);\r\n    final String getKey = \"get\";\r\n    final String refreshKey = \"refresh\";\r\n    final String suffix = \"Suffix\";\r\n    CacheLoader<String, String> computeFunction = new CacheLoader<String, String>() {\r\n        @Override\r\n        public String load(String key) {\r\n            computationStarted.countDown();\r\n            assertTrue(Uninterruptibles.awaitUninterruptibly(letGetFinishSignal, 300, TimeUnit.SECONDS));\r\n            return key + suffix;\r\n        }\r\n    };\r\n    final LoadingCache<String, String> cache = CaffeinatedGuava.build(Caffeine.newBuilder(), computeFunction);\r\n    ConcurrentMap<String, String> map = cache.asMap();\r\n    map.put(refreshKey, refreshKey);\r\n    new Thread(() -> {\r\n        cache.getUnchecked(getKey);\r\n        getFinishedSignal.countDown();\r\n    }).start();\r\n    new Thread(() -> {\r\n        cache.refresh(refreshKey);\r\n        getFinishedSignal.countDown();\r\n    }).start();\r\n    assertTrue(computationStarted.await(300, TimeUnit.SECONDS));\r\n    cache.invalidate(getKey);\r\n    cache.invalidate(refreshKey);\r\n    assertFalse(map.containsKey(getKey));\r\n    assertFalse(map.containsKey(refreshKey));\r\n    letGetFinishSignal.countDown();\r\n    assertTrue(getFinishedSignal.await(300, TimeUnit.SECONDS));\r\n    checkNothingLogged();\r\n    assertEquals(2, cache.size());\r\n    assertEquals(getKey + suffix, map.get(getKey));\r\n    assertEquals(refreshKey + suffix, map.get(refreshKey));\r\n    assertEquals(2, cache.size());\r\n}"
}, {
	"Path": "com.google.common.cache.CacheLoadingTest.disabled_testInvalidateDuringLoading",
	"Comment": "concurrenthashmap does not support this, as it must return back the removed entry",
	"Method": "void disabled_testInvalidateDuringLoading(){\r\n    computationStarted.countDown();\r\n    assertTrue(Uninterruptibles.awaitUninterruptibly(letGetFinishSignal, 300, TimeUnit.SECONDS));\r\n    return key + suffix;\r\n}"
}, {
	"Path": "org.apache.commons.cli.HelpFormatter.renderWrappedText",
	"Comment": "render the specified text and return the rendered optionsin a stringbuffer.",
	"Method": "StringBuffer renderWrappedText(StringBuffer sb,int width,int nextLineTabStop,String text){\r\n    int pos = findWrapPos(text, width, 0);\r\n    if (pos == -1) {\r\n        sb.append(rtrim(text));\r\n        return sb;\r\n    }\r\n    sb.append(rtrim(text.substring(0, pos))).append(getNewLine());\r\n    if (nextLineTabStop >= width) {\r\n        nextLineTabStop = 1;\r\n    }\r\n    final String padding = createPadding(nextLineTabStop);\r\n    while (true) {\r\n        text = padding + text.substring(pos).trim();\r\n        pos = findWrapPos(text, width, 0);\r\n        if (pos == -1) {\r\n            sb.append(text);\r\n            return sb;\r\n        }\r\n        if (text.length() > width && pos == nextLineTabStop - 1) {\r\n            pos = width;\r\n        }\r\n        sb.append(rtrim(text.substring(0, pos))).append(getNewLine());\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.getFeatureCount",
	"Comment": "returns number of features with weight above a certain threshold.",
	"Method": "int getFeatureCount(double threshold,boolean useMagnitude,int getFeatureCount,Set<L> labels,double threshold,boolean useMagnitude){\r\n    if (labels != null) {\r\n        Set<Integer> iLabels = getLabelIndices(labels);\r\n        return getFeatureCountLabelIndices(iLabels, threshold, useMagnitude);\r\n    } else {\r\n        return getFeatureCount(threshold, useMagnitude);\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.MethodVisitor.visitFieldInsn",
	"Comment": "visits a field instruction. a field instruction is an instruction thatloads or stores the value of a field of an object.",
	"Method": "void visitFieldInsn(int opcode,String owner,String name,String desc){\r\n    if (mv != null) {\r\n        mv.visitFieldInsn(opcode, owner, name, desc);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpec.withLocalItem",
	"Comment": "returns an instance that is identical to this one except that thelocal variable is as specified in the parameter.",
	"Method": "RegisterSpec withLocalItem(LocalItem local){\r\n    if ((this.local == local) || ((this.local != null) && this.local.equals(local))) {\r\n        return this;\r\n    }\r\n    return makeLocalOptional(reg, type, local);\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.md.RuleBasedCorefMentionFinder.findMentions",
	"Comment": "main method of mention detection. extract all np, prp or ne, and filter out by manually written patterns.",
	"Method": "List<List<Mention>> findMentions(Annotation doc,Dictionaries dict,Properties props){\r\n    List<List<Mention>> predictedMentions = new ArrayList();\r\n    Set<String> neStrings = Generics.newHashSet();\r\n    List<Set<IntPair>> mentionSpanSetList = Generics.newArrayList();\r\n    List<CoreMap> sentences = doc.get(CoreAnnotations.SentencesAnnotation.class);\r\n    for (CoreMap s : sentences) {\r\n        List<Mention> mentions = new ArrayList();\r\n        predictedMentions.add(mentions);\r\n        Set<IntPair> mentionSpanSet = Generics.newHashSet();\r\n        Set<IntPair> namedEntitySpanSet = Generics.newHashSet();\r\n        extractPremarkedEntityMentions(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        extractNamedEntityMentions(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        extractNPorPRP(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        extractEnumerations(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        addNamedEntityStrings(s, neStrings, namedEntitySpanSet);\r\n        mentionSpanSetList.add(mentionSpanSet);\r\n    }\r\n    if (CorefProperties.liberalMD(props)) {\r\n        extractNamedEntityModifiers(sentences, mentionSpanSetList, predictedMentions, neStrings);\r\n    }\r\n    for (int i = 0, sz = sentences.size(); i < sz; i++) {\r\n        findHead(sentences.get(i), predictedMentions.get(i));\r\n        setBarePlural(predictedMentions.get(i));\r\n    }\r\n    if (lang == Locale.ENGLISH && !CorefProperties.liberalMD(props)) {\r\n        removeSpuriousMentionsEn(doc, predictedMentions, dict);\r\n    } else if (lang == Locale.CHINESE) {\r\n        if (CorefProperties.liberalMD(props)) {\r\n            removeSpuriousMentionsZhSimple(doc, predictedMentions, dict);\r\n        } else {\r\n            removeSpuriousMentionsZh(doc, predictedMentions, dict, CorefProperties.removeNestedMentions(props));\r\n        }\r\n    }\r\n    return predictedMentions;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.tinycache.TinyCachePolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new TinyCachePolicy(config));\r\n}"
}, {
	"Path": "com.android.dx.util.ByteArrayAnnotatedOutput.throwBounds",
	"Comment": "throws the excpetion for when an attempt is made to write past theend of the instance.",
	"Method": "void throwBounds(){\r\n    throw new IndexOutOfBoundsException(\"attempt to write past the end\");\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.newNameTypeItem",
	"Comment": "adds a name and type to the constant pool of the class being build. doesnothing if the constant pool already contains a similar item.",
	"Method": "Item newNameTypeItem(String name,String desc){\r\n    key2.set(NAME_TYPE, name, desc, null);\r\n    Item result = get(key2);\r\n    if (result == null) {\r\n        put122(NAME_TYPE, newUTF8(name), newUTF8(desc));\r\n        result = new Item(index++, key2);\r\n        put(result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.DoubleMetaphone.doubleMetaphone",
	"Comment": "encode a value with double metaphone, optionally using the alternate encoding.",
	"Method": "String doubleMetaphone(String value,String doubleMetaphone,String value,boolean alternate){\r\n    value = cleanInput(value);\r\n    if (value == null) {\r\n        return null;\r\n    }\r\n    final boolean slavoGermanic = isSlavoGermanic(value);\r\n    int index = isSilentStart(value) ? 1 : 0;\r\n    final DoubleMetaphoneResult result = new DoubleMetaphoneResult(this.getMaxCodeLen());\r\n    while (!result.isComplete() && index <= value.length() - 1) {\r\n        switch(value.charAt(index)) {\r\n            case 'A':\r\n            case 'E':\r\n            case 'I':\r\n            case 'O':\r\n            case 'U':\r\n            case 'Y':\r\n                index = handleAEIOUY(result, index);\r\n                break;\r\n            case 'B':\r\n                result.append('P');\r\n                index = charAt(value, index + 1) == 'B' ? index + 2 : index + 1;\r\n                break;\r\n            case '?':\r\n                result.append('S');\r\n                index++;\r\n                break;\r\n            case 'C':\r\n                index = handleC(value, result, index);\r\n                break;\r\n            case 'D':\r\n                index = handleD(value, result, index);\r\n                break;\r\n            case 'F':\r\n                result.append('F');\r\n                index = charAt(value, index + 1) == 'F' ? index + 2 : index + 1;\r\n                break;\r\n            case 'G':\r\n                index = handleG(value, result, index, slavoGermanic);\r\n                break;\r\n            case 'H':\r\n                index = handleH(value, result, index);\r\n                break;\r\n            case 'J':\r\n                index = handleJ(value, result, index, slavoGermanic);\r\n                break;\r\n            case 'K':\r\n                result.append('K');\r\n                index = charAt(value, index + 1) == 'K' ? index + 2 : index + 1;\r\n                break;\r\n            case 'L':\r\n                index = handleL(value, result, index);\r\n                break;\r\n            case 'M':\r\n                result.append('M');\r\n                index = conditionM0(value, index) ? index + 2 : index + 1;\r\n                break;\r\n            case 'N':\r\n                result.append('N');\r\n                index = charAt(value, index + 1) == 'N' ? index + 2 : index + 1;\r\n                break;\r\n            case '?':\r\n                result.append('N');\r\n                index++;\r\n                break;\r\n            case 'P':\r\n                index = handleP(value, result, index);\r\n                break;\r\n            case 'Q':\r\n                result.append('K');\r\n                index = charAt(value, index + 1) == 'Q' ? index + 2 : index + 1;\r\n                break;\r\n            case 'R':\r\n                index = handleR(value, result, index, slavoGermanic);\r\n                break;\r\n            case 'S':\r\n                index = handleS(value, result, index, slavoGermanic);\r\n                break;\r\n            case 'T':\r\n                index = handleT(value, result, index);\r\n                break;\r\n            case 'V':\r\n                result.append('F');\r\n                index = charAt(value, index + 1) == 'V' ? index + 2 : index + 1;\r\n                break;\r\n            case 'W':\r\n                index = handleW(value, result, index);\r\n                break;\r\n            case 'X':\r\n                index = handleX(value, result, index);\r\n                break;\r\n            case 'Z':\r\n                index = handleZ(value, result, index, slavoGermanic);\r\n                break;\r\n            default:\r\n                index++;\r\n                break;\r\n        }\r\n    }\r\n    return alternate ? result.getAlternate() : result.getPrimary();\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.MultifactorAuthenticationUtils.validateEventIdForMatchingTransitionInContext",
	"Comment": "validate event id for matching transition in context event.",
	"Method": "Event validateEventIdForMatchingTransitionInContext(String eventId,Optional<RequestContext> context,Map<String, Object> attributes){\r\n    val attributesMap = new LocalAttributeMap<Object>(attributes);\r\n    val event = new Event(eventId, eventId, attributesMap);\r\n    return context.map(ctx -> {\r\n        val def = ctx.getMatchingTransition(event.getId());\r\n        if (def == null) {\r\n            throw new AuthenticationException(\"Transition definition cannot be found for event \" + event.getId());\r\n        }\r\n        return event;\r\n    }).orElse(event);\r\n}"
}, {
	"Path": "org.apache.commons.codec.net.BCodec.decode",
	"Comment": "decodes a base64 object into its original form. escaped characters are converted back to their originalrepresentation.",
	"Method": "String decode(String value,Object decode,Object value){\r\n    if (value == null) {\r\n        return null;\r\n    } else if (value instanceof String) {\r\n        return decode((String) value);\r\n    } else {\r\n        throw new DecoderException(\"Objects of type \" + value.getClass().getName() + \" cannot be decoded using BCodec\");\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.CorefRules.antecedentMatchesMentionSpeakerAnnotation",
	"Comment": "the antecedent matches the speaker annotation found in the mention",
	"Method": "boolean antecedentMatchesMentionSpeakerAnnotation(Mention mention,Mention ant,Document document){\r\n    if (mention.headWord == null) {\r\n        return false;\r\n    }\r\n    String speaker = mention.headWord.get(CoreAnnotations.SpeakerAnnotation.class);\r\n    if (speaker == null) {\r\n        return false;\r\n    }\r\n    SpeakerInfo speakerInfo = (document != null) ? document.getSpeakerInfo(speaker) : null;\r\n    if (speakerInfo != null) {\r\n        return (mentionMatchesSpeaker(ant, speakerInfo, false));\r\n    }\r\n    if (speaker.indexOf(\" \") >= 0) {\r\n        for (String s : WHITESPACE_PATTERN.split(speaker)) {\r\n            if (ant.headString.equalsIgnoreCase(s))\r\n                return true;\r\n        }\r\n    } else {\r\n        if (ant.headString.equalsIgnoreCase(speaker))\r\n            return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.objectweb.asm.TypeReference.newTypeArgumentReference",
	"Comment": "returns a reference to the type of a type argument in a constructor ormethod call or reference.",
	"Method": "TypeReference newTypeArgumentReference(int sort,int argIndex){\r\n    return new TypeReference((sort << 24) | argIndex);\r\n}"
}, {
	"Path": "edu.stanford.nlp.fsm.TransducerGraph.createGraphFromPaths",
	"Comment": "if markovorder is zero, we always transition back to the start stateif markovorder is negative, we assume that it is infinite",
	"Method": "TransducerGraph createGraphFromPaths(List paths,int markovOrder,TransducerGraph createGraphFromPaths,ClassicCounter<List<T>> pathCounter,int markovOrder){\r\n    TransducerGraph graph = new TransducerGraph();\r\n    for (List<T> path : pathCounter.keySet()) {\r\n        double count = pathCounter.getCount(path);\r\n        addOnePathToGraph(path, count, markovOrder, graph);\r\n    }\r\n    return graph;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.LocalVariableInfo.setStarts",
	"Comment": "sets the register set associated with the start of the block withthe given label.",
	"Method": "void setStarts(int label,RegisterSpecSet specs){\r\n    throwIfImmutable();\r\n    if (specs == null) {\r\n        throw new NullPointerException(\"specs == null\");\r\n    }\r\n    try {\r\n        blockStarts[label] = specs;\r\n    } catch (ArrayIndexOutOfBoundsException ex) {\r\n        throw new IllegalArgumentException(\"bogus label\");\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpecList.specForRegister",
	"Comment": "returns a registerspec in this list that uses the specified register,or null if there is none in this list.",
	"Method": "RegisterSpec specForRegister(int reg){\r\n    int sz = size();\r\n    for (int i = 0; i < sz; i++) {\r\n        RegisterSpec rs;\r\n        rs = get(i);\r\n        if (rs.getReg() == reg) {\r\n            return rs;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.evicts",
	"Comment": "returns if the cache evicts entries due to a maximum size or weight threshold.",
	"Method": "boolean evicts(){\r\n    return false;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.getNumWeights",
	"Comment": "returns the total number of weights associated with this classifier.",
	"Method": "int getNumWeights(){\r\n    if (weights == null)\r\n        return 0;\r\n    int numWeights = 0;\r\n    for (double[] wts : weights) {\r\n        numWeights += wts.length;\r\n    }\r\n    return numWeights;\r\n}"
}, {
	"Path": "org.apereo.cas.support.events.listener.CasConfigurationEventListener.handleRefreshEvent",
	"Comment": "handle refresh event when issued to this cas server locally.",
	"Method": "void handleRefreshEvent(EnvironmentChangeEvent event){\r\n    LOGGER.trace(\"Received event [{}]\", event);\r\n    rebind();\r\n}"
}, {
	"Path": "com.android.dx.ssa.LocalVariableInfo.setStarts",
	"Comment": "sets the register set associated with the start of the block withthe given index.",
	"Method": "void setStarts(int index,RegisterSpecSet specs){\r\n    throwIfImmutable();\r\n    if (specs == null) {\r\n        throw new NullPointerException(\"specs == null\");\r\n    }\r\n    try {\r\n        blockStarts[index] = specs;\r\n    } catch (ArrayIndexOutOfBoundsException ex) {\r\n        throw new IllegalArgumentException(\"bogus index\");\r\n    }\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.util.FileFinder.combine",
	"Comment": "combines prefixes, base, and suffixes to create a set of file names.",
	"Method": "ImmutableSet<String> combine(Set<String> prefixes,String base,Set<String> suffixes){\r\n    ImmutableSet<String> suffixedSet;\r\n    if (suffixes == null || suffixes.isEmpty()) {\r\n        suffixedSet = ImmutableSet.of(base);\r\n    } else {\r\n        ImmutableSet.Builder<String> suffixedBuilder = ImmutableSet.builder();\r\n        for (String suffix : suffixes) {\r\n            suffixedBuilder.add(base + suffix);\r\n        }\r\n        suffixedSet = suffixedBuilder.build();\r\n    }\r\n    if (prefixes == null || prefixes.isEmpty()) {\r\n        return suffixedSet;\r\n    } else {\r\n        ImmutableSet.Builder<String> builder = ImmutableSet.builder();\r\n        for (String prefix : prefixes) {\r\n            for (String suffix : suffixedSet) {\r\n                builder.add(prefix + suffix);\r\n            }\r\n        }\r\n        return builder.build();\r\n    }\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMap8Test.testContainsAll",
	"Comment": "keyset.containsall returns true for collections with subset of elements",
	"Method": "void testContainsAll(){\r\n    Collection full = populatedSet(3);\r\n    assertTrue(full.containsAll(Arrays.asList()));\r\n    assertTrue(full.containsAll(Arrays.asList(one)));\r\n    assertTrue(full.containsAll(Arrays.asList(one, two)));\r\n    assertFalse(full.containsAll(Arrays.asList(one, two, six)));\r\n    assertFalse(full.containsAll(Arrays.asList(six)));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.expireAfterCreate",
	"Comment": "returns the expiration time for the entry after being created.",
	"Method": "long expireAfterCreate(K key,V value,Expiry<K, V> expiry,long now){\r\n    if (expiresVariable() && (key != null) && (value != null)) {\r\n        long duration = expiry.expireAfterCreate(key, value, now);\r\n        return isAsync ? (now + duration) : (now + Math.min(duration, MAXIMUM_EXPIRY));\r\n    }\r\n    return 0L;\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaConverter.edgeSplitPredecessors",
	"Comment": "inserts z nodes as new predecessors for every node that has multiplesuccessors and multiple predecessors.",
	"Method": "void edgeSplitPredecessors(SsaMethod result){\r\n    ArrayList<SsaBasicBlock> blocks = result.getBlocks();\r\n    for (int i = blocks.size() - 1; i >= 0; i--) {\r\n        SsaBasicBlock block = blocks.get(i);\r\n        if (nodeNeedsUniquePredecessor(block)) {\r\n            block.insertNewPredecessor();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.Remapper.mapInvokeDynamicMethodName",
	"Comment": "map invokedynamic method name to the new name. subclasses can override.",
	"Method": "String mapInvokeDynamicMethodName(String name,String desc){\r\n    return name;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFCliqueTree.getCalibratedCliqueTree",
	"Comment": "this function assumes a linearcliquepotentialfunction is used for wrapping the weights",
	"Method": "CRFCliqueTree<E> getCalibratedCliqueTree(int[][][] data,List<Index<CRFLabel>> labelIndices,int numClasses,Index<E> classIndex,E backgroundSymbol,CliquePotentialFunction cliquePotentialFunc,double[][][] featureVals,CRFCliqueTree<E> getCalibratedCliqueTree,double[] weights,double wscale,int[][] weightIndices,int[][][] data,List<Index<CRFLabel>> labelIndices,int numClasses,Index<E> classIndex,E backgroundSymbol){\r\n    FactorTable[] factorTables = new FactorTable[data.length];\r\n    FactorTable[] messages = new FactorTable[data.length - 1];\r\n    for (int i = 0; i < data.length; i++) {\r\n        factorTables[i] = getFactorTable(weights, wscale, weightIndices, data[i], labelIndices, numClasses);\r\n        if (i > 0) {\r\n            messages[i - 1] = factorTables[i - 1].sumOutFront();\r\n            factorTables[i].multiplyInFront(messages[i - 1]);\r\n        }\r\n    }\r\n    for (int i = factorTables.length - 2; i >= 0; i--) {\r\n        FactorTable summedOut = factorTables[i + 1].sumOutEnd();\r\n        summedOut.divideBy(messages[i]);\r\n        factorTables[i].multiplyInEnd(summedOut);\r\n    }\r\n    return new CRFCliqueTree(factorTables, classIndex, backgroundSymbol);\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.support.DefaultLdapAccountStateHandler.handleWarning",
	"Comment": "handle an account state warning produced by ldaptive account state machinery.override this method to provide custom warning message handling.",
	"Method": "void handleWarning(AccountState.Warning warning,AuthenticationResponse response,PasswordPolicyConfiguration configuration,List<MessageDescriptor> messages){\r\n    LOGGER.debug(\"Handling account state warning [{}]\", warning);\r\n    if (warning == null) {\r\n        LOGGER.debug(\"Account state warning not defined\");\r\n        return;\r\n    }\r\n    if (warning.getExpiration() != null) {\r\n        val expDate = DateTimeUtils.zonedDateTimeOf(warning.getExpiration());\r\n        val ttl = ZonedDateTime.now(ZoneOffset.UTC).until(expDate, ChronoUnit.DAYS);\r\n        LOGGER.debug(\"Password expires in [{}] days. Expiration warning threshold is [{}] days.\", ttl, configuration.getPasswordWarningNumberOfDays());\r\n        if (configuration.isAlwaysDisplayPasswordExpirationWarning() || ttl < configuration.getPasswordWarningNumberOfDays()) {\r\n            messages.add(new PasswordExpiringWarningMessageDescriptor(\"Password expires in {0} days.\", ttl));\r\n        }\r\n    } else {\r\n        LOGGER.debug(\"No account expiration warning was provided as part of the account state\");\r\n    }\r\n    if (warning.getLoginsRemaining() > 0) {\r\n        messages.add(new DefaultMessageDescriptor(\"password.expiration.loginsRemaining\", \"You have {0} logins remaining before you MUST change your password.\", new Serializable[] { warning.getLoginsRemaining() }));\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.feedback.FeedbackWindowTinyLfuPolicy.onMiss",
	"Comment": "adds the entry to the admission window, evicting if necessary.",
	"Method": "void onMiss(long key){\r\n    Node node = new Node(key, Status.EDEN);\r\n    node.appendToTail(headEden);\r\n    data.put(key, node);\r\n    sizeEden++;\r\n    evict();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.event.EventDispatcher.awaitSynchronous",
	"Comment": "blocks until all of the synchronous listeners have finished processing the events this threadpublished.",
	"Method": "void awaitSynchronous(){\r\n    List<CompletableFuture<Void>> futures = pending.get();\r\n    if (futures.isEmpty()) {\r\n        return;\r\n    }\r\n    try {\r\n        CompletableFuture.allOf(futures.toArray(new CompletableFuture<?>[0])).join();\r\n    } catch (CompletionException e) {\r\n        logger.log(Level.WARNING, null, e);\r\n    } finally {\r\n        futures.clear();\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.handler.support.AbstractUsernamePasswordAuthenticationHandler.matches",
	"Comment": "used in case passwordencoder is used to match raw password with encoded password. mainly for bcrypt password encoders where each encodedpassword is different and we cannot use traditional compare of encoded strings to check if passwords match",
	"Method": "boolean matches(CharSequence charSequence,String password){\r\n    return this.passwordEncoder.matches(charSequence, password);\r\n}"
}, {
	"Path": "com.android.dx.util.FixedSizeList.throwIndex",
	"Comment": "throws the appropriate exception for the given index value.",
	"Method": "Object throwIndex(int n){\r\n    if (n < 0) {\r\n        throw new IndexOutOfBoundsException(\"n < 0\");\r\n    }\r\n    throw new IndexOutOfBoundsException(\"n >= size()\");\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RopMethod.getFirstLabel",
	"Comment": "gets the label for the first block in the method that this listrepresents.",
	"Method": "int getFirstLabel(){\r\n    return firstLabel;\r\n}"
}, {
	"Path": "com.android.dx.util.LabeledList.indexOfLabel",
	"Comment": "gets the index of the first item in the list with the givenlabel, if any.",
	"Method": "int indexOfLabel(int label){\r\n    if (label >= labelToIndex.size()) {\r\n        return -1;\r\n    } else {\r\n        return labelToIndex.get(label);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.AbstractSequenceClassifier.classifyAndWriteViterbiSearchGraph",
	"Comment": "load a test file, run the classifier on it, and then write a viterbi searchgraph for each sequence.",
	"Method": "void classifyAndWriteViterbiSearchGraph(String testFile,String searchGraphPrefix,DocumentReaderAndWriter<IN> readerAndWriter){\r\n    Timing timer = new Timing();\r\n    ObjectBank<List<IN>> documents = makeObjectBankFromFile(testFile, readerAndWriter);\r\n    int numWords = 0;\r\n    int numSentences = 0;\r\n    for (List<IN> doc : documents) {\r\n        DFSA<String, Integer> tagLattice = getViterbiSearchGraph(doc, CoreAnnotations.AnswerAnnotation.class);\r\n        numWords += doc.size();\r\n        PrintWriter latticeWriter = new PrintWriter(new FileOutputStream(searchGraphPrefix + '.' + numSentences + \".wlattice\"));\r\n        PrintWriter vsgWriter = new PrintWriter(new FileOutputStream(searchGraphPrefix + '.' + numSentences + \".lattice\"));\r\n        if (readerAndWriter instanceof LatticeWriter) {\r\n            ((LatticeWriter<IN, String, Integer>) readerAndWriter).printLattice(tagLattice, doc, latticeWriter);\r\n        }\r\n        tagLattice.printAttFsmFormat(vsgWriter);\r\n        latticeWriter.close();\r\n        vsgWriter.close();\r\n        numSentences++;\r\n    }\r\n    long millis = timer.stop();\r\n    double wordspersec = numWords / (((double) millis) / 1000);\r\n    NumberFormat nf = new DecimalFormat(\"0.00\");\r\n    log.info(this.getClass().getName() + \" tagged \" + numWords + \" words in \" + numSentences + \" documents at \" + nf.format(wordspersec) + \" words per second.\");\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.monitorEnter",
	"Comment": "generates the instruction to get the monitor of the top stack value.",
	"Method": "void monitorEnter(){\r\n    mv.visitInsn(Opcodes.MONITORENTER);\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassReader.readAnnotationValue",
	"Comment": "reads a value of an annotation and makes the given visitor visit it.",
	"Method": "int readAnnotationValue(int v,char[] buf,String name,AnnotationVisitor av){\r\n    int i;\r\n    if (av == null) {\r\n        switch(b[v] & 0xFF) {\r\n            case 'e':\r\n                return v + 5;\r\n            case '@':\r\n                return readAnnotationValues(v + 3, buf, true, null);\r\n            case '[':\r\n                return readAnnotationValues(v + 1, buf, false, null);\r\n            default:\r\n                return v + 3;\r\n        }\r\n    }\r\n    switch(b[v++] & 0xFF) {\r\n        case 'I':\r\n        case 'J':\r\n        case 'F':\r\n        case 'D':\r\n            av.visit(name, readConst(readUnsignedShort(v), buf));\r\n            v += 2;\r\n            break;\r\n        case 'B':\r\n            av.visit(name, (byte) readInt(items[readUnsignedShort(v)]));\r\n            v += 2;\r\n            break;\r\n        case 'Z':\r\n            av.visit(name, readInt(items[readUnsignedShort(v)]) == 0 ? Boolean.FALSE : Boolean.TRUE);\r\n            v += 2;\r\n            break;\r\n        case 'S':\r\n            av.visit(name, (short) readInt(items[readUnsignedShort(v)]));\r\n            v += 2;\r\n            break;\r\n        case 'C':\r\n            av.visit(name, (char) readInt(items[readUnsignedShort(v)]));\r\n            v += 2;\r\n            break;\r\n        case 's':\r\n            av.visit(name, readUTF8(v, buf));\r\n            v += 2;\r\n            break;\r\n        case 'e':\r\n            av.visitEnum(name, readUTF8(v, buf), readUTF8(v + 2, buf));\r\n            v += 4;\r\n            break;\r\n        case 'c':\r\n            av.visit(name, Type.getType(readUTF8(v, buf)));\r\n            v += 2;\r\n            break;\r\n        case '@':\r\n            v = readAnnotationValues(v + 2, buf, true, av.visitAnnotation(name, readUTF8(v, buf)));\r\n            break;\r\n        case '[':\r\n            int size = readUnsignedShort(v);\r\n            v += 2;\r\n            if (size == 0) {\r\n                return readAnnotationValues(v - 2, buf, false, av.visitArray(name));\r\n            }\r\n            switch(this.b[v++] & 0xFF) {\r\n                case 'B':\r\n                    byte[] bv = new byte[size];\r\n                    for (i = 0; i < size; i++) {\r\n                        bv[i] = (byte) readInt(items[readUnsignedShort(v)]);\r\n                        v += 3;\r\n                    }\r\n                    av.visit(name, bv);\r\n                    --v;\r\n                    break;\r\n                case 'Z':\r\n                    boolean[] zv = new boolean[size];\r\n                    for (i = 0; i < size; i++) {\r\n                        zv[i] = readInt(items[readUnsignedShort(v)]) != 0;\r\n                        v += 3;\r\n                    }\r\n                    av.visit(name, zv);\r\n                    --v;\r\n                    break;\r\n                case 'S':\r\n                    short[] sv = new short[size];\r\n                    for (i = 0; i < size; i++) {\r\n                        sv[i] = (short) readInt(items[readUnsignedShort(v)]);\r\n                        v += 3;\r\n                    }\r\n                    av.visit(name, sv);\r\n                    --v;\r\n                    break;\r\n                case 'C':\r\n                    char[] cv = new char[size];\r\n                    for (i = 0; i < size; i++) {\r\n                        cv[i] = (char) readInt(items[readUnsignedShort(v)]);\r\n                        v += 3;\r\n                    }\r\n                    av.visit(name, cv);\r\n                    --v;\r\n                    break;\r\n                case 'I':\r\n                    int[] iv = new int[size];\r\n                    for (i = 0; i < size; i++) {\r\n                        iv[i] = readInt(items[readUnsignedShort(v)]);\r\n                        v += 3;\r\n                    }\r\n                    av.visit(name, iv);\r\n                    --v;\r\n                    break;\r\n                case 'J':\r\n                    long[] lv = new long[size];\r\n                    for (i = 0; i < size; i++) {\r\n                        lv[i] = readLong(items[readUnsignedShort(v)]);\r\n                        v += 3;\r\n                    }\r\n                    av.visit(name, lv);\r\n                    --v;\r\n                    break;\r\n                case 'F':\r\n                    float[] fv = new float[size];\r\n                    for (i = 0; i < size; i++) {\r\n                        fv[i] = Float.intBitsToFloat(readInt(items[readUnsignedShort(v)]));\r\n                        v += 3;\r\n                    }\r\n                    av.visit(name, fv);\r\n                    --v;\r\n                    break;\r\n                case 'D':\r\n                    double[] dv = new double[size];\r\n                    for (i = 0; i < size; i++) {\r\n                        dv[i] = Double.longBitsToDouble(readLong(items[readUnsignedShort(v)]));\r\n                        v += 3;\r\n                    }\r\n                    av.visit(name, dv);\r\n                    --v;\r\n                    break;\r\n                default:\r\n                    v = readAnnotationValues(v - 3, buf, false, av.visitArray(name));\r\n            }\r\n    }\r\n    return v;\r\n}"
}, {
	"Path": "org.apereo.cas.util.crypto.CertUtils.isExpired",
	"Comment": "determines whether the given crl is expired by comparing the nextupdate fieldwith a given date.",
	"Method": "boolean isExpired(X509CRL crl,boolean isExpired,X509CRL crl,ZonedDateTime reference){\r\n    return reference.isAfter(DateTimeUtils.zonedDateTimeOf(crl.getNextUpdate()));\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.dumpSorted",
	"Comment": "print all features in the classifier and the weight that they assignto each class. the feature names are printed in sorted order.",
	"Method": "void dumpSorted(){\r\n    Datum<L, F> allFeatures = new BasicDatum(features(), (L) null);\r\n    justificationOf(allFeatures, new PrintWriter(System.err, true), true);\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.POSTaggerAnnotatorITest.testWordsPLAnnotation",
	"Comment": "test that the tagger correctly handles getting a single sentencein the wordsplannotation",
	"Method": "void testWordsPLAnnotation(){\r\n    CoreMap sent = makeSentenceCoreMap(testSentences[0]);\r\n    List<CoreMap> sentences = new ArrayList();\r\n    sentences.add(sent);\r\n    Annotation annotation = new Annotation(shortText);\r\n    annotation.set(CoreAnnotations.SentencesAnnotation.class, sentences);\r\n    tagger.annotate(annotation);\r\n    checkLabels(sent, \"PRP$\", \"NN\", \"VBZ\", \"JJ\", \"CC\", \"JJ\", \".\");\r\n}"
}, {
	"Path": "org.apereo.cas.services.RegisteredServiceConsentPolicy.getExcludedAttributes",
	"Comment": "gets excluded attributes.excludes the set of specified attributes from consent.",
	"Method": "Set<String> getExcludedAttributes(){\r\n    return new LinkedHashSet(0);\r\n}"
}, {
	"Path": "org.objectweb.asm.Label.inSubroutine",
	"Comment": "returns true is this basic block belongs to the given subroutine.",
	"Method": "boolean inSubroutine(long id){\r\n    if ((status & Label.VISITED) != 0) {\r\n        return (srcAndRefPositions[(int) (id >>> 32)] & (int) id) != 0;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.DefaultAuthenticationBuilder.newInstance",
	"Comment": "creates a new builder initialized with data from the given authentication source.",
	"Method": "AuthenticationBuilder newInstance(Authentication source,AuthenticationBuilder newInstance){\r\n    return new DefaultAuthenticationBuilder();\r\n}"
}, {
	"Path": "org.objectweb.asm.Handle.getTag",
	"Comment": "returns the kind of field or method designated by this handle.",
	"Method": "int getTag(){\r\n    return tag;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.hasWriter",
	"Comment": "returns whether this cache notifies a writer when an entry is modified.",
	"Method": "boolean hasWriter(){\r\n    return (writer != CacheWriter.disabledWriter());\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.AuthenticationTransaction.hasCredentialOfType",
	"Comment": "does this authenticationtransaction contain a credential of the given type?",
	"Method": "boolean hasCredentialOfType(Class<? extends Credential> type){\r\n    return getCredentials().stream().anyMatch(type::isInstance);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.Span.contains",
	"Comment": "returns true if i is inside this span.note that the start is inclusive and the end is exclusive.",
	"Method": "boolean contains(Span otherSpan,boolean contains,int i){\r\n    return this.start <= i && i < this.end;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.Simulator.reportStats",
	"Comment": "add the stats to the reporter, print if completed, and stop the simulator.",
	"Method": "void reportStats(PolicyStats stats){\r\n    reporter.add(stats);\r\n    if (--remaining == 0) {\r\n        reporter.print();\r\n        context().stop(self());\r\n        System.out.println(\"Executed in \" + stopwatch);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.services.RegisteredServiceAccessStrategy.getDelegatedAuthenticationPolicy",
	"Comment": "return the delegated authentication policy for this service.",
	"Method": "RegisteredServiceDelegatedAuthenticationPolicy getDelegatedAuthenticationPolicy(){\r\n    return null;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.opt.ClairvoyantPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new ClairvoyantPolicy(config));\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getObjectType",
	"Comment": "returns the java type corresponding to the given internal name.",
	"Method": "Type getObjectType(String internalName){\r\n    char[] buf = internalName.toCharArray();\r\n    return new Type(buf[0] == '[' ? ARRAY : OBJECT, buf, 0, buf.length);\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.DelegatedAuthenticationSAML2ClientLogoutAction.findCurrentClientName",
	"Comment": "finds the current client name from the context, using the pac4j profile manager. it is assumed that the context has previously beenpopulated with the profile.",
	"Method": "String findCurrentClientName(WebContext webContext){\r\n    val pm = Pac4jUtils.getPac4jProfileManager(webContext);\r\n    val profile = (Optional<CommonProfile>) pm.get(true);\r\n    return profile.map(CommonProfile::getClientName).orElse(null);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.BeiderMorseEncoder.isConcat",
	"Comment": "discovers if multiple possible encodings are concatenated.",
	"Method": "boolean isConcat(){\r\n    return this.engine.isConcat();\r\n}"
}, {
	"Path": "org.apache.commons.cli.HelpFormatter.getLongOptSeparator",
	"Comment": "returns the separator displayed between a long option and its value.",
	"Method": "String getLongOptSeparator(){\r\n    return longOptSeparator;\r\n}"
}, {
	"Path": "org.apache.commons.cli.TypeHandler.createNumber",
	"Comment": "create a number from a string. if a . is present, it creates adouble, otherwise a long.",
	"Method": "Number createNumber(String str){\r\n    try {\r\n        if (str.indexOf('.') != -1) {\r\n            return Double.valueOf(str);\r\n        }\r\n        return Long.valueOf(str);\r\n    } catch (NumberFormatException e) {\r\n        throw new ParseException(e.getMessage());\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.evictFromEden",
	"Comment": "evicts entries from the eden space into the main space while the eden size exceeds a maximum.",
	"Method": "int evictFromEden(){\r\n    int candidates = 0;\r\n    Node<K, V> node = accessOrderEdenDeque().peek();\r\n    while (edenWeightedSize() > edenMaximum()) {\r\n        if (node == null) {\r\n            break;\r\n        }\r\n        Node<K, V> next = node.getNextInAccessOrder();\r\n        if (node.getWeight() != 0) {\r\n            node.makeMainProbation();\r\n            accessOrderEdenDeque().remove(node);\r\n            accessOrderProbationDeque().add(node);\r\n            candidates++;\r\n            lazySetEdenWeightedSize(edenWeightedSize() - node.getPolicyWeight());\r\n        }\r\n        node = next;\r\n    }\r\n    return candidates;\r\n}"
}, {
	"Path": "edu.stanford.nlp.parser.lexparser.LexicalizedParserITest.testParseString",
	"Comment": "this method tests a very basic string and a few different resultsthat parsing that string should come up with.",
	"Method": "void testParseString(){\r\n    Tree results = englishParser.parse(\"My dog likes to eat yoghurt.\");\r\n    compareOutput(results, false, \"My/PRP$ dog/NN likes/VBZ to/TO eat/VB yoghurt/NN ./.\", \"(ROOT (S (NP (PRP$ My) (NN dog)) (VP (VBZ likes) (S (VP (TO to) (VP (VB eat) (NP (NN yoghurt)))))) (. .)))\", \"nmod:poss(dog-2, My-1) nsubj(likes-3, dog-2) root(ROOT-0, likes-3) mark(eat-5, to-4) xcomp(likes-3, eat-5) dobj(eat-5, yoghurt-6)\", \"nmod:poss(dog-2, My-1) nsubj(likes-3, dog-2) nsubj:xsubj(eat-5, dog-2) root(ROOT-0, likes-3) mark(eat-5, to-4) xcomp(likes-3, eat-5) dobj(eat-5, yoghurt-6)\");\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.Async.getIfReady",
	"Comment": "returns the current value or null if either not done or failed.",
	"Method": "V getIfReady(CompletableFuture<V> future){\r\n    return isReady(future) ? future.join() : null;\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.TokensRegexNERAnnotatorITest.testTokensRegexCustomAnnotate",
	"Comment": "tests for tokensregexner annotator annotating other fields with custom key mapping",
	"Method": "void testTokensRegexCustomAnnotate(){\r\n    Properties props = new Properties();\r\n    props.setProperty(REGEX_ANNOTATOR_NAME + \".mapping.header\", \"pattern,test,overwrite,priority,group\");\r\n    props.setProperty(REGEX_ANNOTATOR_NAME + \".mapping.field.test\", \"edu.stanford.nlp.pipeline.TokensRegexNERAnnotatorITest$TestAnnotation\");\r\n    String[][] regexes = new String[][] { new String[] { \"test\", \"TEST\", \"\", \"0\" } };\r\n    Annotator annotatorCased = getTokensRegexNerAnnotator(props, regexes, true);\r\n    String str = \"Marking all test as test\";\r\n    Annotation document = createDocument(str);\r\n    annotatorCased.annotate(document);\r\n    List<CoreLabel> tokens = document.get(CoreAnnotations.TokensAnnotation.class);\r\n    checkTags(tokens, CoreAnnotations.TextAnnotation.class, \"Marking\", \"all\", \"test\", \"as\", \"test\");\r\n    checkTags(tokens, TestAnnotation.class, null, null, \"TEST\", null, \"TEST\");\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.WindowTinyLfuPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    WindowTinyLfuSettings settings = new WindowTinyLfuSettings(config);\r\n    return settings.percentMain().stream().map(percentMain -> new WindowTinyLfuPolicy(percentMain, settings)).collect(toSet());\r\n}"
}, {
	"Path": "org.apache.commons.cli.CommandLine.iterator",
	"Comment": "returns an iterator over the option members of commandline.",
	"Method": "Iterator<Option> iterator(){\r\n    return options.iterator();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.management.JCacheStatisticsMXBean.recordMisses",
	"Comment": "records cache misses. this should be called when a cache request returns a value that was notfound in the cache.",
	"Method": "void recordMisses(long count){\r\n    if (enabled) {\r\n        misses.add(count);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEntityMention.after",
	"Comment": "verifies if this mention appears after the parameter in textual order",
	"Method": "boolean after(AceEntityMention em){\r\n    if (mHead.getByteStart() > em.mHead.getByteEnd())\r\n        return true;\r\n    return false;\r\n}"
}, {
	"Path": "com.android.dx.util.TwoColumnOutput.flush",
	"Comment": "flushes the output. if there are more lines of pending output in onecolumn, then the other column will get filled with blank lines.",
	"Method": "void flush(){\r\n    try {\r\n        appendNewlineIfNecessary(leftBuf, leftColumn);\r\n        appendNewlineIfNecessary(rightBuf, rightColumn);\r\n        outputFullLines();\r\n        flushLeft();\r\n        flushRight();\r\n    } catch (IOException ex) {\r\n        throw new RuntimeException(ex);\r\n    }\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.build.BuckCommandHandler.notifyLines",
	"Comment": "notify listeners for each complete line. note that in the case of stderr, the last line issaved.",
	"Method": "void notifyLines(Key outputType,Iterable<String> lines){\r\n    if (outputType == ProcessOutputTypes.STDERR) {\r\n        StringBuilder stderr = new StringBuilder();\r\n        for (String line : lines) {\r\n            if (CHARACTER_DIGITS_PATTERN.matcher(line).matches()) {\r\n                stderr.append(line);\r\n            }\r\n        }\r\n        if (stderr.length() != 0) {\r\n            buckModule.getBuckEventsConsumer().consumeConsoleEvent(stderr.toString());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.parser.lexparser.BuildLexicalizedParserITest.testBuildEnglishParser",
	"Comment": "this tests that building and running a simple english parsermodel works correctly.",
	"Method": "void testBuildEnglishParser(){\r\n    for (String englishCommandLine : englishCommandLines) {\r\n        ParserTestCase test = ParserTestCase.buildOneTreebankTestCase(englishCommandLine, englishOneTree, englishThreeTrees);\r\n        buildAndTest(test);\r\n    }\r\n    for (String englishCommandLine : englishTwoTreebanks) {\r\n        ParserTestCase test = ParserTestCase.buildTwoTreebankTestCase(englishCommandLine, englishOneTree, englishSecondTree, englishThreeTrees);\r\n        buildAndTest(test);\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.SoundexUtils.clean",
	"Comment": "cleans up the input string before soundex processing by only returningupper case letters.",
	"Method": "String clean(String str){\r\n    if (str == null || str.length() == 0) {\r\n        return str;\r\n    }\r\n    final int len = str.length();\r\n    final char[] chars = new char[len];\r\n    int count = 0;\r\n    for (int i = 0; i < len; i++) {\r\n        if (Character.isLetter(str.charAt(i))) {\r\n            chars[count++] = str.charAt(i);\r\n        }\r\n    }\r\n    if (count == len) {\r\n        return str.toUpperCase(java.util.Locale.ENGLISH);\r\n    }\r\n    return new String(chars, 0, count).toUpperCase(java.util.Locale.ENGLISH);\r\n}"
}, {
	"Path": "org.objectweb.asm.Handler.remove",
	"Comment": "removes the range between start and end from the given exceptionhandlers.",
	"Method": "Handler remove(Handler h,Label start,Label end){\r\n    if (h == null) {\r\n        return null;\r\n    } else {\r\n        h.next = remove(h.next, start, end);\r\n    }\r\n    int hstart = h.start.position;\r\n    int hend = h.end.position;\r\n    int s = start.position;\r\n    int e = end == null ? Integer.MAX_VALUE : end.position;\r\n    if (s < hend && e > hstart) {\r\n        if (s <= hstart) {\r\n            if (e >= hend) {\r\n                h = h.next;\r\n            } else {\r\n                h.start = end;\r\n            }\r\n        } else if (e >= hend) {\r\n            h.end = start;\r\n        } else {\r\n            Handler g = new Handler();\r\n            g.start = end;\r\n            g.end = h.end;\r\n            g.handler = h.handler;\r\n            g.desc = h.desc;\r\n            g.type = h.type;\r\n            g.next = h.next;\r\n            h.end = start;\r\n            h.next = g;\r\n        }\r\n    }\r\n    return h;\r\n}"
}, {
	"Path": "org.apereo.cas.config.EhcacheTicketRegistryConfiguration.ehCacheCacheManager",
	"Comment": "this bean is used by the spring boot cache actuator which spring boot admin can use to clear caches.actuator needs to be exposed in order for this bean to be used.",
	"Method": "EhCacheCacheManager ehCacheCacheManager(CacheManager ehcacheTicketCacheManager){\r\n    return new EhCacheCacheManager(ehcacheTicketCacheManager);\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassReader.readLabel",
	"Comment": "returns the label corresponding to the given offset. the defaultimplementation of this method creates a label for the given offset if ithas not been already created.",
	"Method": "Label readLabel(int offset,Label[] labels){\r\n    if (labels[offset] == null) {\r\n        labels[offset] = new Label();\r\n    }\r\n    return labels[offset];\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaConverter.testPhiPlacement",
	"Comment": "returns an ssa represention with only the steps through thephi placement run.",
	"Method": "SsaMethod testPhiPlacement(RopMethod rmeth,int paramWidth,boolean isStatic){\r\n    SsaMethod result;\r\n    result = SsaMethod.newFromRopMethod(rmeth, paramWidth, isStatic);\r\n    edgeSplit(result);\r\n    LocalVariableInfo localInfo = LocalVariableExtractor.extract(result);\r\n    placePhiFunctions(result, localInfo, 0);\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.surrogate.SurrogateAuthenticationService.canAuthenticateAs",
	"Comment": "checks whether a principal can authenticate as a surrogate user.",
	"Method": "boolean canAuthenticateAs(String surrogate,Principal principal,Service service){\r\n    return false;\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.util.BuckCellFinder.findBuckTargetFile",
	"Comment": "finds the buck file for the given target, starting from the given sourcefile.",
	"Method": "Optional<VirtualFile> findBuckTargetFile(VirtualFile sourceFile,String target){\r\n    Matcher matcher = BUCK_CELL_PATH_PATTERN.matcher(target);\r\n    if (!matcher.matches()) {\r\n        return Optional.empty();\r\n    }\r\n    String targetName = matcher.group(\"target\");\r\n    if (targetName == null) {\r\n        return Optional.empty();\r\n    }\r\n    String cellName = matcher.group(\"cell\");\r\n    String cellPath = matcher.group(\"path\");\r\n    return findBuckCell(sourceFile, cellName).flatMap(cell -> {\r\n        return Optional.ofNullable(pathMacroExpander.apply(cell.getRoot())).map(s -> sourceFile.getFileSystem().findFileByPath(s)).map(root -> VfsUtil.findRelativeFile(cellPath, root)).map(sub -> VfsUtil.findRelativeFile(cell.getBuildFileName(), sub)).filter(VirtualFile::exists);\r\n    });\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.cast",
	"Comment": "generates the instructions to cast a numerical value from one type toanother.",
	"Method": "void cast(Type from,Type to){\r\n    if (from != to) {\r\n        if (from == Type.DOUBLE_TYPE) {\r\n            if (to == Type.FLOAT_TYPE) {\r\n                mv.visitInsn(Opcodes.D2F);\r\n            } else if (to == Type.LONG_TYPE) {\r\n                mv.visitInsn(Opcodes.D2L);\r\n            } else {\r\n                mv.visitInsn(Opcodes.D2I);\r\n                cast(Type.INT_TYPE, to);\r\n            }\r\n        } else if (from == Type.FLOAT_TYPE) {\r\n            if (to == Type.DOUBLE_TYPE) {\r\n                mv.visitInsn(Opcodes.F2D);\r\n            } else if (to == Type.LONG_TYPE) {\r\n                mv.visitInsn(Opcodes.F2L);\r\n            } else {\r\n                mv.visitInsn(Opcodes.F2I);\r\n                cast(Type.INT_TYPE, to);\r\n            }\r\n        } else if (from == Type.LONG_TYPE) {\r\n            if (to == Type.DOUBLE_TYPE) {\r\n                mv.visitInsn(Opcodes.L2D);\r\n            } else if (to == Type.FLOAT_TYPE) {\r\n                mv.visitInsn(Opcodes.L2F);\r\n            } else {\r\n                mv.visitInsn(Opcodes.L2I);\r\n                cast(Type.INT_TYPE, to);\r\n            }\r\n        } else {\r\n            if (to == Type.BYTE_TYPE) {\r\n                mv.visitInsn(Opcodes.I2B);\r\n            } else if (to == Type.CHAR_TYPE) {\r\n                mv.visitInsn(Opcodes.I2C);\r\n            } else if (to == Type.DOUBLE_TYPE) {\r\n                mv.visitInsn(Opcodes.I2D);\r\n            } else if (to == Type.FLOAT_TYPE) {\r\n                mv.visitInsn(Opcodes.I2F);\r\n            } else if (to == Type.LONG_TYPE) {\r\n                mv.visitInsn(Opcodes.I2L);\r\n            } else if (to == Type.SHORT_TYPE) {\r\n                mv.visitInsn(Opcodes.I2S);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.util.LdapUtils.newLdaptiveSearchEntryResolver",
	"Comment": "new dn resolver entry resolver.creates the necessary search entry resolver.",
	"Method": "EntryResolver newLdaptiveSearchEntryResolver(AbstractLdapAuthenticationProperties l,PooledConnectionFactory factory){\r\n    if (StringUtils.isBlank(l.getBaseDn())) {\r\n        throw new IllegalArgumentException(\"To create a search entry resolver, base dn cannot be empty/blank \");\r\n    }\r\n    if (StringUtils.isBlank(l.getSearchFilter())) {\r\n        throw new IllegalArgumentException(\"To create a search entry resolver, user filter cannot be empty/blank\");\r\n    }\r\n    val entryResolver = new PooledSearchEntryResolver();\r\n    entryResolver.setBaseDn(l.getBaseDn());\r\n    entryResolver.setUserFilter(l.getSearchFilter());\r\n    entryResolver.setSubtreeSearch(l.isSubtreeSearch());\r\n    entryResolver.setConnectionFactory(factory);\r\n    entryResolver.setAllowMultipleEntries(l.isAllowMultipleEntries());\r\n    if (StringUtils.isNotBlank(l.getDerefAliases())) {\r\n        entryResolver.setDerefAliases(DerefAliases.valueOf(l.getDerefAliases()));\r\n    }\r\n    val handlers = new ArrayList<SearchEntryHandler>();\r\n    l.getSearchEntryHandlers().forEach(h -> {\r\n        switch(h.getType()) {\r\n            case CASE_CHANGE:\r\n                val eh = new CaseChangeEntryHandler();\r\n                val caseChange = h.getCaseChange();\r\n                eh.setAttributeNameCaseChange(CaseChangeEntryHandler.CaseChange.valueOf(caseChange.getAttributeNameCaseChange()));\r\n                eh.setAttributeNames(caseChange.getAttributeNames().toArray(ArrayUtils.EMPTY_STRING_ARRAY));\r\n                eh.setAttributeValueCaseChange(CaseChangeEntryHandler.CaseChange.valueOf(caseChange.getAttributeValueCaseChange()));\r\n                eh.setDnCaseChange(CaseChangeEntryHandler.CaseChange.valueOf(caseChange.getDnCaseChange()));\r\n                handlers.add(eh);\r\n                break;\r\n            case DN_ATTRIBUTE_ENTRY:\r\n                val ehd = new DnAttributeEntryHandler();\r\n                val dnAttribute = h.getDnAttribute();\r\n                ehd.setAddIfExists(dnAttribute.isAddIfExists());\r\n                ehd.setDnAttributeName(dnAttribute.getDnAttributeName());\r\n                handlers.add(ehd);\r\n                break;\r\n            case MERGE:\r\n                val ehm = new MergeAttributeEntryHandler();\r\n                val mergeAttribute = h.getMergeAttribute();\r\n                ehm.setAttributeNames(mergeAttribute.getAttributeNames().toArray(ArrayUtils.EMPTY_STRING_ARRAY));\r\n                ehm.setMergeAttributeName(mergeAttribute.getMergeAttributeName());\r\n                handlers.add(ehm);\r\n                break;\r\n            case OBJECT_GUID:\r\n                handlers.add(new ObjectGuidHandler());\r\n                break;\r\n            case OBJECT_SID:\r\n                handlers.add(new ObjectSidHandler());\r\n                break;\r\n            case PRIMARY_GROUP:\r\n                val ehp = new PrimaryGroupIdHandler();\r\n                val primaryGroupId = h.getPrimaryGroupId();\r\n                ehp.setBaseDn(primaryGroupId.getBaseDn());\r\n                ehp.setGroupFilter(primaryGroupId.getGroupFilter());\r\n                handlers.add(ehp);\r\n                break;\r\n            case RANGE_ENTRY:\r\n                handlers.add(new RangeEntryHandler());\r\n                break;\r\n            case RECURSIVE_ENTRY:\r\n                val recursive = h.getRecursive();\r\n                handlers.add(new RecursiveEntryHandler(recursive.getSearchAttribute(), recursive.getMergeAttributes().toArray(ArrayUtils.EMPTY_STRING_ARRAY)));\r\n                break;\r\n            default:\r\n                break;\r\n        }\r\n    });\r\n    if (!handlers.isEmpty()) {\r\n        LOGGER.debug(\"Search entry handlers defined for the entry resolver of [{}] are [{}]\", l.getLdapUrl(), handlers);\r\n        entryResolver.setSearchEntryHandlers(handlers.toArray(new SearchEntryHandler[] {}));\r\n    }\r\n    if (l.isFollowReferrals()) {\r\n        entryResolver.setReferralHandler(new SearchReferralHandler());\r\n    }\r\n    return entryResolver;\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getDimensions",
	"Comment": "returns the number of dimensions of this array type. this method shouldonly be used for an array type.",
	"Method": "int getDimensions(){\r\n    int i = 1;\r\n    while (buf[off + i] == '[') {\r\n        ++i;\r\n    }\r\n    return i;\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMap8Test.testRemoveAll",
	"Comment": "keyset.removeall removes all elements from the given collection",
	"Method": "void testRemoveAll(){\r\n    Set full = populatedSet(3);\r\n    assertTrue(full.removeAll(Arrays.asList(one, two)));\r\n    assertEquals(1, full.size());\r\n    assertFalse(full.removeAll(Arrays.asList(one, two)));\r\n    assertEquals(1, full.size());\r\n}"
}, {
	"Path": "jsr166.JSR166TestCase.permissivePolicy",
	"Comment": "returns a policy containing all the permissions we ever need.",
	"Method": "Policy permissivePolicy(){\r\n    return new AdjustablePolicy(// Permissions needed to change permissions!\r\n    new RuntimePermission(\"modifyThread\"), // Permissions needed to change permissions!\r\n    new RuntimePermission(\"getClassLoader\"), new RuntimePermission(\"setContextClassLoader\"), // Permissions needed by the junit test harness\r\n    new SecurityPermission(\"getPolicy\"), // Permissions needed by the junit test harness\r\n    new SecurityPermission(\"setPolicy\"), new RuntimePermission(\"setSecurityManager\"), new RuntimePermission(\"accessDeclaredMembers\"), new PropertyPermission(\"*\", \"read\"), new java.io.FilePermission(\"<<ALL FILES>>\", \"read\"));\r\n}"
}, {
	"Path": "org.apereo.cas.AbstractCentralAuthenticationService.verifyTicketState",
	"Comment": "validate ticket expiration policy and throws exception if ticket is no longer valid.expired tickets are also deleted from the registry immediately on demand.",
	"Method": "void verifyTicketState(Ticket ticket,String id,Class clazz){\r\n    if (ticket == null) {\r\n        LOGGER.debug(\"Ticket [{}] by type [{}] cannot be found in the ticket registry.\", id, clazz != null ? clazz.getSimpleName() : \"unspecified\");\r\n        throw new InvalidTicketException(id);\r\n    }\r\n    if (ticket.isExpired()) {\r\n        deleteTicket(id);\r\n        LOGGER.debug(\"Ticket [{}] has expired and is now deleted from the ticket registry.\", ticket);\r\n        throw new InvalidTicketException(id);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.web.support.WebUtils.putPublicWorkstationToFlowIfRequestParameterPresent",
	"Comment": "put public workstation into the flow if request parameter present.",
	"Method": "void putPublicWorkstationToFlowIfRequestParameterPresent(RequestContext context){\r\n    if (StringUtils.isNotBlank(context.getExternalContext().getRequestParameterMap().get(PUBLIC_WORKSTATION_ATTRIBUTE))) {\r\n        context.getFlowScope().put(PUBLIC_WORKSTATION_ATTRIBUTE, Boolean.TRUE);\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.BinaryCodec.encode",
	"Comment": "converts an array of raw binary data into an array of ascii 0 and 1 chars.",
	"Method": "byte[] encode(byte[] raw,Object encode,Object raw){\r\n    if (!(raw instanceof byte[])) {\r\n        throw new EncoderException(\"argument not a byte array\");\r\n    }\r\n    return toAsciiChars((byte[]) raw);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.RefinedSoundex.encode",
	"Comment": "encodes an object using the refined soundex algorithm. this method isprovided in order to satisfy the requirements of the encoder interface,and will throw an encoderexception if the supplied object is not of typejava.lang.string.",
	"Method": "Object encode(Object obj,String encode,String str){\r\n    return soundex(str);\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.ifZCmp",
	"Comment": "generates the instructions to jump to a label based on the comparison ofthe top integer stack value with zero.",
	"Method": "void ifZCmp(int mode,Label label){\r\n    mv.visitJumpInsn(mode, label);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.getInstanceMap",
	"Comment": "gets rules for a combination of name type, rule type and a single language.",
	"Method": "Map<String, List<Rule>> getInstanceMap(NameType nameType,RuleType rt,Languages.LanguageSet langs,Map<String, List<Rule>> getInstanceMap,NameType nameType,RuleType rt,String lang){\r\n    final Map<String, List<Rule>> rules = RULES.get(nameType).get(rt).get(lang);\r\n    if (rules == null) {\r\n        throw new IllegalArgumentException(String.format(\"No rules found for %s, %s, %s.\", nameType.getName(), rt.getName(), lang));\r\n    }\r\n    return rules;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.MultifactorAuthenticationUtils.newMultifactorAuthenticationProviderBypass",
	"Comment": "new multifactor authentication provider bypass multifactor.",
	"Method": "MultifactorAuthenticationProviderBypass newMultifactorAuthenticationProviderBypass(MultifactorAuthenticationProviderBypassProperties props){\r\n    val bypass = new ChainingMultifactorAuthenticationBypassProvider();\r\n    bypass.addBypass(new DefaultMultifactorAuthenticationProviderBypass(props));\r\n    if (props.getType() == MultifactorAuthenticationProviderBypassProperties.MultifactorProviderBypassTypes.GROOVY) {\r\n        bypass.addBypass(new GroovyMultifactorAuthenticationProviderBypass(props));\r\n    }\r\n    if (props.getType() == MultifactorAuthenticationProviderBypassProperties.MultifactorProviderBypassTypes.REST) {\r\n        bypass.addBypass(new RestMultifactorAuthenticationProviderBypass(props));\r\n    }\r\n    return bypass;\r\n}"
}, {
	"Path": "org.apereo.cas.support.rest.resources.TicketGrantingTicketResource.createTicketGrantingTicketForRequest",
	"Comment": "create ticket granting ticket for request ticket granting ticket.",
	"Method": "TicketGrantingTicket createTicketGrantingTicketForRequest(MultiValueMap<String, String> requestBody,HttpServletRequest request){\r\n    val credential = this.credentialFactory.fromRequest(request, requestBody);\r\n    if (credential == null || credential.isEmpty()) {\r\n        throw new BadRestRequestException(\"No credentials are provided or extracted to authenticate the REST request\");\r\n    }\r\n    val service = this.serviceFactory.createService(request);\r\n    val authenticationResult = authenticationSystemSupport.handleAndFinalizeSingleAuthenticationTransaction(service, credential);\r\n    return centralAuthenticationService.createTicketGrantingTicket(authenticationResult);\r\n}"
}, {
	"Path": "org.objectweb.asm.xml.ASMContentHandler.peek",
	"Comment": "return the top object on the stack without removing it. if there are noobjects on the stack, return null.",
	"Method": "Object peek(){\r\n    int size = stack.size();\r\n    return size == 0 ? null : stack.get(size - 1);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.CacheProxy.loadAllAndKeepExisting",
	"Comment": "performs the bulk load where the existing entries are retained.",
	"Method": "void loadAllAndKeepExisting(Set<? extends K> keys){\r\n    List<K> keysToLoad = keys.stream().filter(key -> !cache.asMap().containsKey(key)).collect(toList());\r\n    Map<K, V> result = cacheLoader.get().loadAll(keysToLoad);\r\n    for (Map.Entry<K, V> entry : result.entrySet()) {\r\n        if ((entry.getKey() != null) && (entry.getValue() != null)) {\r\n            putIfAbsentNoAwait(entry.getKey(), entry.getValue(), false);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.Hex.decode",
	"Comment": "converts a string or an array of character bytes representing hexadecimal values into an array of bytes of thosesame values. the returned array will be half the length of the passed string or array, as it takes two charactersto represent any given byte. an exception is thrown if the passed char array has an odd number of elements.",
	"Method": "byte[] decode(byte[] array,byte[] decode,ByteBuffer buffer,Object decode,Object object){\r\n    if (object instanceof String) {\r\n        return decode(((String) object).toCharArray());\r\n    } else if (object instanceof byte[]) {\r\n        return decode((byte[]) object);\r\n    } else if (object instanceof ByteBuffer) {\r\n        return decode((ByteBuffer) object);\r\n    } else {\r\n        try {\r\n            return decodeHex((char[]) object);\r\n        } catch (final ClassCastException e) {\r\n            throw new DecoderException(e.getMessage(), e);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMapTest.testPutIfAbsent2",
	"Comment": "putifabsent does not add the pair if the key is already present",
	"Method": "void testPutIfAbsent2(){\r\n    ConcurrentMap map = map5();\r\n    assertEquals(\"A\", map.putIfAbsent(one, \"Z\"));\r\n}"
}, {
	"Path": "org.apereo.cas.adaptors.x509.authentication.handler.support.AbstractX509LdapTests.populateCertificateRevocationListAttribute",
	"Comment": "populate certificate revocation list attribute.dynamically set the attribute value to the crl content.encode it as base64 first. doing this in the code ratherthan in the ldif file to ensure the attribute can be populatedwithout dependencies on the classpath and or filesystem.",
	"Method": "void populateCertificateRevocationListAttribute(int port){\r\n    val col = getLdapDirectory(port).getLdapEntries();\r\n    for (val ldapEntry : col) {\r\n        if (ldapEntry.getDn().equals(DN)) {\r\n            val attr = new LdapAttribute(true);\r\n            val userCA = new byte[1024];\r\n            IOUtils.read(new ClassPathResource(\"userCA-valid.crl\").getInputStream(), userCA);\r\n            val value = EncodingUtils.encodeBase64ToByteArray(userCA);\r\n            attr.setName(\"certificateRevocationList\");\r\n            attr.addBinaryValue(value);\r\n            LdapTestUtils.modifyLdapEntry(getLdapDirectory(port).getConnection(), ldapEntry, attr);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.processPhiUse",
	"Comment": "handles phi uses of new objects. will merge together the sources of a phiinto a single escapeset. adds the result of the phi to the worklist soits uses can be followed.",
	"Method": "void processPhiUse(SsaInsn use,EscapeSet escSet,ArrayList<RegisterSpec> regWorklist){\r\n    int setIndex = findSetIndex(use.getResult());\r\n    if (setIndex != latticeValues.size()) {\r\n        EscapeSet mergeSet = latticeValues.get(setIndex);\r\n        if (mergeSet != escSet) {\r\n            escSet.replaceableArray = false;\r\n            escSet.regSet.or(mergeSet.regSet);\r\n            if (escSet.escape.compareTo(mergeSet.escape) < 0) {\r\n                escSet.escape = mergeSet.escape;\r\n            }\r\n            replaceNode(escSet, mergeSet);\r\n            latticeValues.remove(setIndex);\r\n        }\r\n    } else {\r\n        escSet.regSet.set(use.getResult().getReg());\r\n        regWorklist.add(use.getResult());\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassReader.readAnnotationValues",
	"Comment": "reads the values of an annotation and makes the given visitor visit them.",
	"Method": "int readAnnotationValues(int v,char[] buf,boolean named,AnnotationVisitor av){\r\n    int i = readUnsignedShort(v);\r\n    v += 2;\r\n    if (named) {\r\n        for (; i > 0; --i) {\r\n            v = readAnnotationValue(v + 2, buf, readUTF8(v, buf), av);\r\n        }\r\n    } else {\r\n        for (; i > 0; --i) {\r\n            v = readAnnotationValue(v, buf, null, av);\r\n        }\r\n    }\r\n    if (av != null) {\r\n        av.visitEnd();\r\n    }\r\n    return v;\r\n}"
}, {
	"Path": "org.apache.commons.codec.net.BCodec.getCharset",
	"Comment": "gets the default charset name used for string decoding and encoding.",
	"Method": "Charset getCharset(){\r\n    return this.charset;\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.Rules.entityHaveExtraProperNoun",
	"Comment": "have extra proper noun except strings involved in semantic match",
	"Method": "boolean entityHaveExtraProperNoun(Mention m,Mention a,Set<String> exceptWords){\r\n    Set<String> mProper = Generics.newHashSet();\r\n    Set<String> aProper = Generics.newHashSet();\r\n    String mString = m.spanToString();\r\n    String aString = a.spanToString();\r\n    for (CoreLabel w : m.originalSpan) {\r\n        if (w.get(CoreAnnotations.PartOfSpeechAnnotation.class).startsWith(\"NNP\")) {\r\n            mProper.add(w.get(CoreAnnotations.TextAnnotation.class));\r\n        }\r\n    }\r\n    for (CoreLabel w : a.originalSpan) {\r\n        if (w.get(CoreAnnotations.PartOfSpeechAnnotation.class).startsWith(\"NNP\")) {\r\n            aProper.add(w.get(CoreAnnotations.TextAnnotation.class));\r\n        }\r\n    }\r\n    boolean mHasExtra = false;\r\n    boolean aHasExtra = false;\r\n    for (String s : mProper) {\r\n        if (!aString.contains(s) && !exceptWords.contains(s.toLowerCase())) {\r\n            mHasExtra = true;\r\n            break;\r\n        }\r\n    }\r\n    for (String s : aProper) {\r\n        if (!mString.contains(s) && !exceptWords.contains(s.toLowerCase())) {\r\n            aHasExtra = true;\r\n            break;\r\n        }\r\n    }\r\n    if (mHasExtra && aHasExtra) {\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "the.bytecode.club.bytecodeviewer.decompilers.bytecode.InstructionPattern.resetMatch",
	"Comment": "resets the instruction pointer and clears the last match cache data.",
	"Method": "void resetMatch(){\r\n    reset();\r\n    AbstractInsnNode[] match = lastMatch;\r\n    lastMatch = new AbstractInsnNode[match.length];\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.product.ElasticSearchPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new ElasticSearchPolicy(config));\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.returnValue",
	"Comment": "generates the instruction to return the top stack value to the caller.",
	"Method": "void returnValue(){\r\n    mv.visitInsn(returnType.getOpcode(Opcodes.IRETURN));\r\n}"
}, {
	"Path": "org.apereo.cas.web.DelegatedClientNavigationController.redirectResponseToFlow",
	"Comment": "redirect response to flow. receives the cas, oauth, oidc, etc. callback response, adjust it to work withthe login webflow, and redirects the requests to the login webflow endpoint.",
	"Method": "View redirectResponseToFlow(String clientName,HttpServletRequest request,HttpServletResponse response){\r\n    return buildRedirectViewBackToFlow(clientName, request);\r\n}"
}, {
	"Path": "org.apereo.cas.ticket.registry.MongoDbTicketRegistry.getExpireAt",
	"Comment": "calculate the time at which the ticket is eligible for automated deletion by mongodb.makes the assumption that the cas server date and the mongo server date are in sync.",
	"Method": "Date getExpireAt(Ticket ticket){\r\n    val expirationPolicy = ticket.getExpirationPolicy();\r\n    val ttl = ticket instanceof TicketState ? expirationPolicy.getTimeToLive((TicketState) ticket) : expirationPolicy.getTimeToLive();\r\n    if (ttl < 1) {\r\n        return null;\r\n    }\r\n    return new Date(System.currentTimeMillis() + TimeUnit.SECONDS.toMillis(ttl));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.CacheFactory.tryToCreateFromExternalSettings",
	"Comment": "returns a newly created cache instance if a definition is found in the external settings file.",
	"Method": "CacheProxy<K, V> tryToCreateFromExternalSettings(String cacheName){\r\n    Optional<CaffeineConfiguration<K, V>> configuration = TypesafeConfigurator.from(rootConfig, cacheName);\r\n    return configuration.isPresent() ? createCache(cacheName, configuration.get()) : null;\r\n}"
}, {
	"Path": "org.objectweb.asm.util.CheckMethodAdapter.getLabelStatusField",
	"Comment": "returns the field object corresponding to the label.status field.",
	"Method": "Field getLabelStatusField(){\r\n    if (labelStatusField == null) {\r\n        labelStatusField = getLabelField(\"a\");\r\n        if (labelStatusField == null) {\r\n            labelStatusField = getLabelField(\"status\");\r\n        }\r\n    }\r\n    return labelStatusField;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.weightsAsMapOfCounters",
	"Comment": "this method returns a map from each label to a counter of feature weights for that label.useful for feature analysis.",
	"Method": "Map<L, Counter<F>> weightsAsMapOfCounters(){\r\n    Map<L, Counter<F>> mapOfCounters = Generics.newHashMap();\r\n    for (L label : labelIndex) {\r\n        int labelID = labelIndex.indexOf(label);\r\n        Counter<F> c = new ClassicCounter();\r\n        mapOfCounters.put(label, c);\r\n        for (F f : featureIndex) {\r\n            c.incrementCount(f, weights[featureIndex.indexOf(f)][labelID]);\r\n        }\r\n    }\r\n    return mapOfCounters;\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.checkCast",
	"Comment": "generates the instruction to check that the top stack value is of thegiven type.",
	"Method": "void checkCast(Type type){\r\n    if (!type.equals(OBJECT_TYPE)) {\r\n        typeInsn(Opcodes.CHECKCAST, type);\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.ifNonNull",
	"Comment": "generates the instruction to jump to the given label if the top stackvalue is not null.",
	"Method": "void ifNonNull(Label label){\r\n    mv.visitJumpInsn(Opcodes.IFNONNULL, label);\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getConstructorDescriptor",
	"Comment": "returns the descriptor corresponding to the given constructor.",
	"Method": "String getConstructorDescriptor(Constructor<?> c){\r\n    Class<?>[] parameters = c.getParameterTypes();\r\n    StringBuffer buf = new StringBuffer();\r\n    buf.append('(');\r\n    for (int i = 0; i < parameters.length; ++i) {\r\n        getDescriptor(buf, parameters[i]);\r\n    }\r\n    return buf.append(\")V\").toString();\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.POSTaggerAnnotatorITest.testSentencesAnnotation",
	"Comment": "test that a single sentence works for the sentenceannotation.",
	"Method": "void testSentencesAnnotation(){\r\n    List<CoreLabel> labels = makeSentence(testSentences[0]);\r\n    CoreMap sentence = new ArrayCoreMap();\r\n    sentence.set(CoreAnnotations.TokensAnnotation.class, labels);\r\n    List<CoreMap> sentences = new ArrayList();\r\n    sentences.add(sentence);\r\n    Annotation annotation = new Annotation(shortText);\r\n    annotation.set(CoreAnnotations.SentencesAnnotation.class, sentences);\r\n    tagger.annotate(annotation);\r\n    checkLabels(labels, \"PRP$\", \"NN\", \"VBZ\", \"JJ\", \"CC\", \"JJ\", \".\");\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.stats.StatsCounter.guardedStatsCounter",
	"Comment": "returns an accumulator that suppresses and logs any exception thrown by the delegatestatscounter.",
	"Method": "StatsCounter guardedStatsCounter(StatsCounter statsCounter){\r\n    return new GuardedStatsCounter(statsCounter);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.LoadingCacheProxy.getOrLoad",
	"Comment": "retrieves the value from the cache, loading it if necessary.",
	"Method": "V getOrLoad(K key){\r\n    boolean statsEnabled = statistics.isEnabled();\r\n    long start = statsEnabled ? ticker.read() : 0L;\r\n    long millis = 0L;\r\n    Expirable<V> expirable = cache.getIfPresent(key);\r\n    if ((expirable != null) && !expirable.isEternal()) {\r\n        millis = nanosToMillis((start == 0L) ? ticker.read() : start);\r\n        if (expirable.hasExpired(millis)) {\r\n            Expirable<V> expired = expirable;\r\n            cache.asMap().computeIfPresent(key, (k, e) -> {\r\n                if (e == expired) {\r\n                    dispatcher.publishExpired(this, key, expired.get());\r\n                    statistics.recordEvictions(1);\r\n                    return null;\r\n                }\r\n                return e;\r\n            });\r\n            expirable = null;\r\n        }\r\n    }\r\n    if (expirable == null) {\r\n        expirable = cache.get(key);\r\n        statistics.recordMisses(1L);\r\n    } else {\r\n        statistics.recordHits(1L);\r\n    }\r\n    V value = null;\r\n    if (expirable != null) {\r\n        setAccessExpirationTime(expirable, millis);\r\n        value = copyValue(expirable);\r\n    }\r\n    if (statsEnabled) {\r\n        statistics.recordGetTime(ticker.read() - start);\r\n    }\r\n    return value;\r\n}"
}, {
	"Path": "org.apache.commons.codec.net.QuotedPrintableCodec.getCharset",
	"Comment": "gets the default charset name used for string decoding and encoding.",
	"Method": "Charset getCharset(){\r\n    return this.charset;\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.login.CreateTicketGrantingTicketAction.createOrUpdateTicketGrantingTicket",
	"Comment": "create or update ticket granting ticket ticket granting ticket.",
	"Method": "TicketGrantingTicket createOrUpdateTicketGrantingTicket(AuthenticationResult authenticationResult,Authentication authentication,String ticketGrantingTicket){\r\n    try {\r\n        if (shouldIssueTicketGrantingTicket(authentication, ticketGrantingTicket)) {\r\n            LOGGER.debug(\"Attempting to issue a new ticket-granting ticket...\");\r\n            return this.centralAuthenticationService.createTicketGrantingTicket(authenticationResult);\r\n        }\r\n        LOGGER.debug(\"Updating the existing ticket-granting ticket [{}]...\", ticketGrantingTicket);\r\n        val tgt = this.centralAuthenticationService.getTicket(ticketGrantingTicket, TicketGrantingTicket.class);\r\n        tgt.getAuthentication().update(authentication);\r\n        this.centralAuthenticationService.updateTicket(tgt);\r\n        return tgt;\r\n    } catch (final PrincipalException e) {\r\n        LOGGER.error(e.getMessage(), e);\r\n        throw e;\r\n    } catch (final Exception e) {\r\n        LOGGER.error(e.getMessage(), e);\r\n        throw new InvalidTicketException(ticketGrantingTicket);\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassVisitor.visitEnd",
	"Comment": "visits the end of the class. this method, which is the last one to becalled, is used to inform the visitor that all the fields and methods ofthe class have been visited.",
	"Method": "void visitEnd(){\r\n    if (cv != null) {\r\n        cv.visitEnd();\r\n    }\r\n}"
}, {
	"Path": "me.konloch.kontainer.io.HTTPRequest.cleanup",
	"Comment": "used to clean up the connection, closes the connections and nulls the objects",
	"Method": "void cleanup(){\r\n    try {\r\n        reader.close();\r\n    } catch (Exception e) {\r\n    }\r\n    try {\r\n        writer.close();\r\n    } catch (Exception e) {\r\n    }\r\n    try {\r\n        connection.disconnect();\r\n    } catch (Exception e) {\r\n    }\r\n    reader = null;\r\n    writer = null;\r\n    connection = null;\r\n}"
}, {
	"Path": "org.apereo.cas.support.saml.web.view.Saml10SuccessResponseView.prepareSamlAttributes",
	"Comment": "prepare saml attributes. combines both principal and authenticationattributes.",
	"Method": "Map<String, Object> prepareSamlAttributes(Map<String, Object> model,Service service){\r\n    val registeredService = this.servicesManager.findServiceBy(service);\r\n    val authnAttributes = getCasProtocolAuthenticationAttributes(model, registeredService);\r\n    LOGGER.debug(\"Retrieved authentication attributes [{}] from the model\", authnAttributes);\r\n    val attributesToReturn = new HashMap<String, Object>();\r\n    attributesToReturn.putAll(getPrincipalAttributesAsMultiValuedAttributes(model));\r\n    attributesToReturn.putAll(authnAttributes);\r\n    LOGGER.debug(\"Beginning to encode attributes [{}] for service [{}]\", attributesToReturn, registeredService.getServiceId());\r\n    val finalAttributes = this.protocolAttributeEncoder.encodeAttributes(attributesToReturn, registeredService);\r\n    LOGGER.debug(\"Final collection of attributes are [{}]\", finalAttributes);\r\n    return finalAttributes;\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaBasicBlock.addInsnToHead",
	"Comment": "adds an insn to the head of this basic block, just after any phiinsns.",
	"Method": "void addInsnToHead(Insn insn){\r\n    SsaInsn newInsn = SsaInsn.makeFromRop(insn, this);\r\n    insns.add(getCountPhiInsns(), newInsn);\r\n    parent.onInsnAdded(newInsn);\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.newFieldItem",
	"Comment": "adds a field reference to the constant pool of the class being build.does nothing if the constant pool already contains a similar item.",
	"Method": "Item newFieldItem(String owner,String name,String desc){\r\n    key3.set(FIELD, owner, name, desc);\r\n    Item result = get(key3);\r\n    if (result == null) {\r\n        put122(FIELD, newClass(owner), newNameType(name, desc));\r\n        result = new Item(index++, key3);\r\n        put(result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.Rules.antecedentMatchesMentionSpeakerAnnotation",
	"Comment": "the antecedent matches the speaker annotation found in the mention",
	"Method": "boolean antecedentMatchesMentionSpeakerAnnotation(Mention mention,Mention ant,boolean antecedentMatchesMentionSpeakerAnnotation,Mention mention,Mention ant,Document document){\r\n    if (mention.headWord == null) {\r\n        return false;\r\n    }\r\n    String speaker = mention.headWord.get(CoreAnnotations.SpeakerAnnotation.class);\r\n    if (speaker == null) {\r\n        return false;\r\n    }\r\n    SpeakerInfo speakerInfo = (document != null) ? document.getSpeakerInfo(speaker) : null;\r\n    if (speakerInfo != null) {\r\n        return (mentionMatchesSpeaker(ant, speakerInfo, false));\r\n    }\r\n    if (speaker.indexOf(\" \") >= 0) {\r\n        for (String s : WHITESPACE_PATTERN.split(speaker)) {\r\n            if (ant.headString.equalsIgnoreCase(s))\r\n                return true;\r\n        }\r\n    } else {\r\n        if (ant.headString.equalsIgnoreCase(speaker))\r\n            return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.NERClassifierCombiner.showNCCInfo",
	"Comment": "method for displaying info about an nerclassifiercombiner.",
	"Method": "void showNCCInfo(NERClassifierCombiner ncc){\r\n    log.info(\"\");\r\n    log.info(\"info for this NERClassifierCombiner: \");\r\n    ClassifierCombiner.showCCInfo(ncc);\r\n    log.info(\"useSUTime: \" + ncc.useSUTime);\r\n    log.info(\"applyNumericClassifier: \" + ncc.applyNumericClassifiers);\r\n    log.info(\"\");\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.Synthetic.zipfian",
	"Comment": "returns a sequence of events where some items are more popular than others, according to azipfian distribution.",
	"Method": "LongStream zipfian(int items,double constant,int events){\r\n    return generate(new ZipfianGenerator(items, constant), events);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.GeneralDataset.applyFeatureCountThreshold",
	"Comment": "applies a feature count threshold to the dataset.all features thatoccur fewer than k times are expunged.",
	"Method": "void applyFeatureCountThreshold(int k){\r\n    float[] counts = getFeatureCounts();\r\n    Index<F> newFeatureIndex = new HashIndex();\r\n    int[] featMap = new int[featureIndex.size()];\r\n    for (int i = 0; i < featMap.length; i++) {\r\n        F feat = featureIndex.get(i);\r\n        if (counts[i] >= k) {\r\n            int newIndex = newFeatureIndex.size();\r\n            newFeatureIndex.add(feat);\r\n            featMap[i] = newIndex;\r\n        } else {\r\n            featMap[i] = -1;\r\n        }\r\n    }\r\n    featureIndex = newFeatureIndex;\r\n    for (int i = 0; i < size; i++) {\r\n        List<Integer> featList = new ArrayList(data[i].length);\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            if (featMap[data[i][j]] >= 0) {\r\n                featList.add(featMap[data[i][j]]);\r\n            }\r\n        }\r\n        data[i] = new int[featList.size()];\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            data[i][j] = featList.get(j);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.rop.annotation.Annotations.add",
	"Comment": "adds an element to this instance. there must not already be anelement of the same type.",
	"Method": "void add(Annotation annotation){\r\n    throwIfImmutable();\r\n    if (annotation == null) {\r\n        throw new NullPointerException(\"annotation == null\");\r\n    }\r\n    CstType type = annotation.getType();\r\n    if (annotations.containsKey(type)) {\r\n        throw new IllegalArgumentException(\"duplicate type: \" + type.toHuman());\r\n    }\r\n    annotations.put(type, annotation);\r\n}"
}, {
	"Path": "org.apache.commons.cli.OptionBuilder.isRequired",
	"Comment": "the next option created will be required if requiredis true.",
	"Method": "OptionBuilder isRequired(OptionBuilder isRequired,boolean newRequired){\r\n    OptionBuilder.required = newRequired;\r\n    return INSTANCE;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.Expirable.setExpireTimeMS",
	"Comment": "specifies the time, in milliseconds, when the value will expire.",
	"Method": "void setExpireTimeMS(long expireTimeMS){\r\n    this.expireTimeMS = expireTimeMS;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.NERClassifierCombiner.getClassifier",
	"Comment": "static method for getting an nerclassifiercombiner from an objectinputstream",
	"Method": "NERClassifierCombiner getClassifier(String loadPath,Properties props,NERClassifierCombiner getClassifier,ObjectInputStream ois,Properties props){\r\n    return new NERClassifierCombiner(ois, props);\r\n}"
}, {
	"Path": "org.apache.commons.cli.DefaultParser.updateRequiredOptions",
	"Comment": "removes the option or its group from the list of expected elements.",
	"Method": "void updateRequiredOptions(Option option){\r\n    if (option.isRequired()) {\r\n        expectedOpts.remove(option.getKey());\r\n    }\r\n    if (options.getOptionGroup(option) != null) {\r\n        OptionGroup group = options.getOptionGroup(option);\r\n        if (group.isRequired()) {\r\n            expectedOpts.remove(group);\r\n        }\r\n        group.setSelected(option);\r\n    }\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.api.BuckTarget.isPackageRelative",
	"Comment": "returns true if this is a relative target to the same build file.",
	"Method": "boolean isPackageRelative(){\r\n    return cellName == null && cellPath == null;\r\n}"
}, {
	"Path": "org.apache.commons.cli.Option.addValue",
	"Comment": "this method is not intended to be used. it was a piece of internal api that was made public in 1.0. it currently throws an unsupportedoperationexception.",
	"Method": "boolean addValue(String value){\r\n    throw new UnsupportedOperationException(\"The addValue method is not intended for client use. \" + \"Subclasses should use the addValueForProcessing method instead. \");\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassReader.getMaxStringLength",
	"Comment": "returns the maximum length of the strings contained in the constant poolof the class.",
	"Method": "int getMaxStringLength(){\r\n    return maxStringLength;\r\n}"
}, {
	"Path": "com.android.dx.ssa.PhiTypeResolver.equalsHandlesNulls",
	"Comment": "returns true if a and b are equal, whetheror not either of them are null.",
	"Method": "boolean equalsHandlesNulls(LocalItem a,LocalItem b){\r\n    return (a == b) || ((a != null) && a.equals(b));\r\n}"
}, {
	"Path": "org.apereo.cas.support.saml.SamlUtils.transformSamlObject",
	"Comment": "transform saml object into string without indenting the final string.",
	"Method": "StringWriter transformSamlObject(OpenSamlConfigBean configBean,XMLObject samlObject,T transformSamlObject,OpenSamlConfigBean configBean,String xml,Class<T> clazz,StringWriter transformSamlObject,OpenSamlConfigBean configBean,XMLObject samlObject,boolean indent){\r\n    val writer = new StringWriter();\r\n    try {\r\n        val marshaller = configBean.getMarshallerFactory().getMarshaller(samlObject.getElementQName());\r\n        if (marshaller != null) {\r\n            val element = marshaller.marshall(samlObject);\r\n            val domSource = new DOMSource(element);\r\n            val result = new StreamResult(writer);\r\n            val tf = TransformerFactory.newInstance();\r\n            tf.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);\r\n            val transformer = tf.newTransformer();\r\n            if (indent) {\r\n                transformer.setOutputProperty(OutputKeys.INDENT, \"yes\");\r\n                transformer.setOutputProperty(\"{http://xml.apache.org/xslt}indent-amount\", \"4\");\r\n            }\r\n            transformer.transform(domSource, result);\r\n        }\r\n    } catch (final Exception e) {\r\n        throw new SamlException(e.getMessage(), e);\r\n    }\r\n    return writer;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.event.EventDispatcher.publishRemoved",
	"Comment": "publishes a remove event for the entry to all of the interested listeners.",
	"Method": "void publishRemoved(Cache<K, V> cache,K key,V value){\r\n    publish(cache, EventType.REMOVED, key, null, value, false);\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.api.BuckTargetPattern.asRecursivePackageMatchingPattern",
	"Comment": "returns a pattern like this pattern, but matching all targets in the given package and itsrecursive subpackages.",
	"Method": "BuckTargetPattern asRecursivePackageMatchingPattern(){\r\n    return new BuckTargetPattern(cellName, cellPath, \"/...\");\r\n}"
}, {
	"Path": "org.apereo.cas.support.saml.web.idp.profile.builders.authn.SamlProfileSamlAuthNStatementBuilder.buildAuthnStatement",
	"Comment": "creates an authentication statement for the current request.",
	"Method": "AuthnStatement buildAuthnStatement(Object casAssertion,RequestAbstractType authnRequest,SamlRegisteredServiceServiceProviderMetadataFacade adaptor,SamlRegisteredService service,String binding,MessageContext messageContext,HttpServletRequest request){\r\n    val assertion = Assertion.class.cast(casAssertion);\r\n    val authenticationMethod = this.authnContextClassRefBuilder.build(assertion, authnRequest, adaptor, service);\r\n    var id = CommonUtils.safeGetParameter(request, CasProtocolConstants.PARAMETER_TICKET);\r\n    if (StringUtils.isBlank(id)) {\r\n        LOGGER.warn(\"Unable to locate service ticket as the session index; Generating random identifier instead...\");\r\n        id = '_' + String.valueOf(RandomUtils.getNativeInstance().nextLong());\r\n    }\r\n    val statement = newAuthnStatement(authenticationMethod, DateTimeUtils.zonedDateTimeOf(assertion.getAuthenticationDate()), id);\r\n    if (assertion.getValidUntilDate() != null) {\r\n        val dt = DateTimeUtils.zonedDateTimeOf(assertion.getValidUntilDate());\r\n        statement.setSessionNotOnOrAfter(DateTimeUtils.dateTimeOf(dt.plusSeconds(casProperties.getAuthn().getSamlIdp().getResponse().getSkewAllowance())));\r\n    }\r\n    val subjectLocality = buildSubjectLocality(assertion, authnRequest, adaptor, binding);\r\n    statement.setSubjectLocality(subjectLocality);\r\n    return statement;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.irr.HillClimberFrdPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new HillClimberFrdPolicy(config));\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.NominalDataReader.readData",
	"Comment": "read the data as a list of rvfdatum objects. for the test set we must reuse the indices from the training set",
	"Method": "ArrayList<RVFDatum<String, Integer>> readData(String filename,Map<Integer, Index<String>> indices){\r\n    try {\r\n        String sep = \", \";\r\n        ArrayList<RVFDatum<String, Integer>> examples = new ArrayList();\r\n        for (String line : ObjectBank.getLineIterator(new File(filename))) {\r\n            RVFDatum<String, Integer> next = readDatum(line, sep, indices);\r\n            examples.add(next);\r\n        }\r\n        return examples;\r\n    } catch (Exception e) {\r\n        e.printStackTrace();\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "org.apache.commons.cli.Option.hasValueSeparator",
	"Comment": "return whether this option has specified a value separator.",
	"Method": "boolean hasValueSeparator(){\r\n    return valuesep > 0;\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.replaceNode",
	"Comment": "merges all links in the lattice among two escapesets. on return, thenewnode will have its old links as well as all links from the oldnode.the oldnode has all its links removed.",
	"Method": "void replaceNode(EscapeSet newNode,EscapeSet oldNode){\r\n    for (EscapeSet e : oldNode.parentSets) {\r\n        e.childSets.remove(oldNode);\r\n        e.childSets.add(newNode);\r\n        newNode.parentSets.add(e);\r\n    }\r\n    for (EscapeSet e : oldNode.childSets) {\r\n        e.parentSets.remove(oldNode);\r\n        e.parentSets.add(newNode);\r\n        newNode.childSets.add(e);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.irr.ClockProPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new ClockProPolicy(config));\r\n}"
}, {
	"Path": "org.apereo.cas.CipherExecutor.encode",
	"Comment": "encrypt the value. implementations maychoose to also sign the final value.",
	"Method": "O encode(I value,Object[] parameters,O encode,I value){\r\n    return encode(value, ArrayUtils.EMPTY_OBJECT_ARRAY);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.impl.ConcurrentHashMapV7.put",
	"Comment": "maps the specified key to the specified value in this table.neither the key nor the value can be null. the value can be retrieved by calling the get methodwith a key that is equal to the original key.",
	"Method": "V put(K key,int hash,V value,boolean onlyIfAbsent,V put,K key,V value){\r\n    Segment<K, V> s;\r\n    if (value == null) {\r\n        throw new NullPointerException();\r\n    }\r\n    int hash = hash(key);\r\n    int j = (hash >>> segmentShift) & segmentMask;\r\n    if ((s = (Segment<K, V>) UNSAFE.getObject(segments, (j << SSHIFT) + SBASE)) == null) {\r\n        s = ensureSegment(j);\r\n    }\r\n    return s.put(key, hash, value, false);\r\n}"
}, {
	"Path": "com.android.dx.ssa.Optimizer.optimize",
	"Comment": "runs optimization algorthims over this method, and returns a newinstance of ropmethod with the changes.",
	"Method": "RopMethod optimize(RopMethod rmeth,int paramWidth,boolean isStatic,boolean inPreserveLocals,TranslationAdvice inAdvice,RopMethod optimize,RopMethod rmeth,int paramWidth,boolean isStatic,boolean inPreserveLocals,TranslationAdvice inAdvice,EnumSet<OptionalStep> steps){\r\n    SsaMethod ssaMeth = null;\r\n    preserveLocals = inPreserveLocals;\r\n    advice = inAdvice;\r\n    ssaMeth = SsaConverter.convertToSsaMethod(rmeth, paramWidth, isStatic);\r\n    runSsaFormSteps(ssaMeth, steps);\r\n    RopMethod resultMeth = SsaToRop.convertToRopMethod(ssaMeth, false);\r\n    if (resultMeth.getBlocks().getRegCount() > advice.getMaxOptimalRegisterCount()) {\r\n        resultMeth = optimizeMinimizeRegisters(rmeth, paramWidth, isStatic, steps);\r\n    }\r\n    return resultMeth;\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMap8Test.testMerge3",
	"Comment": "merge removes when the given key is present and function returns null",
	"Method": "void testMerge3(){\r\n    ConcurrentMap map = map5();\r\n    map.merge(one, \"Y\", (x, y) -> null);\r\n    assertFalse(map.containsKey(one));\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.getInsnForMove",
	"Comment": "finds the corresponding instruction for a given move result",
	"Method": "SsaInsn getInsnForMove(SsaInsn moveInsn){\r\n    int pred = moveInsn.getBlock().getPredecessors().nextSetBit(0);\r\n    ArrayList<SsaInsn> predInsns = ssaMeth.getBlocks().get(pred).getInsns();\r\n    return predInsns.get(predInsns.size() - 1);\r\n}"
}, {
	"Path": "edu.stanford.nlp.parser.lexparser.LexicalizedParserITest.testParserQuery",
	"Comment": "test the query structure that you can use for better control ofthe parse",
	"Method": "void testParserQuery(){\r\n    List<CoreLabel> sentence = sampleSausage();\r\n    ParserQuery pq = englishParser.parserQuery();\r\n    pq.parse(sentence);\r\n    compareSingleOutput(pq.getBestParse(), false, pennPrint, \"(ROOT (S (NP (PRP$ My) (NN dog)) (ADVP (RB also)) (VP (VBZ likes) (S (VP (VBG eating) (NP (NN sausage))))) (. .)))\");\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpecList.withoutFirst",
	"Comment": "returns a new instance, which is the same as this instance,except that its first element is removed. mutability of theresult is inherited from the original.",
	"Method": "RegisterSpecList withoutFirst(){\r\n    int newSize = size() - 1;\r\n    if (newSize == 0) {\r\n        return EMPTY;\r\n    }\r\n    RegisterSpecList result = new RegisterSpecList(newSize);\r\n    for (int i = 0; i < newSize; i++) {\r\n        result.set0(i, get0(i + 1));\r\n    }\r\n    if (isImmutable()) {\r\n        result.setImmutable();\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.MentionExtractor.resetDocs",
	"Comment": "reset so that we start at the beginning of the document collection",
	"Method": "void resetDocs(){\r\n    maxID = -1;\r\n    currentDocumentID = null;\r\n}"
}, {
	"Path": "com.android.dx.ssa.ConstCollector.updateConstUses",
	"Comment": "updates all uses of various consts to use the values in the newlyassigned registers.",
	"Method": "void updateConstUses(HashMap<TypedConstant, RegisterSpec> newRegs,int origRegCount){\r\n    final HashSet<TypedConstant> usedByLocal = new HashSet<TypedConstant>();\r\n    final ArrayList<SsaInsn>[] useList = ssaMeth.getUseListCopy();\r\n    for (int i = 0; i < origRegCount; i++) {\r\n        SsaInsn insn = ssaMeth.getDefinitionForRegister(i);\r\n        if (insn == null) {\r\n            continue;\r\n        }\r\n        final RegisterSpec origReg = insn.getResult();\r\n        TypeBearer typeBearer = insn.getResult().getTypeBearer();\r\n        if (!typeBearer.isConstant())\r\n            continue;\r\n        TypedConstant cst = (TypedConstant) typeBearer;\r\n        final RegisterSpec newReg = newRegs.get(cst);\r\n        if (newReg == null) {\r\n            continue;\r\n        }\r\n        if (ssaMeth.isRegALocal(origReg)) {\r\n            if (!COLLECT_ONE_LOCAL) {\r\n                continue;\r\n            } else {\r\n                if (usedByLocal.contains(cst)) {\r\n                    continue;\r\n                } else {\r\n                    usedByLocal.add(cst);\r\n                    fixLocalAssignment(origReg, newRegs.get(cst));\r\n                }\r\n            }\r\n        }\r\n        RegisterMapper mapper = new RegisterMapper() {\r\n            @Override\r\n            public int getNewRegisterCount() {\r\n                return ssaMeth.getRegCount();\r\n            }\r\n            @Override\r\n            public RegisterSpec map(RegisterSpec registerSpec) {\r\n                if (registerSpec.getReg() == origReg.getReg()) {\r\n                    return newReg.withLocalItem(registerSpec.getLocalItem());\r\n                }\r\n                return registerSpec;\r\n            }\r\n        };\r\n        for (SsaInsn use : useList[origReg.getReg()]) {\r\n            if (use.canThrow() && use.getBlock().getSuccessors().cardinality() > 1) {\r\n                continue;\r\n            }\r\n            use.mapSourceRegisters(mapper);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.ConstCollector.updateConstUses",
	"Comment": "updates all uses of various consts to use the values in the newlyassigned registers.",
	"Method": "void updateConstUses(HashMap<TypedConstant, RegisterSpec> newRegs,int origRegCount){\r\n    return ssaMeth.getRegCount();\r\n}"
}, {
	"Path": "com.android.dx.ssa.ConstCollector.updateConstUses",
	"Comment": "updates all uses of various consts to use the values in the newlyassigned registers.",
	"Method": "void updateConstUses(HashMap<TypedConstant, RegisterSpec> newRegs,int origRegCount){\r\n    if (registerSpec.getReg() == origReg.getReg()) {\r\n        return newReg.withLocalItem(registerSpec.getLocalItem());\r\n    }\r\n    return registerSpec;\r\n}"
}, {
	"Path": "org.apereo.cas.services.AbstractRegisteredServiceAttributeReleasePolicy.getReleasedByDefaultAttributes",
	"Comment": "determines a default bundle of attributes that may be released to all serviceswithout the explicit mapping for each service.",
	"Method": "Map<String, Object> getReleasedByDefaultAttributes(Principal p,Map<String, Object> attributes){\r\n    val ctx = ApplicationContextProvider.getApplicationContext();\r\n    if (ctx != null) {\r\n        LOGGER.trace(\"Located application context. Retrieving default attributes for release, if any\");\r\n        val props = ctx.getAutowireCapableBeanFactory().getBean(CasConfigurationProperties.class);\r\n        val defaultAttrs = props.getAuthn().getAttributeRepository().getDefaultAttributesToRelease();\r\n        LOGGER.debug(\"Default attributes for release are: [{}]\", defaultAttrs);\r\n        val defaultAttributesToRelease = new TreeMap<String, Object>(String.CASE_INSENSITIVE_ORDER);\r\n        defaultAttrs.forEach(key -> {\r\n            if (attributes.containsKey(key)) {\r\n                LOGGER.debug(\"Found and added default attribute for release: [{}]\", key);\r\n                defaultAttributesToRelease.put(key, attributes.get(key));\r\n            }\r\n        });\r\n        return defaultAttributesToRelease;\r\n    }\r\n    return new TreeMap();\r\n}"
}, {
	"Path": "the.bytecode.club.bytecodeviewer.searching.RegexInsnFinder.findAllGroups",
	"Comment": "searches for a regex in the instruction list and returns all groups forall matches.",
	"Method": "List<AbstractInsnNode[][]> findAllGroups(String regex){\r\n    final List<AbstractInsnNode[][]> results = new ArrayList<AbstractInsnNode[][]>();\r\n    try {\r\n        final Matcher regexMatcher = Pattern.compile(processRegex(regex), Pattern.MULTILINE).matcher(insnString);\r\n        if (regexMatcher.find()) {\r\n            final AbstractInsnNode[][] result = new AbstractInsnNode[regexMatcher.groupCount() + 1][0];\r\n            for (int i = 0; i <= regexMatcher.groupCount(); i++) {\r\n                result[i] = makeResult(regexMatcher.start(i), regexMatcher.end(i));\r\n            }\r\n            results.add(result);\r\n        }\r\n    } catch (final PatternSyntaxException ex) {\r\n        new the.bytecode.club.bytecodeviewer.api.ExceptionUI(ex);\r\n    }\r\n    return results;\r\n}"
}, {
	"Path": "com.android.dx.ssa.PhiInsn.toRopInsn",
	"Comment": "always throws an exeption, since a phi insn may not beconverted back to rop form.",
	"Method": "Insn toRopInsn(){\r\n    throw new IllegalArgumentException(\"Cannot convert phi insns to rop form\");\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.Caffeine.toString",
	"Comment": "returns a string representation for this caffeine instance. the exact form of the returnedstring is not specified.",
	"Method": "String toString(){\r\n    StringBuilder s = new StringBuilder(64);\r\n    s.append(getClass().getSimpleName()).append('{');\r\n    int baseLength = s.length();\r\n    if (initialCapacity != UNSET_INT) {\r\n        s.append(\"initialCapacity=\").append(initialCapacity).append(\", \");\r\n    }\r\n    if (maximumSize != UNSET_INT) {\r\n        s.append(\"maximumSize=\").append(maximumSize).append(\", \");\r\n    }\r\n    if (maximumWeight != UNSET_INT) {\r\n        s.append(\"maximumWeight=\").append(maximumWeight).append(\", \");\r\n    }\r\n    if (expireAfterWriteNanos != UNSET_INT) {\r\n        s.append(\"expireAfterWrite=\").append(expireAfterWriteNanos).append(\"ns, \");\r\n    }\r\n    if (expireAfterAccessNanos != UNSET_INT) {\r\n        s.append(\"expireAfterAccess=\").append(expireAfterAccessNanos).append(\"ns, \");\r\n    }\r\n    if (expiry != null) {\r\n        s.append(\"expiry, \");\r\n    }\r\n    if (refreshNanos != UNSET_INT) {\r\n        s.append(\"refreshNanos=\").append(refreshNanos).append(\"ns, \");\r\n    }\r\n    if (keyStrength != null) {\r\n        s.append(\"keyStrength=\").append(keyStrength.toString().toLowerCase(US)).append(\", \");\r\n    }\r\n    if (valueStrength != null) {\r\n        s.append(\"valueStrength=\").append(valueStrength.toString().toLowerCase(US)).append(\", \");\r\n    }\r\n    if (removalListener != null) {\r\n        s.append(\"removalListener, \");\r\n    }\r\n    if (writer != null) {\r\n        s.append(\"writer, \");\r\n    }\r\n    if (s.length() > baseLength) {\r\n        s.deleteCharAt(s.length() - 2);\r\n    }\r\n    return s.append('}').toString();\r\n}"
}, {
	"Path": "org.objectweb.asm.MethodVisitor.visitMaxs",
	"Comment": "visits the maximum stack size and the maximum number of local variablesof the method.",
	"Method": "void visitMaxs(int maxStack,int maxLocals){\r\n    if (mv != null) {\r\n        mv.visitMaxs(maxStack, maxLocals);\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.DoubleMetaphone.contains",
	"Comment": "determines whether value contains any of the criteria starting at index start andmatching up to length length.",
	"Method": "boolean contains(String value,int start,int length,String criteria){\r\n    boolean result = false;\r\n    if (start >= 0 && start + length <= value.length()) {\r\n        final String target = value.substring(start, start + length);\r\n        for (final String element : criteria) {\r\n            if (target.equals(element)) {\r\n                result = true;\r\n                break;\r\n            }\r\n        }\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apache.commons.cli.DefaultParser.parse",
	"Comment": "parse the arguments according to the specified options and properties.",
	"Method": "CommandLine parse(Options options,String[] arguments,CommandLine parse,Options options,String[] arguments,Properties properties,CommandLine parse,Options options,String[] arguments,boolean stopAtNonOption,CommandLine parse,Options options,String[] arguments,Properties properties,boolean stopAtNonOption){\r\n    this.options = options;\r\n    this.stopAtNonOption = stopAtNonOption;\r\n    skipParsing = false;\r\n    currentOption = null;\r\n    expectedOpts = new ArrayList(options.getRequiredOptions());\r\n    for (OptionGroup group : options.getOptionGroups()) {\r\n        group.setSelected(null);\r\n    }\r\n    cmd = new CommandLine();\r\n    if (arguments != null) {\r\n        for (String argument : arguments) {\r\n            handleToken(argument);\r\n        }\r\n    }\r\n    checkRequiredArgs();\r\n    handleProperties(properties);\r\n    checkRequiredOptions();\r\n    return cmd;\r\n}"
}, {
	"Path": "org.apache.commons.cli.Options.getMatchingOptions",
	"Comment": "returns the options with a long name starting with the name specified.",
	"Method": "List<String> getMatchingOptions(String opt){\r\n    opt = Util.stripLeadingHyphens(opt);\r\n    List<String> matchingOpts = new ArrayList<String>();\r\n    if (longOpts.keySet().contains(opt)) {\r\n        return Collections.singletonList(opt);\r\n    }\r\n    for (String longOpt : longOpts.keySet()) {\r\n        if (longOpt.startsWith(opt)) {\r\n            matchingOpts.add(longOpt);\r\n        }\r\n    }\r\n    return matchingOpts;\r\n}"
}, {
	"Path": "org.apereo.cas.audit.spi.config.CasCoreAuditConfiguration.customAuditResourceResolverMap",
	"Comment": "extension point for deployers to define custom auditresourceresolvers to extend the stock resolvers.",
	"Method": "Map<String, AuditResourceResolver> customAuditResourceResolverMap(){\r\n    return new HashMap(0);\r\n}"
}, {
	"Path": "com.android.dx.rop.code.SourcePosition.sameLine",
	"Comment": "returns whether the lines match between this instance andthe one given.",
	"Method": "boolean sameLine(SourcePosition other){\r\n    return (line == other.line);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.admission.countmin4.CountMin4.indexOf",
	"Comment": "returns the table index for the counter at the specified depth.",
	"Method": "int indexOf(int item,int i){\r\n    long hash = SEED[i] * item;\r\n    hash += hash >> 32;\r\n    return ((int) hash) & tableMask;\r\n}"
}, {
	"Path": "org.objectweb.asm.xml.ASMContentHandler.endElement",
	"Comment": "process notification of the end of an xml element being reached.",
	"Method": "void endElement(String ns,String lName,String qName){\r\n    String name = lName == null || lName.length() == 0 ? qName : lName;\r\n    Rule r = (Rule) RULES.match(match);\r\n    if (r != null) {\r\n        r.end(name);\r\n    }\r\n    int slash = match.lastIndexOf('/');\r\n    if (slash >= 0) {\r\n        match = match.substring(0, slash);\r\n    } else {\r\n        match = \"\";\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.resolver.impl.SelectiveMultifactorAuthenticationProviderWebflowEventEventResolver.resolveEventsInternal",
	"Comment": "resolve events internal set. implementation may filter events from the collectionto only return the one that is appropriate for this request. the defaultimplementation returns the entire collection.",
	"Method": "Set<Event> resolveEventsInternal(Set<Event> resolveEvents,Authentication authentication,RegisteredService registeredService,HttpServletRequest request,RequestContext context){\r\n    if (!resolveEvents.isEmpty()) {\r\n        LOGGER.trace(\"Collection of resolved events for this authentication sequence are:\");\r\n        resolveEvents.forEach(e -> LOGGER.trace(\"Event id [{}] resolved from [{}]\", e.getId(), e.getSource().getClass().getName()));\r\n    } else {\r\n        LOGGER.trace(\"No events could be resolved for this authentication transaction [{}] and service [{}]\", authentication, registeredService);\r\n    }\r\n    val pair = filterEventsByMultifactorAuthenticationProvider(resolveEvents, authentication, registeredService, request);\r\n    WebUtils.putResolvedMultifactorAuthenticationProviders(context, pair.getValue());\r\n    return pair.getKey();\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.login.TicketGrantingTicketCheckAction.doExecute",
	"Comment": "determines whether the tgt in the flow request context is valid.",
	"Method": "Event doExecute(RequestContext requestContext){\r\n    val tgtId = WebUtils.getTicketGrantingTicketId(requestContext);\r\n    if (StringUtils.isBlank(tgtId)) {\r\n        return new Event(this, CasWebflowConstants.TRANSITION_ID_TGT_NOT_EXISTS);\r\n    }\r\n    try {\r\n        val ticket = this.centralAuthenticationService.getTicket(tgtId, Ticket.class);\r\n        if (ticket != null && !ticket.isExpired()) {\r\n            return new Event(this, CasWebflowConstants.TRANSITION_ID_TGT_VALID);\r\n        }\r\n    } catch (final AbstractTicketException e) {\r\n        LOGGER.trace(\"Could not retrieve ticket id [{}] from registry.\", e.getMessage());\r\n    }\r\n    return new Event(this, CasWebflowConstants.TRANSITION_ID_TGT_INVALID);\r\n}"
}, {
	"Path": "com.android.dx.rop.code.LocalVariableInfo.getAssignment",
	"Comment": "gets the named register being assigned by the given instruction, ifpreviously stored in this instance.",
	"Method": "RegisterSpec getAssignment(Insn insn){\r\n    return insnAssignments.get(insn);\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.principal.PrincipalResolver.resolve",
	"Comment": "resolves a principal from the given credential using an arbitrary strategy.",
	"Method": "Principal resolve(Credential credential,Principal resolve,Credential credential,Optional<AuthenticationHandler> handler,Principal resolve,Credential credential,Optional<Principal> principal,Optional<AuthenticationHandler> handler){\r\n    return resolve(credential, Optional.empty(), handler);\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.RegisterAllocator.getDefinitionSpecForSsaReg",
	"Comment": "returns the registerspec of the definition of the register.",
	"Method": "RegisterSpec getDefinitionSpecForSsaReg(int reg){\r\n    SsaInsn definition = ssaMeth.getDefinitionForRegister(reg);\r\n    return definition == null ? null : definition.getResult();\r\n}"
}, {
	"Path": "org.apereo.cas.services.CasServiceRegistryInitializerConfigurationEventListener.handleRefreshEvent",
	"Comment": "handle refresh event when issued to this cas server locally.",
	"Method": "void handleRefreshEvent(EnvironmentChangeEvent event){\r\n    LOGGER.trace(\"Received event [{}]\", event);\r\n    rebind();\r\n}"
}, {
	"Path": "org.objectweb.asm.MethodVisitor.visitLabel",
	"Comment": "visits a label. a label designates the instruction that will be visitedjust after it.",
	"Method": "void visitLabel(Label label){\r\n    if (mv != null) {\r\n        mv.visitLabel(label);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.MachineReading.removeSkippableRelations",
	"Comment": "removes any relations with relation types in relationstoskip from a dataset.dataset is modified in place.",
	"Method": "void removeSkippableRelations(Annotation dataset,Set<String> relationsToSkip){\r\n    if (relationsToSkip == null || relationsToSkip.isEmpty()) {\r\n        return;\r\n    }\r\n    for (CoreMap sent : dataset.get(CoreAnnotations.SentencesAnnotation.class)) {\r\n        List<RelationMention> relationMentions = sent.get(MachineReadingAnnotations.RelationMentionsAnnotation.class);\r\n        if (relationMentions == null) {\r\n            continue;\r\n        }\r\n        List<RelationMention> newRelationMentions = new ArrayList();\r\n        for (RelationMention rm : relationMentions) {\r\n            if (!relationsToSkip.contains(rm.getType())) {\r\n                newRelationMentions.add(rm);\r\n            }\r\n        }\r\n        sent.set(MachineReadingAnnotations.RelationMentionsAnnotation.class, newRelationMentions);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.rop.type.Type.isPrimitive",
	"Comment": "gets whether this type is a primitive type. all types are eitherprimitive or reference types.",
	"Method": "boolean isPrimitive(){\r\n    switch(basicType) {\r\n        case BT_BOOLEAN:\r\n        case BT_BYTE:\r\n        case BT_CHAR:\r\n        case BT_DOUBLE:\r\n        case BT_FLOAT:\r\n        case BT_INT:\r\n        case BT_LONG:\r\n        case BT_SHORT:\r\n        case BT_VOID:\r\n            {\r\n                return true;\r\n            }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.apache.commons.cli.OptionValidator.isValidChar",
	"Comment": "returns whether the specified character is a valid character.",
	"Method": "boolean isValidChar(char c){\r\n    return Character.isJavaIdentifierPart(c);\r\n}"
}, {
	"Path": "org.apereo.cas.web.AbstractServiceValidateController.verifyRegisteredServiceProperties",
	"Comment": "ensure that the service is found and enabled in the service registry.",
	"Method": "void verifyRegisteredServiceProperties(RegisteredService registeredService,Service service){\r\n    if (registeredService == null) {\r\n        val msg = String.format(\"Service [%s] is not found in service registry.\", service.getId());\r\n        LOGGER.warn(msg);\r\n        throw new UnauthorizedServiceException(UnauthorizedServiceException.CODE_UNAUTHZ_SERVICE, msg);\r\n    }\r\n    if (!registeredService.getAccessStrategy().isServiceAccessAllowed()) {\r\n        val msg = String.format(\"ServiceManagement: Unauthorized Service Access. \" + \"Service [%s] is not enabled in service registry.\", service.getId());\r\n        LOGGER.warn(msg);\r\n        throw new UnauthorizedServiceException(UnauthorizedServiceException.CODE_UNAUTHZ_SERVICE, msg);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.movePropagate",
	"Comment": "identifies extra moves added by scalar replacement and propagates thesource of the move to any users of the result.",
	"Method": "void movePropagate(){\r\n    for (int i = 0; i < ssaMeth.getRegCount(); i++) {\r\n        SsaInsn insn = ssaMeth.getDefinitionForRegister(i);\r\n        if (insn == null || insn.getOpcode() == null || insn.getOpcode().getOpcode() != RegOps.MOVE) {\r\n            continue;\r\n        }\r\n        final ArrayList<SsaInsn>[] useList = ssaMeth.getUseListCopy();\r\n        final RegisterSpec source = insn.getSources().get(0);\r\n        final RegisterSpec result = insn.getResult();\r\n        if (source.getReg() < regCount && result.getReg() < regCount) {\r\n            continue;\r\n        }\r\n        RegisterMapper mapper = new RegisterMapper() {\r\n            @Override\r\n            public int getNewRegisterCount() {\r\n                return ssaMeth.getRegCount();\r\n            }\r\n            @Override\r\n            public RegisterSpec map(RegisterSpec registerSpec) {\r\n                if (registerSpec.getReg() == result.getReg()) {\r\n                    return source;\r\n                }\r\n                return registerSpec;\r\n            }\r\n        };\r\n        for (SsaInsn use : useList[result.getReg()]) {\r\n            use.mapSourceRegisters(mapper);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.movePropagate",
	"Comment": "identifies extra moves added by scalar replacement and propagates thesource of the move to any users of the result.",
	"Method": "void movePropagate(){\r\n    return ssaMeth.getRegCount();\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.movePropagate",
	"Comment": "identifies extra moves added by scalar replacement and propagates thesource of the move to any users of the result.",
	"Method": "void movePropagate(){\r\n    if (registerSpec.getReg() == result.getReg()) {\r\n        return source;\r\n    }\r\n    return registerSpec;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.Synthetic.hotspot",
	"Comment": "returns a sequence of events resembling a hotspot distribution where x% of operations access y%of data items. the parameters specify the bounds for the numbers, the percentage of the of theinterval which comprises the hot set and the percentage of operations that access the hot set.numbers of the hot set are always smaller than any number in the cold set. elements from thehot set and the cold set are chose using a uniform distribution.",
	"Method": "LongStream hotspot(int lowerBound,int upperBound,double hotsetFraction,double hotOpnFraction,int events){\r\n    return generate(new HotspotIntegerGenerator(lowerBound, upperBound, hotsetFraction, hotOpnFraction), events);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.GeneralDataset.retainFeatures",
	"Comment": "retains the given features in the dataset.all features thatdo not occur in features are expunged.",
	"Method": "void retainFeatures(Set<F> features){\r\n    Index<F> newFeatureIndex = new HashIndex();\r\n    int[] featMap = new int[featureIndex.size()];\r\n    for (int i = 0; i < featMap.length; i++) {\r\n        F feat = featureIndex.get(i);\r\n        if (features.contains(feat)) {\r\n            int newIndex = newFeatureIndex.size();\r\n            newFeatureIndex.add(feat);\r\n            featMap[i] = newIndex;\r\n        } else {\r\n            featMap[i] = -1;\r\n        }\r\n    }\r\n    featureIndex = newFeatureIndex;\r\n    for (int i = 0; i < size; i++) {\r\n        List<Integer> featList = new ArrayList(data[i].length);\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            if (featMap[data[i][j]] >= 0) {\r\n                featList.add(featMap[data[i][j]]);\r\n            }\r\n        }\r\n        data[i] = new int[featList.size()];\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            data[i][j] = featList.get(j);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.Base64.isBase64",
	"Comment": "tests a given byte array to see if it contains only valid characters within the base64 alphabet. currently themethod treats whitespace as valid.",
	"Method": "boolean isBase64(byte octet,boolean isBase64,String base64,boolean isBase64,byte[] arrayOctet){\r\n    for (int i = 0; i < arrayOctet.length; i++) {\r\n        if (!isBase64(arrayOctet[i]) && !isWhiteSpace(arrayOctet[i])) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.RVFDataset.scaleFeatures",
	"Comment": "scales feature values linearly such that each feature value lies between 0and 1.",
	"Method": "void scaleFeatures(){\r\n    minValues = new double[featureIndex.size()];\r\n    maxValues = new double[featureIndex.size()];\r\n    Arrays.fill(minValues, Double.POSITIVE_INFINITY);\r\n    Arrays.fill(maxValues, Double.NEGATIVE_INFINITY);\r\n    for (int i = 0; i < size(); i++) {\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            int f = data[i][j];\r\n            if (values[i][j] < minValues[f])\r\n                minValues[f] = values[i][j];\r\n            if (values[i][j] > maxValues[f])\r\n                maxValues[f] = values[i][j];\r\n        }\r\n    }\r\n    for (int f = 0; f < featureIndex.size(); f++) {\r\n        if (minValues[f] == Double.POSITIVE_INFINITY)\r\n            throw new RuntimeException(\"minValue for feature \" + f + \" not assigned. \");\r\n        if (maxValues[f] == Double.NEGATIVE_INFINITY)\r\n            throw new RuntimeException(\"maxValue for feature \" + f + \" not assigned.\");\r\n    }\r\n    for (int i = 0; i < size(); i++) {\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            int f = data[i][j];\r\n            if (minValues[f] != maxValues[f])\r\n                values[i][j] = (values[i][j] - minValues[f]) / (maxValues[f] - minValues[f]);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.resolver.impl.AbstractCasWebflowEventResolver.newEvent",
	"Comment": "new event based on the id, which contains an error attribute referring to the exception occurred.",
	"Method": "Event newEvent(String id,Throwable error,Event newEvent,String id,Event newEvent,String id,AttributeMap attributes){\r\n    return new Event(this, id, attributes);\r\n}"
}, {
	"Path": "org.apereo.cas.services.DefaultRegisteredServiceAccessStrategy.enoughRequiredAttributesAvailableToProcess",
	"Comment": "enough required attributes available to process? check collection sizes and determineif we have enough data to move on.",
	"Method": "boolean enoughRequiredAttributesAvailableToProcess(Map<String, Object> principalAttributes,Map<String, Set<String>> requiredAttributes){\r\n    if (principalAttributes.isEmpty() && !requiredAttributes.isEmpty()) {\r\n        LOGGER.debug(\"No principal attributes are found to satisfy defined attribute requirements\");\r\n        return false;\r\n    }\r\n    if (principalAttributes.size() < requiredAttributes.size()) {\r\n        LOGGER.debug(\"The size of the principal attributes that are [{}] does not match defined required attributes, \" + \"which indicates the principal is not carrying enough data to grant authorization\", principalAttributes);\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getElementType",
	"Comment": "returns the type of the elements of this array type. this method shouldonly be used for an array type.",
	"Method": "Type getElementType(){\r\n    return getType(buf, off + getDimensions());\r\n}"
}, {
	"Path": "org.apache.commons.cli.AlreadySelectedException.getOption",
	"Comment": "returns the option that was added to the group and triggered the exception.",
	"Method": "Option getOption(){\r\n    return option;\r\n}"
}, {
	"Path": "org.apache.commons.cli.Parser.processArgs",
	"Comment": "process the argument values for the specified optionopt using the values retrieved from thespecified iterator iter.",
	"Method": "void processArgs(Option opt,ListIterator<String> iter){\r\n    while (iter.hasNext()) {\r\n        String str = iter.next();\r\n        if (getOptions().hasOption(str) && str.startsWith(\"-\")) {\r\n            iter.previous();\r\n            break;\r\n        }\r\n        try {\r\n            opt.addValueForProcessing(Util.stripLeadingAndTrailingQuotes(str));\r\n        } catch (RuntimeException exp) {\r\n            iter.previous();\r\n            break;\r\n        }\r\n    }\r\n    if (opt.getValues() == null && !opt.hasOptionalArg()) {\r\n        throw new MissingArgumentException(opt);\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.LocalVariableNode.accept",
	"Comment": "makes the given visitor visit this local variable declaration.",
	"Method": "void accept(MethodVisitor mv){\r\n    mv.visitLocalVariable(name, desc, signature, start.getLabel(), end.getLabel(), index);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFBiasedClassifier.main",
	"Comment": "the main method, which is essentially the same as in crfclassifier. see the class documentation.",
	"Method": "void main(String[] args){\r\n    StringUtils.logInvocationString(log, args);\r\n    Properties props = StringUtils.argsToProperties(args);\r\n    CRFBiasedClassifier<CoreLabel> crf = new CRFBiasedClassifier(props);\r\n    String testFile = crf.flags.testFile;\r\n    String loadPath = crf.flags.loadClassifier;\r\n    if (loadPath != null) {\r\n        crf.loadClassifierNoExceptions(loadPath, props);\r\n    } else if (crf.flags.loadJarClassifier != null) {\r\n        crf.loadClassifierNoExceptions(crf.flags.loadJarClassifier, props);\r\n    } else {\r\n        crf.loadDefaultClassifier();\r\n    }\r\n    if (crf.flags.classBias != null) {\r\n        StringTokenizer biases = new java.util.StringTokenizer(crf.flags.classBias, \",\");\r\n        while (biases.hasMoreTokens()) {\r\n            StringTokenizer bias = new java.util.StringTokenizer(biases.nextToken(), \":\");\r\n            String cname = bias.nextToken();\r\n            double w = Double.parseDouble(bias.nextToken());\r\n            crf.setBiasWeight(cname, w);\r\n            log.info(\"Setting bias for class \" + cname + \" to \" + w);\r\n        }\r\n    }\r\n    if (testFile != null) {\r\n        DocumentReaderAndWriter<CoreLabel> readerAndWriter = crf.makeReaderAndWriter();\r\n        if (crf.flags.printFirstOrderProbs) {\r\n            crf.printFirstOrderProbs(testFile, readerAndWriter);\r\n        } else if (crf.flags.printProbs) {\r\n            crf.printProbs(testFile, readerAndWriter);\r\n        } else if (crf.flags.useKBest) {\r\n            int k = crf.flags.kBest;\r\n            crf.classifyAndWriteAnswersKBest(testFile, k, readerAndWriter);\r\n        } else {\r\n            crf.classifyAndWriteAnswers(testFile, readerAndWriter, true);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.RegisterAllocator.insertMoveBefore",
	"Comment": "inserts a move instruction for a specified ssa register before aspecified instruction, creating a new ssa register and adjusting theinterference graph in the process. the insn currently must be thelast insn in a block.",
	"Method": "RegisterSpec insertMoveBefore(SsaInsn insn,RegisterSpec reg){\r\n    SsaBasicBlock block = insn.getBlock();\r\n    ArrayList<SsaInsn> insns = block.getInsns();\r\n    int insnIndex = insns.indexOf(insn);\r\n    if (insnIndex < 0) {\r\n        throw new IllegalArgumentException(\"specified insn is not in this block\");\r\n    }\r\n    if (insnIndex != insns.size() - 1) {\r\n        throw new IllegalArgumentException(\"Adding move here not supported:\" + insn.toHuman());\r\n    }\r\n    RegisterSpec newRegSpec = RegisterSpec.make(ssaMeth.makeNewSsaReg(), reg.getTypeBearer());\r\n    SsaInsn toAdd = SsaInsn.makeFromRop(new PlainInsn(Rops.opMove(newRegSpec.getType()), SourcePosition.NO_INFO, newRegSpec, RegisterSpecList.make(reg)), block);\r\n    insns.add(insnIndex, toAdd);\r\n    int newReg = newRegSpec.getReg();\r\n    IntSet liveOut = block.getLiveOutRegs();\r\n    IntIterator liveOutIter = liveOut.iterator();\r\n    while (liveOutIter.hasNext()) {\r\n        interference.add(newReg, liveOutIter.next());\r\n    }\r\n    RegisterSpecList sources = insn.getSources();\r\n    int szSources = sources.size();\r\n    for (int i = 0; i < szSources; i++) {\r\n        interference.add(newReg, sources.get(i).getReg());\r\n    }\r\n    ssaMeth.onInsnsChanged();\r\n    return newRegSpec;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.CacheProxy.tryClose",
	"Comment": "attempts to close the resource. if an error occurs and an outermost exception is set, then addsthe error to the suppression list.",
	"Method": "Throwable tryClose(Object o,Throwable outer){\r\n    if (o instanceof Closeable) {\r\n        try {\r\n            ((Closeable) o).close();\r\n        } catch (Throwable t) {\r\n            if (outer == null) {\r\n                return t;\r\n            }\r\n            outer.addSuppressed(t);\r\n            return outer;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.product.TCachePolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new TCachePolicy(config));\r\n}"
}, {
	"Path": "org.objectweb.asm.Frame.merge",
	"Comment": "merges the type at the given index in the given type array with the giventype. returns true if the type array has been modified by thisoperation.",
	"Method": "boolean merge(ClassWriter cw,Frame frame,int edge,boolean merge,ClassWriter cw,int t,int[] types,int index){\r\n    int u = types[index];\r\n    if (u == t) {\r\n        return false;\r\n    }\r\n    if ((t & ~DIM) == NULL) {\r\n        if (u == NULL) {\r\n            return false;\r\n        }\r\n        t = NULL;\r\n    }\r\n    if (u == 0) {\r\n        types[index] = t;\r\n        return true;\r\n    }\r\n    int v;\r\n    if ((u & BASE_KIND) == OBJECT || (u & DIM) != 0) {\r\n        if (t == NULL) {\r\n            return false;\r\n        } else if ((t & (DIM | BASE_KIND)) == (u & (DIM | BASE_KIND))) {\r\n            if ((u & BASE_KIND) == OBJECT) {\r\n                v = (t & DIM) | OBJECT | cw.getMergedType(t & BASE_VALUE, u & BASE_VALUE);\r\n            } else {\r\n                int vdim = ELEMENT_OF + (u & DIM);\r\n                v = vdim | OBJECT | cw.addType(\"java/lang/Object\");\r\n            }\r\n        } else if ((t & BASE_KIND) == OBJECT || (t & DIM) != 0) {\r\n            int tdim = (((t & DIM) == 0 || (t & BASE_KIND) == OBJECT) ? 0 : ELEMENT_OF) + (t & DIM);\r\n            int udim = (((u & DIM) == 0 || (u & BASE_KIND) == OBJECT) ? 0 : ELEMENT_OF) + (u & DIM);\r\n            v = Math.min(tdim, udim) | OBJECT | cw.addType(\"java/lang/Object\");\r\n        } else {\r\n            v = TOP;\r\n        }\r\n    } else if (u == NULL) {\r\n        v = (t & BASE_KIND) == OBJECT || (t & DIM) != 0 ? t : TOP;\r\n    } else {\r\n        v = TOP;\r\n    }\r\n    if (u != v) {\r\n        types[index] = v;\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.event.EventDispatcher.publishUpdated",
	"Comment": "publishes a update event for the entry to all of the interested listeners.",
	"Method": "void publishUpdated(Cache<K, V> cache,K key,V oldValue,V newValue){\r\n    publish(cache, EventType.UPDATED, key, oldValue, newValue, false);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.irr.ClockProPolicy.add",
	"Comment": "add meta data after hand hot, evict data if required, and update hands accordingly.",
	"Method": "void add(Node node){\r\n    evict();\r\n    if (handHot == null) {\r\n        handHot = handCold = handTest = node;\r\n        node.next = node.prev = node;\r\n    } else {\r\n        node.prev = handHot;\r\n        node.next = handHot.next;\r\n        handHot.next.prev = node;\r\n        handHot.next = node;\r\n    }\r\n    if (handCold == handHot) {\r\n        handCold = node.next;\r\n    }\r\n    if (handTest == handHot) {\r\n        handTest = node.next;\r\n    }\r\n    handHot = node.next;\r\n}"
}, {
	"Path": "org.apereo.cas.adaptors.jdbc.QueryDatabaseAuthenticationHandlerTests.verifyBCryptSuccess",
	"Comment": "this test proves that in case bcrypt andusing raw password test can authenticate",
	"Method": "void verifyBCryptSuccess(){\r\n    val encoder = new BCryptPasswordEncoder(6, RandomUtils.getNativeInstance());\r\n    val sql = SQL.replace(\"*\", '\\'' + encoder.encode(\"pswbc2\") + \"' password\");\r\n    val q = new QueryDatabaseAuthenticationHandler(\"\", null, null, null, this.dataSource, sql, PASSWORD_FIELD, null, null, new HashMap(0));\r\n    q.setPasswordEncoder(encoder);\r\n    assertNotNull(q.authenticate(CoreAuthenticationTestUtils.getCredentialsWithDifferentUsernameAndPassword(\"user3\", \"pswbc2\")));\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.replaceUse",
	"Comment": "replaces the use for a scalar replaceable array. gets and puts becomemove instructions, and array lengths and fills are handled. can alsoidentify arrayindexoutofbounds exceptions and throw them if detected.",
	"Method": "void replaceUse(SsaInsn use,SsaInsn prev,ArrayList<RegisterSpec> newRegs,HashSet<SsaInsn> deletedInsns){\r\n    int index;\r\n    int length = newRegs.size();\r\n    SsaInsn next;\r\n    RegisterSpecList sources;\r\n    RegisterSpec source, result;\r\n    CstLiteralBits indexReg;\r\n    switch(use.getOpcode().getOpcode()) {\r\n        case RegOps.AGET:\r\n            next = getMoveForInsn(use);\r\n            sources = use.getSources();\r\n            indexReg = ((CstLiteralBits) sources.get(1).getTypeBearer());\r\n            index = indexReg.getIntBits();\r\n            if (index < length) {\r\n                source = newRegs.get(index);\r\n                result = source.withReg(next.getResult().getReg());\r\n                insertPlainInsnBefore(next, RegisterSpecList.make(source), result, RegOps.MOVE, null);\r\n            } else {\r\n                insertExceptionThrow(next, sources.get(1), deletedInsns);\r\n                deletedInsns.add(next.getBlock().getInsns().get(2));\r\n            }\r\n            deletedInsns.add(next);\r\n            break;\r\n        case RegOps.APUT:\r\n            sources = use.getSources();\r\n            indexReg = ((CstLiteralBits) sources.get(2).getTypeBearer());\r\n            index = indexReg.getIntBits();\r\n            if (index < length) {\r\n                source = sources.get(0);\r\n                result = source.withReg(newRegs.get(index).getReg());\r\n                insertPlainInsnBefore(use, RegisterSpecList.make(source), result, RegOps.MOVE, null);\r\n                newRegs.set(index, result.withSimpleType());\r\n            } else {\r\n                insertExceptionThrow(use, sources.get(2), deletedInsns);\r\n            }\r\n            break;\r\n        case RegOps.ARRAY_LENGTH:\r\n            TypeBearer lengthReg = prev.getSources().get(0).getTypeBearer();\r\n            next = getMoveForInsn(use);\r\n            insertPlainInsnBefore(next, RegisterSpecList.EMPTY, next.getResult(), RegOps.CONST, (Constant) lengthReg);\r\n            deletedInsns.add(next);\r\n            break;\r\n        case RegOps.MARK_LOCAL:\r\n            break;\r\n        case RegOps.FILL_ARRAY_DATA:\r\n            Insn ropUse = use.getOriginalRopInsn();\r\n            FillArrayDataInsn fill = (FillArrayDataInsn) ropUse;\r\n            ArrayList<Constant> constList = fill.getInitValues();\r\n            for (int i = 0; i < length; i++) {\r\n                RegisterSpec newFill = RegisterSpec.make(newRegs.get(i).getReg(), (TypeBearer) constList.get(i));\r\n                insertPlainInsnBefore(use, RegisterSpecList.EMPTY, newFill, RegOps.CONST, constList.get(i));\r\n                newRegs.set(i, newFill);\r\n            }\r\n            break;\r\n        default:\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.RegexNERAnnotatorITest.checkTags",
	"Comment": "helper method, checks that each token is tagged with the expected ner type.",
	"Method": "void checkTags(List<CoreLabel> tokens,String tags){\r\n    assertEquals(tags.length, tokens.size());\r\n    for (int i = 0; i < tags.length; ++i) {\r\n        assertEquals(\"Mismatch for token \" + i + \" \" + tokens.get(i), tags[i], tokens.get(i).get(CoreAnnotations.NamedEntityTagAnnotation.class));\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.support.saml.web.idp.profile.builders.enc.SamlIdPObjectSigner.buildSignatureSigningParameters",
	"Comment": "build signature signing parameters signature signing parameters.",
	"Method": "SignatureSigningParameters buildSignatureSigningParameters(RoleDescriptor descriptor,SamlRegisteredService service){\r\n    val criteria = new CriteriaSet();\r\n    val signatureSigningConfiguration = getSignatureSigningConfiguration(descriptor, service);\r\n    criteria.add(new SignatureSigningConfigurationCriterion(signatureSigningConfiguration));\r\n    criteria.add(new RoleDescriptorCriterion(descriptor));\r\n    val resolver = new SAMLMetadataSignatureSigningParametersResolver();\r\n    LOGGER.trace(\"Resolving signature signing parameters for [{}]\", descriptor.getElementQName().getLocalPart());\r\n    @NonNull\r\n    val params = resolver.resolveSingle(criteria);\r\n    LOGGER.trace(\"Created signature signing parameters.\" + \"\\nSignature algorithm: [{}]\" + \"\\nSignature canonicalization algorithm: [{}]\" + \"\\nSignature reference digest methods: [{}]\", params.getSignatureAlgorithm(), params.getSignatureCanonicalizationAlgorithm(), params.getSignatureReferenceDigestMethod());\r\n    return params;\r\n}"
}, {
	"Path": "org.apereo.cas.util.EncodingUtils.encryptValueAsJwt",
	"Comment": "encrypt the value based on the seed array whose length was given during afterpropertiesset,and the key and content encryption ids.",
	"Method": "String encryptValueAsJwt(Key secretKeyEncryptionKey,Serializable value,String algorithmHeaderValue,String contentEncryptionAlgorithmIdentifier){\r\n    try {\r\n        val jwe = new JsonWebEncryption();\r\n        jwe.setPayload(value.toString());\r\n        jwe.enableDefaultCompression();\r\n        jwe.setAlgorithmHeaderValue(algorithmHeaderValue);\r\n        jwe.setEncryptionMethodHeaderParameter(contentEncryptionAlgorithmIdentifier);\r\n        jwe.setKey(secretKeyEncryptionKey);\r\n        jwe.setHeader(\"typ\", \"JWT\");\r\n        LOGGER.trace(\"Encrypting via [{}]\", contentEncryptionAlgorithmIdentifier);\r\n        return jwe.getCompactSerialization();\r\n    } catch (final Exception e) {\r\n        throw new IllegalArgumentException(\"Is JCE Unlimited Strength Jurisdiction Policy installed? \" + e.getMessage(), e);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.AbstractSequenceClassifier.countResults",
	"Comment": "count results using a method appropriate for the tag scheme being used.",
	"Method": "boolean countResults(List<IN> doc,Counter<String> entityTP,Counter<String> entityFP,Counter<String> entityFN){\r\n    String bg = (flags.evaluateBackground ? null : flags.backgroundSymbol);\r\n    if (flags.sighanPostProcessing) {\r\n        return countResultsSegmenter(doc, entityTP, entityFP, entityFN);\r\n    }\r\n    return IOBUtils.countEntityResults(doc, entityTP, entityFP, entityFN, bg);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.MachineReading.makeReader",
	"Comment": "constructs the corpus reader class and sets it as the reader for this machinereading instance.",
	"Method": "GenericDataSetReader makeReader(Properties props){\r\n    try {\r\n        if (reader == null) {\r\n            try {\r\n                reader = MachineReadingProperties.datasetReaderClass.getConstructor(Properties.class).newInstance(props);\r\n            } catch (java.lang.NoSuchMethodException e) {\r\n                reader = MachineReadingProperties.datasetReaderClass.getConstructor().newInstance();\r\n            }\r\n        }\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n    reader.setUseNewHeadFinder(MachineReadingProperties.useNewHeadFinder);\r\n    return reader;\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.logout.TerminateSessionAction.destroyApplicationSession",
	"Comment": "destroy application session.also kills all delegated authn profiles via pac4j.",
	"Method": "void destroyApplicationSession(HttpServletRequest request,HttpServletResponse response){\r\n    LOGGER.trace(\"Destroying application session\");\r\n    val manager = Pac4jUtils.getPac4jProfileManager(request, response);\r\n    manager.logout();\r\n    val session = request.getSession(false);\r\n    if (session != null) {\r\n        val requestedUrl = session.getAttribute(Pac4jConstants.REQUESTED_URL);\r\n        session.invalidate();\r\n        if (requestedUrl != null && !requestedUrl.equals(\"\")) {\r\n            request.getSession(true).setAttribute(Pac4jConstants.REQUESTED_URL, requestedUrl);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.cli.HelpFormatter.renderWrappedTextBlock",
	"Comment": "render the specified text width a maximum width. this method differsfrom renderwrappedtext by not removing leading spaces after a new line.",
	"Method": "Appendable renderWrappedTextBlock(StringBuffer sb,int width,int nextLineTabStop,String text){\r\n    try {\r\n        BufferedReader in = new BufferedReader(new StringReader(text));\r\n        String line;\r\n        boolean firstLine = true;\r\n        while ((line = in.readLine()) != null) {\r\n            if (!firstLine) {\r\n                sb.append(getNewLine());\r\n            } else {\r\n                firstLine = false;\r\n            }\r\n            renderWrappedText(sb, width, nextLineTabStop, line);\r\n        }\r\n    } catch (IOException e) {\r\n    }\r\n    return sb;\r\n}"
}, {
	"Path": "org.apache.commons.codec.digest.DigestUtils.md2Hex",
	"Comment": "calculates the md2 digest and returns the value as a 32 character hex string.",
	"Method": "String md2Hex(byte[] data,String md2Hex,ByteBuffer data,String md2Hex,InputStream data,String md2Hex,String data){\r\n    return Hex.encodeHexString(md2(data));\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.GeneralDataset.numFeatureTypes",
	"Comment": "returns the number of distinct feature types in the dataset.",
	"Method": "int numFeatureTypes(){\r\n    return featureIndex.size();\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.getTopFeaturesLabelIndices",
	"Comment": "returns list of top features with weight above a certain threshold",
	"Method": "List<Triple<F, L, Double>> getTopFeaturesLabelIndices(Set<Integer> iLabels,double threshold,boolean useMagnitude,int numFeatures,boolean descending){\r\n    edu.stanford.nlp.util.PriorityQueue<Pair<Integer, Integer>> biggestKeys = new FixedPrioritiesPriorityQueue();\r\n    for (int feat = 0; feat < weights.length; feat++) {\r\n        for (int lab = 0; lab < weights[feat].length; lab++) {\r\n            if (iLabels != null && !iLabels.contains(lab)) {\r\n                continue;\r\n            }\r\n            double thisWeight;\r\n            if (useMagnitude) {\r\n                thisWeight = Math.abs(weights[feat][lab]);\r\n            } else {\r\n                thisWeight = weights[feat][lab];\r\n            }\r\n            if (thisWeight > threshold) {\r\n                thisWeight = -thisWeight;\r\n                if (biggestKeys.size() == numFeatures) {\r\n                    double lowest = biggestKeys.getPriority();\r\n                    if (thisWeight < lowest) {\r\n                        biggestKeys.removeFirst();\r\n                        biggestKeys.add(new Pair(feat, lab), thisWeight);\r\n                    }\r\n                } else {\r\n                    biggestKeys.add(new Pair(feat, lab), thisWeight);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    List<Triple<F, L, Double>> topFeatures = new ArrayList(biggestKeys.size());\r\n    while (!biggestKeys.isEmpty()) {\r\n        Pair<Integer, Integer> p = biggestKeys.removeFirst();\r\n        double weight = weights[p.first()][p.second()];\r\n        F feat = featureIndex.get(p.first());\r\n        L label = labelIndex.get(p.second());\r\n        topFeatures.add(new Triple(feat, label, weight));\r\n    }\r\n    if (descending) {\r\n        Collections.reverse(topFeatures);\r\n    }\r\n    return topFeatures;\r\n}"
}, {
	"Path": "org.objectweb.asm.signature.SignatureVisitor.visitTypeArgument",
	"Comment": "visits a type argument of the last visited class or inner class type.",
	"Method": "void visitTypeArgument(SignatureVisitor visitTypeArgument,char wildcard){\r\n    return this;\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.AbstractInsnNode.cloneAnnotations",
	"Comment": "clones the annotations of the given instruction into this instruction.",
	"Method": "AbstractInsnNode cloneAnnotations(AbstractInsnNode insn){\r\n    if (insn.visibleTypeAnnotations != null) {\r\n        this.visibleTypeAnnotations = new ArrayList<TypeAnnotationNode>();\r\n        for (int i = 0; i < insn.visibleTypeAnnotations.size(); ++i) {\r\n            TypeAnnotationNode src = insn.visibleTypeAnnotations.get(i);\r\n            TypeAnnotationNode ann = new TypeAnnotationNode(src.typeRef, src.typePath, src.desc);\r\n            src.accept(ann);\r\n            this.visibleTypeAnnotations.add(ann);\r\n        }\r\n    }\r\n    if (insn.invisibleTypeAnnotations != null) {\r\n        this.invisibleTypeAnnotations = new ArrayList<TypeAnnotationNode>();\r\n        for (int i = 0; i < insn.invisibleTypeAnnotations.size(); ++i) {\r\n            TypeAnnotationNode src = insn.invisibleTypeAnnotations.get(i);\r\n            TypeAnnotationNode ann = new TypeAnnotationNode(src.typeRef, src.typePath, src.desc);\r\n            src.accept(ann);\r\n            this.invisibleTypeAnnotations.add(ann);\r\n        }\r\n    }\r\n    return this;\r\n}"
}, {
	"Path": "edu.stanford.nlp.international.spanish.SpanishTokenizerITest.testSpanishTokenizerCoreNLP",
	"Comment": "makes a spanish tokenizer with the options that corenlp uses. results actually no different....",
	"Method": "void testSpanishTokenizerCoreNLP(){\r\n    assert spanishInputs.length == spanishGold.length;\r\n    final TokenizerFactory<CoreLabel> tf = SpanishTokenizer.coreLabelFactory();\r\n    tf.setOptions(\"\");\r\n    tf.setOptions(\"invertible,ptb3Escaping=true,splitAll=true\");\r\n    runSpanish(tf, spanishInputs, spanishGold);\r\n}"
}, {
	"Path": "com.android.dx.rop.code.LocalVariableExtractor.extract",
	"Comment": "extracts out all the local variable information from the given method.",
	"Method": "LocalVariableInfo extract(RopMethod method){\r\n    LocalVariableExtractor lve = new LocalVariableExtractor(method);\r\n    return lve.doit();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.linked.S4LruPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    BasicSettings settings = new BasicSettings(config);\r\n    return settings.admission().stream().map(admission -> new S4LruPolicy(admission, config)).collect(toSet());\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpec.withOffset",
	"Comment": "returns an instance that is identical to this one, except that theregister number is offset by the given amount.",
	"Method": "RegisterSpec withOffset(int delta){\r\n    if (delta == 0) {\r\n        return this;\r\n    }\r\n    return withReg(reg + delta);\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.annotator.BuckAnnotator.annotateLocalFile",
	"Comment": "annotates targets that refer to files relative to this file.",
	"Method": "boolean annotateLocalFile(BuckSingleExpression targetExpression,String targetValue,AnnotationHolder annotationHolder){\r\n    Optional<VirtualFile> targetFile = Optional.of(targetExpression).map(PsiElement::getContainingFile).map(PsiFile::getVirtualFile).map(VirtualFile::getParent).map(dir -> dir.findFileByRelativePath(targetValue)).filter(VirtualFile::exists);\r\n    if (!targetFile.isPresent()) {\r\n        return false;\r\n    }\r\n    Annotation annotation = annotationHolder.createInfoAnnotation(targetExpression, targetFile.get().getPath());\r\n    annotation.setTextAttributes(BuckSyntaxHighlighter.BUCK_FILE_NAME);\r\n    return true;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.opt.UnboundedPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new UnboundedPolicy());\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.KBPStatisticalExtractor.trainMultinomialClassifier",
	"Comment": "train a multinomial classifier off of the provided dataset.",
	"Method": "Classifier<String, String> trainMultinomialClassifier(GeneralDataset<String, String> dataset,int featureThreshold,double sigma){\r\n    log.info(\"Applying feature threshold (\" + featureThreshold + \")...\");\r\n    dataset.applyFeatureCountThreshold(featureThreshold);\r\n    log.info(\"Randomizing dataset...\");\r\n    dataset.randomize(42l);\r\n    log.info(\"Creating factory...\");\r\n    LinearClassifierFactory<String, String> factory = initFactory(sigma);\r\n    log.info(\"BEGIN training\");\r\n    LinearClassifier<String, String> classifier = factory.trainClassifier(dataset);\r\n    log.info(\"END training\");\r\n    Accuracy trainAccuracy = new Accuracy();\r\n    for (Datum<String, String> datum : dataset) {\r\n        String guess = classifier.classOf(datum);\r\n        trainAccuracy.predict(Collections.singleton(guess), Collections.singleton(datum.label()));\r\n    }\r\n    log.info(\"Training accuracy:\");\r\n    log.info(trainAccuracy.toString());\r\n    log.info(\"\");\r\n    return classifier;\r\n}"
}, {
	"Path": "org.objectweb.asm.xml.ASMContentHandler.startElement",
	"Comment": "process notification of the start of an xml element being reached.",
	"Method": "void startElement(String ns,String lName,String qName,Attributes list){\r\n    String name = lName == null || lName.length() == 0 ? qName : lName;\r\n    StringBuffer sb = new StringBuffer(match);\r\n    if (match.length() > 0) {\r\n        sb.append('/');\r\n    }\r\n    sb.append(name);\r\n    match = sb.toString();\r\n    Rule r = (Rule) RULES.match(match);\r\n    if (r != null) {\r\n        r.begin(name, list);\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.net.BCodec.encode",
	"Comment": "encodes an object into its base64 form using the default charset. unsafe characters are escaped.",
	"Method": "String encode(String value,Charset charset,String encode,String value,String charset,String encode,String value,Object encode,Object value){\r\n    if (value == null) {\r\n        return null;\r\n    } else if (value instanceof String) {\r\n        return encode((String) value);\r\n    } else {\r\n        throw new EncoderException(\"Objects of type \" + value.getClass().getName() + \" cannot be encoded using BCodec\");\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.util.CheckMethodAdapter.checkNonDebugLabel",
	"Comment": "checks that the given label is not a label used only for debug purposes.",
	"Method": "void checkNonDebugLabel(Label label){\r\n    Field f = getLabelStatusField();\r\n    int status = 0;\r\n    try {\r\n        status = f == null ? 0 : ((Integer) f.get(label)).intValue();\r\n    } catch (IllegalAccessException e) {\r\n        throw new Error(\"Internal error\");\r\n    }\r\n    if ((status & 0x01) != 0) {\r\n        throw new IllegalArgumentException(\"Labels used for debug info cannot be reused for control flow\");\r\n    }\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.notification.BuckNotification.showErrorBalloon",
	"Comment": "show an error balloon with the given message and attach the given listener.",
	"Method": "void showErrorBalloon(String message,NotificationListener listener){\r\n    NOTIFICATION_GROUP.createNotification(\"\", message, NotificationType.ERROR, listener).notify(project);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.runTestSet",
	"Comment": "this should be called after the classifier has been trained andparseandtrain has been called to accumulate test setthis will return precision,recall and f1 measure",
	"Method": "void runTestSet(List<List<CoreLabel>> testSet){\r\n    Counter<String> tp = new ClassicCounter();\r\n    Counter<String> fp = new ClassicCounter();\r\n    Counter<String> fn = new ClassicCounter();\r\n    Counter<String> actual = new ClassicCounter();\r\n    for (List<CoreLabel> labels : testSet) {\r\n        List<CoreLabel> unannotatedLabels = new ArrayList();\r\n        for (CoreLabel label : labels) {\r\n            CoreLabel newLabel = new CoreLabel();\r\n            newLabel.set(annotationForWord, label.get(annotationForWord));\r\n            newLabel.set(PartOfSpeechAnnotation.class, label.get(PartOfSpeechAnnotation.class));\r\n            unannotatedLabels.add(newLabel);\r\n        }\r\n        List<CoreLabel> annotatedLabels = this.classifier.classify(unannotatedLabels);\r\n        int ind = 0;\r\n        for (CoreLabel expectedLabel : labels) {\r\n            CoreLabel annotatedLabel = annotatedLabels.get(ind);\r\n            String answer = annotatedLabel.get(AnswerAnnotation.class);\r\n            String expectedAnswer = expectedLabel.get(AnswerAnnotation.class);\r\n            actual.incrementCount(expectedAnswer);\r\n            if (!SeqClassifierFlags.DEFAULT_BACKGROUND_SYMBOL.equals(expectedAnswer) && expectedAnswer.equals(answer)) {\r\n                tp.incrementCount(answer);\r\n                System.out.println(\"True Positive:\" + annotatedLabel);\r\n            } else if (!SeqClassifierFlags.DEFAULT_BACKGROUND_SYMBOL.equals(answer)) {\r\n                fp.incrementCount(answer);\r\n                System.out.println(\"False Positive:\" + annotatedLabel);\r\n            } else if (!SeqClassifierFlags.DEFAULT_BACKGROUND_SYMBOL.equals(expectedAnswer)) {\r\n                fn.incrementCount(expectedAnswer);\r\n                System.out.println(\"False Negative:\" + expectedLabel);\r\n            }\r\n            ind++;\r\n        }\r\n    }\r\n    actual.remove(SeqClassifierFlags.DEFAULT_BACKGROUND_SYMBOL);\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.data.Mention.attributesAgree",
	"Comment": "detects if the mention and candidate antecedent agree on all attributes respectively.",
	"Method": "boolean attributesAgree(Mention potentialAntecedent,Dictionaries dict){\r\n    return (this.animaciesAgree(potentialAntecedent) && this.entityTypesAgree(potentialAntecedent, dict) && this.gendersAgree(potentialAntecedent) && this.numbersAgree(potentialAntecedent));\r\n}"
}, {
	"Path": "org.apereo.cas.ticket.registry.HazelcastTicketRegistry.shutdown",
	"Comment": "make sure we shutdown hazelcast when the context is destroyed.",
	"Method": "void shutdown(){\r\n    try {\r\n        LOGGER.info(\"Shutting down Hazelcast instance [{}]\", this.hazelcastInstance.getConfig().getInstanceName());\r\n        this.hazelcastInstance.shutdown();\r\n    } catch (final Exception e) {\r\n        LOGGER.debug(e.getMessage());\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.signature.SignatureReader.parseType",
	"Comment": "parses a field type signature and makes the given visitor visit it.",
	"Method": "int parseType(String signature,int pos,SignatureVisitor v){\r\n    char c;\r\n    int start, end;\r\n    boolean visited, inner;\r\n    String name;\r\n    switch(c = signature.charAt(pos++)) {\r\n        case 'Z':\r\n        case 'C':\r\n        case 'B':\r\n        case 'S':\r\n        case 'I':\r\n        case 'F':\r\n        case 'J':\r\n        case 'D':\r\n        case 'V':\r\n            v.visitBaseType(c);\r\n            return pos;\r\n        case '[':\r\n            return parseType(signature, pos, v.visitArrayType());\r\n        case 'T':\r\n            end = signature.indexOf(';', pos);\r\n            v.visitTypeVariable(signature.substring(pos, end));\r\n            return end + 1;\r\n        default:\r\n            start = pos;\r\n            visited = false;\r\n            inner = false;\r\n            for (; ; ) {\r\n                switch(c = signature.charAt(pos++)) {\r\n                    case '.':\r\n                    case ';':\r\n                        if (!visited) {\r\n                            name = signature.substring(start, pos - 1);\r\n                            if (inner) {\r\n                                v.visitInnerClassType(name);\r\n                            } else {\r\n                                v.visitClassType(name);\r\n                            }\r\n                        }\r\n                        if (c == ';') {\r\n                            v.visitEnd();\r\n                            return pos;\r\n                        }\r\n                        start = pos;\r\n                        visited = false;\r\n                        inner = true;\r\n                        break;\r\n                    case '<':\r\n                        name = signature.substring(start, pos - 1);\r\n                        if (inner) {\r\n                            v.visitInnerClassType(name);\r\n                        } else {\r\n                            v.visitClassType(name);\r\n                        }\r\n                        visited = true;\r\n                        top: for (; ; ) {\r\n                            switch(c = signature.charAt(pos)) {\r\n                                case '>':\r\n                                    break top;\r\n                                case '*':\r\n                                    ++pos;\r\n                                    v.visitTypeArgument();\r\n                                    break;\r\n                                case '+':\r\n                                case '-':\r\n                                    pos = parseType(signature, pos + 1, v.visitTypeArgument(c));\r\n                                    break;\r\n                                default:\r\n                                    pos = parseType(signature, pos, v.visitTypeArgument('='));\r\n                                    break;\r\n                            }\r\n                        }\r\n                }\r\n            }\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.admission.countmin4.PeriodicResetCountMin4.tryReset",
	"Comment": "reduces every counter by half of its original value. to reduce the truncation error, the sampleis reduced by the number of counters with an odd value.",
	"Method": "void tryReset(boolean added){\r\n    if (!added) {\r\n        return;\r\n    }\r\n    additions++;\r\n    if (additions != period) {\r\n        return;\r\n    }\r\n    int count = 0;\r\n    for (int i = 0; i < table.length; i++) {\r\n        count += Long.bitCount(table[i] & ONE_MASK);\r\n        table[i] = (table[i] >>> 1) & RESET_MASK;\r\n    }\r\n    additions = (additions >>> 1) - (count >>> 2);\r\n    doorkeeper.clear();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.membership.bloom.BloomFilter.ensureCapacity",
	"Comment": "initializes and increases the capacity of this bloomfilter instance, if necessary,to ensure that it can accurately estimate the membership of elements given the expectednumber of insertions. this operation forgets all previous memberships when resizing.",
	"Method": "void ensureCapacity(long expectedInsertions,double fpp){\r\n    checkArgument(expectedInsertions >= 0);\r\n    checkArgument(fpp > 0 && fpp < 1);\r\n    double optimalBitsFactor = -Math.log(fpp) / (Math.log(2) * Math.log(2));\r\n    int optimalNumberOfBits = (int) (expectedInsertions * optimalBitsFactor);\r\n    int optimalSize = optimalNumberOfBits >>> BITS_PER_LONG_SHIFT;\r\n    if ((table != null) && (table.length >= optimalSize)) {\r\n        return;\r\n    } else if (optimalSize == 0) {\r\n        tableShift = Integer.SIZE - 1;\r\n        table = new long[1];\r\n    } else {\r\n        int powerOfTwoShift = Integer.SIZE - Integer.numberOfLeadingZeros(optimalSize - 1);\r\n        tableShift = Integer.SIZE - powerOfTwoShift;\r\n        table = new long[1 << powerOfTwoShift];\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.feedback.FeedbackWindowTinyLfuPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    FeedbackWindowTinyLfuSettings settings = new FeedbackWindowTinyLfuSettings(config);\r\n    return settings.percentMain().stream().map(percentMain -> new FeedbackWindowTinyLfuPolicy(percentMain, settings)).collect(toSet());\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RopMethod.withRegisterOffset",
	"Comment": "returns an instance that is identical to this one, except thatthe registers in each instruction are offset by the givenamount.",
	"Method": "RopMethod withRegisterOffset(int delta){\r\n    RopMethod result = new RopMethod(blocks.withRegisterOffset(delta), firstLabel);\r\n    if (exitPredecessors != null) {\r\n        result.exitPredecessors = exitPredecessors;\r\n        result.predecessors = predecessors;\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.AbstractCentralAuthenticationService.isTicketAuthenticityVerified",
	"Comment": "verify the ticket id received is actually legitimatebefore contacting downstream systems to find and process it.",
	"Method": "boolean isTicketAuthenticityVerified(String ticketId){\r\n    if (this.cipherExecutor != null) {\r\n        LOGGER.trace(\"Attempting to decode service ticket [{}] to verify authenticity\", ticketId);\r\n        return !StringUtils.isEmpty(this.cipherExecutor.decode(ticketId));\r\n    }\r\n    return !StringUtils.isEmpty(ticketId);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.printHistCounts",
	"Comment": "print histogram counts from hist and examples over a certain range",
	"Method": "void printHistCounts(int ind,String title,PrintWriter pw,double[][] hist,Object[][] histEg){\r\n    pw.println(title);\r\n    for (int i = 0; i < 200; i++) {\r\n        int intPart, fracPart;\r\n        if (i < 100) {\r\n            intPart = 10 - ((i + 9) / 10);\r\n            fracPart = (10 - (i % 10)) % 10;\r\n        } else {\r\n            intPart = (i / 10) - 10;\r\n            fracPart = i % 10;\r\n        }\r\n        pw.print(\"[\" + ((i < 100) ? \"-\" : \"\") + intPart + \".\" + fracPart + \", \" + ((i < 100) ? \"-\" : \"\") + intPart + \".\" + fracPart + \"+0.1): \" + hist[ind][i]);\r\n        if (histEg[ind][i] != null) {\r\n            pw.print(\"  [\" + histEg[ind][i] + ((hist[ind][i] > 1) ? \", ...\" : \"\") + \"]\");\r\n        }\r\n        pw.println();\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.services.ServiceRegistry.size",
	"Comment": "return number of records held in this service registry. provides default implementation so that implementationsneeded this new functionality could override it and other implementations not caring for it could be left alone.",
	"Method": "long size(){\r\n    return load().size();\r\n}"
}, {
	"Path": "org.objectweb.asm.MethodVisitor.visitVarInsn",
	"Comment": "visits a local variable instruction. a local variable instruction is aninstruction that loads or stores the value of a local variable.",
	"Method": "void visitVarInsn(int opcode,int var){\r\n    if (mv != null) {\r\n        mv.visitVarInsn(opcode, var);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.RuleBasedCorefMentionFinder.extractPredictedMentions",
	"Comment": "main method of mention detection. extract all np, prp or ne, and filter out by manually written patterns.",
	"Method": "List<List<Mention>> extractPredictedMentions(Annotation doc,int maxID,Dictionaries dict){\r\n    List<List<Mention>> predictedMentions = new ArrayList();\r\n    for (CoreMap s : doc.get(CoreAnnotations.SentencesAnnotation.class)) {\r\n        List<Mention> mentions = new ArrayList();\r\n        predictedMentions.add(mentions);\r\n        Set<IntPair> mentionSpanSet = Generics.newHashSet();\r\n        Set<IntPair> namedEntitySpanSet = Generics.newHashSet();\r\n        extractPremarkedEntityMentions(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        extractNamedEntityMentions(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        extractNPorPRP(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        extractEnumerations(s, mentions, mentionSpanSet, namedEntitySpanSet);\r\n        findHead(s, mentions);\r\n        setBarePlural(mentions);\r\n        removeSpuriousMentions(s, mentions, dict);\r\n    }\r\n    if (assignIds)\r\n        assignMentionIDs(predictedMentions, maxID);\r\n    return predictedMentions;\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.FirstFitLocalCombiningAllocator.fitPlanForRange",
	"Comment": "attempts to build a plan for fitting a range of sources into ropregisters.",
	"Method": "int fitPlanForRange(int ropReg,NormalSsaInsn insn,int[] categoriesForIndex,BitSet outMovesRequired){\r\n    RegisterSpecList sources = insn.getSources();\r\n    int szSources = sources.size();\r\n    int fitWidth = 0;\r\n    IntSet liveOut = insn.getBlock().getLiveOutRegs();\r\n    RegisterSpecList liveOutSpecs = ssaSetToSpecs(liveOut);\r\n    BitSet seen = new BitSet(ssaMeth.getRegCount());\r\n    for (int i = 0; i < szSources; i++) {\r\n        RegisterSpec ssaSpec = sources.get(i);\r\n        int ssaReg = ssaSpec.getReg();\r\n        int category = categoriesForIndex[i];\r\n        if (i != 0) {\r\n            ropReg += categoriesForIndex[i - 1];\r\n        }\r\n        if (ssaRegsMapped.get(ssaReg) && mapper.oldToNew(ssaReg) == ropReg) {\r\n            fitWidth += category;\r\n        } else if (rangeContainsReserved(ropReg, category)) {\r\n            fitWidth = -1;\r\n            break;\r\n        } else if (!ssaRegsMapped.get(ssaReg) && canMapReg(ssaSpec, ropReg) && !seen.get(ssaReg)) {\r\n            fitWidth += category;\r\n        } else if (!mapper.areAnyPinned(liveOutSpecs, ropReg, category) && !mapper.areAnyPinned(sources, ropReg, category)) {\r\n            outMovesRequired.set(i);\r\n        } else {\r\n            fitWidth = -1;\r\n            break;\r\n        }\r\n        seen.set(ssaReg);\r\n    }\r\n    return fitWidth;\r\n}"
}, {
	"Path": "org.objectweb.asm.MethodVisitor.visitEnd",
	"Comment": "visits the end of the method. this method, which is the last one to becalled, is used to inform the visitor that all the annotations andattributes of the method have been visited.",
	"Method": "void visitEnd(){\r\n    if (mv != null) {\r\n        mv.visitEnd();\r\n    }\r\n}"
}, {
	"Path": "com.google.common.cache.CacheLoadingTest.disabled_testInvalidateAndReloadDuringLoading",
	"Comment": "concurrenthashmap does not support this, as it must return back the removed entry",
	"Method": "void disabled_testInvalidateAndReloadDuringLoading(){\r\n    final CountDownLatch computationStarted = new CountDownLatch(2);\r\n    final CountDownLatch letGetFinishSignal = new CountDownLatch(1);\r\n    final CountDownLatch getFinishedSignal = new CountDownLatch(4);\r\n    final String getKey = \"get\";\r\n    final String refreshKey = \"refresh\";\r\n    final String suffix = \"Suffix\";\r\n    CacheLoader<String, String> computeFunction = new CacheLoader<String, String>() {\r\n        @Override\r\n        public String load(String key) {\r\n            computationStarted.countDown();\r\n            assertTrue(Uninterruptibles.awaitUninterruptibly(letGetFinishSignal, 300, TimeUnit.SECONDS));\r\n            return key + suffix;\r\n        }\r\n    };\r\n    final LoadingCache<String, String> cache = CaffeinatedGuava.build(Caffeine.newBuilder(), computeFunction);\r\n    ConcurrentMap<String, String> map = cache.asMap();\r\n    map.put(refreshKey, refreshKey);\r\n    new Thread(() -> {\r\n        cache.getUnchecked(getKey);\r\n        getFinishedSignal.countDown();\r\n    }).start();\r\n    new Thread(() -> {\r\n        cache.refresh(refreshKey);\r\n        getFinishedSignal.countDown();\r\n    }).start();\r\n    assertTrue(computationStarted.await(300, TimeUnit.SECONDS));\r\n    cache.invalidate(getKey);\r\n    cache.invalidate(refreshKey);\r\n    assertFalse(map.containsKey(getKey));\r\n    assertFalse(map.containsKey(refreshKey));\r\n    new Thread(() -> {\r\n        cache.getUnchecked(getKey);\r\n        getFinishedSignal.countDown();\r\n    }).start();\r\n    new Thread(() -> {\r\n        cache.refresh(refreshKey);\r\n        getFinishedSignal.countDown();\r\n    }).start();\r\n    letGetFinishSignal.countDown();\r\n    assertTrue(getFinishedSignal.await(300, TimeUnit.SECONDS));\r\n    checkNothingLogged();\r\n    assertEquals(2, cache.size());\r\n    assertEquals(getKey + suffix, map.get(getKey));\r\n    assertEquals(refreshKey + suffix, map.get(refreshKey));\r\n}"
}, {
	"Path": "com.google.common.cache.CacheLoadingTest.disabled_testInvalidateAndReloadDuringLoading",
	"Comment": "concurrenthashmap does not support this, as it must return back the removed entry",
	"Method": "void disabled_testInvalidateAndReloadDuringLoading(){\r\n    computationStarted.countDown();\r\n    assertTrue(Uninterruptibles.awaitUninterruptibly(letGetFinishSignal, 300, TimeUnit.SECONDS));\r\n    return key + suffix;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.AbstractCaverphone.isEncodeEqual",
	"Comment": "tests if the encodings of two strings are equal.this method might be promoted to a new abstractstringencoder superclass.",
	"Method": "boolean isEncodeEqual(String str1,String str2){\r\n    return this.encode(str1).equals(this.encode(str2));\r\n}"
}, {
	"Path": "org.apereo.cas.util.HttpUtils.prepareHttpRequest",
	"Comment": "prepare http request. tries to set the authorization headerin cases where the url endpoint does not actually produce the headeron its own.",
	"Method": "void prepareHttpRequest(HttpUriRequest request,String basicAuthUsername,String basicAuthPassword,Map<String, Object> parameters){\r\n    if (StringUtils.isNotBlank(basicAuthUsername) && StringUtils.isNotBlank(basicAuthPassword)) {\r\n        val auth = EncodingUtils.encodeBase64(basicAuthUsername + ':' + basicAuthPassword);\r\n        request.setHeader(HttpHeaders.AUTHORIZATION, \"Basic \" + auth);\r\n    }\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.util.BuckCellFinder.findBuckFile",
	"Comment": "finds the buck file most closely associated with the given file.",
	"Method": "Optional<File> findBuckFile(File file,Optional<Path> findBuckFile,Path path,Optional<VirtualFile> findBuckFile,VirtualFile file){\r\n    return findBuckCell(file).flatMap(cell -> {\r\n        String cellRoot = pathMacroExpander.apply(cell.getRoot());\r\n        int cellRootLength = cellRoot.length();\r\n        String buildFilename = cell.getBuildFileName();\r\n        VirtualFile parent = file;\r\n        while (parent.getCanonicalPath().length() >= cellRootLength) {\r\n            VirtualFile buckFile = parent.findChild(buildFilename);\r\n            if (buckFile != null && buckFile.exists() && !buckFile.isDirectory()) {\r\n                return Optional.of(buckFile);\r\n            }\r\n            parent = parent.getParent();\r\n            if (parent == null) {\r\n                break;\r\n            }\r\n            if (parent.getCanonicalPath() == null) {\r\n                break;\r\n            }\r\n        }\r\n        return Optional.empty();\r\n    });\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.MatchRatingApproachEncoder.isVowel",
	"Comment": "determines if a letter is a vowel.api usageconsider this method private, it is package protected for unit testing only.",
	"Method": "boolean isVowel(String letter){\r\n    return letter.equalsIgnoreCase(\"E\") || letter.equalsIgnoreCase(\"A\") || letter.equalsIgnoreCase(\"O\") || letter.equalsIgnoreCase(\"I\") || letter.equalsIgnoreCase(\"U\");\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.build.BuckBuildManager.runBuckCommandAndWait",
	"Comment": "execute simple process synchronously in the current thread.",
	"Method": "void runBuckCommandAndWait(BuckCommandHandler handler,Runnable postStartAction){\r\n    saveAndRun(handler, () -> handler.runInCurrentThread(postStartAction));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.WindowTinyLfuPolicy.onMiss",
	"Comment": "adds the entry to the admission window, evicting if necessary.",
	"Method": "void onMiss(long key){\r\n    admittor.record(key);\r\n    Node node = new Node(key, Status.EDEN);\r\n    node.appendToTail(headEden);\r\n    data.put(key, node);\r\n    sizeEden++;\r\n    evict();\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getArgumentTypes",
	"Comment": "returns the argument types of methods of this type. this method shouldonly be used for method types.",
	"Method": "Type[] getArgumentTypes(String methodDescriptor,Type[] getArgumentTypes,Method method,Type[] getArgumentTypes){\r\n    return getArgumentTypes(getDescriptor());\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.PolicyBasedAuthenticationManagerTests.newMockHandler",
	"Comment": "creates a new named mock authentication handler that either successfully validates all credentials or fails tovalidate all credentials.",
	"Method": "AuthenticationHandler newMockHandler(boolean success,AuthenticationHandler newMockHandler,String name,boolean success){\r\n    val mock = mock(AuthenticationHandler.class);\r\n    when(mock.getName()).thenReturn(name);\r\n    when(mock.supports(any(Credential.class))).thenReturn(true);\r\n    if (success) {\r\n        val p = new DefaultPrincipalFactory().createPrincipal(\"nobody\");\r\n        val result = new DefaultAuthenticationHandlerExecutionResult(mock, mock(CredentialMetaData.class), p);\r\n        when(mock.authenticate(any(Credential.class))).thenReturn(result);\r\n    } else {\r\n        when(mock.authenticate(any(Credential.class))).thenThrow(new FailedLoginException());\r\n    }\r\n    return mock;\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.InterferenceGraph.mergeInterferenceSet",
	"Comment": "merges the interference set for a register into a given bit set",
	"Method": "void mergeInterferenceSet(int reg,IntSet set){\r\n    if (reg < interference.size()) {\r\n        set.merge(interference.get(reg));\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpecSet.remove",
	"Comment": "removes a spec from the set. only the register numberof the parameter is significant.",
	"Method": "void remove(RegisterSpec toRemove){\r\n    try {\r\n        specs[toRemove.getReg()] = null;\r\n        size = -1;\r\n    } catch (ArrayIndexOutOfBoundsException ex) {\r\n        throw new IllegalArgumentException(\"bogus reg\");\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.cli.OptionBuilder.hasOptionalArgs",
	"Comment": "the next option can have the specified number of optional arguments.",
	"Method": "OptionBuilder hasOptionalArgs(OptionBuilder hasOptionalArgs,int numArgs){\r\n    OptionBuilder.numberOfArgs = numArgs;\r\n    OptionBuilder.optionalArg = true;\r\n    return INSTANCE;\r\n}"
}, {
	"Path": "org.objectweb.asm.TypeReference.newFormalParameterReference",
	"Comment": "returns a reference to the type of a formal parameter of a method.",
	"Method": "TypeReference newFormalParameterReference(int paramIndex){\r\n    return new TypeReference((METHOD_FORMAL_PARAMETER << 24) | (paramIndex << 16));\r\n}"
}, {
	"Path": "org.apache.commons.codec.digest.HmacUtils.getHmacSha1",
	"Comment": "returns an initialized mac for the hmacsha1 algorithm.every implementation of the java platform is required to support this standard mac algorithm.",
	"Method": "Mac getHmacSha1(byte[] key){\r\n    return getInitializedMac(HmacAlgorithms.HMAC_SHA_1, key);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.segment.FullySegmentedWindowTinyLfuPolicy.onMiss",
	"Comment": "adds the entry to the admission window, evicting if necessary.",
	"Method": "void onMiss(long key){\r\n    Node node = new Node(key, Status.EDEN_PROBATION);\r\n    node.appendToTail(headEdenProbation);\r\n    data.put(key, node);\r\n    sizeEden++;\r\n    evict();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.Synthetic.uniform",
	"Comment": "returns a sequence of events where items are selected uniformly randomly from the intervalinclusively.",
	"Method": "LongStream uniform(int lowerBound,int upperBound,int events){\r\n    return generate(new UniformLongGenerator(lowerBound, upperBound), events);\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.AbstractInsnNode.getNext",
	"Comment": "returns the next instruction in the list to which this instructionbelongs, if any.",
	"Method": "AbstractInsnNode getNext(){\r\n    return next;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.Caffeine.initialCapacity",
	"Comment": "sets the minimum total size for the internal data structures. providing a large enough estimateat construction time avoids the need for expensive resizing operations later, but setting thisvalue unnecessarily high wastes memory.",
	"Method": "Caffeine<K, V> initialCapacity(int initialCapacity){\r\n    requireState(this.initialCapacity == UNSET_INT, \"initial capacity was already set to %s\", this.initialCapacity);\r\n    requireArgument(initialCapacity >= 0);\r\n    this.initialCapacity = initialCapacity;\r\n    return this;\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.InsnList.indexOf",
	"Comment": "returns the index of the given instruction in this list. this methodbuilds a cache of the instruction indexes to avoid scanning the wholelist each time it is called. once the cache is built, this method run inconstant time. the cache is invalidated by all the methods that modifythe list.",
	"Method": "int indexOf(AbstractInsnNode insn){\r\n    if (cache == null) {\r\n        cache = toArray();\r\n    }\r\n    return insn.index;\r\n}"
}, {
	"Path": "org.objectweb.asm.ByteVector.putByte",
	"Comment": "puts a byte into this byte vector. the byte vector is automaticallyenlarged if necessary.",
	"Method": "ByteVector putByte(int b){\r\n    int length = this.length;\r\n    if (length + 1 > data.length) {\r\n        enlarge(1);\r\n    }\r\n    data[length++] = (byte) b;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "org.apereo.cas.monitor.CacheStatistics.getEvictions",
	"Comment": "gets the number of items evicted from the cache in order to make space for new items.",
	"Method": "long getEvictions(){\r\n    return 0;\r\n}"
}, {
	"Path": "org.apache.commons.cli.Option.add",
	"Comment": "add the value to this option.if the number of argumentsis greater than zero and there is enough space in the list thenadd the value.otherwise, throw a runtime exception.",
	"Method": "void add(String value){\r\n    if (!acceptsArg()) {\r\n        throw new RuntimeException(\"Cannot add value, list full.\");\r\n    }\r\n    values.add(value);\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.Hex.toString",
	"Comment": "returns a string representation of the object, which includes the charset name.",
	"Method": "String toString(){\r\n    return super.toString() + \"[charsetName=\" + this.charset + \"]\";\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.FirstFitLocalCombiningAllocator.rangeContainsReserved",
	"Comment": "checks to see if any rop registers in the specified range are reservedfor local variables or parameters.",
	"Method": "boolean rangeContainsReserved(int ropRangeStart,int width){\r\n    for (int i = ropRangeStart; i < (ropRangeStart + width); i++) {\r\n        if (reservedRopRegs.get(i)) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.PolicyBasedAuthenticationManager.evaluateFinalAuthentication",
	"Comment": "evaluate produced authentication context.we apply an implicit security policy of at least one successful authentication.then, we apply the configured security policy.",
	"Method": "void evaluateFinalAuthentication(AuthenticationBuilder builder,AuthenticationTransaction transaction,Set<AuthenticationHandler> authenticationHandlers){\r\n    if (builder.getSuccesses().isEmpty()) {\r\n        publishEvent(new CasAuthenticationTransactionFailureEvent(this, builder.getFailures(), transaction.getCredentials()));\r\n        throw new AuthenticationException(builder.getFailures(), builder.getSuccesses());\r\n    }\r\n    val authentication = builder.build();\r\n    val failures = evaluateAuthenticationPolicies(authentication, transaction, authenticationHandlers);\r\n    if (!failures.getKey()) {\r\n        publishEvent(new CasAuthenticationPolicyFailureEvent(this, builder.getFailures(), transaction, authentication));\r\n        failures.getValue().forEach(e -> handleAuthenticationException(e, e.getClass().getSimpleName(), builder));\r\n        throw new AuthenticationException(builder.getFailures(), builder.getSuccesses());\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getArgumentsAndReturnSizes",
	"Comment": "returns the size of the arguments and of the return value of methods ofthis type. this method should only be used for method types.",
	"Method": "int getArgumentsAndReturnSizes(String desc,int getArgumentsAndReturnSizes){\r\n    return getArgumentsAndReturnSizes(getDescriptor());\r\n}"
}, {
	"Path": "org.apereo.cas.logging.web.LoggingConfigurationEndpoint.updateLoggerLevel",
	"Comment": "looks up the logger in the logger factory,and attempts to find the real logger instancebased on the underlying logging frameworkand retrieve the logger object. then, updates the level.this functionality at this point is heavily dependanton the log4j api.",
	"Method": "void updateLoggerLevel(String loggerName,String loggerLevel,boolean additive){\r\n    val loggerConfigs = getLoggerConfigurations();\r\n    loggerConfigs.stream().filter(cfg -> cfg.getName().equals(loggerName)).forEachOrdered(cfg -> {\r\n        cfg.setLevel(Level.getLevel(loggerLevel));\r\n        cfg.setAdditive(additive);\r\n    });\r\n    this.loggerContext.updateLoggers();\r\n}"
}, {
	"Path": "org.apache.commons.cli.HelpFormatter.printOptions",
	"Comment": "print the help for the specified options to the specified writer, using the specified width, left padding and description padding.",
	"Method": "void printOptions(PrintWriter pw,int width,Options options,int leftPad,int descPad){\r\n    StringBuffer sb = new StringBuffer();\r\n    renderOptions(sb, width, options, leftPad, descPad);\r\n    pw.println(sb.toString());\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.Base64.encodeBase64",
	"Comment": "encodes binary data using the base64 algorithm, optionally chunking the output into 76 character blocks.",
	"Method": "byte[] encodeBase64(byte[] binaryData,byte[] encodeBase64,byte[] binaryData,boolean isChunked,byte[] encodeBase64,byte[] binaryData,boolean isChunked,boolean urlSafe,byte[] encodeBase64,byte[] binaryData,boolean isChunked,boolean urlSafe,int maxResultSize){\r\n    if (binaryData == null || binaryData.length == 0) {\r\n        return binaryData;\r\n    }\r\n    final Base64 b64 = isChunked ? new Base64(urlSafe) : new Base64(0, CHUNK_SEPARATOR, urlSafe);\r\n    final long len = b64.getEncodedLength(binaryData);\r\n    if (len > maxResultSize) {\r\n        throw new IllegalArgumentException(\"Input array too big, the output array would be bigger (\" + len + \") than the specified maximum size of \" + maxResultSize);\r\n    }\r\n    return b64.encode(binaryData);\r\n}"
}, {
	"Path": "org.objectweb.asm.Attribute.isUnknown",
	"Comment": "returns true if this type of attribute is unknown. the defaultimplementation of this method always returns true.",
	"Method": "boolean isUnknown(){\r\n    return true;\r\n}"
}, {
	"Path": "org.apereo.cas.monitor.AbstractCacheHealthIndicator.status",
	"Comment": "computes the status code for a given set of cache statistics.",
	"Method": "Status status(CacheStatistics statistics){\r\n    if (statistics.getEvictions() > 0 && statistics.getEvictions() > evictionThreshold) {\r\n        return new Status(\"WARN\");\r\n    }\r\n    if (statistics.getPercentFree() > 0 && statistics.getPercentFree() < threshold) {\r\n        return Status.OUT_OF_SERVICE;\r\n    }\r\n    return Status.UP;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpec.regString",
	"Comment": "gets the string form for just the register number of this instance.",
	"Method": "String regString(int reg,String regString){\r\n    return regString(reg);\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.toByteArray",
	"Comment": "returns the bytecode of the class that was build with this class writer.",
	"Method": "byte[] toByteArray(){\r\n    if (index > 0xFFFF) {\r\n        throw new RuntimeException(\"Class file too large!\");\r\n    }\r\n    int size = 24 + 2 * interfaceCount;\r\n    int nbFields = 0;\r\n    FieldWriter fb = firstField;\r\n    while (fb != null) {\r\n        ++nbFields;\r\n        size += fb.getSize();\r\n        fb = (FieldWriter) fb.fv;\r\n    }\r\n    int nbMethods = 0;\r\n    MethodWriter mb = firstMethod;\r\n    while (mb != null) {\r\n        ++nbMethods;\r\n        size += mb.getSize();\r\n        mb = (MethodWriter) mb.mv;\r\n    }\r\n    int attributeCount = 0;\r\n    if (bootstrapMethods != null) {\r\n        ++attributeCount;\r\n        size += 8 + bootstrapMethods.length;\r\n        newUTF8(\"BootstrapMethods\");\r\n    }\r\n    if (ClassReader.SIGNATURES && signature != 0) {\r\n        ++attributeCount;\r\n        size += 8;\r\n        newUTF8(\"Signature\");\r\n    }\r\n    if (sourceFile != 0) {\r\n        ++attributeCount;\r\n        size += 8;\r\n        newUTF8(\"SourceFile\");\r\n    }\r\n    if (sourceDebug != null) {\r\n        ++attributeCount;\r\n        size += sourceDebug.length + 6;\r\n        newUTF8(\"SourceDebugExtension\");\r\n    }\r\n    if (enclosingMethodOwner != 0) {\r\n        ++attributeCount;\r\n        size += 10;\r\n        newUTF8(\"EnclosingMethod\");\r\n    }\r\n    if ((access & Opcodes.ACC_DEPRECATED) != 0) {\r\n        ++attributeCount;\r\n        size += 6;\r\n        newUTF8(\"Deprecated\");\r\n    }\r\n    if ((access & Opcodes.ACC_SYNTHETIC) != 0) {\r\n        if ((version & 0xFFFF) < Opcodes.V1_5 || (access & ACC_SYNTHETIC_ATTRIBUTE) != 0) {\r\n            ++attributeCount;\r\n            size += 6;\r\n            newUTF8(\"Synthetic\");\r\n        }\r\n    }\r\n    if (innerClasses != null) {\r\n        ++attributeCount;\r\n        size += 8 + innerClasses.length;\r\n        newUTF8(\"InnerClasses\");\r\n    }\r\n    if (ClassReader.ANNOTATIONS && anns != null) {\r\n        ++attributeCount;\r\n        size += 8 + anns.getSize();\r\n        newUTF8(\"RuntimeVisibleAnnotations\");\r\n    }\r\n    if (ClassReader.ANNOTATIONS && ianns != null) {\r\n        ++attributeCount;\r\n        size += 8 + ianns.getSize();\r\n        newUTF8(\"RuntimeInvisibleAnnotations\");\r\n    }\r\n    if (ClassReader.ANNOTATIONS && tanns != null) {\r\n        ++attributeCount;\r\n        size += 8 + tanns.getSize();\r\n        newUTF8(\"RuntimeVisibleTypeAnnotations\");\r\n    }\r\n    if (ClassReader.ANNOTATIONS && itanns != null) {\r\n        ++attributeCount;\r\n        size += 8 + itanns.getSize();\r\n        newUTF8(\"RuntimeInvisibleTypeAnnotations\");\r\n    }\r\n    if (attrs != null) {\r\n        attributeCount += attrs.getCount();\r\n        size += attrs.getSize(this, null, 0, -1, -1);\r\n    }\r\n    size += pool.length;\r\n    ByteVector out = new ByteVector(size);\r\n    out.putInt(0xCAFEBABE).putInt(version);\r\n    out.putShort(index).putByteArray(pool.data, 0, pool.length);\r\n    int mask = Opcodes.ACC_DEPRECATED | ACC_SYNTHETIC_ATTRIBUTE | ((access & ACC_SYNTHETIC_ATTRIBUTE) / TO_ACC_SYNTHETIC);\r\n    out.putShort(access & ~mask).putShort(name).putShort(superName);\r\n    out.putShort(interfaceCount);\r\n    for (int i = 0; i < interfaceCount; ++i) {\r\n        out.putShort(interfaces[i]);\r\n    }\r\n    out.putShort(nbFields);\r\n    fb = firstField;\r\n    while (fb != null) {\r\n        fb.put(out);\r\n        fb = (FieldWriter) fb.fv;\r\n    }\r\n    out.putShort(nbMethods);\r\n    mb = firstMethod;\r\n    while (mb != null) {\r\n        mb.put(out);\r\n        mb = (MethodWriter) mb.mv;\r\n    }\r\n    out.putShort(attributeCount);\r\n    if (bootstrapMethods != null) {\r\n        out.putShort(newUTF8(\"BootstrapMethods\"));\r\n        out.putInt(bootstrapMethods.length + 2).putShort(bootstrapMethodsCount);\r\n        out.putByteArray(bootstrapMethods.data, 0, bootstrapMethods.length);\r\n    }\r\n    if (ClassReader.SIGNATURES && signature != 0) {\r\n        out.putShort(newUTF8(\"Signature\")).putInt(2).putShort(signature);\r\n    }\r\n    if (sourceFile != 0) {\r\n        out.putShort(newUTF8(\"SourceFile\")).putInt(2).putShort(sourceFile);\r\n    }\r\n    if (sourceDebug != null) {\r\n        int len = sourceDebug.length;\r\n        out.putShort(newUTF8(\"SourceDebugExtension\")).putInt(len);\r\n        out.putByteArray(sourceDebug.data, 0, len);\r\n    }\r\n    if (enclosingMethodOwner != 0) {\r\n        out.putShort(newUTF8(\"EnclosingMethod\")).putInt(4);\r\n        out.putShort(enclosingMethodOwner).putShort(enclosingMethod);\r\n    }\r\n    if ((access & Opcodes.ACC_DEPRECATED) != 0) {\r\n        out.putShort(newUTF8(\"Deprecated\")).putInt(0);\r\n    }\r\n    if ((access & Opcodes.ACC_SYNTHETIC) != 0) {\r\n        if ((version & 0xFFFF) < Opcodes.V1_5 || (access & ACC_SYNTHETIC_ATTRIBUTE) != 0) {\r\n            out.putShort(newUTF8(\"Synthetic\")).putInt(0);\r\n        }\r\n    }\r\n    if (innerClasses != null) {\r\n        out.putShort(newUTF8(\"InnerClasses\"));\r\n        out.putInt(innerClasses.length + 2).putShort(innerClassesCount);\r\n        out.putByteArray(innerClasses.data, 0, innerClasses.length);\r\n    }\r\n    if (ClassReader.ANNOTATIONS && anns != null) {\r\n        out.putShort(newUTF8(\"RuntimeVisibleAnnotations\"));\r\n        anns.put(out);\r\n    }\r\n    if (ClassReader.ANNOTATIONS && ianns != null) {\r\n        out.putShort(newUTF8(\"RuntimeInvisibleAnnotations\"));\r\n        ianns.put(out);\r\n    }\r\n    if (ClassReader.ANNOTATIONS && tanns != null) {\r\n        out.putShort(newUTF8(\"RuntimeVisibleTypeAnnotations\"));\r\n        tanns.put(out);\r\n    }\r\n    if (ClassReader.ANNOTATIONS && itanns != null) {\r\n        out.putShort(newUTF8(\"RuntimeInvisibleTypeAnnotations\"));\r\n        itanns.put(out);\r\n    }\r\n    if (attrs != null) {\r\n        attrs.put(this, null, 0, -1, -1, out);\r\n    }\r\n    if (invalidFrames) {\r\n        anns = null;\r\n        ianns = null;\r\n        attrs = null;\r\n        innerClassesCount = 0;\r\n        innerClasses = null;\r\n        bootstrapMethodsCount = 0;\r\n        bootstrapMethods = null;\r\n        firstField = null;\r\n        lastField = null;\r\n        firstMethod = null;\r\n        lastMethod = null;\r\n        computeMaxs = false;\r\n        computeFrames = true;\r\n        invalidFrames = false;\r\n        new ClassReader(out.data).accept(this, ClassReader.SKIP_FRAMES);\r\n        return toByteArray();\r\n    }\r\n    return out.data;\r\n}"
}, {
	"Path": "org.objectweb.asm.Label.put",
	"Comment": "puts a reference to this label in the bytecode of a method. if theposition of the label is known, the offset is computed and writtendirectly. otherwise, a null offset is written and a new forward referenceis declared for this label.",
	"Method": "void put(MethodWriter owner,ByteVector out,int source,boolean wideOffset){\r\n    if ((status & RESOLVED) == 0) {\r\n        if (wideOffset) {\r\n            addReference(-1 - source, out.length);\r\n            out.putInt(-1);\r\n        } else {\r\n            addReference(source, out.length);\r\n            out.putShort(-1);\r\n        }\r\n    } else {\r\n        if (wideOffset) {\r\n            out.putInt(position - source);\r\n        } else {\r\n            out.putShort(position - source);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.RefinedSoundex.soundex",
	"Comment": "retrieves the refined soundex code for a given string object.",
	"Method": "String soundex(String str){\r\n    if (str == null) {\r\n        return null;\r\n    }\r\n    str = SoundexUtils.clean(str);\r\n    if (str.length() == 0) {\r\n        return str;\r\n    }\r\n    final StringBuilder sBuf = new StringBuilder();\r\n    sBuf.append(str.charAt(0));\r\n    char last, current;\r\n    last = '*';\r\n    for (int i = 0; i < str.length(); i++) {\r\n        current = getMappingCode(str.charAt(i));\r\n        if (current == last) {\r\n            continue;\r\n        } else if (current != 0) {\r\n            sBuf.append(current);\r\n        }\r\n        last = current;\r\n    }\r\n    return sBuf.toString();\r\n}"
}, {
	"Path": "org.objectweb.asm.Label.visitSubroutine",
	"Comment": "finds the basic blocks that belong to a given subroutine, and marks theseblocks as belonging to this subroutine. this method follows the controlflow graph to find all the blocks that are reachable from the currentblock without following any jsr target.",
	"Method": "void visitSubroutine(Label JSR,long id,int nbSubroutines){\r\n    Label stack = this;\r\n    while (stack != null) {\r\n        Label l = stack;\r\n        stack = l.next;\r\n        l.next = null;\r\n        if (JSR != null) {\r\n            if ((l.status & VISITED2) != 0) {\r\n                continue;\r\n            }\r\n            l.status |= VISITED2;\r\n            if ((l.status & RET) != 0) {\r\n                if (!l.inSameSubroutine(JSR)) {\r\n                    Edge e = new Edge();\r\n                    e.info = l.inputStackTop;\r\n                    e.successor = JSR.successors.successor;\r\n                    e.next = l.successors;\r\n                    l.successors = e;\r\n                }\r\n            }\r\n        } else {\r\n            if (l.inSubroutine(id)) {\r\n                continue;\r\n            }\r\n            l.addToSubroutine(id, nbSubroutines);\r\n        }\r\n        Edge e = l.successors;\r\n        while (e != null) {\r\n            if ((l.status & Label.JSR) == 0 || e != l.successors.next) {\r\n                if (e.successor.next == null) {\r\n                    e.successor.next = stack;\r\n                    stack = e.successor;\r\n                }\r\n            }\r\n            e = e.next;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getMethodType",
	"Comment": "returns the java method type corresponding to the given argument andreturn types.",
	"Method": "Type getMethodType(String methodDescriptor,Type getMethodType,Type returnType,Type argumentTypes){\r\n    return getType(getMethodDescriptor(returnType, argumentTypes));\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.getStatic",
	"Comment": "generates the instruction to push the value of a static field on thestack.",
	"Method": "void getStatic(Type owner,String name,Type type){\r\n    fieldInsn(Opcodes.GETSTATIC, owner, name, type);\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.ifNull",
	"Comment": "generates the instruction to jump to the given label if the top stackvalue is null.",
	"Method": "void ifNull(Label label){\r\n    mv.visitJumpInsn(Opcodes.IFNULL, label);\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaMethod.computeReachability",
	"Comment": "computes reachability for all blocks in the method. first clears oldvalues from all blocks, then starts with the entry block and walks downthe control flow graph, marking all blocks it finds as reachable.",
	"Method": "void computeReachability(){\r\n    for (SsaBasicBlock block : blocks) {\r\n        block.setReachable(0);\r\n    }\r\n    ArrayList<SsaBasicBlock> blockList = new ArrayList<SsaBasicBlock>();\r\n    blockList.add(this.getEntryBlock());\r\n    while (!blockList.isEmpty()) {\r\n        SsaBasicBlock block = blockList.remove(0);\r\n        if (block.isReachable())\r\n            continue;\r\n        block.setReachable(1);\r\n        BitSet succs = block.getSuccessors();\r\n        for (int i = succs.nextSetBit(0); i >= 0; i = succs.nextSetBit(i + 1)) {\r\n            blockList.add(blocks.get(i));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.DefaultAuthenticationAttributeReleasePolicy.decideIfProxyGrantingTicketShouldBeReleasedAsAttribute",
	"Comment": "decide if pgt should be released as attribute.the pgt must have been cached as an authentication attributeand the attribute release policy must be allowed to release theattribute.",
	"Method": "void decideIfProxyGrantingTicketShouldBeReleasedAsAttribute(Map<String, Object> attributes,Map<String, Object> model,RegisteredService service){\r\n    val policy = service.getAttributeReleasePolicy();\r\n    val isAuthorized = policy != null && policy.isAuthorizedToReleaseProxyGrantingTicket() && isAttributeAllowedForRelease(CasViewConstants.MODEL_ATTRIBUTE_NAME_PROXY_GRANTING_TICKET);\r\n    val pgtId = (String) model.get(CasViewConstants.MODEL_ATTRIBUTE_NAME_PROXY_GRANTING_TICKET);\r\n    decideAttributeReleaseBasedOnServiceAttributePolicy(attributes, pgtId, CasViewConstants.MODEL_ATTRIBUTE_NAME_PROXY_GRANTING_TICKET, service, isAuthorized);\r\n}"
}, {
	"Path": "org.objectweb.asm.TypeReference.newTypeParameterReference",
	"Comment": "returns a reference to a type parameter of a generic class or method.",
	"Method": "TypeReference newTypeParameterReference(int sort,int paramIndex){\r\n    return new TypeReference((sort << 24) | (paramIndex << 16));\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.build.BuckBuildManager.runBuckCommandWhileConnectedToBuck",
	"Comment": "execute simple process asynchronously with progress and connect to buck server.",
	"Method": "void runBuckCommandWhileConnectedToBuck(BuckCommandHandler handler,String operationTitle,BuckModule module){\r\n    runBuckCommand(handler, operationTitle);\r\n}"
}, {
	"Path": "the.bytecode.club.bytecodeviewer.BytecodeViewer.openFiles",
	"Comment": "opens a file, optional if it should append to the recent files menu",
	"Method": "void openFiles(File[] files,boolean recentFiles){\r\n    if (recentFiles)\r\n        for (File f : files) if (f.exists())\r\n            BytecodeViewer.addRecentFile(f);\r\n    BytecodeViewer.viewer.setIcon(true);\r\n    update = true;\r\n    Thread t = new Thread() {\r\n        @Override\r\n        public void run() {\r\n            try {\r\n                for (final File f : files) {\r\n                    final String fn = f.getName();\r\n                    if (!f.exists()) {\r\n                        update = false;\r\n                        showMessage(\"The file \" + f.getAbsolutePath() + \" could not be found.\");\r\n                    } else {\r\n                        if (f.isDirectory()) {\r\n                            FileContainer container = new FileContainer(f);\r\n                            HashMap<String, byte[]> files = new HashMap<String, byte[]>();\r\n                            boolean finished = false;\r\n                            ArrayList<File> totalFiles = new ArrayList<File>();\r\n                            totalFiles.add(f);\r\n                            String dir = f.getAbsolutePath();\r\n                            while (!finished) {\r\n                                boolean added = false;\r\n                                for (int i = 0; i < totalFiles.size(); i++) {\r\n                                    File child = totalFiles.get(i);\r\n                                    if (child.listFiles() != null)\r\n                                        for (File rocket : child.listFiles()) if (!totalFiles.contains(rocket)) {\r\n                                            totalFiles.add(rocket);\r\n                                            added = true;\r\n                                        }\r\n                                }\r\n                                if (!added) {\r\n                                    for (File child : totalFiles) if (child.isFile()) {\r\n                                        String fileName = child.getAbsolutePath().substring(dir.length() + 1, child.getAbsolutePath().length()).replaceAll(\"\\\\\\\\\", \"\\\\/\");\r\n                                        files.put(fileName, Files.readAllBytes(Paths.get(child.getAbsolutePath())));\r\n                                    }\r\n                                    finished = true;\r\n                                }\r\n                            }\r\n                            container.files = files;\r\n                            BytecodeViewer.files.add(container);\r\n                        } else {\r\n                            if (fn.endsWith(\".jar\") || fn.endsWith(\".zip\")) {\r\n                                try {\r\n                                    JarUtils.put(f);\r\n                                } catch (final Exception e) {\r\n                                    new the.bytecode.club.bytecodeviewer.api.ExceptionUI(e);\r\n                                    update = false;\r\n                                }\r\n                            } else if (fn.endsWith(\".class\")) {\r\n                                try {\r\n                                    byte[] bytes = JarUtils.getBytes(new FileInputStream(f));\r\n                                    String cafebabe = String.format(\"X\", bytes[0]) + String.format(\"X\", bytes[1]) + String.format(\"X\", bytes[2]) + String.format(\"X\", bytes[3]);\r\n                                    if (cafebabe.toLowerCase().equals(\"cafebabe\")) {\r\n                                        final ClassNode cn = JarUtils.getNode(bytes);\r\n                                        FileContainer container = new FileContainer(f);\r\n                                        container.classes.add(cn);\r\n                                        BytecodeViewer.files.add(container);\r\n                                    } else {\r\n                                        showMessage(fn + \": Header does not start with CAFEBABE, ignoring.\");\r\n                                        update = false;\r\n                                    }\r\n                                } catch (final Exception e) {\r\n                                    new the.bytecode.club.bytecodeviewer.api.ExceptionUI(e);\r\n                                    update = false;\r\n                                }\r\n                            } else if (fn.endsWith(\".apk\")) {\r\n                                try {\r\n                                    BytecodeViewer.viewer.setIcon(true);\r\n                                    FileContainer container = new FileContainer(f);\r\n                                    if (viewer.decodeAPKResources.isSelected()) {\r\n                                        File decodedResources = new File(tempDirectory + fs + MiscUtils.randomString(32) + \".apk\");\r\n                                        APKTool.decodeResources(f, decodedResources);\r\n                                        container.files = JarUtils.loadResources(decodedResources);\r\n                                    }\r\n                                    container.files.putAll(JarUtils.loadResources(f));\r\n                                    String name = getRandomizedName() + \".jar\";\r\n                                    File output = new File(tempDirectory + fs + name);\r\n                                    if (BytecodeViewer.viewer.apkConversionGroup.isSelected(BytecodeViewer.viewer.apkConversionDex.getModel()))\r\n                                        Dex2Jar.dex2Jar(f, output);\r\n                                    else if (BytecodeViewer.viewer.apkConversionGroup.isSelected(BytecodeViewer.viewer.apkConversionEnjarify.getModel()))\r\n                                        Enjarify.apk2Jar(f, output);\r\n                                    container.classes = JarUtils.loadClasses(output);\r\n                                    BytecodeViewer.viewer.setIcon(false);\r\n                                    BytecodeViewer.files.add(container);\r\n                                } catch (final Exception e) {\r\n                                    new the.bytecode.club.bytecodeviewer.api.ExceptionUI(e);\r\n                                }\r\n                                return;\r\n                            } else if (fn.endsWith(\".dex\")) {\r\n                                try {\r\n                                    BytecodeViewer.viewer.setIcon(true);\r\n                                    FileContainer container = new FileContainer(f);\r\n                                    String name = getRandomizedName() + \".jar\";\r\n                                    File output = new File(tempDirectory + fs + name);\r\n                                    if (BytecodeViewer.viewer.apkConversionGroup.isSelected(BytecodeViewer.viewer.apkConversionDex.getModel()))\r\n                                        Dex2Jar.dex2Jar(f, output);\r\n                                    else if (BytecodeViewer.viewer.apkConversionGroup.isSelected(BytecodeViewer.viewer.apkConversionEnjarify.getModel()))\r\n                                        Enjarify.apk2Jar(f, output);\r\n                                    container.classes = JarUtils.loadClasses(output);\r\n                                    BytecodeViewer.viewer.setIcon(false);\r\n                                    BytecodeViewer.files.add(container);\r\n                                } catch (final Exception e) {\r\n                                    new the.bytecode.club.bytecodeviewer.api.ExceptionUI(e);\r\n                                }\r\n                                return;\r\n                            } else {\r\n                                HashMap<String, byte[]> files = new HashMap<String, byte[]>();\r\n                                byte[] bytes = JarUtils.getBytes(new FileInputStream(f));\r\n                                files.put(f.getName(), bytes);\r\n                                FileContainer container = new FileContainer(f);\r\n                                container.files = files;\r\n                                BytecodeViewer.files.add(container);\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n            } catch (final Exception e) {\r\n                new the.bytecode.club.bytecodeviewer.api.ExceptionUI(e);\r\n            } finally {\r\n                BytecodeViewer.viewer.setIcon(false);\r\n                if (update)\r\n                    try {\r\n                        MainViewerGUI.getComponent(FileNavigationPane.class).updateTree();\r\n                    } catch (java.lang.NullPointerException e) {\r\n                    }\r\n            }\r\n        }\r\n    };\r\n    t.start();\r\n}"
}, {
	"Path": "the.bytecode.club.bytecodeviewer.BytecodeViewer.openFiles",
	"Comment": "opens a file, optional if it should append to the recent files menu",
	"Method": "void openFiles(File[] files,boolean recentFiles){\r\n    try {\r\n        for (final File f : files) {\r\n            final String fn = f.getName();\r\n            if (!f.exists()) {\r\n                update = false;\r\n                showMessage(\"The file \" + f.getAbsolutePath() + \" could not be found.\");\r\n            } else {\r\n                if (f.isDirectory()) {\r\n                    FileContainer container = new FileContainer(f);\r\n                    HashMap<String, byte[]> files = new HashMap<String, byte[]>();\r\n                    boolean finished = false;\r\n                    ArrayList<File> totalFiles = new ArrayList<File>();\r\n                    totalFiles.add(f);\r\n                    String dir = f.getAbsolutePath();\r\n                    while (!finished) {\r\n                        boolean added = false;\r\n                        for (int i = 0; i < totalFiles.size(); i++) {\r\n                            File child = totalFiles.get(i);\r\n                            if (child.listFiles() != null)\r\n                                for (File rocket : child.listFiles()) if (!totalFiles.contains(rocket)) {\r\n                                    totalFiles.add(rocket);\r\n                                    added = true;\r\n                                }\r\n                        }\r\n                        if (!added) {\r\n                            for (File child : totalFiles) if (child.isFile()) {\r\n                                String fileName = child.getAbsolutePath().substring(dir.length() + 1, child.getAbsolutePath().length()).replaceAll(\"\\\\\\\\\", \"\\\\/\");\r\n                                files.put(fileName, Files.readAllBytes(Paths.get(child.getAbsolutePath())));\r\n                            }\r\n                            finished = true;\r\n                        }\r\n                    }\r\n                    container.files = files;\r\n                    BytecodeViewer.files.add(container);\r\n                } else {\r\n                    if (fn.endsWith(\".jar\") || fn.endsWith(\".zip\")) {\r\n                        try {\r\n                            JarUtils.put(f);\r\n                        } catch (final Exception e) {\r\n                            new the.bytecode.club.bytecodeviewer.api.ExceptionUI(e);\r\n                            update = false;\r\n                        }\r\n                    } else if (fn.endsWith(\".class\")) {\r\n                        try {\r\n                            byte[] bytes = JarUtils.getBytes(new FileInputStream(f));\r\n                            String cafebabe = String.format(\"X\", bytes[0]) + String.format(\"X\", bytes[1]) + String.format(\"X\", bytes[2]) + String.format(\"X\", bytes[3]);\r\n                            if (cafebabe.toLowerCase().equals(\"cafebabe\")) {\r\n                                final ClassNode cn = JarUtils.getNode(bytes);\r\n                                FileContainer container = new FileContainer(f);\r\n                                container.classes.add(cn);\r\n                                BytecodeViewer.files.add(container);\r\n                            } else {\r\n                                showMessage(fn + \": Header does not start with CAFEBABE, ignoring.\");\r\n                                update = false;\r\n                            }\r\n                        } catch (final Exception e) {\r\n                            new the.bytecode.club.bytecodeviewer.api.ExceptionUI(e);\r\n                            update = false;\r\n                        }\r\n                    } else if (fn.endsWith(\".apk\")) {\r\n                        try {\r\n                            BytecodeViewer.viewer.setIcon(true);\r\n                            FileContainer container = new FileContainer(f);\r\n                            if (viewer.decodeAPKResources.isSelected()) {\r\n                                File decodedResources = new File(tempDirectory + fs + MiscUtils.randomString(32) + \".apk\");\r\n                                APKTool.decodeResources(f, decodedResources);\r\n                                container.files = JarUtils.loadResources(decodedResources);\r\n                            }\r\n                            container.files.putAll(JarUtils.loadResources(f));\r\n                            String name = getRandomizedName() + \".jar\";\r\n                            File output = new File(tempDirectory + fs + name);\r\n                            if (BytecodeViewer.viewer.apkConversionGroup.isSelected(BytecodeViewer.viewer.apkConversionDex.getModel()))\r\n                                Dex2Jar.dex2Jar(f, output);\r\n                            else if (BytecodeViewer.viewer.apkConversionGroup.isSelected(BytecodeViewer.viewer.apkConversionEnjarify.getModel()))\r\n                                Enjarify.apk2Jar(f, output);\r\n                            container.classes = JarUtils.loadClasses(output);\r\n                            BytecodeViewer.viewer.setIcon(false);\r\n                            BytecodeViewer.files.add(container);\r\n                        } catch (final Exception e) {\r\n                            new the.bytecode.club.bytecodeviewer.api.ExceptionUI(e);\r\n                        }\r\n                        return;\r\n                    } else if (fn.endsWith(\".dex\")) {\r\n                        try {\r\n                            BytecodeViewer.viewer.setIcon(true);\r\n                            FileContainer container = new FileContainer(f);\r\n                            String name = getRandomizedName() + \".jar\";\r\n                            File output = new File(tempDirectory + fs + name);\r\n                            if (BytecodeViewer.viewer.apkConversionGroup.isSelected(BytecodeViewer.viewer.apkConversionDex.getModel()))\r\n                                Dex2Jar.dex2Jar(f, output);\r\n                            else if (BytecodeViewer.viewer.apkConversionGroup.isSelected(BytecodeViewer.viewer.apkConversionEnjarify.getModel()))\r\n                                Enjarify.apk2Jar(f, output);\r\n                            container.classes = JarUtils.loadClasses(output);\r\n                            BytecodeViewer.viewer.setIcon(false);\r\n                            BytecodeViewer.files.add(container);\r\n                        } catch (final Exception e) {\r\n                            new the.bytecode.club.bytecodeviewer.api.ExceptionUI(e);\r\n                        }\r\n                        return;\r\n                    } else {\r\n                        HashMap<String, byte[]> files = new HashMap<String, byte[]>();\r\n                        byte[] bytes = JarUtils.getBytes(new FileInputStream(f));\r\n                        files.put(f.getName(), bytes);\r\n                        FileContainer container = new FileContainer(f);\r\n                        container.files = files;\r\n                        BytecodeViewer.files.add(container);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    } catch (final Exception e) {\r\n        new the.bytecode.club.bytecodeviewer.api.ExceptionUI(e);\r\n    } finally {\r\n        BytecodeViewer.viewer.setIcon(false);\r\n        if (update)\r\n            try {\r\n                MainViewerGUI.getComponent(FileNavigationPane.class).updateTree();\r\n            } catch (java.lang.NullPointerException e) {\r\n            }\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.CacheGenerator.combinations",
	"Comment": "returns the cartesian set of the possible cache configurations.",
	"Method": "Set<List<Object>> combinations(){\r\n    Set<Boolean> asyncLoading = ImmutableSet.of(true, false);\r\n    Set<Stats> statistics = filterTypes(options.stats(), cacheSpec.stats());\r\n    Set<ReferenceType> keys = filterTypes(options.keys(), cacheSpec.keys());\r\n    Set<ReferenceType> values = filterTypes(options.values(), cacheSpec.values());\r\n    Set<Compute> computations = filterTypes(options.compute(), cacheSpec.compute());\r\n    Set<Implementation> implementations = filterTypes(options.implementation(), cacheSpec.implementation());\r\n    if (isAsyncOnly) {\r\n        values = values.contains(ReferenceType.STRONG) ? ImmutableSet.of(ReferenceType.STRONG) : ImmutableSet.of();\r\n        computations = Sets.filter(computations, Compute.ASYNC::equals);\r\n    }\r\n    if (isAsyncOnly || computations.equals(ImmutableSet.of(Compute.ASYNC))) {\r\n        implementations = implementations.contains(Implementation.Caffeine) ? ImmutableSet.of(Implementation.Caffeine) : ImmutableSet.of();\r\n    }\r\n    if (computations.equals(ImmutableSet.of(Compute.SYNC))) {\r\n        asyncLoading = ImmutableSet.of(false);\r\n    }\r\n    if (computations.isEmpty() || implementations.isEmpty() || keys.isEmpty() || values.isEmpty()) {\r\n        return ImmutableSet.of();\r\n    }\r\n    return Sets.cartesianProduct(ImmutableSet.copyOf(cacheSpec.initialCapacity()), ImmutableSet.copyOf(statistics), ImmutableSet.copyOf(cacheSpec.weigher()), ImmutableSet.copyOf(cacheSpec.maximumSize()), ImmutableSet.copyOf(cacheSpec.expiry()), ImmutableSet.copyOf(cacheSpec.expireAfterAccess()), ImmutableSet.copyOf(cacheSpec.expireAfterWrite()), ImmutableSet.copyOf(cacheSpec.refreshAfterWrite()), ImmutableSet.copyOf(cacheSpec.advanceOnPopulation()), ImmutableSet.copyOf(keys), ImmutableSet.copyOf(values), ImmutableSet.copyOf(cacheSpec.executor()), ImmutableSet.copyOf(cacheSpec.removalListener()), ImmutableSet.copyOf(cacheSpec.population()), ImmutableSet.of(true, isLoadingOnly), ImmutableSet.copyOf(asyncLoading), ImmutableSet.copyOf(computations), ImmutableSet.copyOf(cacheSpec.loader()), ImmutableSet.copyOf(cacheSpec.writer()), ImmutableSet.copyOf(implementations));\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.newConstItem",
	"Comment": "adds a number or string constant to the constant pool of the class beingbuild. does nothing if the constant pool already contains a similar item.",
	"Method": "Item newConstItem(Object cst){\r\n    if (cst instanceof Integer) {\r\n        int val = ((Integer) cst).intValue();\r\n        return newInteger(val);\r\n    } else if (cst instanceof Byte) {\r\n        int val = ((Byte) cst).intValue();\r\n        return newInteger(val);\r\n    } else if (cst instanceof Character) {\r\n        int val = ((Character) cst).charValue();\r\n        return newInteger(val);\r\n    } else if (cst instanceof Short) {\r\n        int val = ((Short) cst).intValue();\r\n        return newInteger(val);\r\n    } else if (cst instanceof Boolean) {\r\n        int val = ((Boolean) cst).booleanValue() ? 1 : 0;\r\n        return newInteger(val);\r\n    } else if (cst instanceof Float) {\r\n        float val = ((Float) cst).floatValue();\r\n        return newFloat(val);\r\n    } else if (cst instanceof Long) {\r\n        long val = ((Long) cst).longValue();\r\n        return newLong(val);\r\n    } else if (cst instanceof Double) {\r\n        double val = ((Double) cst).doubleValue();\r\n        return newDouble(val);\r\n    } else if (cst instanceof String) {\r\n        return newString((String) cst);\r\n    } else if (cst instanceof Type) {\r\n        Type t = (Type) cst;\r\n        int s = t.getSort();\r\n        if (s == Type.OBJECT) {\r\n            return newClassItem(t.getInternalName());\r\n        } else if (s == Type.METHOD) {\r\n            return newMethodTypeItem(t.getDescriptor());\r\n        } else {\r\n            return newClassItem(t.getDescriptor());\r\n        }\r\n    } else if (cst instanceof Handle) {\r\n        Handle h = (Handle) cst;\r\n        return newHandleItem(h.tag, h.owner, h.name, h.desc);\r\n    } else {\r\n        throw new IllegalArgumentException(\"value \" + cst);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.util.TwoColumnOutput.outputFullLines",
	"Comment": "outputs to the final destination as many full line pairs asthere are in the pending output, removing those lines fromtheir respective buffers. this method terminates when atleast one of the two column buffers is empty.",
	"Method": "void outputFullLines(){\r\n    for (; ; ) {\r\n        int leftLen = leftBuf.indexOf(\"\\n\");\r\n        if (leftLen < 0) {\r\n            return;\r\n        }\r\n        int rightLen = rightBuf.indexOf(\"\\n\");\r\n        if (rightLen < 0) {\r\n            return;\r\n        }\r\n        if (leftLen != 0) {\r\n            out.write(leftBuf.substring(0, leftLen));\r\n        }\r\n        if (rightLen != 0) {\r\n            writeSpaces(out, leftWidth - leftLen);\r\n            out.write(rightBuf.substring(0, rightLen));\r\n        }\r\n        out.write('\\n');\r\n        leftBuf.delete(0, leftLen + 1);\r\n        rightBuf.delete(0, rightLen + 1);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.rop.code.Rops.throwBadTypes",
	"Comment": "throws the right exception to complain about a bogus list of types.",
	"Method": "Rop throwBadTypes(TypeList types){\r\n    throw new IllegalArgumentException(\"bad types: \" + types);\r\n}"
}, {
	"Path": "com.android.dx.ssa.DomFront.buildDomTree",
	"Comment": "the dominators algorithm leaves us knowing who the immediate dominatoris for each node. this sweeps the node list and builds the properdominance tree.",
	"Method": "void buildDomTree(){\r\n    int szNodes = nodes.size();\r\n    for (int i = 0; i < szNodes; i++) {\r\n        DomInfo info = domInfos[i];\r\n        if (info.idom == -1)\r\n            continue;\r\n        SsaBasicBlock domParent = nodes.get(info.idom);\r\n        domParent.addDomChild(nodes.get(i));\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.AbstractSequenceClassifier.makePlainTextReaderAndWriter",
	"Comment": "makes a documentreaderandwriter based onflags.plaintextreaderandwriter.useful for reading inuntokenized text documents or reading plain text from the commandline.an example of a way to use this would be to return aedu.stanford.nlp.wordseg.sighan2005documentreaderandwriter forthe chinese segmenter.",
	"Method": "DocumentReaderAndWriter<IN> makePlainTextReaderAndWriter(){\r\n    String readerClassName = flags.plainTextDocumentReaderAndWriter;\r\n    if (readerClassName == null) {\r\n        readerClassName = SeqClassifierFlags.DEFAULT_PLAIN_TEXT_READER;\r\n    }\r\n    DocumentReaderAndWriter<IN> readerAndWriter;\r\n    try {\r\n        readerAndWriter = ReflectionLoading.loadByReflection(readerClassName);\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(String.format(\"Error loading flags.plainTextDocumentReaderAndWriter: '%s'\", flags.plainTextDocumentReaderAndWriter), e);\r\n    }\r\n    readerAndWriter.init(flags);\r\n    return readerAndWriter;\r\n}"
}, {
	"Path": "org.objectweb.asm.Handle.getName",
	"Comment": "returns the name of the field or method designated by this handle.",
	"Method": "String getName(){\r\n    return name;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.MultifactorAuthenticationProvider.validateId",
	"Comment": "validates that the passed mark was created by this provider.",
	"Method": "boolean validateId(String id){\r\n    return id != null && createUniqueId().equals(id);\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.SieveCoreferenceSystem.coref",
	"Comment": "extracts coreference clusters.this is the main api entry point for coreference resolution.return a map from corefchain id to corresponding corefchain.",
	"Method": "Map<Integer, CorefChain> coref(Document document){\r\n    for (int i = 0; i < sieves.length; i++) {\r\n        currentSieve = i;\r\n        DeterministicCorefSieve sieve = sieves[i];\r\n        coreference(document, sieve);\r\n    }\r\n    if ((!Constants.USE_GOLD_MENTIONS && doPostProcessing) || replicateCoNLL)\r\n        postProcessing(document);\r\n    Map<Integer, CorefChain> result = Generics.newHashMap();\r\n    for (CorefCluster c : document.corefClusters.values()) {\r\n        result.put(c.clusterID, new CorefChain(c, document.positions));\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.admission.bloom.MembershipTest.row",
	"Comment": "returns a table row for printing the false positive rates of an implementation.",
	"Method": "String[] row(FilterType filterType,int expectedInsertions,int falsePositives,double falsePositiveRate){\r\n    return new String[] { filterType.toString(), String.format(\"%,d\", expectedInsertions), String.format(\"%,d (%.2f %%)\", falsePositives, 100 * falsePositiveRate) };\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.KBPStatisticalExtractor.classify",
	"Comment": "score the given input, returning both the classification decision and theprobability of that decision.note that this method will not return a relation which does not type check.",
	"Method": "Pair<String, Double> classify(KBPInput input){\r\n    RVFDatum<String, String> datum = new RVFDatum(features(input));\r\n    Counter<String> scores = classifier.scoresOf(datum);\r\n    Counters.expInPlace(scores);\r\n    Counters.normalize(scores);\r\n    String best = Counters.argmax(scores);\r\n    while (!NO_RELATION.equals(best) && scores.size() > 1 && (!KBPRelationExtractor.RelationType.fromString(best).get().validNamedEntityLabels.contains(input.objectType) || RelationType.fromString(best).get().entityType != input.subjectType)) {\r\n        scores.remove(best);\r\n        Counters.normalize(scores);\r\n        best = Counters.argmax(scores);\r\n    }\r\n    return Pair.makePair(best, scores.getCount(best));\r\n}"
}, {
	"Path": "org.objectweb.asm.ByteVector.putByteArray",
	"Comment": "puts an array of bytes into this byte vector. the byte vector isautomatically enlarged if necessary.",
	"Method": "ByteVector putByteArray(byte[] b,int off,int len){\r\n    if (length + len > data.length) {\r\n        enlarge(len);\r\n    }\r\n    if (b != null) {\r\n        System.arraycopy(b, off, data, length, len);\r\n    }\r\n    length += len;\r\n    return this;\r\n}"
}, {
	"Path": "com.google.common.cache.PopulatedCachesTest.caches",
	"Comment": "most of the tests in this class run against every one of these caches.",
	"Method": "Iterable<LoadingCache<Object, Object>> caches(){\r\n    CacheBuilderFactory factory = cacheFactory();\r\n    return Iterables.transform(factory.buildAllPermutations(), new Function<Caffeine<Object, Object>, LoadingCache<Object, Object>>() {\r\n        @Override\r\n        public LoadingCache<Object, Object> apply(Caffeine<Object, Object> builder) {\r\n            return CaffeinatedGuava.build(builder.recordStats(), identityLoader());\r\n        }\r\n    });\r\n}"
}, {
	"Path": "com.google.common.cache.PopulatedCachesTest.caches",
	"Comment": "most of the tests in this class run against every one of these caches.",
	"Method": "Iterable<LoadingCache<Object, Object>> caches(){\r\n    return CaffeinatedGuava.build(builder.recordStats(), identityLoader());\r\n}"
}, {
	"Path": "org.objectweb.asm.Frame.execute",
	"Comment": "simulates the action of the given instruction on the output stack frame.",
	"Method": "void execute(int opcode,int arg,ClassWriter cw,Item item){\r\n    int t1, t2, t3, t4;\r\n    switch(opcode) {\r\n        case Opcodes.NOP:\r\n        case Opcodes.INEG:\r\n        case Opcodes.LNEG:\r\n        case Opcodes.FNEG:\r\n        case Opcodes.DNEG:\r\n        case Opcodes.I2B:\r\n        case Opcodes.I2C:\r\n        case Opcodes.I2S:\r\n        case Opcodes.GOTO:\r\n        case Opcodes.RETURN:\r\n            break;\r\n        case Opcodes.ACONST_NULL:\r\n            push(NULL);\r\n            break;\r\n        case Opcodes.ICONST_M1:\r\n        case Opcodes.ICONST_0:\r\n        case Opcodes.ICONST_1:\r\n        case Opcodes.ICONST_2:\r\n        case Opcodes.ICONST_3:\r\n        case Opcodes.ICONST_4:\r\n        case Opcodes.ICONST_5:\r\n        case Opcodes.BIPUSH:\r\n        case Opcodes.SIPUSH:\r\n        case Opcodes.ILOAD:\r\n            push(INTEGER);\r\n            break;\r\n        case Opcodes.LCONST_0:\r\n        case Opcodes.LCONST_1:\r\n        case Opcodes.LLOAD:\r\n            push(LONG);\r\n            push(TOP);\r\n            break;\r\n        case Opcodes.FCONST_0:\r\n        case Opcodes.FCONST_1:\r\n        case Opcodes.FCONST_2:\r\n        case Opcodes.FLOAD:\r\n            push(FLOAT);\r\n            break;\r\n        case Opcodes.DCONST_0:\r\n        case Opcodes.DCONST_1:\r\n        case Opcodes.DLOAD:\r\n            push(DOUBLE);\r\n            push(TOP);\r\n            break;\r\n        case Opcodes.LDC:\r\n            switch(item.type) {\r\n                case ClassWriter.INT:\r\n                    push(INTEGER);\r\n                    break;\r\n                case ClassWriter.LONG:\r\n                    push(LONG);\r\n                    push(TOP);\r\n                    break;\r\n                case ClassWriter.FLOAT:\r\n                    push(FLOAT);\r\n                    break;\r\n                case ClassWriter.DOUBLE:\r\n                    push(DOUBLE);\r\n                    push(TOP);\r\n                    break;\r\n                case ClassWriter.CLASS:\r\n                    push(OBJECT | cw.addType(\"java/lang/Class\"));\r\n                    break;\r\n                case ClassWriter.STR:\r\n                    push(OBJECT | cw.addType(\"java/lang/String\"));\r\n                    break;\r\n                case ClassWriter.MTYPE:\r\n                    push(OBJECT | cw.addType(\"java/lang/invoke/MethodType\"));\r\n                    break;\r\n                default:\r\n                    push(OBJECT | cw.addType(\"java/lang/invoke/MethodHandle\"));\r\n            }\r\n            break;\r\n        case Opcodes.ALOAD:\r\n            push(get(arg));\r\n            break;\r\n        case Opcodes.IALOAD:\r\n        case Opcodes.BALOAD:\r\n        case Opcodes.CALOAD:\r\n        case Opcodes.SALOAD:\r\n            pop(2);\r\n            push(INTEGER);\r\n            break;\r\n        case Opcodes.LALOAD:\r\n        case Opcodes.D2L:\r\n            pop(2);\r\n            push(LONG);\r\n            push(TOP);\r\n            break;\r\n        case Opcodes.FALOAD:\r\n            pop(2);\r\n            push(FLOAT);\r\n            break;\r\n        case Opcodes.DALOAD:\r\n        case Opcodes.L2D:\r\n            pop(2);\r\n            push(DOUBLE);\r\n            push(TOP);\r\n            break;\r\n        case Opcodes.AALOAD:\r\n            pop(1);\r\n            t1 = pop();\r\n            push(ELEMENT_OF + t1);\r\n            break;\r\n        case Opcodes.ISTORE:\r\n        case Opcodes.FSTORE:\r\n        case Opcodes.ASTORE:\r\n            t1 = pop();\r\n            set(arg, t1);\r\n            if (arg > 0) {\r\n                t2 = get(arg - 1);\r\n                if (t2 == LONG || t2 == DOUBLE) {\r\n                    set(arg - 1, TOP);\r\n                } else if ((t2 & KIND) != BASE) {\r\n                    set(arg - 1, t2 | TOP_IF_LONG_OR_DOUBLE);\r\n                }\r\n            }\r\n            break;\r\n        case Opcodes.LSTORE:\r\n        case Opcodes.DSTORE:\r\n            pop(1);\r\n            t1 = pop();\r\n            set(arg, t1);\r\n            set(arg + 1, TOP);\r\n            if (arg > 0) {\r\n                t2 = get(arg - 1);\r\n                if (t2 == LONG || t2 == DOUBLE) {\r\n                    set(arg - 1, TOP);\r\n                } else if ((t2 & KIND) != BASE) {\r\n                    set(arg - 1, t2 | TOP_IF_LONG_OR_DOUBLE);\r\n                }\r\n            }\r\n            break;\r\n        case Opcodes.IASTORE:\r\n        case Opcodes.BASTORE:\r\n        case Opcodes.CASTORE:\r\n        case Opcodes.SASTORE:\r\n        case Opcodes.FASTORE:\r\n        case Opcodes.AASTORE:\r\n            pop(3);\r\n            break;\r\n        case Opcodes.LASTORE:\r\n        case Opcodes.DASTORE:\r\n            pop(4);\r\n            break;\r\n        case Opcodes.POP:\r\n        case Opcodes.IFEQ:\r\n        case Opcodes.IFNE:\r\n        case Opcodes.IFLT:\r\n        case Opcodes.IFGE:\r\n        case Opcodes.IFGT:\r\n        case Opcodes.IFLE:\r\n        case Opcodes.IRETURN:\r\n        case Opcodes.FRETURN:\r\n        case Opcodes.ARETURN:\r\n        case Opcodes.TABLESWITCH:\r\n        case Opcodes.LOOKUPSWITCH:\r\n        case Opcodes.ATHROW:\r\n        case Opcodes.MONITORENTER:\r\n        case Opcodes.MONITOREXIT:\r\n        case Opcodes.IFNULL:\r\n        case Opcodes.IFNONNULL:\r\n            pop(1);\r\n            break;\r\n        case Opcodes.POP2:\r\n        case Opcodes.IF_ICMPEQ:\r\n        case Opcodes.IF_ICMPNE:\r\n        case Opcodes.IF_ICMPLT:\r\n        case Opcodes.IF_ICMPGE:\r\n        case Opcodes.IF_ICMPGT:\r\n        case Opcodes.IF_ICMPLE:\r\n        case Opcodes.IF_ACMPEQ:\r\n        case Opcodes.IF_ACMPNE:\r\n        case Opcodes.LRETURN:\r\n        case Opcodes.DRETURN:\r\n            pop(2);\r\n            break;\r\n        case Opcodes.DUP:\r\n            t1 = pop();\r\n            push(t1);\r\n            push(t1);\r\n            break;\r\n        case Opcodes.DUP_X1:\r\n            t1 = pop();\r\n            t2 = pop();\r\n            push(t1);\r\n            push(t2);\r\n            push(t1);\r\n            break;\r\n        case Opcodes.DUP_X2:\r\n            t1 = pop();\r\n            t2 = pop();\r\n            t3 = pop();\r\n            push(t1);\r\n            push(t3);\r\n            push(t2);\r\n            push(t1);\r\n            break;\r\n        case Opcodes.DUP2:\r\n            t1 = pop();\r\n            t2 = pop();\r\n            push(t2);\r\n            push(t1);\r\n            push(t2);\r\n            push(t1);\r\n            break;\r\n        case Opcodes.DUP2_X1:\r\n            t1 = pop();\r\n            t2 = pop();\r\n            t3 = pop();\r\n            push(t2);\r\n            push(t1);\r\n            push(t3);\r\n            push(t2);\r\n            push(t1);\r\n            break;\r\n        case Opcodes.DUP2_X2:\r\n            t1 = pop();\r\n            t2 = pop();\r\n            t3 = pop();\r\n            t4 = pop();\r\n            push(t2);\r\n            push(t1);\r\n            push(t4);\r\n            push(t3);\r\n            push(t2);\r\n            push(t1);\r\n            break;\r\n        case Opcodes.SWAP:\r\n            t1 = pop();\r\n            t2 = pop();\r\n            push(t1);\r\n            push(t2);\r\n            break;\r\n        case Opcodes.IADD:\r\n        case Opcodes.ISUB:\r\n        case Opcodes.IMUL:\r\n        case Opcodes.IDIV:\r\n        case Opcodes.IREM:\r\n        case Opcodes.IAND:\r\n        case Opcodes.IOR:\r\n        case Opcodes.IXOR:\r\n        case Opcodes.ISHL:\r\n        case Opcodes.ISHR:\r\n        case Opcodes.IUSHR:\r\n        case Opcodes.L2I:\r\n        case Opcodes.D2I:\r\n        case Opcodes.FCMPL:\r\n        case Opcodes.FCMPG:\r\n            pop(2);\r\n            push(INTEGER);\r\n            break;\r\n        case Opcodes.LADD:\r\n        case Opcodes.LSUB:\r\n        case Opcodes.LMUL:\r\n        case Opcodes.LDIV:\r\n        case Opcodes.LREM:\r\n        case Opcodes.LAND:\r\n        case Opcodes.LOR:\r\n        case Opcodes.LXOR:\r\n            pop(4);\r\n            push(LONG);\r\n            push(TOP);\r\n            break;\r\n        case Opcodes.FADD:\r\n        case Opcodes.FSUB:\r\n        case Opcodes.FMUL:\r\n        case Opcodes.FDIV:\r\n        case Opcodes.FREM:\r\n        case Opcodes.L2F:\r\n        case Opcodes.D2F:\r\n            pop(2);\r\n            push(FLOAT);\r\n            break;\r\n        case Opcodes.DADD:\r\n        case Opcodes.DSUB:\r\n        case Opcodes.DMUL:\r\n        case Opcodes.DDIV:\r\n        case Opcodes.DREM:\r\n            pop(4);\r\n            push(DOUBLE);\r\n            push(TOP);\r\n            break;\r\n        case Opcodes.LSHL:\r\n        case Opcodes.LSHR:\r\n        case Opcodes.LUSHR:\r\n            pop(3);\r\n            push(LONG);\r\n            push(TOP);\r\n            break;\r\n        case Opcodes.IINC:\r\n            set(arg, INTEGER);\r\n            break;\r\n        case Opcodes.I2L:\r\n        case Opcodes.F2L:\r\n            pop(1);\r\n            push(LONG);\r\n            push(TOP);\r\n            break;\r\n        case Opcodes.I2F:\r\n            pop(1);\r\n            push(FLOAT);\r\n            break;\r\n        case Opcodes.I2D:\r\n        case Opcodes.F2D:\r\n            pop(1);\r\n            push(DOUBLE);\r\n            push(TOP);\r\n            break;\r\n        case Opcodes.F2I:\r\n        case Opcodes.ARRAYLENGTH:\r\n        case Opcodes.INSTANCEOF:\r\n            pop(1);\r\n            push(INTEGER);\r\n            break;\r\n        case Opcodes.LCMP:\r\n        case Opcodes.DCMPL:\r\n        case Opcodes.DCMPG:\r\n            pop(4);\r\n            push(INTEGER);\r\n            break;\r\n        case Opcodes.JSR:\r\n        case Opcodes.RET:\r\n            throw new RuntimeException(\"JSR/RET are not supported with computeFrames option\");\r\n        case Opcodes.GETSTATIC:\r\n            push(cw, item.strVal3);\r\n            break;\r\n        case Opcodes.PUTSTATIC:\r\n            pop(item.strVal3);\r\n            break;\r\n        case Opcodes.GETFIELD:\r\n            pop(1);\r\n            push(cw, item.strVal3);\r\n            break;\r\n        case Opcodes.PUTFIELD:\r\n            pop(item.strVal3);\r\n            pop();\r\n            break;\r\n        case Opcodes.INVOKEVIRTUAL:\r\n        case Opcodes.INVOKESPECIAL:\r\n        case Opcodes.INVOKESTATIC:\r\n        case Opcodes.INVOKEINTERFACE:\r\n            pop(item.strVal3);\r\n            if (opcode != Opcodes.INVOKESTATIC) {\r\n                t1 = pop();\r\n                if (opcode == Opcodes.INVOKESPECIAL && item.strVal2.charAt(0) == '<') {\r\n                    init(t1);\r\n                }\r\n            }\r\n            push(cw, item.strVal3);\r\n            break;\r\n        case Opcodes.INVOKEDYNAMIC:\r\n            pop(item.strVal2);\r\n            push(cw, item.strVal2);\r\n            break;\r\n        case Opcodes.NEW:\r\n            push(UNINITIALIZED | cw.addUninitializedType(item.strVal1, arg));\r\n            break;\r\n        case Opcodes.NEWARRAY:\r\n            pop();\r\n            switch(arg) {\r\n                case Opcodes.T_BOOLEAN:\r\n                    push(ARRAY_OF | BOOLEAN);\r\n                    break;\r\n                case Opcodes.T_CHAR:\r\n                    push(ARRAY_OF | CHAR);\r\n                    break;\r\n                case Opcodes.T_BYTE:\r\n                    push(ARRAY_OF | BYTE);\r\n                    break;\r\n                case Opcodes.T_SHORT:\r\n                    push(ARRAY_OF | SHORT);\r\n                    break;\r\n                case Opcodes.T_INT:\r\n                    push(ARRAY_OF | INTEGER);\r\n                    break;\r\n                case Opcodes.T_FLOAT:\r\n                    push(ARRAY_OF | FLOAT);\r\n                    break;\r\n                case Opcodes.T_DOUBLE:\r\n                    push(ARRAY_OF | DOUBLE);\r\n                    break;\r\n                default:\r\n                    push(ARRAY_OF | LONG);\r\n                    break;\r\n            }\r\n            break;\r\n        case Opcodes.ANEWARRAY:\r\n            String s = item.strVal1;\r\n            pop();\r\n            if (s.charAt(0) == '[') {\r\n                push(cw, '[' + s);\r\n            } else {\r\n                push(ARRAY_OF | OBJECT | cw.addType(s));\r\n            }\r\n            break;\r\n        case Opcodes.CHECKCAST:\r\n            s = item.strVal1;\r\n            pop();\r\n            if (s.charAt(0) == '[') {\r\n                push(cw, s);\r\n            } else {\r\n                push(OBJECT | cw.addType(s));\r\n            }\r\n            break;\r\n        default:\r\n            pop(arg);\r\n            push(cw, item.strVal1);\r\n            break;\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.AbstractSequenceClassifier.writeAnswers",
	"Comment": "write the classifications of the sequence classifier to a writer in aformat determined by the documentreaderandwriter used.",
	"Method": "void writeAnswers(List<IN> doc,PrintWriter printWriter,DocumentReaderAndWriter<IN> readerAndWriter){\r\n    if (flags.lowerNewgeneThreshold) {\r\n        return;\r\n    }\r\n    if (flags.numRuns <= 1) {\r\n        readerAndWriter.printAnswers(doc, printWriter);\r\n        printWriter.flush();\r\n    }\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.ui.BuckEventsConsumer.sendAsConsoleEvent",
	"Comment": "add a bucktextnode to display a message as if it were sent as a console event",
	"Method": "void sendAsConsoleEvent(String message,TextType textType){\r\n    if (mCurrentBuildRootElement == null) {\r\n        return;\r\n    }\r\n    mBuckUIManager.getBuckTreeViewPanel().getModifiableModel().addChild(mCurrentBuildRootElement, new BuckTextNode(message, textType));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.expiresAfterWrite",
	"Comment": "returns if the cache expires entries after an write time threshold.",
	"Method": "boolean expiresAfterWrite(){\r\n    return false;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.segment.S4WindowTinyLfuPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    S4WindowTinyLfuSettings settings = new S4WindowTinyLfuSettings(config);\r\n    return settings.percentMain().stream().map(percentMain -> new S4WindowTinyLfuPolicy(percentMain, settings)).collect(toSet());\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.linked.SegmentedLruPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    BasicSettings settings = new BasicSettings(config);\r\n    return settings.admission().stream().map(admission -> new SegmentedLruPolicy(admission, config)).collect(toSet());\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.two_queue.TuQueuePolicy.onMiss",
	"Comment": "adds the entry to the cache as hot, overflowing to the cold queue, and evicts if necessary.",
	"Method": "void onMiss(long key){\r\n    Node node = new Node(key);\r\n    node.type = QueueType.HOT;\r\n    node.appendToTail(headHot);\r\n    data.put(key, node);\r\n    sizeHot++;\r\n    if (sizeHot > maxHot) {\r\n        Node demoted = headHot.next;\r\n        demoted.remove();\r\n        sizeHot--;\r\n        demoted.appendToTail(headCold);\r\n        demoted.type = QueueType.COLD;\r\n        sizeCold++;\r\n        evict();\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.DefaultMultifactorAuthenticationProviderBypass.locateMatchingAttributeBasedOnAuthenticationAttributes",
	"Comment": "skip bypass and support event based on authentication attributes.",
	"Method": "boolean locateMatchingAttributeBasedOnAuthenticationAttributes(MultifactorAuthenticationProviderBypassProperties bypass,Authentication authn){\r\n    return locateMatchingAttributeValue(bypass.getAuthenticationAttributeName(), bypass.getAuthenticationAttributeValue(), authn.getAttributes());\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.RandomSeedEnforcer.unwrap",
	"Comment": "returns the underlying bounded cache, or null if not applicable.",
	"Method": "BoundedLocalCache<?, ?> unwrap(Cache<?, ?> cache){\r\n    ConcurrentMap<?, ?> map = cache.asMap();\r\n    if (map instanceof LocalAsyncLoadingCache.AsMapView<?, ?>) {\r\n        map = ((LocalAsyncLoadingCache.AsMapView<?, ?>) cache.asMap()).delegate;\r\n    }\r\n    return (map instanceof BoundedLocalCache<?, ?>) ? (BoundedLocalCache<?, ?>) map : null;\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.Mention.isListMemberOf",
	"Comment": "check list member? true if this mention is inside the other mention and the other mention is a list",
	"Method": "boolean isListMemberOf(Mention m){\r\n    if (this.equals(m))\r\n        return false;\r\n    if (m.mentionType == MentionType.LIST && this.mentionType == MentionType.LIST)\r\n        return false;\r\n    if (m.mentionType == MentionType.LIST) {\r\n        return this.includedIn(m);\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.FirstFitLocalCombiningAllocator.adjustAndMapSourceRangeRange",
	"Comment": "maps the source registers of the specified instruction such that theywill fall in a contiguous range in rop form. moves are inserted asnecessary to allow the range to be allocated.",
	"Method": "void adjustAndMapSourceRangeRange(NormalSsaInsn insn){\r\n    int newRegStart = findRangeAndAdjust(insn);\r\n    RegisterSpecList sources = insn.getSources();\r\n    int szSources = sources.size();\r\n    int nextRopReg = newRegStart;\r\n    for (int i = 0; i < szSources; i++) {\r\n        RegisterSpec source = sources.get(i);\r\n        int sourceReg = source.getReg();\r\n        int category = source.getCategory();\r\n        int curRopReg = nextRopReg;\r\n        nextRopReg += category;\r\n        if (ssaRegsMapped.get(sourceReg)) {\r\n            continue;\r\n        }\r\n        LocalItem localItem = getLocalItemForReg(sourceReg);\r\n        addMapping(source, curRopReg);\r\n        if (localItem != null) {\r\n            markReserved(curRopReg, category);\r\n            ArrayList<RegisterSpec> similarRegisters = localVariables.get(localItem);\r\n            int szSimilar = similarRegisters.size();\r\n            for (int j = 0; j < szSimilar; j++) {\r\n                RegisterSpec similarSpec = similarRegisters.get(j);\r\n                int similarReg = similarSpec.getReg();\r\n                if (-1 != sources.indexOfRegister(similarReg)) {\r\n                    continue;\r\n                }\r\n                tryMapReg(similarSpec, curRopReg, category);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.ticket.registry.MongoDbTicketRegistry.removeDifferingIndexIfAny",
	"Comment": "remove any index with the same indexkey but differing indexoptions in anticipation of recreating it.",
	"Method": "void removeDifferingIndexIfAny(MongoCollection collection,Index index){\r\n    val indexes = (ListIndexesIterable<Document>) collection.listIndexes();\r\n    var indexExistsWithDifferentOptions = false;\r\n    for (val existingIndex : indexes) {\r\n        val keyMatches = existingIndex.get(\"key\").equals(index.getIndexKeys());\r\n        val optionsMatch = index.getIndexOptions().entrySet().stream().allMatch(entry -> entry.getValue().equals(existingIndex.get(entry.getKey())));\r\n        val noExtraOptions = existingIndex.keySet().stream().allMatch(key -> MONGO_INDEX_KEYS.contains(key) || index.getIndexOptions().keySet().contains(key));\r\n        indexExistsWithDifferentOptions |= keyMatches && !(optionsMatch && noExtraOptions);\r\n    }\r\n    if (indexExistsWithDifferentOptions) {\r\n        LOGGER.debug(\"Removing MongoDb index [{}] from [{}] because it appears to already exist in a different form\", index.getIndexKeys(), collection.getNamespace());\r\n        collection.dropIndex(index.getIndexKeys());\r\n    }\r\n}"
}, {
	"Path": "com.facebook.buck.tools.consistency.TargetsStressRunner.verifyNoChanges",
	"Comment": "verifies that there are no changes between several targets files",
	"Method": "void verifyNoChanges(Path firstOutputFile,List<Path> outputFiles){\r\n    TargetHashFileParser parser = new TargetHashFileParser();\r\n    ParsedTargetsFile originalFile = parser.parseFile(firstOutputFile);\r\n    for (Path file : outputFiles) {\r\n        ParsedTargetsFile newTargetsFile = parser.parseFile(file);\r\n        TargetsDiffer targetsDiffer = null;\r\n        try {\r\n            targetsDiffer = differFactory.call();\r\n        } catch (Exception e) {\r\n            throw new TargetsStressRunException(String.format(\"Error creating differ: %s\", e.getMessage()), e);\r\n        }\r\n        if (targetsDiffer.printDiff(originalFile, newTargetsFile) == DiffResult.CHANGES_FOUND) {\r\n            throw new TargetsStressRunException(String.format(\"Found differences between %s and %s\", originalFile.filename, newTargetsFile.filename));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaConverter.updateSsaMethod",
	"Comment": "updates an ssa representation, placing phi functions and renaming allregisters above a certain threshold number.",
	"Method": "void updateSsaMethod(SsaMethod ssaMeth,int threshold){\r\n    LocalVariableInfo localInfo = LocalVariableExtractor.extract(ssaMeth);\r\n    placePhiFunctions(ssaMeth, localInfo, threshold);\r\n    new SsaRenamer(ssaMeth, threshold).run();\r\n}"
}, {
	"Path": "org.apache.commons.codec.digest.HmacUtils.getHmacSha256",
	"Comment": "returns an initialized mac for the hmacsha256 algorithm.every implementation of the java platform is required to support this standard mac algorithm.",
	"Method": "Mac getHmacSha256(byte[] key){\r\n    return getInitializedMac(HmacAlgorithms.HMAC_SHA_256, key);\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassReader.readCode",
	"Comment": "reads the bytecode of a method and makes the given visitor visit it.",
	"Method": "void readCode(MethodVisitor mv,Context context,int u){\r\n    byte[] b = this.b;\r\n    char[] c = context.buffer;\r\n    int maxStack = readUnsignedShort(u);\r\n    int maxLocals = readUnsignedShort(u + 2);\r\n    int codeLength = readInt(u + 4);\r\n    u += 8;\r\n    int codeStart = u;\r\n    int codeEnd = u + codeLength;\r\n    Label[] labels = context.labels = new Label[codeLength + 2];\r\n    readLabel(codeLength + 1, labels);\r\n    while (u < codeEnd) {\r\n        int offset = u - codeStart;\r\n        int opcode = b[u] & 0xFF;\r\n        switch(ClassWriter.TYPE[opcode]) {\r\n            case ClassWriter.NOARG_INSN:\r\n            case ClassWriter.IMPLVAR_INSN:\r\n                u += 1;\r\n                break;\r\n            case ClassWriter.LABEL_INSN:\r\n                readLabel(offset + readShort(u + 1), labels);\r\n                u += 3;\r\n                break;\r\n            case ClassWriter.LABELW_INSN:\r\n                readLabel(offset + readInt(u + 1), labels);\r\n                u += 5;\r\n                break;\r\n            case ClassWriter.WIDE_INSN:\r\n                opcode = b[u + 1] & 0xFF;\r\n                if (opcode == Opcodes.IINC) {\r\n                    u += 6;\r\n                } else {\r\n                    u += 4;\r\n                }\r\n                break;\r\n            case ClassWriter.TABL_INSN:\r\n                u = u + 4 - (offset & 3);\r\n                readLabel(offset + readInt(u), labels);\r\n                for (int i = readInt(u + 8) - readInt(u + 4) + 1; i > 0; --i) {\r\n                    readLabel(offset + readInt(u + 12), labels);\r\n                    u += 4;\r\n                }\r\n                u += 12;\r\n                break;\r\n            case ClassWriter.LOOK_INSN:\r\n                u = u + 4 - (offset & 3);\r\n                readLabel(offset + readInt(u), labels);\r\n                for (int i = readInt(u + 4); i > 0; --i) {\r\n                    readLabel(offset + readInt(u + 12), labels);\r\n                    u += 8;\r\n                }\r\n                u += 8;\r\n                break;\r\n            case ClassWriter.VAR_INSN:\r\n            case ClassWriter.SBYTE_INSN:\r\n            case ClassWriter.LDC_INSN:\r\n                u += 2;\r\n                break;\r\n            case ClassWriter.SHORT_INSN:\r\n            case ClassWriter.LDCW_INSN:\r\n            case ClassWriter.FIELDORMETH_INSN:\r\n            case ClassWriter.TYPE_INSN:\r\n            case ClassWriter.IINC_INSN:\r\n                u += 3;\r\n                break;\r\n            case ClassWriter.ITFMETH_INSN:\r\n            case ClassWriter.INDYMETH_INSN:\r\n                u += 5;\r\n                break;\r\n            default:\r\n                u += 4;\r\n                break;\r\n        }\r\n    }\r\n    for (int i = readUnsignedShort(u); i > 0; --i) {\r\n        Label start = readLabel(readUnsignedShort(u + 2), labels);\r\n        Label end = readLabel(readUnsignedShort(u + 4), labels);\r\n        Label handler = readLabel(readUnsignedShort(u + 6), labels);\r\n        String type = readUTF8(items[readUnsignedShort(u + 8)], c);\r\n        mv.visitTryCatchBlock(start, end, handler, type);\r\n        u += 8;\r\n    }\r\n    u += 2;\r\n    int[] tanns = null;\r\n    int[] itanns = null;\r\n    int tann = 0;\r\n    int itann = 0;\r\n    int ntoff = -1;\r\n    int nitoff = -1;\r\n    int varTable = 0;\r\n    int varTypeTable = 0;\r\n    boolean zip = true;\r\n    boolean unzip = (context.flags & EXPAND_FRAMES) != 0;\r\n    int stackMap = 0;\r\n    int stackMapSize = 0;\r\n    int frameCount = 0;\r\n    Context frame = null;\r\n    Attribute attributes = null;\r\n    for (int i = readUnsignedShort(u); i > 0; --i) {\r\n        String attrName = readUTF8(u + 2, c);\r\n        if (\"LocalVariableTable\".equals(attrName)) {\r\n            if ((context.flags & SKIP_DEBUG) == 0) {\r\n                varTable = u + 8;\r\n                for (int j = readUnsignedShort(u + 8), v = u; j > 0; --j) {\r\n                    int label = readUnsignedShort(v + 10);\r\n                    if (labels[label] == null) {\r\n                        readLabel(label, labels).status |= Label.DEBUG;\r\n                    }\r\n                    label += readUnsignedShort(v + 12);\r\n                    if (labels[label] == null) {\r\n                        readLabel(label, labels).status |= Label.DEBUG;\r\n                    }\r\n                    v += 10;\r\n                }\r\n            }\r\n        } else if (\"LocalVariableTypeTable\".equals(attrName)) {\r\n            varTypeTable = u + 8;\r\n        } else if (\"LineNumberTable\".equals(attrName)) {\r\n            if ((context.flags & SKIP_DEBUG) == 0) {\r\n                for (int j = readUnsignedShort(u + 8), v = u; j > 0; --j) {\r\n                    int label = readUnsignedShort(v + 10);\r\n                    if (labels[label] == null) {\r\n                        readLabel(label, labels).status |= Label.DEBUG;\r\n                    }\r\n                    Label l = labels[label];\r\n                    while (l.line > 0) {\r\n                        if (l.next == null) {\r\n                            l.next = new Label();\r\n                        }\r\n                        l = l.next;\r\n                    }\r\n                    l.line = readUnsignedShort(v + 12);\r\n                    v += 4;\r\n                }\r\n            }\r\n        } else if (ANNOTATIONS && \"RuntimeVisibleTypeAnnotations\".equals(attrName)) {\r\n            tanns = readTypeAnnotations(mv, context, u + 8, true);\r\n            ntoff = tanns.length == 0 || readByte(tanns[0]) < 0x43 ? -1 : readUnsignedShort(tanns[0] + 1);\r\n        } else if (ANNOTATIONS && \"RuntimeInvisibleTypeAnnotations\".equals(attrName)) {\r\n            itanns = readTypeAnnotations(mv, context, u + 8, false);\r\n            nitoff = itanns.length == 0 || readByte(itanns[0]) < 0x43 ? -1 : readUnsignedShort(itanns[0] + 1);\r\n        } else if (FRAMES && \"StackMapTable\".equals(attrName)) {\r\n            if ((context.flags & SKIP_FRAMES) == 0) {\r\n                stackMap = u + 10;\r\n                stackMapSize = readInt(u + 4);\r\n                frameCount = readUnsignedShort(u + 8);\r\n            }\r\n        } else if (FRAMES && \"StackMap\".equals(attrName)) {\r\n            if ((context.flags & SKIP_FRAMES) == 0) {\r\n                zip = false;\r\n                stackMap = u + 10;\r\n                stackMapSize = readInt(u + 4);\r\n                frameCount = readUnsignedShort(u + 8);\r\n            }\r\n        } else {\r\n            for (int j = 0; j < context.attrs.length; ++j) {\r\n                if (context.attrs[j].type.equals(attrName)) {\r\n                    Attribute attr = context.attrs[j].read(this, u + 8, readInt(u + 4), c, codeStart - 8, labels);\r\n                    if (attr != null) {\r\n                        attr.next = attributes;\r\n                        attributes = attr;\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        u += 6 + readInt(u + 4);\r\n    }\r\n    u += 2;\r\n    if (FRAMES && stackMap != 0) {\r\n        frame = context;\r\n        frame.offset = -1;\r\n        frame.mode = 0;\r\n        frame.localCount = 0;\r\n        frame.localDiff = 0;\r\n        frame.stackCount = 0;\r\n        frame.local = new Object[maxLocals];\r\n        frame.stack = new Object[maxStack];\r\n        if (unzip) {\r\n            getImplicitFrame(context);\r\n        }\r\n        for (int i = stackMap; i < stackMap + stackMapSize - 2; ++i) {\r\n            if (b[i] == 8) {\r\n                int v = readUnsignedShort(i + 1);\r\n                if (v >= 0 && v < codeLength) {\r\n                    if ((b[codeStart + v] & 0xFF) == Opcodes.NEW) {\r\n                        readLabel(v, labels);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n    u = codeStart;\r\n    while (u < codeEnd) {\r\n        int offset = u - codeStart;\r\n        Label l = labels[offset];\r\n        if (l != null) {\r\n            Label next = l.next;\r\n            l.next = null;\r\n            mv.visitLabel(l);\r\n            if ((context.flags & SKIP_DEBUG) == 0 && l.line > 0) {\r\n                mv.visitLineNumber(l.line, l);\r\n                while (next != null) {\r\n                    mv.visitLineNumber(next.line, l);\r\n                    next = next.next;\r\n                }\r\n            }\r\n        }\r\n        while (FRAMES && frame != null && (frame.offset == offset || frame.offset == -1)) {\r\n            if (frame.offset != -1) {\r\n                if (!zip || unzip) {\r\n                    mv.visitFrame(Opcodes.F_NEW, frame.localCount, frame.local, frame.stackCount, frame.stack);\r\n                } else {\r\n                    mv.visitFrame(frame.mode, frame.localDiff, frame.local, frame.stackCount, frame.stack);\r\n                }\r\n            }\r\n            if (frameCount > 0) {\r\n                stackMap = readFrame(stackMap, zip, unzip, frame);\r\n                --frameCount;\r\n            } else {\r\n                frame = null;\r\n            }\r\n        }\r\n        int opcode = b[u] & 0xFF;\r\n        switch(ClassWriter.TYPE[opcode]) {\r\n            case ClassWriter.NOARG_INSN:\r\n                mv.visitInsn(opcode);\r\n                u += 1;\r\n                break;\r\n            case ClassWriter.IMPLVAR_INSN:\r\n                if (opcode > Opcodes.ISTORE) {\r\n                    opcode -= 59;\r\n                    mv.visitVarInsn(Opcodes.ISTORE + (opcode >> 2), opcode & 0x3);\r\n                } else {\r\n                    opcode -= 26;\r\n                    mv.visitVarInsn(Opcodes.ILOAD + (opcode >> 2), opcode & 0x3);\r\n                }\r\n                u += 1;\r\n                break;\r\n            case ClassWriter.LABEL_INSN:\r\n                mv.visitJumpInsn(opcode, labels[offset + readShort(u + 1)]);\r\n                u += 3;\r\n                break;\r\n            case ClassWriter.LABELW_INSN:\r\n                mv.visitJumpInsn(opcode - 33, labels[offset + readInt(u + 1)]);\r\n                u += 5;\r\n                break;\r\n            case ClassWriter.WIDE_INSN:\r\n                opcode = b[u + 1] & 0xFF;\r\n                if (opcode == Opcodes.IINC) {\r\n                    mv.visitIincInsn(readUnsignedShort(u + 2), readShort(u + 4));\r\n                    u += 6;\r\n                } else {\r\n                    mv.visitVarInsn(opcode, readUnsignedShort(u + 2));\r\n                    u += 4;\r\n                }\r\n                break;\r\n            case ClassWriter.TABL_INSN:\r\n                {\r\n                    u = u + 4 - (offset & 3);\r\n                    int label = offset + readInt(u);\r\n                    int min = readInt(u + 4);\r\n                    int max = readInt(u + 8);\r\n                    Label[] table = new Label[max - min + 1];\r\n                    u += 12;\r\n                    for (int i = 0; i < table.length; ++i) {\r\n                        table[i] = labels[offset + readInt(u)];\r\n                        u += 4;\r\n                    }\r\n                    mv.visitTableSwitchInsn(min, max, labels[label], table);\r\n                    break;\r\n                }\r\n            case ClassWriter.LOOK_INSN:\r\n                {\r\n                    u = u + 4 - (offset & 3);\r\n                    int label = offset + readInt(u);\r\n                    int len = readInt(u + 4);\r\n                    int[] keys = new int[len];\r\n                    Label[] values = new Label[len];\r\n                    u += 8;\r\n                    for (int i = 0; i < len; ++i) {\r\n                        keys[i] = readInt(u);\r\n                        values[i] = labels[offset + readInt(u + 4)];\r\n                        u += 8;\r\n                    }\r\n                    mv.visitLookupSwitchInsn(labels[label], keys, values);\r\n                    break;\r\n                }\r\n            case ClassWriter.VAR_INSN:\r\n                mv.visitVarInsn(opcode, b[u + 1] & 0xFF);\r\n                u += 2;\r\n                break;\r\n            case ClassWriter.SBYTE_INSN:\r\n                mv.visitIntInsn(opcode, b[u + 1]);\r\n                u += 2;\r\n                break;\r\n            case ClassWriter.SHORT_INSN:\r\n                mv.visitIntInsn(opcode, readShort(u + 1));\r\n                u += 3;\r\n                break;\r\n            case ClassWriter.LDC_INSN:\r\n                mv.visitLdcInsn(readConst(b[u + 1] & 0xFF, c));\r\n                u += 2;\r\n                break;\r\n            case ClassWriter.LDCW_INSN:\r\n                mv.visitLdcInsn(readConst(readUnsignedShort(u + 1), c));\r\n                u += 3;\r\n                break;\r\n            case ClassWriter.FIELDORMETH_INSN:\r\n            case ClassWriter.ITFMETH_INSN:\r\n                {\r\n                    int cpIndex = items[readUnsignedShort(u + 1)];\r\n                    boolean itf = b[cpIndex - 1] == ClassWriter.IMETH;\r\n                    String iowner = readClass(cpIndex, c);\r\n                    cpIndex = items[readUnsignedShort(cpIndex + 2)];\r\n                    String iname = readUTF8(cpIndex, c);\r\n                    String idesc = readUTF8(cpIndex + 2, c);\r\n                    if (opcode < Opcodes.INVOKEVIRTUAL) {\r\n                        mv.visitFieldInsn(opcode, iowner, iname, idesc);\r\n                    } else {\r\n                        mv.visitMethodInsn(opcode, iowner, iname, idesc, itf);\r\n                    }\r\n                    if (opcode == Opcodes.INVOKEINTERFACE) {\r\n                        u += 5;\r\n                    } else {\r\n                        u += 3;\r\n                    }\r\n                    break;\r\n                }\r\n            case ClassWriter.INDYMETH_INSN:\r\n                {\r\n                    int cpIndex = items[readUnsignedShort(u + 1)];\r\n                    int bsmIndex = context.bootstrapMethods[readUnsignedShort(cpIndex)];\r\n                    Handle bsm = (Handle) readConst(readUnsignedShort(bsmIndex), c);\r\n                    int bsmArgCount = readUnsignedShort(bsmIndex + 2);\r\n                    Object[] bsmArgs = new Object[bsmArgCount];\r\n                    bsmIndex += 4;\r\n                    for (int i = 0; i < bsmArgCount; i++) {\r\n                        bsmArgs[i] = readConst(readUnsignedShort(bsmIndex), c);\r\n                        bsmIndex += 2;\r\n                    }\r\n                    cpIndex = items[readUnsignedShort(cpIndex + 2)];\r\n                    String iname = readUTF8(cpIndex, c);\r\n                    String idesc = readUTF8(cpIndex + 2, c);\r\n                    mv.visitInvokeDynamicInsn(iname, idesc, bsm, bsmArgs);\r\n                    u += 5;\r\n                    break;\r\n                }\r\n            case ClassWriter.TYPE_INSN:\r\n                mv.visitTypeInsn(opcode, readClass(u + 1, c));\r\n                u += 3;\r\n                break;\r\n            case ClassWriter.IINC_INSN:\r\n                mv.visitIincInsn(b[u + 1] & 0xFF, b[u + 2]);\r\n                u += 3;\r\n                break;\r\n            default:\r\n                mv.visitMultiANewArrayInsn(readClass(u + 1, c), b[u + 3] & 0xFF);\r\n                u += 4;\r\n                break;\r\n        }\r\n        while (tanns != null && tann < tanns.length && ntoff <= offset) {\r\n            if (ntoff == offset) {\r\n                int v = readAnnotationTarget(context, tanns[tann]);\r\n                readAnnotationValues(v + 2, c, true, mv.visitInsnAnnotation(context.typeRef, context.typePath, readUTF8(v, c), true));\r\n            }\r\n            ntoff = ++tann >= tanns.length || readByte(tanns[tann]) < 0x43 ? -1 : readUnsignedShort(tanns[tann] + 1);\r\n        }\r\n        while (itanns != null && itann < itanns.length && nitoff <= offset) {\r\n            if (nitoff == offset) {\r\n                int v = readAnnotationTarget(context, itanns[itann]);\r\n                readAnnotationValues(v + 2, c, true, mv.visitInsnAnnotation(context.typeRef, context.typePath, readUTF8(v, c), false));\r\n            }\r\n            nitoff = ++itann >= itanns.length || readByte(itanns[itann]) < 0x43 ? -1 : readUnsignedShort(itanns[itann] + 1);\r\n        }\r\n    }\r\n    if (labels[codeLength] != null) {\r\n        mv.visitLabel(labels[codeLength]);\r\n    }\r\n    if ((context.flags & SKIP_DEBUG) == 0 && varTable != 0) {\r\n        int[] typeTable = null;\r\n        if (varTypeTable != 0) {\r\n            u = varTypeTable + 2;\r\n            typeTable = new int[readUnsignedShort(varTypeTable) * 3];\r\n            for (int i = typeTable.length; i > 0; ) {\r\n                typeTable[--i] = u + 6;\r\n                typeTable[--i] = readUnsignedShort(u + 8);\r\n                typeTable[--i] = readUnsignedShort(u);\r\n                u += 10;\r\n            }\r\n        }\r\n        u = varTable + 2;\r\n        for (int i = readUnsignedShort(varTable); i > 0; --i) {\r\n            int start = readUnsignedShort(u);\r\n            int length = readUnsignedShort(u + 2);\r\n            int index = readUnsignedShort(u + 8);\r\n            String vsignature = null;\r\n            if (typeTable != null) {\r\n                for (int j = 0; j < typeTable.length; j += 3) {\r\n                    if (typeTable[j] == start && typeTable[j + 1] == index) {\r\n                        vsignature = readUTF8(typeTable[j + 2], c);\r\n                        break;\r\n                    }\r\n                }\r\n            }\r\n            mv.visitLocalVariable(readUTF8(u + 4, c), readUTF8(u + 6, c), vsignature, labels[start], labels[start + length], index);\r\n            u += 10;\r\n        }\r\n    }\r\n    if (tanns != null) {\r\n        for (int i = 0; i < tanns.length; ++i) {\r\n            if ((readByte(tanns[i]) >> 1) == (0x40 >> 1)) {\r\n                int v = readAnnotationTarget(context, tanns[i]);\r\n                v = readAnnotationValues(v + 2, c, true, mv.visitLocalVariableAnnotation(context.typeRef, context.typePath, context.start, context.end, context.index, readUTF8(v, c), true));\r\n            }\r\n        }\r\n    }\r\n    if (itanns != null) {\r\n        for (int i = 0; i < itanns.length; ++i) {\r\n            if ((readByte(itanns[i]) >> 1) == (0x40 >> 1)) {\r\n                int v = readAnnotationTarget(context, itanns[i]);\r\n                v = readAnnotationValues(v + 2, c, true, mv.visitLocalVariableAnnotation(context.typeRef, context.typePath, context.start, context.end, context.index, readUTF8(v, c), false));\r\n            }\r\n        }\r\n    }\r\n    while (attributes != null) {\r\n        Attribute attr = attributes.next;\r\n        attributes.next = null;\r\n        mv.visitAttribute(attributes);\r\n        attributes = attr;\r\n    }\r\n    mv.visitMaxs(maxStack, maxLocals);\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.iinc",
	"Comment": "generates the instruction to increment the given local variable.",
	"Method": "void iinc(int local,int amount){\r\n    mv.visitIincInsn(local, amount);\r\n}"
}, {
	"Path": "jsr166.JSR166TestCase.getShortDelay",
	"Comment": "returns the shortest timed delay. this couldbe reimplemented to use for example a property.",
	"Method": "long getShortDelay(){\r\n    return 50;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.event.EventTypeAwareListener.isCompatible",
	"Comment": "returns if the backing listener consumes this type of event.",
	"Method": "boolean isCompatible(EventType eventType){\r\n    switch(eventType) {\r\n        case CREATED:\r\n            return (listener instanceof CacheEntryCreatedListener<?, ?>);\r\n        case UPDATED:\r\n            return (listener instanceof CacheEntryUpdatedListener<?, ?>);\r\n        case REMOVED:\r\n            return (listener instanceof CacheEntryRemovedListener<?, ?>);\r\n        case EXPIRED:\r\n            return (listener instanceof CacheEntryExpiredListener<?, ?>);\r\n    }\r\n    throw new IllegalStateException(\"Unknown event type: \" + eventType);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.PRCurve.logPrecision",
	"Comment": "what is the precision at this recall if we look at the score as the probability of class 1 given xas if coming from logistic regression",
	"Method": "int logPrecision(int recall){\r\n    int totaltaken = 0;\r\n    int rightIndex = numSamples() - 1;\r\n    int leftIndex = 0;\r\n    int totalcorrect = 0;\r\n    while (totaltaken < recall) {\r\n        double confr = Math.abs(scores[rightIndex] - .5);\r\n        double confl = Math.abs(scores[leftIndex] - .5);\r\n        int chosen = leftIndex;\r\n        if (confr > confl) {\r\n            chosen = rightIndex;\r\n            rightIndex--;\r\n        } else {\r\n            leftIndex++;\r\n        }\r\n        if ((scores[chosen] >= .5) && (classes[chosen] == 1)) {\r\n            totalcorrect++;\r\n        }\r\n        if ((scores[chosen] < .5) && (classes[chosen] == 0)) {\r\n            totalcorrect++;\r\n        }\r\n        totaltaken++;\r\n    }\r\n    return totalcorrect;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.CacheValidationListener.cleanUp",
	"Comment": "free memory by clearing unused resources after test execution.",
	"Method": "void cleanUp(ITestResult testResult){\r\n    Object[] params = testResult.getParameters();\r\n    for (int i = 0; i < params.length; i++) {\r\n        Object param = params[i];\r\n        if ((param instanceof AsyncLoadingCache<?, ?>) || (param instanceof Cache<?, ?>) || (param instanceof Map<?, ?>)) {\r\n            params[i] = param.getClass().getSimpleName();\r\n        } else {\r\n            params[i] = Objects.toString(param);\r\n        }\r\n    }\r\n    CacheSpec.interner.remove();\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMap8Test.testComputeIfPresent",
	"Comment": "computeifpresent does not replace if the key is already present",
	"Method": "void testComputeIfPresent(){\r\n    ConcurrentMap map = map5();\r\n    map.computeIfPresent(six, (x, y) -> \"Z\");\r\n    assertFalse(map.containsKey(six));\r\n}"
}, {
	"Path": "org.apache.commons.cli.AmbiguousOptionException.createMessage",
	"Comment": "build the exception message from the specified list of options.",
	"Method": "String createMessage(String option,Collection<String> matchingOptions){\r\n    StringBuilder buf = new StringBuilder(\"Ambiguous option: '\");\r\n    buf.append(option);\r\n    buf.append(\"'  (could be: \");\r\n    Iterator<String> it = matchingOptions.iterator();\r\n    while (it.hasNext()) {\r\n        buf.append(\"'\");\r\n        buf.append(it.next());\r\n        buf.append(\"'\");\r\n        if (it.hasNext()) {\r\n            buf.append(\", \");\r\n        }\r\n    }\r\n    buf.append(\")\");\r\n    return buf.toString();\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.client.BaseSpnegoKnownClientSystemsFilterAction.getRemoteHostName",
	"Comment": "convenience method to perform a reverse dns lookup. threads the requestthrough a custom runnable class in order to prevent inordinately longuser waits while performing reverse lookup.",
	"Method": "String getRemoteHostName(String remoteIp){\r\n    val revDNS = new ReverseDNSRunnable(remoteIp);\r\n    val t = new Thread(revDNS);\r\n    t.start();\r\n    try {\r\n        t.join(this.timeout);\r\n    } catch (final InterruptedException e) {\r\n        LOGGER.debug(\"Threaded lookup failed.  Defaulting to IP [{}].\", remoteIp, e);\r\n    }\r\n    val remoteHostName = revDNS.getHostName();\r\n    LOGGER.debug(\"Found remote host name [{}].\", remoteHostName);\r\n    return StringUtils.isNotBlank(remoteHostName) ? remoteHostName : remoteIp;\r\n}"
}, {
	"Path": "org.apereo.cas.util.CompressionUtils.compress",
	"Comment": "use zipoutputstream to zip text to byte array, then convertbyte array to base64 string, so it can be transferred via http request.",
	"Method": "String compress(String srcTxt){\r\n    try (val rstBao = new ByteArrayOutputStream();\r\n        val zos = new GZIPOutputStream(rstBao)) {\r\n        zos.write(srcTxt.getBytes(StandardCharsets.UTF_8));\r\n        zos.flush();\r\n        zos.finish();\r\n        val bytes = rstBao.toByteArray();\r\n        val base64 = StringUtils.remove(EncodingUtils.encodeBase64(bytes), '\\0');\r\n        return new String(StandardCharsets.UTF_8.encode(base64).array(), StandardCharsets.UTF_8);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.configuration.support.RelaxedPropertyNames.forCamelCase",
	"Comment": "return a relaxed name for the given source camelcase source name.",
	"Method": "RelaxedPropertyNames forCamelCase(String name){\r\n    final var result = new StringBuilder();\r\n    for (final var c : name.toCharArray()) {\r\n        result.append(Character.isUpperCase(c) && result.length() > 0 && result.charAt(result.length() - 1) != '-' ? \"-\" + Character.toLowerCase(c) : c);\r\n    }\r\n    return new RelaxedPropertyNames(result.toString());\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.misc.SingletonPredictor.saveToSerialized",
	"Comment": "saves the singleton predictor model to the given filename.if there is an error, a runtimeioexception is thrown.",
	"Method": "void saveToSerialized(LogisticClassifier<String, String> predictor,String filename){\r\n    try {\r\n        log.info(\"Writing singleton predictor in serialized format to file \" + filename + ' ');\r\n        ObjectOutputStream out = IOUtils.writeStreamFromString(filename);\r\n        out.writeObject(predictor);\r\n        out.close();\r\n        log.info(\"done.\");\r\n    } catch (IOException ioe) {\r\n        throw new RuntimeIOException(ioe);\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.AuthenticationPreProcessor.supports",
	"Comment": "determines whether the processor has the capability to perform tasks on the given credential.",
	"Method": "boolean supports(Credential credential){\r\n    return true;\r\n}"
}, {
	"Path": "org.apereo.cas.support.wsfederation.authentication.handler.support.WsFederationAuthenticationHandler.supports",
	"Comment": "determines if this handler can support the credentials provided.",
	"Method": "boolean supports(Credential credentials,boolean supports,Class<? extends Credential> clazz){\r\n    return WsFederationCredential.class.isAssignableFrom(clazz);\r\n}"
}, {
	"Path": "com.android.dx.rop.type.Type.getInitializedType",
	"Comment": "gets the initialized type corresponding to this instance, but onlyif this instance is in fact an uninitialized object type.",
	"Method": "Type getInitializedType(){\r\n    if (initializedType == null) {\r\n        throw new IllegalArgumentException(\"initialized type: \" + descriptor);\r\n    }\r\n    return initializedType;\r\n}"
}, {
	"Path": "org.apereo.cas.oidc.util.OidcAuthorizationRequestSupport.isCasAuthenticationOldForMaxAgeAuthorizationRequest",
	"Comment": "is cas authentication old for max age authorization request?",
	"Method": "boolean isCasAuthenticationOldForMaxAgeAuthorizationRequest(WebContext context,ZonedDateTime authenticationDate,boolean isCasAuthenticationOldForMaxAgeAuthorizationRequest,WebContext context,Authentication authentication,boolean isCasAuthenticationOldForMaxAgeAuthorizationRequest,WebContext context,boolean isCasAuthenticationOldForMaxAgeAuthorizationRequest,WebContext context,UserProfile profile){\r\n    val authTime = profile.getAttribute(CasProtocolConstants.VALIDATION_CAS_MODEL_ATTRIBUTE_NAME_AUTHENTICATION_DATE);\r\n    if (authTime == null) {\r\n        return false;\r\n    }\r\n    val dt = ZonedDateTime.parse(authTime.toString());\r\n    return isCasAuthenticationOldForMaxAgeAuthorizationRequest(context, dt);\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpecList.withFirst",
	"Comment": "returns a new instance, which is the same as this instance,except that it has an additional element prepended to the original.mutability of the result is inherited from the original.",
	"Method": "RegisterSpecList withFirst(RegisterSpec spec){\r\n    int sz = size();\r\n    RegisterSpecList result = new RegisterSpecList(sz + 1);\r\n    for (int i = 0; i < sz; i++) {\r\n        result.set0(i + 1, get0(i));\r\n    }\r\n    result.set0(0, spec);\r\n    if (isImmutable()) {\r\n        result.setImmutable();\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaBasicBlock.insertNewPredecessor",
	"Comment": "inserts a new empty goto block as a predecessor to this block.all previous predecessors will be predecessors to the new block.",
	"Method": "SsaBasicBlock insertNewPredecessor(){\r\n    SsaBasicBlock newPred = parent.makeNewGotoBlock();\r\n    newPred.predecessors = predecessors;\r\n    newPred.successors.set(index);\r\n    newPred.successorList.add(index);\r\n    newPred.primarySuccessor = index;\r\n    predecessors = new BitSet(parent.getBlocks().size());\r\n    predecessors.set(newPred.index);\r\n    for (int i = newPred.predecessors.nextSetBit(0); i >= 0; i = newPred.predecessors.nextSetBit(i + 1)) {\r\n        SsaBasicBlock predBlock = parent.getBlocks().get(i);\r\n        predBlock.replaceSuccessor(index, newPred.index);\r\n    }\r\n    return newPred;\r\n}"
}, {
	"Path": "com.android.dx.util.IntList.removeIndex",
	"Comment": "removes an element at a given index, shifting elements at greaterindicies down one.",
	"Method": "void removeIndex(int n){\r\n    if (n >= size) {\r\n        throw new IndexOutOfBoundsException(\"n >= size()\");\r\n    }\r\n    System.arraycopy(values, n + 1, values, n, size - n - 1);\r\n    size--;\r\n}"
}, {
	"Path": "org.apereo.cas.support.oauth.web.response.accesstoken.ext.AccessTokenAuthorizationCodeGrantRequestExtractor.getOAuthRegisteredServiceBy",
	"Comment": "gets oauth registered service from the request.implementation attempts to locate the redirect uri from request andcheck with service registry to find a matching oauth service.",
	"Method": "OAuthRegisteredService getOAuthRegisteredServiceBy(HttpServletRequest request){\r\n    val redirectUri = getRegisteredServiceIdentifierFromRequest(request);\r\n    val registeredService = OAuth20Utils.getRegisteredOAuthServiceByRedirectUri(this.servicesManager, redirectUri);\r\n    LOGGER.debug(\"Located registered service [{}]\", registeredService);\r\n    return registeredService;\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.ifICmp",
	"Comment": "generates the instructions to jump to a label based on the comparison ofthe top two integer stack values.",
	"Method": "void ifICmp(int mode,Label label){\r\n    ifCmp(Type.INT_TYPE, mode, label);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.RemovalListeners.rejecting",
	"Comment": "a removal listener that throws an exception if a notification arrives.",
	"Method": "RemovalListener<K, V> rejecting(){\r\n    return new RejectingRemovalListener();\r\n}"
}, {
	"Path": "com.android.dx.rop.annotation.AnnotationsList.set",
	"Comment": "sets the element at the given index. the given element must beimmutable.",
	"Method": "void set(int n,Annotations a){\r\n    a.throwIfMutable();\r\n    set0(n, a);\r\n}"
}, {
	"Path": "com.android.dx.ssa.DomFront.run",
	"Comment": "calculates the dominance frontier information for the method.",
	"Method": "DomInfo[] run(){\r\n    int szNodes = nodes.size();\r\n    if (DEBUG) {\r\n        for (int i = 0; i < szNodes; i++) {\r\n            SsaBasicBlock node = nodes.get(i);\r\n            System.out.println(\"pred[\" + i + \"]: \" + node.getPredecessors());\r\n        }\r\n    }\r\n    Dominators methDom = Dominators.make(meth, domInfos, false);\r\n    if (DEBUG) {\r\n        for (int i = 0; i < szNodes; i++) {\r\n            DomInfo info = domInfos[i];\r\n            System.out.println(\"idom[\" + i + \"]: \" + info.idom);\r\n        }\r\n    }\r\n    buildDomTree();\r\n    if (DEBUG) {\r\n        debugPrintDomChildren();\r\n    }\r\n    for (int i = 0; i < szNodes; i++) {\r\n        domInfos[i].dominanceFrontiers = SetFactory.makeDomFrontSet(szNodes);\r\n    }\r\n    calcDomFronts();\r\n    if (DEBUG) {\r\n        for (int i = 0; i < szNodes; i++) {\r\n            System.out.println(\"df[\" + i + \"]: \" + domInfos[i].dominanceFrontiers);\r\n        }\r\n    }\r\n    return domInfos;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.BasicBlockList.getInstructionCount",
	"Comment": "gets the total instruction count for this instance. this is thesum of the instruction counts of each block.",
	"Method": "int getInstructionCount(){\r\n    int sz = size();\r\n    int result = 0;\r\n    for (int i = 0; i < sz; i++) {\r\n        BasicBlock one = (BasicBlock) getOrNull0(i);\r\n        if (one != null) {\r\n            result += one.getInsns().size();\r\n        }\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.segment.RandomWindowTinyLfuPolicy.removeFromTable",
	"Comment": "removes the node from the table and adds the index to the free list.",
	"Method": "void removeFromTable(Node[] table,Node node){\r\n    int last = table.length - 1;\r\n    table[node.index] = table[last];\r\n    table[node.index].index = node.index;\r\n    table[last] = null;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.common.DomReader.getChildByNameAndAttribute",
	"Comment": "searches for children that have the given name and attribute",
	"Method": "Node getChildByNameAndAttribute(Node node,String name,String attributeName,String attributeValue){\r\n    NodeList children = node.getChildNodes();\r\n    NamedNodeMap attribs = node.getAttributes();\r\n    Node attribute = null;\r\n    if (node.getNodeName().equals(name) && attribs != null && (attribute = attribs.getNamedItem(attributeName)) != null && attribute.getNodeValue().equals(attributeValue))\r\n        return node;\r\n    for (int i = 0; i < children.getLength(); i++) {\r\n        Node found = getChildByAttribute(children.item(i), attributeName, attributeValue);\r\n        if (found != null)\r\n            return found;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.product.OhcPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    OhcSettings settings = new OhcSettings(config);\r\n    return settings.policy().stream().map(policy -> new OhcPolicy(settings, policy)).collect(toSet());\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.misc.SingletonPredictor.train",
	"Comment": "train the singleton predictor using a logistic regression classifier.",
	"Method": "LogisticClassifier<String, String> train(GeneralDataset<String, String> pDataset){\r\n    LogisticClassifierFactory<String, String> lcf = new LogisticClassifierFactory();\r\n    LogisticClassifier<String, String> classifier = lcf.trainClassifier(pDataset);\r\n    return classifier;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.RVFDataset.summaryStatistics",
	"Comment": "prints some summary statistics to the logger for the dataset.",
	"Method": "void summaryStatistics(){\r\n    logger.info(\"numDatums: \" + size);\r\n    StringBuilder sb = new StringBuilder(\"numLabels: \");\r\n    sb.append(labelIndex.size()).append(\" [\");\r\n    Iterator<L> iter = labelIndex.iterator();\r\n    while (iter.hasNext()) {\r\n        sb.append(iter.next());\r\n        if (iter.hasNext()) {\r\n            sb.append(\", \");\r\n        }\r\n    }\r\n    sb.append(']');\r\n    logger.info(sb.toString());\r\n    logger.info(\"numFeatures (Phi(X) types): \" + featureIndex.size());\r\n}"
}, {
	"Path": "edu.stanford.nlp.coref.CorefRules.entityTokenDistance",
	"Comment": "return true if the two mentions are less than n mentions apart in the same sent",
	"Method": "boolean entityTokenDistance(Mention m1,Mention m2){\r\n    if ((m2.sentNum == m1.sentNum) && (m1.startIndex - m2.startIndex < 6))\r\n        return true;\r\n    return false;\r\n}"
}, {
	"Path": "org.apereo.cas.services.OidcRegisteredService.setDynamicallyRegistered",
	"Comment": "indicates the service was dynamically registered.records the registration time automatically.",
	"Method": "void setDynamicallyRegistered(boolean dynamicallyRegistered){\r\n    if (dynamicallyRegistered && !this.dynamicallyRegistered && dynamicRegistrationDateTime == null) {\r\n        setDynamicRegistrationDateTime(ZonedDateTime.now());\r\n    }\r\n    this.dynamicallyRegistered = dynamicallyRegistered;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.GenericDataSetReader.findTreeWithSpan",
	"Comment": "finds the tree with the given token span.the tree must have corelabel labels and tree.indexspans must be called before this method.",
	"Method": "Tree findTreeWithSpan(Tree tree,int start,int end){\r\n    CoreLabel l = (CoreLabel) tree.label();\r\n    if (l != null && l.containsKey(CoreAnnotations.BeginIndexAnnotation.class) && l.containsKey(CoreAnnotations.EndIndexAnnotation.class)) {\r\n        int myStart = l.get(CoreAnnotations.BeginIndexAnnotation.class);\r\n        int myEnd = l.get(CoreAnnotations.EndIndexAnnotation.class);\r\n        if (start == myStart && end == myEnd) {\r\n            return tree;\r\n        } else if (end < myStart) {\r\n            return null;\r\n        } else if (start >= myEnd) {\r\n            return null;\r\n        }\r\n    }\r\n    for (Tree kid : tree.children()) {\r\n        if (kid == null)\r\n            continue;\r\n        Tree ret = findTreeWithSpan(kid, start, end);\r\n        if (ret != null)\r\n            return ret;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpecList.withoutLast",
	"Comment": "returns a new instance, which is the same as this instance,except that its last element is removed. mutability of theresult is inherited from the original.",
	"Method": "RegisterSpecList withoutLast(){\r\n    int newSize = size() - 1;\r\n    if (newSize == 0) {\r\n        return EMPTY;\r\n    }\r\n    RegisterSpecList result = new RegisterSpecList(newSize);\r\n    for (int i = 0; i < newSize; i++) {\r\n        result.set0(i, get0(i));\r\n    }\r\n    if (isImmutable()) {\r\n        result.setImmutable();\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.DefaultAuthenticationTransaction.hasCredentialOfType",
	"Comment": "does this authenticationtransaction contain a credential of the given type?",
	"Method": "boolean hasCredentialOfType(Class<? extends Credential> type){\r\n    return credentials.stream().anyMatch(type::isInstance);\r\n}"
}, {
	"Path": "com.android.dx.util.ByteArray.checkOffsets",
	"Comment": "checks a range of offsets for validity, throwing if invalid.",
	"Method": "void checkOffsets(int s,int e){\r\n    if ((s < 0) || (e < s) || (e > size)) {\r\n        throw new IllegalArgumentException(\"bad range: \" + s + \"..\" + e + \"; actual size \" + size);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.event.EventDispatcher.ignoreSynchronous",
	"Comment": "ignores and clears the queued futures to the synchronous listeners that are processing eventsthis thread published.",
	"Method": "void ignoreSynchronous(){\r\n    pending.get().clear();\r\n}"
}, {
	"Path": "org.objectweb.asm.ByteVector.putUTF8",
	"Comment": "puts an utf8 string into this byte vector. the byte vector isautomatically enlarged if necessary.",
	"Method": "ByteVector putUTF8(String s){\r\n    int charLength = s.length();\r\n    if (charLength > 65535) {\r\n        throw new IllegalArgumentException();\r\n    }\r\n    int len = length;\r\n    if (len + 2 + charLength > data.length) {\r\n        enlarge(2 + charLength);\r\n    }\r\n    byte[] data = this.data;\r\n    data[len++] = (byte) (charLength >>> 8);\r\n    data[len++] = (byte) charLength;\r\n    for (int i = 0; i < charLength; ++i) {\r\n        char c = s.charAt(i);\r\n        if (c >= '\\001' && c <= '\\177') {\r\n            data[len++] = (byte) c;\r\n        } else {\r\n            length = len;\r\n            return encodeUTF8(s, i, 65535);\r\n        }\r\n    }\r\n    length = len;\r\n    return this;\r\n}"
}, {
	"Path": "org.apache.commons.codec.Charsets.toCharset",
	"Comment": "returns a charset for the named charset. if the name is null, return the default charset.",
	"Method": "Charset toCharset(Charset charset,Charset toCharset,String charset){\r\n    return charset == null ? Charset.defaultCharset() : Charset.forName(charset);\r\n}"
}, {
	"Path": "org.apache.commons.cli.OptionBuilder.create",
	"Comment": "create an option using the current settings and withthe specified option char.",
	"Method": "Option create(char opt,Option create,Option create,String opt){\r\n    Option option = null;\r\n    try {\r\n        option = new Option(opt, description);\r\n        option.setLongOpt(longopt);\r\n        option.setRequired(required);\r\n        option.setOptionalArg(optionalArg);\r\n        option.setArgs(numberOfArgs);\r\n        option.setType(type);\r\n        option.setValueSeparator(valuesep);\r\n        option.setArgName(argName);\r\n    } finally {\r\n        OptionBuilder.reset();\r\n    }\r\n    return option;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.copy.AbstractCopier.roundtrip",
	"Comment": "performs the serialization and deserialization, returning the copied object.",
	"Method": "T roundtrip(T object,ClassLoader classLoader){\r\n    A data = serialize(object);\r\n    @SuppressWarnings(\"unchecked\")\r\n    T copy = (T) deserialize(data, classLoader);\r\n    return copy;\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassVisitor.visitInnerClass",
	"Comment": "visits information about an inner class. this inner class is notnecessarily a member of the class being visited.",
	"Method": "void visitInnerClass(String name,String outerName,String innerName,int access){\r\n    if (cv != null) {\r\n        cv.visitInnerClass(name, outerName, innerName, access);\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.cli.CommandLine.resolveOption",
	"Comment": "retrieves the option object given the long or short option as a string",
	"Method": "Option resolveOption(String opt){\r\n    opt = Util.stripLeadingHyphens(opt);\r\n    for (Option option : options) {\r\n        if (opt.equals(option.getOpt())) {\r\n            return option;\r\n        }\r\n        if (opt.equals(option.getLongOpt())) {\r\n            return option;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.FirstFitLocalCombiningAllocator.handlePhiInsns",
	"Comment": "handles all phi instructions, trying to map them to a common register.",
	"Method": "void handlePhiInsns(){\r\n    for (PhiInsn insn : phiInsns) {\r\n        processPhiInsn(insn);\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.FirstFitLocalCombiningAllocator.getLocalItemForReg",
	"Comment": "gets a local item associated with an ssa register, if one exists.",
	"Method": "LocalItem getLocalItemForReg(int ssaReg){\r\n    for (Map.Entry<LocalItem, ArrayList<RegisterSpec>> entry : localVariables.entrySet()) {\r\n        for (RegisterSpec spec : entry.getValue()) {\r\n            if (spec.getReg() == ssaReg) {\r\n                return entry.getKey();\r\n            }\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "org.apache.commons.cli.HelpFormatter.setOptionComparator",
	"Comment": "set the comparator used to sort the options when they output in help text.passing in a null comparator will keep the options in the order they were declared.",
	"Method": "void setOptionComparator(Comparator<Option> comparator){\r\n    this.optionComparator = comparator;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.Synthetic.skewedZipfianLatest",
	"Comment": "returns a zipfian sequence with a popularity distribution of items, skewed to favor recentitems significantly more than older items",
	"Method": "LongStream skewedZipfianLatest(int items,int events){\r\n    return generate(new SkewedLatestGenerator(new CounterGenerator(items)), events);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.ClassifierCombiner.getClassifier",
	"Comment": "static method for getting a classifiercombiner from objectinputstream",
	"Method": "ClassifierCombiner getClassifier(String loadPath,Properties props,ClassifierCombiner getClassifier,ObjectInputStream ois,Properties props){\r\n    return new ClassifierCombiner(ois, props);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.adaptive.CartPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new CartPolicy(config));\r\n}"
}, {
	"Path": "jd.cli.util.ClassFileUtil.ExtractDirectoryPath",
	"Comment": "lecture rapide de la structure de la classe et extraction du nom durepoertoire de base.",
	"Method": "String ExtractDirectoryPath(String pathToClass){\r\n    DataInputStream dis = null;\r\n    String directoryPath = null;\r\n    try {\r\n        dis = new DataInputStream(new BufferedInputStream(new FileInputStream(pathToClass)));\r\n        int magic = dis.readInt();\r\n        if (magic != CoreConstants.JAVA_MAGIC_NUMBER)\r\n            throw new ClassFormatException(\"Invalid Java .class file\");\r\n        dis.readUnsignedShort();\r\n        dis.readUnsignedShort();\r\n        Constant[] constants = DeserializeConstants(dis);\r\n        dis.readUnsignedShort();\r\n        int this_class = dis.readUnsignedShort();\r\n        Constant c = constants[this_class];\r\n        if ((c == null) || (c.tag != ConstantConstant.CONSTANT_Class))\r\n            throw new ClassFormatException(\"Invalid contant pool\");\r\n        c = constants[((ConstantClass) c).name_index];\r\n        if ((c == null) || (c.tag != ConstantConstant.CONSTANT_Utf8))\r\n            throw new ClassFormatException(\"Invalid contant pool\");\r\n        String internalClassName = ((ConstantUtf8) c).bytes;\r\n        String pathSuffix = internalClassName.replace(StringConstants.INTERNAL_PACKAGE_SEPARATOR, File.separatorChar) + StringConstants.CLASS_FILE_SUFFIX;\r\n        int index = pathToClass.indexOf(pathSuffix);\r\n        if (index < 0)\r\n            throw new ClassFormatException(\"Invalid internal class name\");\r\n        directoryPath = pathToClass.substring(0, index);\r\n    } catch (FileNotFoundException e) {\r\n        directoryPath = null;\r\n        e.printStackTrace();\r\n    } catch (IOException e) {\r\n        directoryPath = null;\r\n        e.printStackTrace();\r\n    } finally {\r\n        if (dis != null)\r\n            try {\r\n                dis.close();\r\n            } catch (IOException e) {\r\n            }\r\n    }\r\n    return directoryPath;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.documentsToDataAndLabels",
	"Comment": "convert an objectbank to arrays of data features and labels.this version is used at training time.",
	"Method": "Triple<int[][][][], int[][], double[][][][]> documentsToDataAndLabels(Collection<List<IN>> documents){\r\n    List<int[][][]> data = new ArrayList();\r\n    List<double[][][]> featureVal = new ArrayList();\r\n    List<int[]> labels = new ArrayList();\r\n    int numDatums = 0;\r\n    for (List<IN> doc : documents) {\r\n        Triple<int[][][], int[], double[][][]> docTriple = documentToDataAndLabels(doc);\r\n        data.add(docTriple.first());\r\n        labels.add(docTriple.second());\r\n        if (flags.useEmbedding)\r\n            featureVal.add(docTriple.third());\r\n        numDatums += doc.size();\r\n    }\r\n    log.info(\"numClasses: \" + classIndex.size() + ' ' + classIndex);\r\n    log.info(\"numDocuments: \" + data.size());\r\n    log.info(\"numDatums: \" + numDatums);\r\n    log.info(\"numFeatures: \" + featureIndex.size());\r\n    printFeatures();\r\n    double[][][][] featureValArr = null;\r\n    if (flags.useEmbedding)\r\n        featureValArr = featureVal.toArray(new double[data.size()][][][]);\r\n    return new Triple(data.toArray(new int[data.size()][][][]), labels.toArray(new int[labels.size()][]), featureValArr);\r\n}"
}, {
	"Path": "org.apache.commons.cli.MissingOptionException.getMissingOptions",
	"Comment": "returns the list of options or option groups missing in the command line parsed.",
	"Method": "List getMissingOptions(){\r\n    return missingOptions;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.expiresVariable",
	"Comment": "returns if the cache expires entries after a variable time threshold.",
	"Method": "boolean expiresVariable(){\r\n    return false;\r\n}"
}, {
	"Path": "com.facebook.buck.tools.documentation.generator.skylark.rendering.SoyTemplateSkylarkSignatureRenderer.render",
	"Comment": "renders provided skylark signature into a soy template content similar to manually writtentemplates for all python dsl functions.",
	"Method": "String render(SkylarkCallable skylarkSignature){\r\n    ST stringTemplate = createTemplate(FUNCTION_TEMPLATE_NAME);\r\n    stringTemplate.add(\"openCurly\", \"{\");\r\n    stringTemplate.add(\"closeCurly\", \"}\");\r\n    stringTemplate.add(\"signature\", toMap(skylarkSignature));\r\n    return stringTemplate.render();\r\n}"
}, {
	"Path": "com.android.dx.merge.DexMergeTest.testMergedOutputSizeIsBounded",
	"Comment": "merging dex files uses pessimistic sizes that naturally leave gaps in theoutput files. if those gaps grow too large, the merger is supposed tocompact the result. this exercises that by repeatedly merging a dex withitself.",
	"Method": "void testMergedOutputSizeIsBounded(){\r\n    int steps = 100;\r\n    int compactWasteThreshold = 1024;\r\n    Dex dexA = resourceToDexBuffer(\"/testdata/Basic.dex\");\r\n    Dex dexB = resourceToDexBuffer(\"/testdata/TryCatchFinally.dex\");\r\n    Dex merged = new DexMerger(dexA, dexB, CollisionPolicy.KEEP_FIRST).merge();\r\n    int maxLength = 0;\r\n    for (int i = 0; i < steps; i++) {\r\n        DexMerger dexMerger = new DexMerger(dexA, merged, CollisionPolicy.KEEP_FIRST);\r\n        dexMerger.setCompactWasteThreshold(compactWasteThreshold);\r\n        merged = dexMerger.merge();\r\n        maxLength = Math.max(maxLength, merged.getLength());\r\n    }\r\n    int maxExpectedLength = dexA.getLength() + dexB.getLength() + compactWasteThreshold;\r\n    assertTrue(maxLength + \" < \" + maxExpectedLength, maxLength < maxExpectedLength);\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getMethodDescriptor",
	"Comment": "returns the descriptor corresponding to the given argument and returntypes.",
	"Method": "String getMethodDescriptor(Type returnType,Type argumentTypes,String getMethodDescriptor,Method m){\r\n    Class<?>[] parameters = m.getParameterTypes();\r\n    StringBuffer buf = new StringBuffer();\r\n    buf.append('(');\r\n    for (int i = 0; i < parameters.length; ++i) {\r\n        getDescriptor(buf, parameters[i]);\r\n    }\r\n    buf.append(')');\r\n    getDescriptor(buf, m.getReturnType());\r\n    return buf.toString();\r\n}"
}, {
	"Path": "org.apereo.cas.ticket.registry.MemcachedTicketRegistry.getTimeout",
	"Comment": "if not time out value is specified, expire the ticket immediately.",
	"Method": "int getTimeout(Ticket ticket){\r\n    val ttl = ticket.getExpirationPolicy().getTimeToLive().intValue();\r\n    if (ttl == 0) {\r\n        return 1;\r\n    }\r\n    return ttl;\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.InterferenceGraph.ensureCapacity",
	"Comment": "ensures that the interference graph is appropriately sized.",
	"Method": "void ensureCapacity(int size){\r\n    int countRegs = interference.size();\r\n    interference.ensureCapacity(size);\r\n    for (int i = countRegs; i < size; i++) {\r\n        interference.add(SetFactory.makeInterferenceSet(size));\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LogConditionalObjectiveFunction.calculateSCL",
	"Comment": "calculate the summed conditional likelihood of this data by summingconditional estimates.",
	"Method": "void calculateSCL(double[] x){\r\n    value = 0.0;\r\n    Arrays.fill(derivative, 0.0);\r\n    double[] sums = new double[numClasses];\r\n    double[] probs = new double[numClasses];\r\n    for (int d = 0; d < data.length; d++) {\r\n        int[] features = data[d];\r\n        Arrays.fill(sums, 0.0);\r\n        for (int c = 0; c < numClasses; c++) {\r\n            for (int feature : features) {\r\n                int i = indexOf(feature, c);\r\n                sums[c] += x[i];\r\n            }\r\n        }\r\n        double total = ArrayMath.logSum(sums);\r\n        int ld = labels[d];\r\n        for (int c = 0; c < numClasses; c++) {\r\n            probs[c] = Math.exp(sums[c] - total);\r\n            for (int feature : features) {\r\n                int i = indexOf(feature, c);\r\n                derivative[i] += probs[ld] * probs[c];\r\n            }\r\n        }\r\n        for (int feature : features) {\r\n            int i = indexOf(feature, labels[d]);\r\n            derivative[i] -= probs[ld];\r\n        }\r\n        value -= probs[ld];\r\n    }\r\n    if (true) {\r\n        for (int i = 0; i < x.length; i++) {\r\n            double k = 1.0;\r\n            double w = x[i];\r\n            value += k * w * w / 2.0;\r\n            derivative[i] += k * w;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaBasicBlock.replaceLastInsn",
	"Comment": "replaces the last insn in this block. the provided insn must havesome branchingness.",
	"Method": "void replaceLastInsn(Insn insn){\r\n    if (insn.getOpcode().getBranchingness() == Rop.BRANCH_NONE) {\r\n        throw new IllegalArgumentException(\"last insn must branch\");\r\n    }\r\n    SsaInsn oldInsn = insns.get(insns.size() - 1);\r\n    SsaInsn newInsn = SsaInsn.makeFromRop(insn, this);\r\n    insns.set(insns.size() - 1, newInsn);\r\n    parent.onInsnRemoved(oldInsn);\r\n    parent.onInsnAdded(newInsn);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.event.EventDispatcher.publishExpired",
	"Comment": "publishes a expire event for the entry to all of the interested listeners.",
	"Method": "void publishExpired(Cache<K, V> cache,K key,V value){\r\n    publish(cache, EventType.EXPIRED, key, value, null, false);\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.ifCmp",
	"Comment": "generates the instructions to jump to a label based on the comparison ofthe top two stack values.",
	"Method": "void ifCmp(Type type,int mode,Label label){\r\n    switch(type.getSort()) {\r\n        case Type.LONG:\r\n            mv.visitInsn(Opcodes.LCMP);\r\n            break;\r\n        case Type.DOUBLE:\r\n            mv.visitInsn(mode == GE || mode == GT ? Opcodes.DCMPL : Opcodes.DCMPG);\r\n            break;\r\n        case Type.FLOAT:\r\n            mv.visitInsn(mode == GE || mode == GT ? Opcodes.FCMPL : Opcodes.FCMPG);\r\n            break;\r\n        case Type.ARRAY:\r\n        case Type.OBJECT:\r\n            switch(mode) {\r\n                case EQ:\r\n                    mv.visitJumpInsn(Opcodes.IF_ACMPEQ, label);\r\n                    return;\r\n                case NE:\r\n                    mv.visitJumpInsn(Opcodes.IF_ACMPNE, label);\r\n                    return;\r\n            }\r\n            throw new IllegalArgumentException(\"Bad comparison for type \" + type);\r\n        default:\r\n            int intOp = -1;\r\n            switch(mode) {\r\n                case EQ:\r\n                    intOp = Opcodes.IF_ICMPEQ;\r\n                    break;\r\n                case NE:\r\n                    intOp = Opcodes.IF_ICMPNE;\r\n                    break;\r\n                case GE:\r\n                    intOp = Opcodes.IF_ICMPGE;\r\n                    break;\r\n                case LT:\r\n                    intOp = Opcodes.IF_ICMPLT;\r\n                    break;\r\n                case LE:\r\n                    intOp = Opcodes.IF_ICMPLE;\r\n                    break;\r\n                case GT:\r\n                    intOp = Opcodes.IF_ICMPGT;\r\n                    break;\r\n            }\r\n            mv.visitJumpInsn(intOp, label);\r\n            return;\r\n    }\r\n    mv.visitJumpInsn(mode, label);\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.arrayLength",
	"Comment": "generates the instruction to compute the length of an array.",
	"Method": "void arrayLength(){\r\n    mv.visitInsn(Opcodes.ARRAYLENGTH);\r\n}"
}, {
	"Path": "edu.stanford.nlp.parser.lexparser.LexicalizedParserITest.compareSingleOutput",
	"Comment": "compares one view of the result tree to the expected results.setting outputresults to true makes it print out the results.this is useful because assertequals sometimes abbreviates thestrings on failure, which makes it hard to diagnose.",
	"Method": "void compareSingleOutput(Tree results,boolean outputResults,TreePrint printer,String expectedOutput){\r\n    StringWriter sw = new StringWriter();\r\n    printer.printTree(results, (new PrintWriter(sw)));\r\n    if (expectedOutput != null) {\r\n        expectedOutput = expectedOutput.replaceAll(\"\\\\s+\", \" \").trim();\r\n    }\r\n    String actualOutput = sw.toString().replaceAll(\"\\\\s+\", \" \").trim();\r\n    if (outputResults) {\r\n        if (expectedOutput != null) {\r\n            System.out.println(expectedOutput);\r\n        }\r\n        System.out.println(actualOutput);\r\n    }\r\n    if (expectedOutput != null) {\r\n        assertEquals(expectedOutput, actualOutput);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFNonLinearSecondOrderLogConditionalObjectiveFunction.calculate",
	"Comment": "calculates both value and partial derivatives at the point x, and save them internally.",
	"Method": "void calculate(double[] x){\r\n    double prob = 0.0;\r\n    Quadruple<double[][], double[][], double[][], double[][]> allParams = separateWeights(x);\r\n    double[][] W4Edge = allParams.first();\r\n    double[][] U4Edge = allParams.second();\r\n    double[][] W = allParams.third();\r\n    double[][] U = allParams.fourth();\r\n    double[][] Y4Edge = null;\r\n    double[][] Y = null;\r\n    if (flags.softmaxOutputLayer) {\r\n        Y4Edge = new double[U4Edge.length][];\r\n        for (int i = 0; i < U4Edge.length; i++) {\r\n            Y4Edge[i] = ArrayMath.softmax(U4Edge[i]);\r\n        }\r\n        Y = new double[U.length][];\r\n        for (int i = 0; i < U.length; i++) {\r\n            Y[i] = ArrayMath.softmax(U[i]);\r\n        }\r\n    }\r\n    double[][] What4Edge = emptyW4Edge();\r\n    double[][] Uhat4Edge = emptyU4Edge();\r\n    double[][] What = emptyW();\r\n    double[][] Uhat = emptyU();\r\n    double[][] eW4Edge = emptyW4Edge();\r\n    double[][] eU4Edge = emptyU4Edge();\r\n    double[][] eW = emptyW();\r\n    double[][] eU = emptyU();\r\n    for (int m = 0; m < data.length; m++) {\r\n        int[][][] docData = data[m];\r\n        int[] docLabels = labels[m];\r\n        NonLinearSecondOrderCliquePotentialFunction cliquePotentialFunction = new NonLinearSecondOrderCliquePotentialFunction(W4Edge, U4Edge, W, U, flags);\r\n        CRFCliqueTree<String> cliqueTree = CRFCliqueTree.getCalibratedCliqueTree(docData, labelIndices, numClasses, classIndex, backgroundSymbol, cliquePotentialFunction, null);\r\n        int[] given = new int[window - 1];\r\n        Arrays.fill(given, classIndex.indexOf(backgroundSymbol));\r\n        int[] windowLabels = new int[window];\r\n        Arrays.fill(windowLabels, classIndex.indexOf(backgroundSymbol));\r\n        if (docLabels.length > docData.length) {\r\n            System.arraycopy(docLabels, 0, given, 0, given.length);\r\n            System.arraycopy(docLabels, 0, windowLabels, 0, windowLabels.length);\r\n            int[] newDocLabels = new int[docData.length];\r\n            System.arraycopy(docLabels, docLabels.length - newDocLabels.length, newDocLabels, 0, newDocLabels.length);\r\n            docLabels = newDocLabels;\r\n        }\r\n        for (int i = 0; i < docData.length; i++) {\r\n            int label = docLabels[i];\r\n            double p = cliqueTree.condLogProbGivenPrevious(i, label, given);\r\n            if (VERBOSE) {\r\n                log.info(\"P(\" + label + \"|\" + ArrayMath.toString(given) + \")=\" + p);\r\n            }\r\n            prob += p;\r\n            System.arraycopy(given, 1, given, 0, given.length - 1);\r\n            given[given.length - 1] = label;\r\n        }\r\n        for (int i = 0; i < docData.length; i++) {\r\n            System.arraycopy(windowLabels, 1, windowLabels, 0, window - 1);\r\n            windowLabels[window - 1] = docLabels[i];\r\n            for (int j = 0; j < docData[i].length; j++) {\r\n                Index<CRFLabel> labelIndex = labelIndices.get(j);\r\n                int[] cliqueFeatures = docData[i][j];\r\n                double[] As = null;\r\n                double[] fDeriv = null;\r\n                double[][] yTimesA = null;\r\n                double[] sumOfYTimesA = null;\r\n                int inputSize, outputSize = -1;\r\n                if (j == 0) {\r\n                    inputSize = inputLayerSize;\r\n                    outputSize = outputLayerSize;\r\n                    As = cliquePotentialFunction.hiddenLayerOutput(W, cliqueFeatures, flags, null, j + 1);\r\n                } else {\r\n                    inputSize = inputLayerSize4Edge;\r\n                    outputSize = outputLayerSize4Edge;\r\n                    As = cliquePotentialFunction.hiddenLayerOutput(W4Edge, cliqueFeatures, flags, null, j + 1);\r\n                }\r\n                fDeriv = new double[inputSize];\r\n                double fD = 0;\r\n                for (int q = 0; q < inputSize; q++) {\r\n                    if (useSigmoid) {\r\n                        fD = As[q] * (1 - As[q]);\r\n                    } else {\r\n                        fD = 1 - As[q] * As[q];\r\n                    }\r\n                    fDeriv[q] = fD;\r\n                }\r\n                if (flags.softmaxOutputLayer) {\r\n                    double val = 0;\r\n                    yTimesA = new double[outputSize][numHiddenUnits];\r\n                    for (int ii = 0; ii < outputSize; ii++) {\r\n                        yTimesA[ii] = new double[numHiddenUnits];\r\n                    }\r\n                    sumOfYTimesA = new double[outputSize];\r\n                    for (int k = 0; k < outputSize; k++) {\r\n                        double[] Yk = null;\r\n                        if (flags.tieOutputLayer) {\r\n                            if (j == 0) {\r\n                                Yk = Y[0];\r\n                            } else {\r\n                                Yk = Y4Edge[0];\r\n                            }\r\n                        } else {\r\n                            if (j == 0) {\r\n                                Yk = Y[k];\r\n                            } else {\r\n                                Yk = Y4Edge[k];\r\n                            }\r\n                        }\r\n                        double sum = 0;\r\n                        for (int q = 0; q < inputSize; q++) {\r\n                            if (q % outputSize == k) {\r\n                                int hiddenUnitNo = q / outputSize;\r\n                                val = As[q] * Yk[hiddenUnitNo];\r\n                                yTimesA[k][hiddenUnitNo] = val;\r\n                                sum += val;\r\n                            }\r\n                        }\r\n                        sumOfYTimesA[k] = sum;\r\n                    }\r\n                }\r\n                int[] cliqueLabel = new int[j + 1];\r\n                System.arraycopy(windowLabels, window - 1 - j, cliqueLabel, 0, j + 1);\r\n                CRFLabel crfLabel = new CRFLabel(cliqueLabel);\r\n                int givenLabelIndex = labelIndex.indexOf(crfLabel);\r\n                double[] Uk = null;\r\n                double[] UhatK = null;\r\n                double[] Yk = null;\r\n                double[] yTimesAK = null;\r\n                double sumOfYTimesAK = 0;\r\n                if (flags.tieOutputLayer) {\r\n                    if (j == 0) {\r\n                        Uk = U[0];\r\n                        UhatK = Uhat[0];\r\n                    } else {\r\n                        Uk = U4Edge[0];\r\n                        UhatK = Uhat4Edge[0];\r\n                    }\r\n                    if (flags.softmaxOutputLayer) {\r\n                        if (j == 0) {\r\n                            Yk = Y[0];\r\n                        } else {\r\n                            Yk = Y4Edge[0];\r\n                        }\r\n                    }\r\n                } else {\r\n                    if (j == 0) {\r\n                        Uk = U[givenLabelIndex];\r\n                        UhatK = Uhat[givenLabelIndex];\r\n                    } else {\r\n                        Uk = U4Edge[givenLabelIndex];\r\n                        UhatK = Uhat4Edge[givenLabelIndex];\r\n                    }\r\n                    if (flags.softmaxOutputLayer) {\r\n                        if (j == 0) {\r\n                            Yk = Y[givenLabelIndex];\r\n                        } else {\r\n                            Yk = Y4Edge[givenLabelIndex];\r\n                        }\r\n                    }\r\n                }\r\n                if (flags.softmaxOutputLayer) {\r\n                    yTimesAK = yTimesA[givenLabelIndex];\r\n                    sumOfYTimesAK = sumOfYTimesA[givenLabelIndex];\r\n                }\r\n                for (int k = 0; k < inputSize; k++) {\r\n                    double deltaK = 1;\r\n                    if (flags.sparseOutputLayer || flags.tieOutputLayer) {\r\n                        if (k % outputSize == givenLabelIndex) {\r\n                            int hiddenUnitNo = k / outputSize;\r\n                            if (flags.softmaxOutputLayer) {\r\n                                UhatK[hiddenUnitNo] += (yTimesAK[hiddenUnitNo] - Yk[hiddenUnitNo] * sumOfYTimesAK);\r\n                                deltaK *= Yk[hiddenUnitNo];\r\n                            } else {\r\n                                UhatK[hiddenUnitNo] += As[k];\r\n                                deltaK *= Uk[hiddenUnitNo];\r\n                            }\r\n                        }\r\n                    } else {\r\n                        UhatK[k] += As[k];\r\n                        if (useOutputLayer) {\r\n                            deltaK *= Uk[k];\r\n                        }\r\n                    }\r\n                    if (useHiddenLayer)\r\n                        deltaK *= fDeriv[k];\r\n                    if (useOutputLayer) {\r\n                        if (flags.sparseOutputLayer || flags.tieOutputLayer) {\r\n                            if (k % outputSize == givenLabelIndex) {\r\n                                double[] WhatK = null;\r\n                                if (j == 0) {\r\n                                    WhatK = What[k];\r\n                                } else {\r\n                                    WhatK = What4Edge[k];\r\n                                }\r\n                                for (int cliqueFeature : cliqueFeatures) {\r\n                                    WhatK[cliqueFeature] += deltaK;\r\n                                }\r\n                            }\r\n                        } else {\r\n                            double[] WhatK = null;\r\n                            if (j == 0) {\r\n                                WhatK = What[k];\r\n                            } else {\r\n                                WhatK = What4Edge[k];\r\n                            }\r\n                            for (int cliqueFeature : cliqueFeatures) {\r\n                                WhatK[cliqueFeature] += deltaK;\r\n                            }\r\n                        }\r\n                    } else {\r\n                        if (k == givenLabelIndex) {\r\n                            double[] WhatK = null;\r\n                            if (j == 0) {\r\n                                WhatK = What[k];\r\n                            } else {\r\n                                WhatK = What4Edge[k];\r\n                            }\r\n                            for (int cliqueFeature : cliqueFeatures) {\r\n                                WhatK[cliqueFeature] += deltaK;\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n                for (int k = 0; k < labelIndex.size(); k++) {\r\n                    int[] label = labelIndex.get(k).getLabel();\r\n                    double p = cliqueTree.prob(i, label);\r\n                    double[] Uk2 = null;\r\n                    double[] eUK = null;\r\n                    double[] Yk2 = null;\r\n                    if (flags.tieOutputLayer) {\r\n                        if (j == 0) {\r\n                            Uk2 = U[0];\r\n                            eUK = eU[0];\r\n                        } else {\r\n                            Uk2 = U4Edge[0];\r\n                            eUK = eU4Edge[0];\r\n                        }\r\n                        if (flags.softmaxOutputLayer) {\r\n                            if (j == 0) {\r\n                                Yk2 = Y[0];\r\n                            } else {\r\n                                Yk2 = Y4Edge[0];\r\n                            }\r\n                        }\r\n                    } else {\r\n                        if (j == 0) {\r\n                            Uk2 = U[k];\r\n                            eUK = eU[k];\r\n                        } else {\r\n                            Uk2 = U4Edge[k];\r\n                            eUK = eU4Edge[k];\r\n                        }\r\n                        if (flags.softmaxOutputLayer) {\r\n                            if (j == 0) {\r\n                                Yk2 = Y[k];\r\n                            } else {\r\n                                Yk2 = Y4Edge[k];\r\n                            }\r\n                        }\r\n                    }\r\n                    if (useOutputLayer) {\r\n                        for (int q = 0; q < inputSize; q++) {\r\n                            double deltaQ = 1;\r\n                            if (flags.sparseOutputLayer || flags.tieOutputLayer) {\r\n                                if (q % outputSize == k) {\r\n                                    int hiddenUnitNo = q / outputSize;\r\n                                    if (flags.softmaxOutputLayer) {\r\n                                        eUK[hiddenUnitNo] += (yTimesA[k][hiddenUnitNo] - Yk2[hiddenUnitNo] * sumOfYTimesA[k]) * p;\r\n                                        deltaQ = Yk2[hiddenUnitNo];\r\n                                    } else {\r\n                                        eUK[hiddenUnitNo] += As[q] * p;\r\n                                        deltaQ = Uk2[hiddenUnitNo];\r\n                                    }\r\n                                }\r\n                            } else {\r\n                                eUK[q] += As[q] * p;\r\n                                deltaQ = Uk2[q];\r\n                            }\r\n                            if (useHiddenLayer)\r\n                                deltaQ *= fDeriv[q];\r\n                            if (flags.sparseOutputLayer || flags.tieOutputLayer) {\r\n                                if (q % outputSize == k) {\r\n                                    double[] eWq = null;\r\n                                    if (j == 0) {\r\n                                        eWq = eW[q];\r\n                                    } else {\r\n                                        eWq = eW4Edge[q];\r\n                                    }\r\n                                    for (int cliqueFeature : cliqueFeatures) {\r\n                                        eWq[cliqueFeature] += deltaQ * p;\r\n                                    }\r\n                                }\r\n                            } else {\r\n                                double[] eWq = null;\r\n                                if (j == 0) {\r\n                                    eWq = eW[q];\r\n                                } else {\r\n                                    eWq = eW4Edge[q];\r\n                                }\r\n                                for (int cliqueFeature : cliqueFeatures) {\r\n                                    eWq[cliqueFeature] += deltaQ * p;\r\n                                }\r\n                            }\r\n                        }\r\n                    } else {\r\n                        double deltaK = 1;\r\n                        if (useHiddenLayer)\r\n                            deltaK *= fDeriv[k];\r\n                        double[] eWK = null;\r\n                        if (j == 0) {\r\n                            eWK = eW[k];\r\n                        } else {\r\n                            eWK = eW4Edge[k];\r\n                        }\r\n                        for (int cliqueFeature : cliqueFeatures) {\r\n                            eWK[cliqueFeature] += deltaK * p;\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n    if (Double.isNaN(prob)) {\r\n        throw new RuntimeException(\"Got NaN for prob in CRFNonLinearSecondOrderLogConditionalObjectiveFunction.calculate()\");\r\n    }\r\n    value = -prob;\r\n    if (VERBOSE) {\r\n        log.info(\"value is \" + value);\r\n    }\r\n    int index = 0;\r\n    for (int i = 0; i < eW4Edge.length; i++) {\r\n        for (int j = 0; j < eW4Edge[i].length; j++) {\r\n            derivative[index++] = (eW4Edge[i][j] - What4Edge[i][j]);\r\n            if (VERBOSE) {\r\n                log.info(\"inputLayerWeights4Edge deriv(\" + i + \",\" + j + \") = \" + eW4Edge[i][j] + \" - \" + What4Edge[i][j] + \" = \" + derivative[index - 1]);\r\n            }\r\n        }\r\n    }\r\n    for (int i = 0; i < eW.length; i++) {\r\n        for (int j = 0; j < eW[i].length; j++) {\r\n            derivative[index++] = (eW[i][j] - What[i][j]);\r\n            if (VERBOSE) {\r\n                log.info(\"inputLayerWeights deriv(\" + i + \",\" + j + \") = \" + eW[i][j] + \" - \" + What[i][j] + \" = \" + derivative[index - 1]);\r\n            }\r\n        }\r\n    }\r\n    if (index != beforeOutputWeights)\r\n        throw new RuntimeException(\"after W derivative, index(\" + index + \") != beforeOutputWeights(\" + beforeOutputWeights + \")\");\r\n    if (useOutputLayer) {\r\n        for (int i = 0; i < eU4Edge.length; i++) {\r\n            for (int j = 0; j < eU4Edge[i].length; j++) {\r\n                derivative[index++] = (eU4Edge[i][j] - Uhat4Edge[i][j]);\r\n                if (VERBOSE) {\r\n                    log.info(\"outputLayerWeights4Edge deriv(\" + i + \",\" + j + \") = \" + eU4Edge[i][j] + \" - \" + Uhat4Edge[i][j] + \" = \" + derivative[index - 1]);\r\n                }\r\n            }\r\n        }\r\n        for (int i = 0; i < eU.length; i++) {\r\n            for (int j = 0; j < eU[i].length; j++) {\r\n                derivative[index++] = (eU[i][j] - Uhat[i][j]);\r\n                if (VERBOSE) {\r\n                    log.info(\"outputLayerWeights deriv(\" + i + \",\" + j + \") = \" + eU[i][j] + \" - \" + Uhat[i][j] + \" = \" + derivative[index - 1]);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    if (index != x.length)\r\n        throw new RuntimeException(\"after W derivative, index(\" + index + \") != x.length(\" + x.length + \")\");\r\n    int regSize = x.length;\r\n    if (flags.skipOutputRegularization || flags.softmaxOutputLayer) {\r\n        regSize = beforeOutputWeights;\r\n    }\r\n    if (prior == QUADRATIC_PRIOR) {\r\n        double sigmaSq = sigma * sigma;\r\n        for (int i = 0; i < regSize; i++) {\r\n            double k = 1.0;\r\n            double w = x[i];\r\n            value += k * w * w / 2.0 / sigmaSq;\r\n            derivative[i] += k * w / sigmaSq;\r\n        }\r\n    } else if (prior == HUBER_PRIOR) {\r\n        double sigmaSq = sigma * sigma;\r\n        for (int i = 0; i < regSize; i++) {\r\n            double w = x[i];\r\n            double wabs = Math.abs(w);\r\n            if (wabs < epsilon) {\r\n                value += w * w / 2.0 / epsilon / sigmaSq;\r\n                derivative[i] += w / epsilon / sigmaSq;\r\n            } else {\r\n                value += (wabs - epsilon / 2) / sigmaSq;\r\n                derivative[i] += ((w < 0.0) ? -1.0 : 1.0) / sigmaSq;\r\n            }\r\n        }\r\n    } else if (prior == QUARTIC_PRIOR) {\r\n        double sigmaQu = sigma * sigma * sigma * sigma;\r\n        for (int i = 0; i < regSize; i++) {\r\n            double k = 1.0;\r\n            double w = x[i];\r\n            value += k * w * w * w * w / 2.0 / sigmaQu;\r\n            derivative[i] += k * w / sigmaQu;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaBasicBlock.addMoveToEnd",
	"Comment": "adds a move instruction to the end of this basic block, justbefore the last instruction. if the result of the final instructionis the source in question, then the move is placed at the beginning ofthe primary successor block. this is for unversioned registers.",
	"Method": "void addMoveToEnd(RegisterSpec result,RegisterSpec source){\r\n    if (result.getReg() == source.getReg()) {\r\n        return;\r\n    }\r\n    NormalSsaInsn lastInsn;\r\n    lastInsn = (NormalSsaInsn) insns.get(insns.size() - 1);\r\n    if (lastInsn.getResult() != null || lastInsn.getSources().size() > 0) {\r\n        for (int i = successors.nextSetBit(0); i >= 0; i = successors.nextSetBit(i + 1)) {\r\n            SsaBasicBlock succ;\r\n            succ = parent.getBlocks().get(i);\r\n            succ.addMoveToBeginning(result, source);\r\n        }\r\n    } else {\r\n        RegisterSpecList sources = RegisterSpecList.make(source);\r\n        NormalSsaInsn toAdd = new NormalSsaInsn(new PlainInsn(Rops.opMove(result.getType()), SourcePosition.NO_INFO, result, sources), this);\r\n        insns.add(insns.size() - 1, toAdd);\r\n        movesFromPhisAtEnd++;\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.Type.getReturnType",
	"Comment": "returns the return type of methods of this type. this method should onlybe used for method types.",
	"Method": "Type getReturnType(String methodDescriptor,Type getReturnType,Method method,Type getReturnType){\r\n    return getReturnType(getDescriptor());\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.BasicEntityExtractor.extractEntities",
	"Comment": "label entities in an extractionsentence. assumes the classifier has alreadybeen trained.",
	"Method": "CoreMap extractEntities(CoreMap sentence,int sentCount){\r\n    List<CoreLabel> testSentence = AnnotationUtils.sentenceEntityMentionsToCoreLabels(sentence, false, annotationsToSkip, null, useSubTypes, useBIO);\r\n    List<CoreLabel> annotatedSentence = this.classifier.classify(testSentence);\r\n    logger.finest(\"CLASSFIER OUTPUT: \" + annotatedSentence);\r\n    List<EntityMention> extractedEntities = new ArrayList();\r\n    int i = 0;\r\n    String lastType = null;\r\n    int startIndex = -1;\r\n    for (CoreLabel label : annotatedSentence) {\r\n        String type = label.get(AnswerAnnotation.class);\r\n        if (type.equals(SeqClassifierFlags.DEFAULT_BACKGROUND_SYMBOL)) {\r\n            type = null;\r\n        }\r\n        if (type == null && lastType != null) {\r\n            makeEntityMention(sentence, startIndex, i, lastType, extractedEntities, sentCount);\r\n            logger.info(\"Found entity: \" + extractedEntities.get(extractedEntities.size() - 1));\r\n            startIndex = -1;\r\n        } else if (lastType == null && type != null) {\r\n            startIndex = i;\r\n        } else if (lastType != null && type != null && (type.startsWith(\"B-\") || (lastType.startsWith(\"I-\") && type.startsWith(\"I-\") && !lastType.equals(type)) || (notBIO(lastType) && notBIO(type) && !lastType.equals(type)))) {\r\n            makeEntityMention(sentence, startIndex, i, lastType, extractedEntities, sentCount);\r\n            logger.info(\"Found entity: \" + extractedEntities.get(extractedEntities.size() - 1));\r\n            startIndex = i;\r\n        }\r\n        lastType = type;\r\n        i++;\r\n    }\r\n    sentence.set(MachineReadingAnnotations.EntityMentionsAnnotation.class, extractedEntities);\r\n    logger.finest(\"EXTRACTED ENTITIES: \");\r\n    for (EntityMention e : extractedEntities) {\r\n        logger.finest(\"\\t\" + e);\r\n    }\r\n    postprocessSentence(sentence, sentCount);\r\n    return sentence;\r\n}"
}, {
	"Path": "org.apache.commons.cli.OptionBuilder.hasArg",
	"Comment": "the next option created will require an argument value ifhasarg is true.",
	"Method": "OptionBuilder hasArg(OptionBuilder hasArg,boolean hasArg){\r\n    OptionBuilder.numberOfArgs = hasArg ? 1 : Option.UNINITIALIZED;\r\n    return INSTANCE;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.opt.ClairvoyantPolicy.evict",
	"Comment": "removes the entry whose next access is farthest away into the future.",
	"Method": "void evict(){\r\n    data.remove(data.lastInt());\r\n    policyStats.recordEviction();\r\n}"
}, {
	"Path": "org.apereo.cas.couchdb.surrogate.SurrogateAuthorizationCouchDbRepository.findBySurrogatePrincipal",
	"Comment": "find by surrogate, principal, service touple for authorization check.",
	"Method": "List<CouchDbSurrogateAuthorization> findBySurrogatePrincipal(String surrogate,String principal){\r\n    return queryView(\"by_surrogate_principal\", ComplexKey.of(principal, surrogate));\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMap8Test.testCompute4",
	"Comment": "compute removes when the given key is present and function returns null",
	"Method": "void testCompute4(){\r\n    ConcurrentMap map = map5();\r\n    map.compute(one, (x, y) -> null);\r\n    assertFalse(map.containsKey(one));\r\n}"
}, {
	"Path": "com.google.common.cache.CacheLoadingTest.testConcurrentLoadingDefault",
	"Comment": "on a successful concurrent computation, only one thread does the work, but all the threads getthe same result.",
	"Method": "void testConcurrentLoadingDefault(Caffeine<Object, Object> builder){\r\n    int count = 10;\r\n    final AtomicInteger callCount = new AtomicInteger();\r\n    final CountDownLatch startSignal = new CountDownLatch(count + 1);\r\n    final Object result = new Object();\r\n    LoadingCache<String, Object> cache = CaffeinatedGuava.build(builder, new CacheLoader<String, Object>() {\r\n        @Override\r\n        public Object load(String key) {\r\n            callCount.incrementAndGet();\r\n            assertTrue(Uninterruptibles.awaitUninterruptibly(startSignal, 300, TimeUnit.SECONDS));\r\n            return result;\r\n        }\r\n    });\r\n    List<Object> resultArray = doConcurrentGet(cache, \"bar\", count, startSignal);\r\n    assertEquals(1, callCount.get());\r\n    for (int i = 0; i < count; i++) {\r\n        assertSame(\"result(\" + i + \") didn't match expected\", result, resultArray.get(i));\r\n    }\r\n}"
}, {
	"Path": "com.google.common.cache.CacheLoadingTest.testConcurrentLoadingDefault",
	"Comment": "on a successful concurrent computation, only one thread does the work, but all the threads getthe same result.",
	"Method": "void testConcurrentLoadingDefault(Caffeine<Object, Object> builder){\r\n    callCount.incrementAndGet();\r\n    assertTrue(Uninterruptibles.awaitUninterruptibly(startSignal, 300, TimeUnit.SECONDS));\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.principal.resolvers.ChainingPrincipalResolver.supports",
	"Comment": "determines whether the credential is supported by this component by delegating to the first configuredresolver in the chain.",
	"Method": "boolean supports(Credential credential){\r\n    return this.chain.get(0).supports(credential);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.refreshAfterWriteNanos",
	"Comment": "returns how long after the last write an entry becomes a candidate for refresh.",
	"Method": "long refreshAfterWriteNanos(){\r\n    throw new UnsupportedOperationException();\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.util.BuckCellFinder.findExtensionFile",
	"Comment": "finds an extension file, starting from the given sourcefile.",
	"Method": "Optional<VirtualFile> findExtensionFile(VirtualFile sourceFile,String target){\r\n    if (target.startsWith(\":\")) {\r\n        return Optional.ofNullable(sourceFile.getParent()).map(f -> f.findFileByRelativePath(target.substring(1))).filter(VirtualFile::exists);\r\n    }\r\n    Matcher matcher = BUCK_CELL_PATH_PATTERN.matcher(target);\r\n    if (!matcher.matches()) {\r\n        return Optional.empty();\r\n    }\r\n    String targetName = matcher.group(\"target\");\r\n    if (targetName == null) {\r\n        return Optional.empty();\r\n    }\r\n    String cellName = matcher.group(\"cell\");\r\n    String cellPath = matcher.group(\"path\");\r\n    return findBuckCell(sourceFile, cellName).flatMap(cell -> {\r\n        return Optional.ofNullable(pathMacroExpander.apply(cell.getRoot())).map(s -> sourceFile.getFileSystem().findFileByPath(s)).map(cellRoot -> cellRoot.findFileByRelativePath(cellPath)).map(subDir -> subDir.findFileByRelativePath(targetName)).filter(VirtualFile::exists);\r\n    });\r\n}"
}, {
	"Path": "edu.stanford.nlp.parser.lexparser.LexicalizedParserITest.compareOutput",
	"Comment": "given a tree and a bunch of expected strings, this method takesthat tree and compares its components to the expected output byprinting the tree in a few different ways.there are probablybetter ways of testing the trees, ie by comparing the treedirectly instead of printing it out, but printing it also makesthe output very easy to inspect visually.setting outputresults to true makes it print out the results.",
	"Method": "void compareOutput(Tree results,boolean outputResults,String expectedTags,String expectedPenn,String expectedDep,String expectedDepCol){\r\n    compareSingleOutput(results, outputResults, tagPrint, expectedTags);\r\n    compareSingleOutput(results, outputResults, pennPrint, expectedPenn);\r\n    compareSingleOutput(results, outputResults, typDepPrint, expectedDep);\r\n    compareSingleOutput(results, outputResults, typDepColPrint, expectedDepCol);\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.BaseNCodec.isInAlphabet",
	"Comment": "tests a given string to see if it contains only valid characters within the alphabet.the method treats whitespace and pad as valid.",
	"Method": "boolean isInAlphabet(byte value,boolean isInAlphabet,byte[] arrayOctet,boolean allowWSPad,boolean isInAlphabet,String basen){\r\n    return isInAlphabet(StringUtils.getBytesUtf8(basen), true);\r\n}"
}, {
	"Path": "the.bytecode.club.bytecodeviewer.searching.RegexInsnFinder.findGroups",
	"Comment": "searches for a regex in the instruction list and returns all groups forthe first match.",
	"Method": "AbstractInsnNode[][] findGroups(String regex){\r\n    try {\r\n        final Matcher regexMatcher = Pattern.compile(processRegex(regex), Pattern.MULTILINE).matcher(insnString);\r\n        if (regexMatcher.find()) {\r\n            final AbstractInsnNode[][] result = new AbstractInsnNode[regexMatcher.groupCount() + 1][0];\r\n            for (int i = 0; i <= regexMatcher.groupCount(); i++) {\r\n                result[i] = makeResult(regexMatcher.start(i), regexMatcher.end(i));\r\n            }\r\n            return result;\r\n        }\r\n    } catch (final PatternSyntaxException ex) {\r\n        new the.bytecode.club.bytecodeviewer.api.ExceptionUI(ex);\r\n    }\r\n    return new AbstractInsnNode[0][0];\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.PolicyBasedAuthenticationManager.getAuthenticationMetadataPopulatorsForTransaction",
	"Comment": "gets authentication metadata populators for transaction.",
	"Method": "Collection<AuthenticationMetaDataPopulator> getAuthenticationMetadataPopulatorsForTransaction(AuthenticationTransaction transaction){\r\n    return this.authenticationEventExecutionPlan.getAuthenticationMetadataPopulators(transaction);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.event.JCacheEvictionListener.setCache",
	"Comment": "sets the cache instance that was created with this listener.",
	"Method": "void setCache(Cache<K, V> cache){\r\n    this.cache = requireNonNull(cache);\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.DaitchMokotoffSoundex.soundex",
	"Comment": "perform the actual dm soundex algorithm on the input string.",
	"Method": "String soundex(String source,String[] soundex,String source,boolean branching){\r\n    if (source == null) {\r\n        return null;\r\n    }\r\n    final String input = cleanup(source);\r\n    final Set<Branch> currentBranches = new LinkedHashSet<Branch>();\r\n    currentBranches.add(new Branch());\r\n    char lastChar = '\\0';\r\n    for (int index = 0; index < input.length(); index++) {\r\n        final char ch = input.charAt(index);\r\n        if (Character.isWhitespace(ch)) {\r\n            continue;\r\n        }\r\n        final String inputContext = input.substring(index);\r\n        final List<Rule> rules = RULES.get(ch);\r\n        if (rules == null) {\r\n            continue;\r\n        }\r\n        @SuppressWarnings(\"unchecked\")\r\n        final List<Branch> nextBranches = branching ? new ArrayList<Branch>() : Collections.EMPTY_LIST;\r\n        for (final Rule rule : rules) {\r\n            if (rule.matches(inputContext)) {\r\n                if (branching) {\r\n                    nextBranches.clear();\r\n                }\r\n                final String[] replacements = rule.getReplacements(inputContext, lastChar == '\\0');\r\n                final boolean branchingRequired = replacements.length > 1 && branching;\r\n                for (final Branch branch : currentBranches) {\r\n                    for (final String nextReplacement : replacements) {\r\n                        final Branch nextBranch = branchingRequired ? branch.createBranch() : branch;\r\n                        final boolean force = (lastChar == 'm' && ch == 'n') || (lastChar == 'n' && ch == 'm');\r\n                        nextBranch.processNextReplacement(nextReplacement, force);\r\n                        if (branching) {\r\n                            nextBranches.add(nextBranch);\r\n                        } else {\r\n                            break;\r\n                        }\r\n                    }\r\n                }\r\n                if (branching) {\r\n                    currentBranches.clear();\r\n                    currentBranches.addAll(nextBranches);\r\n                }\r\n                index += rule.getPatternLength() - 1;\r\n                break;\r\n            }\r\n        }\r\n        lastChar = ch;\r\n    }\r\n    final String[] result = new String[currentBranches.size()];\r\n    int index = 0;\r\n    for (final Branch branch : currentBranches) {\r\n        branch.finish();\r\n        result[index++] = branch.toString();\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.apereo.cas.adaptors.trusted.authentication.handler.support.PrincipalBearingCredentialsAuthenticationHandlerTests.verifyNonNullPrincipal",
	"Comment": "when the credentials bear a principal, succeed the authentication.",
	"Method": "void verifyNonNullPrincipal(){\r\n    val credentials = new PrincipalBearingCredential(PrincipalFactoryUtils.newPrincipalFactory().createPrincipal(\"scott\"));\r\n    assertNotNull(this.handler.authenticate(credentials));\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.GeneralDataset.applyFeatureMaxCountThreshold",
	"Comment": "applies a max feature count threshold to the dataset.all features thatoccur greater than k times are expunged.",
	"Method": "void applyFeatureMaxCountThreshold(int k){\r\n    float[] counts = getFeatureCounts();\r\n    HashIndex<F> newFeatureIndex = new HashIndex();\r\n    int[] featMap = new int[featureIndex.size()];\r\n    for (int i = 0; i < featMap.length; i++) {\r\n        F feat = featureIndex.get(i);\r\n        if (counts[i] <= k) {\r\n            int newIndex = newFeatureIndex.size();\r\n            newFeatureIndex.add(feat);\r\n            featMap[i] = newIndex;\r\n        } else {\r\n            featMap[i] = -1;\r\n        }\r\n    }\r\n    featureIndex = newFeatureIndex;\r\n    for (int i = 0; i < size; i++) {\r\n        List<Integer> featList = new ArrayList(data[i].length);\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            if (featMap[data[i][j]] >= 0) {\r\n                featList.add(featMap[data[i][j]]);\r\n            }\r\n        }\r\n        data[i] = new int[featList.size()];\r\n        for (int j = 0; j < data[i].length; j++) {\r\n            data[i][j] = featList.get(j);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.tree.InsnList.accept",
	"Comment": "makes the given visitor visit all of the instructions in this list.",
	"Method": "void accept(MethodVisitor mv){\r\n    AbstractInsnNode insn = first;\r\n    while (insn != null) {\r\n        insn.accept(mv);\r\n        insn = insn.next;\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.SCCP.process",
	"Comment": "performs sparse conditional constant propagation on a method.",
	"Method": "void process(SsaMethod ssaMethod){\r\n    new SCCP(ssaMethod).run();\r\n}"
}, {
	"Path": "com.android.dx.ssa.SCCP.replaceBranches",
	"Comment": "replaces branches that have constant conditions with gotos",
	"Method": "void replaceBranches(){\r\n    for (SsaInsn insn : branchWorklist) {\r\n        int oldSuccessor = -1;\r\n        SsaBasicBlock block = insn.getBlock();\r\n        int successorSize = block.getSuccessorList().size();\r\n        for (int i = 0; i < successorSize; i++) {\r\n            int successorBlock = block.getSuccessorList().get(i);\r\n            if (!executableBlocks.get(successorBlock)) {\r\n                oldSuccessor = successorBlock;\r\n            }\r\n        }\r\n        if (successorSize != 2 || oldSuccessor == -1)\r\n            continue;\r\n        Insn originalRopInsn = insn.getOriginalRopInsn();\r\n        block.replaceLastInsn(new PlainInsn(Rops.GOTO, originalRopInsn.getPosition(), null, RegisterSpecList.EMPTY));\r\n        block.removeSuccessor(oldSuccessor);\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.cli.Option.getValue",
	"Comment": "returns the specified value of this option or null if there is no value.",
	"Method": "String getValue(String getValue,int index,String getValue,String defaultValue){\r\n    String value = getValue();\r\n    return (value != null) ? value : defaultValue;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.TimerWheel.expire",
	"Comment": "expires entries or reschedules into the proper bucket if still active.",
	"Method": "void expire(int index,long previousTicks,long currentTicks){\r\n    Node<K, V>[] timerWheel = wheel[index];\r\n    int start, end;\r\n    if ((currentTicks - previousTicks) >= timerWheel.length) {\r\n        end = timerWheel.length;\r\n        start = 0;\r\n    } else {\r\n        long mask = SPANS[index] - 1;\r\n        start = (int) (previousTicks & mask);\r\n        end = 1 + (int) (currentTicks & mask);\r\n    }\r\n    int mask = timerWheel.length - 1;\r\n    for (int i = start; i < end; i++) {\r\n        Node<K, V> sentinel = timerWheel[(i & mask)];\r\n        Node<K, V> prev = sentinel.getPreviousInVariableOrder();\r\n        Node<K, V> node = sentinel.getNextInVariableOrder();\r\n        sentinel.setPreviousInVariableOrder(sentinel);\r\n        sentinel.setNextInVariableOrder(sentinel);\r\n        while (node != sentinel) {\r\n            Node<K, V> next = node.getNextInVariableOrder();\r\n            node.setPreviousInVariableOrder(null);\r\n            node.setNextInVariableOrder(null);\r\n            try {\r\n                if (((node.getVariableTime() - nanos) > 0) || !cache.evictEntry(node, RemovalCause.EXPIRED, nanos)) {\r\n                    Node<K, V> newSentinel = findBucket(node.getVariableTime());\r\n                    link(newSentinel, node);\r\n                }\r\n                node = next;\r\n            } catch (Throwable t) {\r\n                node.setPreviousInVariableOrder(sentinel.getPreviousInVariableOrder());\r\n                node.setNextInVariableOrder(next);\r\n                sentinel.getPreviousInVariableOrder().setNextInVariableOrder(node);\r\n                sentinel.setPreviousInVariableOrder(prev);\r\n                throw t;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.cli.CommandLine.addOption",
	"Comment": "add an option to the command line.the values of the option are stored.",
	"Method": "void addOption(Option opt){\r\n    options.add(opt);\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.domains.ace.reader.RobustTokenizer.tokenizeText",
	"Comment": "tokenizes and adds blank spaces were needed between each token",
	"Method": "String tokenizeText(){\r\n    List<WordToken> tokenList = tokenizeToWordTokens();\r\n    StringBuffer strBuffer = new StringBuffer();\r\n    Iterator<WordToken> iter = tokenList.iterator();\r\n    if (iter.hasNext()) {\r\n        strBuffer.append(iter.next());\r\n    }\r\n    while (iter.hasNext()) {\r\n        strBuffer.append(\" \");\r\n        strBuffer.append(iter.next());\r\n    }\r\n    return strBuffer.toString().replaceAll(\"\\\\s\\\\s+\", \" \");\r\n}"
}, {
	"Path": "com.android.dx.ssa.NormalSsaInsn.upgradeToLiteral",
	"Comment": "upgrades this insn to a version that represents the constant sourceliterally. if the upgrade is not possible, this does nothing.",
	"Method": "void upgradeToLiteral(){\r\n    RegisterSpecList oldSources = insn.getSources();\r\n    insn = insn.withSourceLiteral();\r\n    getBlock().getParent().onSourcesChanged(this, oldSources);\r\n}"
}, {
	"Path": "jsr166.JSR166TestCase.delayedDate",
	"Comment": "returns a new date instance representing a time delaymillismilliseconds in the future.",
	"Method": "Date delayedDate(long delayMillis){\r\n    return new Date(System.currentTimeMillis() + delayMillis);\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.principal.resolvers.PersonDirectoryPrincipalResolver.extractPrincipalId",
	"Comment": "extracts the id of the user from the provided credential. this method should be overridden by subclasses toachieve more sophisticated strategies for producing a principal id from a credential.",
	"Method": "String extractPrincipalId(Credential credential,Optional<Principal> currentPrincipal){\r\n    LOGGER.debug(\"Extracting credential id based on existing credential [{}]\", credential);\r\n    if (currentPrincipal != null && currentPrincipal.isPresent()) {\r\n        val principal = currentPrincipal.get();\r\n        LOGGER.debug(\"Principal is currently resolved is [{}]\", principal);\r\n        if (useCurrentPrincipalId) {\r\n            LOGGER.debug(\"Using the existing resolved principal id [{}]\", principal.getId());\r\n            return principal.getId();\r\n        }\r\n    }\r\n    val id = credential.getId();\r\n    LOGGER.debug(\"Extracted principal id [{}]\", id);\r\n    return id;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.Registry.policies",
	"Comment": "returns all of the policies that have been configured for simulation.",
	"Method": "Set<Policy> policies(BasicSettings settings){\r\n    return settings.policies().stream().flatMap(name -> policy(settings, name).stream()).collect(toSet());\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.SingleConsumerQueueTest.cleanUp",
	"Comment": "free memory by clearing unused resources after test execution.",
	"Method": "void cleanUp(ITestResult testResult){\r\n    Object[] params = testResult.getParameters();\r\n    for (int i = 0; i < params.length; i++) {\r\n        Object param = params[i];\r\n        if ((param instanceof SingleConsumerQueue<?>)) {\r\n            boolean linearizable = (((SingleConsumerQueue<?>) param).factory.apply(null) instanceof LinearizableNode<?>);\r\n            params[i] = param.getClass().getSimpleName() + \"_\" + (linearizable ? \"linearizable\" : \"optimistic\");\r\n        } else {\r\n            params[i] = Objects.toString(param);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.android.dx.ssa.back.FirstFitLocalCombiningAllocator.handleInvokeRangeInsns",
	"Comment": "handles all insns that want a register range for their sources.",
	"Method": "void handleInvokeRangeInsns(){\r\n    for (NormalSsaInsn insn : invokeRangeInsns) {\r\n        adjustAndMapSourceRangeRange(insn);\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.cli.OptionBuilder.withLongOpt",
	"Comment": "the next option created will have the following long option value.",
	"Method": "OptionBuilder withLongOpt(String newLongopt){\r\n    OptionBuilder.longopt = newLongopt;\r\n    return INSTANCE;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.segment.LruWindowTinyLfuPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    LruWindowTinyLfuSettings settings = new LruWindowTinyLfuSettings(config);\r\n    return settings.percentMain().stream().map(percentMain -> new LruWindowTinyLfuPolicy(percentMain, settings)).collect(toSet());\r\n}"
}, {
	"Path": "org.apereo.cas.web.flow.resolver.impl.AbstractCasWebflowEventResolver.handleAuthenticationTransactionAndGrantTicketGrantingTicket",
	"Comment": "handle authentication transaction and grant ticket granting ticket.",
	"Method": "Set<Event> handleAuthenticationTransactionAndGrantTicketGrantingTicket(RequestContext context){\r\n    val response = WebUtils.getHttpServletResponseFromExternalWebflowContext(context);\r\n    try {\r\n        val credential = getCredentialFromContext(context);\r\n        val builderResult = WebUtils.getAuthenticationResultBuilder(context);\r\n        LOGGER.debug(\"Handling authentication transaction for credential [{}]\", credential);\r\n        val service = WebUtils.getService(context);\r\n        val builder = this.authenticationSystemSupport.handleAuthenticationTransaction(service, builderResult, credential);\r\n        LOGGER.debug(\"Issuing ticket-granting tickets for service [{}]\", service);\r\n        return CollectionUtils.wrapSet(grantTicketGrantingTicketToAuthenticationResult(context, builder, service));\r\n    } catch (final Exception e) {\r\n        LOGGER.error(e.getMessage(), e);\r\n        val messageContext = context.getMessageContext();\r\n        messageContext.addMessage(new MessageBuilder().error().code(DEFAULT_MESSAGE_BUNDLE_PREFIX.concat(e.getClass().getSimpleName())).build());\r\n        response.setStatus(HttpStatus.UNAUTHORIZED.value());\r\n        return CollectionUtils.wrapSet(getAuthenticationFailureErrorEvent(context));\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.graph.DirectedMultiGraph.hashCode",
	"Comment": "be careful hashing these. they are mutable objects, and changing the objectwill throw off the hash code, messing up your hash table",
	"Method": "int hashCode(){\r\n    return outgoingEdges.hashCode();\r\n}"
}, {
	"Path": "org.apereo.cas.services.ServicesManager.getDomains",
	"Comment": "returns a list of domains being managed by the servicemanager.",
	"Method": "Collection<String> getDomains(){\r\n    return Stream.of(\"default\").collect(Collectors.toList());\r\n}"
}, {
	"Path": "org.objectweb.asm.util.CheckClassAdapter.checkState",
	"Comment": "checks that the visit method has been called and that visitend has notbeen called.",
	"Method": "void checkState(){\r\n    if (!start) {\r\n        throw new IllegalStateException(\"Cannot visit member before visit has been called.\");\r\n    }\r\n    if (end) {\r\n        throw new IllegalStateException(\"Cannot visit member after visitEnd has been called.\");\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.ner.CMMClassifier.getDataset",
	"Comment": "build a dataset from some data. used for training a classifier.by passing in an extra origdataset, you can get a dataset based on featureindex andclassindex in an existing origdataset.",
	"Method": "Dataset<String, String> getDataset(Collection<List<IN>> data,Dataset<String, String> getDataset,Collection<List<IN>> data,Index<String> featureIndex,Index<String> classIndex,Dataset<String, String> getDataset,ObjectBank<List<IN>> data,Dataset<String, String> origDataset,Dataset<String, String> getDataset,Dataset<String, String> oldData,Index<String> goodFeatures){\r\n    int[][] oldDataArray = oldData.getDataArray();\r\n    int[] oldLabelArray = oldData.getLabelsArray();\r\n    Index<String> oldFeatureIndex = oldData.featureIndex;\r\n    int[] oldToNewFeatureMap = new int[oldFeatureIndex.size()];\r\n    int[][] newDataArray = new int[oldDataArray.length][];\r\n    log.info(\"Building reduced dataset...\");\r\n    int size = oldFeatureIndex.size();\r\n    int max = 0;\r\n    for (int i = 0; i < size; i++) {\r\n        oldToNewFeatureMap[i] = goodFeatures.indexOf(oldFeatureIndex.get(i));\r\n        if (oldToNewFeatureMap[i] > max) {\r\n            max = oldToNewFeatureMap[i];\r\n        }\r\n    }\r\n    for (int i = 0; i < oldDataArray.length; i++) {\r\n        int[] data = oldDataArray[i];\r\n        size = 0;\r\n        for (int oldF : data) {\r\n            if (oldToNewFeatureMap[oldF] > 0) {\r\n                size++;\r\n            }\r\n        }\r\n        int[] newData = new int[size];\r\n        int index = 0;\r\n        for (int oldF : data) {\r\n            int f = oldToNewFeatureMap[oldF];\r\n            if (f > 0) {\r\n                newData[index++] = f;\r\n            }\r\n        }\r\n        newDataArray[i] = newData;\r\n    }\r\n    Dataset<String, String> train = new Dataset(oldData.labelIndex, oldLabelArray, goodFeatures, newDataArray, newDataArray.length);\r\n    log.info(\"done.\");\r\n    if (flags.featThreshFile != null) {\r\n        log.info(\"applying thresholds...\");\r\n        List<Pair<Pattern, Integer>> thresh = getThresholds(flags.featThreshFile);\r\n        train.applyFeatureCountThreshold(thresh);\r\n    } else if (flags.featureThreshold > 1) {\r\n        log.info(\"Removing Features with counts < \" + flags.featureThreshold);\r\n        train.applyFeatureCountThreshold(flags.featureThreshold);\r\n    }\r\n    train.summaryStatistics();\r\n    return train;\r\n}"
}, {
	"Path": "com.android.dx.rop.cst.CstType.intern",
	"Comment": "returns an interned instance of this class for the given type.",
	"Method": "CstType intern(Type type){\r\n    CstType cst = new CstType(type);\r\n    CstType result = interns.putIfAbsent(type, cst);\r\n    return result != null ? result : cst;\r\n}"
}, {
	"Path": "com.android.dx.rop.type.Type.getComponentType",
	"Comment": "gets the component type of this type. this method is only valid onarray types.",
	"Method": "Type getComponentType(){\r\n    if (componentType == null) {\r\n        if (descriptor.charAt(0) != '[') {\r\n            throw new IllegalArgumentException(\"not an array type: \" + descriptor);\r\n        }\r\n        componentType = intern(descriptor.substring(1));\r\n    }\r\n    return componentType;\r\n}"
}, {
	"Path": "org.apereo.cas.services.DefaultRegisteredServiceAccessStrategy.enoughAttributesAvailableToProcess",
	"Comment": "enough attributes available to process? check collection sizes and determineif we have enough data to move on.",
	"Method": "boolean enoughAttributesAvailableToProcess(String principal,Map<String, Object> principalAttributes){\r\n    if (!enoughRequiredAttributesAvailableToProcess(principalAttributes, this.requiredAttributes)) {\r\n        return false;\r\n    }\r\n    if (principalAttributes.size() < this.rejectedAttributes.size()) {\r\n        LOGGER.debug(\"The size of the principal attributes that are [{}] does not match defined rejected attributes, \" + \"which means the principal is not carrying enough data to grant authorization\", principalAttributes);\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.collectValues",
	"Comment": "returns if the values are weak or soft reference garbage collected.",
	"Method": "boolean collectValues(){\r\n    return false;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.segment.RandomWindowTinyLfuPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    RandomWindowTinyLfuSettings settings = new RandomWindowTinyLfuSettings(config);\r\n    return settings.percentMain().stream().map(percentMain -> new RandomWindowTinyLfuPolicy(percentMain, settings)).collect(toSet());\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.loadArgArray",
	"Comment": "generates the instructions to load all the method arguments on the stack,as a single object array.",
	"Method": "void loadArgArray(){\r\n    push(argumentTypes.length);\r\n    newArray(OBJECT_TYPE);\r\n    for (int i = 0; i < argumentTypes.length; i++) {\r\n        dup();\r\n        push(i);\r\n        loadArg(i);\r\n        box(argumentTypes[i]);\r\n        arrayStore(OBJECT_TYPE);\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.printFactorTable",
	"Comment": "takes the file, reads it in, and prints out the factor table at each position.",
	"Method": "void printFactorTable(String filename,DocumentReaderAndWriter<IN> readerAndWriter){\r\n    ObjectBank<List<IN>> docs = makeObjectBankFromFile(filename, readerAndWriter);\r\n    printFactorTableDocuments(docs);\r\n}"
}, {
	"Path": "com.android.dx.rop.code.ThrowingInsn.toCatchString",
	"Comment": "gets the string form of a register spec list to be used as a catcheslist.",
	"Method": "String toCatchString(TypeList catches){\r\n    StringBuffer sb = new StringBuffer(100);\r\n    sb.append(\"catch\");\r\n    int sz = catches.size();\r\n    for (int i = 0; i < sz; i++) {\r\n        sb.append(\" \");\r\n        sb.append(catches.getType(i).toHuman());\r\n    }\r\n    return sb.toString();\r\n}"
}, {
	"Path": "org.apache.commons.cli.PatternOptionBuilder.isValueCode",
	"Comment": "returns whether ch is a value code, i.e.whether it represents a class in a pattern.",
	"Method": "boolean isValueCode(char ch){\r\n    return ch == '@' || ch == ':' || ch == '%' || ch == '+' || ch == '#' || ch == '<' || ch == '>' || ch == '*' || ch == '/' || ch == '!';\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.expiresAfterWriteNanos",
	"Comment": "returns how long after the last write to an entry the map will retain that entry.",
	"Method": "long expiresAfterWriteNanos(){\r\n    throw new UnsupportedOperationException();\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFClassifier.scaleWeights",
	"Comment": "scales the weights of this crfclassifier by the specified weight.",
	"Method": "void scaleWeights(double scale){\r\n    for (int i = 0; i < weights.length; i++) {\r\n        for (int j = 0; j < weights[i].length; j++) {\r\n            weights[i][j] *= scale;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.Async.getWhenSuccessful",
	"Comment": "returns the value when completed successfully or null if failed.",
	"Method": "V getWhenSuccessful(CompletableFuture<V> future){\r\n    try {\r\n        return (future == null) ? null : future.get();\r\n    } catch (InterruptedException e) {\r\n        Thread.currentThread().interrupt();\r\n        return null;\r\n    } catch (ExecutionException e) {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.SingletonPredictor.train",
	"Comment": "train the singleton predictor using a logistic regression classifier.",
	"Method": "LogisticClassifier<String, String> train(GeneralDataset<String, String> pDataset){\r\n    LogisticClassifierFactory<String, String> lcf = new LogisticClassifierFactory();\r\n    LogisticClassifier<String, String> classifier = lcf.trainClassifier(pDataset);\r\n    return classifier;\r\n}"
}, {
	"Path": "org.apereo.cas.services.RegisteredServiceAccessStrategy.getUnauthorizedRedirectUrl",
	"Comment": "redirect the request to a separate and possibly external urlin case authorization fails for this service. if no url isspecified, cas shall redirect the request by default to a genericpage that describes the authorization failed attempt.",
	"Method": "URI getUnauthorizedRedirectUrl(){\r\n    return null;\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.logProbabilityOfRVFDatum",
	"Comment": "returns a counter for the log probability of each of the classeslooking at the the sum of e^v for each count v, should be 1",
	"Method": "Counter<L> logProbabilityOfRVFDatum(RVFDatum<L, F> example){\r\n    Counter<L> scores = scoresOfRVFDatum(example);\r\n    Counters.logNormalizeInPlace(scores);\r\n    return scores;\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.storeArg",
	"Comment": "generates the instruction to store the top stack value in the givenmethod argument.",
	"Method": "void storeArg(int arg){\r\n    storeInsn(argumentTypes[arg], getArgIndex(arg));\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.principal.WebApplicationServiceFactory.newWebApplicationService",
	"Comment": "build new web application service simple web application service.",
	"Method": "AbstractWebApplicationService newWebApplicationService(HttpServletRequest request,String serviceToUse){\r\n    val artifactId = request != null ? request.getParameter(CasProtocolConstants.PARAMETER_TICKET) : null;\r\n    val id = cleanupUrl(serviceToUse);\r\n    val newService = new SimpleWebApplicationServiceImpl(id, serviceToUse, artifactId);\r\n    determineWebApplicationFormat(request, newService);\r\n    val source = getSourceParameter(request, CasProtocolConstants.PARAMETER_TARGET_SERVICE, CasProtocolConstants.PARAMETER_SERVICE);\r\n    newService.setSource(source);\r\n    return newService;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.calculate",
	"Comment": "calculates both value and partial derivatives at the point x, and save them internally.",
	"Method": "void calculate(double[] x){\r\n    to2D(x, weights);\r\n    setWeights(weights);\r\n    clear2D(E);\r\n    double prob = regularGradientAndValue();\r\n    if (Double.isNaN(prob)) {\r\n        throw new RuntimeException(\"Got NaN for prob in CRFLogConditionalObjectiveFunction.calculate()\" + \" - this may well indicate numeric underflow due to overly long documents.\");\r\n    }\r\n    value = -prob;\r\n    if (VERBOSE) {\r\n        log.info(\"value is \" + Math.exp(-value));\r\n    }\r\n    int index = 0;\r\n    for (int i = 0; i < E.length; i++) {\r\n        for (int j = 0; j < E[i].length; j++) {\r\n            derivative[index] = (E[i][j] - Ehat[i][j]);\r\n            if (VERBOSE) {\r\n                log.info(\"deriv(\" + i + \",\" + j + \") = \" + E[i][j] + \" - \" + Ehat[i][j] + \" = \" + derivative[index]);\r\n            }\r\n            index++;\r\n        }\r\n    }\r\n    applyPrior(x, 1.0);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.SingleConsumerQueue.transferOrCombine",
	"Comment": "attempts to receive a linked list from a waiting producer or transfer the specified linked listto an arriving producer.",
	"Method": "Node<E> transferOrCombine(Node<E> first,Node<E> last){\r\n    int index = index();\r\n    AtomicReference<Node<E>> slot = arena[index];\r\n    for (; ; ) {\r\n        Node<E> found = slot.get();\r\n        if (found == null) {\r\n            if (slot.compareAndSet(null, first)) {\r\n                for (int spin = 0; spin < SPINS; spin++) {\r\n                    if (slot.get() != first) {\r\n                        return null;\r\n                    }\r\n                }\r\n                return slot.compareAndSet(first, null) ? first : null;\r\n            }\r\n        } else if (slot.compareAndSet(found, null)) {\r\n            last.lazySetNext(found);\r\n            last = findLast(found);\r\n            for (int i = 1; i < ARENA_LENGTH; i++) {\r\n                slot = arena[(i + index) & ARENA_MASK];\r\n                found = slot.get();\r\n                if ((found != null) && slot.compareAndSet(found, null)) {\r\n                    last.lazySetNext(found);\r\n                    last = findLast(found);\r\n                }\r\n            }\r\n            return last;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.ner.CMMClassifier.loadDefaultClassifier",
	"Comment": "used to load the default supplied classifier.this functionwill only work if run inside a jar file",
	"Method": "void loadDefaultClassifier(){\r\n    loadClassifierNoExceptions(DEFAULT_CLASSIFIER, null);\r\n}"
}, {
	"Path": "org.objectweb.asm.ByteVector.put12",
	"Comment": "puts a byte and a short into this byte vector. the byte vector isautomatically enlarged if necessary.",
	"Method": "ByteVector put12(int b,int s){\r\n    int length = this.length;\r\n    if (length + 3 > data.length) {\r\n        enlarge(3);\r\n    }\r\n    byte[] data = this.data;\r\n    data[length++] = (byte) b;\r\n    data[length++] = (byte) (s >>> 8);\r\n    data[length++] = (byte) s;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.FrequencySketch.spread",
	"Comment": "applies a supplemental hash function to a given hashcode, which defends against poor qualityhash functions.",
	"Method": "int spread(int x){\r\n    x = ((x >>> 16) ^ x) * 0x45d9f3b;\r\n    x = ((x >>> 16) ^ x) * randomSeed;\r\n    return (x >>> 16) ^ x;\r\n}"
}, {
	"Path": "org.objectweb.asm.ByteVector.put11",
	"Comment": "puts two bytes into this byte vector. the byte vector is automaticallyenlarged if necessary.",
	"Method": "ByteVector put11(int b1,int b2){\r\n    int length = this.length;\r\n    if (length + 2 > data.length) {\r\n        enlarge(2);\r\n    }\r\n    byte[] data = this.data;\r\n    data[length++] = (byte) b1;\r\n    data[length++] = (byte) b2;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "org.apereo.cas.web.support.AbstractInMemoryThrottledSubmissionHandlerInterceptorAdapter.decrement",
	"Comment": "this class relies on an external configuration to clean it up.it ignores the threshold data in the parent class.",
	"Method": "void decrement(){\r\n    LOGGER.info(\"Beginning audit cleanup...\");\r\n    val now = ZonedDateTime.now(ZoneOffset.UTC);\r\n    this.ipMap.entrySet().removeIf(entry -> submissionRate(now, entry.getValue()) < getThresholdRate());\r\n    LOGGER.debug(\"Done decrementing count for throttler.\");\r\n}"
}, {
	"Path": "org.apereo.cas.services.RegisteredServiceAccessStrategyUtils.getRegisteredServiceExpirationPolicyPredicate",
	"Comment": "returns a predicate that determined whether a service has expired.",
	"Method": "Predicate<RegisteredService> getRegisteredServiceExpirationPolicyPredicate(){\r\n    return service -> {\r\n        try {\r\n            if (service == null) {\r\n                return false;\r\n            }\r\n            val policy = service.getExpirationPolicy();\r\n            if (policy == null || StringUtils.isBlank(policy.getExpirationDate())) {\r\n                return true;\r\n            }\r\n            val now = getCurrentSystemTime();\r\n            val expirationDate = DateTimeUtils.localDateTimeOf(policy.getExpirationDate());\r\n            LOGGER.debug(\"Service expiration date is [{}] while now is [{}]\", expirationDate, now);\r\n            return !now.isAfter(expirationDate);\r\n        } catch (final Exception e) {\r\n            LOGGER.warn(e.getMessage(), e);\r\n        }\r\n        return false;\r\n    };\r\n}"
}, {
	"Path": "com.android.dx.rop.annotation.Annotations.combine",
	"Comment": "constructs an immutable instance which is the combination of thetwo given instances. the two instances must contain disjoint setsof types.",
	"Method": "Annotations combine(Annotations a1,Annotations a2,Annotations combine,Annotations annotations,Annotation annotation){\r\n    Annotations result = new Annotations();\r\n    result.addAll(annotations);\r\n    result.add(annotation);\r\n    result.setImmutable();\r\n    return result;\r\n}"
}, {
	"Path": "org.apache.commons.cli.MissingOptionException.createMessage",
	"Comment": "build the exception message from the specified list of options.",
	"Method": "String createMessage(List<?> missingOptions){\r\n    StringBuilder buf = new StringBuilder(\"Missing required option\");\r\n    buf.append(missingOptions.size() == 1 ? \"\" : \"s\");\r\n    buf.append(\": \");\r\n    Iterator<?> it = missingOptions.iterator();\r\n    while (it.hasNext()) {\r\n        buf.append(it.next());\r\n        if (it.hasNext()) {\r\n            buf.append(\", \");\r\n        }\r\n    }\r\n    return buf.toString();\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.ExtractionSentence.getRelation",
	"Comment": "return the relation that holds between the given entities.return a relation of type unrelated if this sentence contains no relation between the entities.",
	"Method": "RelationMention getRelation(RelationMentionFactory factory,ExtractionObject args){\r\n    for (RelationMention rel : relationMentions) {\r\n        if (rel.argsMatch(args)) {\r\n            return rel;\r\n        }\r\n    }\r\n    return RelationMention.createUnrelatedRelation(factory, args);\r\n}"
}, {
	"Path": "com.android.dx.ssa.SCCP.simulatePhiBlock",
	"Comment": "simulate the phis in a block and note the results in the lattice.",
	"Method": "void simulatePhiBlock(SsaBasicBlock block){\r\n    for (SsaInsn insn : block.getInsns()) {\r\n        if (insn instanceof PhiInsn) {\r\n            simulatePhi((PhiInsn) insn);\r\n        } else {\r\n            return;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.impl.ConcurrentHashMapV7.putAll",
	"Comment": "copies all of the mappings from the specified map to this one.these mappings replace any mappings that this map had for any of thekeys currently in the specified map.",
	"Method": "void putAll(Map<? extends K, ? extends V> m){\r\n    for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {\r\n        put(e.getKey(), e.getValue());\r\n    }\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunctionWithDropout.calculate",
	"Comment": "calculates both value and partial derivatives at the point x, and save them internally.",
	"Method": "void calculate(double[] x){\r\n    double prob = 0.0;\r\n    to2D(x, weights);\r\n    setWeights(weights);\r\n    clear2D(E);\r\n    clear2D(dropoutPriorGradTotal);\r\n    MulticoreWrapper<Pair<Integer, Boolean>, Quadruple<Integer, Double, Map<Integer, double[]>, Map<Integer, double[]>>> wrapper = new MulticoreWrapper(multiThreadGrad, dropoutPriorThreadProcessor);\r\n    for (int m = 0; m < totalData.length; m++) {\r\n        boolean submitIsUnsup = (m >= unsupDropoutStartIndex);\r\n        wrapper.put(new Pair(m, submitIsUnsup));\r\n        while (wrapper.peek()) {\r\n            Quadruple<Integer, Double, Map<Integer, double[]>, Map<Integer, double[]>> result = wrapper.poll();\r\n            int docIndex = result.first();\r\n            boolean isUnsup = docIndex >= unsupDropoutStartIndex;\r\n            if (isUnsup) {\r\n                prob += unsupDropoutScale * result.second();\r\n            } else {\r\n                prob += result.second();\r\n            }\r\n            Map<Integer, double[]> partialDropout = result.fourth();\r\n            if (partialDropout != null) {\r\n                if (isUnsup) {\r\n                    combine2DArr(dropoutPriorGradTotal, partialDropout, unsupDropoutScale);\r\n                } else {\r\n                    combine2DArr(dropoutPriorGradTotal, partialDropout);\r\n                }\r\n            }\r\n            if (!isUnsup) {\r\n                Map<Integer, double[]> partialE = result.third();\r\n                if (partialE != null)\r\n                    combine2DArr(E, partialE);\r\n            }\r\n        }\r\n    }\r\n    wrapper.join();\r\n    while (wrapper.peek()) {\r\n        Quadruple<Integer, Double, Map<Integer, double[]>, Map<Integer, double[]>> result = wrapper.poll();\r\n        int docIndex = result.first();\r\n        boolean isUnsup = docIndex >= unsupDropoutStartIndex;\r\n        if (isUnsup) {\r\n            prob += unsupDropoutScale * result.second();\r\n        } else {\r\n            prob += result.second();\r\n        }\r\n        Map<Integer, double[]> partialDropout = result.fourth();\r\n        if (partialDropout != null) {\r\n            if (isUnsup) {\r\n                combine2DArr(dropoutPriorGradTotal, partialDropout, unsupDropoutScale);\r\n            } else {\r\n                combine2DArr(dropoutPriorGradTotal, partialDropout);\r\n            }\r\n        }\r\n        if (!isUnsup) {\r\n            Map<Integer, double[]> partialE = result.third();\r\n            if (partialE != null)\r\n                combine2DArr(E, partialE);\r\n        }\r\n    }\r\n    if (Double.isNaN(prob)) {\r\n        throw new RuntimeException(\"Got NaN for prob in CRFLogConditionalObjectiveFunctionWithDropout.calculate()\" + \" - this may well indicate numeric underflow due to overly long documents.\");\r\n    }\r\n    value = -prob;\r\n    if (VERBOSE) {\r\n        log.info(\"value is \" + Math.exp(-value));\r\n    }\r\n    int index = 0;\r\n    for (int i = 0; i < E.length; i++) {\r\n        for (int j = 0; j < E[i].length; j++) {\r\n            derivative[index] = (E[i][j] - Ehat[i][j]);\r\n            derivative[index] += dropoutScale * dropoutPriorGradTotal[i][j];\r\n            if (VERBOSE) {\r\n                log.info(\"deriv(\" + i + ',' + j + \") = \" + E[i][j] + \" - \" + Ehat[i][j] + \" = \" + derivative[index]);\r\n            }\r\n            index++;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.DoubleMetaphone.isDoubleMetaphoneEqual",
	"Comment": "check if the double metaphone values of two string valuesare equal, optionally using the alternate value.",
	"Method": "boolean isDoubleMetaphoneEqual(String value1,String value2,boolean isDoubleMetaphoneEqual,String value1,String value2,boolean alternate){\r\n    return StringUtils.equals(doubleMetaphone(value1, alternate), doubleMetaphone(value2, alternate));\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.ColumnDataClassifier.testExamples",
	"Comment": "test and evaluate classifier on examples with their string representation and gold classification available.",
	"Method": "Pair<Double, Double> testExamples(Classifier<String, String> cl,GeneralDataset<String, String> test,List<String[]> lineInfos){\r\n    if (!(globalFlags.crossValidationFolds > 0 && !globalFlags.printCrossValidationDecisions)) {\r\n        String message = \"\";\r\n        if (globalFlags.csvOutput != null) {\r\n            message += formatCsv(globalFlags.csvOutput, storedHeader.split(\"\\t\"), null);\r\n        } else {\r\n            message += \"Output format: \";\r\n            if (globalFlags.displayedColumn >= 0) {\r\n                message += \"dataColumn\" + globalFlags.displayedColumn + '\\t';\r\n            }\r\n            message += \"goldAnswer\\t\";\r\n            if (globalFlags.displayAllAnswers) {\r\n                logger.info(message + \"[P(class) class]+ {sorted by probability}\");\r\n            } else {\r\n                logger.info(message + \"classifierAnswer\\tP(clAnswer)\\tP(goldAnswer)\");\r\n            }\r\n        }\r\n    }\r\n    Counter<String> contingency = new ClassicCounter();\r\n    for (int i = 0, sz = test.size(); i < sz; i++) {\r\n        testExample(cl, test, lineInfos, contingency, i);\r\n    }\r\n    if (globalFlags.groupingColumn >= 0 && globalFlags.rankingAccuracyClass != null)\r\n        finishRanking(contingency, bestSim);\r\n    return writeResultsSummary(test.size(), contingency, cl.labels());\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.notification.BuckNotification.showInfoBalloon",
	"Comment": "show an info balloon with the given message and attach the given listener.",
	"Method": "void showInfoBalloon(String message,NotificationListener listener){\r\n    NOTIFICATION_GROUP.createNotification(\"\", message, NotificationType.INFORMATION, listener).notify(project);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.configuration.TypesafeConfigurator.cacheNames",
	"Comment": "retrieves the names of the caches defined in the configuration resource.",
	"Method": "Set<String> cacheNames(Config config){\r\n    return config.hasPath(\"caffeine.jcache\") ? Collections.unmodifiableSet(config.getObject(\"caffeine.jcache\").keySet()) : Collections.emptySet();\r\n}"
}, {
	"Path": "com.android.dx.rop.code.BasicBlock.hasExceptionHandlers",
	"Comment": "returns whether this block has any associated exception handlers.this is just a shorthand for inspecting the last instruction inthe block to see if it could throw, and if so, whether it in facthas any associated handlers.",
	"Method": "boolean hasExceptionHandlers(){\r\n    Insn lastInsn = insns.getLast();\r\n    return lastInsn.getCatches().size() != 0;\r\n}"
}, {
	"Path": "com.android.dx.ssa.EscapeAnalysis.processMoveResultPseudoInsn",
	"Comment": "determine the origin of a move result pseudo instruction that generatesan object. creates a new escapeset for the new object accordingly.",
	"Method": "EscapeSet processMoveResultPseudoInsn(SsaInsn insn){\r\n    RegisterSpec result = insn.getResult();\r\n    SsaInsn prevSsaInsn = getInsnForMove(insn);\r\n    int prevOpcode = prevSsaInsn.getOpcode().getOpcode();\r\n    EscapeSet escSet;\r\n    RegisterSpec prevSource;\r\n    switch(prevOpcode) {\r\n        case RegOps.NEW_INSTANCE:\r\n        case RegOps.CONST:\r\n            escSet = new EscapeSet(result.getReg(), regCount, EscapeState.NONE);\r\n            break;\r\n        case RegOps.NEW_ARRAY:\r\n        case RegOps.FILLED_NEW_ARRAY:\r\n            prevSource = prevSsaInsn.getSources().get(0);\r\n            if (prevSource.getTypeBearer().isConstant()) {\r\n                escSet = new EscapeSet(result.getReg(), regCount, EscapeState.NONE);\r\n                escSet.replaceableArray = true;\r\n            } else {\r\n                escSet = new EscapeSet(result.getReg(), regCount, EscapeState.GLOBAL);\r\n            }\r\n            break;\r\n        case RegOps.GET_STATIC:\r\n            escSet = new EscapeSet(result.getReg(), regCount, EscapeState.GLOBAL);\r\n            break;\r\n        case RegOps.CHECK_CAST:\r\n        case RegOps.GET_FIELD:\r\n        case RegOps.AGET:\r\n            prevSource = prevSsaInsn.getSources().get(0);\r\n            int setIndex = findSetIndex(prevSource);\r\n            if (setIndex != latticeValues.size()) {\r\n                escSet = latticeValues.get(setIndex);\r\n                escSet.regSet.set(result.getReg());\r\n                return escSet;\r\n            }\r\n            if (prevSource.getType() == Type.KNOWN_NULL) {\r\n                escSet = new EscapeSet(result.getReg(), regCount, EscapeState.NONE);\r\n            } else {\r\n                escSet = new EscapeSet(result.getReg(), regCount, EscapeState.GLOBAL);\r\n            }\r\n            break;\r\n        default:\r\n            return null;\r\n    }\r\n    latticeValues.add(escSet);\r\n    return escSet;\r\n}"
}, {
	"Path": "org.apereo.cas.ticket.proxy.ProxyHandler.canHandle",
	"Comment": "whether this handler can support the proxy request identified by the given credentials.",
	"Method": "boolean canHandle(Credential credential){\r\n    return true;\r\n}"
}, {
	"Path": "org.apache.commons.codec.binary.Hex.encodeHexString",
	"Comment": "converts a byte buffer into a string representing the hexadecimal values of each byte in order. the returnedstring will be double the length of the passed array, as it takes two characters to represent any given byte.",
	"Method": "String encodeHexString(byte[] data,String encodeHexString,ByteBuffer data){\r\n    return new String(encodeHex(data));\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.SerialVersionUIDAdder.hasSVUID",
	"Comment": "returns true if the class already has a svuid field. the result of thismethod is only valid when visitend is or has been called.",
	"Method": "boolean hasSVUID(){\r\n    return hasSVUID;\r\n}"
}, {
	"Path": "edu.stanford.nlp.pipeline.RegexNERAnnotatorITest.testPriority",
	"Comment": "in the mapping file, christianity is assigned a higher priority than early christianity,and so early should not be marked as religion.",
	"Method": "void testPriority(){\r\n    String str = \"Christianity is of higher regex priority than Early Christianity . \";\r\n    String[] split = str.split(\" \");\r\n    List<CoreLabel> tokens = SentenceUtils.toCoreLabelList(split);\r\n    CoreMap sentence = new ArrayCoreMap();\r\n    sentence.set(CoreAnnotations.TokensAnnotation.class, tokens);\r\n    List<CoreMap> sentences = new ArrayList();\r\n    sentences.add(sentence);\r\n    Annotation corpus = new Annotation(\"Christianity is of higher regex priority than Early \" + \"Christianity. \");\r\n    corpus.set(CoreAnnotations.SentencesAnnotation.class, sentences);\r\n    annotator.annotate(corpus);\r\n    checkTags(tokens, \"RELIGION\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"RELIGION\", \"O\");\r\n}"
}, {
	"Path": "com.facebook.buck.tools.documentation.generator.skylark.rendering.SoyTemplateSkylarkSignatureRenderer.renderTableOfContents",
	"Comment": "renders a table of contents for the skylark functions subsection on buckbuild.com website.",
	"Method": "String renderTableOfContents(Iterable<SkylarkCallable> signatures){\r\n    ST stringTemplate = createTemplate(TABLE_OF_CONTENTS_TEMPLATE_NAME);\r\n    stringTemplate.add(\"openCurly\", \"{\");\r\n    stringTemplate.add(\"closeCurly\", \"}\");\r\n    stringTemplate.add(\"signatures\", Streams.stream(signatures).sorted(Comparator.comparing(SkylarkCallable::name)).map(SoyTemplateSkylarkSignatureRenderer::toMap).collect(Collectors.toList()));\r\n    return stringTemplate.render();\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.Span.union",
	"Comment": "the union of two spans. that is, the minimal span that contains both.",
	"Method": "Span union(Span a,Span b){\r\n    return Span.fromValues(Math.min(a.start, b.start), Math.max(a.end, b.end));\r\n}"
}, {
	"Path": "org.apache.commons.cli.OptionBuilder.withArgName",
	"Comment": "the next option created will have the specified argument value name.",
	"Method": "OptionBuilder withArgName(String name){\r\n    OptionBuilder.argName = name;\r\n    return INSTANCE;\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.MultifactorAuthenticationCredential.getProviderId",
	"Comment": "returns the unique id of the provider that created the credential.",
	"Method": "String getProviderId(){\r\n    return null;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.BoundedLocalCache.expiresAfterAccess",
	"Comment": "returns if the cache expires entries after an access time threshold.",
	"Method": "boolean expiresAfterAccess(){\r\n    return false;\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.util.FileFinder.getOptionalFile",
	"Comment": "tries to find a file with one of a number of possible names in a search path.",
	"Method": "Optional<Path> getOptionalFile(String name,Iterable<Path> searchPath,Optional<Path> getOptionalFile,String name,Iterable<Path> searchPath,Function<Path, Boolean> filter,Optional<Path> getOptionalFile,Set<String> possibleNames,Iterable<Path> searchPath,Optional<Path> getOptionalFile,Set<String> possibleNames,Iterable<Path> searchPath,Function<Path, Boolean> filter){\r\n    for (Path path : searchPath) {\r\n        for (String filename : possibleNames) {\r\n            Path resolved = path.resolve(filename);\r\n            if (filter.apply(resolved)) {\r\n                return Optional.of(resolved);\r\n            }\r\n        }\r\n    }\r\n    return Optional.empty();\r\n}"
}, {
	"Path": "org.objectweb.asm.TypeReference.newTypeParameterBoundReference",
	"Comment": "returns a reference to a type parameter bound of a generic class ormethod.",
	"Method": "TypeReference newTypeParameterBoundReference(int sort,int paramIndex,int boundIndex){\r\n    return new TypeReference((sort << 24) | (paramIndex << 16) | (boundIndex << 8));\r\n}"
}, {
	"Path": "edu.stanford.nlp.dcoref.SieveCoreferenceSystem.printLinkWithContext",
	"Comment": "print a coref link information including context and parse tree",
	"Method": "void printLinkWithContext(Logger logger,String header,IntTuple src,IntTuple dst,Document document,Semantics semantics){\r\n    List<List<Mention>> orderedMentionsBySentence = document.getOrderedMentions();\r\n    List<List<Mention>> goldOrderedMentionsBySentence = document.goldOrderedMentionsBySentence;\r\n    Mention srcMention = orderedMentionsBySentence.get(src.get(0)).get(src.get(1));\r\n    Mention dstMention = orderedMentionsBySentence.get(dst.get(0)).get(dst.get(1));\r\n    List<CoreLabel> srcSentence = srcMention.sentenceWords;\r\n    List<CoreLabel> dstSentence = dstMention.sentenceWords;\r\n    printLink(logger, header, src, dst, orderedMentionsBySentence);\r\n    printList(logger, \"Mention:\" + srcMention.spanToString(), \"Gender:\" + srcMention.gender.toString(), \"Number:\" + srcMention.number.toString(), \"Animacy:\" + srcMention.animacy.toString(), \"Person:\" + srcMention.person.toString(), \"NER:\" + srcMention.nerString, \"Head:\" + srcMention.headString, \"Type:\" + srcMention.mentionType.toString(), \"utter: \" + srcMention.headWord.get(CoreAnnotations.UtteranceAnnotation.class), \"speakerID: \" + srcMention.headWord.get(CoreAnnotations.SpeakerAnnotation.class), \"twinless:\" + srcMention.twinless);\r\n    logger.fine(\"Context:\");\r\n    String p = \"\";\r\n    for (int i = 0; i < srcSentence.size(); i++) {\r\n        if (i == srcMention.startIndex) {\r\n            p += \"[\";\r\n        }\r\n        if (i == srcMention.endIndex) {\r\n            p += \"]\";\r\n        }\r\n        p += srcSentence.get(i).word() + \" \";\r\n    }\r\n    logger.fine(p);\r\n    StringBuilder golds = new StringBuilder();\r\n    golds.append(\"Gold mentions in the sentence:\\n\");\r\n    Counter<Integer> mBegin = new ClassicCounter();\r\n    Counter<Integer> mEnd = new ClassicCounter();\r\n    for (Mention m : goldOrderedMentionsBySentence.get(src.get(0))) {\r\n        mBegin.incrementCount(m.startIndex);\r\n        mEnd.incrementCount(m.endIndex);\r\n    }\r\n    List<CoreLabel> l = document.annotation.get(CoreAnnotations.SentencesAnnotation.class).get(src.get(0)).get(CoreAnnotations.TokensAnnotation.class);\r\n    for (int i = 0; i < l.size(); i++) {\r\n        for (int j = 0; j < mEnd.getCount(i); j++) {\r\n            golds.append(\"]\");\r\n        }\r\n        for (int j = 0; j < mBegin.getCount(i); j++) {\r\n            golds.append(\"[\");\r\n        }\r\n        golds.append(l.get(i).get(CoreAnnotations.TextAnnotation.class));\r\n        golds.append(\" \");\r\n    }\r\n    logger.fine(golds.toString());\r\n    printList(logger, \"\\nAntecedent:\" + dstMention.spanToString(), \"Gender:\" + dstMention.gender.toString(), \"Number:\" + dstMention.number.toString(), \"Animacy:\" + dstMention.animacy.toString(), \"Person:\" + dstMention.person.toString(), \"NER:\" + dstMention.nerString, \"Head:\" + dstMention.headString, \"Type:\" + dstMention.mentionType.toString(), \"utter: \" + dstMention.headWord.get(CoreAnnotations.UtteranceAnnotation.class), \"speakerID: \" + dstMention.headWord.get(CoreAnnotations.SpeakerAnnotation.class), \"twinless:\" + dstMention.twinless);\r\n    logger.fine(\"Context:\");\r\n    p = \"\";\r\n    for (int i = 0; i < dstSentence.size(); i++) {\r\n        if (i == dstMention.startIndex) {\r\n            p += \"[\";\r\n        }\r\n        if (i == dstMention.endIndex) {\r\n            p += \"]\";\r\n        }\r\n        p += dstSentence.get(i).word() + \" \";\r\n    }\r\n    logger.fine(p);\r\n    golds = new StringBuilder();\r\n    golds.append(\"Gold mentions in the sentence:\\n\");\r\n    mBegin = new ClassicCounter();\r\n    mEnd = new ClassicCounter();\r\n    for (Mention m : goldOrderedMentionsBySentence.get(dst.get(0))) {\r\n        mBegin.incrementCount(m.startIndex);\r\n        mEnd.incrementCount(m.endIndex);\r\n    }\r\n    l = document.annotation.get(CoreAnnotations.SentencesAnnotation.class).get(dst.get(0)).get(CoreAnnotations.TokensAnnotation.class);\r\n    for (int i = 0; i < l.size(); i++) {\r\n        for (int j = 0; j < mEnd.getCount(i); j++) {\r\n            golds.append(\"]\");\r\n        }\r\n        for (int j = 0; j < mBegin.getCount(i); j++) {\r\n            golds.append(\"[\");\r\n        }\r\n        golds.append(l.get(i).get(CoreAnnotations.TextAnnotation.class));\r\n        golds.append(\" \");\r\n    }\r\n    logger.fine(golds.toString());\r\n    logger.finer(\"\\nMention:: --------------------------------------------------------\");\r\n    try {\r\n        logger.finer(srcMention.dependency.toString());\r\n    } catch (Exception e) {\r\n    }\r\n    logger.finer(\"Parse:\");\r\n    logger.finer(formatPennTree(srcMention.contextParseTree));\r\n    logger.finer(\"\\nAntecedent:: -----------------------------------------------------\");\r\n    try {\r\n        logger.finer(dstMention.dependency.toString());\r\n    } catch (Exception e) {\r\n    }\r\n    logger.finer(\"Parse:\");\r\n    logger.finer(formatPennTree(dstMention.contextParseTree));\r\n}"
}, {
	"Path": "com.android.dx.util.ByteArray.underlyingOffset",
	"Comment": "returns the offset into the given array represented by the givenoffset into this instance.",
	"Method": "int underlyingOffset(int offset,byte[] bytes){\r\n    if (bytes != this.bytes) {\r\n        throw new IllegalArgumentException(\"wrong bytes\");\r\n    }\r\n    return start + offset;\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.GeneratorAdapter.storeInsn",
	"Comment": "generates the instruction to store the top stack value in a localvariable.",
	"Method": "void storeInsn(Type type,int index){\r\n    mv.visitVarInsn(type.getOpcode(Opcodes.ISTORE), index);\r\n}"
}, {
	"Path": "com.android.dx.ssa.LocalVariableInfo.getStarts0",
	"Comment": "helper method, to get the starts for a index, throwing theright exception for range problems.",
	"Method": "RegisterSpecSet getStarts0(int index){\r\n    try {\r\n        return blockStarts[index];\r\n    } catch (ArrayIndexOutOfBoundsException ex) {\r\n        throw new IllegalArgumentException(\"bogus index\");\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.product.ExpiringMapPolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new ExpiringMapPolicy(config));\r\n}"
}, {
	"Path": "com.android.dx.ssa.LocalVariableExtractor.extract",
	"Comment": "extracts out all the local variable information from the given method.",
	"Method": "LocalVariableInfo extract(SsaMethod method){\r\n    LocalVariableExtractor lve = new LocalVariableExtractor(method);\r\n    return lve.doit();\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken.loadProximityClasses",
	"Comment": "loads all proximity classes from the hard disk the words map must becreated before!",
	"Method": "void loadProximityClasses(String proxFileName){\r\n    log.info(\"Loading proximity classes...\");\r\n    BufferedReader in = null;\r\n    try {\r\n        in = new BufferedReader(new FileReader(proxFileName));\r\n    } catch (java.io.IOException e) {\r\n        log.info(\"Warning: no proximity database found.\");\r\n        return;\r\n    }\r\n    String line;\r\n    while ((line = in.readLine()) != null) {\r\n        ArrayList<String> tokens = SimpleTokenize.tokenize(line);\r\n        if (tokens.size() > 0) {\r\n            Integer key = WORDS.get(tokens.get(0));\r\n            ArrayList<Integer> value = new ArrayList();\r\n            for (int i = 0; i < tokens.size() && i < PROXIMITY_CLASS_SIZE; i++) {\r\n                Integer word = WORDS.get(tokens.get(i));\r\n                value.add(word);\r\n            }\r\n            PROX_CLASSES.put(key, value);\r\n        }\r\n    }\r\n    in.close();\r\n    log.info(\"Finished loading proximity classes.\");\r\n}"
}, {
	"Path": "org.objectweb.asm.commons.Method.getArgumentTypes",
	"Comment": "returns the argument types of the method described by this object.",
	"Method": "Type[] getArgumentTypes(){\r\n    return Type.getArgumentTypes(desc);\r\n}"
}, {
	"Path": "org.apereo.cas.web.support.WebUtils.getHttpServletResponseFromExternalWebflowContext",
	"Comment": "gets the http servlet response from the current servlet context.",
	"Method": "HttpServletResponse getHttpServletResponseFromExternalWebflowContext(RequestContext context,HttpServletResponse getHttpServletResponseFromExternalWebflowContext){\r\n    val servletExternalContext = (ServletExternalContext) ExternalContextHolder.getExternalContext();\r\n    if (servletExternalContext != null) {\r\n        return (HttpServletResponse) servletExternalContext.getNativeResponse();\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.LabelDictionary.lock",
	"Comment": "setup the constrained label sets and free bookkeeping resources.",
	"Method": "void lock(int threshold,Index<String> labelIndex){\r\n    if (labelDictionary != null)\r\n        throw new RuntimeException(\"Label dictionary is already locked\");\r\n    log.info(\"Label dictionary enabled\");\r\n    System.err.printf(\"#observations: %d%n\", (int) observationCounts.totalCount());\r\n    Counters.retainAbove(observationCounts, threshold);\r\n    Set<String> constrainedObservations = observationCounts.keySet();\r\n    labelDictionary = new int[constrainedObservations.size()][];\r\n    observationIndex = new HashIndex(constrainedObservations.size());\r\n    for (String observation : constrainedObservations) {\r\n        int i = observationIndex.addToIndex(observation);\r\n        assert i < labelDictionary.length;\r\n        Set<String> allowedLabels = observedLabels.get(observation);\r\n        labelDictionary[i] = new int[allowedLabels.size()];\r\n        int j = 0;\r\n        for (String label : allowedLabels) {\r\n            labelDictionary[i][j++] = labelIndex.indexOf(label);\r\n        }\r\n        if (DEBUG) {\r\n            System.err.printf(\"%s : %s%n\", observation, allowedLabels.toString());\r\n        }\r\n    }\r\n    observationIndex.lock();\r\n    System.err.printf(\"#constraints: %d%n\", labelDictionary.length);\r\n    observationCounts = null;\r\n    observedLabels = null;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFLogConditionalObjectiveFunction.domainDimension",
	"Comment": "this used to be computed lazily, but that was clearly erroneous for multithreading!",
	"Method": "int domainDimension(){\r\n    return domainDimension;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.CacheGenerator.filterTypes",
	"Comment": "returns the set of options filtered if a specific type is specified.",
	"Method": "Set<T> filterTypes(Optional<T> type,T[] options){\r\n    if (type.isPresent()) {\r\n        return type.filter(Arrays.asList(options)::contains).isPresent() ? ImmutableSet.of(type.get()) : ImmutableSet.of();\r\n    }\r\n    return ImmutableSet.copyOf(Arrays.asList(options));\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.LocalCache.statsAware",
	"Comment": "decorates the remapping function to record statistics if enabled.",
	"Method": "Function<? super K, ? extends V> statsAware(Function<? super K, ? extends V> mappingFunction,boolean recordLoad,BiFunction<? super T, ? super U, ? extends R> statsAware,BiFunction<? super T, ? super U, ? extends R> remappingFunction,BiFunction<? super T, ? super U, ? extends R> statsAware,BiFunction<? super T, ? super U, ? extends R> remappingFunction,boolean recordMiss,boolean recordLoad){\r\n    if (!isRecordingStats()) {\r\n        return remappingFunction;\r\n    }\r\n    return (t, u) -> {\r\n        R result;\r\n        if ((u == null) && recordMiss) {\r\n            statsCounter().recordMisses(1);\r\n        }\r\n        long startTime = statsTicker().read();\r\n        try {\r\n            result = remappingFunction.apply(t, u);\r\n        } catch (RuntimeException | Error e) {\r\n            statsCounter().recordLoadFailure(statsTicker().read() - startTime);\r\n            throw e;\r\n        }\r\n        long loadTime = statsTicker().read() - startTime;\r\n        if (recordLoad) {\r\n            if (result == null) {\r\n                statsCounter().recordLoadFailure(loadTime);\r\n            } else {\r\n                statsCounter().recordLoadSuccess(loadTime);\r\n            }\r\n        }\r\n        return result;\r\n    };\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.BeiderMorseEncoder.setMaxPhonemes",
	"Comment": "sets the number of maximum of phonemes that shall be considered by the engine.",
	"Method": "void setMaxPhonemes(int maxPhonemes){\r\n    this.engine = new PhoneticEngine(this.engine.getNameType(), this.engine.getRuleType(), this.engine.isConcat(), maxPhonemes);\r\n}"
}, {
	"Path": "org.objectweb.asm.ClassWriter.newInteger",
	"Comment": "adds an integer to the constant pool of the class being build. doesnothing if the constant pool already contains a similar item.",
	"Method": "Item newInteger(int value){\r\n    key.set(value);\r\n    Item result = get(key);\r\n    if (result == null) {\r\n        pool.putByte(INT).putInt(value);\r\n        result = new Item(index++, key);\r\n        put(result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.CRFCliqueTree.condLogProbGivenPrevious",
	"Comment": "gives the probability of a tag at a single position conditioned on asequence of previous labels.",
	"Method": "double condLogProbGivenPrevious(int position,int label,int[] prevLabels,double condLogProbGivenPrevious,int position,E label,E[] prevLabels){\r\n    return condLogProbGivenPrevious(position, classIndex.indexOf(label), objectArrayToIntArray(prevLabels));\r\n}"
}, {
	"Path": "org.apereo.cas.support.saml.web.idp.profile.builders.enc.SamlIdPObjectSigner.encode",
	"Comment": "encode a given saml object by invoking a number of outbound security handlers on the context.",
	"Method": "T encode(T samlObject,SamlRegisteredService service,SamlRegisteredServiceServiceProviderMetadataFacade adaptor,HttpServletResponse response,HttpServletRequest request,String binding,RequestAbstractType authnRequest){\r\n    LOGGER.trace(\"Attempting to encode [{}] for [{}]\", samlObject.getClass().getName(), adaptor.getEntityId());\r\n    val outboundContext = new MessageContext<T>();\r\n    prepareOutboundContext(samlObject, adaptor, outboundContext, binding, authnRequest);\r\n    prepareSecurityParametersContext(adaptor, outboundContext, service);\r\n    prepareEndpointURLSchemeSecurityHandler(outboundContext);\r\n    prepareSamlOutboundDestinationHandler(outboundContext);\r\n    prepareSamlOutboundProtocolMessageSigningHandler(outboundContext);\r\n    return samlObject;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.sketch.feedback.FeedbackTinyLfuPolicy.evict",
	"Comment": "if the size exceeds the maximum, then the candidate and victim are evaluated and one isevicted.",
	"Method": "void evict(Node candidate){\r\n    if (data.size() > maximumSize) {\r\n        Node evict;\r\n        Node victim = head.next;\r\n        if (admittor.admit(candidate.key, victim.key)) {\r\n            evict = victim;\r\n        } else if (adapt(candidate)) {\r\n            evict = victim;\r\n        } else {\r\n            evict = candidate;\r\n            feedback.put(candidate.key);\r\n        }\r\n        data.remove(evict.key);\r\n        evict.remove();\r\n        policyStats.recordEviction();\r\n    }\r\n}"
}, {
	"Path": "org.apereo.cas.authentication.LdapAuthenticationHandler.initialize",
	"Comment": "initialize the handler, setup the authentication entry attributes.",
	"Method": "void initialize(){\r\n    val attributes = new HashSet<String>();\r\n    LOGGER.debug(\"Initializing LDAP attribute configuration...\");\r\n    if (StringUtils.isNotBlank(this.principalIdAttribute)) {\r\n        LOGGER.debug(\"Configured to retrieve principal id attribute [{}]\", this.principalIdAttribute);\r\n        attributes.add(this.principalIdAttribute);\r\n    }\r\n    if (this.principalAttributeMap != null && !this.principalAttributeMap.isEmpty()) {\r\n        val attrs = this.principalAttributeMap.keySet();\r\n        attributes.addAll(attrs);\r\n        LOGGER.debug(\"Configured to retrieve principal attribute collection of [{}]\", attrs);\r\n    }\r\n    if (authenticator.getReturnAttributes() != null) {\r\n        val authenticatorAttributes = CollectionUtils.wrapList(authenticator.getReturnAttributes());\r\n        if (!authenticatorAttributes.isEmpty()) {\r\n            LOGGER.debug(\"Filtering authentication entry attributes [{}] based on authenticator attributes [{}]\", authenticatedEntryAttributes, authenticatorAttributes);\r\n            attributes.removeIf(authenticatorAttributes::contains);\r\n        }\r\n    }\r\n    this.authenticatedEntryAttributes = attributes.toArray(ArrayUtils.EMPTY_STRING_ARRAY);\r\n    LOGGER.debug(\"LDAP authentication entry attributes for the authentication request are [{}]\", (Object[]) this.authenticatedEntryAttributes);\r\n}"
}, {
	"Path": "com.android.dx.ssa.SsaBasicBlock.removeAllPhiInsns",
	"Comment": "deletes all phi insns. do this after adding appropriate move insns.",
	"Method": "void removeAllPhiInsns(){\r\n    insns.subList(0, getCountPhiInsns()).clear();\r\n}"
}, {
	"Path": "org.apereo.cas.logging.web.LoggingConfigurationEndpoint.initialize",
	"Comment": "init. attempts to locate the logging configuration to insert listeners.the log configuration location is pulled directly from the environmentgiven there is not an explicit property mapping for it provided by boot, etc.",
	"Method": "void initialize(){\r\n    val pair = buildLoggerContext(environment, resourceLoader);\r\n    pair.ifPresent(it -> {\r\n        this.logConfigurationFile = it.getKey();\r\n        this.loggerContext = it.getValue();\r\n    });\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.ner.CMMClassifier.classOf",
	"Comment": "returns the most likely class for the word at the given position.",
	"Method": "String classOf(List<IN> lineInfos,int pos){\r\n    Datum<String, String> d = makeDatum(lineInfos, pos, featureFactories);\r\n    return classifier.classOf(d);\r\n}"
}, {
	"Path": "com.android.dx.ssa.LiteralOpUpgrader.tryReplacingWithConstant",
	"Comment": "tries to replace an instruction with a const instruction. the giveninstruction must have a constant result for it to be replaced.",
	"Method": "boolean tryReplacingWithConstant(NormalSsaInsn insn){\r\n    Insn originalRopInsn = insn.getOriginalRopInsn();\r\n    Rop opcode = originalRopInsn.getOpcode();\r\n    RegisterSpec result = insn.getResult();\r\n    if (result != null && !ssaMeth.isRegALocal(result) && opcode.getOpcode() != RegOps.CONST) {\r\n        TypeBearer type = insn.getResult().getTypeBearer();\r\n        if (type.isConstant() && type.getBasicType() == Type.BT_INT) {\r\n            replacePlainInsn(insn, RegisterSpecList.EMPTY, RegOps.CONST, (Constant) type);\r\n            if (opcode.getOpcode() == RegOps.MOVE_RESULT_PSEUDO) {\r\n                int pred = insn.getBlock().getPredecessors().nextSetBit(0);\r\n                ArrayList<SsaInsn> predInsns = ssaMeth.getBlocks().get(pred).getInsns();\r\n                NormalSsaInsn sourceInsn = (NormalSsaInsn) predInsns.get(predInsns.size() - 1);\r\n                replacePlainInsn(sourceInsn, RegisterSpecList.EMPTY, RegOps.GOTO, null);\r\n            }\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.apache.commons.codec.language.bm.Rule.getInstance",
	"Comment": "gets rules for a combination of name type, rule type and a single language.",
	"Method": "List<Rule> getInstance(NameType nameType,RuleType rt,Languages.LanguageSet langs,List<Rule> getInstance,NameType nameType,RuleType rt,String lang){\r\n    return getInstance(nameType, rt, LanguageSet.from(new HashSet<String>(Arrays.asList(lang))));\r\n}"
}, {
	"Path": "org.apereo.cas.services.CouchbaseServiceRegistry.destroy",
	"Comment": "stops the couchbase client and cancels the initialization task if uncompleted.",
	"Method": "void destroy(){\r\n    this.couchbase.shutdown();\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.LinearClassifier.getTopFeatures",
	"Comment": "returns list of top features with weight above a certain threshold",
	"Method": "List<Triple<F, L, Double>> getTopFeatures(double threshold,boolean useMagnitude,int numFeatures,List<Triple<F, L, Double>> getTopFeatures,Set<L> labels,double threshold,boolean useMagnitude,int numFeatures,boolean descending){\r\n    if (labels != null) {\r\n        Set<Integer> iLabels = getLabelIndices(labels);\r\n        return getTopFeaturesLabelIndices(iLabels, threshold, useMagnitude, numFeatures, descending);\r\n    } else {\r\n        return getTopFeaturesLabelIndices(null, threshold, useMagnitude, numFeatures, descending);\r\n    }\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.linked.FrequentlyUsedPolicy.onMiss",
	"Comment": "adds the entry, creating an initial frequency list of 1 if necessary, and evicts if needed.",
	"Method": "void onMiss(long key){\r\n    FrequencyNode freq1 = (freq0.next.count == 1) ? freq0.next : new FrequencyNode(1, freq0);\r\n    Node node = new Node(key, freq1);\r\n    policyStats.recordMiss();\r\n    data.put(key, node);\r\n    node.append();\r\n    evict(node);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.Expirable.getExpireTimeMS",
	"Comment": "returns the time, in milliseconds, when the value will expire.",
	"Method": "long getExpireTimeMS(){\r\n    return expireTimeMS;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.machinereading.structure.ExtractionObject.getFullValue",
	"Comment": "always returns the text corresponding to the extent of this object, even whengetvalue is overridden by subclass.",
	"Method": "String getFullValue(){\r\n    List<CoreLabel> tokens = sentence.get(CoreAnnotations.TokensAnnotation.class);\r\n    StringBuilder sb = new StringBuilder();\r\n    if (tokens != null && extentTokenSpan != null) {\r\n        for (int i = extentTokenSpan.start(); i < extentTokenSpan.end(); i++) {\r\n            if (i > extentTokenSpan.start())\r\n                sb.append(' ');\r\n            sb.append(tokens.get(i).word());\r\n        }\r\n    }\r\n    return sb.toString();\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.testing.RemovalListeners.consuming",
	"Comment": "a removal listener that stores the notifications for inspection.",
	"Method": "RemovalListener<K, V> consuming(){\r\n    return new ConsumingRemovalListener();\r\n}"
}, {
	"Path": "com.facebook.buck.intellij.ideabuck.ui.BuckEventsConsumer.attach",
	"Comment": "add a new bucktextnode in the bucktreeviewpanel, which becomes the root when adding new nodesin the event consumers",
	"Method": "void attach(String message){\r\n    mCurrentBuildRootElement = new BuckTextNode(message, TextType.INFO);\r\n    mBuckUIManager.getBuckTreeViewPanel().getModifiableModel().addChild(mBuckUIManager.getBuckTreeViewPanel().getRoot(), mCurrentBuildRootElement);\r\n    mMainBuildStartTimestamp = 0;\r\n    mConnection = mProject.getMessageBus().connect();\r\n    mConnection.subscribe(BuckProjectGenerationFinishedConsumer.PROJECT_GENERATION_FINISHED_CONSUMER, this);\r\n    mConnection.subscribe(BuckProjectGenerationStartedConsumer.PROJECT_GENERATION_STARTED_CONSUMER, this);\r\n    mConnection.subscribe(BuckProjectGenerationProgressConsumer.PROJECT_GENERATION_PROGRESS_CONSUMER, this);\r\n    mConnection.subscribe(BuckBuildStartConsumer.BUCK_BUILD_START, this);\r\n    mConnection.subscribe(BuckBuildEndConsumer.BUCK_BUILD_END, this);\r\n    mConnection.subscribe(BuckBuildProgressUpdateConsumer.BUCK_BUILD_PROGRESS_UPDATE, this);\r\n    mConnection.subscribe(RulesParsingStartConsumer.BUCK_PARSE_RULE_START, this);\r\n    mConnection.subscribe(RulesParsingEndConsumer.BUCK_PARSE_RULE_END, this);\r\n    mConnection.subscribe(RulesParsingProgressUpdateConsumer.BUCK_PARSE_PROGRESS_UPDATE, this);\r\n    mConnection.subscribe(CompilerErrorConsumer.COMPILER_ERROR_CONSUMER, this);\r\n    mConnection.subscribe(BuckConsoleEventConsumer.BUCK_CONSOLE_EVENT, this);\r\n    mConnection.subscribe(TestRunStartedConsumer.BUCK_TEST_RUN_STARTED, this);\r\n    mConnection.subscribe(TestRunCompleteConsumer.BUCK_TEST_RUN_COMPLETE, this);\r\n    mConnection.subscribe(TestResultsAvailableConsumer.BUCK_TEST_RESULTS_AVAILABLE, this);\r\n    mConnection.subscribe(BuckInstallFinishedConsumer.INSTALL_FINISHED_CONSUMER, this);\r\n    attached = true;\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.jcache.CacheProxy.enableManagement",
	"Comment": "enables or disables the configuration management jmx bean.",
	"Method": "void enableManagement(boolean enabled){\r\n    requireNotClosed();\r\n    synchronized (configuration) {\r\n        if (enabled) {\r\n            JmxRegistration.registerMXBean(this, cacheMXBean, MBeanType.Configuration);\r\n        } else {\r\n            JmxRegistration.unregisterMXBean(this, MBeanType.Configuration);\r\n        }\r\n        configuration.setManagementEnabled(enabled);\r\n    }\r\n}"
}, {
	"Path": "org.objectweb.asm.Label.addReference",
	"Comment": "adds a forward reference to this label. this method must be called onlyfor a true forward reference, i.e. only if this label is not resolvedyet. for backward references, the offset of the reference can be, andmust be, computed and stored directly.",
	"Method": "void addReference(int sourcePosition,int referencePosition){\r\n    if (srcAndRefPositions == null) {\r\n        srcAndRefPositions = new int[6];\r\n    }\r\n    if (referenceCount >= srcAndRefPositions.length) {\r\n        int[] a = new int[srcAndRefPositions.length + 6];\r\n        System.arraycopy(srcAndRefPositions, 0, a, 0, srcAndRefPositions.length);\r\n        srcAndRefPositions = a;\r\n    }\r\n    srcAndRefPositions[referenceCount++] = sourcePosition;\r\n    srcAndRefPositions[referenceCount++] = referencePosition;\r\n}"
}, {
	"Path": "edu.stanford.nlp.ie.crf.FactorTable.conditionalLogProbGivenNext",
	"Comment": "computes the probability of the tag of being at the beginning of the tablegiven that the tag sequence given is at the end of the table. given is atthe end, of is at the beginning",
	"Method": "double conditionalLogProbGivenNext(int[] given,int of){\r\n    if (given.length != windowSize - 1) {\r\n        throw new IllegalArgumentException(\"conditionalLogProbGivenNext requires given one less than clique size (\" + windowSize + \") but was \" + Arrays.toString(given));\r\n    }\r\n    int[] label = indicesEnd(given);\r\n    double[] masses = new double[label.length];\r\n    for (int i = 0; i < masses.length; i++) {\r\n        masses[i] = table[label[i]];\r\n    }\r\n    double z = ArrayMath.logSum(masses);\r\n    return table[indexOf(of, given)] - z;\r\n}"
}, {
	"Path": "jsr166.ConcurrentHashMap8Test.testComputeIfAbsent2",
	"Comment": "computeifabsent does not replace if the key is already present",
	"Method": "void testComputeIfAbsent2(){\r\n    ConcurrentMap map = map5();\r\n    assertEquals(\"A\", map.computeIfAbsent(one, (x) -> \"Z\"));\r\n}"
}, {
	"Path": "org.apereo.cas.adaptors.x509.authentication.handler.support.X509CredentialsAuthenticationHandler.isCertificateFromTrustedIssuer",
	"Comment": "checks if is certificate from trusted issuer based on the regex pattern.",
	"Method": "boolean isCertificateFromTrustedIssuer(X509Certificate cert){\r\n    return doesNameMatchPattern(cert.getIssuerDN(), this.regExTrustedIssuerDnPattern);\r\n}"
}, {
	"Path": "edu.stanford.nlp.classify.Classifier.evaluateAccuracy",
	"Comment": "evaluate the accuracy of this classifier on the given dataset.",
	"Method": "double evaluateAccuracy(GeneralDataset<L, F> testData){\r\n    int numCorrect = 0;\r\n    for (RVFDatum<L, F> datum : testData) {\r\n        L label = datum.label();\r\n        if (label == null) {\r\n            throw new IllegalArgumentException(\"Cannot compute precision and recall on unlabelled dataset. Offending datum: \" + datum);\r\n        }\r\n        L guess = classOf(datum);\r\n        if (label.equals(guess)) {\r\n            numCorrect += 1;\r\n        }\r\n    }\r\n    return ((double) numCorrect) / ((double) testData.size);\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.FrequencySketch.indexOf",
	"Comment": "returns the table index for the counter at the specified depth.",
	"Method": "int indexOf(int item,int i){\r\n    long hash = SEED[i] * item;\r\n    hash += hash >> 32;\r\n    return ((int) hash) & tableMask;\r\n}"
}, {
	"Path": "org.apereo.cas.web.support.AbstractInMemoryThrottledSubmissionHandlerInterceptorAdapter.submissionRate",
	"Comment": "computes the instantaneous rate in between two given dates corresponding to two submissions.",
	"Method": "double submissionRate(ZonedDateTime a,ZonedDateTime b){\r\n    return SUBMISSION_RATE_DIVIDEND / (a.toInstant().toEpochMilli() - b.toInstant().toEpochMilli());\r\n}"
}, {
	"Path": "com.github.benmanes.caffeine.cache.simulator.policy.product.CaffeinePolicy.policies",
	"Comment": "returns all variations of this policy based on the configuration parameters.",
	"Method": "Set<Policy> policies(Config config){\r\n    return ImmutableSet.of(new CaffeinePolicy(config));\r\n}"
}, {
	"Path": "com.android.dx.rop.code.RegisterSpec.withReg",
	"Comment": "returns an instance that is identical to this one, except that theregister number is replaced by the given one.",
	"Method": "RegisterSpec withReg(int newReg){\r\n    if (reg == newReg) {\r\n        return this;\r\n    }\r\n    return makeLocalOptional(newReg, type, local);\r\n}"
}]