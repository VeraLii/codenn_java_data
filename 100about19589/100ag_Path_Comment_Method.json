[{
	"Path": "com.google.android.exoplayer2.PlaybackInfo.createDummy",
	"Comment": "creates empty dummy playback info which can be used for masking as long as no real playbackinfo is available.",
	"Method": "PlaybackInfo createDummy(long startPositionUs,TrackSelectorResult emptyTrackSelectorResult){\r\n    return new PlaybackInfo(Timeline.EMPTY, null, DUMMY_MEDIA_PERIOD_ID, startPositionUs, C.TIME_UNSET, Player.STATE_IDLE, false, TrackGroupArray.EMPTY, emptyTrackSelectorResult, DUMMY_MEDIA_PERIOD_ID, startPositionUs, 0, startPositionUs);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.enqueueNextMediaPeriod",
	"Comment": "enqueues a new media period based on the specified information as the new loading media period,and returns it.",
	"Method": "MediaPeriod enqueueNextMediaPeriod(RendererCapabilities[] rendererCapabilities,TrackSelector trackSelector,Allocator allocator,MediaSource mediaSource,MediaPeriodInfo info){\r\n    long rendererPositionOffsetUs = loading == null ? info.startPositionUs : (loading.getRendererOffset() + loading.info.durationUs);\r\n    MediaPeriodHolder newPeriodHolder = new MediaPeriodHolder(rendererCapabilities, rendererPositionOffsetUs, trackSelector, allocator, mediaSource, info);\r\n    if (loading != null) {\r\n        Assertions.checkState(hasPlayingPeriod());\r\n        loading.next = newPeriodHolder;\r\n    }\r\n    oldFrontPeriodUid = null;\r\n    loading = newPeriodHolder;\r\n    length++;\r\n    return newPeriodHolder.mediaPeriod;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.vp9.LibvpxVideoRenderer.shouldDropOutputBuffer",
	"Comment": "returns whether the buffer being processed should be dropped.",
	"Method": "boolean shouldDropOutputBuffer(long earlyUs,long elapsedRealtimeUs){\r\n    return isBufferLate(earlyUs);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.BaseTrackSelection.equals",
	"Comment": "track groups are compared by identity not value, as distinct groups may have the same value.",
	"Method": "boolean equals(Object obj){\r\n    if (this == obj) {\r\n        return true;\r\n    }\r\n    if (obj == null || getClass() != obj.getClass()) {\r\n        return false;\r\n    }\r\n    BaseTrackSelection other = (BaseTrackSelection) obj;\r\n    return group == other.group && Arrays.equals(tracks, other.tracks);\r\n}"
}, {
	"Path": "org.elasticsearch.test.http.MockWebServer.start",
	"Comment": "starts the webserver and binds it to an arbitrary ephemeral portthe webserver will be able to serve requests once this method returns",
	"Method": "void start(){\r\n    InetSocketAddress address = new InetSocketAddress(InetAddress.getLoopbackAddress().getHostAddress(), 0);\r\n    if (sslContext != null) {\r\n        HttpsServer httpsServer = MockHttpServer.createHttps(address, 0);\r\n        httpsServer.setHttpsConfigurator(new CustomHttpsConfigurator(sslContext, needClientAuth));\r\n        server = httpsServer;\r\n    } else {\r\n        server = MockHttpServer.createHttp(address, 0);\r\n    }\r\n    server.start();\r\n    this.hostname = server.getAddress().getHostString();\r\n    this.port = server.getAddress().getPort();\r\n    server.createContext(\"/\", s -> {\r\n        try {\r\n            MockResponse response = responses.poll();\r\n            MockRequest request = createRequest(s);\r\n            requests.add(request);\r\n            if (logger.isDebugEnabled()) {\r\n                logger.debug(\"[{}:{}] incoming HTTP request [{} {}], returning status [{}] body [{}]\", getHostName(), getPort(), s.getRequestMethod(), s.getRequestURI(), response.getStatusCode(), getStartOfBody(response));\r\n            }\r\n            sleepIfNeeded(response.getBeforeReplyDelay());\r\n            s.getResponseHeaders().putAll(response.getHeaders().headers);\r\n            if (Strings.isEmpty(response.getBody())) {\r\n                s.sendResponseHeaders(response.getStatusCode(), 0);\r\n            } else {\r\n                byte[] responseAsBytes = response.getBody().getBytes(StandardCharsets.UTF_8);\r\n                s.sendResponseHeaders(response.getStatusCode(), responseAsBytes.length);\r\n                sleepIfNeeded(response.getBodyDelay());\r\n                if (\"HEAD\".equals(request.getMethod()) == false) {\r\n                    try (OutputStream responseBody = s.getResponseBody()) {\r\n                        responseBody.write(responseAsBytes);\r\n                    }\r\n                }\r\n            }\r\n        } catch (Exception e) {\r\n            logger.error((Supplier<?>) () -> new ParameterizedMessage(\"failed to respond to request [{} {}]\", s.getRequestMethod(), s.getRequestURI()), e);\r\n        } finally {\r\n            s.close();\r\n        }\r\n    });\r\n    logger.info(\"bound HTTP mock server to [{}:{}]\", getHostName(), getPort());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.CurrentExecutions.put",
	"Comment": "tries to put an watch execution class for a watch in the current executions",
	"Method": "boolean put(String id,ExecutionService.WatchExecution execution){\r\n    lock.lock();\r\n    try {\r\n        if (seal.get() != null) {\r\n            throw illegalState(\"could not register execution [{}]. current executions are sealed and forbid registrations of \" + \"additional executions.\", id);\r\n        }\r\n        return currentExecutions.putIfAbsent(id, execution) != null;\r\n    } finally {\r\n        lock.unlock();\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.text.dvb.DvbParser.parsePageComposition",
	"Comment": "parses a page composition segment, as defined by etsi en 300 743 7.2.2.",
	"Method": "PageComposition parsePageComposition(ParsableBitArray data,int length){\r\n    int timeoutSecs = data.readBits(8);\r\n    int version = data.readBits(4);\r\n    int state = data.readBits(2);\r\n    data.skipBits(2);\r\n    int remainingLength = length - 2;\r\n    SparseArray<PageRegion> regions = new SparseArray();\r\n    while (remainingLength > 0) {\r\n        int regionId = data.readBits(8);\r\n        data.skipBits(8);\r\n        int regionHorizontalAddress = data.readBits(16);\r\n        int regionVerticalAddress = data.readBits(16);\r\n        remainingLength -= 6;\r\n        regions.put(regionId, new PageRegion(regionHorizontalAddress, regionVerticalAddress));\r\n    }\r\n    return new PageComposition(timeoutSecs, version, state, regions);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.Loader.cancelLoading",
	"Comment": "cancels the current load. this method should only be called when a load is in progress.",
	"Method": "void cancelLoading(){\r\n    currentTask.cancel(false);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.watch.ClockMock.rewindSeconds",
	"Comment": "freeze the clock if not frozen and rewind it by the given number of seconds",
	"Method": "void rewindSeconds(int seconds){\r\n    rewind(TimeValue.timeValueSeconds(seconds));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authz.privilege.ApplicationPrivilege.validatePrivilegeName",
	"Comment": "validate that the provided privilege name is valid, and throws an exception otherwise",
	"Method": "void validatePrivilegeName(String name){\r\n    if (isValidPrivilegeName(name) == false) {\r\n        throw new IllegalArgumentException(\"Application privilege names must match the pattern \" + VALID_NAME.pattern() + \" (found '\" + name + \"')\");\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.rest.RestRequestFilter.getFilteredRequest",
	"Comment": "wraps the restrequest and returns a version that provides the filtered content",
	"Method": "RestRequest getFilteredRequest(RestRequest restRequest){\r\n    Set<String> fields = getFilteredFields();\r\n    if (restRequest.hasContent() && fields.isEmpty() == false) {\r\n        return new RestRequest(restRequest) {\r\n            private BytesReference filteredBytes = null;\r\n            @Override\r\n            public boolean hasContent() {\r\n                return true;\r\n            }\r\n            @Override\r\n            public BytesReference content() {\r\n                if (filteredBytes == null) {\r\n                    BytesReference content = restRequest.content();\r\n                    Tuple<XContentType, Map<String, Object>> result = XContentHelper.convertToMap(content, true);\r\n                    Map<String, Object> transformedSource = XContentMapValues.filter(result.v2(), null, fields.toArray(Strings.EMPTY_ARRAY));\r\n                    try {\r\n                        XContentBuilder xContentBuilder = XContentBuilder.builder(result.v1().xContent()).map(transformedSource);\r\n                        filteredBytes = BytesReference.bytes(xContentBuilder);\r\n                    } catch (IOException e) {\r\n                        throw new ElasticsearchException(\"failed to parse request\", e);\r\n                    }\r\n                }\r\n                return filteredBytes;\r\n            }\r\n        };\r\n    } else {\r\n        return restRequest;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.rest.RestRequestFilter.getFilteredRequest",
	"Comment": "wraps the restrequest and returns a version that provides the filtered content",
	"Method": "RestRequest getFilteredRequest(RestRequest restRequest){\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.rest.RestRequestFilter.getFilteredRequest",
	"Comment": "wraps the restrequest and returns a version that provides the filtered content",
	"Method": "RestRequest getFilteredRequest(RestRequest restRequest){\r\n    if (filteredBytes == null) {\r\n        BytesReference content = restRequest.content();\r\n        Tuple<XContentType, Map<String, Object>> result = XContentHelper.convertToMap(content, true);\r\n        Map<String, Object> transformedSource = XContentMapValues.filter(result.v2(), null, fields.toArray(Strings.EMPTY_ARRAY));\r\n        try {\r\n            XContentBuilder xContentBuilder = XContentBuilder.builder(result.v1().xContent()).map(transformedSource);\r\n            filteredBytes = BytesReference.bytes(xContentBuilder);\r\n        } catch (IOException e) {\r\n            throw new ElasticsearchException(\"failed to parse request\", e);\r\n        }\r\n    }\r\n    return filteredBytes;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.proto.SqlQueryRequest.filter",
	"Comment": "an optional query dsl defined query that can added as a filter on the top of the sql query",
	"Method": "ToXContent filter(){\r\n    return filter;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.opus.OpusLibrary.getVersion",
	"Comment": "returns the version of the underlying library if available, or null otherwise.",
	"Method": "String getVersion(){\r\n    return isAvailable() ? opusGetVersion() : null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.ts.NalUnitTargetBuffer.appendToNalUnit",
	"Comment": "called to pass stream data. the data passed should not include the 3 byte start code.",
	"Method": "void appendToNalUnit(byte[] data,int offset,int limit){\r\n    if (!isFilling) {\r\n        return;\r\n    }\r\n    int readLength = limit - offset;\r\n    if (nalData.length < nalLength + readLength) {\r\n        nalData = Arrays.copyOf(nalData, (nalLength + readLength) * 2);\r\n    }\r\n    System.arraycopy(data, offset, nalData, nalLength, readLength);\r\n    nalLength += readLength;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.CodecSpecificDataUtil.buildNalUnit",
	"Comment": "constructs a nal unit consisting of the nal start code followed by the specified data.",
	"Method": "byte[] buildNalUnit(byte[] data,int offset,int length){\r\n    byte[] nalUnit = new byte[length + NAL_START_CODE.length];\r\n    System.arraycopy(NAL_START_CODE, 0, nalUnit, 0, NAL_START_CODE.length);\r\n    System.arraycopy(data, offset, nalUnit, NAL_START_CODE.length, length);\r\n    return nalUnit;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.FileStructureUtils.guessScalarMapping",
	"Comment": "given some sample values for a field, guess the most appropriate index mapping for thefield.",
	"Method": "Map<String, String> guessScalarMapping(List<String> explanation,String fieldName,Collection<String> fieldValues){\r\n    assert fieldValues.isEmpty() == false;\r\n    if (fieldValues.stream().allMatch(value -> \"true\".equals(value) || \"false\".equals(value))) {\r\n        return Collections.singletonMap(MAPPING_TYPE_SETTING, \"boolean\");\r\n    }\r\n    Iterator<String> iter = fieldValues.iterator();\r\n    TimestampMatch timestampMatch = TimestampFormatFinder.findFirstFullMatch(iter.next());\r\n    while (timestampMatch != null && iter.hasNext()) {\r\n        if (timestampMatch.equals(TimestampFormatFinder.findFirstFullMatch(iter.next(), timestampMatch.candidateIndex)) == false) {\r\n            timestampMatch = null;\r\n        }\r\n    }\r\n    if (timestampMatch != null) {\r\n        return timestampMatch.getEsDateMappingTypeWithFormat();\r\n    }\r\n    if (fieldValues.stream().allMatch(NUMBER_GROK::match)) {\r\n        try {\r\n            fieldValues.forEach(Long::parseLong);\r\n            return Collections.singletonMap(MAPPING_TYPE_SETTING, \"long\");\r\n        } catch (NumberFormatException e) {\r\n            explanation.add(\"Rejecting type 'long' for field [\" + fieldName + \"] due to parse failure: [\" + e.getMessage() + \"]\");\r\n        }\r\n        try {\r\n            fieldValues.forEach(Double::parseDouble);\r\n            return Collections.singletonMap(MAPPING_TYPE_SETTING, \"double\");\r\n        } catch (NumberFormatException e) {\r\n            explanation.add(\"Rejecting type 'double' for field [\" + fieldName + \"] due to parse failure: [\" + e.getMessage() + \"]\");\r\n        }\r\n    } else if (fieldValues.stream().allMatch(IP_GROK::match)) {\r\n        return Collections.singletonMap(MAPPING_TYPE_SETTING, \"ip\");\r\n    }\r\n    if (fieldValues.stream().anyMatch(FileStructureUtils::isMoreLikelyTextThanKeyword)) {\r\n        return Collections.singletonMap(MAPPING_TYPE_SETTING, \"text\");\r\n    }\r\n    return Collections.singletonMap(MAPPING_TYPE_SETTING, \"keyword\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.qa.cli.EmbeddedCli.assertConnectionTest",
	"Comment": "assert that result of the connection test. default implementationasserts that the test passes but overridden to check places wherewe want to assert that it fails.",
	"Method": "void assertConnectionTest(){\r\n    assertEquals(\"\", readLine());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.ads.AdPlaybackState.withAdLoadError",
	"Comment": "returns an instance with the specified ad marked as having a load error.",
	"Method": "AdPlaybackState withAdLoadError(int adGroupIndex,int adIndexInAdGroup){\r\n    AdGroup[] adGroups = Arrays.copyOf(this.adGroups, this.adGroups.length);\r\n    adGroups[adGroupIndex] = adGroups[adGroupIndex].withAdState(AD_STATE_ERROR, adIndexInAdGroup);\r\n    return new AdPlaybackState(adGroupTimesUs, adGroups, adResumePositionUs, contentDurationUs);\r\n}"
}, {
	"Path": "org.greenrobot.eventbus.EventBus.removeStickyEvent",
	"Comment": "remove and gets the recent sticky event for the given event type.",
	"Method": "T removeStickyEvent(Class<T> eventType,boolean removeStickyEvent,Object event){\r\n    synchronized (stickyEvents) {\r\n        Class<?> eventType = event.getClass();\r\n        Object existingEvent = stickyEvents.get(eventType);\r\n        if (event.equals(existingEvent)) {\r\n            stickyEvents.remove(eventType);\r\n            return true;\r\n        } else {\r\n            return false;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.DefaultTrackSelectorTest.testSelectPreferredTextTrackMultipleRenderers",
	"Comment": "tests audio track selection when there are multiple audio renderers.",
	"Method": "void testSelectPreferredTextTrackMultipleRenderers(){\r\n    Format english = buildTextFormat(\"en\", \"en\");\r\n    Format german = buildTextFormat(\"de\", \"de\");\r\n    Map<String, Integer> firstRendererMappedCapabilities = new HashMap();\r\n    firstRendererMappedCapabilities.put(english.id, FORMAT_HANDLED);\r\n    firstRendererMappedCapabilities.put(german.id, FORMAT_UNSUPPORTED_SUBTYPE);\r\n    RendererCapabilities firstRendererCapabilities = new FakeMappedRendererCapabilities(C.TRACK_TYPE_TEXT, firstRendererMappedCapabilities);\r\n    Map<String, Integer> secondRendererMappedCapabilities = new HashMap();\r\n    secondRendererMappedCapabilities.put(english.id, FORMAT_UNSUPPORTED_SUBTYPE);\r\n    secondRendererMappedCapabilities.put(german.id, FORMAT_HANDLED);\r\n    RendererCapabilities secondRendererCapabilities = new FakeMappedRendererCapabilities(C.TRACK_TYPE_TEXT, secondRendererMappedCapabilities);\r\n    RendererCapabilities[] rendererCapabilities = new RendererCapabilities[] { firstRendererCapabilities, secondRendererCapabilities };\r\n    TrackSelectorResult result = trackSelector.selectTracks(rendererCapabilities, wrapFormats(english, german));\r\n    assertThat(result.selections.get(0)).isNull();\r\n    assertThat(result.selections.get(1)).isNull();\r\n    trackSelector.setParameters(trackSelector.buildUponParameters().setPreferredTextLanguage(\"en\"));\r\n    result = trackSelector.selectTracks(rendererCapabilities, wrapFormats(english, german));\r\n    assertThat(result.selections.get(0).getFormat(0)).isSameAs(english);\r\n    assertThat(result.selections.get(1)).isNull();\r\n    trackSelector.setParameters(trackSelector.buildUponParameters().setPreferredTextLanguage(\"de\"));\r\n    result = trackSelector.selectTracks(rendererCapabilities, wrapFormats(english, german));\r\n    assertThat(result.selections.get(0)).isNull();\r\n    assertThat(result.selections.get(1).getFormat(0)).isSameAs(german);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.client.RemoteFailure.parseFromResponse",
	"Comment": "parse a failure from the response. the stream is not closed when the parsing is complete.the caller must close it.",
	"Method": "RemoteFailure parseFromResponse(InputStream stream){\r\n    stream = new BufferedInputStream(stream);\r\n    stream.mark(MAX_RAW_RESPONSE);\r\n    JsonParser parser = null;\r\n    try {\r\n        parser = JSON_FACTORY.createParser(stream);\r\n        return parseResponseTopLevel(parser);\r\n    } catch (JsonParseException e) {\r\n        throw new IOException(parseErrorMessage(e.getOriginalMessage(), stream, parser), e);\r\n    } catch (IOException e) {\r\n        throw new IOException(parseErrorMessage(e.getMessage(), stream, parser), e);\r\n    } finally {\r\n        if (parser != null) {\r\n            parser.close();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.Label.put",
	"Comment": "puts a reference to this label in the bytecode of a method. if the position of the label is known, the offset iscomputed and written directly. otherwise, a null offset is written and a new forward reference is declared forthis label.",
	"Method": "void put(MethodWriter owner,ByteVector out,int source){\r\n    if ((status & 2) == 0) {\r\n        addReference(source, out.length);\r\n        out.putShort(-1);\r\n    } else {\r\n        out.putShort(position - source);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.output.AutoDetectResultProcessor.isFailed",
	"Comment": "if failed then there was an error parsing the results that cannot be recovered from",
	"Method": "boolean isFailed(){\r\n    return failed;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.AtomicFile.delete",
	"Comment": "delete the atomic file. this deletes both the base and backup files.",
	"Method": "void delete(){\r\n    baseName.delete();\r\n    backupName.delete();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.ParsingLoadable.getResult",
	"Comment": "returns the loaded object, or null if an object has not been loaded.",
	"Method": "T getResult(){\r\n    return result;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mkv.DefaultEbmlReader.maybeResyncToNextLevel1Element",
	"Comment": "does a byte by byte search to try and find the next level 1 element. this method is called ifsome invalid data is encountered in the parser.",
	"Method": "long maybeResyncToNextLevel1Element(ExtractorInput input){\r\n    input.resetPeekPosition();\r\n    while (true) {\r\n        input.peekFully(scratch, 0, MAX_ID_BYTES);\r\n        int varintLength = VarintReader.parseUnsignedVarintLength(scratch[0]);\r\n        if (varintLength != C.LENGTH_UNSET && varintLength <= MAX_ID_BYTES) {\r\n            int potentialId = (int) VarintReader.assembleVarint(scratch, varintLength, false);\r\n            if (output.isLevel1Element(potentialId)) {\r\n                input.skipFully(varintLength);\r\n                return potentialId;\r\n            }\r\n        }\r\n        input.skipFully(1);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.AudioFocusManager.setAudioAttributes",
	"Comment": "sets audio attributes that should be used to manage audio focus.",
	"Method": "int setAudioAttributes(AudioAttributes audioAttributes,boolean playWhenReady,int playerState){\r\n    if (this.audioAttributes == null && audioAttributes == null) {\r\n        return playWhenReady ? PLAYER_COMMAND_PLAY_WHEN_READY : PLAYER_COMMAND_DO_NOT_PLAY;\r\n    }\r\n    Assertions.checkNotNull(audioManager, \"SimpleExoPlayer must be created with a context to handle audio focus.\");\r\n    if (!Util.areEqual(this.audioAttributes, audioAttributes)) {\r\n        this.audioAttributes = audioAttributes;\r\n        focusGain = convertAudioAttributesToFocusGain(audioAttributes);\r\n        Assertions.checkArgument(focusGain == C.AUDIOFOCUS_GAIN || focusGain == C.AUDIOFOCUS_NONE, \"Automatic handling of audio focus is only available for USAGE_MEDIA and USAGE_GAME.\");\r\n        if (playWhenReady && (playerState == Player.STATE_BUFFERING || playerState == Player.STATE_READY)) {\r\n            return requestAudioFocus();\r\n        }\r\n    }\r\n    return playerState == Player.STATE_IDLE ? handleIdle(playWhenReady) : handlePrepare(playWhenReady);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.history.HistoryStore.validate",
	"Comment": "check if everything is set up for the history store to operate fully. checks for thecurrent watcher history index and if it is open.",
	"Method": "boolean validate(ClusterState state){\r\n    String currentIndex = HistoryStoreField.getHistoryIndexNameForTime(DateTime.now(DateTimeZone.UTC));\r\n    IndexMetaData indexMetaData = WatchStoreUtils.getConcreteIndex(currentIndex, state.metaData());\r\n    return indexMetaData == null || (indexMetaData.getState() == IndexMetaData.State.OPEN && state.routingTable().index(indexMetaData.getIndex()).allPrimaryShardsActive());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.MappingTrackSelectorTest.testMappingMulti",
	"Comment": "tests video and audio track groups are mapped onto the correct renderers when there aremultiple track groups of the same type.",
	"Method": "void testMappingMulti(){\r\n    FakeMappingTrackSelector trackSelector = new FakeMappingTrackSelector();\r\n    TrackGroupArray multiTrackGroups = new TrackGroupArray(VIDEO_TRACK_GROUP, AUDIO_TRACK_GROUP, VIDEO_TRACK_GROUP);\r\n    trackSelector.selectTracks(RENDERER_CAPABILITIES, multiTrackGroups);\r\n    trackSelector.assertMappedTrackGroups(0, VIDEO_TRACK_GROUP, VIDEO_TRACK_GROUP);\r\n    trackSelector.assertMappedTrackGroups(1, AUDIO_TRACK_GROUP);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.Util.addWithOverflowDefault",
	"Comment": "returns the sum of two arguments, or a third argument if the result overflows.",
	"Method": "long addWithOverflowDefault(long x,long y,long overflowResult){\r\n    long result = x + y;\r\n    if (((x ^ result) & (y ^ result)) < 0) {\r\n        return overflowResult;\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.alibaba.fastjson.util.AntiCollisionHashMap.getEntry",
	"Comment": "returns the entry associated with the specified key in the safelyhashmap.returns null if the safelyhashmap contains no mapping for the key.",
	"Method": "Entry<K, V> getEntry(Object key){\r\n    int hash = (key == null) ? 0 : (key instanceof String) ? hash(hashString((String) key)) : hash(key.hashCode());\r\n    for (Entry<K, V> e = table[indexFor(hash, table.length)]; e != null; e = e.next) {\r\n        Object k;\r\n        if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k))))\r\n            return e;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.file.tool.UsersToolTests.assertRole",
	"Comment": "checks the role has the given users, or that the role does not exist if not users are passed.",
	"Method": "void assertRole(String role,String users){\r\n    List<String> lines = Files.readAllLines(confDir.resolve(\"users_roles\"), StandardCharsets.UTF_8);\r\n    for (String line : lines) {\r\n        String[] roleUsers = line.split(\":\", 2);\r\n        if (roleUsers.length != 2) {\r\n            fail(\"Corrupted users_roles file, line: \" + line);\r\n        }\r\n        if (role.equals(roleUsers[0]) == false) {\r\n            continue;\r\n        }\r\n        if (users.length == 0) {\r\n            fail(\"Found role \" + role + \" in users_roles file with users [\" + roleUsers[1] + \"]\");\r\n        }\r\n        List<String> gotUsers = Arrays.asList(roleUsers[1].split(\",\"));\r\n        for (String user : users) {\r\n            if (gotUsers.contains(user) == false) {\r\n                fail(\"Expected users [\" + Arrays.toString(users) + \"] for role \" + role + \" but found [\" + gotUsers.toString() + \"]\");\r\n            }\r\n        }\r\n        return;\r\n    }\r\n    if (users.length != 0) {\r\n        fail(\"Could not find role \" + role + \" in users_roles file:\\n\" + lines.toString());\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlSpMetadataBuilder.nameIdFormat",
	"Comment": "the format that the service provider expects for incoming nameid element.",
	"Method": "SamlSpMetadataBuilder nameIdFormat(String nameIdFormat){\r\n    this.nameIdFormat = nameIdFormat;\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.test.SecuritySingleNodeTestCase.transportSSLEnabled",
	"Comment": "allows to control whether ssl key information is auto generated or not on the transport layer",
	"Method": "boolean transportSSLEnabled(){\r\n    return randomBoolean();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.Mp4Extractor.processFtypAtom",
	"Comment": "process an ftyp atom to determine whether the media is quicktime.",
	"Method": "boolean processFtypAtom(ParsableByteArray atomData){\r\n    atomData.setPosition(Atom.HEADER_SIZE);\r\n    int majorBrand = atomData.readInt();\r\n    if (majorBrand == BRAND_QUICKTIME) {\r\n        return true;\r\n    }\r\n    atomData.skipBytes(4);\r\n    while (atomData.bytesLeft() > 0) {\r\n        if (atomData.readInt() == BRAND_QUICKTIME) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.process.writer.LengthEncodedWriterTests.testLengthEncodedWriterIndividualRecords",
	"Comment": "test the writefield and writenumfields methods of lengthencodedwriter",
	"Method": "void testLengthEncodedWriterIndividualRecords(){\r\n    {\r\n        String[] header = { \"one\", \"two\", \"three\", \"four\", \"five\" };\r\n        String[] record1 = { \"r1\", \"r2\", \"rr3\", \"rrr4\", \"r5\" };\r\n        String[] record2 = { \"y1\", \"y2\", \"yy3\", \"yyy4\", \"y5\" };\r\n        ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\r\n        LengthEncodedWriter writer = new LengthEncodedWriter(bos);\r\n        writer.writeNumFields(header.length);\r\n        for (int i = 0; i < header.length; i++) {\r\n            writer.writeField(header[i]);\r\n        }\r\n        final int NUM_RECORDS = 5;\r\n        for (int i = 0; i < NUM_RECORDS; i++) {\r\n            writer.writeNumFields(record1.length);\r\n            for (int j = 0; j < record1.length; j++) {\r\n                writer.writeField(record1[j]);\r\n            }\r\n            writer.writeNumFields(record2.length);\r\n            for (int j = 0; j < record2.length; j++) {\r\n                writer.writeField(record2[j]);\r\n            }\r\n        }\r\n        ByteBuffer bb = ByteBuffer.wrap(bos.toByteArray());\r\n        int numFields = bb.getInt();\r\n        Assert.assertEquals(numFields, header.length);\r\n        for (int i = 0; i < numFields; i++) {\r\n            int recordSize = bb.getInt();\r\n            byte[] charBuff = new byte[recordSize];\r\n            for (int j = 0; j < recordSize; j++) {\r\n                charBuff[j] = bb.get();\r\n            }\r\n            String value = new String(charBuff, StandardCharsets.UTF_8);\r\n            Assert.assertEquals(header[i], value);\r\n        }\r\n        for (int n = 0; n < NUM_RECORDS; n++) {\r\n            numFields = bb.getInt();\r\n            Assert.assertEquals(numFields, record1.length);\r\n            for (int i = 0; i < numFields; i++) {\r\n                int recordSize = bb.getInt();\r\n                byte[] charBuff = new byte[recordSize];\r\n                for (int j = 0; j < recordSize; j++) {\r\n                    charBuff[j] = bb.get();\r\n                }\r\n                String value = new String(charBuff, StandardCharsets.UTF_8);\r\n                Assert.assertEquals(value, record1[i]);\r\n            }\r\n            numFields = bb.getInt();\r\n            Assert.assertEquals(numFields, record2.length);\r\n            for (int i = 0; i < numFields; i++) {\r\n                int recordSize = bb.getInt();\r\n                byte[] charBuff = new byte[recordSize];\r\n                for (int j = 0; j < recordSize; j++) {\r\n                    charBuff[j] = bb.get();\r\n                }\r\n                String value = new String(charBuff, StandardCharsets.UTF_8);\r\n                Assert.assertEquals(value, record2[i]);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ExoPlayerTest.testPlayEmptyTimeline",
	"Comment": "tests playback of a source that exposes an empty timeline. playback is expected to end withouterror.",
	"Method": "void testPlayEmptyTimeline(){\r\n    Timeline timeline = Timeline.EMPTY;\r\n    FakeRenderer renderer = new FakeRenderer();\r\n    ExoPlayerTestRunner testRunner = new Builder().setTimeline(timeline).setRenderers(renderer).build(context).start().blockUntilEnded(TIMEOUT_MS);\r\n    testRunner.assertNoPositionDiscontinuities();\r\n    testRunner.assertTimelinesEqual(timeline);\r\n    assertThat(renderer.formatReadCount).isEqualTo(0);\r\n    assertThat(renderer.sampleBufferReadCount).isEqualTo(0);\r\n    assertThat(renderer.isEnded).isFalse();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlAuthenticatorTests.testThatTheTestSignersInteractCorrectlyWithOpenSaml",
	"Comment": "this is testing a test, but the real signing tests are useless if our signing is incorrectly implemented",
	"Method": "void testThatTheTestSignersInteractCorrectlyWithOpenSaml(){\r\n    final String xml = getSimpleResponse(clock.instant());\r\n    final Response unsigned = toResponse(xml);\r\n    assertThat(unsigned.isSigned(), equalTo(false));\r\n    assertThat(unsigned.getAssertions().get(0).isSigned(), equalTo(false));\r\n    final Response signedDoc = toResponse(signDoc(xml, idpSigningCertificatePair));\r\n    assertThat(signedDoc.isSigned(), equalTo(true));\r\n    assertThat(signedDoc.getAssertions().get(0).isSigned(), equalTo(false));\r\n    final Response signedAssertions = toResponse(signAssertions(xml, idpSigningCertificatePair));\r\n    assertThat(signedAssertions.isSigned(), equalTo(false));\r\n    assertThat(signedAssertions.getAssertions().get(0).isSigned(), equalTo(true));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherIndexingListenerTests.testWithAliasPointingToTwoIndicesSetsWatcherInactive",
	"Comment": "if the creates a .watches alias that points to two indices, set watcher to be inactive",
	"Method": "void testWithAliasPointingToTwoIndicesSetsWatcherInactive(){\r\n    listener.setConfiguration(INACTIVE);\r\n    DiscoveryNode node1 = newNode(\"node_1\");\r\n    Index fooIndex = new Index(\"foo\", \"someuuid\");\r\n    ShardId fooShardId = new ShardId(fooIndex, 0);\r\n    ShardRouting fooShardRouting = TestShardRouting.newShardRouting(fooShardId, node1.getId(), true, STARTED);\r\n    IndexRoutingTable.Builder fooIndexRoutingTable = IndexRoutingTable.builder(fooIndex).addShard(fooShardRouting);\r\n    ClusterState previousState = ClusterState.builder(new ClusterName(\"my-cluster\")).metaData(MetaData.builder().put(createIndexBuilder(\"foo\", 1, 0).putAlias(AliasMetaData.builder(Watch.INDEX)))).nodes(new DiscoveryNodes.Builder().masterNodeId(\"node_1\").localNodeId(\"node_1\").add(node1)).routingTable(RoutingTable.builder().add(fooIndexRoutingTable).build()).build();\r\n    Index barIndex = new Index(\"bar\", \"someuuid2\");\r\n    ShardId barShardId = new ShardId(fooIndex, 0);\r\n    IndexMetaData.Builder barIndexMetaData = createIndexBuilder(\"bar\", 1, 0).putAlias(AliasMetaData.builder(Watch.INDEX));\r\n    ShardRouting barShardRouting = TestShardRouting.newShardRouting(barShardId, node1.getId(), true, STARTED);\r\n    IndexRoutingTable.Builder barIndexRoutingTable = IndexRoutingTable.builder(barIndex).addShard(barShardRouting);\r\n    ClusterState currentState = ClusterState.builder(new ClusterName(\"my-cluster\")).metaData(MetaData.builder().put(createIndexBuilder(\"foo\", 1, 0).putAlias(AliasMetaData.builder(Watch.INDEX))).put(barIndexMetaData)).nodes(new DiscoveryNodes.Builder().masterNodeId(\"node_1\").localNodeId(\"node_1\").add(node1)).routingTable(RoutingTable.builder().add(IndexRoutingTable.builder(fooIndex).addShard(fooShardRouting)).add(barIndexRoutingTable).build()).build();\r\n    ClusterChangedEvent nodeGoneEvent = new ClusterChangedEvent(\"something\", currentState, previousState);\r\n    listener.clusterChanged(nodeGoneEvent);\r\n    assertThat(listener.getConfiguration(), is(INACTIVE));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.getDequeueOutputBufferTimeoutUs",
	"Comment": "returns the maximum time to block whilst waiting for a decoded output buffer.",
	"Method": "long getDequeueOutputBufferTimeoutUs(){\r\n    return 0;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.PoolingSessionFactory.createConnectionPool",
	"Comment": "creates the connection pool that will be used by the session factory and initializes the health check support",
	"Method": "LDAPConnectionPool createConnectionPool(RealmConfig config,ServerSet serverSet,TimeValue timeout,Logger logger,BindRequest bindRequest,Supplier<String> healthCheckDnSupplier){\r\n    final int initialSize = config.getSetting(PoolingSessionFactorySettings.POOL_INITIAL_SIZE);\r\n    final int size = config.getSetting(PoolingSessionFactorySettings.POOL_SIZE);\r\n    LDAPConnectionPool pool = null;\r\n    boolean success = false;\r\n    try {\r\n        pool = LdapUtils.privilegedConnect(() -> new LDAPConnectionPool(serverSet, bindRequest, initialSize, size));\r\n        pool.setRetryFailedOperationsDueToInvalidConnections(true);\r\n        if (config.getSetting(PoolingSessionFactorySettings.HEALTH_CHECK_ENABLED)) {\r\n            String entryDn = config.getSetting(PoolingSessionFactorySettings.HEALTH_CHECK_DN).orElseGet(healthCheckDnSupplier);\r\n            final long healthCheckInterval = config.getSetting(PoolingSessionFactorySettings.HEALTH_CHECK_INTERVAL).millis();\r\n            if (entryDn != null) {\r\n                LDAPConnectionPoolHealthCheck healthCheck = new GetEntryLDAPConnectionPoolHealthCheck(entryDn, timeout.millis(), false, false, false, true, false);\r\n                pool.setHealthCheck(healthCheck);\r\n                pool.setHealthCheckIntervalMillis(healthCheckInterval);\r\n            } else {\r\n                logger.warn(new ParameterizedMessage(\"[{}] and [{}} have not been specified or are not valid distinguished names,\" + \"so connection health checking is disabled\", RealmSettings.getFullSettingKey(config, PoolingSessionFactorySettings.BIND_DN), RealmSettings.getFullSettingKey(config, PoolingSessionFactorySettings.HEALTH_CHECK_DN)));\r\n            }\r\n        }\r\n        success = true;\r\n        return pool;\r\n    } finally {\r\n        if (success == false && pool != null) {\r\n            pool.close();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.TestDownloadManagerListener.blockUntilTasksCompleteAndThrowAnyDownloadError",
	"Comment": "blocks until all remove and download tasks are complete and throws an exception if there was anerror.",
	"Method": "void blockUntilTasksCompleteAndThrowAnyDownloadError(){\r\n    synchronized (this) {\r\n        downloadFinishedCondition = new CountDownLatch(1);\r\n    }\r\n    dummyMainThread.runOnMainThread(() -> {\r\n        if (downloadManager.isIdle()) {\r\n            downloadFinishedCondition.countDown();\r\n        }\r\n    });\r\n    assertThat(downloadFinishedCondition.await(TIMEOUT, TimeUnit.MILLISECONDS)).isTrue();\r\n    if (downloadError != null) {\r\n        throw new Exception(downloadError);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.qa.jdbc.ResultSetTestCase.createTestDataForNumericValueTypes",
	"Comment": "creates test data for all numeric get methods. all values random and different from the other numeric fields already generated.it returns a map containing the field name and its randomly generated value to be later used in checking the returned values.",
	"Method": "Map<String, Number> createTestDataForNumericValueTypes(Supplier<Number> randomGenerator){\r\n    Map<String, Number> map = new HashMap();\r\n    createIndex(\"test\");\r\n    updateMappingForNumericValuesTests(\"test\");\r\n    index(\"test\", \"1\", builder -> {\r\n        byte test_byte = randomValueOtherThanMany(map::containsValue, randomGenerator).byteValue();\r\n        builder.field(\"test_byte\", test_byte);\r\n        map.put(\"test_byte\", test_byte);\r\n        int test_integer = randomValueOtherThanMany(map::containsValue, randomGenerator).intValue();\r\n        builder.field(\"test_integer\", test_integer);\r\n        map.put(\"test_integer\", test_integer);\r\n        int test_short = randomValueOtherThanMany(map::containsValue, randomGenerator).shortValue();\r\n        builder.field(\"test_short\", test_short);\r\n        map.put(\"test_short\", test_short);\r\n        long test_long = randomValueOtherThanMany(map::containsValue, randomGenerator).longValue();\r\n        builder.field(\"test_long\", test_long);\r\n        map.put(\"test_long\", test_long);\r\n        double test_double = randomValueOtherThanMany(map::containsValue, randomGenerator).doubleValue();\r\n        builder.field(\"test_double\", test_double);\r\n        map.put(\"test_double\", test_double);\r\n        float test_float = randomValueOtherThanMany(map::containsValue, randomGenerator).floatValue();\r\n        builder.field(\"test_float\", test_float);\r\n        map.put(\"test_float\", test_float);\r\n    });\r\n    return map;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.demo.PlayerActivity.createAdsMediaSource",
	"Comment": "returns an ads media source, reusing the ads loader if one exists.",
	"Method": "MediaSource createAdsMediaSource(MediaSource mediaSource,Uri adTagUri){\r\n    try {\r\n        Class<?> loaderClass = Class.forName(\"com.google.android.exoplayer2.ext.ima.ImaAdsLoader\");\r\n        if (adsLoader == null) {\r\n            Constructor<? extends AdsLoader> loaderConstructor = loaderClass.asSubclass(AdsLoader.class).getConstructor(android.content.Context.class, android.net.Uri.class);\r\n            adsLoader = loaderConstructor.newInstance(this, adTagUri);\r\n            adUiViewGroup = new FrameLayout(this);\r\n            playerView.getOverlayFrameLayout().addView(adUiViewGroup);\r\n        }\r\n        AdsMediaSource.MediaSourceFactory adMediaSourceFactory = new AdsMediaSource.MediaSourceFactory() {\r\n            @Override\r\n            public MediaSource createMediaSource(Uri uri) {\r\n                return PlayerActivity.this.buildMediaSource(uri);\r\n            }\r\n            @Override\r\n            public int[] getSupportedTypes() {\r\n                return new int[] { C.TYPE_DASH, C.TYPE_SS, C.TYPE_HLS, C.TYPE_OTHER };\r\n            }\r\n        };\r\n        return new AdsMediaSource(mediaSource, adMediaSourceFactory, adsLoader, adUiViewGroup);\r\n    } catch (ClassNotFoundException e) {\r\n        return null;\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.demo.PlayerActivity.createAdsMediaSource",
	"Comment": "returns an ads media source, reusing the ads loader if one exists.",
	"Method": "MediaSource createAdsMediaSource(MediaSource mediaSource,Uri adTagUri){\r\n    return PlayerActivity.this.buildMediaSource(uri);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.demo.PlayerActivity.createAdsMediaSource",
	"Comment": "returns an ads media source, reusing the ads loader if one exists.",
	"Method": "MediaSource createAdsMediaSource(MediaSource mediaSource,Uri adTagUri){\r\n    return new int[] { C.TYPE_DASH, C.TYPE_SS, C.TYPE_HLS, C.TYPE_OTHER };\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.transport.ssl.SslIntegrationTests.testThatUnconfiguredCiphersAreRejected",
	"Comment": "no ssl exception as this is the exception is returned when connecting",
	"Method": "void testThatUnconfiguredCiphersAreRejected(){\r\n    Set<String> supportedCiphers = Sets.newHashSet(SSLContext.getDefault().getSupportedSSLParameters().getCipherSuites());\r\n    Set<String> defaultXPackCiphers = Sets.newHashSet(XPackSettings.DEFAULT_CIPHERS);\r\n    final List<String> unconfiguredCiphers = new ArrayList(Sets.difference(supportedCiphers, defaultXPackCiphers));\r\n    Collections.shuffle(unconfiguredCiphers, random());\r\n    assumeFalse(\"the unconfigured ciphers list is empty\", unconfiguredCiphers.isEmpty());\r\n    try (TransportClient transportClient = new TestXPackTransportClient(Settings.builder().put(transportClientSettings()).put(\"node.name\", \"programmatic_transport_client\").put(\"cluster.name\", internalCluster().getClusterName()).putList(\"xpack.ssl.cipher_suites\", unconfiguredCiphers).build(), LocalStateSecurity.class)) {\r\n        TransportAddress transportAddress = randomFrom(internalCluster().getInstance(Transport.class).boundAddress().boundAddresses());\r\n        transportClient.addTransportAddress(transportAddress);\r\n        transportClient.admin().cluster().prepareHealth().get();\r\n        fail(\"Expected NoNodeAvailableException\");\r\n    } catch (NoNodeAvailableException e) {\r\n        assertThat(e.getMessage(), containsString(\"None of the configured nodes are available: [{#transport#\"));\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerView.getControllerShowTimeoutMs",
	"Comment": "returns the playback controls timeout. the playback controls are automatically hidden afterthis duration of time has elapsed without user input and with playback or buffering inprogress.",
	"Method": "int getControllerShowTimeoutMs(){\r\n    return controllerShowTimeoutMs;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.audit.logfile.LoggingAuditTrailTests.forge",
	"Comment": "creates address without any lookups. hostname can be null, for missing",
	"Method": "InetAddress forge(String hostname,String address){\r\n    final byte[] bytes = InetAddress.getByName(address).getAddress();\r\n    return InetAddress.getByAddress(hostname, bytes);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.refreshToken",
	"Comment": "uses the refresh token to refresh its associated token and returns the new token with anupdated expiration date to the listener",
	"Method": "void refreshToken(String refreshToken,ActionListener<Tuple<UserToken, String>> listener){\r\n    ensureEnabled();\r\n    findTokenFromRefreshToken(refreshToken, ActionListener.wrap(tuple -> {\r\n        final Authentication userAuth = Authentication.readFromContext(client.threadPool().getThreadContext());\r\n        final String tokenDocId = tuple.v1().getHits().getHits()[0].getId();\r\n        innerRefresh(tokenDocId, userAuth, listener, tuple.v2());\r\n    }, listener::onFailure), new AtomicInteger(0));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authz.accesscontrol.OptOutQueryCache.cachingIsSafe",
	"Comment": "returns true if its safe to use the query cache for this query.",
	"Method": "boolean cachingIsSafe(Weight weight,IndicesAccessControl.IndexAccessControl permissions){\r\n    Set<String> fields = new HashSet();\r\n    try {\r\n        FieldExtractor.extractFields(weight.getQuery(), fields);\r\n    } catch (UnsupportedOperationException ok) {\r\n        return false;\r\n    }\r\n    for (String field : fields) {\r\n        if (field.startsWith(\"_\") || permissions.getFieldPermissions().grantsAccessTo(field) == false) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.ima.ImaAdsLoader.requestAds",
	"Comment": "requests ads, if they have not already been requested. must be called on the main thread.ads will be requested automatically when the player is prepared if this method has not beencalled, so it is only necessary to call this method if you want to request ads before preparingthe player.",
	"Method": "void requestAds(ViewGroup adUiViewGroup){\r\n    if (adPlaybackState != null || adsManager != null || pendingAdRequestContext != null) {\r\n        return;\r\n    }\r\n    adDisplayContainer.setAdContainer(adUiViewGroup);\r\n    pendingAdRequestContext = new Object();\r\n    AdsRequest request = imaFactory.createAdsRequest();\r\n    if (adTagUri != null) {\r\n        request.setAdTagUrl(adTagUri.toString());\r\n    } else {\r\n        request.setAdsResponse(adsResponse);\r\n    }\r\n    if (vastLoadTimeoutMs != TIMEOUT_UNSET) {\r\n        request.setVastLoadTimeout(vastLoadTimeoutMs);\r\n    }\r\n    request.setAdDisplayContainer(adDisplayContainer);\r\n    request.setContentProgressProvider(this);\r\n    request.setUserRequestContext(pendingAdRequestContext);\r\n    adsLoader.requestAds(request);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.SpnegoClient.handleResponse",
	"Comment": "handles server response and returns new token if any to be sent to server.",
	"Method": "String handleResponse(String base64Token){\r\n    if (gssContext.isEstablished()) {\r\n        throw new IllegalStateException(\"GSS Context has already been established\");\r\n    }\r\n    final byte[] token = Base64.getDecoder().decode(base64Token);\r\n    final byte[] outToken = KerberosTestCase.doAsWrapper(loginContext.getSubject(), (PrivilegedExceptionAction<byte[]>) () -> gssContext.initSecContext(token, 0, token.length));\r\n    if (outToken == null || outToken.length == 0) {\r\n        return null;\r\n    }\r\n    return Base64.getEncoder().encodeToString(outToken);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.ConstantBitrateSeekMap.getTimeUsAtPosition",
	"Comment": "returns the stream time in microseconds for a given stream position.",
	"Method": "long getTimeUsAtPosition(long position,long getTimeUsAtPosition,long position,long firstFrameBytePosition,int bitrate){\r\n    return Math.max(0, position - firstFrameBytePosition) * C.BITS_PER_BYTE * C.MICROS_PER_SECOND / bitrate;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.readUnsignedLongToLong",
	"Comment": "reads the next eight bytes as an unsigned long into a long, if the top bit is a zero.",
	"Method": "long readUnsignedLongToLong(){\r\n    long result = readLong();\r\n    if (result < 0) {\r\n        throw new IllegalStateException(\"Top bit not zero: \" + result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.DefaultExtractorInput.commitBytesRead",
	"Comment": "advances the position by the specified number of bytes read.",
	"Method": "void commitBytesRead(int bytesRead){\r\n    if (bytesRead != C.RESULT_END_OF_INPUT) {\r\n        position += bytesRead;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.transport.ssl.SslMultiPortTests.testThatTransportClientWithOnlyTruststoreCannotConnectToClientProfile",
	"Comment": "uses a transport client that only trusts the testnode certificate. this test connects to the client profile, which usesthe testnode certificate and requires the client to present a certificate, so this connection will never work asthe client has no certificate to present",
	"Method": "void testThatTransportClientWithOnlyTruststoreCannotConnectToClientProfile(){\r\n    Settings settings = Settings.builder().put(SecurityField.USER_SETTING.getKey(), TEST_USER_NAME + \":\" + TEST_PASSWORD).put(\"cluster.name\", internalCluster().getClusterName()).put(\"xpack.security.transport.ssl.enabled\", true).put(\"xpack.ssl.client_authentication\", SSLClientAuth.REQUIRED).put(\"xpack.ssl.certificate_authorities\", getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.crt\")).build();\r\n    try (TransportClient transportClient = new TestXPackTransportClient(settings, Collections.singletonList(LocalStateSecurity.class))) {\r\n        transportClient.addTransportAddress(new TransportAddress(InetAddress.getLoopbackAddress(), getProfilePort(\"client\")));\r\n        assertGreenClusterState(transportClient);\r\n        fail(\"Expected NoNodeAvailableException\");\r\n    } catch (NoNodeAvailableException e) {\r\n        assertThat(e.getMessage(), containsString(\"None of the configured nodes are available: [{#transport#-\"));\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.analytics.AnalyticsCollector.setPlayer",
	"Comment": "sets the player for which data will be collected. must only be called if no player has been setyet.",
	"Method": "void setPlayer(Player player){\r\n    Assertions.checkState(this.player == null);\r\n    this.player = Assertions.checkNotNull(player);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.FieldStatsCalculator.findTopHits",
	"Comment": "order by descending count, with a secondary sort to ensure reproducibility of results.",
	"Method": "List<Map<String, Object>> findTopHits(int numTopHits,Map<T, Integer> countsByValue,Comparator<Map.Entry<T, Integer>> secondarySort,Function<T, Object> outputMapper){\r\n    List<Map.Entry<T, Integer>> sortedByCount = countsByValue.entrySet().stream().sorted(Comparator.comparing(Map.Entry<T, Integer>::getValue, Comparator.reverseOrder()).thenComparing(secondarySort)).limit(numTopHits).collect(Collectors.toList());\r\n    List<Map<String, Object>> topHits = new ArrayList(sortedByCount.size());\r\n    for (Map.Entry<T, Integer> entry : sortedByCount) {\r\n        Map<String, Object> topHit = new LinkedHashMap(3);\r\n        topHit.put(\"value\", outputMapper.apply(entry.getKey()));\r\n        topHit.put(\"count\", entry.getValue());\r\n        topHits.add(topHit);\r\n    }\r\n    return topHits;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleQueue.discardTo",
	"Comment": "discards up to but not including the sample immediately before or at the specified time.",
	"Method": "void discardTo(long timeUs,boolean toKeyframe,boolean stopAtReadPosition){\r\n    discardDownstreamTo(metadataQueue.discardTo(timeUs, toKeyframe, stopAtReadPosition));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.GrokPatternCreator.processCandidateAndSplit",
	"Comment": "given a chosen grok pattern and a collection of message snippets, split the snippets into thematched section and the pieces before and after it.recurse to find more matches in the piecesbefore and after and update the supplied string builder.",
	"Method": "void processCandidateAndSplit(GrokPatternCandidate chosenPattern,boolean isLast,Collection<String> snippets,boolean ignoreKeyValueCandidateLeft,int ignoreValueOnlyCandidatesLeft,boolean ignoreKeyValueCandidateRight,int ignoreValueOnlyCandidatesRight){\r\n    Collection<String> prefaces = new ArrayList();\r\n    Collection<String> epilogues = new ArrayList();\r\n    String patternBuilderContent = chosenPattern.processCaptures(fieldNameCountStore, snippets, prefaces, epilogues, mappings, fieldStats, timeoutChecker);\r\n    appendBestGrokMatchForStrings(false, prefaces, ignoreKeyValueCandidateLeft, ignoreValueOnlyCandidatesLeft);\r\n    overallGrokPatternBuilder.append(patternBuilderContent);\r\n    appendBestGrokMatchForStrings(isLast, epilogues, ignoreKeyValueCandidateRight, ignoreValueOnlyCandidatesRight);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.AudioTimestampPoller.reset",
	"Comment": "resets polling. should be called whenever the audio track is paused or resumed.",
	"Method": "void reset(){\r\n    if (audioTimestamp != null) {\r\n        updateState(STATE_INITIALIZING);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.DefaultMediaClock.onRendererEnabled",
	"Comment": "notifies the media clock that a renderer has been enabled. starts using the media clock of theprovided renderer if available.",
	"Method": "void onRendererEnabled(Renderer renderer){\r\n    MediaClock rendererMediaClock = renderer.getMediaClock();\r\n    if (rendererMediaClock != null && rendererMediaClock != rendererClock) {\r\n        if (rendererClock != null) {\r\n            throw ExoPlaybackException.createForUnexpected(new IllegalStateException(\"Multiple renderer media clocks enabled.\"));\r\n        }\r\n        this.rendererClock = rendererMediaClock;\r\n        this.rendererClockSource = renderer;\r\n        rendererClock.setPlaybackParameters(standaloneMediaClock.getPlaybackParameters());\r\n        ensureSynced();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authz.AuthorizationUtils.switchUserBasedOnActionOriginAndExecute",
	"Comment": "stashes the current context and executes the consumer as the proper user based on the origin of the action.this method knows nothing about listeners so it is important that callers ensure their listeners preserve theircontext and restore it appropriately.",
	"Method": "void switchUserBasedOnActionOriginAndExecute(ThreadContext threadContext,SecurityContext securityContext,Consumer<ThreadContext.StoredContext> consumer){\r\n    final String actionOrigin = threadContext.getTransient(ClientHelper.ACTION_ORIGIN_TRANSIENT_NAME);\r\n    if (actionOrigin == null) {\r\n        assert false : \"cannot switch user if there is no action origin\";\r\n        throw new IllegalStateException(\"cannot switch user if there is no action origin\");\r\n    }\r\n    switch(actionOrigin) {\r\n        case SECURITY_ORIGIN:\r\n            securityContext.executeAsUser(XPackSecurityUser.INSTANCE, consumer, Version.CURRENT);\r\n            break;\r\n        case WATCHER_ORIGIN:\r\n        case ML_ORIGIN:\r\n        case MONITORING_ORIGIN:\r\n        case DEPRECATION_ORIGIN:\r\n        case PERSISTENT_TASK_ORIGIN:\r\n        case ROLLUP_ORIGIN:\r\n        case INDEX_LIFECYCLE_ORIGIN:\r\n        case TASKS_ORIGIN:\r\n            securityContext.executeAsUser(XPackUser.INSTANCE, consumer, Version.CURRENT);\r\n            break;\r\n        default:\r\n            assert false : \"action.origin [\" + actionOrigin + \"] is unknown!\";\r\n            throw new IllegalStateException(\"action.origin [\" + actionOrigin + \"] should always be a known value\");\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.test.rest.XPackRestIT.awaitCallApi",
	"Comment": "executes an api call using the admin context, waiting for it to succeed.",
	"Method": "void awaitCallApi(String apiName,Map<String, String> params,List<Map<String, Object>> bodies,CheckedFunction<ClientYamlTestResponse, Boolean, IOException> success,Supplier<String> error){\r\n    AtomicReference<IOException> exceptionHolder = new AtomicReference();\r\n    awaitBusy(() -> {\r\n        try {\r\n            ClientYamlTestResponse response = callApi(apiName, params, bodies, getApiCallHeaders());\r\n            if (response.getStatusCode() == HttpStatus.SC_OK) {\r\n                exceptionHolder.set(null);\r\n                return success.apply(response);\r\n            }\r\n            return false;\r\n        } catch (IOException e) {\r\n            exceptionHolder.set(e);\r\n        }\r\n        return false;\r\n    });\r\n    IOException exception = exceptionHolder.get();\r\n    if (exception != null) {\r\n        throw new IllegalStateException(error.get(), exception);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.TriggeredWatchStore.createBulkRequest",
	"Comment": "create a bulk request from the triggered watches with a specified document type",
	"Method": "BulkRequest createBulkRequest(List<TriggeredWatch> triggeredWatches){\r\n    BulkRequest request = new BulkRequest();\r\n    for (TriggeredWatch triggeredWatch : triggeredWatches) {\r\n        IndexRequest indexRequest = new IndexRequest(TriggeredWatchStoreField.INDEX_NAME, TriggeredWatchStoreField.DOC_TYPE, triggeredWatch.id().value());\r\n        try (XContentBuilder builder = XContentFactory.jsonBuilder()) {\r\n            triggeredWatch.toXContent(builder, ToXContent.EMPTY_PARAMS);\r\n            indexRequest.source(builder);\r\n        }\r\n        indexRequest.opType(IndexRequest.OpType.CREATE);\r\n        request.add(indexRequest);\r\n    }\r\n    return request;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.Util.getBytesFromHexString",
	"Comment": "returns a byte array containing values parsed from the hex string provided.",
	"Method": "byte[] getBytesFromHexString(String hexString){\r\n    byte[] data = new byte[hexString.length() / 2];\r\n    for (int i = 0; i < data.length; i++) {\r\n        int stringOffset = i * 2;\r\n        data[i] = (byte) ((Character.digit(hexString.charAt(stringOffset), 16) << 4) + Character.digit(hexString.charAt(stringOffset + 1), 16));\r\n    }\r\n    return data;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.cli.CliReplTests.testEmptyNotSent",
	"Comment": "test that empty commands are skipped. this includes commands that arejust new lines.",
	"Method": "void testEmptyNotSent(){\r\n    CliTerminal cliTerminal = new TestTerminal(\";\", \"\", \"\", \";\", \"exit;\");\r\n    CliSession mockSession = mock(CliSession.class);\r\n    CliCommand mockCommand = mock(CliCommand.class);\r\n    CliRepl cli = new CliRepl(cliTerminal, mockSession, mockCommand);\r\n    cli.execute();\r\n    verify(mockCommand, times(1)).handle(cliTerminal, mockSession, \"logo\");\r\n    verifyNoMoreInteractions(mockSession, mockCommand);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupJobTask.triggered",
	"Comment": "this is called by the scheduleengine when the cron triggers.",
	"Method": "void triggered(SchedulerEngine.Event event){\r\n    if (event.getJobName().equals(SCHEDULE_NAME + \"_\" + job.getConfig().getId())) {\r\n        logger.debug(\"Rollup indexer [\" + event.getJobName() + \"] schedule has triggered, state: [\" + indexer.getState() + \"]\");\r\n        indexer.maybeTriggerAsyncJob(System.currentTimeMillis());\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.integration.MlPluginDisabledIT.testActionsFail",
	"Comment": "check that when the ml plugin is disabled, you cannot create a job as therest handler is not registered",
	"Method": "void testActionsFail(){\r\n    XContentBuilder xContentBuilder = jsonBuilder();\r\n    xContentBuilder.startObject();\r\n    {\r\n        xContentBuilder.field(\"actions-fail-job\", \"foo\");\r\n        xContentBuilder.field(\"description\", \"Analysis of response time by airline\");\r\n        xContentBuilder.startObject(\"analysis_config\");\r\n        {\r\n            xContentBuilder.field(\"bucket_span\", \"3600s\");\r\n            xContentBuilder.startArray(\"detectors\");\r\n            {\r\n                xContentBuilder.startObject();\r\n                {\r\n                    xContentBuilder.field(\"function\", \"metric\");\r\n                    xContentBuilder.field(\"field_name\", \"responsetime\");\r\n                    xContentBuilder.field(\"by_field_name\", \"airline\");\r\n                }\r\n                xContentBuilder.endObject();\r\n            }\r\n            xContentBuilder.endArray();\r\n        }\r\n        xContentBuilder.endObject();\r\n        xContentBuilder.startObject(\"data_description\");\r\n        {\r\n            xContentBuilder.field(\"format\", \"xcontent\");\r\n            xContentBuilder.field(\"time_field\", \"time\");\r\n            xContentBuilder.field(\"time_format\", \"epoch\");\r\n        }\r\n        xContentBuilder.endObject();\r\n    }\r\n    xContentBuilder.endObject();\r\n    Request request = new Request(\"PUT\", MachineLearning.BASE_PATH + \"anomaly_detectors/foo\");\r\n    request.setJsonEntity(Strings.toString(xContentBuilder));\r\n    ResponseException exception = expectThrows(ResponseException.class, () -> client().performRequest(request));\r\n    assertThat(exception.getMessage(), containsString(\"no handler found for uri [/_xpack/ml/anomaly_detectors/foo] and method [PUT]\"));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.ConcatenatingMediaSource.getChildPeriodUid",
	"Comment": "return uid of child period from period uid of concatenated source.",
	"Method": "Object getChildPeriodUid(MediaSourceHolder holder,Object periodUid){\r\n    Object childUid = ConcatenatedTimeline.getChildPeriodUidFromConcatenatedUid(periodUid);\r\n    return childUid.equals(DeferredTimeline.DUMMY_ID) ? holder.timeline.replacedId : childUid;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.readLittleEndianUnsignedInt24",
	"Comment": "reads the next three bytes as an unsigned value in little endian order.",
	"Method": "int readLittleEndianUnsignedInt24(){\r\n    return (data[position++] & 0xFF) | (data[position++] & 0xFF) << 8 | (data[position++] & 0xFF) << 16;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ExoPlayerImplInternal.resolveSubsequentPeriod",
	"Comment": "given a period index into an old timeline, finds the first subsequent period that also existsin a new timeline. the uid of this period in the new timeline is returned.",
	"Method": "Object resolveSubsequentPeriod(Object oldPeriodUid,Timeline oldTimeline,Timeline newTimeline){\r\n    int oldPeriodIndex = oldTimeline.getIndexOfPeriod(oldPeriodUid);\r\n    int newPeriodIndex = C.INDEX_UNSET;\r\n    int maxIterations = oldTimeline.getPeriodCount();\r\n    for (int i = 0; i < maxIterations && newPeriodIndex == C.INDEX_UNSET; i++) {\r\n        oldPeriodIndex = oldTimeline.getNextPeriodIndex(oldPeriodIndex, period, window, repeatMode, shuffleModeEnabled);\r\n        if (oldPeriodIndex == C.INDEX_UNSET) {\r\n            break;\r\n        }\r\n        newPeriodIndex = newTimeline.getIndexOfPeriod(oldTimeline.getUidOfPeriod(oldPeriodIndex));\r\n    }\r\n    return newPeriodIndex == C.INDEX_UNSET ? null : newTimeline.getUidOfPeriod(newPeriodIndex);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.XmlPullParserUtil.getAttributeValueIgnorePrefix",
	"Comment": "returns the value of an attribute of the current start tag. any raw attribute names in thecurrent start tag have their prefixes stripped before matching.",
	"Method": "String getAttributeValueIgnorePrefix(XmlPullParser xpp,String attributeName){\r\n    int attributeCount = xpp.getAttributeCount();\r\n    for (int i = 0; i < attributeCount; i++) {\r\n        if (stripPrefix(xpp.getAttributeName(i)).equals(attributeName)) {\r\n            return xpp.getAttributeValue(i);\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.CodecSpecificDataUtil.buildAvcCodecString",
	"Comment": "builds an rfc 6381 avc codec string using the provided parameters.",
	"Method": "String buildAvcCodecString(int profileIdc,int constraintsFlagsAndReservedZero2Bits,int levelIdc){\r\n    return String.format(\"avc1.XXX\", profileIdc, constraintsFlagsAndReservedZero2Bits, levelIdc);\r\n}"
}, {
	"Path": "com.alibaba.fastjson.serializer.JavaBeanSerializer.getFieldNames",
	"Comment": "get field names of not null fields. keep the same logic as getsize.",
	"Method": "Set<String> getFieldNames(Object object){\r\n    Set<String> fieldNames = new HashSet<String>();\r\n    for (FieldSerializer getter : sortedGetters) {\r\n        Object value = getter.getPropertyValueDirect(object);\r\n        if (value != null) {\r\n            fieldNames.add(getter.fieldInfo.name);\r\n        }\r\n    }\r\n    return fieldNames;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.LdapRealm.doAuthenticate",
	"Comment": "given a username and password, open a connection to ldap, bind to authenticate, retrieve groups, map to roles and build the user.this user will then be passed to the listener",
	"Method": "void doAuthenticate(UsernamePasswordToken token,ActionListener<AuthenticationResult> listener){\r\n    assert delegatedRealms != null : \"Realm has not been initialized correctly\";\r\n    final CancellableLdapRunnable<AuthenticationResult> cancellableLdapRunnable = new CancellableLdapRunnable(listener, ex -> AuthenticationResult.unsuccessful(\"Authentication against realm [\" + this.toString() + \"] failed\", ex), () -> sessionFactory.session(token.principal(), token.credentials(), contextPreservingListener(new LdapSessionActionListener(\"authenticate\", token.principal(), listener))), logger);\r\n    threadPool.generic().execute(cancellableLdapRunnable);\r\n    threadPool.schedule(executionTimeout, Names.SAME, cancellableLdapRunnable::maybeTimeout);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.params.ForecastParams.getTmpStorage",
	"Comment": "temporary storage forecast is allowed to use for persisting models.",
	"Method": "String getTmpStorage(){\r\n    return tmpStorage;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.LdapSessionFactory.buildDnFromTemplate",
	"Comment": "securely escapes the username and inserts it into the template using messageformat",
	"Method": "String buildDnFromTemplate(String username,String template){\r\n    String escapedUsername = escapedRDNValue(username);\r\n    return new MessageFormat(template, Locale.ROOT).format(new Object[] { escapedUsername }, new StringBuffer(), null).toString();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.playlist.DefaultHlsPlaylistTracker.createFixedFactory",
	"Comment": "creates a factory which always returns the given playlist parser.",
	"Method": "HlsPlaylistParserFactory createFixedFactory(ParsingLoadable.Parser<HlsPlaylist> playlistParser){\r\n    return new HlsPlaylistParserFactory() {\r\n        @Override\r\n        public ParsingLoadable.Parser<HlsPlaylist> createPlaylistParser() {\r\n            return playlistParser;\r\n        }\r\n        @Override\r\n        public ParsingLoadable.Parser<HlsPlaylist> createPlaylistParser(HlsMasterPlaylist masterPlaylist) {\r\n            return playlistParser;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.playlist.DefaultHlsPlaylistTracker.createFixedFactory",
	"Comment": "creates a factory which always returns the given playlist parser.",
	"Method": "HlsPlaylistParserFactory createFixedFactory(ParsingLoadable.Parser<HlsPlaylist> playlistParser){\r\n    return playlistParser;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.playlist.DefaultHlsPlaylistTracker.createFixedFactory",
	"Comment": "creates a factory which always returns the given playlist parser.",
	"Method": "HlsPlaylistParserFactory createFixedFactory(ParsingLoadable.Parser<HlsPlaylist> playlistParser){\r\n    return playlistParser;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.AudioCapabilities.getMaxChannelCount",
	"Comment": "returns the maximum number of channels the device can play at the same time.",
	"Method": "int getMaxChannelCount(){\r\n    return maxChannelCount;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateGenerateTool.fullyWriteFile",
	"Comment": "this method handles the deletion of a file in the case of a partial write",
	"Method": "void fullyWriteFile(Path file,Writer writer){\r\n    boolean success = false;\r\n    try (OutputStream outputStream = Files.newOutputStream(file, StandardOpenOption.CREATE_NEW);\r\n        ZipOutputStream zipOutputStream = new ZipOutputStream(outputStream, StandardCharsets.UTF_8);\r\n        JcaPEMWriter pemWriter = new JcaPEMWriter(new OutputStreamWriter(zipOutputStream, StandardCharsets.UTF_8))) {\r\n        writer.write(zipOutputStream, pemWriter);\r\n        PosixFileAttributeView view = Files.getFileAttributeView(file, PosixFileAttributeView.class);\r\n        if (view != null) {\r\n            view.setPermissions(Sets.newHashSet(PosixFilePermission.OWNER_READ, PosixFilePermission.OWNER_WRITE));\r\n        }\r\n        success = true;\r\n    } finally {\r\n        if (success == false) {\r\n            Files.deleteIfExists(file);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.process.writer.AbstractControlMsgWriter.writeMessage",
	"Comment": "transform the supplied control message to length encoded values andwrite to the outputstream.",
	"Method": "void writeMessage(String message){\r\n    lengthEncodedWriter.writeNumFields(numberOfFields);\r\n    for (int i = 1; i < numberOfFields; ++i) {\r\n        lengthEncodedWriter.writeField(\"\");\r\n    }\r\n    lengthEncodedWriter.writeField(message);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.StandaloneMediaClock.start",
	"Comment": "starts the clock. does nothing if the clock is already started.",
	"Method": "void start(){\r\n    if (!started) {\r\n        baseElapsedMs = clock.elapsedRealtime();\r\n        started = true;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.notification.email.attachment.ReportingAttachmentParser.requestReportGeneration",
	"Comment": "trigger the initial report generation and catch possible exceptions",
	"Method": "HttpResponse requestReportGeneration(String watchId,String attachmentId,HttpRequest request){\r\n    HttpResponse response = httpClient.execute(request);\r\n    if (response.status() != 200) {\r\n        throw new ElasticsearchException(\"Watch[{}] reporting[{}] Error response when trying to trigger reporting generation \" + \"host[{}], port[{}] method[{}], path[{}], status[{}]\", watchId, attachmentId, request.host(), request.port(), request.method(), request.path(), response.status());\r\n    }\r\n    return response;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.Timeline.getLastWindowIndex",
	"Comment": "returns the index of the last window in the playback order depending on whether shuffling isenabled.",
	"Method": "int getLastWindowIndex(boolean shuffleModeEnabled){\r\n    return isEmpty() ? C.INDEX_UNSET : getWindowCount() - 1;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.PoolingSessionFactory.close",
	"Comment": "this method is used to cleanup the connection pool if one is being used",
	"Method": "void close(){\r\n    if (connectionPool != null) {\r\n        connectionPool.close();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.computeSecretKey",
	"Comment": "generates a secret key based off of the provided password and salt.this method is computationally expensive.",
	"Method": "SecretKey computeSecretKey(char[] rawPassword,byte[] salt){\r\n    SecretKeyFactory secretKeyFactory = SecretKeyFactory.getInstance(KDF_ALGORITHM);\r\n    PBEKeySpec keySpec = new PBEKeySpec(rawPassword, salt, ITERATIONS, 128);\r\n    SecretKey tmp = secretKeyFactory.generateSecret(keySpec);\r\n    return new SecretKeySpec(tmp.getEncoded(), \"AES\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.checkIfTokenIsRevoked",
	"Comment": "checks if the token has been stored as a revoked token to ensure we do not allow tokens thathave been explicitly cleared.",
	"Method": "void checkIfTokenIsRevoked(UserToken userToken,ActionListener<UserToken> listener){\r\n    if (securityIndex.indexExists() == false) {\r\n        listener.onResponse(userToken);\r\n    } else {\r\n        securityIndex.checkIndexVersionThenExecute(listener::onFailure, () -> {\r\n            MultiGetRequest mGetRequest = client.prepareMultiGet().add(SecurityIndexManager.SECURITY_INDEX_NAME, TYPE, getInvalidatedTokenDocumentId(userToken)).add(SecurityIndexManager.SECURITY_INDEX_NAME, TYPE, getTokenDocumentId(userToken)).request();\r\n            Consumer<Exception> onFailure = ex -> listener.onFailure(traceLog(\"check token state\", userToken.getId(), ex));\r\n            executeAsyncWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN, mGetRequest, new ActionListener<MultiGetResponse>() {\r\n                @Override\r\n                public void onResponse(MultiGetResponse response) {\r\n                    MultiGetItemResponse[] itemResponse = response.getResponses();\r\n                    if (itemResponse[0].isFailed()) {\r\n                        onFailure(itemResponse[0].getFailure().getFailure());\r\n                    } else if (itemResponse[0].getResponse().isExists()) {\r\n                        onFailure.accept(expiredTokenException());\r\n                    } else if (itemResponse[1].isFailed()) {\r\n                        onFailure(itemResponse[1].getFailure().getFailure());\r\n                    } else if (itemResponse[1].getResponse().isExists()) {\r\n                        Map<String, Object> source = itemResponse[1].getResponse().getSource();\r\n                        Map<String, Object> accessTokenSource = (Map<String, Object>) source.get(\"access_token\");\r\n                        if (accessTokenSource == null) {\r\n                            onFailure.accept(new IllegalStateException(\"token document is missing access_token field\"));\r\n                        } else {\r\n                            Boolean invalidated = (Boolean) accessTokenSource.get(\"invalidated\");\r\n                            if (invalidated == null) {\r\n                                onFailure.accept(new IllegalStateException(\"token document is missing invalidated field\"));\r\n                            } else if (invalidated) {\r\n                                onFailure.accept(expiredTokenException());\r\n                            } else {\r\n                                listener.onResponse(userToken);\r\n                            }\r\n                        }\r\n                    } else if (userToken.getVersion().onOrAfter(Version.V_6_2_0)) {\r\n                        onFailure.accept(new IllegalStateException(\"token document is missing and must be present\"));\r\n                    } else {\r\n                        listener.onResponse(userToken);\r\n                    }\r\n                }\r\n                @Override\r\n                public void onFailure(Exception e) {\r\n                    if (isShardNotAvailableException(e)) {\r\n                        logger.warn(\"failed to get token [{}] since index is not available\", userToken.getId());\r\n                        listener.onResponse(null);\r\n                    } else {\r\n                        logger.error(new ParameterizedMessage(\"failed to get token [{}]\", userToken.getId()), e);\r\n                        listener.onFailure(e);\r\n                    }\r\n                }\r\n            }, client::multiGet);\r\n        });\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.checkIfTokenIsRevoked",
	"Comment": "checks if the token has been stored as a revoked token to ensure we do not allow tokens thathave been explicitly cleared.",
	"Method": "void checkIfTokenIsRevoked(UserToken userToken,ActionListener<UserToken> listener){\r\n    MultiGetItemResponse[] itemResponse = response.getResponses();\r\n    if (itemResponse[0].isFailed()) {\r\n        onFailure(itemResponse[0].getFailure().getFailure());\r\n    } else if (itemResponse[0].getResponse().isExists()) {\r\n        onFailure.accept(expiredTokenException());\r\n    } else if (itemResponse[1].isFailed()) {\r\n        onFailure(itemResponse[1].getFailure().getFailure());\r\n    } else if (itemResponse[1].getResponse().isExists()) {\r\n        Map<String, Object> source = itemResponse[1].getResponse().getSource();\r\n        Map<String, Object> accessTokenSource = (Map<String, Object>) source.get(\"access_token\");\r\n        if (accessTokenSource == null) {\r\n            onFailure.accept(new IllegalStateException(\"token document is missing access_token field\"));\r\n        } else {\r\n            Boolean invalidated = (Boolean) accessTokenSource.get(\"invalidated\");\r\n            if (invalidated == null) {\r\n                onFailure.accept(new IllegalStateException(\"token document is missing invalidated field\"));\r\n            } else if (invalidated) {\r\n                onFailure.accept(expiredTokenException());\r\n            } else {\r\n                listener.onResponse(userToken);\r\n            }\r\n        }\r\n    } else if (userToken.getVersion().onOrAfter(Version.V_6_2_0)) {\r\n        onFailure.accept(new IllegalStateException(\"token document is missing and must be present\"));\r\n    } else {\r\n        listener.onResponse(userToken);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.checkIfTokenIsRevoked",
	"Comment": "checks if the token has been stored as a revoked token to ensure we do not allow tokens thathave been explicitly cleared.",
	"Method": "void checkIfTokenIsRevoked(UserToken userToken,ActionListener<UserToken> listener){\r\n    if (isShardNotAvailableException(e)) {\r\n        logger.warn(\"failed to get token [{}] since index is not available\", userToken.getId());\r\n        listener.onResponse(null);\r\n    } else {\r\n        logger.error(new ParameterizedMessage(\"failed to get token [{}]\", userToken.getId()), e);\r\n        listener.onFailure(e);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.PsshAtomUtil.parseSchemeSpecificData",
	"Comment": "parses the scheme specific data from a pssh atom. version 0 and 1 pssh atoms are supported.the scheme specific data is only parsed if the data is a valid pssh atom matching the givenuuid, or if the data is a valid pssh atom of any type in the case that the passed uuid is null.",
	"Method": "byte[] parseSchemeSpecificData(byte[] atom,UUID uuid){\r\n    PsshAtom parsedAtom = parsePsshAtom(atom);\r\n    if (parsedAtom == null) {\r\n        return null;\r\n    }\r\n    if (uuid != null && !uuid.equals(parsedAtom.uuid)) {\r\n        Log.w(TAG, \"UUID mismatch. Expected: \" + uuid + \", got: \" + parsedAtom.uuid + \".\");\r\n        return null;\r\n    }\r\n    return parsedAtom.schemeData;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherService.wrapWatcherService",
	"Comment": "wraps an abstract runnable to easier supply onfailure and dorun methods via lambdasthis ensures that the uncaught exception handler in the executing threadpool does not get called",
	"Method": "AbstractRunnable wrapWatcherService(Runnable run,Consumer<Exception> exceptionConsumer){\r\n    return new AbstractRunnable() {\r\n        @Override\r\n        public void onFailure(Exception e) {\r\n            exceptionConsumer.accept(e);\r\n        }\r\n        @Override\r\n        protected void doRun() throws Exception {\r\n            run.run();\r\n        }\r\n    };\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherService.wrapWatcherService",
	"Comment": "wraps an abstract runnable to easier supply onfailure and dorun methods via lambdasthis ensures that the uncaught exception handler in the executing threadpool does not get called",
	"Method": "AbstractRunnable wrapWatcherService(Runnable run,Consumer<Exception> exceptionConsumer){\r\n    exceptionConsumer.accept(e);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherService.wrapWatcherService",
	"Comment": "wraps an abstract runnable to easier supply onfailure and dorun methods via lambdasthis ensures that the uncaught exception handler in the executing threadpool does not get called",
	"Method": "AbstractRunnable wrapWatcherService(Runnable run,Consumer<Exception> exceptionConsumer){\r\n    run.run();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.amr.AmrExtractor.getBitrateFromFrameSize",
	"Comment": "returns the stream bitrate, given a frame size and the duration of that frame in microseconds.",
	"Method": "int getBitrateFromFrameSize(int frameSize,long durationUsPerFrame){\r\n    return (int) ((frameSize * C.BITS_PER_BYTE * C.MICROS_PER_SECOND) / durationUsPerFrame);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.KerberosTicketValidator.privilegedDisposeNoThrow",
	"Comment": "privileged wrapper for closing gsscontext, does not throw exceptions but logsthem as a debug message.",
	"Method": "void privilegedDisposeNoThrow(GSSContext gssContext){\r\n    if (gssContext != null) {\r\n        try {\r\n            AccessController.doPrivileged((PrivilegedExceptionAction<Void>) () -> {\r\n                gssContext.dispose();\r\n                return null;\r\n            });\r\n        } catch (PrivilegedActionException e) {\r\n            LOGGER.debug(\"Could not dispose GSS Context\", e.getCause());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.KerberosTicketValidator.createCredentials",
	"Comment": "for acquiring spnego mechanism credentials for service based on the subject",
	"Method": "GSSCredential createCredentials(GSSManager gssManager,Subject subject){\r\n    return doAsWrapper(subject, (PrivilegedExceptionAction<GSSCredential>) () -> gssManager.createCredential(null, GSSCredential.DEFAULT_LIFETIME, SUPPORTED_OIDS, GSSCredential.ACCEPT_ONLY));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.Atom.parseFullAtomFlags",
	"Comment": "parses the atom flags out of the additional integer component of a full atom.",
	"Method": "int parseFullAtomFlags(int fullAtomInt){\r\n    return 0x00FFFFFF & fullAtomInt;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.drm.OfflineLicenseHelper.getLicenseDurationRemainingSec",
	"Comment": "returns the remaining license and playback durations in seconds, for an offline license.",
	"Method": "Pair<Long, Long> getLicenseDurationRemainingSec(byte[] offlineLicenseKeySetId){\r\n    Assertions.checkNotNull(offlineLicenseKeySetId);\r\n    DrmSession<T> drmSession = openBlockingKeyRequest(DefaultDrmSessionManager.MODE_QUERY, offlineLicenseKeySetId, null);\r\n    DrmSessionException error = drmSession.getError();\r\n    Pair<Long, Long> licenseDurationRemainingSec = WidevineUtil.getLicenseDurationRemainingSec(drmSession);\r\n    drmSessionManager.releaseSession(drmSession);\r\n    if (error != null) {\r\n        if (error.getCause() instanceof KeysExpiredException) {\r\n            return Pair.create(0L, 0L);\r\n        }\r\n        throw error;\r\n    }\r\n    return licenseDurationRemainingSec;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeRealm.clearCache",
	"Comment": "method is used for testing to verify cache expiration since expireall is final",
	"Method": "void clearCache(){\r\n    expireAll();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.datafeed.ProblemTracker.reportExtractionProblem",
	"Comment": "reports as extraction problem if it is different than the last seen problem",
	"Method": "void reportExtractionProblem(String problemMessage){\r\n    reportProblem(Messages.JOB_AUDIT_DATAFEED_DATA_EXTRACTION_ERROR, problemMessage);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.vp9.VpxLibrary.isHighBitDepthSupported",
	"Comment": "returns true if the underlying libvpx library supports high bit depth.",
	"Method": "boolean isHighBitDepthSupported(){\r\n    String config = getBuildConfig();\r\n    int indexHbd = config != null ? config.indexOf(\"--enable-vp9-highbitdepth\") : -1;\r\n    return indexHbd >= 0;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.DataSourceInputStream.bytesRead",
	"Comment": "returns the total number of bytes that have been read or skipped.",
	"Method": "long bytesRead(){\r\n    return totalBytesRead;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.smoothstreaming.manifest.SsManifestParserTest.testParseSmoothStreamingManifest",
	"Comment": "simple test to ensure the sample manifests parse without any exceptions being thrown.",
	"Method": "void testParseSmoothStreamingManifest(){\r\n    SsManifestParser parser = new SsManifestParser();\r\n    parser.parse(Uri.parse(\"https://example.com/test.ismc\"), TestUtil.getInputStream(RuntimeEnvironment.application, SAMPLE_ISMC_1));\r\n    parser.parse(Uri.parse(\"https://example.com/test.ismc\"), TestUtil.getInputStream(RuntimeEnvironment.application, SAMPLE_ISMC_2));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.opus.OpusLibrary.isAvailable",
	"Comment": "returns whether the underlying library is available, loading it if necessary.",
	"Method": "boolean isAvailable(){\r\n    return LOADER.isAvailable();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.TrackSampleTable.getIndexOfLaterOrEqualSynchronizationSample",
	"Comment": "returns the sample index of the closest synchronization sample at or after the given timestamp,if one is available.",
	"Method": "int getIndexOfLaterOrEqualSynchronizationSample(long timeUs){\r\n    int startIndex = Util.binarySearchCeil(timestampsUs, timeUs, true, false);\r\n    for (int i = startIndex; i < timestampsUs.length; i++) {\r\n        if ((flags[i] & C.BUFFER_FLAG_KEY_FRAME) != 0) {\r\n            return i;\r\n        }\r\n    }\r\n    return C.INDEX_UNSET;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.AbstractConcatenatedTimeline.getChildTimelineUidFromConcatenatedUid",
	"Comment": "returns uid of child timeline from a concatenated period uid.",
	"Method": "Object getChildTimelineUidFromConcatenatedUid(Object concatenatedUid){\r\n    return ((Pair<?, ?>) concatenatedUid).first;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.MappingTrackSelectorTest.testMapping",
	"Comment": "tests that the video and audio track groups are mapped onto the correct renderers.",
	"Method": "void testMapping(){\r\n    FakeMappingTrackSelector trackSelector = new FakeMappingTrackSelector();\r\n    trackSelector.selectTracks(RENDERER_CAPABILITIES, TRACK_GROUPS);\r\n    trackSelector.assertMappedTrackGroups(0, VIDEO_TRACK_GROUP);\r\n    trackSelector.assertMappedTrackGroups(1, AUDIO_TRACK_GROUP);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.wav.WavHeader.hasDataBounds",
	"Comment": "returns whether the data start position and size have been set.",
	"Method": "boolean hasDataBounds(){\r\n    return dataStartPosition != 0 && dataSize != 0;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateGenerateTool.parseFile",
	"Comment": "parses the input file to retrieve the certificate information",
	"Method": "Collection<CertificateInformation> parseFile(Path file){\r\n    try (Reader reader = Files.newBufferedReader(file)) {\r\n        XContentParser xContentParser = XContentType.YAML.xContent().createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, reader);\r\n        return InputFileParser.PARSER.parse(xContentParser, new ArrayList(), null);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.AtomicFile.openRead",
	"Comment": "open the atomic file for reading. if there previously was an incomplete write, this will rollback to the last good data before opening for read.note that if another thread is currently performing a write, this will incorrectly considerit to be in the state of a bad write and roll back, causing the new data currently beingwritten to be dropped. you must do your own threading protection for access to atomicfile.",
	"Method": "InputStream openRead(){\r\n    restoreBackup();\r\n    return new FileInputStream(baseName);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.support.Automatons.wildcard",
	"Comment": "builds and returns an automaton that represents the given pattern.",
	"Method": "Automaton wildcard(String text){\r\n    List<Automaton> automata = new ArrayList();\r\n    for (int i = 0; i < text.length(); ) {\r\n        final char c = text.charAt(i);\r\n        int length = 1;\r\n        switch(c) {\r\n            case WILDCARD_STRING:\r\n                automata.add(Automata.makeAnyString());\r\n                break;\r\n            case WILDCARD_CHAR:\r\n                automata.add(Automata.makeAnyChar());\r\n                break;\r\n            case WILDCARD_ESCAPE:\r\n                if (i + length < text.length()) {\r\n                    final char nextChar = text.charAt(i + length);\r\n                    length += 1;\r\n                    automata.add(Automata.makeChar(nextChar));\r\n                    break;\r\n                }\r\n            default:\r\n                automata.add(Automata.makeChar(c));\r\n        }\r\n        i += length;\r\n    }\r\n    return concatenate(automata);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.jdbc.SqlQueryParameterAnalyzer.skipString",
	"Comment": "skips a string starting at the current position i, returns the length of the string",
	"Method": "int skipString(int i,String sql,char q){\r\n    for (i = i + 1; i < sql.length(); i++) {\r\n        char c = sql.charAt(i);\r\n        if (c == q) {\r\n            if (i + 1 < sql.length() && sql.charAt(i + 1) == q) {\r\n                i++;\r\n            } else {\r\n                return i;\r\n            }\r\n        }\r\n    }\r\n    throw new SQLException(\"Cannot parse given sql; unclosed string\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authz.permission.FieldPermissions.grantsAccessTo",
	"Comment": "returns true if this field permission policy allows access to the field and false if not.fieldname can be a wildcard.",
	"Method": "boolean grantsAccessTo(String fieldName){\r\n    return permittedFieldsAutomatonIsTotal || permittedFieldsAutomaton.run(fieldName);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.token.InvalidateTokenRequestBuilder.setTokenString",
	"Comment": "the string representation of the token that is being invalidated. this is the value returnedfrom a create token request.",
	"Method": "InvalidateTokenRequestBuilder setTokenString(String token){\r\n    request.setTokenString(token);\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testReloadingPEMTrustConfig",
	"Comment": "test the reloading of sslcontext whose trust config is backed by pem certificate files.",
	"Method": "void testReloadingPEMTrustConfig(){\r\n    Path tempDir = createTempDir();\r\n    Path serverCertPath = tempDir.resolve(\"testnode.crt\");\r\n    Path serverKeyPath = tempDir.resolve(\"testnode.pem\");\r\n    Path updatedCert = tempDir.resolve(\"updated.crt\");\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.crt\"), serverCertPath);\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.pem\"), serverKeyPath);\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode_updated.crt\"), updatedCert);\r\n    Settings settings = Settings.builder().put(\"xpack.ssl.certificate_authorities\", serverCertPath).put(\"path.home\", createTempDir()).build();\r\n    Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);\r\n    try (MockWebServer server = getSslServer(serverKeyPath, serverCertPath, \"testnode\")) {\r\n        final Consumer<SSLContext> trustMaterialPreChecks = (context) -> {\r\n            try (CloseableHttpClient client = HttpClients.custom().setSSLContext(context).build()) {\r\n                privilegedConnect(() -> client.execute(new HttpGet(\"https://localhost:\" + server.getPort())).close());\r\n            } catch (Exception e) {\r\n                throw new RuntimeException(\"Exception connecting to the mock server\", e);\r\n            }\r\n        };\r\n        final Runnable modifier = () -> {\r\n            try {\r\n                atomicMoveIfPossible(updatedCert, serverCertPath);\r\n            } catch (Exception e) {\r\n                throw new RuntimeException(\"failed to modify file\", e);\r\n            }\r\n        };\r\n        final Consumer<SSLContext> trustMaterialPostChecks = (updatedContext) -> {\r\n            try (CloseableHttpClient client = HttpClients.custom().setSSLContext(updatedContext).build()) {\r\n                SSLHandshakeException sslException = expectThrows(SSLHandshakeException.class, () -> privilegedConnect(() -> client.execute(new HttpGet(\"https://localhost:\" + server.getPort())).close()));\r\n                assertThat(sslException.getCause().getMessage(), containsString(\"PKIX path validation failed\"));\r\n            } catch (Exception e) {\r\n                throw new RuntimeException(\"Error closing CloseableHttpClient\", e);\r\n            }\r\n        };\r\n        validateSSLConfigurationIsReloaded(settings, env, trustMaterialPreChecks, modifier, trustMaterialPostChecks);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.transport.nio.SSLDriver.renegotiate",
	"Comment": "requests a tls renegotiation. this means the we will request that the peer performs another handshakeprior to the continued exchange of application data. this can only be requested if we are currently inapplication mode.",
	"Method": "void renegotiate(){\r\n    if (currentMode.isApplication()) {\r\n        currentMode = new HandshakeMode();\r\n        engine.beginHandshake();\r\n        ((HandshakeMode) currentMode).startHandshake();\r\n    } else {\r\n        throw new IllegalStateException(\"Attempted to renegotiate while in invalid mode: \" + currentMode.modeName());\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexer.createAggregationBuilders",
	"Comment": "this returns a set of aggregation builders which represent the configuredset of metrics. used to iterate over historical data.",
	"Method": "List<AggregationBuilder> createAggregationBuilders(List<MetricConfig> metricsConfigs){\r\n    final List<AggregationBuilder> builders = new ArrayList();\r\n    if (metricsConfigs != null) {\r\n        for (MetricConfig metricConfig : metricsConfigs) {\r\n            final List<String> metrics = metricConfig.getMetrics();\r\n            if (metrics.isEmpty() == false) {\r\n                final String field = metricConfig.getField();\r\n                for (String metric : metrics) {\r\n                    ValuesSourceAggregationBuilder.LeafOnly newBuilder;\r\n                    if (metric.equals(MetricConfig.MIN.getPreferredName())) {\r\n                        newBuilder = new MinAggregationBuilder(formatFieldName(field, MinAggregationBuilder.NAME, RollupField.VALUE));\r\n                    } else if (metric.equals(MetricConfig.MAX.getPreferredName())) {\r\n                        newBuilder = new MaxAggregationBuilder(formatFieldName(field, MaxAggregationBuilder.NAME, RollupField.VALUE));\r\n                    } else if (metric.equals(MetricConfig.AVG.getPreferredName())) {\r\n                        newBuilder = new SumAggregationBuilder(formatFieldName(field, AvgAggregationBuilder.NAME, RollupField.VALUE));\r\n                        ValuesSourceAggregationBuilder.LeafOnly countBuilder = new ValueCountAggregationBuilder(formatFieldName(field, AvgAggregationBuilder.NAME, RollupField.COUNT_FIELD), ValueType.NUMERIC);\r\n                        countBuilder.field(field);\r\n                        builders.add(countBuilder);\r\n                    } else if (metric.equals(MetricConfig.SUM.getPreferredName())) {\r\n                        newBuilder = new SumAggregationBuilder(formatFieldName(field, SumAggregationBuilder.NAME, RollupField.VALUE));\r\n                    } else if (metric.equals(MetricConfig.VALUE_COUNT.getPreferredName())) {\r\n                        newBuilder = new ValueCountAggregationBuilder(formatFieldName(field, ValueCountAggregationBuilder.NAME, RollupField.VALUE), ValueType.NUMERIC);\r\n                    } else {\r\n                        throw new IllegalArgumentException(\"Unsupported metric type [\" + metric + \"]\");\r\n                    }\r\n                    newBuilder.field(field);\r\n                    builders.add(newBuilder);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return Collections.unmodifiableList(builders);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateTool.readPrivateKey",
	"Comment": "helper method to read a private key and support prompting of user for a key. to avoid passwords being placed as an argument wecan prompt the user for their password if we encounter an encrypted key.",
	"Method": "PrivateKey readPrivateKey(Path path,char[] password,Terminal terminal){\r\n    AtomicReference<char[]> passwordReference = new AtomicReference(password);\r\n    try {\r\n        return PemUtils.readPrivateKey(path, () -> {\r\n            if (password != null) {\r\n                return password;\r\n            }\r\n            char[] promptedValue = terminal.readSecret(\"Enter password for CA private key (\" + path.getFileName() + \") : \");\r\n            passwordReference.set(promptedValue);\r\n            return promptedValue;\r\n        });\r\n    } finally {\r\n        if (passwordReference.get() != null) {\r\n            Arrays.fill(passwordReference.get(), (char) 0);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.ParsingLoadable.bytesLoaded",
	"Comment": "returns the number of bytes loaded. in the case that the network response was compressed, thevalue returned is the size of the data after decompression. must only be called afterthe load completed, failed, or was canceled.",
	"Method": "long bytesLoaded(){\r\n    return dataSource.getBytesRead();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.TimedValueQueue.pollFloor",
	"Comment": "returns the value with the greatest timestamp which is less than or equal to the giventimestamp. removes all older values and the returned one from the buffer.",
	"Method": "V pollFloor(long timestamp){\r\n    return poll(timestamp, true);\r\n}"
}, {
	"Path": "com.alibaba.fastjson.util.AntiCollisionHashMap.removeEntryForKey",
	"Comment": "removes and returns the entry associated with the specified key in thesafelyhashmap. returns null if the safelyhashmap contains no mapping forthis key.",
	"Method": "Entry<K, V> removeEntryForKey(Object key){\r\n    int hash = (key == null) ? 0 : (key instanceof String) ? hash(hashString((String) key)) : hash(key.hashCode());\r\n    int i = indexFor(hash, table.length);\r\n    Entry<K, V> prev = table[i];\r\n    Entry<K, V> e = prev;\r\n    while (e != null) {\r\n        Entry<K, V> next = e.next;\r\n        Object k;\r\n        if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) {\r\n            modCount++;\r\n            size--;\r\n            if (prev == e)\r\n                table[i] = next;\r\n            else\r\n                prev.next = next;\r\n            return e;\r\n        }\r\n        prev = e;\r\n        e = next;\r\n    }\r\n    return e;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLService.isConfigurationValidForServerUsage",
	"Comment": "returns whether the provided settings results in a valid configuration that can be used for server connections",
	"Method": "boolean isConfigurationValidForServerUsage(SSLConfiguration sslConfiguration){\r\n    Objects.requireNonNull(sslConfiguration, \"SSLConfiguration cannot be null\");\r\n    return sslConfiguration.keyConfig() != KeyConfig.NONE;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerView.setControllerShowTimeoutMs",
	"Comment": "sets the playback controls timeout. the playback controls are automatically hidden after thisduration of time has elapsed without user input and with playback or buffering in progress.",
	"Method": "void setControllerShowTimeoutMs(int controllerShowTimeoutMs){\r\n    Assertions.checkState(controller != null);\r\n    this.controllerShowTimeoutMs = controllerShowTimeoutMs;\r\n    if (controller.isVisible()) {\r\n        showController();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.history.HistoryActionConditionTests.testActionConditionWithHardFailures",
	"Comment": "a hard failure is where an exception is thrown by the script condition.",
	"Method": "void testActionConditionWithHardFailures(){\r\n    final String id = \"testActionConditionWithHardFailures\";\r\n    final ExecutableCondition scriptConditionFailsHard = mockScriptCondition(\"throw new IllegalStateException('failed');\");\r\n    final List<ExecutableCondition> actionConditionsWithFailure = Arrays.asList(scriptConditionFailsHard, conditionPasses, InternalAlwaysCondition.INSTANCE);\r\n    Collections.shuffle(actionConditionsWithFailure, random());\r\n    final int failedIndex = actionConditionsWithFailure.indexOf(scriptConditionFailsHard);\r\n    putAndTriggerWatch(id, input, actionConditionsWithFailure.toArray(new Condition[actionConditionsWithFailure.size()]));\r\n    flush();\r\n    assertWatchWithMinimumActionsCount(id, ExecutionState.EXECUTED, 1);\r\n    final SearchResponse response = searchHistory(SearchSourceBuilder.searchSource().query(termQuery(\"watch_id\", id)));\r\n    assertThat(response.getHits().getTotalHits(), is(1L));\r\n    final SearchHit hit = response.getHits().getAt(0);\r\n    final List<Object> actions = getActionsFromHit(hit.getSourceAsMap());\r\n    for (int i = 0; i < actionConditionsWithFailure.size(); ++i) {\r\n        final Map<String, Object> action = (Map<String, Object>) actions.get(i);\r\n        final Map<String, Object> condition = (Map<String, Object>) action.get(\"condition\");\r\n        final Map<String, Object> logging = (Map<String, Object>) action.get(\"logging\");\r\n        assertThat(action.get(\"id\"), is(\"action\" + i));\r\n        if (i == failedIndex) {\r\n            assertThat(action.get(\"status\"), is(\"condition_failed\"));\r\n            assertThat(action.get(\"reason\"), is(\"condition failed. skipping: [expected] failed hard\"));\r\n            assertThat(condition, nullValue());\r\n            assertThat(logging, nullValue());\r\n        } else {\r\n            assertThat(condition.get(\"type\"), is(actionConditionsWithFailure.get(i).type()));\r\n            assertThat(action.get(\"status\"), is(\"success\"));\r\n            assertThat(condition.get(\"met\"), is(true));\r\n            assertThat(action.get(\"reason\"), nullValue());\r\n            assertThat(logging.get(\"logged_text\"), is(Integer.toString(i)));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.KerberosRealmTestCase.buildKerberosRealmSettings",
	"Comment": "build kerberos realm settings with default config and given keytab",
	"Method": "Settings buildKerberosRealmSettings(String realmName,String keytabPath,Settings buildKerberosRealmSettings,String realmName,String keytabPath,int maxUsersInCache,String cacheTTL,boolean enableDebugging,boolean removeRealmName,Settings buildKerberosRealmSettings,String realmName,String keytabPath,int maxUsersInCache,String cacheTTL,boolean enableDebugging,boolean removeRealmName,Settings globalSettings){\r\n    final Settings.Builder builder = Settings.builder().put(RealmSettings.getFullSettingKey(realmName, KerberosRealmSettings.HTTP_SERVICE_KEYTAB_PATH), keytabPath).put(RealmSettings.getFullSettingKey(realmName, KerberosRealmSettings.CACHE_MAX_USERS_SETTING), maxUsersInCache).put(RealmSettings.getFullSettingKey(realmName, KerberosRealmSettings.CACHE_TTL_SETTING), cacheTTL).put(RealmSettings.getFullSettingKey(realmName, KerberosRealmSettings.SETTING_KRB_DEBUG_ENABLE), enableDebugging).put(RealmSettings.getFullSettingKey(realmName, KerberosRealmSettings.SETTING_REMOVE_REALM_NAME), removeRealmName).put(globalSettings);\r\n    return builder.build();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.BinarySearchSeeker.setSeekTargetUs",
	"Comment": "sets the target time in microseconds within the stream to seek to.",
	"Method": "void setSeekTargetUs(long timeUs){\r\n    if (seekOperationParams != null && seekOperationParams.getSeekTimeUs() == timeUs) {\r\n        return;\r\n    }\r\n    seekOperationParams = createSeekParamsForTargetTimeUs(timeUs);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.rest.job.RestDeleteJobAction.nullTaskListener",
	"Comment": "or it will be stored in the task result when called asynchronously",
	"Method": "TaskListener nullTaskListener(){\r\n    return new TaskListener() {\r\n        @Override\r\n        public void onResponse(Task task, Object o) {\r\n        }\r\n        @Override\r\n        public void onFailure(Task task, Throwable e) {\r\n        }\r\n    };\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.rest.job.RestDeleteJobAction.nullTaskListener",
	"Comment": "or it will be stored in the task result when called asynchronously",
	"Method": "TaskListener nullTaskListener(){\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.rest.job.RestDeleteJobAction.nullTaskListener",
	"Comment": "or it will be stored in the task result when called asynchronously",
	"Method": "TaskListener nullTaskListener(){\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.findActiveTokensForRealm",
	"Comment": "find all stored refresh and access tokens that have not been invalidated or expired, and were issued against the specified realm.",
	"Method": "void findActiveTokensForRealm(String realmName,ActionListener<Collection<Tuple<UserToken, String>>> listener){\r\n    ensureEnabled();\r\n    final SecurityIndexManager frozenSecurityIndex = securityIndex.freeze();\r\n    if (Strings.isNullOrEmpty(realmName)) {\r\n        listener.onFailure(new IllegalArgumentException(\"Realm name is required\"));\r\n    } else if (frozenSecurityIndex.indexExists() == false) {\r\n        listener.onResponse(Collections.emptyList());\r\n    } else if (frozenSecurityIndex.isAvailable() == false) {\r\n        listener.onFailure(frozenSecurityIndex.getUnavailableReason());\r\n    } else {\r\n        final Instant now = clock.instant();\r\n        final BoolQueryBuilder boolQuery = QueryBuilders.boolQuery().filter(QueryBuilders.termQuery(\"doc_type\", \"token\")).filter(QueryBuilders.termQuery(\"access_token.realm\", realmName)).filter(QueryBuilders.boolQuery().should(QueryBuilders.boolQuery().must(QueryBuilders.termQuery(\"access_token.invalidated\", false)).must(QueryBuilders.rangeQuery(\"access_token.user_token.expiration_time\").gte(now.toEpochMilli()))).should(QueryBuilders.termQuery(\"refresh_token.invalidated\", false)));\r\n        final SearchRequest request = client.prepareSearch(SecurityIndexManager.SECURITY_INDEX_NAME).setScroll(DEFAULT_KEEPALIVE_SETTING.get(settings)).setQuery(boolQuery).setVersion(false).setSize(1000).setFetchSource(true).request();\r\n        securityIndex.checkIndexVersionThenExecute(listener::onFailure, () -> ScrollHelper.fetchAllByEntity(client, request, listener, this::parseHit));\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherService.shutDown",
	"Comment": "shuts down the trigger service as well to make sure there are no lingering threadsalso no need to check anything, as this is final, we just can go to status stopped",
	"Method": "void shutDown(){\r\n    logger.info(\"stopping watch service, reason [shutdown initiated]\");\r\n    executionService.pause();\r\n    triggerService.stop();\r\n    stopExecutor();\r\n    logger.debug(\"watch service has stopped\");\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecInfo.newPassthroughInstance",
	"Comment": "creates an instance representing an audio passthrough decoder.",
	"Method": "MediaCodecInfo newPassthroughInstance(String name){\r\n    return new MediaCodecInfo(name, null, null, true, false, false);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.TimelineAsserts.assertNextWindowIndices",
	"Comment": "asserts that next window indices for each window depending on the repeat mode and the shufflemode are equal to the given sequence.",
	"Method": "void assertNextWindowIndices(Timeline timeline,int repeatMode,boolean shuffleModeEnabled,int expectedNextWindowIndices){\r\n    for (int i = 0; i < timeline.getWindowCount(); i++) {\r\n        assertThat(timeline.getNextWindowIndex(i, repeatMode, shuffleModeEnabled)).isEqualTo(expectedNextWindowIndices[i]);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecInfo.isAudioSampleRateSupportedV21",
	"Comment": "whether the decoder supports audio with a given sample rate.must not be called if the device sdk version is less than 21.",
	"Method": "boolean isAudioSampleRateSupportedV21(int sampleRate){\r\n    if (capabilities == null) {\r\n        logNoSupport(\"sampleRate.caps\");\r\n        return false;\r\n    }\r\n    AudioCapabilities audioCapabilities = capabilities.getAudioCapabilities();\r\n    if (audioCapabilities == null) {\r\n        logNoSupport(\"sampleRate.aCaps\");\r\n        return false;\r\n    }\r\n    if (!audioCapabilities.isSampleRateSupported(sampleRate)) {\r\n        logNoSupport(\"sampleRate.support, \" + sampleRate);\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.audit.AuditTrailService.getAuditTrails",
	"Comment": "returns the audit trail implementations that this service delegates to.",
	"Method": "List<AuditTrail> getAuditTrails(){\r\n    return auditTrails;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.test.integration.SingleNodeTests.testThatLoadingWithNonExistingIndexWorks",
	"Comment": "the watch should be executed properly, despite the index being created and the cluster state listener being reloaded",
	"Method": "void testThatLoadingWithNonExistingIndexWorks(){\r\n    stopWatcher();\r\n    ClusterStateResponse clusterStateResponse = client().admin().cluster().prepareState().get();\r\n    IndexMetaData metaData = WatchStoreUtils.getConcreteIndex(Watch.INDEX, clusterStateResponse.getState().metaData());\r\n    String watchIndexName = metaData.getIndex().getName();\r\n    assertAcked(client().admin().indices().prepareDelete(watchIndexName));\r\n    startWatcher();\r\n    String watchId = randomAlphaOfLength(20);\r\n    PutWatchResponse putWatchResponse = watcherClient().preparePutWatch(watchId).setSource(watchBuilder().trigger(schedule(interval(1, IntervalSchedule.Interval.Unit.SECONDS))).input(simpleInput()).addAction(\"_logger\", loggingAction(\"logging of watch _name\"))).get();\r\n    assertThat(putWatchResponse.isCreated(), is(true));\r\n    assertBusy(() -> {\r\n        client().admin().indices().prepareRefresh(\".watcher-history*\");\r\n        SearchResponse searchResponse = client().prepareSearch(\".watcher-history*\").setSize(0).get();\r\n        assertThat(searchResponse.getHits().getTotalHits(), is(greaterThanOrEqualTo(1L)));\r\n    }, 5, TimeUnit.SECONDS);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.drm.DrmInitData.get",
	"Comment": "retrieves data for a given drm scheme, specified by its uuid.",
	"Method": "SchemeData get(UUID uuid,SchemeData get,int index){\r\n    return schemeDatas[index];\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.test.feature_aware.FeatureAwareCheckTests.runCustomViolationTest",
	"Comment": "runs a test on an actual class implementing a custom interface and not the expected marker interface.",
	"Method": "void runCustomViolationTest(Class<? extends ClusterState.FeatureAware> clazz,Class<?> outerClazz,Class<? extends ClusterState.FeatureAware> interfaceClazz,Class<? extends ClusterState.FeatureAware> expectedInterfaceClazz){\r\n    runTest(clazz, outerClazz, interfaceClazz, expectedInterfaceClazz, true);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.Sonic.queueEndOfStream",
	"Comment": "forces generating output using whatever data has been queued already. no extra delay will beadded to the output, but flushing in the middle of words could introduce distortion.",
	"Method": "void queueEndOfStream(){\r\n    int remainingFrameCount = inputFrameCount;\r\n    float s = speed / pitch;\r\n    float r = rate * pitch;\r\n    int expectedOutputFrames = outputFrameCount + (int) ((remainingFrameCount / s + pitchFrameCount) / r + 0.5f);\r\n    inputBuffer = ensureSpaceForAdditionalFrames(inputBuffer, inputFrameCount, remainingFrameCount + 2 * maxRequiredFrameCount);\r\n    for (int xSample = 0; xSample < 2 * maxRequiredFrameCount * channelCount; xSample++) {\r\n        inputBuffer[remainingFrameCount * channelCount + xSample] = 0;\r\n    }\r\n    inputFrameCount += 2 * maxRequiredFrameCount;\r\n    processStreamInput();\r\n    if (outputFrameCount > expectedOutputFrames) {\r\n        outputFrameCount = expectedOutputFrames;\r\n    }\r\n    inputFrameCount = 0;\r\n    remainingInputToCopyFrameCount = 0;\r\n    pitchFrameCount = 0;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.realm.ClearRealmCacheRequest.usernames",
	"Comment": "sets the usernames of the users that should be evicted from the caches. when not set, all userswill be evicted.",
	"Method": "String[] usernames(ClearRealmCacheRequest usernames,String usernames){\r\n    this.usernames = usernames;\r\n    return this;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.DefaultHttpDataSource.getContentLength",
	"Comment": "attempts to extract the length of the content from the response headers of an open connection.",
	"Method": "long getContentLength(HttpURLConnection connection){\r\n    long contentLength = C.LENGTH_UNSET;\r\n    String contentLengthHeader = connection.getHeaderField(\"Content-Length\");\r\n    if (!TextUtils.isEmpty(contentLengthHeader)) {\r\n        try {\r\n            contentLength = Long.parseLong(contentLengthHeader);\r\n        } catch (NumberFormatException e) {\r\n            Log.e(TAG, \"Unexpected Content-Length [\" + contentLengthHeader + \"]\");\r\n        }\r\n    }\r\n    String contentRangeHeader = connection.getHeaderField(\"Content-Range\");\r\n    if (!TextUtils.isEmpty(contentRangeHeader)) {\r\n        Matcher matcher = CONTENT_RANGE_HEADER.matcher(contentRangeHeader);\r\n        if (matcher.find()) {\r\n            try {\r\n                long contentLengthFromRange = Long.parseLong(matcher.group(2)) - Long.parseLong(matcher.group(1)) + 1;\r\n                if (contentLength < 0) {\r\n                    contentLength = contentLengthFromRange;\r\n                } else if (contentLength != contentLengthFromRange) {\r\n                    Log.w(TAG, \"Inconsistent headers [\" + contentLengthHeader + \"] [\" + contentRangeHeader + \"]\");\r\n                    contentLength = Math.max(contentLength, contentLengthFromRange);\r\n                }\r\n            } catch (NumberFormatException e) {\r\n                Log.e(TAG, \"Unexpected Content-Range [\" + contentRangeHeader + \"]\");\r\n            }\r\n        }\r\n    }\r\n    return contentLength;\r\n}"
}, {
	"Path": "org.elasticsearch.test.SecurityIntegTestCase.createIndicesWithRandomAliases",
	"Comment": "creates the indices provided as argument, randomly associating them with aliases, indexes one dummy document per indexand refreshes the new indices",
	"Method": "void createIndicesWithRandomAliases(String indices){\r\n    createIndex(indices);\r\n    if (frequently()) {\r\n        boolean aliasAdded = false;\r\n        IndicesAliasesRequestBuilder builder = client().admin().indices().prepareAliases();\r\n        for (String index : indices) {\r\n            if (frequently()) {\r\n                builder.addAlias(index, \"alias-\" + index);\r\n                aliasAdded = true;\r\n            }\r\n        }\r\n        if (aliasAdded == false || randomBoolean()) {\r\n            for (String index : indices) {\r\n                builder.addAlias(index, \"alias\");\r\n            }\r\n        }\r\n        assertAcked(builder);\r\n    }\r\n    for (String index : indices) {\r\n        client().prepareIndex(index, \"type\").setSource(\"field\", \"value\").get();\r\n    }\r\n    refresh(indices);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.drm.DefaultDrmSessionManager.newPlayReadyInstance",
	"Comment": "instantiates a new instance using the playready scheme.note that playready is unsupported by most android devices, with the exception of android tvdevices, which do provide support.",
	"Method": "DefaultDrmSessionManager<FrameworkMediaCrypto> newPlayReadyInstance(MediaDrmCallback callback,String customData,Handler eventHandler,DefaultDrmSessionEventListener eventListener,DefaultDrmSessionManager<FrameworkMediaCrypto> newPlayReadyInstance,MediaDrmCallback callback,String customData){\r\n    HashMap<String, String> optionalKeyRequestParameters;\r\n    if (!TextUtils.isEmpty(customData)) {\r\n        optionalKeyRequestParameters = new HashMap();\r\n        optionalKeyRequestParameters.put(PLAYREADY_CUSTOM_DATA_KEY, customData);\r\n    } else {\r\n        optionalKeyRequestParameters = null;\r\n    }\r\n    return newFrameworkInstance(C.PLAYREADY_UUID, callback, optionalKeyRequestParameters);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.support.SecurityIndexManager.addIndexStateListener",
	"Comment": "add a listener for notifications on state changes to the configured index.the previous and current state are provided.",
	"Method": "void addIndexStateListener(BiConsumer<State, State> listener){\r\n    stateChangeListeners.add(listener);\r\n}"
}, {
	"Path": "org.elasticsearch.test.http.MockWebServer.sleepIfNeeded",
	"Comment": "sleep the specified amount of time, if the time value is not null",
	"Method": "void sleepIfNeeded(TimeValue timeValue){\r\n    if (timeValue == null) {\r\n        return;\r\n    }\r\n    CountDownLatch latch = new CountDownLatch(1);\r\n    latches.add(latch);\r\n    try {\r\n        latch.await(timeValue.millis(), TimeUnit.MILLISECONDS);\r\n    } finally {\r\n        latches.remove(latch);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.HlsSampleStreamWrapper.prepareWithMasterPlaylistInfo",
	"Comment": "prepares the sample stream wrapper with master playlist information.",
	"Method": "void prepareWithMasterPlaylistInfo(TrackGroupArray trackGroups,int primaryTrackGroupIndex,TrackGroupArray optionalTrackGroups){\r\n    prepared = true;\r\n    this.trackGroups = trackGroups;\r\n    this.optionalTrackGroups = optionalTrackGroups;\r\n    this.primaryTrackGroupIndex = primaryTrackGroupIndex;\r\n    callback.onPrepared();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.expression.function.scalar.string.StringFunctionUtils.substring",
	"Comment": "extract a substring from the given string, using start index and length of the extracted substring.",
	"Method": "String substring(String s,int start,int length){\r\n    if (!hasLength(s)) {\r\n        return s;\r\n    }\r\n    if (start < 0)\r\n        start = 0;\r\n    if (start + 1 > s.length() || length < 0)\r\n        return \"\";\r\n    return (start + length > s.length()) ? s.substring(start) : s.substring(start, start + length);\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ByteVector.putByte",
	"Comment": "puts a byte into this byte vector. the byte vector is automatically enlarged if necessary.",
	"Method": "ByteVector putByte(int b){\r\n    int length = this.length;\r\n    if (length + 1 > data.length) {\r\n        enlarge(1);\r\n    }\r\n    data[length++] = (byte) b;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.license.XPackLicenseStateTests.assertAllowed",
	"Comment": "creates a license state with the given license type and active state, and checks the given method returns expected.",
	"Method": "void assertAllowed(OperationMode mode,boolean active,Predicate<XPackLicenseState> predicate,boolean expected){\r\n    XPackLicenseState licenseState = new XPackLicenseState(Settings.EMPTY);\r\n    licenseState.update(mode, active, null);\r\n    assertEquals(expected, predicate.test(licenseState));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.user.HasPrivilegesResponse.getApplicationPrivileges",
	"Comment": "retrieves the results from checking application privileges,",
	"Method": "Map<String, List<ResourcePrivileges>> getApplicationPrivileges(){\r\n    return Collections.unmodifiableMap(application);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.CodecSpecificDataUtil.splitNalUnits",
	"Comment": "splits an array of nal units.if the input consists of nal start code delimited units, then the returned array consists ofthe split nal units, each of which is still prefixed with the nal start code. for any otherinput, null is returned.",
	"Method": "byte[][] splitNalUnits(byte[] data){\r\n    if (!isNalStartCode(data, 0)) {\r\n        return null;\r\n    }\r\n    List<Integer> starts = new ArrayList();\r\n    int nalUnitIndex = 0;\r\n    do {\r\n        starts.add(nalUnitIndex);\r\n        nalUnitIndex = findNalStartCode(data, nalUnitIndex + NAL_START_CODE.length);\r\n    } while (nalUnitIndex != C.INDEX_UNSET);\r\n    byte[][] split = new byte[starts.size()][];\r\n    for (int i = 0; i < starts.size(); i++) {\r\n        int startIndex = starts.get(i);\r\n        int endIndex = i < starts.size() - 1 ? starts.get(i + 1) : data.length;\r\n        byte[] nal = new byte[endIndex - startIndex];\r\n        System.arraycopy(data, startIndex, nal, 0, nal.length);\r\n        split[i] = nal;\r\n    }\r\n    return split;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.AbstractDataToProcessWriter.tokenizeForCategorization",
	"Comment": "tokenize the field that has been configured for categorization, and store the resulting list of tokens in csvformat in the appropriate field of the record to be sent to the analytics.",
	"Method": "void tokenizeForCategorization(CategorizationAnalyzer categorizationAnalyzer,String categorizationFieldValue,String[] record,String tokenizeForCategorization,CategorizationAnalyzer categorizationAnalyzer,String categorizationFieldName,String categorizationFieldValue){\r\n    StringBuilder builder = new StringBuilder();\r\n    CsvContext context = new CsvContext(0, 0, 0);\r\n    CsvEncoder encoder = new DefaultCsvEncoder();\r\n    boolean first = true;\r\n    for (String token : categorizationAnalyzer.tokenizeField(categorizationFieldName, categorizationFieldValue)) {\r\n        if (first) {\r\n            first = false;\r\n        } else {\r\n            builder.appendCodePoint(CsvPreference.STANDARD_PREFERENCE.getDelimiterChar());\r\n        }\r\n        builder.append(encoder.encode(token, context, CsvPreference.STANDARD_PREFERENCE));\r\n    }\r\n    return builder.toString();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.output.AutoDetectResultProcessor.waitForFlushAcknowledgement",
	"Comment": "blocks until a flush is acknowledged or the timeout expires, whichever happens first.",
	"Method": "FlushAcknowledgement waitForFlushAcknowledgement(String flushId,Duration timeout){\r\n    return failed ? null : flushListener.waitForFlush(flushId, timeout);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.qa.cli.EmbeddedCli.close",
	"Comment": "attempts an orderly shutdown of the cli, reporting any unconsumed lines as errors.",
	"Method": "void close(){\r\n    if (closed) {\r\n        return;\r\n    }\r\n    try {\r\n        out.write(\"quit;\\n\");\r\n        out.flush();\r\n        List<String> nonQuit = new ArrayList();\r\n        String line;\r\n        while (true) {\r\n            line = readLine();\r\n            if (line == null) {\r\n                fail(\"got EOF before [Bye!]. Extras \" + nonQuit);\r\n            }\r\n            if (line.contains(\"quit;\")) {\r\n                continue;\r\n            }\r\n            if (line.contains(\"Bye!\")) {\r\n                break;\r\n            }\r\n            if (false == line.isEmpty()) {\r\n                nonQuit.add(line);\r\n            }\r\n        }\r\n        assertThat(\"unconsumed lines\", nonQuit, empty());\r\n    } finally {\r\n        forceClose();\r\n    }\r\n    assertEquals(0, returnCode.get());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.DelimitedFileStructureFinder.levenshteinDistance",
	"Comment": "this method implements the simple algorithm for calculating levenshtein distance.",
	"Method": "int levenshteinDistance(String first,String second){\r\n    int firstLen = (first == null) ? 0 : first.length();\r\n    int secondLen = (second == null) ? 0 : second.length();\r\n    if (firstLen == 0) {\r\n        return secondLen;\r\n    }\r\n    if (secondLen == 0) {\r\n        return firstLen;\r\n    }\r\n    int[] currentCol = new int[secondLen + 1];\r\n    int[] prevCol = new int[secondLen + 1];\r\n    for (int down = 0; down <= secondLen; ++down) {\r\n        currentCol[down] = down;\r\n    }\r\n    for (int across = 1; across <= firstLen; ++across) {\r\n        int[] tmp = prevCol;\r\n        prevCol = currentCol;\r\n        currentCol = tmp;\r\n        currentCol[0] = across;\r\n        for (int down = 1; down <= secondLen; ++down) {\r\n            if (first.charAt(across - 1) == second.charAt(down - 1)) {\r\n                currentCol[down] = prevCol[down - 1];\r\n            } else {\r\n                int option1 = prevCol[down];\r\n                int option2 = currentCol[down - 1];\r\n                int option3 = prevCol[down - 1];\r\n                currentCol[down] = Math.min(Math.min(option1, option2), option3) + 1;\r\n            }\r\n        }\r\n    }\r\n    return currentCol[secondLen];\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.template.TemplateUtils.loadTemplateIntoMap",
	"Comment": "loads a json template as a resource and puts it into the provided map",
	"Method": "void loadTemplateIntoMap(String resource,Map<String, IndexTemplateMetaData> map,String templateName,String version,String versionProperty,Logger logger){\r\n    final String template = loadTemplate(resource, version, versionProperty);\r\n    try (XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, template)) {\r\n        map.put(templateName, IndexTemplateMetaData.Builder.fromXContent(parser, templateName));\r\n    } catch (IOException e) {\r\n        logger.error(\"Error loading template [{}] as part of metadata upgrading\", templateName);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectProcessManager.flushJob",
	"Comment": "flush the running job, ensuring that the native process has had theopportunity to process all data previously sent to it with none leftsitting in buffers.",
	"Method": "void flushJob(JobTask jobTask,FlushJobParams params,ActionListener<FlushAcknowledgement> handler){\r\n    logger.debug(\"Flushing job {}\", jobTask.getJobId());\r\n    AutodetectCommunicator communicator = getOpenAutodetectCommunicator(jobTask);\r\n    if (communicator == null) {\r\n        String message = String.format(Locale.ROOT, \"Cannot flush because job [%s] is not open\", jobTask.getJobId());\r\n        logger.debug(message);\r\n        handler.onFailure(ExceptionsHelper.conflictStatusException(message));\r\n        return;\r\n    }\r\n    communicator.flushJob(params, (flushAcknowledgement, e) -> {\r\n        if (e != null) {\r\n            String msg = String.format(Locale.ROOT, \"[%s] exception while flushing job\", jobTask.getJobId());\r\n            logger.error(msg);\r\n            handler.onFailure(ExceptionsHelper.serverError(msg, e));\r\n        } else {\r\n            handler.onResponse(flushAcknowledgement);\r\n        }\r\n    });\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.KerberosTestCase.createPrincipalKeyTab",
	"Comment": "creates principals and exports them to the keytab created in the directory.",
	"Method": "Path createPrincipalKeyTab(Path dir,String princNames){\r\n    final Path path = dir.resolve(randomAlphaOfLength(10) + \".keytab\");\r\n    simpleKdcLdapServer.createPrincipal(path, princNames);\r\n    return path;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.shouldLoadNextMediaPeriod",
	"Comment": "returns whether a new loading media period should be enqueued, if available.",
	"Method": "boolean shouldLoadNextMediaPeriod(){\r\n    return loading == null || (!loading.info.isFinal && loading.isFullyBuffered() && loading.info.durationUs != C.TIME_UNSET && length < MAXIMUM_BUFFER_AHEAD_PERIODS);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.drm.ClearKeyUtil.adjustResponseData",
	"Comment": "adjusts clearkey response data to be suitable for providing to the android clearkey cdm.",
	"Method": "byte[] adjustResponseData(byte[] response){\r\n    if (Util.SDK_INT >= 27) {\r\n        return response;\r\n    }\r\n    try {\r\n        JSONObject responseJson = new JSONObject(Util.fromUtf8Bytes(response));\r\n        StringBuilder adjustedResponseBuilder = new StringBuilder(\"{\\\"keys\\\":[\");\r\n        JSONArray keysArray = responseJson.getJSONArray(\"keys\");\r\n        for (int i = 0; i < keysArray.length(); i++) {\r\n            if (i != 0) {\r\n                adjustedResponseBuilder.append(\",\");\r\n            }\r\n            JSONObject key = keysArray.getJSONObject(i);\r\n            adjustedResponseBuilder.append(\"{\\\"k\\\":\\\"\");\r\n            adjustedResponseBuilder.append(base64UrlToBase64(key.getString(\"k\")));\r\n            adjustedResponseBuilder.append(\"\\\",\\\"kid\\\":\\\"\");\r\n            adjustedResponseBuilder.append(base64UrlToBase64(key.getString(\"kid\")));\r\n            adjustedResponseBuilder.append(\"\\\",\\\"kty\\\":\\\"\");\r\n            adjustedResponseBuilder.append(key.getString(\"kty\"));\r\n            adjustedResponseBuilder.append(\"\\\"}\");\r\n        }\r\n        adjustedResponseBuilder.append(\"]}\");\r\n        return Util.getUtf8Bytes(adjustedResponseBuilder.toString());\r\n    } catch (JSONException e) {\r\n        Log.e(TAG, \"Failed to adjust response data: \" + Util.fromUtf8Bytes(response), e);\r\n        return response;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.DataCountsReporter.reportMissingField",
	"Comment": "increments the missing field countrecords with missing fields are still processed",
	"Method": "void reportMissingField(){\r\n    totalRecordStats.incrementMissingFieldCount(1);\r\n    incrementalRecordStats.incrementMissingFieldCount(1);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.cache.CachedContent.touch",
	"Comment": "copies the given span with an updated last access time. passed span becomes invalid after thiscall.",
	"Method": "SimpleCacheSpan touch(SimpleCacheSpan cacheSpan){\r\n    SimpleCacheSpan newCacheSpan = cacheSpan.copyWithUpdatedLastAccessTime(id);\r\n    if (!cacheSpan.file.renameTo(newCacheSpan.file)) {\r\n        throw new CacheException(\"Renaming of \" + cacheSpan.file + \" to \" + newCacheSpan.file + \" failed.\");\r\n    }\r\n    Assertions.checkState(cachedSpans.remove(cacheSpan));\r\n    cachedSpans.add(newCacheSpan);\r\n    return newCacheSpan;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.CsvDataToProcessWriter.write",
	"Comment": "read the csv inputindex, transform to length encoded values and pipe tothe outputstream. if any of the expected fields in theanalysis inputindex or if the expected time field is missing from the csvheader a exception is thrown",
	"Method": "void write(InputStream inputStream,CategorizationAnalyzer categorizationAnalyzer,XContentType xContentType,BiConsumer<DataCounts, Exception> handler){\r\n    CsvPreference csvPref = new CsvPreference.Builder(dataDescription.getQuoteCharacter(), dataDescription.getFieldDelimiter(), new String(new char[] { DataDescription.LINE_ENDING })).maxLinesPerRow(MAX_LINES_PER_RECORD).build();\r\n    dataCountsReporter.startNewIncrementalCount();\r\n    try (CsvListReader csvReader = new CsvListReader(new InputStreamReader(inputStream, StandardCharsets.UTF_8), csvPref)) {\r\n        String[] header = csvReader.getHeader(true);\r\n        if (header == null) {\r\n            handler.accept(dataCountsReporter.incrementalStats(), null);\r\n            return;\r\n        }\r\n        long inputFieldCount = Math.max(header.length - 1, 0);\r\n        buildFieldIndexMapping(header);\r\n        int maxIndex = 0;\r\n        for (Integer index : inFieldIndexes.values()) {\r\n            maxIndex = Math.max(index, maxIndex);\r\n        }\r\n        Integer categorizationFieldIndex = inFieldIndexes.get(analysisConfig.getCategorizationFieldName());\r\n        int numFields = outputFieldCount();\r\n        String[] record = new String[numFields];\r\n        List<String> line;\r\n        while ((line = csvReader.read()) != null) {\r\n            Arrays.fill(record, \"\");\r\n            if (maxIndex >= line.size()) {\r\n                LOGGER.warn(\"Not enough fields in csv record, expected at least \" + maxIndex + \". \" + line);\r\n                for (InputOutputMap inOut : inputOutputMap) {\r\n                    if (inOut.inputIndex >= line.size()) {\r\n                        dataCountsReporter.reportMissingField();\r\n                        continue;\r\n                    }\r\n                    String field = line.get(inOut.inputIndex);\r\n                    record[inOut.outputIndex] = (field == null) ? \"\" : field;\r\n                }\r\n            } else {\r\n                for (InputOutputMap inOut : inputOutputMap) {\r\n                    String field = line.get(inOut.inputIndex);\r\n                    record[inOut.outputIndex] = (field == null) ? \"\" : field;\r\n                }\r\n            }\r\n            if (categorizationAnalyzer != null && categorizationFieldIndex != null && categorizationFieldIndex < line.size()) {\r\n                tokenizeForCategorization(categorizationAnalyzer, line.get(categorizationFieldIndex), record);\r\n            }\r\n            transformTimeAndWrite(record, inputFieldCount);\r\n        }\r\n        dataCountsReporter.finishReporting(ActionListener.wrap(response -> handler.accept(dataCountsReporter.incrementalStats(), null), e -> handler.accept(null, e)));\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.vp9.VpxLibrary.isAvailable",
	"Comment": "returns whether the underlying library is available, loading it if necessary.",
	"Method": "boolean isAvailable(){\r\n    return LOADER.isAvailable();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.support.LdapSession.groups",
	"Comment": "asynchronously retrieves a list of group distinguished names",
	"Method": "void groups(ActionListener<List<String>> listener){\r\n    groupsResolver.resolve(connection, userDn, timeout, logger, attributes, listener);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.exporter.local.LocalExporterIntegTests.checkMonitoringTemplates",
	"Comment": "checks that the monitoring templates have been created by the local exporter",
	"Method": "void checkMonitoringTemplates(){\r\n    final Set<String> templates = new HashSet();\r\n    templates.add(\".monitoring-alerts\");\r\n    templates.add(\".monitoring-es\");\r\n    templates.add(\".monitoring-kibana\");\r\n    templates.add(\".monitoring-logstash\");\r\n    templates.add(\".monitoring-beats\");\r\n    GetIndexTemplatesResponse response = client().admin().indices().prepareGetTemplates(\".monitoring-*\").get();\r\n    Set<String> actualTemplates = response.getIndexTemplates().stream().map(IndexTemplateMetaData::getName).collect(Collectors.toSet());\r\n    assertEquals(templates, actualTemplates);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.vp9.VpxOutputBuffer.isSafeToMultiply",
	"Comment": "ensures that the result of multiplying individual numbers can fit into the size limit of aninteger.",
	"Method": "boolean isSafeToMultiply(int a,int b){\r\n    return a >= 0 && b >= 0 && !(b > 0 && a >= Integer.MAX_VALUE / b);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.text.dvb.DvbParser.parseClutDefinition",
	"Comment": "parses a clut definition segment, as defined by etsi en 300 743 7.2.4.",
	"Method": "ClutDefinition parseClutDefinition(ParsableBitArray data,int length){\r\n    int clutId = data.readBits(8);\r\n    data.skipBits(8);\r\n    int remainingLength = length - 2;\r\n    int[] clutEntries2Bit = generateDefault2BitClutEntries();\r\n    int[] clutEntries4Bit = generateDefault4BitClutEntries();\r\n    int[] clutEntries8Bit = generateDefault8BitClutEntries();\r\n    while (remainingLength > 0) {\r\n        int entryId = data.readBits(8);\r\n        int entryFlags = data.readBits(8);\r\n        remainingLength -= 2;\r\n        int[] clutEntries;\r\n        if ((entryFlags & 0x80) != 0) {\r\n            clutEntries = clutEntries2Bit;\r\n        } else if ((entryFlags & 0x40) != 0) {\r\n            clutEntries = clutEntries4Bit;\r\n        } else {\r\n            clutEntries = clutEntries8Bit;\r\n        }\r\n        int y;\r\n        int cr;\r\n        int cb;\r\n        int t;\r\n        if ((entryFlags & 0x01) != 0) {\r\n            y = data.readBits(8);\r\n            cr = data.readBits(8);\r\n            cb = data.readBits(8);\r\n            t = data.readBits(8);\r\n            remainingLength -= 4;\r\n        } else {\r\n            y = data.readBits(6) << 2;\r\n            cr = data.readBits(4) << 4;\r\n            cb = data.readBits(4) << 4;\r\n            t = data.readBits(2) << 6;\r\n            remainingLength -= 2;\r\n        }\r\n        if (y == 0x00) {\r\n            cr = 0x00;\r\n            cb = 0x00;\r\n            t = 0xFF;\r\n        }\r\n        int a = (byte) (0xFF - (t & 0xFF));\r\n        int r = (int) (y + (1.40200 * (cr - 128)));\r\n        int g = (int) (y - (0.34414 * (cb - 128)) - (0.71414 * (cr - 128)));\r\n        int b = (int) (y + (1.77200 * (cb - 128)));\r\n        clutEntries[entryId] = getColor(a, Util.constrainValue(r, 0, 255), Util.constrainValue(g, 0, 255), Util.constrainValue(b, 0, 255));\r\n    }\r\n    return new ClutDefinition(clutId, clutEntries2Bit, clutEntries4Bit, clutEntries8Bit);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.XmlPullParserUtil.isStartTagIgnorePrefix",
	"Comment": "returns whether the current event is a start tag with the specified name. if the current eventhas a raw name then its prefix is stripped before matching.",
	"Method": "boolean isStartTagIgnorePrefix(XmlPullParser xpp,String name){\r\n    return isStartTag(xpp) && stripPrefix(xpp.getName()).equals(name);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.FakeTimeline.createAdPlaybackState",
	"Comment": "returns an ad playback state with the specified number of ads in each of the specified adgroups, each ten seconds long.",
	"Method": "AdPlaybackState createAdPlaybackState(int adsPerAdGroup,long adGroupTimesUs){\r\n    int adGroupCount = adGroupTimesUs.length;\r\n    AdPlaybackState adPlaybackState = new AdPlaybackState(adGroupTimesUs);\r\n    long[][] adDurationsUs = new long[adGroupCount][];\r\n    for (int i = 0; i < adGroupCount; i++) {\r\n        adPlaybackState = adPlaybackState.withAdCount(i, adsPerAdGroup);\r\n        adDurationsUs[i] = new long[adsPerAdGroup];\r\n        Arrays.fill(adDurationsUs[i], AD_DURATION_US);\r\n    }\r\n    adPlaybackState = adPlaybackState.withAdDurationsUs(adDurationsUs);\r\n    return adPlaybackState;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.support.SecurityIndexManager.isIndexDeleted",
	"Comment": "return true if the state moves from the index existing to the index not existing.",
	"Method": "boolean isIndexDeleted(State previousState,State currentState){\r\n    return previousState.indexStatus != null && currentState.indexStatus == null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.KerberosTicketValidator.doAsWrapper",
	"Comment": "privileged wrapper that invokes action with subject.doas to perform work asgiven subject.",
	"Method": "T doAsWrapper(Subject subject,PrivilegedExceptionAction<T> action){\r\n    try {\r\n        return AccessController.doPrivileged((PrivilegedExceptionAction<T>) () -> Subject.doAs(subject, action));\r\n    } catch (PrivilegedActionException pae) {\r\n        if (pae.getCause() instanceof PrivilegedActionException) {\r\n            throw (PrivilegedActionException) pae.getCause();\r\n        }\r\n        throw pae;\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.text.webvtt.WebvttParserUtil.isWebvttHeaderLine",
	"Comment": "returns whether the given input is the first line of a webvtt file.",
	"Method": "boolean isWebvttHeaderLine(ParsableByteArray input){\r\n    String line = input.readLine();\r\n    return line != null && line.startsWith(WEBVTT_HEADER);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.hasPlayingPeriod",
	"Comment": "returns whether the reading and playing period holders are set.",
	"Method": "boolean hasPlayingPeriod(){\r\n    return playing != null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.Util.scaleLargeTimestamp",
	"Comment": "scales a large timestamp.logically, scaling consists of a multiplication followed by a division. the actual operationsperformed are designed to minimize the probability of overflow.",
	"Method": "long scaleLargeTimestamp(long timestamp,long multiplier,long divisor){\r\n    if (divisor >= multiplier && (divisor % multiplier) == 0) {\r\n        long divisionFactor = divisor / multiplier;\r\n        return timestamp / divisionFactor;\r\n    } else if (divisor < multiplier && (multiplier % divisor) == 0) {\r\n        long multiplicationFactor = multiplier / divisor;\r\n        return timestamp * multiplicationFactor;\r\n    } else {\r\n        double multiplicationFactor = (double) multiplier / divisor;\r\n        return (long) (timestamp * multiplicationFactor);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.offline.DownloadService.startForeground",
	"Comment": "starts the service in the foreground without adding a new action. if there are any not finishedactions and the requirements are met, the service resumes executing actions. otherwise it stopsimmediately.",
	"Method": "void startForeground(Context context,Class<? extends DownloadService> clazz){\r\n    Intent intent = getIntent(context, clazz, ACTION_INIT).putExtra(KEY_FOREGROUND, true);\r\n    Util.startForegroundService(context, intent);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.indexlifecycle.IndexLifecycleRunner.addStepInfoToClusterState",
	"Comment": "conditionally updates cluster state with new step info. the new cluster state is onlybuilt if the step info has changed, otherwise the same old clusterstate isreturned",
	"Method": "ClusterState addStepInfoToClusterState(Index index,ClusterState clusterState,ToXContentObject stepInfo){\r\n    IndexMetaData indexMetaData = clusterState.getMetaData().index(index);\r\n    if (indexMetaData == null) {\r\n        return clusterState;\r\n    }\r\n    LifecycleExecutionState lifecycleState = LifecycleExecutionState.fromIndexMetadata(indexMetaData);\r\n    final String stepInfoString;\r\n    try (XContentBuilder infoXContentBuilder = JsonXContent.contentBuilder()) {\r\n        stepInfo.toXContent(infoXContentBuilder, ToXContent.EMPTY_PARAMS);\r\n        stepInfoString = BytesReference.bytes(infoXContentBuilder).utf8ToString();\r\n    }\r\n    if (stepInfoString.equals(lifecycleState.getStepInfo())) {\r\n        return clusterState;\r\n    }\r\n    LifecycleExecutionState.Builder newState = LifecycleExecutionState.builder(lifecycleState);\r\n    newState.setStepInfo(stepInfoString);\r\n    ClusterState.Builder newClusterStateBuilder = newClusterStateWithLifecycleState(index, clusterState, newState.build());\r\n    return newClusterStateBuilder.build();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.client.SecurityClient.prepareClearRolesCache",
	"Comment": "clears the roles cache. this api only works for the naitve roles that are stored in an elasticsearch index. it ispossible to clear the cache of all roles or to specify the names of individual roles that should have their cachecleared.",
	"Method": "ClearRolesCacheRequestBuilder prepareClearRolesCache(){\r\n    return new ClearRolesCacheRequestBuilder(client);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.chunk.ChunkSampleStream.primarySampleIndexToMediaChunkIndex",
	"Comment": "returns the media chunk index corresponding to a given primary sample index.",
	"Method": "int primarySampleIndexToMediaChunkIndex(int primarySampleIndex,int minChunkIndex){\r\n    for (int i = minChunkIndex + 1; i < mediaChunks.size(); i++) {\r\n        if (mediaChunks.get(i).getFirstSampleIndex(0) > primarySampleIndex) {\r\n            return i - 1;\r\n        }\r\n    }\r\n    return mediaChunks.size() - 1;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authz.IndicesAndAliasesResolverTests.testNonRemotableRequestDoesNotAllowRemoteIndices",
	"Comment": "tests that request types that do not support remote indices will be resolved as if all index names are local.",
	"Method": "void testNonRemotableRequestDoesNotAllowRemoteIndices(){\r\n    IndicesOptions options = IndicesOptions.fromOptions(true, false, false, false);\r\n    Tuple<TransportRequest, String> tuple = randomFrom(new Tuple<TransportRequest, String>(new CloseIndexRequest(\"remote:foo\").indicesOptions(options), CloseIndexAction.NAME), new Tuple<TransportRequest, String>(new DeleteIndexRequest(\"remote:foo\").indicesOptions(options), DeleteIndexAction.NAME), new Tuple<TransportRequest, String>(new PutMappingRequest(\"remote:foo\").indicesOptions(options), PutMappingAction.NAME));\r\n    IndexNotFoundException e = expectThrows(IndexNotFoundException.class, () -> resolveIndices(tuple.v1(), buildAuthorizedIndices(user, tuple.v2())).getLocal());\r\n    assertEquals(\"no such index [[remote:foo]]\", e.getMessage());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.restart.FullClusterRestartIT.testRollupAfterRestart",
	"Comment": "tests that a rollup job created on a old cluster is correctly restarted after the upgrade.",
	"Method": "void testRollupAfterRestart(){\r\n    assumeTrue(\"Rollup can be tested with 6.3.0 and onwards\", getOldClusterVersion().onOrAfter(Version.V_6_3_0));\r\n    if (isRunningAgainstOldCluster()) {\r\n        final int numDocs = 59;\r\n        final int year = randomIntBetween(1970, 2018);\r\n        final StringBuilder bulk = new StringBuilder();\r\n        for (int i = 0; i < numDocs; i++) {\r\n            bulk.append(\"{\\\"index\\\":{\\\"_index\\\":\\\"rollup-docs\\\",\\\"_type\\\":\\\"doc\\\"}}\\n\");\r\n            String date = String.format(Locale.ROOT, \"d-01-01T00:d:00Z\", year, i);\r\n            bulk.append(\"{\\\"timestamp\\\":\\\"\").append(date).append(\"\\\",\\\"value\\\":\").append(i).append(\"}\\n\");\r\n        }\r\n        bulk.append(\"\\r\\n\");\r\n        final Request bulkRequest = new Request(\"POST\", \"/_bulk\");\r\n        bulkRequest.setJsonEntity(bulk.toString());\r\n        client().performRequest(bulkRequest);\r\n        final Request createRollupJobRequest = new Request(\"PUT\", \"/_xpack/rollup/job/rollup-job-test\");\r\n        createRollupJobRequest.setJsonEntity(\"{\" + \"\\\"index_pattern\\\":\\\"rollup-*\\\",\" + \"\\\"rollup_index\\\":\\\"results-rollup\\\",\" + \"\\\"cron\\\":\\\"*/30 * * * * ?\\\",\" + \"\\\"page_size\\\":100,\" + \"\\\"groups\\\":{\" + \"    \\\"date_histogram\\\":{\" + \"        \\\"field\\\":\\\"timestamp\\\",\" + \"        \\\"interval\\\":\\\"5m\\\"\" + \"      }\" + \"},\" + \"\\\"metrics\\\":[\" + \"    {\\\"field\\\":\\\"value\\\",\\\"metrics\\\":[\\\"min\\\",\\\"max\\\",\\\"sum\\\"]}\" + \"]\" + \"}\");\r\n        Map<String, Object> createRollupJobResponse = entityAsMap(client().performRequest(createRollupJobRequest));\r\n        assertThat(createRollupJobResponse.get(\"acknowledged\"), equalTo(Boolean.TRUE));\r\n        final Request startRollupJobRequest = new Request(\"POST\", \"_xpack/rollup/job/rollup-job-test/_start\");\r\n        Map<String, Object> startRollupJobResponse = entityAsMap(client().performRequest(startRollupJobRequest));\r\n        assertThat(startRollupJobResponse.get(\"started\"), equalTo(Boolean.TRUE));\r\n        assertRollUpJob(\"rollup-job-test\");\r\n    } else {\r\n        final Request clusterHealthRequest = new Request(\"GET\", \"/_cluster/health\");\r\n        clusterHealthRequest.addParameter(\"wait_for_status\", \"yellow\");\r\n        clusterHealthRequest.addParameter(\"wait_for_no_relocating_shards\", \"true\");\r\n        if (getOldClusterVersion().onOrAfter(Version.V_6_2_0)) {\r\n            clusterHealthRequest.addParameter(\"wait_for_no_initializing_shards\", \"true\");\r\n        }\r\n        Map<String, Object> clusterHealthResponse = entityAsMap(client().performRequest(clusterHealthRequest));\r\n        assertThat(clusterHealthResponse.get(\"timed_out\"), equalTo(Boolean.FALSE));\r\n        assertRollUpJob(\"rollup-job-test\");\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.plugin.TransportSqlQueryAction.operation",
	"Comment": "actual implementation of the action. statically available to support embedded mode.",
	"Method": "void operation(PlanExecutor planExecutor,SqlQueryRequest request,ActionListener<SqlQueryResponse> listener,String username,String clusterName){\r\n    Configuration cfg = new Configuration(request.timeZone(), request.fetchSize(), request.requestTimeout(), request.pageTimeout(), request.filter(), request.mode(), username, clusterName);\r\n    QueryMetric metric = QueryMetric.from(request.mode(), request.clientId());\r\n    planExecutor.metrics().total(metric);\r\n    if (Strings.hasText(request.cursor()) == false) {\r\n        planExecutor.sql(cfg, request.query(), request.params(), ActionListener.wrap(rowSet -> listener.onResponse(createResponse(request, rowSet)), e -> {\r\n            planExecutor.metrics().failed(metric);\r\n            listener.onFailure(e);\r\n        }));\r\n    } else {\r\n        planExecutor.metrics().paging(metric);\r\n        planExecutor.nextPage(cfg, Cursors.decodeFromString(request.cursor()), ActionListener.wrap(rowSet -> listener.onResponse(createResponse(rowSet, null)), e -> {\r\n            planExecutor.metrics().failed(metric);\r\n            listener.onFailure(e);\r\n        }));\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.GrokPatternCreator.adjustForPunctuation",
	"Comment": "if the snippets supplied begin with more than 1 character of common punctuation or whitespacethen add all but the last of these characters to the overall pattern and remove them from thesnippets.",
	"Method": "Collection<String> adjustForPunctuation(Collection<String> snippets){\r\n    assert snippets.isEmpty() == false;\r\n    StringBuilder commonInitialPunctuation = new StringBuilder();\r\n    for (String snippet : snippets) {\r\n        if (commonInitialPunctuation.length() == 0) {\r\n            for (int index = 0; index < snippet.length(); ++index) {\r\n                char ch = snippet.charAt(index);\r\n                if (PUNCTUATION_OR_SPACE_NEEDS_ESCAPING.get(ch) != null) {\r\n                    commonInitialPunctuation.append(ch);\r\n                } else {\r\n                    break;\r\n                }\r\n            }\r\n        } else {\r\n            if (commonInitialPunctuation.length() > snippet.length()) {\r\n                commonInitialPunctuation.delete(snippet.length(), commonInitialPunctuation.length());\r\n            }\r\n            for (int index = 0; index < commonInitialPunctuation.length(); ++index) {\r\n                char ch = snippet.charAt(index);\r\n                if (ch != commonInitialPunctuation.charAt(index)) {\r\n                    commonInitialPunctuation.delete(index, commonInitialPunctuation.length());\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n        if (commonInitialPunctuation.length() <= 1) {\r\n            return snippets;\r\n        }\r\n    }\r\n    int numLiteralCharacters = commonInitialPunctuation.length() - 1;\r\n    for (int index = 0; index < numLiteralCharacters; ++index) {\r\n        char ch = commonInitialPunctuation.charAt(index);\r\n        if (PUNCTUATION_OR_SPACE_NEEDS_ESCAPING.getOrDefault(ch, false)) {\r\n            overallGrokPatternBuilder.append('\\\\');\r\n        }\r\n        overallGrokPatternBuilder.append(ch);\r\n    }\r\n    return snippets.stream().map(snippet -> snippet.substring(numLiteralCharacters)).collect(Collectors.toList());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.TriggeredWatchStore.delete",
	"Comment": "delete a triggered watch entry.note that this happens asynchronously, as these kind of requests are batched together to reduce the amount of concurrent requests.",
	"Method": "void delete(Wid wid){\r\n    DeleteRequest request = new DeleteRequest(TriggeredWatchStoreField.INDEX_NAME, TriggeredWatchStoreField.DOC_TYPE, wid.value());\r\n    bulkProcessor.add(request);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.text.dvb.DvbParser.parseRegionComposition",
	"Comment": "parses a region composition segment, as defined by etsi en 300 743 7.2.3.",
	"Method": "RegionComposition parseRegionComposition(ParsableBitArray data,int length){\r\n    int id = data.readBits(8);\r\n    data.skipBits(4);\r\n    boolean fillFlag = data.readBit();\r\n    data.skipBits(3);\r\n    int width = data.readBits(16);\r\n    int height = data.readBits(16);\r\n    int levelOfCompatibility = data.readBits(3);\r\n    int depth = data.readBits(3);\r\n    data.skipBits(2);\r\n    int clutId = data.readBits(8);\r\n    int pixelCode8Bit = data.readBits(8);\r\n    int pixelCode4Bit = data.readBits(4);\r\n    int pixelCode2Bit = data.readBits(2);\r\n    data.skipBits(2);\r\n    int remainingLength = length - 10;\r\n    SparseArray<RegionObject> regionObjects = new SparseArray();\r\n    while (remainingLength > 0) {\r\n        int objectId = data.readBits(16);\r\n        int objectType = data.readBits(2);\r\n        int objectProvider = data.readBits(2);\r\n        int objectHorizontalPosition = data.readBits(12);\r\n        data.skipBits(4);\r\n        int objectVerticalPosition = data.readBits(12);\r\n        remainingLength -= 6;\r\n        int foregroundPixelCode = 0;\r\n        int backgroundPixelCode = 0;\r\n        if (objectType == 0x01 || objectType == 0x02) {\r\n            foregroundPixelCode = data.readBits(8);\r\n            backgroundPixelCode = data.readBits(8);\r\n            remainingLength -= 2;\r\n        }\r\n        regionObjects.put(objectId, new RegionObject(objectType, objectProvider, objectHorizontalPosition, objectVerticalPosition, foregroundPixelCode, backgroundPixelCode));\r\n    }\r\n    return new RegionComposition(id, fillFlag, width, height, levelOfCompatibility, depth, clutId, pixelCode8Bit, pixelCode4Bit, pixelCode2Bit, regionObjects);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.action.AbstractSqlQueryRequest.params",
	"Comment": "an optional list of parameters if the sql query is parametrized",
	"Method": "List<SqlTypedParamValue> params(AbstractSqlQueryRequest params,List<SqlTypedParamValue> params){\r\n    if (params == null) {\r\n        throw new IllegalArgumentException(\"params may not be null.\");\r\n    }\r\n    this.params = params;\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testTrustStoreReloadException",
	"Comment": "tests the reloading of a truststore when there is an exception during reloading. an exception is caused by truncating the truststorethat is being monitored",
	"Method": "void testTrustStoreReloadException(){\r\n    Path tempDir = createTempDir();\r\n    Path trustStorePath = tempDir.resolve(\"testnode.jks\");\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.jks\"), trustStorePath);\r\n    MockSecureSettings secureSettings = new MockSecureSettings();\r\n    secureSettings.setString(\"xpack.ssl.truststore.secure_password\", \"testnode\");\r\n    Settings settings = Settings.builder().put(\"xpack.ssl.truststore.path\", trustStorePath).put(\"path.home\", createTempDir()).setSecureSettings(secureSettings).build();\r\n    Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);\r\n    final SSLService sslService = new SSLService(settings, env);\r\n    final SSLConfiguration config = sslService.getSSLConfiguration(\"xpack.ssl\");\r\n    new SSLConfigurationReloader(env, sslService, resourceWatcherService) {\r\n        @Override\r\n        void reloadSSLContext(SSLConfiguration configuration) {\r\n            fail(\"reload should not be called! [truststore reload exception]\");\r\n        }\r\n    };\r\n    final SSLContext context = sslService.sslContextHolder(config).sslContext();\r\n    try (OutputStream os = Files.newOutputStream(trustStorePath, StandardOpenOption.TRUNCATE_EXISTING)) {\r\n    }\r\n    assertThat(sslService.sslContextHolder(config).sslContext(), sameInstance(context));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testTrustStoreReloadException",
	"Comment": "tests the reloading of a truststore when there is an exception during reloading. an exception is caused by truncating the truststorethat is being monitored",
	"Method": "void testTrustStoreReloadException(){\r\n    fail(\"reload should not be called! [truststore reload exception]\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.jdbc.SqlQueryParameterAnalyzer.skipLineComment",
	"Comment": "skips a line comment starting at the current position i, returns the length of the comment",
	"Method": "int skipLineComment(int i,String sql){\r\n    for (; i < sql.length(); i++) {\r\n        char c = sql.charAt(i);\r\n        if (c == '\\n' || c == '\\r') {\r\n            return i;\r\n        }\r\n    }\r\n    return i;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.rollup.RollupField.formatCountAggName",
	"Comment": "format to the appropriate rollup convention for extra count aggs.these are added to averages and bucketing aggs that need a count",
	"Method": "String formatCountAggName(String field){\r\n    return field + \".\" + RollupField.COUNT_FIELD;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onQueueInputBuffer",
	"Comment": "called immediately before an input buffer is queued into the codec.",
	"Method": "void onQueueInputBuffer(DecoderInputBuffer buffer){\r\n    buffersInCodecCount++;\r\n    lastInputTimeUs = Math.max(buffer.timeUs, lastInputTimeUs);\r\n    if (Util.SDK_INT < 23 && tunneling) {\r\n        onProcessedTunneledBuffer(buffer.timeUs);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleQueue.splice",
	"Comment": "indicates samples that are subsequently queued should be spliced into those already queued.",
	"Method": "void splice(){\r\n    pendingSplice = true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ReusableBufferedOutputStream.reset",
	"Comment": "resets this stream and uses the given output stream for writing. this stream must be closedbefore resetting.",
	"Method": "void reset(OutputStream out){\r\n    Assertions.checkState(closed);\r\n    this.out = out;\r\n    count = 0;\r\n    closed = false;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.watch.WatchStoreUtils.getConcreteIndex",
	"Comment": "method to get indexmetadata of a index, that potentially is behind an alias.",
	"Method": "IndexMetaData getConcreteIndex(String name,MetaData metaData){\r\n    AliasOrIndex aliasOrIndex = metaData.getAliasAndIndexLookup().get(name);\r\n    if (aliasOrIndex == null) {\r\n        return null;\r\n    }\r\n    if (aliasOrIndex.isAlias() && aliasOrIndex.getIndices().size() > 1) {\r\n        throw new IllegalStateException(\"Alias [\" + name + \"] points to more than one index\");\r\n    }\r\n    return aliasOrIndex.getIndices().get(0);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.flac.FlacDecoderJni.getLastFrameTimestamp",
	"Comment": "returns the timestamp for the first sample in the last decoded frame.",
	"Method": "long getLastFrameTimestamp(){\r\n    return flacGetLastFrameTimestamp(nativeDecoderContext);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.execution.search.SqlSourceBuilder.addScriptField",
	"Comment": "return the given field as a script field with the supplied script",
	"Method": "void addScriptField(String name,Script script){\r\n    scriptFields.put(name, script);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.getDecoderInfos",
	"Comment": "returns a list of decoders that can decode media in the specified format, in priority order.",
	"Method": "List<MediaCodecInfo> getDecoderInfos(MediaCodecSelector mediaCodecSelector,Format format,boolean requiresSecureDecoder){\r\n    return mediaCodecSelector.getDecoderInfos(format.sampleMimeType, requiresSecureDecoder);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.analytics.AnalyticsCollector.notifySeekStarted",
	"Comment": "notify analytics collector that a seek operation will start. should be called before the playeradjusts its state and position to the seek.",
	"Method": "void notifySeekStarted(){\r\n    if (!mediaPeriodQueueTracker.isSeeking()) {\r\n        EventTime eventTime = generatePlayingMediaPeriodEventTime();\r\n        mediaPeriodQueueTracker.onSeekStarted();\r\n        for (AnalyticsListener listener : listeners) {\r\n            listener.onSeekStarted(eventTime);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ClassWriter.toByteArray",
	"Comment": "returns the bytecode of the class that was build with this class writer.",
	"Method": "byte[] toByteArray(){\r\n    int size = 24 + 2 * interfaceCount;\r\n    int nbFields = 0;\r\n    FieldWriter fb = firstField;\r\n    while (fb != null) {\r\n        ++nbFields;\r\n        size += fb.getSize();\r\n        fb = fb.next;\r\n    }\r\n    int nbMethods = 0;\r\n    MethodWriter mb = firstMethod;\r\n    while (mb != null) {\r\n        ++nbMethods;\r\n        size += mb.getSize();\r\n        mb = mb.next;\r\n    }\r\n    int attributeCount = 0;\r\n    size += pool.length;\r\n    ByteVector out = new ByteVector(size);\r\n    out.putInt(0xCAFEBABE).putInt(version);\r\n    out.putShort(index).putByteArray(pool.data, 0, pool.length);\r\n    int mask = 393216;\r\n    out.putShort(access & ~mask).putShort(name).putShort(superName);\r\n    out.putShort(interfaceCount);\r\n    for (int i = 0; i < interfaceCount; ++i) {\r\n        out.putShort(interfaces[i]);\r\n    }\r\n    out.putShort(nbFields);\r\n    fb = firstField;\r\n    while (fb != null) {\r\n        fb.put(out);\r\n        fb = fb.next;\r\n    }\r\n    out.putShort(nbMethods);\r\n    mb = firstMethod;\r\n    while (mb != null) {\r\n        mb.put(out);\r\n        mb = mb.next;\r\n    }\r\n    out.putShort(attributeCount);\r\n    return out.data;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.Ac3Util.parseTrueHdSyncframeAudioSampleCount",
	"Comment": "returns the number of audio samples represented by the given truehd syncframe, or 0 if thebuffer is not the start of a syncframe.",
	"Method": "int parseTrueHdSyncframeAudioSampleCount(byte[] syncframe,int parseTrueHdSyncframeAudioSampleCount,ByteBuffer buffer,int offset){\r\n    boolean isMlp = (buffer.get(buffer.position() + offset + 7) & 0xFF) == 0xBB;\r\n    return 40 << ((buffer.get(buffer.position() + offset + (isMlp ? 9 : 8)) >> 4) & 0x07);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.ts.NalUnitTargetBuffer.isCompleted",
	"Comment": "returns whether the buffer currently holds a complete nal unit of the target type.",
	"Method": "boolean isCompleted(){\r\n    return isCompleted;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.IndexerUtils.processBuckets",
	"Comment": "the only entry point in this class.you hand this method an aggregation and an indexpattern, and it returns a list of rolled documents that you can index",
	"Method": "List<IndexRequest> processBuckets(CompositeAggregation agg,String rollupIndex,RollupIndexerJobStats stats,GroupConfig groupConfig,String jobId,boolean isUpgradedDocID){\r\n    logger.debug(\"Buckets: [\" + agg.getBuckets().size() + \"][\" + jobId + \"]\");\r\n    return agg.getBuckets().stream().map(b -> {\r\n        stats.incrementNumDocuments(b.getDocCount());\r\n        TreeMap<String, Object> keys = new TreeMap(b.getKey());\r\n        List<Aggregation> metrics = b.getAggregations().asList();\r\n        RollupIDGenerator idGenerator;\r\n        if (isUpgradedDocID) {\r\n            idGenerator = new RollupIDGenerator.Murmur3(jobId);\r\n        } else {\r\n            idGenerator = new RollupIDGenerator.CRC();\r\n        }\r\n        Map<String, Object> doc = new HashMap(keys.size() + metrics.size());\r\n        processKeys(keys, doc, b.getDocCount(), groupConfig, idGenerator);\r\n        idGenerator.add(jobId);\r\n        processMetrics(metrics, doc);\r\n        doc.put(RollupField.ROLLUP_META + \".\" + RollupField.VERSION_FIELD, isUpgradedDocID ? Rollup.CURRENT_ROLLUP_VERSION : Rollup.ROLLUP_VERSION_V1);\r\n        doc.put(RollupField.ROLLUP_META + \".\" + RollupField.ID.getPreferredName(), jobId);\r\n        IndexRequest request = new IndexRequest(rollupIndex, RollupField.TYPE_NAME, idGenerator.getID());\r\n        request.source(doc);\r\n        return request;\r\n    }).collect(Collectors.toList());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.notification.slack.message.SlackMessageTests.testUrlPathIsFiltered",
	"Comment": "the url path contains sensitive information, which should not be exposed",
	"Method": "void testUrlPathIsFiltered(){\r\n    HttpResponse response = new HttpResponse(500);\r\n    String path = randomAlphaOfLength(20);\r\n    HttpRequest request = HttpRequest.builder(\"localhost\", 1234).path(path).build();\r\n    SlackMessage slackMessage = new SlackMessage(\"from\", new String[] { \"to\" }, \"icon\", \"text\", null);\r\n    SentMessages sentMessages = new SentMessages(\"foo\", Arrays.asList(SentMessages.SentMessage.responded(\"recipient\", slackMessage, request, response)));\r\n    try (XContentBuilder builder = jsonBuilder()) {\r\n        WatcherParams params = WatcherParams.builder().hideSecrets(false).build();\r\n        sentMessages.toXContent(builder, params);\r\n        assertThat(Strings.toString(builder), containsString(path));\r\n        try (XContentParser parser = builder.contentType().xContent().createParser(NamedXContentRegistry.EMPTY, DeprecationHandler.THROW_UNSUPPORTED_OPERATION, Strings.toString(builder))) {\r\n            parser.map();\r\n        }\r\n    }\r\n    try (XContentBuilder builder = jsonBuilder()) {\r\n        sentMessages.toXContent(builder, ToXContent.EMPTY_PARAMS);\r\n        assertThat(Strings.toString(builder), not(containsString(path)));\r\n        try (XContentParser parser = builder.contentType().xContent().createParser(NamedXContentRegistry.EMPTY, DeprecationHandler.THROW_UNSUPPORTED_OPERATION, Strings.toString(builder))) {\r\n            parser.map();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.SimpleExoPlayer.setVideoListener",
	"Comment": "sets a listener to receive video events, removing all existing listeners.",
	"Method": "void setVideoListener(VideoListener listener){\r\n    videoListeners.clear();\r\n    if (listener != null) {\r\n        addVideoListener(listener);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.PermissionsIT.testCanManageIndexWithNoPermissions",
	"Comment": "this tests the awkward behavior where an admin can have permissions to create a policy,but then not have permissions to operate on an index that was later associated with that policy by anotheruser",
	"Method": "void testCanManageIndexWithNoPermissions(){\r\n    createIndexAsAdmin(\"not-ilm\", indexSettingsWithPolicy, \"\");\r\n    Request request = new Request(\"GET\", \"/not-ilm/_ilm/explain\");\r\n    ResponseException exception = expectThrows(ResponseException.class, () -> client().performRequest(request));\r\n    assertThat(exception.getResponse().getStatusLine().getStatusCode(), equalTo(RestStatus.FORBIDDEN.getStatus()));\r\n    assertBusy(() -> {\r\n        Response response = adminClient().performRequest(request);\r\n        assertOK(response);\r\n        try (InputStream is = response.getEntity().getContent()) {\r\n            Map<String, Object> mapResponse = XContentHelper.convertToMap(XContentType.JSON.xContent(), is, true);\r\n            Map<String, Object> indexExplain = (Map<String, Object>) ((Map<String, Object>) mapResponse.get(\"indices\")).get(\"not-ilm\");\r\n            assertThat(indexExplain.get(\"managed\"), equalTo(true));\r\n            assertThat(indexExplain.get(\"step\"), equalTo(\"ERROR\"));\r\n            assertThat(indexExplain.get(\"failed_step\"), equalTo(\"delete\"));\r\n            Map<String, String> stepInfo = (Map<String, String>) indexExplain.get(\"step_info\");\r\n            assertThat(stepInfo.get(\"type\"), equalTo(\"security_exception\"));\r\n            assertThat(stepInfo.get(\"reason\"), equalTo(\"action [indices:admin/delete] is unauthorized for user [test_ilm]\"));\r\n        }\r\n    });\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.client.RemoteFailure.remoteTrace",
	"Comment": "stack trace from elasticsearch for the remote failure. mostly just useful for debuggingerrors that happen to be bugs.",
	"Method": "String remoteTrace(){\r\n    return remoteTrace;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.expression.UnresolvedAttributeTests.randomQualifier",
	"Comment": "a random qualifier. it is important that this be distinctfrom the name and the unresolvedmessage for testing transform.",
	"Method": "String randomQualifier(){\r\n    return randomBoolean() ? null : randomAlphaOfLength(6);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.FlacStreamInfo.getApproxBytesPerFrame",
	"Comment": "returns the approximate number of bytes per frame for the current flac stream.",
	"Method": "long getApproxBytesPerFrame(){\r\n    long approxBytesPerFrame;\r\n    if (maxFrameSize > 0) {\r\n        approxBytesPerFrame = ((long) maxFrameSize + minFrameSize) / 2 + 1;\r\n    } else {\r\n        long blockSize = (minBlockSize == maxBlockSize && minBlockSize > 0) ? minBlockSize : 4096;\r\n        approxBytesPerFrame = (blockSize * channels * bitsPerSample) / 8 + 64;\r\n    }\r\n    return approxBytesPerFrame;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.StandaloneMediaClock.stop",
	"Comment": "stops the clock. does nothing if the clock is already stopped.",
	"Method": "void stop(){\r\n    if (started) {\r\n        resetPosition(getPositionUs());\r\n        started = false;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateTool.parseFile",
	"Comment": "parses the input file to retrieve the certificate information",
	"Method": "Collection<CertificateInformation> parseFile(Path file){\r\n    try (Reader reader = Files.newBufferedReader(file)) {\r\n        XContentParser xContentParser = XContentType.YAML.xContent().createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, reader);\r\n        return CertificateToolParser.PARSER.parse(xContentParser, new ArrayList(), null);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.PsshAtomUtil.parseUuid",
	"Comment": "parses the uuid from a pssh atom. version 0 and 1 pssh atoms are supported.the uuid is only parsed if the data is a valid pssh atom.",
	"Method": "UUID parseUuid(byte[] atom){\r\n    PsshAtom parsedAtom = parsePsshAtom(atom);\r\n    if (parsedAtom == null) {\r\n        return null;\r\n    }\r\n    return parsedAtom.uuid;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.ads.AdPlaybackState.withContentDurationUs",
	"Comment": "returns an instance with the specified content duration, in microseconds.",
	"Method": "AdPlaybackState withContentDurationUs(long contentDurationUs){\r\n    if (this.contentDurationUs == contentDurationUs) {\r\n        return this;\r\n    } else {\r\n        return new AdPlaybackState(adGroupTimesUs, adGroups, adResumePositionUs, contentDurationUs);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.DummySurface.isSecureSupported",
	"Comment": "returns whether the device supports secure dummy surfaces.",
	"Method": "boolean isSecureSupported(Context context){\r\n    if (!secureModeInitialized) {\r\n        secureMode = Util.SDK_INT < 24 ? SECURE_MODE_NONE : getSecureModeV24(context);\r\n        secureModeInitialized = true;\r\n    }\r\n    return secureMode != SECURE_MODE_NONE;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.BaseTrackSelection.isBlacklisted",
	"Comment": "returns whether the track at the specified index in the selection is blacklisted.",
	"Method": "boolean isBlacklisted(int index,long nowMs){\r\n    return blacklistUntilTimes[index] > nowMs;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authc.support.mapper.ExpressionRoleMapping.getName",
	"Comment": "the name of this mapping. the name exists for the sole purpose of providing a meaningful identifier for each mapping, so that it maybe referred to for update, retrieval or deletion. the name does not affect the set of roles that a mapping provides.",
	"Method": "String getName(){\r\n    return name;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.text.webvtt.WebvttDecoder.getNextEvent",
	"Comment": "positions the input right before the next event, and returns the kind of event found. does notconsume any data from such event, if any.",
	"Method": "int getNextEvent(ParsableByteArray parsableWebvttData){\r\n    int foundEvent = EVENT_NONE;\r\n    int currentInputPosition = 0;\r\n    while (foundEvent == EVENT_NONE) {\r\n        currentInputPosition = parsableWebvttData.getPosition();\r\n        String line = parsableWebvttData.readLine();\r\n        if (line == null) {\r\n            foundEvent = EVENT_END_OF_FILE;\r\n        } else if (STYLE_START.equals(line)) {\r\n            foundEvent = EVENT_STYLE_BLOCK;\r\n        } else if (line.startsWith(COMMENT_START)) {\r\n            foundEvent = EVENT_COMMENT;\r\n        } else {\r\n            foundEvent = EVENT_CUE;\r\n        }\r\n    }\r\n    parsableWebvttData.setPosition(currentInputPosition);\r\n    return foundEvent;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.offline.DownloadService.getRequirements",
	"Comment": "returns requirements for downloads to take place. by default the only requirement is that thedevice has network connectivity.",
	"Method": "Requirements getRequirements(){\r\n    return DEFAULT_REQUIREMENTS;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateGenerateTool.getCertificateInformationList",
	"Comment": "this method handles the collection of information about each instance that is necessary to generate a certificate. the user maybe prompted or the information can be gathered from a file",
	"Method": "Collection<CertificateInformation> getCertificateInformationList(Terminal terminal,String inputFile){\r\n    if (inputFile != null) {\r\n        return parseAndValidateFile(terminal, resolvePath(inputFile).toAbsolutePath());\r\n    }\r\n    Map<String, CertificateInformation> map = new HashMap();\r\n    boolean done = false;\r\n    while (done == false) {\r\n        String name = terminal.readText(\"Enter instance name: \");\r\n        if (name.isEmpty() == false) {\r\n            final boolean isNameValidFilename = Name.isValidFilename(name);\r\n            String filename = terminal.readText(\"Enter name for directories and files \" + (isNameValidFilename ? \"[\" + name + \"]\" : \"\") + \": \");\r\n            if (filename.isEmpty() && isNameValidFilename) {\r\n                filename = name;\r\n            }\r\n            String ipAddresses = terminal.readText(\"Enter IP Addresses for instance (comma-separated if more than one) []: \");\r\n            String dnsNames = terminal.readText(\"Enter DNS names for instance (comma-separated if more than one) []: \");\r\n            List<String> ipList = Arrays.asList(Strings.splitStringByCommaToArray(ipAddresses));\r\n            List<String> dnsList = Arrays.asList(Strings.splitStringByCommaToArray(dnsNames));\r\n            List<String> commonNames = null;\r\n            CertificateInformation information = new CertificateInformation(name, filename, ipList, dnsList, commonNames);\r\n            List<String> validationErrors = information.validate();\r\n            if (validationErrors.isEmpty()) {\r\n                if (map.containsKey(name)) {\r\n                    terminal.println(\"Overwriting previously defined instance information [\" + name + \"]\");\r\n                }\r\n                map.put(name, information);\r\n            } else {\r\n                for (String validationError : validationErrors) {\r\n                    terminal.println(validationError);\r\n                }\r\n                terminal.println(\"Skipping entry as invalid values were found\");\r\n            }\r\n        } else {\r\n            terminal.println(\"A name must be provided\");\r\n        }\r\n        String exit = terminal.readText(\"Would you like to specify another instance? Press 'y' to continue entering instance \" + \"information: \");\r\n        if (\"y\".equals(exit) == false) {\r\n            done = true;\r\n        }\r\n    }\r\n    return map.values();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.watch.ClockMock.unfreeze",
	"Comment": "the clock will be reset to current time and will advance from now",
	"Method": "ClockMock unfreeze(){\r\n    wrappedClock = Clock.system(getZone());\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.ESNativeRealmMigrateTool.getTerminalLogger",
	"Comment": "creates a new logger that is detached from the root logger and only has an appender that will output log messages to the terminal",
	"Method": "Logger getTerminalLogger(Terminal terminal){\r\n    final Logger logger = LogManager.getLogger(ESNativeRealmMigrateTool.class);\r\n    Loggers.setLevel(logger, Level.ALL);\r\n    final LoggerContext ctx = (LoggerContext) LogManager.getContext(false);\r\n    final Configuration config = ctx.getConfiguration();\r\n    final Appender appender = new AbstractAppender(ESNativeRealmMigrateTool.class.getName(), null, // Specify the configuration so log4j doesn't re-initialize\r\n    PatternLayout.newBuilder().withConfiguration(config).withPattern(\"%m\").build()) {\r\n        @Override\r\n        public void append(LogEvent event) {\r\n            switch(event.getLevel().getStandardLevel()) {\r\n                case FATAL:\r\n                case ERROR:\r\n                    terminal.println(Verbosity.NORMAL, event.getMessage().getFormattedMessage());\r\n                    break;\r\n                case OFF:\r\n                    break;\r\n                default:\r\n                    terminal.println(Verbosity.VERBOSE, event.getMessage().getFormattedMessage());\r\n                    break;\r\n            }\r\n        }\r\n    };\r\n    appender.start();\r\n    final LoggerConfig loggerConfig = config.getLoggerConfig(ESNativeRealmMigrateTool.class.getName());\r\n    loggerConfig.setParent(null);\r\n    loggerConfig.getAppenders().forEach((s, a) -> Loggers.removeAppender(logger, a));\r\n    Loggers.addAppender(logger, appender);\r\n    return logger;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.ESNativeRealmMigrateTool.getTerminalLogger",
	"Comment": "creates a new logger that is detached from the root logger and only has an appender that will output log messages to the terminal",
	"Method": "Logger getTerminalLogger(Terminal terminal){\r\n    switch(event.getLevel().getStandardLevel()) {\r\n        case FATAL:\r\n        case ERROR:\r\n            terminal.println(Verbosity.NORMAL, event.getMessage().getFormattedMessage());\r\n            break;\r\n        case OFF:\r\n            break;\r\n        default:\r\n            terminal.println(Verbosity.VERBOSE, event.getMessage().getFormattedMessage());\r\n            break;\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.spherical.SceneRenderer.setProjection",
	"Comment": "sets projection data and stereo mode of the media to be played.",
	"Method": "void setProjection(byte[] projectionData,int stereoMode,long timeNs){\r\n    byte[] oldProjectionData = lastProjectionData;\r\n    int oldStereoMode = lastStereoMode;\r\n    lastProjectionData = projectionData;\r\n    lastStereoMode = stereoMode == Format.NO_VALUE ? defaultStereoMode : stereoMode;\r\n    if (oldStereoMode == lastStereoMode && Arrays.equals(oldProjectionData, lastProjectionData)) {\r\n        return;\r\n    }\r\n    Projection projectionFromData = null;\r\n    if (lastProjectionData != null) {\r\n        projectionFromData = ProjectionDecoder.decode(lastProjectionData, lastStereoMode);\r\n    }\r\n    Projection projection = projectionFromData != null && ProjectionRenderer.isSupported(projectionFromData) ? projectionFromData : Projection.createEquirectangular(lastStereoMode);\r\n    projectionQueue.add(timeNs, projection);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.createReservedUser",
	"Comment": "asynchronous method to create a reserved user with the given password hash. the cache for the user will be cleared after the documenthas been indexed",
	"Method": "void createReservedUser(String username,char[] passwordHash,RefreshPolicy refresh,ActionListener<Void> listener){\r\n    securityIndex.prepareIndexIfNeededThenExecute(listener::onFailure, () -> {\r\n        executeAsyncWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN, client.prepareIndex(SECURITY_INDEX_NAME, INDEX_TYPE, getIdForUser(RESERVED_USER_TYPE, username)).setSource(Fields.PASSWORD.getPreferredName(), String.valueOf(passwordHash), Fields.ENABLED.getPreferredName(), true, Fields.TYPE.getPreferredName(), RESERVED_USER_TYPE).setRefreshPolicy(refresh).request(), new ActionListener<IndexResponse>() {\r\n            @Override\r\n            public void onResponse(IndexResponse indexResponse) {\r\n                clearRealmCache(username, listener, null);\r\n            }\r\n            @Override\r\n            public void onFailure(Exception e) {\r\n                listener.onFailure(e);\r\n            }\r\n        }, client::index);\r\n    });\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.createReservedUser",
	"Comment": "asynchronous method to create a reserved user with the given password hash. the cache for the user will be cleared after the documenthas been indexed",
	"Method": "void createReservedUser(String username,char[] passwordHash,RefreshPolicy refresh,ActionListener<Void> listener){\r\n    clearRealmCache(username, listener, null);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.createReservedUser",
	"Comment": "asynchronous method to create a reserved user with the given password hash. the cache for the user will be cleared after the documenthas been indexed",
	"Method": "void createReservedUser(String username,char[] passwordHash,RefreshPolicy refresh,ActionListener<Void> listener){\r\n    listener.onFailure(e);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.trigger.TriggerService.remove",
	"Comment": "removes the job associated with the given name from this trigger service.",
	"Method": "boolean remove(String jobName){\r\n    perWatchStats.remove(jobName);\r\n    for (TriggerEngine engine : engines.values()) {\r\n        if (engine.remove(jobName)) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.AbstractDataToProcessWriter.inputFields",
	"Comment": "get all the expected input fields i.e. all the fields wemust see in the csv header",
	"Method": "Collection<String> inputFields(){\r\n    Set<String> requiredFields = analysisConfig.analysisFields();\r\n    requiredFields.add(dataDescription.getTimeField());\r\n    requiredFields.remove(AnalysisConfig.ML_CATEGORY_FIELD);\r\n    return requiredFields;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.ffmpeg.FfmpegLibrary.isAvailable",
	"Comment": "returns whether the underlying library is available, loading it if necessary.",
	"Method": "boolean isAvailable(){\r\n    return LOADER.isAvailable();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.HlsSampleStreamWrapper.deriveFormat",
	"Comment": "derives a track sample format from the corresponding format in the master playlist, and asample format that may have been obtained from a chunk belonging to a different track.",
	"Method": "Format deriveFormat(Format playlistFormat,Format sampleFormat,boolean propagateBitrate){\r\n    if (playlistFormat == null) {\r\n        return sampleFormat;\r\n    }\r\n    int bitrate = propagateBitrate ? playlistFormat.bitrate : Format.NO_VALUE;\r\n    int sampleTrackType = MimeTypes.getTrackType(sampleFormat.sampleMimeType);\r\n    String codecs = Util.getCodecsOfType(playlistFormat.codecs, sampleTrackType);\r\n    String mimeType = MimeTypes.getMediaMimeType(codecs);\r\n    if (mimeType == null) {\r\n        mimeType = sampleFormat.sampleMimeType;\r\n    }\r\n    return sampleFormat.copyWithContainerInfo(playlistFormat.id, playlistFormat.label, mimeType, codecs, bitrate, playlistFormat.width, playlistFormat.height, playlistFormat.selectionFlags, playlistFormat.language);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.client.RemoteFailure.cause",
	"Comment": "cause of the remote failure. mostly just useful for dbuegging errors that happen to be bugs.",
	"Method": "RemoteFailure cause(){\r\n    return cause;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlAuthenticatorTests.initCredentials",
	"Comment": "generating x.509 credentials can be cpu intensive and slow, so we only want to do it once per class.",
	"Method": "void initCredentials(){\r\n    idpSigningCertificatePair = readRandomKeyPair(randomSigningAlgorithm());\r\n    spSigningCertificatePair = readRandomKeyPair(randomSigningAlgorithm());\r\n    spEncryptionCertificatePairs = Arrays.asList(readKeyPair(\"RSA_2048\"), readKeyPair(\"RSA_4096\"));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ml.job.config.JobUpdateTests.createRandom",
	"Comment": "creates a completely random update when the job is nullor a random update that is is valid for the given job",
	"Method": "JobUpdate createRandom(String jobId,Job job){\r\n    JobUpdate.Builder update = new JobUpdate.Builder(jobId);\r\n    if (randomBoolean()) {\r\n        int groupsNum = randomIntBetween(0, 10);\r\n        List<String> groups = new ArrayList(groupsNum);\r\n        for (int i = 0; i < groupsNum; i++) {\r\n            groups.add(JobTests.randomValidJobId());\r\n        }\r\n        update.setGroups(groups);\r\n    }\r\n    if (randomBoolean()) {\r\n        update.setDescription(randomAlphaOfLength(20));\r\n    }\r\n    if (randomBoolean()) {\r\n        List<JobUpdate.DetectorUpdate> detectorUpdates = job == null ? createRandomDetectorUpdates() : createRandomDetectorUpdatesForJob(job);\r\n        update.setDetectorUpdates(detectorUpdates);\r\n    }\r\n    if (randomBoolean()) {\r\n        update.setModelPlotConfig(new ModelPlotConfig(randomBoolean(), randomAlphaOfLength(10)));\r\n    }\r\n    if (randomBoolean()) {\r\n        update.setAnalysisLimits(AnalysisLimits.validateAndSetDefaults(AnalysisLimitsTests.createRandomized(), null, AnalysisLimits.DEFAULT_MODEL_MEMORY_LIMIT_MB));\r\n    }\r\n    if (randomBoolean()) {\r\n        update.setRenormalizationWindowDays(randomNonNegativeLong());\r\n    }\r\n    if (randomBoolean()) {\r\n        update.setBackgroundPersistInterval(TimeValue.timeValueHours(randomIntBetween(1, 24)));\r\n    }\r\n    if (randomBoolean()) {\r\n        update.setModelSnapshotRetentionDays(randomNonNegativeLong());\r\n    }\r\n    if (randomBoolean()) {\r\n        update.setResultsRetentionDays(randomNonNegativeLong());\r\n    }\r\n    if (randomBoolean() && jobSupportsCategorizationFilters(job)) {\r\n        update.setCategorizationFilters(Arrays.asList(generateRandomStringArray(10, 10, false)));\r\n    }\r\n    if (randomBoolean()) {\r\n        update.setCustomSettings(Collections.singletonMap(randomAlphaOfLength(10), randomAlphaOfLength(10)));\r\n    }\r\n    if (useInternalParser && randomBoolean()) {\r\n        update.setModelSnapshotId(randomAlphaOfLength(10));\r\n    }\r\n    if (useInternalParser && randomBoolean()) {\r\n        update.setModelSnapshotMinVersion(Version.CURRENT);\r\n    }\r\n    if (useInternalParser && randomBoolean()) {\r\n        update.setEstablishedModelMemory(randomNonNegativeLong());\r\n    }\r\n    if (useInternalParser && randomBoolean()) {\r\n        update.setJobVersion(randomFrom(Version.CURRENT, Version.V_6_2_0, Version.V_6_1_0));\r\n    }\r\n    return update.build();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.PemUtils.possiblyDecryptPKCS1Key",
	"Comment": "decrypts the password protected contents using the algorithm and iv that is specified in the pem headers of the file",
	"Method": "byte[] possiblyDecryptPKCS1Key(Map<String, String> pemHeaders,String keyContents,Supplier<char[]> passwordSupplier){\r\n    byte[] keyBytes = Base64.getDecoder().decode(keyContents);\r\n    String procType = pemHeaders.get(\"Proc-Type\");\r\n    if (\"4,ENCRYPTED\".equals(procType)) {\r\n        String encryptionParameters = pemHeaders.get(\"DEK-Info\");\r\n        if (null == encryptionParameters) {\r\n            throw new IOException(\"Malformed PEM File, DEK-Info header is missing\");\r\n        }\r\n        char[] password = passwordSupplier.get();\r\n        if (password == null) {\r\n            throw new IOException(\"cannot read encrypted key without a password\");\r\n        }\r\n        Cipher cipher = getCipherFromParameters(encryptionParameters, password);\r\n        byte[] decryptedKeyBytes = cipher.doFinal(keyBytes);\r\n        return decryptedKeyBytes;\r\n    }\r\n    return keyBytes;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.ConcatenatingMediaSource.getMediaSourceHolderUid",
	"Comment": "return uid of media source holder from period uid of concatenated source.",
	"Method": "Object getMediaSourceHolderUid(Object periodUid){\r\n    return ConcatenatedTimeline.getChildTimelineUidFromConcatenatedUid(periodUid);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.ts.TsDurationReader.readDuration",
	"Comment": "reads a ts duration from the input, using the given pcr pid.this reader reads the duration by reading pcr values of the pcr pid packets at the start andat the end of the stream, calculating the difference, and converting that into stream duration.",
	"Method": "int readDuration(ExtractorInput input,PositionHolder seekPositionHolder,int pcrPid){\r\n    if (pcrPid <= 0) {\r\n        return finishReadDuration(input);\r\n    }\r\n    if (!isLastPcrValueRead) {\r\n        return readLastPcrValue(input, seekPositionHolder, pcrPid);\r\n    }\r\n    if (lastPcrValue == C.TIME_UNSET) {\r\n        return finishReadDuration(input);\r\n    }\r\n    if (!isFirstPcrValueRead) {\r\n        return readFirstPcrValue(input, seekPositionHolder, pcrPid);\r\n    }\r\n    if (firstPcrValue == C.TIME_UNSET) {\r\n        return finishReadDuration(input);\r\n    }\r\n    long minPcrPositionUs = pcrTimestampAdjuster.adjustTsTimestamp(firstPcrValue);\r\n    long maxPcrPositionUs = pcrTimestampAdjuster.adjustTsTimestamp(lastPcrValue);\r\n    durationUs = maxPcrPositionUs - minPcrPositionUs;\r\n    return finishReadDuration(input);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.getUsers",
	"Comment": "retrieve a list of users, if usernames is null or empty, fetch all users",
	"Method": "void getUsers(String[] userNames,ActionListener<Collection<User>> listener){\r\n    final Consumer<Exception> handleException = (t) -> {\r\n        if (TransportActions.isShardNotAvailableException(t)) {\r\n            logger.trace(\"could not retrieve users because of a shard not available exception\", t);\r\n            if (t instanceof IndexNotFoundException) {\r\n                listener.onResponse(Collections.emptyList());\r\n            } else {\r\n                listener.onFailure(t);\r\n            }\r\n        }\r\n        listener.onFailure(t);\r\n    };\r\n    final SecurityIndexManager frozenSecurityIndex = this.securityIndex.freeze();\r\n    if (frozenSecurityIndex.indexExists() == false) {\r\n        listener.onResponse(Collections.emptyList());\r\n    } else if (frozenSecurityIndex.isAvailable() == false) {\r\n        listener.onFailure(frozenSecurityIndex.getUnavailableReason());\r\n    } else if (userNames.length == 1) {\r\n        final String username = userNames[0];\r\n        getUserAndPassword(username, ActionListener.wrap((uap) -> listener.onResponse(uap == null ? Collections.emptyList() : Collections.singletonList(uap.user())), handleException));\r\n    } else {\r\n        securityIndex.checkIndexVersionThenExecute(listener::onFailure, () -> {\r\n            final QueryBuilder query;\r\n            if (userNames == null || userNames.length == 0) {\r\n                query = QueryBuilders.termQuery(Fields.TYPE.getPreferredName(), USER_DOC_TYPE);\r\n            } else {\r\n                final String[] users = Arrays.stream(userNames).map(s -> getIdForUser(USER_DOC_TYPE, s)).toArray(String[]::new);\r\n                query = QueryBuilders.boolQuery().filter(QueryBuilders.idsQuery(INDEX_TYPE).addIds(users));\r\n            }\r\n            final Supplier<ThreadContext.StoredContext> supplier = client.threadPool().getThreadContext().newRestorableContext(false);\r\n            try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN)) {\r\n                SearchRequest request = client.prepareSearch(SECURITY_INDEX_NAME).setScroll(DEFAULT_KEEPALIVE_SETTING.get(settings)).setQuery(query).setSize(1000).setFetchSource(true).request();\r\n                request.indicesOptions().ignoreUnavailable();\r\n                ScrollHelper.fetchAllByEntity(client, request, new ContextPreservingActionListener(supplier, listener), (hit) -> {\r\n                    UserAndPassword u = transformUser(hit.getId(), hit.getSourceAsMap());\r\n                    return u != null ? u.user() : null;\r\n                });\r\n            }\r\n        });\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.support.mapper.NativeRoleMappingStore.loadMappings",
	"Comment": "loads all mappings from the index.package private for unit testing",
	"Method": "void loadMappings(ActionListener<List<ExpressionRoleMapping>> listener){\r\n    if (securityIndex.isIndexUpToDate() == false) {\r\n        listener.onFailure(new IllegalStateException(\"Security index is not on the current version - the native realm will not be operational until \" + \"the upgrade API is run on the security index\"));\r\n        return;\r\n    }\r\n    final QueryBuilder query = QueryBuilders.termQuery(DOC_TYPE_FIELD, DOC_TYPE_ROLE_MAPPING);\r\n    final Supplier<ThreadContext.StoredContext> supplier = client.threadPool().getThreadContext().newRestorableContext(false);\r\n    try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN)) {\r\n        SearchRequest request = client.prepareSearch(SECURITY_INDEX_NAME).setScroll(DEFAULT_KEEPALIVE_SETTING.get(settings)).setTypes(SECURITY_GENERIC_TYPE).setQuery(query).setSize(1000).setFetchSource(true).request();\r\n        request.indicesOptions().ignoreUnavailable();\r\n        ScrollHelper.fetchAllByEntity(client, request, new ContextPreservingActionListener(supplier, ActionListener.wrap((Collection<ExpressionRoleMapping> mappings) -> listener.onResponse(mappings.stream().filter(Objects::nonNull).collect(Collectors.toList())), ex -> {\r\n            logger.error(new ParameterizedMessage(\"failed to load role mappings from index [{}] skipping all mappings.\", SECURITY_INDEX_NAME), ex);\r\n            listener.onResponse(Collections.emptyList());\r\n        })), doc -> buildMapping(getNameFromId(doc.getId()), doc.getSourceRef()));\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloader.directoriesToMonitor",
	"Comment": "returns a unique set of directories that need to be monitored based on the provided file paths",
	"Method": "Set<Path> directoriesToMonitor(List<Path> filePaths){\r\n    Set<Path> paths = new HashSet();\r\n    for (Path path : filePaths) {\r\n        paths.add(path.getParent());\r\n    }\r\n    return paths;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.action.TransportStopDatafeedAction.resolveDataFeedIds",
	"Comment": "resolve the requested datafeeds and add their ids to one of the listarguments depending on datafeed state.",
	"Method": "void resolveDataFeedIds(StopDatafeedAction.Request request,MlMetadata mlMetadata,PersistentTasksCustomMetaData tasks,List<String> startedDatafeedIds,List<String> stoppingDatafeedIds){\r\n    Set<String> expandedDatafeedIds = mlMetadata.expandDatafeedIds(request.getDatafeedId(), request.allowNoDatafeeds());\r\n    for (String expandedDatafeedId : expandedDatafeedIds) {\r\n        validateDatafeedTask(expandedDatafeedId, mlMetadata);\r\n        addDatafeedTaskIdAccordingToState(expandedDatafeedId, MlTasks.getDatafeedState(expandedDatafeedId, tasks), startedDatafeedIds, stoppingDatafeedIds);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.scheduler.Cron.isValid",
	"Comment": "indicates whether the specified cron expression can be parsed into avalid cron expression",
	"Method": "boolean isValid(String expression){\r\n    try {\r\n        validate(expression);\r\n    } catch (IllegalArgumentException pe) {\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.dash.manifest.UrlTemplate.buildUri",
	"Comment": "constructs a uri from the template, substituting in the provided arguments.arguments whose corresponding identifiers are not present in the template will be ignored.",
	"Method": "String buildUri(String representationId,long segmentNumber,int bandwidth,long time){\r\n    StringBuilder builder = new StringBuilder();\r\n    for (int i = 0; i < identifierCount; i++) {\r\n        builder.append(urlPieces[i]);\r\n        if (identifiers[i] == REPRESENTATION_ID) {\r\n            builder.append(representationId);\r\n        } else if (identifiers[i] == NUMBER_ID) {\r\n            builder.append(String.format(Locale.US, identifierFormatTags[i], segmentNumber));\r\n        } else if (identifiers[i] == BANDWIDTH_ID) {\r\n            builder.append(String.format(Locale.US, identifierFormatTags[i], bandwidth));\r\n        } else if (identifiers[i] == TIME_ID) {\r\n            builder.append(String.format(Locale.US, identifierFormatTags[i], time));\r\n        }\r\n    }\r\n    builder.append(urlPieces[identifierCount]);\r\n    return builder.toString();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlSpMetadataBuilder.withContact",
	"Comment": "a contact within the organisation that operates the service provider",
	"Method": "SamlSpMetadataBuilder withContact(ContactInfo contact,SamlSpMetadataBuilder withContact,String type,String givenName,String surName,String email){\r\n    return withContact(new ContactInfo(ContactInfo.getType(type), givenName, surName, email));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.TriggeredWatchStoreTests.testLoadStoreAsAlias",
	"Comment": "make sure that the watch store supports a single alias pointing to the watch index",
	"Method": "void testLoadStoreAsAlias(){\r\n    ClusterState.Builder csBuilder = new ClusterState.Builder(new ClusterName(\"_name\"));\r\n    RoutingTable.Builder routingTableBuilder = RoutingTable.builder();\r\n    MetaData.Builder metaDataBuilder = MetaData.builder();\r\n    metaDataBuilder.put(IndexMetaData.builder(\"triggered-watches-alias\").settings(indexSettings).putAlias(new AliasMetaData.Builder(TriggeredWatchStoreField.INDEX_NAME).build()));\r\n    final Index index = metaDataBuilder.get(\"triggered-watches-alias\").getIndex();\r\n    IndexRoutingTable.Builder indexRoutingTableBuilder = IndexRoutingTable.builder(index);\r\n    ShardId shardId = new ShardId(index, 0);\r\n    indexRoutingTableBuilder.addIndexShard(new IndexShardRoutingTable.Builder(shardId).addShard(TestShardRouting.newShardRouting(shardId, \"_node_id\", null, true, ShardRoutingState.STARTED)).build());\r\n    indexRoutingTableBuilder.addReplica();\r\n    routingTableBuilder.add(indexRoutingTableBuilder.build());\r\n    csBuilder.metaData(metaDataBuilder);\r\n    csBuilder.routingTable(routingTableBuilder.build());\r\n    ClusterState cs = csBuilder.build();\r\n    assertThat(TriggeredWatchStore.validate(cs), is(true));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.DefaultTrackSelector.getMaxVideoSizeInViewport",
	"Comment": "given viewport dimensions and video dimensions, computes the maximum size of the video as itwill be rendered to fit inside of the viewport.",
	"Method": "Point getMaxVideoSizeInViewport(boolean orientationMayChange,int viewportWidth,int viewportHeight,int videoWidth,int videoHeight){\r\n    if (orientationMayChange && (videoWidth > videoHeight) != (viewportWidth > viewportHeight)) {\r\n        int tempViewportWidth = viewportWidth;\r\n        viewportWidth = viewportHeight;\r\n        viewportHeight = tempViewportWidth;\r\n    }\r\n    if (videoWidth * viewportHeight >= videoHeight * viewportWidth) {\r\n        return new Point(viewportWidth, Util.ceilDivide(viewportWidth * videoHeight, videoWidth));\r\n    } else {\r\n        return new Point(Util.ceilDivide(viewportHeight * videoWidth, videoHeight), viewportHeight);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.MediaCodecVideoRenderer.getMaxInputSize",
	"Comment": "returns a maximum input buffer size for a given codec and format.",
	"Method": "int getMaxInputSize(MediaCodecInfo codecInfo,Format format){\r\n    if (format.maxInputSize != Format.NO_VALUE) {\r\n        int totalInitializationDataSize = 0;\r\n        int initializationDataCount = format.initializationData.size();\r\n        for (int i = 0; i < initializationDataCount; i++) {\r\n            totalInitializationDataSize += format.initializationData.get(i).length;\r\n        }\r\n        return format.maxInputSize + totalInitializationDataSize;\r\n    } else {\r\n        return getCodecMaxInputSize(codecInfo, format.sampleMimeType, format.width, format.height);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.advancePlayingPeriod",
	"Comment": "dequeues the playing period holder from the front of the queue and advances the playing periodholder to be the next item in the queue. if the playing period holder is unset, set it to theitem in the front of the queue.",
	"Method": "MediaPeriodHolder advancePlayingPeriod(){\r\n    if (playing != null) {\r\n        if (playing == reading) {\r\n            reading = playing.next;\r\n        }\r\n        playing.release();\r\n        length--;\r\n        if (length == 0) {\r\n            loading = null;\r\n            oldFrontPeriodUid = playing.uid;\r\n            oldFrontPeriodWindowSequenceNumber = playing.info.id.windowSequenceNumber;\r\n        }\r\n        playing = playing.next;\r\n    } else {\r\n        playing = loading;\r\n        reading = loading;\r\n    }\r\n    return playing;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.TraceUtil.beginSection",
	"Comment": "writes a trace message to indicate that a given section of code has begun.",
	"Method": "void beginSection(String sectionName){\r\n    if (ExoPlayerLibraryInfo.TRACE_ENABLED && Util.SDK_INT >= 18) {\r\n        beginSectionV18(sectionName);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.FileStructureUtils.guessMappingsAndCalculateFieldStats",
	"Comment": "given the sampled records, guess appropriate elasticsearch mappings.",
	"Method": "Tuple<SortedMap<String, Object>, SortedMap<String, FieldStats>> guessMappingsAndCalculateFieldStats(List<String> explanation,List<Map<String, ?>> sampleRecords,TimeoutChecker timeoutChecker){\r\n    SortedMap<String, Object> mappings = new TreeMap();\r\n    SortedMap<String, FieldStats> fieldStats = new TreeMap();\r\n    Set<String> uniqueFieldNames = sampleRecords.stream().flatMap(record -> record.keySet().stream()).collect(Collectors.toSet());\r\n    for (String fieldName : uniqueFieldNames) {\r\n        List<Object> fieldValues = sampleRecords.stream().flatMap(record -> {\r\n            Object fieldValue = record.get(fieldName);\r\n            return (fieldValue == null) ? Stream.empty() : Stream.of(fieldValue);\r\n        }).collect(Collectors.toList());\r\n        Tuple<Map<String, String>, FieldStats> mappingAndFieldStats = guessMappingAndCalculateFieldStats(explanation, fieldName, fieldValues, timeoutChecker);\r\n        if (mappingAndFieldStats != null) {\r\n            if (mappingAndFieldStats.v1() != null) {\r\n                mappings.put(fieldName, mappingAndFieldStats.v1());\r\n            }\r\n            if (mappingAndFieldStats.v2() != null) {\r\n                fieldStats.put(fieldName, mappingAndFieldStats.v2());\r\n            }\r\n        }\r\n    }\r\n    return new Tuple(mappings, fieldStats);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.exporter.local.LocalExporter.licenseChanged",
	"Comment": "when the license changes, we need to ensure that watcher is setup properly.",
	"Method": "void licenseChanged(){\r\n    watcherSetup.set(false);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.XmlPullParserUtil.isStartTag",
	"Comment": "returns whether the current event is a start tag with the specified name.",
	"Method": "boolean isStartTag(XmlPullParser xpp,String name,boolean isStartTag,XmlPullParser xpp){\r\n    return xpp.getEventType() == XmlPullParser.START_TAG;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherIndexingListenerTests.mockClusterState",
	"Comment": "create a mock cluster state, the returns the specified index as watch index",
	"Method": "ClusterState mockClusterState(String watchIndex){\r\n    MetaData metaData = mock(MetaData.class);\r\n    if (watchIndex == null) {\r\n        when(metaData.getAliasAndIndexLookup()).thenReturn(Collections.emptySortedMap());\r\n    } else {\r\n        SortedMap<String, AliasOrIndex> indices = new TreeMap();\r\n        IndexMetaData indexMetaData = mock(IndexMetaData.class);\r\n        when(indexMetaData.getIndex()).thenReturn(new Index(watchIndex, randomAlphaOfLength(10)));\r\n        indices.put(watchIndex, new AliasOrIndex.Index(indexMetaData));\r\n        if (watchIndex.equals(Watch.INDEX) == false) {\r\n            AliasMetaData aliasMetaData = mock(AliasMetaData.class);\r\n            when(aliasMetaData.alias()).thenReturn(watchIndex);\r\n            indices.put(Watch.INDEX, new AliasOrIndex.Alias(aliasMetaData, indexMetaData));\r\n        }\r\n        when(metaData.getAliasAndIndexLookup()).thenReturn(indices);\r\n    }\r\n    ClusterState clusterState = mock(ClusterState.class);\r\n    when(clusterState.metaData()).thenReturn(metaData);\r\n    DiscoveryNodes nodes = DiscoveryNodes.builder().localNodeId(\"node_1\").masterNodeId(\"node_1\").add(newNode(\"node_1\")).build();\r\n    when(clusterState.nodes()).thenReturn(nodes);\r\n    when(clusterState.getBlocks()).thenReturn(ClusterBlocks.EMPTY_CLUSTER_BLOCK);\r\n    return clusterState;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.SecurityContext.getAuthentication",
	"Comment": "returns the authentication information, or null if the current request has no authentication info.",
	"Method": "Authentication getAuthentication(){\r\n    try {\r\n        return Authentication.readFromContext(threadContext);\r\n    } catch (IOException e) {\r\n        logger.error(\"failed to read authentication\", e);\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecInfo.isVideoSizeAndRateSupportedV21",
	"Comment": "whether the decoder supports video with a given width, height and frame rate.must not be called if the device sdk version is less than 21.",
	"Method": "boolean isVideoSizeAndRateSupportedV21(int width,int height,double frameRate){\r\n    if (capabilities == null) {\r\n        logNoSupport(\"sizeAndRate.caps\");\r\n        return false;\r\n    }\r\n    VideoCapabilities videoCapabilities = capabilities.getVideoCapabilities();\r\n    if (videoCapabilities == null) {\r\n        logNoSupport(\"sizeAndRate.vCaps\");\r\n        return false;\r\n    }\r\n    if (!areSizeAndRateSupportedV21(videoCapabilities, width, height, frameRate)) {\r\n        if (width >= height || !areSizeAndRateSupportedV21(videoCapabilities, height, width, frameRate)) {\r\n            logNoSupport(\"sizeAndRate.support, \" + width + \"x\" + height + \"x\" + frameRate);\r\n            return false;\r\n        }\r\n        logAssumedSupport(\"sizeAndRate.rotated, \" + width + \"x\" + height + \"x\" + frameRate);\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.Util.getUserAgent",
	"Comment": "returns a user agent string based on the given application name and the library version.",
	"Method": "String getUserAgent(Context context,String applicationName){\r\n    String versionName;\r\n    try {\r\n        String packageName = context.getPackageName();\r\n        PackageInfo info = context.getPackageManager().getPackageInfo(packageName, 0);\r\n        versionName = info.versionName;\r\n    } catch (NameNotFoundException e) {\r\n        versionName = \"?\";\r\n    }\r\n    return applicationName + \"/\" + versionName + \" (Linux;Android \" + Build.VERSION.RELEASE + \") \" + ExoPlayerLibraryInfo.VERSION_SLASHY;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testReloadingKeyStore",
	"Comment": "tests reloading a keystore that is used in the keymanager of sslcontext",
	"Method": "void testReloadingKeyStore(){\r\n    assumeFalse(\"Can't run in a FIPS JVM\", inFipsJvm());\r\n    final Path tempDir = createTempDir();\r\n    final Path keystorePath = tempDir.resolve(\"testnode.jks\");\r\n    final Path updatedKeystorePath = tempDir.resolve(\"testnode_updated.jks\");\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.jks\"), keystorePath);\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode_updated.jks\"), updatedKeystorePath);\r\n    MockSecureSettings secureSettings = new MockSecureSettings();\r\n    secureSettings.setString(\"xpack.ssl.keystore.secure_password\", \"testnode\");\r\n    final Settings settings = Settings.builder().put(\"path.home\", createTempDir()).put(\"xpack.ssl.keystore.path\", keystorePath).setSecureSettings(secureSettings).build();\r\n    final Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);\r\n    try (CloseableHttpClient client = getSSLClient(keystorePath, \"testnode\")) {\r\n        final Consumer<SSLContext> keyMaterialPreChecks = (context) -> {\r\n            try (MockWebServer server = new MockWebServer(context, true)) {\r\n                server.enqueue(new MockResponse().setResponseCode(200).setBody(\"body\"));\r\n                server.start();\r\n                privilegedConnect(() -> client.execute(new HttpGet(\"https://localhost:\" + server.getPort())).close());\r\n            } catch (Exception e) {\r\n                throw new RuntimeException(\"Exception starting or connecting to the mock server\", e);\r\n            }\r\n        };\r\n        final Runnable modifier = () -> {\r\n            try {\r\n                atomicMoveIfPossible(updatedKeystorePath, keystorePath);\r\n            } catch (Exception e) {\r\n                throw new RuntimeException(\"modification failed\", e);\r\n            }\r\n        };\r\n        final Consumer<SSLContext> keyMaterialPostChecks = (updatedContext) -> {\r\n            try (MockWebServer server = new MockWebServer(updatedContext, true)) {\r\n                server.enqueue(new MockResponse().setResponseCode(200).setBody(\"body\"));\r\n                server.start();\r\n                SSLHandshakeException sslException = expectThrows(SSLHandshakeException.class, () -> privilegedConnect(() -> client.execute(new HttpGet(\"https://localhost:\" + server.getPort())).close()));\r\n                assertThat(sslException.getCause().getMessage(), containsString(\"PKIX path validation failed\"));\r\n            } catch (Exception e) {\r\n                throw new RuntimeException(\"Exception starting or connecting to the mock server\", e);\r\n            }\r\n        };\r\n        validateSSLConfigurationIsReloaded(settings, env, keyMaterialPreChecks, modifier, keyMaterialPostChecks);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.TimestampAdjuster.usToPts",
	"Comment": "converts a timestamp in microseconds to a 90 khz clock timestamp.",
	"Method": "long usToPts(long us){\r\n    return (us * 90000) / C.MICROS_PER_SECOND;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.smoothstreaming.offline.SsDownloadHelper.getManifest",
	"Comment": "returns the smoothstreaming manifest. must not be called until after preparation completes.",
	"Method": "SsManifest getManifest(){\r\n    Assertions.checkNotNull(manifest);\r\n    return manifest;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.HlsChunkSource.setIsTimestampMaster",
	"Comment": "sets whether this chunk source is responsible for initializing timestamp adjusters.",
	"Method": "void setIsTimestampMaster(boolean isTimestampMaster){\r\n    this.isTimestampMaster = isTimestampMaster;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.ExecutionService.clearExecutionsAndQueue",
	"Comment": "empty the currently queued tasks and wait for current executions to finish.",
	"Method": "int clearExecutionsAndQueue(){\r\n    int cancelledTaskCount = executor.queue().drainTo(new ArrayList());\r\n    this.clearExecutions();\r\n    return cancelledTaskCount;\r\n}"
}, {
	"Path": "org.elasticsearch.test.http.MockWebServer.close",
	"Comment": "closes down the webserver. also tries to stop all the currently sleeping requests first by counting down their respectivelatches.",
	"Method": "void close(){\r\n    logger.debug(\"[{}:{}] Counting down all latches before terminating executor\", getHostName(), getPort());\r\n    latches.forEach(CountDownLatch::countDown);\r\n    if (server.getExecutor() instanceof ExecutorService) {\r\n        terminate((ExecutorService) server.getExecutor());\r\n    }\r\n    server.stop(0);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.cache.ContentMetadataMutations.getEditedValues",
	"Comment": "returns a map of metadata name, value pairs to be set. values are copied.",
	"Method": "Map<String, Object> getEditedValues(){\r\n    HashMap<String, Object> hashMap = new HashMap(editedValues);\r\n    for (Entry<String, Object> entry : hashMap.entrySet()) {\r\n        Object value = entry.getValue();\r\n        if (value instanceof byte[]) {\r\n            byte[] bytes = (byte[]) value;\r\n            entry.setValue(Arrays.copyOf(bytes, bytes.length));\r\n        }\r\n    }\r\n    return Collections.unmodifiableMap(hashMap);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherLifeCycleServiceTests.testNonDataNode",
	"Comment": "make sure that cluster state changes can be processed on nodes that do not hold data",
	"Method": "void testNonDataNode(){\r\n    Index index = new Index(Watch.INDEX, \"foo\");\r\n    ShardId shardId = new ShardId(index, 0);\r\n    ShardRouting shardRouting = TestShardRouting.newShardRouting(shardId, \"node2\", true, STARTED);\r\n    IndexRoutingTable.Builder indexRoutingTable = IndexRoutingTable.builder(index).addShard(shardRouting);\r\n    DiscoveryNode node1 = new DiscoveryNode(\"node_1\", ESTestCase.buildNewFakeTransportAddress(), Collections.emptyMap(), new HashSet(asList(randomFrom(DiscoveryNode.Role.INGEST, DiscoveryNode.Role.MASTER))), Version.CURRENT);\r\n    DiscoveryNode node2 = new DiscoveryNode(\"node_2\", ESTestCase.buildNewFakeTransportAddress(), Collections.emptyMap(), new HashSet(asList(DiscoveryNode.Role.DATA)), Version.CURRENT);\r\n    DiscoveryNode node3 = new DiscoveryNode(\"node_3\", ESTestCase.buildNewFakeTransportAddress(), Collections.emptyMap(), new HashSet(asList(DiscoveryNode.Role.DATA)), Version.CURRENT);\r\n    IndexMetaData.Builder indexMetaDataBuilder = IndexMetaData.builder(Watch.INDEX).settings(Settings.builder().put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1).put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0).put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT));\r\n    ClusterState previousState = ClusterState.builder(new ClusterName(\"my-cluster\")).metaData(MetaData.builder().put(indexMetaDataBuilder)).nodes(new DiscoveryNodes.Builder().masterNodeId(\"node_1\").localNodeId(\"node_1\").add(node1).add(node2).add(node3)).routingTable(RoutingTable.builder().add(indexRoutingTable).build()).build();\r\n    IndexMetaData.Builder newIndexMetaDataBuilder = IndexMetaData.builder(Watch.INDEX).settings(Settings.builder().put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1).put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1).put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT));\r\n    ShardRouting replicaShardRouting = TestShardRouting.newShardRouting(shardId, \"node3\", false, STARTED);\r\n    IndexRoutingTable.Builder newRoutingTable = IndexRoutingTable.builder(index).addShard(shardRouting).addShard(replicaShardRouting);\r\n    ClusterState currentState = ClusterState.builder(new ClusterName(\"my-cluster\")).metaData(MetaData.builder().put(newIndexMetaDataBuilder)).nodes(new DiscoveryNodes.Builder().masterNodeId(\"node_1\").localNodeId(\"node_1\").add(node1).add(node2).add(node3)).routingTable(RoutingTable.builder().add(newRoutingTable).build()).build();\r\n    lifeCycleService.clusterChanged(new ClusterChangedEvent(\"any\", currentState, previousState));\r\n    verify(watcherService, times(0)).pauseExecution(anyObject());\r\n    verify(watcherService, times(0)).reload(any(), any());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.ts.PsDurationReader.readDuration",
	"Comment": "reads a ps duration from the input.this reader reads the duration by reading scr values from the header of a pack at the startand at the end of the stream, calculating the difference, and converting that into streamduration.",
	"Method": "int readDuration(ExtractorInput input,PositionHolder seekPositionHolder){\r\n    if (!isLastScrValueRead) {\r\n        return readLastScrValue(input, seekPositionHolder);\r\n    }\r\n    if (lastScrValue == C.TIME_UNSET) {\r\n        return finishReadDuration(input);\r\n    }\r\n    if (!isFirstScrValueRead) {\r\n        return readFirstScrValue(input, seekPositionHolder);\r\n    }\r\n    if (firstScrValue == C.TIME_UNSET) {\r\n        return finishReadDuration(input);\r\n    }\r\n    long minScrPositionUs = scrTimestampAdjuster.adjustTsTimestamp(firstScrValue);\r\n    long maxScrPositionUs = scrTimestampAdjuster.adjustTsTimestamp(lastScrValue);\r\n    durationUs = maxScrPositionUs - minScrPositionUs;\r\n    return finishReadDuration(input);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleMetadataQueue.advanceTo",
	"Comment": "attempts to advance the read position to the sample before or at the specified time.",
	"Method": "int advanceTo(long timeUs,boolean toKeyframe,boolean allowTimeBeyondBuffer){\r\n    int relativeReadIndex = getRelativeIndex(readPosition);\r\n    if (!hasNextSample() || timeUs < timesUs[relativeReadIndex] || (timeUs > largestQueuedTimestampUs && !allowTimeBeyondBuffer)) {\r\n        return SampleQueue.ADVANCE_FAILED;\r\n    }\r\n    int offset = findSampleBefore(relativeReadIndex, length - readPosition, timeUs, toKeyframe);\r\n    if (offset == -1) {\r\n        return SampleQueue.ADVANCE_FAILED;\r\n    }\r\n    readPosition += offset;\r\n    return offset;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.PlayerMessage.getWindowIndex",
	"Comment": "returns window index at which the message will be delivered.",
	"Method": "int getWindowIndex(){\r\n    return windowIndex;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.OggTestData.getCommentHeaderDataUTF8",
	"Comment": "returns a valid vorbis comment header with 3 comments including utf8 chars in bytes.",
	"Method": "byte[] getCommentHeaderDataUTF8(){\r\n    byte[] commentHeaderData = new byte[COMMENT_HEADER_WITH_UTF8.length];\r\n    System.arraycopy(COMMENT_HEADER_WITH_UTF8, 0, commentHeaderData, 0, COMMENT_HEADER_WITH_UTF8.length);\r\n    return commentHeaderData;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.exporter.http.HttpExporter.createDefaultParams",
	"Comment": "create the default parameters to use with bulk indexing operations.",
	"Method": "Map<String, String> createDefaultParams(Config config){\r\n    final TimeValue bulkTimeout = BULK_TIMEOUT_SETTING.getConcreteSettingForNamespace(config.name()).get(config.settings());\r\n    final MapBuilder<String, String> params = new MapBuilder();\r\n    if (TimeValue.MINUS_ONE.equals(bulkTimeout) == false) {\r\n        params.put(\"timeout\", bulkTimeout.toString());\r\n    }\r\n    if (USE_INGEST_PIPELINE_SETTING.getConcreteSettingForNamespace(config.name()).get(config.settings())) {\r\n        params.put(\"pipeline\", MonitoringTemplateUtils.pipelineName(MonitoringTemplateUtils.TEMPLATE_VERSION));\r\n    }\r\n    params.put(\"filter_path\", \"errors,items.*.error\");\r\n    return params.immutableMap();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testReloadingKeyStoreException",
	"Comment": "tests the reloading of a keystore when there is an exception during reloading. an exception is caused by truncating the keystorethat is being monitored",
	"Method": "void testReloadingKeyStoreException(){\r\n    assumeFalse(\"Can't run in a FIPS JVM\", inFipsJvm());\r\n    Path tempDir = createTempDir();\r\n    Path keystorePath = tempDir.resolve(\"testnode.jks\");\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.jks\"), keystorePath);\r\n    MockSecureSettings secureSettings = new MockSecureSettings();\r\n    secureSettings.setString(\"xpack.ssl.keystore.secure_password\", \"testnode\");\r\n    Settings settings = Settings.builder().put(\"xpack.ssl.keystore.path\", keystorePath).setSecureSettings(secureSettings).put(\"path.home\", createTempDir()).build();\r\n    Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);\r\n    final SSLService sslService = new SSLService(settings, env);\r\n    final SSLConfiguration config = sslService.getSSLConfiguration(\"xpack.ssl\");\r\n    new SSLConfigurationReloader(env, sslService, resourceWatcherService) {\r\n        @Override\r\n        void reloadSSLContext(SSLConfiguration configuration) {\r\n            fail(\"reload should not be called! [keystore reload exception]\");\r\n        }\r\n    };\r\n    final SSLContext context = sslService.sslContextHolder(config).sslContext();\r\n    try (OutputStream out = Files.newOutputStream(keystorePath, StandardOpenOption.TRUNCATE_EXISTING)) {\r\n    }\r\n    assertThat(sslService.sslContextHolder(config).sslContext(), sameInstance(context));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testReloadingKeyStoreException",
	"Comment": "tests the reloading of a keystore when there is an exception during reloading. an exception is caused by truncating the keystorethat is being monitored",
	"Method": "void testReloadingKeyStoreException(){\r\n    fail(\"reload should not be called! [keystore reload exception]\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.SpnegoClient.loginUsingPassword",
	"Comment": "performs authentication using provided principal name and password for client",
	"Method": "LoginContext loginUsingPassword(String principal,SecureString password){\r\n    final Set<Principal> principals = Collections.singleton(new KerberosPrincipal(principal));\r\n    final Subject subject = new Subject(false, principals, Collections.emptySet(), Collections.emptySet());\r\n    final Configuration conf = new PasswordJaasConf(principal);\r\n    final CallbackHandler callback = new KrbCallbackHandler(principal, password);\r\n    final LoginContext loginContext = new LoginContext(CRED_CONF_NAME, subject, callback, conf);\r\n    loginContext.login();\r\n    return loginContext;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.indexBwcInvalidation",
	"Comment": "performs the actual bwc invalidation of a token and then kicks off the new invalidation method",
	"Method": "void indexBwcInvalidation(UserToken userToken,ActionListener<Boolean> listener,AtomicInteger attemptCount,long expirationEpochMilli){\r\n    if (attemptCount.get() > MAX_RETRY_ATTEMPTS) {\r\n        logger.warn(\"Failed to invalidate token [{}] after [{}] attempts\", userToken.getId(), attemptCount.get());\r\n        listener.onFailure(invalidGrantException(\"failed to invalidate token\"));\r\n    } else {\r\n        final String invalidatedTokenId = getInvalidatedTokenDocumentId(userToken);\r\n        IndexRequest indexRequest = client.prepareIndex(SecurityIndexManager.SECURITY_INDEX_NAME, TYPE, invalidatedTokenId).setOpType(OpType.CREATE).setSource(\"doc_type\", INVALIDATED_TOKEN_DOC_TYPE, \"expiration_time\", expirationEpochMilli).setRefreshPolicy(RefreshPolicy.WAIT_UNTIL).request();\r\n        final String tokenDocId = getTokenDocumentId(userToken);\r\n        final Version version = userToken.getVersion();\r\n        securityIndex.prepareIndexIfNeededThenExecute(ex -> listener.onFailure(traceLog(\"prepare security index\", tokenDocId, ex)), () -> executeAsyncWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN, indexRequest, ActionListener.<IndexResponse>wrap(indexResponse -> {\r\n            ActionListener<Boolean> wrappedListener = ActionListener.wrap(ignore -> listener.onResponse(true), listener::onFailure);\r\n            indexInvalidation(tokenDocId, version, wrappedListener, attemptCount, \"access_token\", 1L);\r\n        }, e -> {\r\n            Throwable cause = ExceptionsHelper.unwrapCause(e);\r\n            traceLog(\"(bwc) invalidate token\", tokenDocId, cause);\r\n            if (cause instanceof VersionConflictEngineException) {\r\n                ActionListener<Boolean> wrappedListener = ActionListener.wrap(ignore -> listener.onResponse(false), listener::onFailure);\r\n                indexInvalidation(tokenDocId, version, wrappedListener, attemptCount, \"access_token\", 1L);\r\n            } else if (isShardNotAvailableException(e)) {\r\n                attemptCount.incrementAndGet();\r\n                indexBwcInvalidation(userToken, listener, attemptCount, expirationEpochMilli);\r\n            } else {\r\n                listener.onFailure(e);\r\n            }\r\n        }), client::index));\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister.commitResultWrites",
	"Comment": "once all the job data has been written this function will becalled to commit the writes to the datastore.",
	"Method": "void commitResultWrites(String jobId){\r\n    String indexName = AnomalyDetectorsIndex.jobResultsAliasedName(jobId);\r\n    logger.trace(\"[{}] ES API CALL: refresh index {}\", jobId, indexName);\r\n    RefreshRequest refreshRequest = new RefreshRequest(indexName);\r\n    refreshRequest.indicesOptions(IndicesOptions.lenientExpandOpen());\r\n    try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {\r\n        client.admin().indices().refresh(refreshRequest).actionGet();\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.ads.AdPlaybackState.withSkippedAd",
	"Comment": "returns an instance with the specified ad marked as skipped.",
	"Method": "AdPlaybackState withSkippedAd(int adGroupIndex,int adIndexInAdGroup){\r\n    AdGroup[] adGroups = Arrays.copyOf(this.adGroups, this.adGroups.length);\r\n    adGroups[adGroupIndex] = adGroups[adGroupIndex].withAdState(AD_STATE_SKIPPED, adIndexInAdGroup);\r\n    return new AdPlaybackState(adGroupTimesUs, adGroups, adResumePositionUs, contentDurationUs);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.DefaultTimeBar.setUnplayedColor",
	"Comment": "sets the color for the portion of the time bar after the current played position.",
	"Method": "void setUnplayedColor(int unplayedColor){\r\n    unplayedPaint.setColor(unplayedColor);\r\n    invalidate(seekBounds);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.DefaultMediaClock.onRendererDisabled",
	"Comment": "notifies the media clock that a renderer has been disabled. stops using the media clock of thisrenderer if used.",
	"Method": "void onRendererDisabled(Renderer renderer){\r\n    if (renderer == rendererClockSource) {\r\n        this.rendererClock = null;\r\n        this.rendererClockSource = null;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfiguration.cipherSuites",
	"Comment": "the cipher suites that will be used for this ssl configuration",
	"Method": "List<String> cipherSuites(){\r\n    return ciphers;\r\n}"
}, {
	"Path": "com.alibaba.fastjson.support.jaxrs.FastJsonProvider.locateConfigProvider",
	"Comment": "helper method that is called if no config has been explicitly configured.",
	"Method": "FastJsonConfig locateConfigProvider(Class<?> type,MediaType mediaType){\r\n    if (providers != null) {\r\n        ContextResolver<FastJsonConfig> resolver = providers.getContextResolver(FastJsonConfig.class, mediaType);\r\n        if (resolver == null) {\r\n            resolver = providers.getContextResolver(FastJsonConfig.class, null);\r\n        }\r\n        if (resolver != null) {\r\n            return resolver.getContext(type);\r\n        }\r\n    }\r\n    return fastJsonConfig;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testPEMTrustReloadException",
	"Comment": "tests the reloading of a trust config backed by pem files when there is an exception during reloading. an exception is caused bytruncating the certificate file that is being monitored",
	"Method": "void testPEMTrustReloadException(){\r\n    Path tempDir = createTempDir();\r\n    Path clientCertPath = tempDir.resolve(\"testclient.crt\");\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testclient.crt\"), clientCertPath);\r\n    Settings settings = Settings.builder().putList(\"xpack.ssl.certificate_authorities\", clientCertPath.toString()).put(\"path.home\", createTempDir()).build();\r\n    Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);\r\n    final SSLService sslService = new SSLService(settings, env);\r\n    final SSLConfiguration config = sslService.getSSLConfiguration(\"xpack.ssl\");\r\n    new SSLConfigurationReloader(env, sslService, resourceWatcherService) {\r\n        @Override\r\n        void reloadSSLContext(SSLConfiguration configuration) {\r\n            fail(\"reload should not be called! [pem trust reload exception]\");\r\n        }\r\n    };\r\n    final SSLContext context = sslService.sslContextHolder(config).sslContext();\r\n    Path updatedCert = tempDir.resolve(\"updated.crt\");\r\n    try (OutputStream os = Files.newOutputStream(updatedCert)) {\r\n        os.write(randomByte());\r\n    }\r\n    atomicMoveIfPossible(updatedCert, clientCertPath);\r\n    assertThat(sslService.sslContextHolder(config).sslContext(), sameInstance(context));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testPEMTrustReloadException",
	"Comment": "tests the reloading of a trust config backed by pem files when there is an exception during reloading. an exception is caused bytruncating the certificate file that is being monitored",
	"Method": "void testPEMTrustReloadException(){\r\n    fail(\"reload should not be called! [pem trust reload exception]\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfiguration.keyConfig",
	"Comment": "the configuration for the key, if any, that will be used as part of this ssl configuration",
	"Method": "KeyConfig keyConfig(){\r\n    return keyConfig;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.datafeed.ProblemTracker.finishReport",
	"Comment": "issues a recovery message if appropriate and prepares for next report",
	"Method": "void finishReport(){\r\n    if (!hasProblems && hadProblems) {\r\n        auditor.info(jobId, Messages.getMessage(Messages.JOB_AUDIT_DATAFEED_RECOVERED));\r\n    }\r\n    hadProblems = hasProblems;\r\n    hasProblems = false;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.plugin.SqlLicenseChecker.checkIfSqlAllowed",
	"Comment": "throws an elasticsearchsecurityexception if the specified mode is not allowed",
	"Method": "void checkIfSqlAllowed(Mode mode){\r\n    checkIfSqlAllowed.accept(mode);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.realm.ClearRealmCacheRequestBuilder.usernames",
	"Comment": "sets the usernames of the users that should be evicted from the caches. when not set, all userswill be evicted.",
	"Method": "ClearRealmCacheRequestBuilder usernames(String usernames){\r\n    request.usernames(usernames);\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.upgrade.IndexUpgradeCheckFactory.supportedParams",
	"Comment": "using this method the check can expose additional user parameter that can be specified by the user on upgrade api",
	"Method": "Collection<String> supportedParams(){\r\n    return Collections.emptyList();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.SecurityContext.setUser",
	"Comment": "sets the user forcefully to the provided user. there must not be an existing user in the threadcontext otherwise an exceptionwill be thrown. this method is package private for testing.",
	"Method": "void setUser(User user,Version version){\r\n    Objects.requireNonNull(user);\r\n    final Authentication.RealmRef authenticatedBy = new Authentication.RealmRef(\"__attach\", \"__attach\", nodeName);\r\n    final Authentication.RealmRef lookedUpBy;\r\n    if (user.isRunAs()) {\r\n        lookedUpBy = authenticatedBy;\r\n    } else {\r\n        lookedUpBy = null;\r\n    }\r\n    setAuthentication(new Authentication(user, authenticatedBy, lookedUpBy, version));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.SecurityExtension.loadExtensions",
	"Comment": "loads the xpacksecurityextensions from the given class loader",
	"Method": "List<SecurityExtension> loadExtensions(ClassLoader loader){\r\n    SPIClassIterator<SecurityExtension> iterator = SPIClassIterator.get(SecurityExtension.class, loader);\r\n    List<SecurityExtension> extensions = new ArrayList();\r\n    while (iterator.hasNext()) {\r\n        final Class<? extends SecurityExtension> c = iterator.next();\r\n        try {\r\n            extensions.add(c.getConstructor().newInstance());\r\n        } catch (Exception e) {\r\n            throw new ServiceConfigurationError(\"failed to load security extension [\" + c.getName() + \"]\", e);\r\n        }\r\n    }\r\n    return extensions;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.verifyPassword",
	"Comment": "this method is used to verify the username and credentials against those stored in the system.",
	"Method": "void verifyPassword(String username,SecureString password,ActionListener<AuthenticationResult> listener,boolean verifyPassword,SecureString data){\r\n    getUserAndPassword(username, ActionListener.wrap((userAndPassword) -> {\r\n        if (userAndPassword == null || userAndPassword.passwordHash() == null) {\r\n            listener.onResponse(AuthenticationResult.notHandled());\r\n        } else if (userAndPassword.verifyPassword(password)) {\r\n            listener.onResponse(AuthenticationResult.success(userAndPassword.user()));\r\n        } else {\r\n            listener.onResponse(AuthenticationResult.unsuccessful(\"Password authentication failed for \" + username, null));\r\n        }\r\n    }, listener::onFailure));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.flac.FlacLibrary.isAvailable",
	"Comment": "returns whether the underlying library is available, loading it if necessary.",
	"Method": "boolean isAvailable(){\r\n    return LOADER.isAvailable();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodInfo.copyWithStartPositionUs",
	"Comment": "returns a copy of this instance with the start position set to the specified value.",
	"Method": "MediaPeriodInfo copyWithStartPositionUs(long startPositionUs){\r\n    return new MediaPeriodInfo(id, startPositionUs, contentPositionUs, durationUs, isLastInTimelinePeriod, isFinal);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.TestUtil.assertBitmapsAreSimilar",
	"Comment": "asserts whether actual bitmap is very similar to the expected bitmap at some quality level.this is defined as their psnr value is greater than or equal to the threshold. the higherthe threshold, the more similar they are.",
	"Method": "void assertBitmapsAreSimilar(Bitmap expectedBitmap,Bitmap actualBitmap,double psnrThresholdDb){\r\n    assertThat(getPsnr(expectedBitmap, actualBitmap)).isAtLeast(psnrThresholdDb);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.utils.NamedPipeHelper.openNamedPipeOutputStreamUnix",
	"Comment": "this has to use different logic to the input pipe case to avoid the danger of creatinga regular file when the named pipe does not exist when the method is first called.",
	"Method": "OutputStream openNamedPipeOutputStreamUnix(Path file,Duration timeout){\r\n    long timeoutMillisRemaining = timeout.toMillis();\r\n    while (timeoutMillisRemaining > 0 && !Files.exists(file)) {\r\n        long thisSleep = Math.min(timeoutMillisRemaining, PAUSE_TIME_MS);\r\n        timeoutMillisRemaining -= thisSleep;\r\n        try {\r\n            Thread.sleep(thisSleep);\r\n        } catch (InterruptedException ie) {\r\n            Thread.currentThread().interrupt();\r\n            break;\r\n        }\r\n    }\r\n    if (Files.isRegularFile(file)) {\r\n        throw new IOException(file + \" is not a named pipe\");\r\n    }\r\n    if (!Files.exists(file)) {\r\n        throw new FileNotFoundException(\"Cannot open \" + file + \" (No such file or directory)\");\r\n    }\r\n    return Files.newOutputStream(file);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.PsshAtomUtil.parseVersion",
	"Comment": "parses the version from a pssh atom. version 0 and 1 pssh atoms are supported.the version is only parsed if the data is a valid pssh atom.",
	"Method": "int parseVersion(byte[] atom){\r\n    PsshAtom parsedAtom = parsePsshAtom(atom);\r\n    if (parsedAtom == null) {\r\n        return -1;\r\n    }\r\n    return parsedAtom.version;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.action.CliFormatter.estimateSize",
	"Comment": "pick a good estimate of the buffer size needed to contain the rows.",
	"Method": "int estimateSize(int rows){\r\n    int rowWidthEstimate = width.length;\r\n    for (int w : width) {\r\n        rowWidthEstimate += w;\r\n    }\r\n    return rowWidthEstimate * rows;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.metadata.id3.Id3Decoder.copyOfRangeIfValid",
	"Comment": "copies the specified range of an array, or returns a zero length array if the range is invalid.",
	"Method": "byte[] copyOfRangeIfValid(byte[] data,int from,int to){\r\n    if (to <= from) {\r\n        return Util.EMPTY_BYTE_ARRAY;\r\n    }\r\n    return Arrays.copyOfRange(data, from, to);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.exporter.Exporters.getSettings",
	"Comment": "return all the settings of all the exporters, no matter if http or local",
	"Method": "List<Setting.AffixSetting<?>> getSettings(){\r\n    List<Setting.AffixSetting<?>> settings = new ArrayList();\r\n    settings.addAll(Exporter.getSettings());\r\n    settings.addAll(HttpExporter.getSettings());\r\n    return settings;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.FixedSampleSizeRechunker.rechunk",
	"Comment": "rechunk the given fixed sample size input to produce a new sequence of samples.",
	"Method": "Results rechunk(int fixedSampleSize,long[] chunkOffsets,int[] chunkSampleCounts,long timestampDeltaInTimeUnits){\r\n    int maxSampleCount = MAX_SAMPLE_SIZE / fixedSampleSize;\r\n    int rechunkedSampleCount = 0;\r\n    for (int chunkSampleCount : chunkSampleCounts) {\r\n        rechunkedSampleCount += Util.ceilDivide(chunkSampleCount, maxSampleCount);\r\n    }\r\n    long[] offsets = new long[rechunkedSampleCount];\r\n    int[] sizes = new int[rechunkedSampleCount];\r\n    int maximumSize = 0;\r\n    long[] timestamps = new long[rechunkedSampleCount];\r\n    int[] flags = new int[rechunkedSampleCount];\r\n    int originalSampleIndex = 0;\r\n    int newSampleIndex = 0;\r\n    for (int chunkIndex = 0; chunkIndex < chunkSampleCounts.length; chunkIndex++) {\r\n        int chunkSamplesRemaining = chunkSampleCounts[chunkIndex];\r\n        long sampleOffset = chunkOffsets[chunkIndex];\r\n        while (chunkSamplesRemaining > 0) {\r\n            int bufferSampleCount = Math.min(maxSampleCount, chunkSamplesRemaining);\r\n            offsets[newSampleIndex] = sampleOffset;\r\n            sizes[newSampleIndex] = fixedSampleSize * bufferSampleCount;\r\n            maximumSize = Math.max(maximumSize, sizes[newSampleIndex]);\r\n            timestamps[newSampleIndex] = (timestampDeltaInTimeUnits * originalSampleIndex);\r\n            flags[newSampleIndex] = C.BUFFER_FLAG_KEY_FRAME;\r\n            sampleOffset += sizes[newSampleIndex];\r\n            originalSampleIndex += bufferSampleCount;\r\n            chunkSamplesRemaining -= bufferSampleCount;\r\n            newSampleIndex++;\r\n        }\r\n    }\r\n    long duration = timestampDeltaInTimeUnits * originalSampleIndex;\r\n    return new Results(offsets, sizes, maximumSize, timestamps, flags, duration);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.normalizer.Normalizer.mergeRecursively",
	"Comment": "recursively merges the scores returned by the normalization process into the results",
	"Method": "double mergeRecursively(Iterator<NormalizerResult> scoresIter,Normalizable parent,boolean parentHadBigChange,Normalizable result){\r\n    boolean hasBigChange = false;\r\n    if (result.isContainerOnly() == false) {\r\n        if (!scoresIter.hasNext()) {\r\n            String msg = \"Error iterating normalized results\";\r\n            LOGGER.error(\"[{}] {}\", jobId, msg);\r\n            throw new ElasticsearchException(msg);\r\n        }\r\n        result.resetBigChangeFlag();\r\n        if (parent != null && parentHadBigChange) {\r\n            result.setParentScore(parent.getNormalizedScore());\r\n            result.raiseBigChangeFlag();\r\n        }\r\n        double normalizedScore = scoresIter.next().getNormalizedScore();\r\n        hasBigChange = isBigUpdate(result.getNormalizedScore(), normalizedScore);\r\n        if (hasBigChange) {\r\n            result.setNormalizedScore(normalizedScore);\r\n            result.raiseBigChangeFlag();\r\n            if (parent != null) {\r\n                parent.raiseBigChangeFlag();\r\n            }\r\n        }\r\n    }\r\n    for (Normalizable.ChildType childrenType : result.getChildrenTypes()) {\r\n        List<Normalizable> children = result.getChildren(childrenType);\r\n        if (!children.isEmpty()) {\r\n            double maxChildrenScore = 0.0;\r\n            for (Normalizable child : children) {\r\n                maxChildrenScore = Math.max(mergeRecursively(scoresIter, result, hasBigChange, child), maxChildrenScore);\r\n            }\r\n            hasBigChange |= result.setMaxChildrenScore(childrenType, maxChildrenScore);\r\n        }\r\n    }\r\n    return result.getNormalizedScore();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.TimestampAdjuster.ptsToUs",
	"Comment": "converts a 90 khz clock timestamp to a timestamp in microseconds.",
	"Method": "long ptsToUs(long pts){\r\n    return (pts * C.MICROS_PER_SECOND) / 90000;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleQueue.advanceTo",
	"Comment": "attempts to advance the read position to the sample before or at the specified time.",
	"Method": "int advanceTo(long timeUs,boolean toKeyframe,boolean allowTimeBeyondBuffer){\r\n    return metadataQueue.advanceTo(timeUs, toKeyframe, allowTimeBeyondBuffer);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.PemUtils.removeECHeaders",
	"Comment": "removes the ec headers that openssl adds to ec private keys as the information in themis redundant",
	"Method": "BufferedReader removeECHeaders(BufferedReader bReader){\r\n    String line = bReader.readLine();\r\n    while (line != null) {\r\n        if (OPENSSL_EC_PARAMS_FOOTER.equals(line.trim())) {\r\n            break;\r\n        }\r\n        line = bReader.readLine();\r\n    }\r\n    if (null == line || OPENSSL_EC_PARAMS_FOOTER.equals(line.trim()) == false) {\r\n        throw new IOException(\"Malformed PEM file, EC Parameters footer is missing\");\r\n    }\r\n    if (OPENSSL_EC_HEADER.equals(bReader.readLine()) == false) {\r\n        throw new IOException(\"Malformed PEM file, EC Key header is missing\");\r\n    }\r\n    return bReader;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.PlaybackInfo.resetToNewPosition",
	"Comment": "copies playback info and resets playing and loading position.",
	"Method": "PlaybackInfo resetToNewPosition(MediaPeriodId periodId,long startPositionUs,long contentPositionUs){\r\n    return new PlaybackInfo(timeline, manifest, periodId, startPositionUs, periodId.isAd() ? contentPositionUs : C.TIME_UNSET, playbackState, isLoading, trackGroups, trackSelectorResult, periodId, startPositionUs, 0, startPositionUs);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.HlsSampleStreamWrapper.seekToUs",
	"Comment": "attempts to seek to the specified position in microseconds.",
	"Method": "boolean seekToUs(long positionUs,boolean forceReset){\r\n    lastSeekPositionUs = positionUs;\r\n    if (isPendingReset()) {\r\n        pendingResetPositionUs = positionUs;\r\n        return true;\r\n    }\r\n    if (sampleQueuesBuilt && !forceReset && seekInsideBufferUs(positionUs)) {\r\n        return false;\r\n    }\r\n    pendingResetPositionUs = positionUs;\r\n    loadingFinished = false;\r\n    mediaChunks.clear();\r\n    if (loader.isLoading()) {\r\n        loader.cancelLoading();\r\n    } else {\r\n        resetSampleQueues();\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.support.WatcherIndexTemplateRegistryTests.testThatTemplatesAreAppliedOnNewerNodes",
	"Comment": "otherwise a rolling upgrade would not work as expected, when the node has a .watches shard on it",
	"Method": "void testThatTemplatesAreAppliedOnNewerNodes(){\r\n    DiscoveryNode localNode = new DiscoveryNode(\"node\", ESTestCase.buildNewFakeTransportAddress(), Version.CURRENT);\r\n    DiscoveryNode masterNode = new DiscoveryNode(\"master\", ESTestCase.buildNewFakeTransportAddress(), Version.V_6_0_0);\r\n    DiscoveryNodes nodes = DiscoveryNodes.builder().localNodeId(\"node\").masterNodeId(\"master\").add(localNode).add(masterNode).build();\r\n    ClusterChangedEvent event = createClusterChangedEvent(Arrays.asList(WatcherIndexTemplateRegistryField.TRIGGERED_TEMPLATE_NAME, WatcherIndexTemplateRegistryField.WATCHES_TEMPLATE_NAME, \".watch-history-6\"), nodes);\r\n    registry.clusterChanged(event);\r\n    ArgumentCaptor<PutIndexTemplateRequest> argumentCaptor = ArgumentCaptor.forClass(PutIndexTemplateRequest.class);\r\n    verify(client.admin().indices(), times(1)).putTemplate(argumentCaptor.capture(), anyObject());\r\n    assertThat(argumentCaptor.getValue().name(), is(WatcherIndexTemplateRegistryField.HISTORY_TEMPLATE_NAME));\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ByteVector.putUTF8",
	"Comment": "puts an utf8 string into this byte vector. the byte vector is automatically enlarged if necessary.",
	"Method": "ByteVector putUTF8(String s){\r\n    int charLength = s.length();\r\n    int len = length;\r\n    if (len + 2 + charLength > data.length) {\r\n        enlarge(2 + charLength);\r\n    }\r\n    byte[] data = this.data;\r\n    data[len++] = (byte) (charLength >>> 8);\r\n    data[len++] = (byte) charLength;\r\n    for (int i = 0; i < charLength; ++i) {\r\n        char c = s.charAt(i);\r\n        if (c >= '\\001' && c <= '\\177') {\r\n            data[len++] = (byte) c;\r\n        } else {\r\n            throw new UnsupportedOperationException();\r\n        }\r\n    }\r\n    length = len;\r\n    return this;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.dash.manifest.DashManifestParser.getSampleMimeType",
	"Comment": "derives a sample mimetype from a container mimetype and codecs attribute.",
	"Method": "String getSampleMimeType(String containerMimeType,String codecs){\r\n    if (MimeTypes.isAudio(containerMimeType)) {\r\n        return MimeTypes.getAudioMediaMimeType(codecs);\r\n    } else if (MimeTypes.isVideo(containerMimeType)) {\r\n        return MimeTypes.getVideoMediaMimeType(codecs);\r\n    } else if (mimeTypeIsRawText(containerMimeType)) {\r\n        return containerMimeType;\r\n    } else if (MimeTypes.APPLICATION_MP4.equals(containerMimeType)) {\r\n        if (codecs != null) {\r\n            if (codecs.startsWith(\"stpp\")) {\r\n                return MimeTypes.APPLICATION_TTML;\r\n            } else if (codecs.startsWith(\"wvtt\")) {\r\n                return MimeTypes.APPLICATION_MP4VTT;\r\n            }\r\n        }\r\n    } else if (MimeTypes.APPLICATION_RAWCC.equals(containerMimeType)) {\r\n        if (codecs != null) {\r\n            if (codecs.contains(\"cea708\")) {\r\n                return MimeTypes.APPLICATION_CEA708;\r\n            } else if (codecs.contains(\"eia608\") || codecs.contains(\"cea608\")) {\r\n                return MimeTypes.APPLICATION_CEA608;\r\n            }\r\n        }\r\n        return null;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.capacity",
	"Comment": "returns the capacity of the array, which may be larger than the limit.",
	"Method": "int capacity(){\r\n    return data.length;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.test.rest.XPackRestTestHelper.waitForMlTemplates",
	"Comment": "waits for the machine learning templates to be createdand check the version is up to date",
	"Method": "void waitForMlTemplates(RestClient client){\r\n    AtomicReference<Version> masterNodeVersion = new AtomicReference();\r\n    ESTestCase.awaitBusy(() -> {\r\n        String response;\r\n        try {\r\n            Request request = new Request(\"GET\", \"/_cat/nodes\");\r\n            request.addParameter(\"h\", \"master,version\");\r\n            response = EntityUtils.toString(client.performRequest(request).getEntity());\r\n        } catch (IOException e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n        for (String line : response.split(\"\\n\")) {\r\n            if (line.startsWith(\"*\")) {\r\n                masterNodeVersion.set(Version.fromString(line.substring(2).trim()));\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    });\r\n    final List<String> templateNames = Arrays.asList(AuditorField.NOTIFICATIONS_INDEX, MlMetaIndex.INDEX_NAME, AnomalyDetectorsIndex.jobStateIndexName(), AnomalyDetectorsIndex.jobResultsIndexPrefix());\r\n    for (String template : templateNames) {\r\n        ESTestCase.awaitBusy(() -> {\r\n            Map<?, ?> response;\r\n            try {\r\n                String string = EntityUtils.toString(client.performRequest(new Request(\"GET\", \"/_template/\" + template)).getEntity());\r\n                response = XContentHelper.convertToMap(JsonXContent.jsonXContent, string, false);\r\n            } catch (ResponseException e) {\r\n                if (e.getResponse().getStatusLine().getStatusCode() == 404) {\r\n                    return false;\r\n                }\r\n                throw new RuntimeException(e);\r\n            } catch (IOException e) {\r\n                throw new RuntimeException(e);\r\n            }\r\n            Map<?, ?> templateDefinition = (Map<?, ?>) response.get(template);\r\n            return Version.fromId((Integer) templateDefinition.get(\"version\")).equals(masterNodeVersion.get());\r\n        });\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlTestCase.readRandomKeyPair",
	"Comment": "generates signed certificate and associates with generated key pair.",
	"Method": "Tuple<X509Certificate, PrivateKey> readRandomKeyPair(Tuple<X509Certificate, PrivateKey> readRandomKeyPair,String algorithm){\r\n    int keySize;\r\n    switch(algorithm) {\r\n        case \"EC\":\r\n            keySize = randomFrom(256, 384);\r\n            break;\r\n        case \"RSA\":\r\n            keySize = randomFrom(1024, 2048, 4096);\r\n            break;\r\n        case \"DSA\":\r\n            keySize = randomFrom(1024, 2048, 3072);\r\n            break;\r\n        default:\r\n            keySize = randomFrom(1024, 2048);\r\n    }\r\n    Path keyPath = PathUtils.get(SamlTestCase.class.getResource(\"/org/elasticsearch/xpack/security/authc/saml/saml_\" + algorithm + \"_\" + keySize + \".key\").toURI());\r\n    Path certPath = PathUtils.get(SamlTestCase.class.getResource(\"/org/elasticsearch/xpack/security/authc/saml/saml_\" + algorithm + \"_\" + keySize + \".crt\").toURI());\r\n    X509Certificate certificate = CertParsingUtils.readX509Certificates(Collections.singletonList(certPath))[0];\r\n    PrivateKey privateKey = PemUtils.readPrivateKey(keyPath, \"\"::toCharArray);\r\n    return new Tuple(certificate, privateKey);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.DataCountsReporter.finishReporting",
	"Comment": "report the counts now regardless of whether or not we are at a reporting boundary.",
	"Method": "void finishReporting(ActionListener<Boolean> listener){\r\n    Date now = new Date();\r\n    incrementalRecordStats.setLastDataTimeStamp(now);\r\n    totalRecordStats.setLastDataTimeStamp(now);\r\n    diagnostics.flush();\r\n    retrieveDiagnosticsIntermediateResults();\r\n    dataCountsPersister.persistDataCounts(job.getId(), runningTotalStats(), listener);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerView.hideController",
	"Comment": "hides the playback controls. does nothing if playback controls are disabled.",
	"Method": "void hideController(){\r\n    if (controller != null) {\r\n        controller.hide();\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecUtil.codecNeedsDisableAdaptationWorkaround",
	"Comment": "returns whether the decoder is known to fail when adapting, despite advertising itself as anadaptive decoder.",
	"Method": "boolean codecNeedsDisableAdaptationWorkaround(String name){\r\n    return Util.SDK_INT <= 22 && (\"ODROID-XU3\".equals(Util.MODEL) || \"Nexus 10\".equals(Util.MODEL)) && (\"OMX.Exynos.AVC.Decoder\".equals(name) || \"OMX.Exynos.AVC.Decoder.secure\".equals(name));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.removeAfter",
	"Comment": "removes all period holders after the given period holder. this process may also remove thecurrently reading period holder. if that is the case, the reading period holder is set to bethe same as the playing period holder at the front of the queue.",
	"Method": "boolean removeAfter(MediaPeriodHolder mediaPeriodHolder){\r\n    Assertions.checkState(mediaPeriodHolder != null);\r\n    boolean removedReading = false;\r\n    loading = mediaPeriodHolder;\r\n    while (mediaPeriodHolder.next != null) {\r\n        mediaPeriodHolder = mediaPeriodHolder.next;\r\n        if (mediaPeriodHolder == reading) {\r\n            reading = playing;\r\n            removedReading = true;\r\n        }\r\n        mediaPeriodHolder.release();\r\n        length--;\r\n    }\r\n    loading.next = null;\r\n    return removedReading;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authz.permission.FieldPermissionsCache.getFieldPermissions",
	"Comment": "returns a field permissions object that corresponds to the merging of the given field permissions and caches the instance if one wasnot found in the cache.",
	"Method": "FieldPermissions getFieldPermissions(String[] granted,String[] denied,FieldPermissions getFieldPermissions,FieldPermissionsDefinition fieldPermissionsDefinition,FieldPermissions getFieldPermissions,Collection<FieldPermissions> fieldPermissionsCollection){\r\n    Optional<FieldPermissions> allowAllFieldPermissions = fieldPermissionsCollection.stream().filter(((Predicate<FieldPermissions>) (FieldPermissions::hasFieldLevelSecurity)).negate()).findFirst();\r\n    return allowAllFieldPermissions.orElseGet(() -> {\r\n        final Set<FieldGrantExcludeGroup> fieldGrantExcludeGroups = fieldPermissionsCollection.stream().flatMap(fieldPermission -> fieldPermission.getFieldPermissionsDefinition().getFieldGrantExcludeGroups().stream()).collect(Collectors.toSet());\r\n        final FieldPermissionsDefinition combined = new FieldPermissionsDefinition(fieldGrantExcludeGroups);\r\n        try {\r\n            return cache.computeIfAbsent(combined, (key) -> {\r\n                List<Automaton> automatonList = fieldPermissionsCollection.stream().map(FieldPermissions::getIncludeAutomaton).collect(Collectors.toList());\r\n                return new FieldPermissions(key, Automatons.unionAndMinimize(automatonList));\r\n            });\r\n        } catch (ExecutionException e) {\r\n            throw new ElasticsearchException(\"unable to compute field permissions\", e);\r\n        }\r\n    });\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleMetadataQueue.attemptSplice",
	"Comment": "attempts to discard samples from the end of the queue to allow samples starting from thespecified timestamp to be spliced in. samples will not be discarded prior to the read position.",
	"Method": "boolean attemptSplice(long timeUs){\r\n    if (length == 0) {\r\n        return timeUs > largestDiscardedTimestampUs;\r\n    }\r\n    long largestReadTimestampUs = Math.max(largestDiscardedTimestampUs, getLargestTimestamp(readPosition));\r\n    if (largestReadTimestampUs >= timeUs) {\r\n        return false;\r\n    }\r\n    int retainCount = length;\r\n    int relativeSampleIndex = getRelativeIndex(length - 1);\r\n    while (retainCount > readPosition && timesUs[relativeSampleIndex] >= timeUs) {\r\n        retainCount--;\r\n        relativeSampleIndex--;\r\n        if (relativeSampleIndex == -1) {\r\n            relativeSampleIndex = capacity - 1;\r\n        }\r\n    }\r\n    discardUpstreamSamples(absoluteFirstIndex + retainCount);\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.audit.index.IndexAuditTrail.peek",
	"Comment": "for testing to ensure we get the proper timestamp and index name...",
	"Method": "Message peek(Message peek){\r\n    return queueConsumer.peek();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherIndexingListenerTests.testShardConfigurationShouldBeTriggeredExactlyOnce",
	"Comment": "no matter how many copies of a shard exist, a watch should always be triggered exactly once",
	"Method": "void testShardConfigurationShouldBeTriggeredExactlyOnce(){\r\n    int numberOfShards = randomIntBetween(1, 20);\r\n    int numberOfDocuments = randomIntBetween(1, 10000);\r\n    BitSet bitSet = new BitSet(numberOfDocuments);\r\n    logger.info(\"Testing [{}] documents with [{}] shards\", numberOfDocuments, numberOfShards);\r\n    for (int currentShardId = 0; currentShardId < numberOfShards; currentShardId++) {\r\n        ShardAllocationConfiguration sac = new ShardAllocationConfiguration(currentShardId, numberOfShards, Collections.emptyList());\r\n        for (int i = 0; i < numberOfDocuments; i++) {\r\n            boolean shouldBeTriggered = sac.shouldBeTriggered(\"watch_\" + i);\r\n            boolean hasAlreadyBeenTriggered = bitSet.get(i);\r\n            if (shouldBeTriggered) {\r\n                String message = String.format(Locale.ROOT, \"Watch [%s] has already been \" + \"triggered\", i);\r\n                assertThat(message, hasAlreadyBeenTriggered, is(false));\r\n                bitSet.set(i);\r\n            }\r\n        }\r\n    }\r\n    assertThat(bitSet.cardinality(), is(numberOfDocuments));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authz.store.NativeRolesStore.getRoleDescriptors",
	"Comment": "retrieve a list of roles, if rolestoget is null or empty, fetch all roles",
	"Method": "void getRoleDescriptors(Set<String> names,ActionListener<RoleRetrievalResult> listener){\r\n    if (securityIndex.indexExists() == false) {\r\n        listener.onResponse(RoleRetrievalResult.success(Collections.emptySet()));\r\n    } else if (names == null || names.isEmpty()) {\r\n        securityIndex.checkIndexVersionThenExecute(listener::onFailure, () -> {\r\n            QueryBuilder query = QueryBuilders.termQuery(RoleDescriptor.Fields.TYPE.getPreferredName(), ROLE_TYPE);\r\n            final Supplier<ThreadContext.StoredContext> supplier = client.threadPool().getThreadContext().newRestorableContext(false);\r\n            try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN)) {\r\n                SearchRequest request = client.prepareSearch(SecurityIndexManager.SECURITY_INDEX_NAME).setScroll(DEFAULT_KEEPALIVE_SETTING.get(settings)).setQuery(query).setSize(1000).setFetchSource(true).request();\r\n                request.indicesOptions().ignoreUnavailable();\r\n                ScrollHelper.fetchAllByEntity(client, request, new ContextPreservingActionListener(supplier, ActionListener.wrap(roles -> listener.onResponse(RoleRetrievalResult.success(new HashSet(roles))), e -> listener.onResponse(RoleRetrievalResult.failure(e)))), (hit) -> transformRole(hit.getId(), hit.getSourceRef(), logger, licenseState));\r\n            }\r\n        });\r\n    } else if (names.size() == 1) {\r\n        getRoleDescriptor(Objects.requireNonNull(names.iterator().next()), listener);\r\n    } else {\r\n        securityIndex.checkIndexVersionThenExecute(listener::onFailure, () -> {\r\n            final String[] roleIds = names.stream().map(NativeRolesStore::getIdForRole).toArray(String[]::new);\r\n            MultiGetRequest multiGetRequest = client.prepareMultiGet().add(SECURITY_INDEX_NAME, ROLE_DOC_TYPE, roleIds).request();\r\n            executeAsyncWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN, multiGetRequest, ActionListener.<MultiGetResponse>wrap(mGetResponse -> {\r\n                final MultiGetItemResponse[] responses = mGetResponse.getResponses();\r\n                Set<RoleDescriptor> descriptors = new HashSet();\r\n                for (int i = 0; i < responses.length; i++) {\r\n                    MultiGetItemResponse item = responses[i];\r\n                    if (item.isFailed()) {\r\n                        final Exception failure = item.getFailure().getFailure();\r\n                        for (int j = i + 1; j < responses.length; j++) {\r\n                            item = responses[j];\r\n                            if (item.isFailed()) {\r\n                                failure.addSuppressed(failure);\r\n                            }\r\n                        }\r\n                        listener.onResponse(RoleRetrievalResult.failure(failure));\r\n                        return;\r\n                    } else if (item.getResponse().isExists()) {\r\n                        descriptors.add(transformRole(item.getResponse()));\r\n                    }\r\n                }\r\n                listener.onResponse(RoleRetrievalResult.success(descriptors));\r\n            }, e -> listener.onResponse(RoleRetrievalResult.failure(e))), client::multiGet);\r\n        });\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.actions.index.ExecutableIndexAction.getField",
	"Comment": "extracts the specified field out of data map, or alternative falls back to the action value",
	"Method": "String getField(String actionId,String watchId,String name,Map<String, Object> data,String fieldName,String defaultValue){\r\n    Object obj = data.remove(fieldName);\r\n    if (obj != null) {\r\n        if (defaultValue != null) {\r\n            throw illegalState(\"could not execute action [{}] of watch [{}]. \" + \"[ctx.payload.{}] or [ctx.payload._doc.{}] were set together with action [{}] field. Only set one of them\", actionId, watchId, fieldName, fieldName, name);\r\n        } else {\r\n            return obj.toString();\r\n        }\r\n    }\r\n    return defaultValue;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.support.FileAttributesChecker.check",
	"Comment": "check if attributes of the paths have changed, warning to the given terminal if they have.",
	"Method": "void check(Terminal terminal){\r\n    for (int i = 0; i < paths.length; ++i) {\r\n        if (attributes[i] == null) {\r\n            continue;\r\n        }\r\n        PosixFileAttributeView view = Files.getFileAttributeView(paths[i], PosixFileAttributeView.class);\r\n        PosixFileAttributes newAttributes = view.readAttributes();\r\n        PosixFileAttributes oldAttributes = attributes[i];\r\n        if (oldAttributes.permissions().equals(newAttributes.permissions()) == false) {\r\n            terminal.println(Terminal.Verbosity.SILENT, \"WARNING: The file permissions of [\" + paths[i] + \"] have changed \" + \"from [\" + PosixFilePermissions.toString(oldAttributes.permissions()) + \"] \" + \"to [\" + PosixFilePermissions.toString(newAttributes.permissions()) + \"]\");\r\n            terminal.println(Terminal.Verbosity.SILENT, \"Please ensure that the user account running Elasticsearch has read access to this file!\");\r\n        }\r\n        if (oldAttributes.owner().getName().equals(newAttributes.owner().getName()) == false) {\r\n            terminal.println(Terminal.Verbosity.SILENT, \"WARNING: Owner of file [\" + paths[i] + \"] \" + \"used to be [\" + oldAttributes.owner().getName() + \"], \" + \"but now is [\" + newAttributes.owner().getName() + \"]\");\r\n        }\r\n        if (oldAttributes.group().getName().equals(newAttributes.group().getName()) == false) {\r\n            terminal.println(Terminal.Verbosity.SILENT, \"WARNING: Group of file [\" + paths[i] + \"] \" + \"used to be [\" + oldAttributes.group().getName() + \"], \" + \"but now is [\" + newAttributes.group().getName() + \"]\");\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.Label.addReference",
	"Comment": "adds a forward reference to this label. this method must be called only for a true forward reference, i.e. onlyif this label is not resolved yet. for backward references, the offset of the reference can be, and must be,computed and stored directly.",
	"Method": "void addReference(int sourcePosition,int referencePosition){\r\n    if (srcAndRefPositions == null) {\r\n        srcAndRefPositions = new int[6];\r\n    }\r\n    if (referenceCount >= srcAndRefPositions.length) {\r\n        int[] a = new int[srcAndRefPositions.length + 6];\r\n        System.arraycopy(srcAndRefPositions, 0, a, 0, srcAndRefPositions.length);\r\n        srcAndRefPositions = a;\r\n    }\r\n    srcAndRefPositions[referenceCount++] = sourcePosition;\r\n    srcAndRefPositions[referenceCount++] = referencePosition;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableBitArray.byteAlign",
	"Comment": "aligns the position to the next byte boundary. does nothing if the position is already aligned.",
	"Method": "void byteAlign(){\r\n    if (bitOffset == 0) {\r\n        return;\r\n    }\r\n    bitOffset = 0;\r\n    byteOffset++;\r\n    assertValidOffset();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.FakeMediaSource.setNewSourceInfo",
	"Comment": "sets a new timeline and manifest. if the source is already prepared, this triggers a sourceinfo refresh message being sent to the listener.",
	"Method": "void setNewSourceInfo(Timeline newTimeline,Object newManifest){\r\n    if (sourceInfoRefreshHandler != null) {\r\n        sourceInfoRefreshHandler.post(() -> {\r\n            assertThat(releasedSource).isFalse();\r\n            assertThat(preparedSource).isTrue();\r\n            timeline = newTimeline;\r\n            manifest = newManifest;\r\n            finishSourcePreparation();\r\n        });\r\n    } else {\r\n        timeline = newTimeline;\r\n        manifest = newManifest;\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.crypto.AesFlushingCipherTest.testMidJoin",
	"Comment": "test decryption starting from the middle of an encrypted block.",
	"Method": "void testMidJoin(){\r\n    byte[] reference = TestUtil.buildTestData(DATA_LENGTH);\r\n    byte[] data = reference.clone();\r\n    Random random = new Random(RANDOM_SEED);\r\n    int offset = 0;\r\n    while (offset < data.length) {\r\n        int bytes = 1 + random.nextInt(4095);\r\n        bytes = Math.min(bytes, data.length - offset);\r\n        encryptCipher.updateInPlace(data, offset, bytes);\r\n        offset += bytes;\r\n    }\r\n    int unchangedByteCount = data.length - getDifferingByteCount(reference, data);\r\n    assertThat(unchangedByteCount <= getMaxUnchangedBytesAllowedPostEncryption(data.length)).isTrue();\r\n    offset = random.nextInt(4096);\r\n    decryptCipher = new AesFlushingCipher(Cipher.DECRYPT_MODE, KEY, NONCE, offset + START_OFFSET);\r\n    int remainingLength = data.length - offset;\r\n    int originalOffset = offset;\r\n    while (remainingLength > 0) {\r\n        int bytes = 1 + random.nextInt(4095);\r\n        bytes = Math.min(bytes, remainingLength);\r\n        decryptCipher.updateInPlace(data, offset, bytes);\r\n        offset += bytes;\r\n        remainingLength -= bytes;\r\n    }\r\n    int differingByteCount = getDifferingByteCount(reference, data, originalOffset);\r\n    assertThat(differingByteCount).isEqualTo(0);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.Util.subtractWithOverflowDefault",
	"Comment": "returns the difference between two arguments, or a third argument if the result overflows.",
	"Method": "long subtractWithOverflowDefault(long x,long y,long overflowResult){\r\n    long result = x - y;\r\n    if (((x ^ y) & (x ^ result)) < 0) {\r\n        return overflowResult;\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerView.maybeShowController",
	"Comment": "shows the playback controls, but only if forced or shown indefinitely.",
	"Method": "void maybeShowController(boolean isForced){\r\n    if (isPlayingAd() && controllerHideDuringAds) {\r\n        return;\r\n    }\r\n    if (useController) {\r\n        boolean wasShowingIndefinitely = controller.isVisible() && controller.getShowTimeoutMs() <= 0;\r\n        boolean shouldShowIndefinitely = shouldShowControllerIndefinitely();\r\n        if (isForced || wasShowingIndefinitely || shouldShowIndefinitely) {\r\n            showController(shouldShowIndefinitely);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.ChunkIndex.getChunkIndex",
	"Comment": "obtains the index of the chunk corresponding to a given time.",
	"Method": "int getChunkIndex(long timeUs){\r\n    return Util.binarySearchFloor(timesUs, timeUs, true, true);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    AtomicBoolean isFinished = new AtomicBoolean(false);\r\n    RollupJob job = new RollupJob(ConfigTestHelpers.randomRollupJobConfig(random()), Collections.emptyMap());\r\n    AtomicReference<IndexerState> state = new AtomicReference(IndexerState.STOPPED);\r\n    Function<SearchRequest, SearchResponse> searchFunction = searchRequest -> {\r\n        Aggregations aggs = new Aggregations(Collections.singletonList(new CompositeAggregation() {\r\n            @Override\r\n            public List<? extends Bucket> getBuckets() {\r\n                Bucket b = new Bucket() {\r\n                    @Override\r\n                    public Map<String, Object> getKey() {\r\n                        state.set(IndexerState.STOPPING);\r\n                        return Collections.singletonMap(\"foo\", \"bar\");\r\n                    }\r\n                    @Override\r\n                    public String getKeyAsString() {\r\n                        return null;\r\n                    }\r\n                    @Override\r\n                    public long getDocCount() {\r\n                        return 1;\r\n                    }\r\n                    @Override\r\n                    public Aggregations getAggregations() {\r\n                        return new InternalAggregations(Collections.emptyList());\r\n                    }\r\n                    @Override\r\n                    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\r\n                        return null;\r\n                    }\r\n                };\r\n                return Collections.singletonList(b);\r\n            }\r\n            @Override\r\n            public Map<String, Object> afterKey() {\r\n                return null;\r\n            }\r\n            @Override\r\n            public String getName() {\r\n                return RollupField.NAME;\r\n            }\r\n            @Override\r\n            public String getType() {\r\n                return null;\r\n            }\r\n            @Override\r\n            public Map<String, Object> getMetaData() {\r\n                return null;\r\n            }\r\n            @Override\r\n            public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\r\n                return null;\r\n            }\r\n        }));\r\n        final SearchResponseSections sections = new SearchResponseSections(new SearchHits(new SearchHit[0], 0, 0), aggs, null, false, null, null, 1);\r\n        return new SearchResponse(sections, null, 1, 1, 0, 0, ShardSearchFailure.EMPTY_ARRAY, null);\r\n    };\r\n    Function<BulkRequest, BulkResponse> bulkFunction = bulkRequest -> new BulkResponse(new BulkItemResponse[0], 100);\r\n    Consumer<Exception> failureConsumer = e -> {\r\n        assertThat(e.getMessage(), equalTo(\"Could not identify key in agg [foo]\"));\r\n        isFinished.set(true);\r\n    };\r\n    final ExecutorService executor = Executors.newFixedThreadPool(1);\r\n    try {\r\n        NonEmptyRollupIndexer indexer = new NonEmptyRollupIndexer(executor, job, state, null, searchFunction, bulkFunction, failureConsumer);\r\n        final CountDownLatch latch = indexer.newLatch(1);\r\n        indexer.start();\r\n        assertThat(indexer.getState(), equalTo(IndexerState.STARTED));\r\n        assertTrue(indexer.maybeTriggerAsyncJob(System.currentTimeMillis()));\r\n        assertThat(indexer.getState(), equalTo(IndexerState.INDEXING));\r\n        latch.countDown();\r\n        ESTestCase.awaitBusy(() -> isFinished.get());\r\n        assertThat(indexer.getState(), equalTo(IndexerState.STOPPED));\r\n        assertThat(indexer.getStats().getNumInvocations(), equalTo(1L));\r\n        assertThat(indexer.getStats().getNumPages(), equalTo(1L));\r\n        assertThat(indexer.getStats().getSearchFailures(), equalTo(1L));\r\n        assertThat(indexer.getStats().getOutputDocuments(), equalTo(0L));\r\n        assertTrue(indexer.abort());\r\n    } finally {\r\n        executor.shutdownNow();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    Bucket b = new Bucket() {\r\n        @Override\r\n        public Map<String, Object> getKey() {\r\n            state.set(IndexerState.STOPPING);\r\n            return Collections.singletonMap(\"foo\", \"bar\");\r\n        }\r\n        @Override\r\n        public String getKeyAsString() {\r\n            return null;\r\n        }\r\n        @Override\r\n        public long getDocCount() {\r\n            return 1;\r\n        }\r\n        @Override\r\n        public Aggregations getAggregations() {\r\n            return new InternalAggregations(Collections.emptyList());\r\n        }\r\n        @Override\r\n        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\r\n            return null;\r\n        }\r\n    };\r\n    return Collections.singletonList(b);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    state.set(IndexerState.STOPPING);\r\n    return Collections.singletonMap(\"foo\", \"bar\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    return 1;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    return new InternalAggregations(Collections.emptyList());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    return RollupField.NAME;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupIndexerStateTests.testFailureWhileStopping",
	"Comment": "tests to make sure that errors in search do not interfere with shutdown procedure",
	"Method": "void testFailureWhileStopping(){\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.collector.Collector.getCollectionIndices",
	"Comment": "returns the names of indices monitoring collects data from.",
	"Method": "String[] getCollectionIndices(){\r\n    final List<String> indices = clusterService.getClusterSettings().get(INDICES);\r\n    assert indices != null;\r\n    if (indices.isEmpty()) {\r\n        return Strings.EMPTY_ARRAY;\r\n    } else {\r\n        return indices.toArray(new String[indices.size()]);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.analytics.AnalyticsCollector.resetForNewMediaSource",
	"Comment": "resets the analytics collector for a new media source. should be called before the player isprepared with a new media source.",
	"Method": "void resetForNewMediaSource(){\r\n    List<MediaPeriodInfo> mediaPeriodInfos = new ArrayList(mediaPeriodQueueTracker.mediaPeriodInfoQueue);\r\n    for (MediaPeriodInfo mediaPeriodInfo : mediaPeriodInfos) {\r\n        onMediaPeriodReleased(mediaPeriodInfo.windowIndex, mediaPeriodInfo.mediaPeriodId);\r\n    }\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ClassWriter.newMethodItem",
	"Comment": "adds a method reference to the constant pool of the class being build. does nothing if the constant pool alreadycontains a similar item.",
	"Method": "Item newMethodItem(String owner,String name,String desc,boolean itf){\r\n    int type = itf ? 11 : 10;\r\n    key3.set(type, owner, name, desc);\r\n    Item result = get(key3);\r\n    if (result == null) {\r\n        int s1 = newClassItem(owner).index, s2 = newNameTypeItem(name, desc).index;\r\n        pool.put12(type, s1).putShort(s2);\r\n        result = new Item(index++, key3);\r\n        put(result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.process.ProcessPipes.addArgs",
	"Comment": "augments a list of command line arguments, for example that built up by the autodetectbuilder class.",
	"Method": "void addArgs(List<String> command){\r\n    if (logPipeName != null) {\r\n        command.add(LOG_PIPE_ARG + logPipeName);\r\n    }\r\n    if (commandPipeName != null) {\r\n        command.add(COMMAND_PIPE_ARG + commandPipeName);\r\n    }\r\n    if (processInPipeName != null) {\r\n        command.add(INPUT_ARG + processInPipeName);\r\n        command.add(INPUT_IS_PIPE_ARG);\r\n    }\r\n    if (processOutPipeName != null) {\r\n        command.add(OUTPUT_ARG + processOutPipeName);\r\n        command.add(OUTPUT_IS_PIPE_ARG);\r\n    }\r\n    if (restorePipeName != null) {\r\n        command.add(RESTORE_ARG + restorePipeName);\r\n        command.add(RESTORE_IS_PIPE_ARG);\r\n    }\r\n    if (persistPipeName != null) {\r\n        command.add(PERSIST_ARG + persistPipeName);\r\n        command.add(PERSIST_IS_PIPE_ARG);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.decoder.Buffer.getFlag",
	"Comment": "returns whether the specified flag has been set on this buffer.",
	"Method": "boolean getFlag(int flag){\r\n    return (flags & flag) == flag;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.wav.WavHeader.getTimeUs",
	"Comment": "returns the time in microseconds for the given position in bytes.",
	"Method": "long getTimeUs(long position){\r\n    long positionOffset = Math.max(0, position - dataStartPosition);\r\n    return (positionOffset * C.MICROS_PER_SECOND) / averageBytesPerSecond;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.support.LdapUtils.followReferral",
	"Comment": "performs the actual connection and following of a referral given a url string.this referral is being followed as it may contain a result that is relevant to our search",
	"Method": "void followReferral(LDAPConnection ldapConnection,String urlString,SearchRequest searchRequest,ActionListener<SearchResult> listener,int depth,boolean ignoreErrors,SearchResult originatingResult){\r\n    final LDAPURL referralURL = new LDAPURL(urlString);\r\n    final String host = referralURL.getHost();\r\n    if (host == null) {\r\n        throw new LDAPException(ResultCode.UNAVAILABLE, \"Null referral host in \" + urlString);\r\n    }\r\n    final String requestBaseDN;\r\n    if (referralURL.baseDNProvided()) {\r\n        requestBaseDN = referralURL.getBaseDN().toString();\r\n    } else {\r\n        requestBaseDN = searchRequest.getBaseDN();\r\n    }\r\n    final SearchScope requestScope;\r\n    if (referralURL.scopeProvided()) {\r\n        requestScope = referralURL.getScope();\r\n    } else {\r\n        requestScope = searchRequest.getScope();\r\n    }\r\n    final Filter requestFilter;\r\n    if (referralURL.filterProvided()) {\r\n        requestFilter = referralURL.getFilter();\r\n    } else {\r\n        requestFilter = searchRequest.getFilter();\r\n    }\r\n    final LDAPConnection referralConn = privilegedConnect(() -> ldapConnection.getReferralConnector().getReferralConnection(referralURL, ldapConnection));\r\n    final LdapSearchResultListener ldapListener = new LdapSearchResultListener(referralConn, ignoreErrors, ActionListener.wrap(searchResult -> {\r\n        IOUtils.close(referralConn);\r\n        listener.onResponse(searchResult);\r\n    }, e -> {\r\n        IOUtils.closeWhileHandlingException(referralConn);\r\n        if (ignoreErrors) {\r\n            if (LOGGER.isDebugEnabled()) {\r\n                LOGGER.debug(new ParameterizedMessage(\"Failed to retrieve results from referral URL [{}].\" + \" Treating as 'no results'\", referralURL), e);\r\n            }\r\n            listener.onResponse(emptyResult(originatingResult));\r\n        } else {\r\n            listener.onFailure(e);\r\n        }\r\n    }), depth);\r\n    boolean success = false;\r\n    try {\r\n        final SearchRequest referralSearchRequest = new SearchRequest(ldapListener, searchRequest.getControls(), requestBaseDN, requestScope, searchRequest.getDereferencePolicy(), searchRequest.getSizeLimit(), searchRequest.getTimeLimitSeconds(), searchRequest.typesOnly(), requestFilter, searchRequest.getAttributes());\r\n        ldapListener.setSearchRequest(searchRequest);\r\n        referralConn.asyncSearch(referralSearchRequest);\r\n        success = true;\r\n    } finally {\r\n        if (success == false) {\r\n            IOUtils.closeWhileHandlingException(referralConn);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.audit.index.IndexAuditTrail.remoteTransportClientPlugins",
	"Comment": "method for testing to allow different plugins such as mock transport...",
	"Method": "List<Class<? extends Plugin>> remoteTransportClientPlugins(){\r\n    return Arrays.asList(XPackClientPlugin.class);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecUtil.getDecoderInfo",
	"Comment": "returns information about the preferred decoder for a given mime type.",
	"Method": "MediaCodecInfo getDecoderInfo(String mimeType,boolean secure){\r\n    List<MediaCodecInfo> decoderInfos = getDecoderInfos(mimeType, secure);\r\n    return decoderInfos.isEmpty() ? null : decoderInfos.get(0);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupJobTask.shutdown",
	"Comment": "attempt to gracefully cleanup the rollup job so it can be terminated.this tries to remove the job from the scheduler, and potentially any othercleanup operations in the future",
	"Method": "void shutdown(){\r\n    try {\r\n        logger.info(\"Rollup indexer [\" + job.getConfig().getId() + \"] received abort request, stopping indexer.\");\r\n        schedulerEngine.remove(SCHEDULE_NAME + \"_\" + job.getConfig().getId());\r\n        schedulerEngine.unregister(this);\r\n    } catch (Exception e) {\r\n        markAsFailed(e);\r\n        return;\r\n    }\r\n    markAsCompleted();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.spherical.FrameRotationQueue.reset",
	"Comment": "removes all of the rotations and forces rotations to be recentered.",
	"Method": "void reset(){\r\n    rotations.clear();\r\n    recenterMatrixComputed = false;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.exporter.Exporters.export",
	"Comment": "exports a collection of monitoring documents using the configured exporters",
	"Method": "void export(Collection<MonitoringDoc> docs,ActionListener<Void> listener){\r\n    if (this.lifecycleState() != Lifecycle.State.STARTED) {\r\n        listener.onFailure(new ExportException(\"Export service is not started\"));\r\n    } else if (docs != null && docs.size() > 0) {\r\n        wrapExportBulk(ActionListener.wrap(bulk -> {\r\n            if (bulk != null) {\r\n                doExport(bulk, docs, listener);\r\n            } else {\r\n                listener.onResponse(null);\r\n            }\r\n        }, listener::onFailure));\r\n    } else {\r\n        listener.onResponse(null);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.qa.jdbc.LocalH2.anonymousDb",
	"Comment": "creates an in memory anonymous database and returns the only connection to it.closing the connection will remove the db.",
	"Method": "Connection anonymousDb(){\r\n    return DriverManager.getConnection(memUrl(null));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ConditionVariable.open",
	"Comment": "opens the condition and releases all threads that are blocked.",
	"Method": "boolean open(){\r\n    if (isOpen) {\r\n        return false;\r\n    }\r\n    isOpen = true;\r\n    notifyAll();\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.common.http.HttpClient.setProxy",
	"Comment": "enriches the config object optionally with proxy information",
	"Method": "void setProxy(RequestConfig.Builder config,HttpRequest request,HttpProxy configuredProxy){\r\n    if (request.proxy != null && request.proxy.equals(HttpProxy.NO_PROXY) == false) {\r\n        String scheme = request.proxy.getScheme() != null ? request.proxy.getScheme().scheme() : Scheme.HTTP.scheme();\r\n        HttpHost proxy = new HttpHost(request.proxy.getHost(), request.proxy.getPort(), scheme);\r\n        config.setProxy(proxy);\r\n    } else if (HttpProxy.NO_PROXY.equals(configuredProxy) == false) {\r\n        HttpHost proxy = new HttpHost(configuredProxy.getHost(), configuredProxy.getPort(), configuredProxy.getScheme().scheme());\r\n        config.setProxy(proxy);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.GrokPatternCreator.getOverallGrokPatternBuilder",
	"Comment": "this is purely to allow unit tests to inspect the partial grok pattern after testing implementation details.it should not be used in production code.",
	"Method": "StringBuilder getOverallGrokPatternBuilder(){\r\n    return overallGrokPatternBuilder;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authz.permission.IndicesPermission.authorize",
	"Comment": "authorizes the provided action against the provided indices, given the current cluster metadata",
	"Method": "Map<String, IndicesAccessControl.IndexAccessControl> authorize(String action,Set<String> requestedIndicesOrAliases,MetaData metaData,FieldPermissionsCache fieldPermissionsCache){\r\n    SortedMap<String, AliasOrIndex> allAliasesAndIndices = metaData.getAliasAndIndexLookup();\r\n    Map<String, Set<FieldPermissions>> fieldPermissionsByIndex = new HashMap();\r\n    Map<String, DocumentLevelPermissions> roleQueriesByIndex = new HashMap();\r\n    Map<String, Boolean> grantedBuilder = new HashMap();\r\n    for (String indexOrAlias : requestedIndicesOrAliases) {\r\n        boolean granted = false;\r\n        Set<String> concreteIndices = new HashSet();\r\n        AliasOrIndex aliasOrIndex = allAliasesAndIndices.get(indexOrAlias);\r\n        if (aliasOrIndex != null) {\r\n            for (IndexMetaData indexMetaData : aliasOrIndex.getIndices()) {\r\n                concreteIndices.add(indexMetaData.getIndex().getName());\r\n            }\r\n        }\r\n        for (Group group : groups) {\r\n            if (group.check(action, indexOrAlias)) {\r\n                granted = true;\r\n                for (String index : concreteIndices) {\r\n                    Set<FieldPermissions> fieldPermissions = fieldPermissionsByIndex.computeIfAbsent(index, (k) -> new HashSet());\r\n                    fieldPermissionsByIndex.put(indexOrAlias, fieldPermissions);\r\n                    fieldPermissions.add(group.getFieldPermissions());\r\n                    DocumentLevelPermissions permissions = roleQueriesByIndex.computeIfAbsent(index, (k) -> new DocumentLevelPermissions());\r\n                    roleQueriesByIndex.putIfAbsent(indexOrAlias, permissions);\r\n                    if (group.hasQuery()) {\r\n                        permissions.addAll(group.getQuery());\r\n                    } else {\r\n                        permissions.setAllowAll(true);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        if (concreteIndices.isEmpty()) {\r\n            grantedBuilder.put(indexOrAlias, granted);\r\n        } else {\r\n            grantedBuilder.put(indexOrAlias, granted);\r\n            for (String concreteIndex : concreteIndices) {\r\n                grantedBuilder.put(concreteIndex, granted);\r\n            }\r\n        }\r\n    }\r\n    Map<String, IndicesAccessControl.IndexAccessControl> indexPermissions = new HashMap();\r\n    for (Map.Entry<String, Boolean> entry : grantedBuilder.entrySet()) {\r\n        String index = entry.getKey();\r\n        DocumentLevelPermissions permissions = roleQueriesByIndex.get(index);\r\n        final Set<BytesReference> roleQueries;\r\n        if (permissions != null && permissions.isAllowAll() == false) {\r\n            roleQueries = unmodifiableSet(permissions.queries);\r\n        } else {\r\n            roleQueries = null;\r\n        }\r\n        final FieldPermissions fieldPermissions;\r\n        final Set<FieldPermissions> indexFieldPermissions = fieldPermissionsByIndex.get(index);\r\n        if (indexFieldPermissions != null && indexFieldPermissions.isEmpty() == false) {\r\n            fieldPermissions = indexFieldPermissions.size() == 1 ? indexFieldPermissions.iterator().next() : fieldPermissionsCache.getFieldPermissions(indexFieldPermissions);\r\n        } else {\r\n            fieldPermissions = FieldPermissions.DEFAULT;\r\n        }\r\n        indexPermissions.put(index, new IndicesAccessControl.IndexAccessControl(entry.getValue(), fieldPermissions, roleQueries));\r\n    }\r\n    return unmodifiableMap(indexPermissions);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.diagnostics.DataStreamDiagnosticsTests.testSparseBucketsLongerPeriod",
	"Comment": "send signals, make a longer period of sparse signals, then go up againthe number of sparse buckets should not be to much, it could be normal.",
	"Method": "void testSparseBucketsLongerPeriod(){\r\n    DataStreamDiagnostics d = new DataStreamDiagnostics(job, dataCounts);\r\n    sendManyDataPoints(d, 10000, 69000, 1000);\r\n    sendManyDataPoints(d, 70000, 129000, 1200);\r\n    sendManyDataPoints(d, 130000, 189000, 1);\r\n    sendManyDataPoints(d, 190000, 249000, 1100);\r\n    sendManyDataPoints(d, 250000, 309000, 1300);\r\n    sendManyDataPoints(d, 310000, 369000, 1050);\r\n    sendManyDataPoints(d, 370000, 429000, 1022);\r\n    sendManyDataPoints(d, 430000, 489000, 10);\r\n    sendManyDataPoints(d, 490000, 549000, 1333);\r\n    sendManyDataPoints(d, 550000, 609000, 1400);\r\n    d.flush();\r\n    assertEquals(9, d.getBucketCount());\r\n    assertEquals(0, d.getEmptyBucketCount());\r\n    assertEquals(2, d.getSparseBucketCount());\r\n    assertEquals(new Date(420000), d.getLatestSparseBucketTime());\r\n    assertEquals(null, d.getLatestEmptyBucketTime());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.TrackSelectionView.setShowDisableOption",
	"Comment": "sets whether an option is available for disabling the renderer.",
	"Method": "void setShowDisableOption(boolean showDisableOption){\r\n    disableView.setVisibility(showDisableOption ? View.VISIBLE : View.GONE);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.process.NativeStorageProvider.cleanupLocalTmpStorageInCaseOfUncleanShutdown",
	"Comment": "removes any temporary storage leftovers.removes all temp files and folder which might be there as a result of anunclean node shutdown or broken clients.do not call while there are running jobs.",
	"Method": "void cleanupLocalTmpStorageInCaseOfUncleanShutdown(){\r\n    for (Path p : environment.dataFiles()) {\r\n        IOUtils.rm(p.resolve(LOCAL_STORAGE_SUBFOLDER).resolve(LOCAL_STORAGE_TMP_FOLDER));\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.chunk.BaseMediaChunkOutput.getWriteIndices",
	"Comment": "returns the current absolute write indices of the individual sample queues.",
	"Method": "int[] getWriteIndices(){\r\n    int[] writeIndices = new int[sampleQueues.length];\r\n    for (int i = 0; i < sampleQueues.length; i++) {\r\n        if (sampleQueues[i] != null) {\r\n            writeIndices[i] = sampleQueues[i].getWriteIndex();\r\n        }\r\n    }\r\n    return writeIndices;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLService.createDynamicSSLService",
	"Comment": "creates a new sslservice that supports dynamic creation of sslcontext instances. instances created by this service will not becached and will not be monitored for reloading. this dynamic server does have access to the cached and monitored instances thathave been created during initialization",
	"Method": "SSLService createDynamicSSLService(){\r\n    return new SSLService(settings, env, globalSSLConfiguration, sslConfigurations, sslContexts) {\r\n        @Override\r\n        Map<SSLConfiguration, SSLContextHolder> loadSSLConfigurations() {\r\n            return Collections.emptyMap();\r\n        }\r\n        @Override\r\n        SSLContextHolder sslContextHolder(SSLConfiguration sslConfiguration) {\r\n            SSLContextHolder holder = sslContexts.get(sslConfiguration);\r\n            if (holder == null) {\r\n                holder = createSslContext(sslConfiguration);\r\n            }\r\n            return holder;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLService.createDynamicSSLService",
	"Comment": "creates a new sslservice that supports dynamic creation of sslcontext instances. instances created by this service will not becached and will not be monitored for reloading. this dynamic server does have access to the cached and monitored instances thathave been created during initialization",
	"Method": "SSLService createDynamicSSLService(){\r\n    return Collections.emptyMap();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLService.createDynamicSSLService",
	"Comment": "creates a new sslservice that supports dynamic creation of sslcontext instances. instances created by this service will not becached and will not be monitored for reloading. this dynamic server does have access to the cached and monitored instances thathave been created during initialization",
	"Method": "SSLService createDynamicSSLService(){\r\n    SSLContextHolder holder = sslContexts.get(sslConfiguration);\r\n    if (holder == null) {\r\n        holder = createSslContext(sslConfiguration);\r\n    }\r\n    return holder;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.util.DateUtils.of",
	"Comment": "parses the given string into a datetime using utc as a default timezone.",
	"Method": "ZonedDateTime of(long millis,ZonedDateTime of,long millis,ZoneId id,ZonedDateTime of,String dateFormat,ZonedDateTime of,DateTime dateTime){\r\n    LocalDateTime ldt = LocalDateTime.of(dateTime.getYear(), dateTime.getMonthOfYear(), dateTime.getDayOfMonth(), dateTime.getHourOfDay(), dateTime.getMinuteOfHour(), dateTime.getSecondOfMinute(), dateTime.getMillisOfSecond() * 1_000_000);\r\n    return ZonedDateTime.ofStrict(ldt, ZoneOffset.ofTotalSeconds(dateTime.getZone().getOffset(dateTime) / 1000), org.elasticsearch.common.time.DateUtils.dateTimeZoneToZoneId(dateTime.getZone()));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.DefaultTrackSelectorTest.testSelectTracksWithNullOverrideForDifferentTracks",
	"Comment": "tests that an override is not applied for a different set of available track groups.",
	"Method": "void testSelectTracksWithNullOverrideForDifferentTracks(){\r\n    DefaultTrackSelector trackSelector = new DefaultTrackSelector();\r\n    trackSelector.init(invalidationListener, bandwidthMeter);\r\n    trackSelector.setParameters(trackSelector.buildUponParameters().setSelectionOverride(0, new TrackGroupArray(VIDEO_TRACK_GROUP), null));\r\n    TrackSelectorResult result = trackSelector.selectTracks(RENDERER_CAPABILITIES, new TrackGroupArray(VIDEO_TRACK_GROUP, AUDIO_TRACK_GROUP, VIDEO_TRACK_GROUP));\r\n    assertTrackSelections(result, TRACK_SELECTIONS);\r\n    assertThat(result.rendererConfigurations).isEqualTo(new RendererConfiguration[] { DEFAULT, DEFAULT });\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.Util.getPcmEncoding",
	"Comment": "converts a sample bit depth to a corresponding pcm encoding constant.",
	"Method": "int getPcmEncoding(int bitDepth){\r\n    switch(bitDepth) {\r\n        case 8:\r\n            return C.ENCODING_PCM_8BIT;\r\n        case 16:\r\n            return C.ENCODING_PCM_16BIT;\r\n        case 24:\r\n            return C.ENCODING_PCM_24BIT;\r\n        case 32:\r\n            return C.ENCODING_PCM_32BIT;\r\n        default:\r\n            return C.ENCODING_INVALID;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.test.SecurityIntegTestCase.transportSSLEnabled",
	"Comment": "allows to control whether ssl key information is auto generated or not on the transport layer",
	"Method": "boolean transportSSLEnabled(){\r\n    return randomBoolean();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.Mp4Extractor.processMoovAtom",
	"Comment": "updates the stored track metadata to reflect the contents of the specified moov atom.",
	"Method": "void processMoovAtom(ContainerAtom moov){\r\n    int firstVideoTrackIndex = C.INDEX_UNSET;\r\n    long durationUs = C.TIME_UNSET;\r\n    List<Mp4Track> tracks = new ArrayList();\r\n    Metadata metadata = null;\r\n    GaplessInfoHolder gaplessInfoHolder = new GaplessInfoHolder();\r\n    Atom.LeafAtom udta = moov.getLeafAtomOfType(Atom.TYPE_udta);\r\n    if (udta != null) {\r\n        metadata = AtomParsers.parseUdta(udta, isQuickTime);\r\n        if (metadata != null) {\r\n            gaplessInfoHolder.setFromMetadata(metadata);\r\n        }\r\n    }\r\n    boolean ignoreEditLists = (flags & FLAG_WORKAROUND_IGNORE_EDIT_LISTS) != 0;\r\n    ArrayList<TrackSampleTable> trackSampleTables = getTrackSampleTables(moov, gaplessInfoHolder, ignoreEditLists);\r\n    int trackCount = trackSampleTables.size();\r\n    for (int i = 0; i < trackCount; i++) {\r\n        TrackSampleTable trackSampleTable = trackSampleTables.get(i);\r\n        Track track = trackSampleTable.track;\r\n        Mp4Track mp4Track = new Mp4Track(track, trackSampleTable, extractorOutput.track(i, track.type));\r\n        int maxInputSize = trackSampleTable.maximumSize + 3 * 10;\r\n        Format format = track.format.copyWithMaxInputSize(maxInputSize);\r\n        if (track.type == C.TRACK_TYPE_AUDIO) {\r\n            if (gaplessInfoHolder.hasGaplessInfo()) {\r\n                format = format.copyWithGaplessInfo(gaplessInfoHolder.encoderDelay, gaplessInfoHolder.encoderPadding);\r\n            }\r\n            if (metadata != null) {\r\n                format = format.copyWithMetadata(metadata);\r\n            }\r\n        }\r\n        mp4Track.trackOutput.format(format);\r\n        durationUs = Math.max(durationUs, track.durationUs != C.TIME_UNSET ? track.durationUs : trackSampleTable.durationUs);\r\n        if (track.type == C.TRACK_TYPE_VIDEO && firstVideoTrackIndex == C.INDEX_UNSET) {\r\n            firstVideoTrackIndex = tracks.size();\r\n        }\r\n        tracks.add(mp4Track);\r\n    }\r\n    this.firstVideoTrackIndex = firstVideoTrackIndex;\r\n    this.durationUs = durationUs;\r\n    this.tracks = tracks.toArray(new Mp4Track[tracks.size()]);\r\n    accumulatedSampleSizes = calculateAccumulatedSampleSizes(this.tracks);\r\n    extractorOutput.endTracks();\r\n    extractorOutput.seekMap(this);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authz.permission.RunAsPermission.check",
	"Comment": "checks if this permission grants run as to the specified user",
	"Method": "boolean check(String username){\r\n    return predicate.test(username);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateGenerateTool.generateAndWriteSignedCertificates",
	"Comment": "generates signed certificates in pem format stored in a zip file",
	"Method": "void generateAndWriteSignedCertificates(Path outputFile,Collection<CertificateInformation> certificateInformations,CAInfo caInfo,int keysize,int days,char[] pkcs12Password){\r\n    fullyWriteFile(outputFile, (outputStream, pemWriter) -> {\r\n        writeCAInfoIfGenerated(outputStream, pemWriter, caInfo);\r\n        for (CertificateInformation certificateInformation : certificateInformations) {\r\n            KeyPair keyPair = CertGenUtils.generateKeyPair(keysize);\r\n            Certificate certificate = CertGenUtils.generateSignedCertificate(certificateInformation.name.x500Principal, getSubjectAlternativeNamesValue(certificateInformation.ipAddresses, certificateInformation.dnsNames, certificateInformation.commonNames), keyPair, caInfo.caCert, caInfo.privateKey, days);\r\n            final String dirName = certificateInformation.name.filename + \"/\";\r\n            ZipEntry zipEntry = new ZipEntry(dirName);\r\n            assert zipEntry.isDirectory();\r\n            outputStream.putNextEntry(zipEntry);\r\n            final String entryBase = dirName + certificateInformation.name.filename;\r\n            outputStream.putNextEntry(new ZipEntry(entryBase + \".crt\"));\r\n            pemWriter.writeObject(certificate);\r\n            pemWriter.flush();\r\n            outputStream.closeEntry();\r\n            outputStream.putNextEntry(new ZipEntry(entryBase + \".key\"));\r\n            pemWriter.writeObject(keyPair.getPrivate());\r\n            pemWriter.flush();\r\n            outputStream.closeEntry();\r\n            if (pkcs12Password != null) {\r\n                final KeyStore pkcs12 = KeyStore.getInstance(\"PKCS12\");\r\n                pkcs12.load(null);\r\n                pkcs12.setKeyEntry(certificateInformation.name.originalName, keyPair.getPrivate(), pkcs12Password, new Certificate[] { certificate });\r\n                outputStream.putNextEntry(new ZipEntry(entryBase + \".p12\"));\r\n                pkcs12.store(outputStream, pkcs12Password);\r\n                outputStream.closeEntry();\r\n            }\r\n        }\r\n    });\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.dash.PlayerEmsgHandler.isPlayerEmsgEvent",
	"Comment": "returns whether an event with given schemeiduri and value is a dash emsg event targeting theplayer.",
	"Method": "boolean isPlayerEmsgEvent(String schemeIdUri,String value){\r\n    return \"urn:mpeg:dash:event:2012\".equals(schemeIdUri) && (\"1\".equals(value) || \"2\".equals(value) || \"3\".equals(value));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableBitArray.getBytePosition",
	"Comment": "returns the current byte offset. must only be called when the position is byte aligned.",
	"Method": "int getBytePosition(){\r\n    Assertions.checkState(bitOffset == 0);\r\n    return byteOffset;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.SecurityRealmSettingsTests.transportSSLEnabled",
	"Comment": "always enable transport ssl so that it is possible to have a pki realm",
	"Method": "boolean transportSSLEnabled(){\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.cast.CastPlayer.loadItem",
	"Comment": "loads a single item media queue. if no session is available, does nothing.",
	"Method": "PendingResult<MediaChannelResult> loadItem(MediaQueueItem item,long positionMs){\r\n    return loadItems(new MediaQueueItem[] { item }, 0, positionMs, REPEAT_MODE_OFF);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.TimeoutChecker.check",
	"Comment": "check whether the operation has been running longer than the permitted time.",
	"Method": "void check(String where){\r\n    if (timeoutExceeded) {\r\n        throw new ElasticsearchTimeoutException(\"Aborting \" + operation + \" during [\" + where + \"] as it has taken longer than the timeout of [\" + timeout + \"]\");\r\n    }\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ByteVector.putByteArray",
	"Comment": "puts an array of bytes into this byte vector. the byte vector is automatically enlarged if necessary.",
	"Method": "ByteVector putByteArray(byte[] b,int off,int len){\r\n    if (length + len > data.length) {\r\n        enlarge(len);\r\n    }\r\n    if (b != null) {\r\n        System.arraycopy(b, off, data, length, len);\r\n    }\r\n    length += len;\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.indexlifecycle.IndexLifecycleRunner.runPeriodicStep",
	"Comment": "run the current step, only if it is an asynchronous wait step. thesewait criteria are checked periodically from the ilm scheduler",
	"Method": "void runPeriodicStep(String policy,IndexMetaData indexMetaData){\r\n    String index = indexMetaData.getIndex().getName();\r\n    LifecycleExecutionState lifecycleState = LifecycleExecutionState.fromIndexMetadata(indexMetaData);\r\n    Step currentStep = getCurrentStep(stepRegistry, policy, indexMetaData, lifecycleState);\r\n    if (currentStep == null) {\r\n        if (stepRegistry.policyExists(policy) == false) {\r\n            markPolicyDoesNotExist(policy, indexMetaData.getIndex(), lifecycleState);\r\n            return;\r\n        } else {\r\n            logger.error(\"current step [{}] for index [{}] with policy [{}] is not recognized\", getCurrentStepKey(lifecycleState), index, policy);\r\n            return;\r\n        }\r\n    }\r\n    if (currentStep instanceof TerminalPolicyStep) {\r\n        logger.debug(\"policy [{}] for index [{}] complete, skipping execution\", policy, index);\r\n        return;\r\n    } else if (currentStep instanceof ErrorStep) {\r\n        logger.debug(\"policy [{}] for index [{}] on an error step, skipping execution\", policy, index);\r\n        return;\r\n    }\r\n    logger.trace(\"[{}] maybe running periodic step ({}) with current step {}\", index, currentStep.getClass().getSimpleName(), currentStep.getKey());\r\n    if (currentStep instanceof PhaseCompleteStep) {\r\n        if (isReadyToTransitionToThisPhase(policy, indexMetaData, currentStep.getNextStepKey().getPhase())) {\r\n            moveToStep(indexMetaData.getIndex(), policy, currentStep.getKey(), currentStep.getNextStepKey());\r\n        }\r\n    } else if (currentStep instanceof AsyncWaitStep) {\r\n        logger.debug(\"[{}] running periodic policy with current-step [{}]\", index, currentStep.getKey());\r\n        ((AsyncWaitStep) currentStep).evaluateCondition(indexMetaData, new AsyncWaitStep.Listener() {\r\n            @Override\r\n            public void onResponse(boolean conditionMet, ToXContentObject stepInfo) {\r\n                logger.trace(\"cs-change-async-wait-callback, [{}] current-step: {}\", index, currentStep.getKey());\r\n                if (conditionMet) {\r\n                    moveToStep(indexMetaData.getIndex(), policy, currentStep.getKey(), currentStep.getNextStepKey());\r\n                } else if (stepInfo != null) {\r\n                    setStepInfo(indexMetaData.getIndex(), policy, currentStep.getKey(), stepInfo);\r\n                }\r\n            }\r\n            @Override\r\n            public void onFailure(Exception e) {\r\n                moveToErrorStep(indexMetaData.getIndex(), policy, currentStep.getKey(), e);\r\n            }\r\n        });\r\n    } else {\r\n        logger.trace(\"[{}] ignoring non periodic step execution from step transition [{}]\", index, currentStep.getKey());\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.indexlifecycle.IndexLifecycleRunner.runPeriodicStep",
	"Comment": "run the current step, only if it is an asynchronous wait step. thesewait criteria are checked periodically from the ilm scheduler",
	"Method": "void runPeriodicStep(String policy,IndexMetaData indexMetaData){\r\n    logger.trace(\"cs-change-async-wait-callback, [{}] current-step: {}\", index, currentStep.getKey());\r\n    if (conditionMet) {\r\n        moveToStep(indexMetaData.getIndex(), policy, currentStep.getKey(), currentStep.getNextStepKey());\r\n    } else if (stepInfo != null) {\r\n        setStepInfo(indexMetaData.getIndex(), policy, currentStep.getKey(), stepInfo);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.indexlifecycle.IndexLifecycleRunner.runPeriodicStep",
	"Comment": "run the current step, only if it is an asynchronous wait step. thesewait criteria are checked periodically from the ilm scheduler",
	"Method": "void runPeriodicStep(String policy,IndexMetaData indexMetaData){\r\n    moveToErrorStep(indexMetaData.getIndex(), policy, currentStep.getKey(), e);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.changePassword",
	"Comment": "async method to change the password of a native or reserved user. if a reserved user does not exist, the document will be createdwith a hash of the provided password.",
	"Method": "void changePassword(ChangePasswordRequest request,ActionListener<Void> listener){\r\n    final String username = request.username();\r\n    assert SystemUser.NAME.equals(username) == false && XPackUser.NAME.equals(username) == false : username + \"is internal!\";\r\n    final String docType;\r\n    if (ClientReservedRealm.isReserved(username, settings)) {\r\n        docType = RESERVED_USER_TYPE;\r\n    } else {\r\n        docType = USER_DOC_TYPE;\r\n    }\r\n    securityIndex.prepareIndexIfNeededThenExecute(listener::onFailure, () -> {\r\n        executeAsyncWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN, client.prepareUpdate(SECURITY_INDEX_NAME, INDEX_TYPE, getIdForUser(docType, username)).setDoc(Requests.INDEX_CONTENT_TYPE, Fields.PASSWORD.getPreferredName(), String.valueOf(request.passwordHash())).setRefreshPolicy(request.getRefreshPolicy()).request(), new ActionListener<UpdateResponse>() {\r\n            @Override\r\n            public void onResponse(UpdateResponse updateResponse) {\r\n                assert updateResponse.getResult() == DocWriteResponse.Result.UPDATED;\r\n                clearRealmCache(request.username(), listener, null);\r\n            }\r\n            @Override\r\n            public void onFailure(Exception e) {\r\n                if (isIndexNotFoundOrDocumentMissing(e)) {\r\n                    if (docType.equals(RESERVED_USER_TYPE)) {\r\n                        createReservedUser(username, request.passwordHash(), request.getRefreshPolicy(), listener);\r\n                    } else {\r\n                        logger.debug((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage(\"failed to change password for user [{}]\", request.username()), e);\r\n                        ValidationException validationException = new ValidationException();\r\n                        validationException.addValidationError(\"user must exist in order to change password\");\r\n                        listener.onFailure(validationException);\r\n                    }\r\n                } else {\r\n                    listener.onFailure(e);\r\n                }\r\n            }\r\n        }, client::update);\r\n    });\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.changePassword",
	"Comment": "async method to change the password of a native or reserved user. if a reserved user does not exist, the document will be createdwith a hash of the provided password.",
	"Method": "void changePassword(ChangePasswordRequest request,ActionListener<Void> listener){\r\n    assert updateResponse.getResult() == DocWriteResponse.Result.UPDATED;\r\n    clearRealmCache(request.username(), listener, null);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.changePassword",
	"Comment": "async method to change the password of a native or reserved user. if a reserved user does not exist, the document will be createdwith a hash of the provided password.",
	"Method": "void changePassword(ChangePasswordRequest request,ActionListener<Void> listener){\r\n    if (isIndexNotFoundOrDocumentMissing(e)) {\r\n        if (docType.equals(RESERVED_USER_TYPE)) {\r\n            createReservedUser(username, request.passwordHash(), request.getRefreshPolicy(), listener);\r\n        } else {\r\n            logger.debug((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage(\"failed to change password for user [{}]\", request.username()), e);\r\n            ValidationException validationException = new ValidationException();\r\n            validationException.addValidationError(\"user must exist in order to change password\");\r\n            listener.onFailure(validationException);\r\n        }\r\n    } else {\r\n        listener.onFailure(e);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.FlacStreamInfo.maxDecodedFrameSize",
	"Comment": "returns the maximum size for a decoded frame from the flac stream.",
	"Method": "int maxDecodedFrameSize(){\r\n    return maxBlockSize * channels * (bitsPerSample / 8);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.FieldStatsCalculator.accept",
	"Comment": "add a collection of values to the calculator.the values to be added can be combined by the caller and added in asingle call to this method or added in multiple calls to this method.",
	"Method": "void accept(Collection<String> fieldValues){\r\n    count += fieldValues.size();\r\n    for (String fieldValue : fieldValues) {\r\n        countsByStringValue.compute(fieldValue, (k, v) -> (v == null) ? 1 : (1 + v));\r\n        if (countsByNumericValue != null) {\r\n            try {\r\n                countsByNumericValue.compute(Double.valueOf(fieldValue), (k, v) -> (v == null) ? 1 : (1 + v));\r\n            } catch (NumberFormatException e) {\r\n                countsByNumericValue = null;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateTool.fullyWriteFile",
	"Comment": "this method handles the deletion of a file in the case of a partial write",
	"Method": "void fullyWriteFile(Path file,CheckedConsumer<OutputStream, Exception> writer){\r\n    assert file != null;\r\n    assert writer != null;\r\n    boolean success = false;\r\n    if (Files.exists(file)) {\r\n        throw new UserException(ExitCodes.IO_ERROR, \"Output file '\" + file + \"' already exists\");\r\n    }\r\n    try (OutputStream outputStream = Files.newOutputStream(file, StandardOpenOption.CREATE_NEW)) {\r\n        writer.accept(outputStream);\r\n        PosixFileAttributeView view = Files.getFileAttributeView(file, PosixFileAttributeView.class);\r\n        if (view != null) {\r\n            view.setPermissions(Sets.newHashSet(PosixFilePermission.OWNER_READ, PosixFilePermission.OWNER_WRITE));\r\n        }\r\n        success = true;\r\n    } finally {\r\n        if (success == false) {\r\n            Files.deleteIfExists(file);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.alibaba.fastjson.JSONPath.keySet",
	"Comment": "compile jsonpath and use it to extract keyset or field names from rootobject.",
	"Method": "Set<?> keySet(Object rootObject,Set<?> keySet,Object rootObject,String path){\r\n    JSONPath jsonpath = compile(path);\r\n    Object result = jsonpath.eval(rootObject);\r\n    return jsonpath.evalKeySet(result);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.AbstractDataToProcessWriter.createInputOutputMap",
	"Comment": "create a map of input index to output index. this does not include the time or control fields.",
	"Method": "List<InputOutputMap> createInputOutputMap(Map<String, Integer> inFieldIndexes){\r\n    List<InputOutputMap> inputOutputMap = new ArrayList();\r\n    int outIndex = TIME_FIELD_OUT_INDEX;\r\n    Integer inIndex = inFieldIndexes.get(dataDescription.getTimeField());\r\n    if (inIndex == null) {\r\n        throw new IllegalStateException(String.format(Locale.ROOT, \"Input time field '%s' not found\", dataDescription.getTimeField()));\r\n    }\r\n    inputOutputMap.add(new InputOutputMap(inIndex, outIndex));\r\n    for (String field : analysisConfig.analysisFields()) {\r\n        if (AnalysisConfig.ML_CATEGORY_FIELD.equals(field) == false) {\r\n            ++outIndex;\r\n            inIndex = inFieldIndexes.get(field);\r\n            if (inIndex != null) {\r\n                inputOutputMap.add(new InputOutputMap(inIndex, outIndex));\r\n            }\r\n        }\r\n    }\r\n    return inputOutputMap;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.DefaultHttpDataSource.getConnection",
	"Comment": "returns the current connection, or null if the source is not currently opened.",
	"Method": "HttpURLConnection getConnection(){\r\n    return connection;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.KerberosTicketValidator.acceptSecContext",
	"Comment": "handles gss context establishment. received token is passed to the gsscontexton acceptor side and returns with out token that needs to be sent to peer forfurther gss context establishment.",
	"Method": "byte[] acceptSecContext(byte[] base64decodedTicket,GSSContext gssContext,Subject subject){\r\n    return doAsWrapper(subject, (PrivilegedExceptionAction<byte[]>) () -> gssContext.acceptSecContext(base64decodedTicket, 0, base64decodedTicket.length));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.getLoadingPeriod",
	"Comment": "returns the loading period holder which is at the end of the queue, or null if the queue isempty.",
	"Method": "MediaPeriodHolder getLoadingPeriod(){\r\n    return loading;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.FileStructureUtils.makeIngestPipelineDefinition",
	"Comment": "create an ingest pipeline definition appropriate for the file structure.",
	"Method": "Map<String, Object> makeIngestPipelineDefinition(String grokPattern,String timestampField,List<String> timestampFormats,boolean needClientTimezone){\r\n    if (grokPattern == null && timestampField == null) {\r\n        return null;\r\n    }\r\n    Map<String, Object> pipeline = new LinkedHashMap();\r\n    pipeline.put(Pipeline.DESCRIPTION_KEY, \"Ingest pipeline created by file structure finder\");\r\n    List<Map<String, Object>> processors = new ArrayList();\r\n    if (grokPattern != null) {\r\n        Map<String, Object> grokProcessorSettings = new LinkedHashMap();\r\n        grokProcessorSettings.put(\"field\", \"message\");\r\n        grokProcessorSettings.put(\"patterns\", Collections.singletonList(grokPattern));\r\n        processors.add(Collections.singletonMap(\"grok\", grokProcessorSettings));\r\n    }\r\n    if (timestampField != null) {\r\n        Map<String, Object> dateProcessorSettings = new LinkedHashMap();\r\n        dateProcessorSettings.put(\"field\", timestampField);\r\n        if (needClientTimezone) {\r\n            dateProcessorSettings.put(\"timezone\", \"{{ \" + BEAT_TIMEZONE_FIELD + \" }}\");\r\n        }\r\n        dateProcessorSettings.put(\"formats\", timestampFormats);\r\n        processors.add(Collections.singletonMap(\"date\", dateProcessorSettings));\r\n    }\r\n    if (grokPattern != null && timestampField != null) {\r\n        processors.add(Collections.singletonMap(\"remove\", Collections.singletonMap(\"field\", timestampField)));\r\n    }\r\n    pipeline.put(Pipeline.PROCESSORS_KEY, processors);\r\n    return pipeline;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.MediaSourceTestRunner.release",
	"Comment": "releases the runner. should be called when the runner is no longer required.",
	"Method": "void release(){\r\n    playbackThread.quit();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.type.EsField.getExactField",
	"Comment": "returns the path to the keyword version of this field if this field is text and it has a subfield that isindexed as keyword, null if such field is not found or the field name itself in all other cases",
	"Method": "EsField getExactField(){\r\n    return this;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleMetadataQueue.peekSourceId",
	"Comment": "peeks the source id of the next sample to be read, or the current upstream source id if thequeue is empty or if the read position is at the end of the queue.",
	"Method": "int peekSourceId(){\r\n    int relativeReadIndex = getRelativeIndex(readPosition);\r\n    return hasNextSample() ? sourceIds[relativeReadIndex] : upstreamSourceId;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.amr.AmrExtractor.readAmrHeader",
	"Comment": "peeks the amr header from the beginning of the input, and consumes it if it exists.",
	"Method": "boolean readAmrHeader(ExtractorInput input){\r\n    if (peekAmrSignature(input, amrSignatureNb)) {\r\n        isWideBand = false;\r\n        input.skipFully(amrSignatureNb.length);\r\n        return true;\r\n    } else if (peekAmrSignature(input, amrSignatureWb)) {\r\n        isWideBand = true;\r\n        input.skipFully(amrSignatureWb.length);\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ClassWriter.newConstItem",
	"Comment": "adds a number or string constant to the constant pool of the class being build. does nothing if the constant poolalready contains a similar item.",
	"Method": "Item newConstItem(Object cst){\r\n    if (cst instanceof Integer) {\r\n        int val = ((Integer) cst).intValue();\r\n        key.set(val);\r\n        Item result = get(key);\r\n        if (result == null) {\r\n            pool.putByte(3).putInt(val);\r\n            result = new Item(index++, key);\r\n            put(result);\r\n        }\r\n        return result;\r\n    } else if (cst instanceof String) {\r\n        return newString((String) cst);\r\n    } else if (cst instanceof Type) {\r\n        Type t = (Type) cst;\r\n        return newClassItem(t.sort == 10 ? t.getInternalName() : t.getDescriptor());\r\n    } else {\r\n        throw new IllegalArgumentException(\"value \" + cst);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.trigger.schedule.tool.CronEvalToolTests.testEnsureDateIsShownInRootLocale",
	"Comment": "we always have to output in standard locale and independent from timezone",
	"Method": "void testEnsureDateIsShownInRootLocale(){\r\n    String output = execute(\"-c\", \"1\", \"0 0 11 ? * MON-SAT 2040\");\r\n    if (TimeZone.getDefault().equals(DateTimeZone.UTC.toTimeZone())) {\r\n        assertThat(output, not(containsString(\"local time is\")));\r\n        long linesStartingWithOne = Arrays.stream(output.split(\"\\n\")).filter(s -> s.startsWith(\"\\t\")).count();\r\n        assertThat(linesStartingWithOne, is(0L));\r\n    } else {\r\n        assertThat(output, containsString(\"] in UTC, local time is\"));\r\n        assertThat(output, containsString(\"Mon, 2 Jan 2040 11:00:00\"));\r\n        logger.info(output);\r\n        long linesStartingWithOne = Arrays.stream(output.split(\"\\n\")).filter(s -> s.startsWith(\"\\t\")).count();\r\n        assertThat(linesStartingWithOne, is(1L));\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerView.getPlayer",
	"Comment": "returns the player currently set on this view, or null if no player is set.",
	"Method": "Player getPlayer(){\r\n    return player;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.persistence.JobDataDeleter.deleteModelSnapshots",
	"Comment": "delete a list of model snapshots and their corresponding state documents.",
	"Method": "void deleteModelSnapshots(List<ModelSnapshot> modelSnapshots,ActionListener<BulkResponse> listener){\r\n    if (modelSnapshots.isEmpty()) {\r\n        listener.onResponse(new BulkResponse(new BulkItemResponse[0], 0L));\r\n        return;\r\n    }\r\n    String stateIndexName = AnomalyDetectorsIndex.jobStateIndexName();\r\n    ActionListener<BulkResponse> docDeleteListener = ActionListener.wrap(response -> {\r\n        if (response.hasFailures() == false) {\r\n            listener.onResponse(response);\r\n            return;\r\n        }\r\n        BulkRequestBuilder bulkRequestBuilder = client.prepareBulk();\r\n        for (ModelSnapshot modelSnapshot : modelSnapshots) {\r\n            for (String stateDocId : modelSnapshot.legacyStateDocumentIds()) {\r\n                bulkRequestBuilder.add(client.prepareDelete(stateIndexName, ModelState.TYPE, stateDocId));\r\n            }\r\n            bulkRequestBuilder.add(client.prepareDelete(AnomalyDetectorsIndex.jobResultsAliasedName(modelSnapshot.getJobId()), ModelSnapshot.TYPE.getPreferredName(), ModelSnapshot.v54DocumentId(modelSnapshot)));\r\n        }\r\n        bulkRequestBuilder.setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE);\r\n        try {\r\n            bulkRequestBuilder.execute(ActionListener.wrap(listener::onResponse, e -> {\r\n                if (e instanceof IllegalArgumentException && e.getMessage().contains(\"as the final mapping would have more than 1 type\")) {\r\n                    listener.onResponse(response);\r\n                }\r\n                listener.onFailure(e);\r\n            }));\r\n        } catch (Exception e) {\r\n            listener.onFailure(e);\r\n        }\r\n    }, listener::onFailure);\r\n    BulkRequestBuilder bulkRequestBuilder = client.prepareBulk();\r\n    for (ModelSnapshot modelSnapshot : modelSnapshots) {\r\n        for (String stateDocId : modelSnapshot.stateDocumentIds()) {\r\n            bulkRequestBuilder.add(client.prepareDelete(stateIndexName, ElasticsearchMappings.DOC_TYPE, stateDocId));\r\n        }\r\n        bulkRequestBuilder.add(client.prepareDelete(AnomalyDetectorsIndex.jobResultsAliasedName(modelSnapshot.getJobId()), ElasticsearchMappings.DOC_TYPE, ModelSnapshot.documentId(modelSnapshot)));\r\n    }\r\n    bulkRequestBuilder.setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE);\r\n    try {\r\n        executeAsyncWithOrigin(client, ML_ORIGIN, BulkAction.INSTANCE, bulkRequestBuilder.request(), docDeleteListener);\r\n    } catch (Exception e) {\r\n        listener.onFailure(e);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.getUserTokenString",
	"Comment": "serializes a token to a string containing an encrypted representation of the token",
	"Method": "String getUserTokenString(UserToken userToken){\r\n    try (ByteArrayOutputStream os = new ByteArrayOutputStream(MINIMUM_BASE64_BYTES);\r\n        OutputStream base64 = Base64.getEncoder().wrap(os);\r\n        StreamOutput out = new OutputStreamStreamOutput(base64)) {\r\n        out.setVersion(userToken.getVersion());\r\n        KeyAndCache keyAndCache = keyCache.activeKeyCache;\r\n        Version.writeVersion(userToken.getVersion(), out);\r\n        out.writeByteArray(keyAndCache.getSalt().bytes);\r\n        out.writeByteArray(keyAndCache.getKeyHash().bytes);\r\n        final byte[] initializationVector = getNewInitializationVector();\r\n        out.writeByteArray(initializationVector);\r\n        try (CipherOutputStream encryptedOutput = new CipherOutputStream(out, getEncryptionCipher(initializationVector, keyAndCache, userToken.getVersion()));\r\n            StreamOutput encryptedStreamOutput = new OutputStreamStreamOutput(encryptedOutput)) {\r\n            encryptedStreamOutput.setVersion(userToken.getVersion());\r\n            if (userToken.getVersion().onOrAfter(Version.V_6_2_0)) {\r\n                encryptedStreamOutput.writeString(userToken.getId());\r\n            } else {\r\n                userToken.writeTo(encryptedStreamOutput);\r\n            }\r\n            encryptedStreamOutput.close();\r\n            return new String(os.toByteArray(), StandardCharsets.UTF_8);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.notification.email.attachment.ReportingAttachmentParser.extractIdFromJson",
	"Comment": "extract the id from json payload, so we know which id to poll for",
	"Method": "String extractIdFromJson(String watchId,String attachmentId,BytesReference body){\r\n    try (InputStream stream = body.streamInput();\r\n        XContentParser parser = JsonXContent.jsonXContent.createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, stream)) {\r\n        KibanaReportingPayload payload = new KibanaReportingPayload();\r\n        PAYLOAD_PARSER.parse(parser, payload, null);\r\n        String path = payload.getPath();\r\n        if (Strings.isEmpty(path)) {\r\n            throw new ElasticsearchException(\"Watch[{}] reporting[{}] field path found in JSON payload, payload was {}\", watchId, attachmentId, body.utf8ToString());\r\n        }\r\n        return path;\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerView.setControllerHideDuringAds",
	"Comment": "sets whether the playback controls are hidden when ads are playing. controls are always shownduring ads if they are enabled and the player is paused.",
	"Method": "void setControllerHideDuringAds(boolean controllerHideDuringAds){\r\n    this.controllerHideDuringAds = controllerHideDuringAds;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.PemUtils.getKeyAlgorithmIdentifier",
	"Comment": "parses a der encoded private key and reads its algorithm identifier object oid.",
	"Method": "String getKeyAlgorithmIdentifier(byte[] keyBytes){\r\n    DerParser parser = new DerParser(keyBytes);\r\n    DerParser.Asn1Object sequence = parser.readAsn1Object();\r\n    parser = sequence.getParser();\r\n    parser.readAsn1Object().getInteger();\r\n    DerParser.Asn1Object algSequence = parser.readAsn1Object();\r\n    parser = algSequence.getParser();\r\n    String oidString = parser.readAsn1Object().getOid();\r\n    switch(oidString) {\r\n        case \"1.2.840.10040.4.1\":\r\n            return \"DSA\";\r\n        case \"1.2.840.113549.1.1.1\":\r\n            return \"RSA\";\r\n        case \"1.2.840.10045.2.1\":\r\n            return \"EC\";\r\n    }\r\n    throw new GeneralSecurityException(\"Error parsing key algorithm identifier. Algorithm with OID: \" + oidString + \" is not \" + \"supported\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.Watcher.getIndexTemplateMetaDataUpgrader",
	"Comment": "these are all old templates from pre 6.0 era, that need to be deleted",
	"Method": "UnaryOperator<Map<String, IndexTemplateMetaData>> getIndexTemplateMetaDataUpgrader(){\r\n    return map -> {\r\n        map.keySet().removeIf(name -> name.startsWith(\"watch_history_\"));\r\n        return map;\r\n    };\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authz.IndicesAndAliasesResolverTests.testRemotableRequestsAllowRemoteIndices",
	"Comment": "tests that all the request types that are known to support remote indices successfully pass them through the resolver",
	"Method": "void testRemotableRequestsAllowRemoteIndices(){\r\n    IndicesOptions options = IndicesOptions.fromOptions(true, false, false, false);\r\n    Tuple<TransportRequest, String> tuple = randomFrom(new Tuple<TransportRequest, String>(new SearchRequest(\"remote:foo\").indicesOptions(options), SearchAction.NAME), new Tuple<TransportRequest, String>(new FieldCapabilitiesRequest().indices(\"remote:foo\").indicesOptions(options), FieldCapabilitiesAction.NAME), new Tuple<TransportRequest, String>(new GraphExploreRequest().indices(\"remote:foo\").indicesOptions(options), GraphExploreAction.NAME));\r\n    final TransportRequest request = tuple.v1();\r\n    ResolvedIndices resolved = resolveIndices(request, buildAuthorizedIndices(user, tuple.v2()));\r\n    assertThat(resolved.getRemote(), containsInAnyOrder(\"remote:foo\"));\r\n    assertThat(resolved.getLocal(), emptyIterable());\r\n    assertThat(((IndicesRequest) request).indices(), arrayContaining(\"remote:foo\"));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.integration.ScheduledEventsIT.testAddOpenedJobToGroupWithCalendar",
	"Comment": "an open job that later gets added to a calendar, should take the scheduled events into account",
	"Method": "void testAddOpenedJobToGroupWithCalendar(){\r\n    TimeValue bucketSpan = TimeValue.timeValueMinutes(30);\r\n    String groupName = \"opened-calendar-job-group\";\r\n    Job.Builder job = createJob(\"scheduled-events-add-opened-job-to-group-with-calendar\", bucketSpan);\r\n    long startTime = 1514764800000L;\r\n    final int bucketCount = 5;\r\n    openJob(job.getId());\r\n    postData(job.getId(), generateData(startTime, bucketSpan, bucketCount, bucketIndex -> randomIntBetween(100, 200)).stream().collect(Collectors.joining()));\r\n    String calendarId = \"test-calendar-open-job-update\";\r\n    putCalendar(calendarId, Collections.singletonList(groupName), \"testAddOpenedJobToGroupWithCalendar calendar\");\r\n    List<ScheduledEvent> events = new ArrayList();\r\n    long eventStartTime = startTime + (bucketCount + 1) * bucketSpan.millis();\r\n    long eventEndTime = eventStartTime + (long) (1.5 * bucketSpan.millis());\r\n    events.add(new ScheduledEvent.Builder().description(\"Some Event\").startTime(ZonedDateTime.ofInstant(Instant.ofEpochMilli(eventStartTime), ZoneOffset.UTC)).endTime(ZonedDateTime.ofInstant(Instant.ofEpochMilli(eventEndTime), ZoneOffset.UTC)).calendarId(calendarId).build());\r\n    postScheduledEvents(calendarId, events);\r\n    UpdateJobAction.Request jobUpdateRequest = new UpdateJobAction.Request(job.getId(), new JobUpdate.Builder(job.getId()).setGroups(Collections.singletonList(groupName)).build());\r\n    client().execute(UpdateJobAction.INSTANCE, jobUpdateRequest).actionGet();\r\n    assertBusy(() -> {\r\n        SearchResponse searchResponse = client().prepareSearch(\".ml-notifications\").setSize(1).addSort(\"timestamp\", SortOrder.DESC).setQuery(QueryBuilders.boolQuery().filter(QueryBuilders.termQuery(\"job_id\", job.getId())).filter(QueryBuilders.termQuery(\"level\", \"info\"))).get();\r\n        SearchHit[] hits = searchResponse.getHits().getHits();\r\n        assertThat(hits.length, equalTo(1));\r\n        assertThat(hits[0].getSourceAsMap().get(\"message\"), equalTo(\"Job updated: [groups]\"));\r\n    });\r\n    postData(job.getId(), generateData(startTime + bucketCount * bucketSpan.millis(), bucketSpan, 5, bucketIndex -> randomIntBetween(100, 200)).stream().collect(Collectors.joining()));\r\n    closeJob(job.getId());\r\n    GetBucketsAction.Request getBucketsRequest = new GetBucketsAction.Request(job.getId());\r\n    List<Bucket> buckets = getBuckets(getBucketsRequest);\r\n    for (int i = 0; i <= bucketCount; i++) {\r\n        assertEquals(0, buckets.get(i).getScheduledEvents().size());\r\n    }\r\n    assertEquals(1, buckets.get(6).getScheduledEvents().size());\r\n    assertEquals(\"Some Event\", buckets.get(6).getScheduledEvents().get(0));\r\n    assertEquals(1, buckets.get(7).getScheduledEvents().size());\r\n    assertEquals(\"Some Event\", buckets.get(7).getScheduledEvents().get(0));\r\n    assertEquals(0, buckets.get(8).getScheduledEvents().size());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.XmlPullParserUtil.isEndTag",
	"Comment": "returns whether the current event is an end tag with the specified name.",
	"Method": "boolean isEndTag(XmlPullParser xpp,String name,boolean isEndTag,XmlPullParser xpp){\r\n    return xpp.getEventType() == XmlPullParser.END_TAG;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.ScrollHelper.fetchAllByEntity",
	"Comment": "this method fetches all results for the given search request, parses them using the given hit parser and calls thelistener once done.",
	"Method": "void fetchAllByEntity(Client client,SearchRequest request,ActionListener<Collection<T>> listener,Function<SearchHit, T> hitParser){\r\n    final List<T> results = new ArrayList();\r\n    if (request.scroll() == null) {\r\n        throw new IllegalArgumentException(\"request must have scroll set\");\r\n    }\r\n    final Consumer<SearchResponse> clearScroll = (response) -> {\r\n        if (response != null && response.getScrollId() != null) {\r\n            ClearScrollRequest clearScrollRequest = new ClearScrollRequest();\r\n            clearScrollRequest.addScrollId(response.getScrollId());\r\n            client.clearScroll(clearScrollRequest, ActionListener.wrap((r) -> {\r\n            }, e -> LOGGER.warn(new ParameterizedMessage(\"clear scroll failed for scroll id [{}]\", response.getScrollId()), e)));\r\n        }\r\n    };\r\n    client.search(request, new ContextPreservingActionListener(client.threadPool().getThreadContext().newRestorableContext(true), new ActionListener<SearchResponse>() {\r\n        private volatile SearchResponse lastResponse = null;\r\n        @Override\r\n        public void onResponse(SearchResponse resp) {\r\n            try {\r\n                lastResponse = resp;\r\n                if (resp.getHits().getHits().length > 0) {\r\n                    for (SearchHit hit : resp.getHits().getHits()) {\r\n                        final T oneResult = hitParser.apply(hit);\r\n                        if (oneResult != null) {\r\n                            results.add(oneResult);\r\n                        }\r\n                    }\r\n                    if (results.size() > resp.getHits().getTotalHits()) {\r\n                        clearScroll.accept(lastResponse);\r\n                        listener.onFailure(new IllegalStateException(\"scrolling returned more hits [\" + results.size() + \"] than expected [\" + resp.getHits().getTotalHits() + \"] so bailing out to prevent unbounded \" + \"memory consumption.\"));\r\n                    } else if (results.size() == resp.getHits().getTotalHits()) {\r\n                        clearScroll.accept(resp);\r\n                        listener.onResponse(Collections.unmodifiableList(results));\r\n                    } else {\r\n                        SearchScrollRequest scrollRequest = new SearchScrollRequest(resp.getScrollId());\r\n                        scrollRequest.scroll(request.scroll().keepAlive());\r\n                        client.searchScroll(scrollRequest, this);\r\n                    }\r\n                } else {\r\n                    clearScroll.accept(resp);\r\n                    listener.onResponse(Collections.unmodifiableList(results));\r\n                }\r\n            } catch (Exception e) {\r\n                onFailure(e);\r\n            }\r\n        }\r\n        @Override\r\n        public void onFailure(Exception t) {\r\n            try {\r\n                clearScroll.accept(lastResponse);\r\n            } finally {\r\n                if (t instanceof IndexNotFoundException) {\r\n                    listener.onResponse(Collections.<T>emptyList());\r\n                } else {\r\n                    listener.onFailure(t);\r\n                }\r\n            }\r\n        }\r\n    }));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.ScrollHelper.fetchAllByEntity",
	"Comment": "this method fetches all results for the given search request, parses them using the given hit parser and calls thelistener once done.",
	"Method": "void fetchAllByEntity(Client client,SearchRequest request,ActionListener<Collection<T>> listener,Function<SearchHit, T> hitParser){\r\n    try {\r\n        lastResponse = resp;\r\n        if (resp.getHits().getHits().length > 0) {\r\n            for (SearchHit hit : resp.getHits().getHits()) {\r\n                final T oneResult = hitParser.apply(hit);\r\n                if (oneResult != null) {\r\n                    results.add(oneResult);\r\n                }\r\n            }\r\n            if (results.size() > resp.getHits().getTotalHits()) {\r\n                clearScroll.accept(lastResponse);\r\n                listener.onFailure(new IllegalStateException(\"scrolling returned more hits [\" + results.size() + \"] than expected [\" + resp.getHits().getTotalHits() + \"] so bailing out to prevent unbounded \" + \"memory consumption.\"));\r\n            } else if (results.size() == resp.getHits().getTotalHits()) {\r\n                clearScroll.accept(resp);\r\n                listener.onResponse(Collections.unmodifiableList(results));\r\n            } else {\r\n                SearchScrollRequest scrollRequest = new SearchScrollRequest(resp.getScrollId());\r\n                scrollRequest.scroll(request.scroll().keepAlive());\r\n                client.searchScroll(scrollRequest, this);\r\n            }\r\n        } else {\r\n            clearScroll.accept(resp);\r\n            listener.onResponse(Collections.unmodifiableList(results));\r\n        }\r\n    } catch (Exception e) {\r\n        onFailure(e);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.ScrollHelper.fetchAllByEntity",
	"Comment": "this method fetches all results for the given search request, parses them using the given hit parser and calls thelistener once done.",
	"Method": "void fetchAllByEntity(Client client,SearchRequest request,ActionListener<Collection<T>> listener,Function<SearchHit, T> hitParser){\r\n    try {\r\n        clearScroll.accept(lastResponse);\r\n    } finally {\r\n        if (t instanceof IndexNotFoundException) {\r\n            listener.onResponse(Collections.<T>emptyList());\r\n        } else {\r\n            listener.onFailure(t);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.MlDailyMaintenanceService.delayToNextTime",
	"Comment": "calculates the delay until the next time the maintenance should be triggered.the next time is 30 minutes past midnight of the following day plus a randomoffset. the random offset is added in order to avoid multiple clustersrunning the maintenance tasks at the same time. a cluster with a given nameshall have the same offset throughout its life.",
	"Method": "TimeValue delayToNextTime(ClusterName clusterName){\r\n    Random random = new Random(clusterName.hashCode());\r\n    int minutesOffset = random.ints(0, MAX_TIME_OFFSET_MINUTES).findFirst().getAsInt();\r\n    DateTime now = DateTime.now(ISOChronology.getInstance());\r\n    DateTime next = now.plusDays(1).withTimeAtStartOfDay().plusMinutes(30).plusMinutes(minutesOffset);\r\n    return TimeValue.timeValueMillis(next.getMillis() - now.getMillis());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.text.webvtt.WebvttCssStyle.getSpecificityScore",
	"Comment": "returns a value in a score system compliant with the css specificity rules.",
	"Method": "int getSpecificityScore(String id,String tag,String[] classes,String voice){\r\n    if (targetId.isEmpty() && targetTag.isEmpty() && targetClasses.isEmpty() && targetVoice.isEmpty()) {\r\n        return tag.isEmpty() ? 1 : 0;\r\n    }\r\n    int score = 0;\r\n    score = updateScoreForMatch(score, targetId, id, 0x40000000);\r\n    score = updateScoreForMatch(score, targetTag, tag, 2);\r\n    score = updateScoreForMatch(score, targetVoice, voice, 4);\r\n    if (score == -1 || !Arrays.asList(classes).containsAll(targetClasses)) {\r\n        return 0;\r\n    } else {\r\n        score += targetClasses.size() * 4;\r\n    }\r\n    return score;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.cast.CastPlayer.addItems",
	"Comment": "appends a sequence of items to the media queue. if no media queue exists, does nothing.",
	"Method": "PendingResult<MediaChannelResult> addItems(MediaQueueItem items,PendingResult<MediaChannelResult> addItems,int periodId,MediaQueueItem items){\r\n    if (getMediaStatus() != null && (periodId == MediaQueueItem.INVALID_ITEM_ID || currentTimeline.getIndexOfPeriod(periodId) != C.INDEX_UNSET)) {\r\n        return remoteMediaClient.queueInsertItems(items, periodId, null);\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.CurrentExecutions.sealAndAwaitEmpty",
	"Comment": "calling this method makes the class stop accepting new executions and throws and exception instead.in addition it waits for a certain amount of time for current executions to finish before returning",
	"Method": "void sealAndAwaitEmpty(TimeValue maxStopTimeout){\r\n    lock.lock();\r\n    try {\r\n        seal.set(true);\r\n        while (currentExecutions.size() > 0) {\r\n            empty.await(maxStopTimeout.millis(), TimeUnit.MILLISECONDS);\r\n        }\r\n    } catch (InterruptedException e) {\r\n        Thread.currentThread().interrupt();\r\n    } finally {\r\n        lock.unlock();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.persistence.JobResultsProvider.influencers",
	"Comment": "return a page of influencers for the given job and within the given date rangeuses a supplied client, so may run as the currently authenticated user",
	"Method": "void influencers(String jobId,InfluencersQuery query,Consumer<QueryPage<Influencer>> handler,Consumer<Exception> errorHandler,Client client){\r\n    QueryBuilder fb = new ResultsFilterBuilder().timeRange(Result.TIMESTAMP.getPreferredName(), query.getStart(), query.getEnd()).score(Influencer.INFLUENCER_SCORE.getPreferredName(), query.getInfluencerScoreFilter()).interim(query.isIncludeInterim()).build();\r\n    String indexName = AnomalyDetectorsIndex.jobResultsAliasedName(jobId);\r\n    LOGGER.trace(\"ES API CALL: search all of influencers from index {}{}  with filter from {} size {}\", () -> indexName, () -> (query.getSortField() != null) ? \" with sort \" + (query.isSortDescending() ? \"descending\" : \"ascending\") + \" on field \" + query.getSortField() : \"\", query::getFrom, query::getSize);\r\n    QueryBuilder qb = new BoolQueryBuilder().filter(fb).filter(new TermsQueryBuilder(Result.RESULT_TYPE.getPreferredName(), Influencer.RESULT_TYPE_VALUE));\r\n    SearchRequest searchRequest = new SearchRequest(indexName);\r\n    searchRequest.indicesOptions(MlIndicesUtils.addIgnoreUnavailable(searchRequest.indicesOptions()));\r\n    FieldSortBuilder sb = query.getSortField() == null ? SortBuilders.fieldSort(ElasticsearchMappings.ES_DOC) : new FieldSortBuilder(query.getSortField()).order(query.isSortDescending() ? SortOrder.DESC : SortOrder.ASC);\r\n    searchRequest.source(new SearchSourceBuilder().query(qb).from(query.getFrom()).size(query.getSize()).sort(sb));\r\n    executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, searchRequest, ActionListener.<SearchResponse>wrap(response -> {\r\n        List<Influencer> influencers = new ArrayList();\r\n        for (SearchHit hit : response.getHits().getHits()) {\r\n            BytesReference source = hit.getSourceRef();\r\n            try (InputStream stream = source.streamInput();\r\n                XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, stream)) {\r\n                influencers.add(Influencer.LENIENT_PARSER.apply(parser, null));\r\n            } catch (IOException e) {\r\n                throw new ElasticsearchParseException(\"failed to parse influencer\", e);\r\n            }\r\n        }\r\n        QueryPage<Influencer> result = new QueryPage(influencers, response.getHits().getTotalHits(), Influencer.RESULTS_FIELD);\r\n        handler.accept(result);\r\n    }, e -> errorHandler.accept(mapAuthFailure(e, jobId, GetInfluencersAction.NAME))), client::search);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.text.ttml.TtmlStyle.chain",
	"Comment": "chains this style to referential style. local properties which are already setare never overridden.",
	"Method": "TtmlStyle chain(TtmlStyle ancestor){\r\n    return inherit(ancestor, true);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.TimelineAsserts.assertPreviousWindowIndices",
	"Comment": "asserts that previous window indices for each window depending on the repeat mode and theshuffle mode are equal to the given sequence.",
	"Method": "void assertPreviousWindowIndices(Timeline timeline,int repeatMode,boolean shuffleModeEnabled,int expectedPreviousWindowIndices){\r\n    for (int i = 0; i < timeline.getWindowCount(); i++) {\r\n        assertThat(timeline.getPreviousWindowIndex(i, repeatMode, shuffleModeEnabled)).isEqualTo(expectedPreviousWindowIndices[i]);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.TrackSampleTable.getIndexOfEarlierOrEqualSynchronizationSample",
	"Comment": "returns the sample index of the closest synchronization sample at or before the giventimestamp, if one is available.",
	"Method": "int getIndexOfEarlierOrEqualSynchronizationSample(long timeUs){\r\n    int startIndex = Util.binarySearchFloor(timestampsUs, timeUs, true, false);\r\n    for (int i = startIndex; i >= 0; i--) {\r\n        if ((flags[i] & C.BUFFER_FLAG_KEY_FRAME) != 0) {\r\n            return i;\r\n        }\r\n    }\r\n    return C.INDEX_UNSET;\r\n}"
}, {
	"Path": "com.alibaba.fastjson.util.AntiCollisionHashMap.containsValue",
	"Comment": "returns true if this map maps one or more keys to the specifiedvalue.",
	"Method": "boolean containsValue(Object value){\r\n    if (value == null)\r\n        return containsNullValue();\r\n    Entry[] tab = table;\r\n    for (int i = 0; i < tab.length; i++) for (Entry e = tab[i]; e != null; e = e.next) if (value.equals(e.value))\r\n        return true;\r\n    return false;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.transport.actions.stats.WatcherStatsResponse.getWatchesCount",
	"Comment": "sum all watches across all nodes to get a total count of watches in the cluster",
	"Method": "long getWatchesCount(long getWatchesCount){\r\n    return getNodes().stream().mapToLong(WatcherStatsResponse.Node::getWatchesCount).sum();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.TextLogFileStructureFinder.weightForMatch",
	"Comment": "used to weight a timestamp match according to how far along the line it is found.timestamps at the very beginning of the line are given a weight of 1.the weightprogressively decreases the more text there is preceding the timestamp match, butis always greater than 0.",
	"Method": "double weightForMatch(String preface){\r\n    return Math.pow(1.0 + preface.length() / 15.0, -1.1);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.HlsSampleStreamWrapper.seekInsideBufferUs",
	"Comment": "attempts to seek to the specified position within the sample queues.",
	"Method": "boolean seekInsideBufferUs(long positionUs){\r\n    int sampleQueueCount = sampleQueues.length;\r\n    for (int i = 0; i < sampleQueueCount; i++) {\r\n        SampleQueue sampleQueue = sampleQueues[i];\r\n        sampleQueue.rewind();\r\n        boolean seekInsideQueue = sampleQueue.advanceTo(positionUs, true, false) != SampleQueue.ADVANCE_FAILED;\r\n        if (!seekInsideQueue && (sampleQueueIsAudioVideoFlags[i] || !haveAudioVideoSampleQueues)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.PemUtils.removeDsaHeaders",
	"Comment": "removes the dsa params headers that openssl adds to dsa private keys as the information in themis redundant",
	"Method": "BufferedReader removeDsaHeaders(BufferedReader bReader){\r\n    String line = bReader.readLine();\r\n    while (line != null) {\r\n        if (OPENSSL_DSA_PARAMS_FOOTER.equals(line.trim())) {\r\n            break;\r\n        }\r\n        line = bReader.readLine();\r\n    }\r\n    if (null == line || OPENSSL_DSA_PARAMS_FOOTER.equals(line.trim()) == false) {\r\n        throw new IOException(\"Malformed PEM file, DSA Parameters footer is missing\");\r\n    }\r\n    if (OPENSSL_DSA_HEADER.equals(bReader.readLine()) == false) {\r\n        throw new IOException(\"Malformed PEM file, DSA Key header is missing\");\r\n    }\r\n    return bReader;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherService.reload",
	"Comment": "reload the watcher service, does not switch the state from stopped to started, just keep going",
	"Method": "void reload(ClusterState state,String reason){\r\n    processedClusterStateVersion.set(state.getVersion());\r\n    triggerService.pauseExecution();\r\n    int cancelledTaskCount = executionService.clearExecutionsAndQueue();\r\n    logger.info(\"reloading watcher, reason [{}], cancelled [{}] queued tasks\", reason, cancelledTaskCount);\r\n    executor.execute(wrapWatcherService(() -> reloadInner(state, reason, false), e -> logger.error(\"error reloading watcher\", e)));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.drm.ClearKeyUtil.adjustRequestData",
	"Comment": "adjusts clearkey request data obtained from the android clearkey cdm to be spec compliant.",
	"Method": "byte[] adjustRequestData(byte[] request){\r\n    if (Util.SDK_INT >= 27) {\r\n        return request;\r\n    }\r\n    String requestString = Util.fromUtf8Bytes(request);\r\n    return Util.getUtf8Bytes(base64ToBase64Url(requestString));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.TriggeredWatchStoreTests.testLoadingFailsWithTwoAliases",
	"Comment": "make sure that the watch store supports only a single index in an alias",
	"Method": "void testLoadingFailsWithTwoAliases(){\r\n    ClusterState.Builder csBuilder = new ClusterState.Builder(new ClusterName(\"_name\"));\r\n    MetaData.Builder metaDataBuilder = MetaData.builder();\r\n    RoutingTable.Builder routingTableBuilder = RoutingTable.builder();\r\n    metaDataBuilder.put(IndexMetaData.builder(\"triggered-watches-alias\").settings(indexSettings).putAlias(new AliasMetaData.Builder(TriggeredWatchStoreField.INDEX_NAME).build()));\r\n    metaDataBuilder.put(IndexMetaData.builder(\"whatever\").settings(indexSettings).putAlias(new AliasMetaData.Builder(TriggeredWatchStoreField.INDEX_NAME).build()));\r\n    final Index index = metaDataBuilder.get(\"triggered-watches-alias\").getIndex();\r\n    IndexRoutingTable.Builder indexRoutingTableBuilder = IndexRoutingTable.builder(index);\r\n    indexRoutingTableBuilder.addIndexShard(new IndexShardRoutingTable.Builder(new ShardId(index, 0)).addShard(TestShardRouting.newShardRouting(\"triggered-watches-alias\", 0, \"_node_id\", null, true, ShardRoutingState.STARTED)).build());\r\n    indexRoutingTableBuilder.addReplica();\r\n    final Index otherIndex = metaDataBuilder.get(\"whatever\").getIndex();\r\n    IndexRoutingTable.Builder otherIndexRoutingTableBuilder = IndexRoutingTable.builder(otherIndex);\r\n    otherIndexRoutingTableBuilder.addIndexShard(new IndexShardRoutingTable.Builder(new ShardId(index, 0)).addShard(TestShardRouting.newShardRouting(\"whatever\", 0, \"_node_id\", null, true, ShardRoutingState.STARTED)).build());\r\n    csBuilder.metaData(metaDataBuilder);\r\n    csBuilder.routingTable(routingTableBuilder.build());\r\n    ClusterState cs = csBuilder.build();\r\n    IllegalStateException e = expectThrows(IllegalStateException.class, () -> TriggeredWatchStore.validate(cs));\r\n    assertThat(e.getMessage(), is(\"Alias [.triggered_watches] points to more than one index\"));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.diagnostics.DataStreamDiagnosticsTests.testEmptyBucketsLongerOutage",
	"Comment": "send signals, then make a long pause, send another signal and then checkwhether counts are right.",
	"Method": "void testEmptyBucketsLongerOutage(){\r\n    DataStreamDiagnostics d = new DataStreamDiagnostics(job, dataCounts);\r\n    d.checkRecord(10000);\r\n    d.checkRecord(70000);\r\n    d.checkRecord(190000);\r\n    d.checkRecord(250000);\r\n    d.checkRecord(310000);\r\n    d.checkRecord(370000);\r\n    d.checkRecord(490000);\r\n    d.checkRecord(550000);\r\n    d.checkRecord(6490000);\r\n    d.flush();\r\n    assertEquals(108, d.getBucketCount());\r\n    assertEquals(100, d.getEmptyBucketCount());\r\n    assertEquals(0, d.getSparseBucketCount());\r\n    assertEquals(null, d.getLatestSparseBucketTime());\r\n    assertEquals(new Date(6420000), d.getLatestEmptyBucketTime());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.action.AbstractSqlQueryRequest.filter",
	"Comment": "an optional query dsl defined query that can added as a filter on the top of the sql query",
	"Method": "AbstractSqlQueryRequest filter(QueryBuilder filter,QueryBuilder filter){\r\n    return filter;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.getFromHeader",
	"Comment": "gets the token from the authorization header if the header begins withbearer",
	"Method": "String getFromHeader(ThreadContext threadContext){\r\n    String header = threadContext.getHeader(\"Authorization\");\r\n    if (Strings.hasText(header) && header.regionMatches(true, 0, \"Bearer \", 0, \"Bearer \".length()) && header.length() > \"Bearer \".length()) {\r\n        return header.substring(\"Bearer \".length());\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.TestsSSLService.sslContext",
	"Comment": "allows to get alternative ssl context, like for the http client",
	"Method": "SSLContext sslContext(SSLContext sslContext,Settings settings,SSLContext sslContext,String context){\r\n    return sslContextHolder(super.getSSLConfiguration(context)).sslContext();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.chunk.DataChunk.getDataHolder",
	"Comment": "returns the array in which the data is held.this method should be used for recycling the holder only, and not for reading the data.",
	"Method": "byte[] getDataHolder(){\r\n    return data;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.watch.WatchStatus.onCheck",
	"Comment": "called whenever an watch is checked, ie. the condition of the watch is evaluated to see ifthe watch should be executed.",
	"Method": "void onCheck(boolean metCondition,DateTime timestamp){\r\n    lastChecked = timestamp;\r\n    if (metCondition) {\r\n        lastMetCondition = timestamp;\r\n    } else {\r\n        for (ActionStatus status : actions.values()) {\r\n            status.resetAckStatus(timestamp);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.datafeed.ProblemTracker.reportProblem",
	"Comment": "reports the problem if it is different than the last seen problem",
	"Method": "void reportProblem(String template,String problemMessage){\r\n    hasProblems = true;\r\n    if (!Objects.equals(previousProblem, problemMessage)) {\r\n        previousProblem = problemMessage;\r\n        auditor.error(jobId, Messages.getMessage(template, problemMessage));\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.action.SqlQueryRequest.cursor",
	"Comment": "the key that must be sent back to sql to access the next page ofresults.",
	"Method": "String cursor(SqlQueryRequest cursor,String cursor){\r\n    if (cursor == null) {\r\n        throw new IllegalArgumentException(\"cursor may not be null.\");\r\n    }\r\n    this.cursor = cursor;\r\n    return this;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.DtsUtil.parseDtsAudioSampleCount",
	"Comment": "returns the number of audio samples represented by the given dts frame.",
	"Method": "int parseDtsAudioSampleCount(byte[] data,int parseDtsAudioSampleCount,ByteBuffer buffer){\r\n    int position = buffer.position();\r\n    int nblks;\r\n    switch(buffer.get(position)) {\r\n        case FIRST_BYTE_LE:\r\n            nblks = ((buffer.get(position + 5) & 0x01) << 6) | ((buffer.get(position + 4) & 0xFC) >> 2);\r\n            break;\r\n        case FIRST_BYTE_14B_LE:\r\n            nblks = ((buffer.get(position + 4) & 0x07) << 4) | ((buffer.get(position + 7) & 0x3C) >> 2);\r\n            break;\r\n        case FIRST_BYTE_14B_BE:\r\n            nblks = ((buffer.get(position + 5) & 0x07) << 4) | ((buffer.get(position + 6) & 0x3C) >> 2);\r\n            break;\r\n        default:\r\n            nblks = ((buffer.get(position + 4) & 0x01) << 6) | ((buffer.get(position + 5) & 0xFC) >> 2);\r\n    }\r\n    return (nblks + 1) * 32;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.DataCountsReporter.reportRecordWritten",
	"Comment": "increment the number of records written by 1 and incrementthe total number of fields read.",
	"Method": "void reportRecordWritten(long inputFieldCount,long recordTimeMs){\r\n    Date recordDate = new Date(recordTimeMs);\r\n    totalRecordStats.incrementInputFieldCount(inputFieldCount);\r\n    totalRecordStats.incrementProcessedRecordCount(1);\r\n    totalRecordStats.setLatestRecordTimeStamp(recordDate);\r\n    incrementalRecordStats.incrementInputFieldCount(inputFieldCount);\r\n    incrementalRecordStats.incrementProcessedRecordCount(1);\r\n    incrementalRecordStats.setLatestRecordTimeStamp(recordDate);\r\n    boolean isFirstReport = totalRecordStats.getEarliestRecordTimeStamp() == null;\r\n    if (isFirstReport) {\r\n        totalRecordStats.setEarliestRecordTimeStamp(recordDate);\r\n        incrementalRecordStats.setEarliestRecordTimeStamp(recordDate);\r\n    }\r\n    long totalRecords = getInputRecordCount();\r\n    if (reportingBoundaryFunction.apply(totalRecords)) {\r\n        logStatus(totalRecords);\r\n    }\r\n    diagnostics.checkRecord(recordTimeMs);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authz.privilege.ApplicationPrivilege.validatePrivilegeOrActionName",
	"Comment": "validate that the provided name is a valid privilege name or action name, and throws an exception otherwise",
	"Method": "void validatePrivilegeOrActionName(String name){\r\n    if (VALID_NAME_OR_ACTION.matcher(name).matches() == false) {\r\n        throw new IllegalArgumentException(\"Application privilege names and actions must match the pattern \" + VALID_NAME_OR_ACTION.pattern() + \" (found '\" + name + \"')\");\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.SimpleExoPlayer.setTextOutput",
	"Comment": "sets an output to receive text events, removing all existing outputs.",
	"Method": "void setTextOutput(TextOutput output){\r\n    textOutputs.clear();\r\n    if (output != null) {\r\n        addTextOutput(output);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.diagnostics.DataStreamDiagnosticsTests.testSparseBucketsLastTwo",
	"Comment": "test for sparsity on the last 2 buckets, should create a sparse bucketsignal on the 2nd to last",
	"Method": "void testSparseBucketsLastTwo(){\r\n    DataStreamDiagnostics d = new DataStreamDiagnostics(job, dataCounts);\r\n    sendManyDataPoints(d, 10000, 69000, 1000);\r\n    sendManyDataPoints(d, 70000, 129000, 1200);\r\n    sendManyDataPoints(d, 130000, 189000, 1);\r\n    sendManyDataPoints(d, 190000, 249000, 1100);\r\n    sendManyDataPoints(d, 250000, 309000, 1300);\r\n    sendManyDataPoints(d, 310000, 369000, 1050);\r\n    sendManyDataPoints(d, 370000, 429000, 1022);\r\n    sendManyDataPoints(d, 430000, 489000, 1400);\r\n    sendManyDataPoints(d, 490000, 549000, 9);\r\n    sendManyDataPoints(d, 550000, 609000, 10);\r\n    d.flush();\r\n    assertEquals(9, d.getBucketCount());\r\n    assertEquals(0, d.getEmptyBucketCount());\r\n    assertEquals(2, d.getSparseBucketCount());\r\n    assertEquals(new Date(480000), d.getLatestSparseBucketTime());\r\n    assertEquals(null, d.getLatestEmptyBucketTime());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherIndexingListener.isWatchDocument",
	"Comment": "check if a supplied index and document matches the current configuration for watcher",
	"Method": "boolean isWatchDocument(String index,String docType){\r\n    return configuration.isIndexAndActive(index) && docType.equals(Watch.DOC_TYPE);\r\n}"
}, {
	"Path": "com.alibaba.fastjson.util.AntiCollisionHashMap.containsKey",
	"Comment": "returns true if this map contains a mapping for the specifiedkey.",
	"Method": "boolean containsKey(Object key){\r\n    return getEntry(key) != null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.getAuthenticationAndMetaData",
	"Comment": "reads the authentication and metadata from the given token.this method does not validate whether the token is expired or not.",
	"Method": "void getAuthenticationAndMetaData(String token,ActionListener<Tuple<Authentication, Map<String, Object>>> listener){\r\n    decodeToken(token, ActionListener.wrap(userToken -> {\r\n        if (userToken == null) {\r\n            listener.onFailure(new ElasticsearchSecurityException(\"supplied token is not valid\"));\r\n        } else {\r\n            listener.onResponse(new Tuple(userToken.getAuthentication(), userToken.getMetadata()));\r\n        }\r\n    }, listener::onFailure));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.codecNeedsMonoChannelCountWorkaround",
	"Comment": "returns whether the decoder is known to set the number of audio channels in the output formatto 2 for the given input format, whilst only actually outputting a single channel.if true is returned then we explicitly override the number of channels in the output format,setting it to 1.",
	"Method": "boolean codecNeedsMonoChannelCountWorkaround(String name,Format format){\r\n    return Util.SDK_INT <= 18 && format.channelCount == 1 && \"OMX.MTK.AUDIO.DECODER.MP3\".equals(name);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.DecoderCountersUtil.getTotalBufferCount",
	"Comment": "returns the sum of the skipped, dropped and rendered buffers.",
	"Method": "int getTotalBufferCount(DecoderCounters counters){\r\n    counters.ensureUpdated();\r\n    return counters.skippedOutputBufferCount + counters.droppedBufferCount + counters.renderedOutputBufferCount;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.amr.AmrExtractor.peekAmrSignature",
	"Comment": "peeks from the beginning of the input to see if the given amr signature exists.",
	"Method": "boolean peekAmrSignature(ExtractorInput input,byte[] amrSignature){\r\n    input.resetPeekPosition();\r\n    byte[] header = new byte[amrSignature.length];\r\n    input.peekFully(header, 0, amrSignature.length);\r\n    return Arrays.equals(header, amrSignature);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.ExecutionService.clearExecutions",
	"Comment": "this clears out the current executions and sets new empty current executionsthis is needed, because when this method is called, watcher keeps running, so sealing executions would be a bad idea",
	"Method": "void clearExecutions(){\r\n    final CurrentExecutions currentExecutionsBeforeSetting = currentExecutions.getAndSet(new CurrentExecutions());\r\n    genericExecutor.execute(() -> currentExecutionsBeforeSetting.sealAndAwaitEmpty(maxStopTimeout));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.upgrade.UpgradeField.checkInternalIndexFormat",
	"Comment": "checks the format of an internal index and returns true if the index is up to date or false if upgrade is required",
	"Method": "boolean checkInternalIndexFormat(IndexMetaData indexMetaData){\r\n    return indexMetaData.getSettings().getAsInt(IndexMetaData.INDEX_FORMAT_SETTING.getKey(), 0) == EXPECTED_INDEX_FORMAT_VERSION;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerView.setControllerHideOnTouch",
	"Comment": "sets whether the playback controls are hidden by touch events.",
	"Method": "void setControllerHideOnTouch(boolean controllerHideOnTouch){\r\n    Assertions.checkState(controller != null);\r\n    this.controllerHideOnTouch = controllerHideOnTouch;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.AbstractConcatenatedTimeline.getChildPeriodUidFromConcatenatedUid",
	"Comment": "returns uid of the period in the child timeline from a concatenated period uid.",
	"Method": "Object getChildPeriodUidFromConcatenatedUid(Object concatenatedUid){\r\n    return ((Pair<?, ?>) concatenatedUid).second;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherIndexingListener.clusterChanged",
	"Comment": "listen for cluster state changes. this method will start, stop or reload the watcherservice based on cluster state information.the method checks, if there are local watch indices up and running.",
	"Method": "void clusterChanged(ClusterChangedEvent event){\r\n    if (Strings.isNullOrEmpty(event.state().nodes().getMasterNodeId()) || event.state().getBlocks().hasGlobalBlock(ClusterBlockLevel.WRITE)) {\r\n        configuration = INACTIVE;\r\n        return;\r\n    }\r\n    if (event.state().nodes().getLocalNode().isDataNode() && event.metaDataChanged()) {\r\n        try {\r\n            IndexMetaData metaData = WatchStoreUtils.getConcreteIndex(Watch.INDEX, event.state().metaData());\r\n            if (metaData == null) {\r\n                configuration = INACTIVE;\r\n            } else {\r\n                checkWatchIndexHasChanged(metaData, event);\r\n            }\r\n        } catch (IllegalStateException e) {\r\n            logger.error(\"error loading watches index: [{}]\", e.getMessage());\r\n            configuration = INACTIVE;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLService.getLoadedSSLConfigurations",
	"Comment": "accessor to the loaded ssl configuration objects at the current point in time. this is useful for testing",
	"Method": "Collection<SSLConfiguration> getLoadedSSLConfigurations(){\r\n    return Collections.unmodifiableSet(new HashSet(sslContexts.keySet()));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.readUnsignedIntToInt",
	"Comment": "reads the next four bytes as an unsigned integer into an integer, if the top bit is a zero.",
	"Method": "int readUnsignedIntToInt(){\r\n    int result = readInt();\r\n    if (result < 0) {\r\n        throw new IllegalStateException(\"Top bit not zero: \" + result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.Label.resolve",
	"Comment": "resolves all forward references to this label. this method must be called when this label is added to thebytecode of the method, i.e. when its position becomes known. this method fills in the blanks that where left inthe bytecode by each forward reference previously added to this label.",
	"Method": "void resolve(MethodWriter owner,int position,byte[] data){\r\n    this.status |= 2;\r\n    this.position = position;\r\n    int i = 0;\r\n    while (i < referenceCount) {\r\n        int source = srcAndRefPositions[i++];\r\n        int reference = srcAndRefPositions[i++];\r\n        int offset = position - source;\r\n        data[reference++] = (byte) (offset >>> 8);\r\n        data[reference] = (byte) offset;\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.Util.splitCodecs",
	"Comment": "splits a codecs sequence string, as defined in rfc 6381, into individual codec strings.",
	"Method": "String[] splitCodecs(String codecs){\r\n    if (TextUtils.isEmpty(codecs)) {\r\n        return new String[0];\r\n    }\r\n    return split(codecs.trim(), \"(\\\\s*,\\\\s*)\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.cli.command.AbstractServerCliCommand.handleExceptionWhileCommunicatingWithServer",
	"Comment": "handle an exception while communication with the server. extractedinto a method so that tests can bubble the failure.",
	"Method": "void handleExceptionWhileCommunicatingWithServer(CliTerminal terminal,CliSession cliSession,RuntimeException e){\r\n    terminal.line().error(\"Communication error [\").param(e.getMessage() == null ? e.getClass().getName() : e.getMessage()).error(\"]\").ln();\r\n    if (cliSession.isDebug()) {\r\n        terminal.printStackTrace(e);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.DefaultHttpDataSource.makeConnection",
	"Comment": "establishes a connection, following redirects to do so where permitted.",
	"Method": "HttpURLConnection makeConnection(DataSpec dataSpec,HttpURLConnection makeConnection,URL url,int httpMethod,byte[] httpBody,long position,long length,boolean allowGzip,boolean followRedirects){\r\n    HttpURLConnection connection = (HttpURLConnection) url.openConnection();\r\n    connection.setConnectTimeout(connectTimeoutMillis);\r\n    connection.setReadTimeout(readTimeoutMillis);\r\n    if (defaultRequestProperties != null) {\r\n        for (Map.Entry<String, String> property : defaultRequestProperties.getSnapshot().entrySet()) {\r\n            connection.setRequestProperty(property.getKey(), property.getValue());\r\n        }\r\n    }\r\n    for (Map.Entry<String, String> property : requestProperties.getSnapshot().entrySet()) {\r\n        connection.setRequestProperty(property.getKey(), property.getValue());\r\n    }\r\n    if (!(position == 0 && length == C.LENGTH_UNSET)) {\r\n        String rangeRequest = \"bytes=\" + position + \"-\";\r\n        if (length != C.LENGTH_UNSET) {\r\n            rangeRequest += (position + length - 1);\r\n        }\r\n        connection.setRequestProperty(\"Range\", rangeRequest);\r\n    }\r\n    connection.setRequestProperty(\"User-Agent\", userAgent);\r\n    if (!allowGzip) {\r\n        connection.setRequestProperty(\"Accept-Encoding\", \"identity\");\r\n    }\r\n    connection.setInstanceFollowRedirects(followRedirects);\r\n    connection.setDoOutput(httpBody != null);\r\n    connection.setRequestMethod(DataSpec.getStringForHttpMethod(httpMethod));\r\n    if (httpBody != null) {\r\n        connection.setFixedLengthStreamingMode(httpBody.length);\r\n        connection.connect();\r\n        OutputStream os = connection.getOutputStream();\r\n        os.write(httpBody);\r\n        os.close();\r\n    } else {\r\n        connection.connect();\r\n    }\r\n    return connection;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authc.support.BCrypt.checkpw",
	"Comment": "check that a plaintext password matches a previously hashedone.modified from the original to take a securestring plaintext and use a constant time comparison",
	"Method": "boolean checkpw(SecureString plaintext,String hashed){\r\n    return CharArrays.constantTimeEquals(hashed, hashpw(plaintext, hashed));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.diagnostics.DataStreamDiagnostics.flush",
	"Comment": "flush all counters, should be called at the end of the data stream",
	"Method": "void flush(){\r\n    bucketDiagnostics.flush();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertGenUtils.generateSignedCertificate",
	"Comment": "generates a signed certificate using the provided ca private key andinformation from the ca certificate",
	"Method": "X509Certificate generateSignedCertificate(X500Principal principal,GeneralNames subjectAltNames,KeyPair keyPair,X509Certificate caCert,PrivateKey caPrivKey,int days,X509Certificate generateSignedCertificate,X500Principal principal,GeneralNames subjectAltNames,KeyPair keyPair,X509Certificate caCert,PrivateKey caPrivKey,int days,String signatureAlgorithm,X509Certificate generateSignedCertificate,X500Principal principal,GeneralNames subjectAltNames,KeyPair keyPair,X509Certificate caCert,PrivateKey caPrivKey,boolean isCa,int days,String signatureAlgorithm){\r\n    Objects.requireNonNull(keyPair, \"Key-Pair must not be null\");\r\n    final DateTime notBefore = new DateTime(DateTimeZone.UTC);\r\n    if (days < 1) {\r\n        throw new IllegalArgumentException(\"the certificate must be valid for at least one day\");\r\n    }\r\n    final DateTime notAfter = notBefore.plusDays(days);\r\n    final BigInteger serial = CertGenUtils.getSerial();\r\n    JcaX509ExtensionUtils extUtils = new JcaX509ExtensionUtils();\r\n    X500Name subject = X500Name.getInstance(principal.getEncoded());\r\n    final X500Name issuer;\r\n    final AuthorityKeyIdentifier authorityKeyIdentifier;\r\n    if (caCert != null) {\r\n        if (caCert.getBasicConstraints() < 0) {\r\n            throw new IllegalArgumentException(\"ca certificate is not a CA!\");\r\n        }\r\n        issuer = X500Name.getInstance(caCert.getIssuerX500Principal().getEncoded());\r\n        authorityKeyIdentifier = extUtils.createAuthorityKeyIdentifier(caCert.getPublicKey());\r\n    } else {\r\n        issuer = subject;\r\n        authorityKeyIdentifier = extUtils.createAuthorityKeyIdentifier(keyPair.getPublic());\r\n    }\r\n    JcaX509v3CertificateBuilder builder = new JcaX509v3CertificateBuilder(issuer, serial, new Time(notBefore.toDate(), Locale.ROOT), new Time(notAfter.toDate(), Locale.ROOT), subject, keyPair.getPublic());\r\n    builder.addExtension(Extension.subjectKeyIdentifier, false, extUtils.createSubjectKeyIdentifier(keyPair.getPublic()));\r\n    builder.addExtension(Extension.authorityKeyIdentifier, false, authorityKeyIdentifier);\r\n    if (subjectAltNames != null) {\r\n        builder.addExtension(Extension.subjectAlternativeName, false, subjectAltNames);\r\n    }\r\n    builder.addExtension(Extension.basicConstraints, isCa, new BasicConstraints(isCa));\r\n    PrivateKey signingKey = caPrivKey != null ? caPrivKey : keyPair.getPrivate();\r\n    ContentSigner signer = new JcaContentSignerBuilder((Strings.isNullOrEmpty(signatureAlgorithm)) ? getDefaultSignatureAlgorithm(signingKey) : signatureAlgorithm).setProvider(CertGenUtils.BC_PROV).build(signingKey);\r\n    X509CertificateHolder certificateHolder = builder.build(signer);\r\n    return new JcaX509CertificateConverter().getCertificate(certificateHolder);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.AudioCapabilitiesReceiver.unregister",
	"Comment": "unregisters the receiver, meaning it will no longer notify the listener when audio capabilitychanges occur.",
	"Method": "void unregister(){\r\n    if (receiver != null) {\r\n        context.unregisterReceiver(receiver);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.ts.AdtsReader.findNextSample",
	"Comment": "locates the next sample start, advancing the position to the byte that immediately followsidentifier. if a sample was not located, the position is advanced to the limit.",
	"Method": "void findNextSample(ParsableByteArray pesBuffer){\r\n    byte[] adtsData = pesBuffer.data;\r\n    int position = pesBuffer.getPosition();\r\n    int endOffset = pesBuffer.limit();\r\n    while (position < endOffset) {\r\n        int data = adtsData[position++] & 0xFF;\r\n        if (matchState == MATCH_STATE_FF && isAdtsSyncBytes((byte) 0xFF, (byte) data)) {\r\n            if (foundFirstFrame || checkSyncPositionValid(pesBuffer, position - 2)) {\r\n                currentFrameVersion = (data & 0x8) >> 3;\r\n                hasCrc = (data & 0x1) == 0;\r\n                if (!foundFirstFrame) {\r\n                    setCheckingAdtsHeaderState();\r\n                } else {\r\n                    setReadingAdtsHeaderState();\r\n                }\r\n                pesBuffer.setPosition(position);\r\n                return;\r\n            }\r\n        }\r\n        switch(matchState | data) {\r\n            case MATCH_STATE_START | 0xFF:\r\n                matchState = MATCH_STATE_FF;\r\n                break;\r\n            case MATCH_STATE_START | 'I':\r\n                matchState = MATCH_STATE_I;\r\n                break;\r\n            case MATCH_STATE_I | 'D':\r\n                matchState = MATCH_STATE_ID;\r\n                break;\r\n            case MATCH_STATE_ID | '3':\r\n                setReadingId3HeaderState();\r\n                pesBuffer.setPosition(position);\r\n                return;\r\n            default:\r\n                if (matchState != MATCH_STATE_START) {\r\n                    matchState = MATCH_STATE_START;\r\n                    position--;\r\n                }\r\n                break;\r\n        }\r\n    }\r\n    pesBuffer.setPosition(position);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.Sonic.previousPeriodBetter",
	"Comment": "returns whether the previous pitch period estimate is a better approximation, which can occurat the abrupt end of voiced words.",
	"Method": "boolean previousPeriodBetter(int minDiff,int maxDiff){\r\n    if (minDiff == 0 || prevPeriod == 0) {\r\n        return false;\r\n    }\r\n    if (maxDiff > minDiff * 3) {\r\n        return false;\r\n    }\r\n    if (minDiff * 2 <= prevMinDiff * 3) {\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.restart.FullClusterRestartIT.testSingleDoc",
	"Comment": "tests that a single document survives. super basic smoke test.",
	"Method": "void testSingleDoc(){\r\n    String docLocation = \"/testsingledoc/doc/1\";\r\n    String doc = \"{\\\"test\\\": \\\"test\\\"}\";\r\n    if (isRunningAgainstOldCluster()) {\r\n        Request createDoc = new Request(\"PUT\", docLocation);\r\n        createDoc.addParameter(\"refresh\", \"true\");\r\n        createDoc.setJsonEntity(doc);\r\n        client().performRequest(createDoc);\r\n    }\r\n    assertThat(toStr(client().performRequest(new Request(\"GET\", docLocation))), containsString(doc));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.MimeTypes.getMediaMimeType",
	"Comment": "derives a mimetype from a codec identifier, as defined in rfc 6381.",
	"Method": "String getMediaMimeType(String codec){\r\n    if (codec == null) {\r\n        return null;\r\n    }\r\n    codec = Util.toLowerInvariant(codec.trim());\r\n    if (codec.startsWith(\"avc1\") || codec.startsWith(\"avc3\")) {\r\n        return MimeTypes.VIDEO_H264;\r\n    } else if (codec.startsWith(\"hev1\") || codec.startsWith(\"hvc1\")) {\r\n        return MimeTypes.VIDEO_H265;\r\n    } else if (codec.startsWith(\"vp9\") || codec.startsWith(\"vp09\")) {\r\n        return MimeTypes.VIDEO_VP9;\r\n    } else if (codec.startsWith(\"vp8\") || codec.startsWith(\"vp08\")) {\r\n        return MimeTypes.VIDEO_VP8;\r\n    } else if (codec.startsWith(\"mp4a\")) {\r\n        String mimeType = null;\r\n        if (codec.startsWith(\"mp4a.\")) {\r\n            String objectTypeString = codec.substring(5);\r\n            if (objectTypeString.length() >= 2) {\r\n                try {\r\n                    String objectTypeHexString = Util.toUpperInvariant(objectTypeString.substring(0, 2));\r\n                    int objectTypeInt = Integer.parseInt(objectTypeHexString, 16);\r\n                    mimeType = getMimeTypeFromMp4ObjectType(objectTypeInt);\r\n                } catch (NumberFormatException ignored) {\r\n                }\r\n            }\r\n        }\r\n        return mimeType == null ? MimeTypes.AUDIO_AAC : mimeType;\r\n    } else if (codec.startsWith(\"ac-3\") || codec.startsWith(\"dac3\")) {\r\n        return MimeTypes.AUDIO_AC3;\r\n    } else if (codec.startsWith(\"ec-3\") || codec.startsWith(\"dec3\")) {\r\n        return MimeTypes.AUDIO_E_AC3;\r\n    } else if (codec.startsWith(\"ec+3\")) {\r\n        return MimeTypes.AUDIO_E_AC3_JOC;\r\n    } else if (codec.startsWith(\"dtsc\") || codec.startsWith(\"dtse\")) {\r\n        return MimeTypes.AUDIO_DTS;\r\n    } else if (codec.startsWith(\"dtsh\") || codec.startsWith(\"dtsl\")) {\r\n        return MimeTypes.AUDIO_DTS_HD;\r\n    } else if (codec.startsWith(\"opus\")) {\r\n        return MimeTypes.AUDIO_OPUS;\r\n    } else if (codec.startsWith(\"vorbis\")) {\r\n        return MimeTypes.AUDIO_VORBIS;\r\n    } else if (codec.startsWith(\"flac\")) {\r\n        return MimeTypes.AUDIO_FLAC;\r\n    } else {\r\n        return getCustomMimeTypeForCodec(codec);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.protocol.AbstractHlrcStreamableXContentTestCase.doParseInstance",
	"Comment": "are only there for testing and could go away? then the additional testhlrcfromxcontent is also no longer needed.",
	"Method": "T doParseInstance(XContentParser parser){\r\n    return convertHlrcToInternal(doHlrcParseInstance(parser));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.ExecutionService.getWatch",
	"Comment": "gets a watch but in a synchronous way, so that no async calls need to be built",
	"Method": "GetResponse getWatch(String id){\r\n    try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), WATCHER_ORIGIN)) {\r\n        GetRequest getRequest = new GetRequest(Watch.INDEX, Watch.DOC_TYPE, id).preference(Preference.LOCAL.type()).realtime(true);\r\n        PlainActionFuture<GetResponse> future = PlainActionFuture.newFuture();\r\n        client.get(getRequest, future);\r\n        return future.actionGet();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.template.TemplateUtils.checkTemplateExistsAndVersionIsGTECurrentVersion",
	"Comment": "checks if a versioned template exists, and if it exists checks if the version is greater than or equal to the current version.",
	"Method": "boolean checkTemplateExistsAndVersionIsGTECurrentVersion(String templateName,ClusterState state){\r\n    IndexTemplateMetaData templateMetaData = state.metaData().templates().get(templateName);\r\n    if (templateMetaData == null) {\r\n        return false;\r\n    }\r\n    return templateMetaData.version() != null && templateMetaData.version() >= Version.CURRENT.id;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.SecurityContext.executeAsUser",
	"Comment": "runs the consumer in a new context as the provided user. the original context is provided to the consumer. when this methodreturns, the original context is restored.",
	"Method": "void executeAsUser(User user,Consumer<StoredContext> consumer,Version version){\r\n    final StoredContext original = threadContext.newStoredContext(true);\r\n    try (ThreadContext.StoredContext ctx = threadContext.stashContext()) {\r\n        setUser(user, version);\r\n        consumer.accept(original);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.vp9.VpxOutputBuffer.initForYuvFrame",
	"Comment": "resizes the buffer based on the given stride. called via jni after decoding completes.",
	"Method": "boolean initForYuvFrame(int width,int height,int yStride,int uvStride,int colorspace){\r\n    this.width = width;\r\n    this.height = height;\r\n    this.colorspace = colorspace;\r\n    int uvHeight = (int) (((long) height + 1) / 2);\r\n    if (!isSafeToMultiply(yStride, height) || !isSafeToMultiply(uvStride, uvHeight)) {\r\n        return false;\r\n    }\r\n    int yLength = yStride * height;\r\n    int uvLength = uvStride * uvHeight;\r\n    int minimumYuvSize = yLength + (uvLength * 2);\r\n    if (!isSafeToMultiply(uvLength, 2) || minimumYuvSize < yLength) {\r\n        return false;\r\n    }\r\n    initData(minimumYuvSize);\r\n    if (yuvPlanes == null) {\r\n        yuvPlanes = new ByteBuffer[3];\r\n    }\r\n    yuvPlanes[0] = data.slice();\r\n    yuvPlanes[0].limit(yLength);\r\n    data.position(yLength);\r\n    yuvPlanes[1] = data.slice();\r\n    yuvPlanes[1].limit(uvLength);\r\n    data.position(yLength + uvLength);\r\n    yuvPlanes[2] = data.slice();\r\n    yuvPlanes[2].limit(uvLength);\r\n    if (yuvStrides == null) {\r\n        yuvStrides = new int[3];\r\n    }\r\n    yuvStrides[0] = yStride;\r\n    yuvStrides[1] = uvStride;\r\n    yuvStrides[2] = uvStride;\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.collector.Collector.shouldCollect",
	"Comment": "indicates if the current collector is allowed to collect data",
	"Method": "boolean shouldCollect(boolean isElectedMaster){\r\n    if (licenseState.isMonitoringAllowed() == false) {\r\n        logger.trace(\"collector [{}] can not collect data due to invalid license\", name());\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.expression.function.UnresolvedFunction.buildResolved",
	"Comment": "build a function to replace this one after resolving the function.",
	"Method": "Function buildResolved(Configuration configuration,FunctionDefinition def){\r\n    return resolutionType.buildResolved(this, configuration, def);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.wav.WavHeader.setDataBounds",
	"Comment": "sets the data start position and size in bytes of sample data in this wav.",
	"Method": "void setDataBounds(long dataStartPosition,long dataSize){\r\n    this.dataStartPosition = dataStartPosition;\r\n    this.dataSize = dataSize;\r\n}"
}, {
	"Path": "org.greenrobot.eventbus.annotationprocessor.EventBusAnnotationProcessor.checkForSubscribersToSkip",
	"Comment": "subscriber classes should be skipped if their class or any involved event class are not visible to the index.",
	"Method": "void checkForSubscribersToSkip(Messager messager,String myPackage){\r\n    for (TypeElement skipCandidate : methodsByClass.keySet()) {\r\n        TypeElement subscriberClass = skipCandidate;\r\n        while (subscriberClass != null) {\r\n            if (!isVisible(myPackage, subscriberClass)) {\r\n                boolean added = classesToSkip.add(skipCandidate);\r\n                if (added) {\r\n                    String msg;\r\n                    if (subscriberClass.equals(skipCandidate)) {\r\n                        msg = \"Falling back to reflection because class is not public\";\r\n                    } else {\r\n                        msg = \"Falling back to reflection because \" + skipCandidate + \" has a non-public super class\";\r\n                    }\r\n                    messager.printMessage(Diagnostic.Kind.NOTE, msg, subscriberClass);\r\n                }\r\n                break;\r\n            }\r\n            List<ExecutableElement> methods = methodsByClass.get(subscriberClass);\r\n            if (methods != null) {\r\n                for (ExecutableElement method : methods) {\r\n                    String skipReason = null;\r\n                    VariableElement param = method.getParameters().get(0);\r\n                    TypeMirror typeMirror = getParamTypeMirror(param, messager);\r\n                    if (!(typeMirror instanceof DeclaredType) || !(((DeclaredType) typeMirror).asElement() instanceof TypeElement)) {\r\n                        skipReason = \"event type cannot be processed\";\r\n                    }\r\n                    if (skipReason == null) {\r\n                        TypeElement eventTypeElement = (TypeElement) ((DeclaredType) typeMirror).asElement();\r\n                        if (!isVisible(myPackage, eventTypeElement)) {\r\n                            skipReason = \"event type is not public\";\r\n                        }\r\n                    }\r\n                    if (skipReason != null) {\r\n                        boolean added = classesToSkip.add(skipCandidate);\r\n                        if (added) {\r\n                            String msg = \"Falling back to reflection because \" + skipReason;\r\n                            if (!subscriberClass.equals(skipCandidate)) {\r\n                                msg += \" (found in super class for \" + skipCandidate + \")\";\r\n                            }\r\n                            messager.printMessage(Diagnostic.Kind.NOTE, msg, param);\r\n                        }\r\n                        break;\r\n                    }\r\n                }\r\n            }\r\n            subscriberClass = getSuperclass(subscriberClass);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.expression.UnresolvedAttributeTests.randomUnresolvedMessage",
	"Comment": "a random qualifier. it is important that this be distinctfrom the name and the qualifier for testing transform.",
	"Method": "String randomUnresolvedMessage(){\r\n    return randomAlphaOfLength(7);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.cast.CastPlayer.updateTimeline",
	"Comment": "updates the current timeline and returns whether it has changed.",
	"Method": "boolean updateTimeline(){\r\n    CastTimeline oldTimeline = currentTimeline;\r\n    MediaStatus status = getMediaStatus();\r\n    currentTimeline = status != null ? timelineTracker.getCastTimeline(status) : CastTimeline.EMPTY_CAST_TIMELINE;\r\n    return !oldTimeline.equals(currentTimeline);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.expression.gen.script.Params.asCodeNames",
	"Comment": "return vars and aggs in the declared order for binding them to the script",
	"Method": "List<String> asCodeNames(){\r\n    if (params.isEmpty()) {\r\n        return emptyList();\r\n    }\r\n    List<String> names = new ArrayList(params.size());\r\n    int aggs = 0, vars = 0;\r\n    for (Param<?> p : params) {\r\n        names.add(p.prefix() + (p instanceof Agg ? aggs++ : vars++));\r\n    }\r\n    return names;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.notification.pagerduty.PagerDutyAccountsTests.testContextIsSentCorrect",
	"Comment": "the pagerduty api accepts any json, thus this was never caught",
	"Method": "void testContextIsSentCorrect(){\r\n    Settings.Builder builder = Settings.builder().put(\"xpack.notification.pagerduty.default_account\", \"account1\");\r\n    addAccountSettings(\"account1\", builder);\r\n    PagerDutyService service = new PagerDutyService(builder.build(), httpClient, new ClusterSettings(Settings.EMPTY, new HashSet(PagerDutyService.getSettings())));\r\n    PagerDutyAccount account = service.getAccount(\"account1\");\r\n    ArgumentCaptor<HttpRequest> argumentCaptor = ArgumentCaptor.forClass(HttpRequest.class);\r\n    when(httpClient.execute(argumentCaptor.capture())).thenReturn(new HttpResponse(200));\r\n    IncidentEventContext[] contexts = { IncidentEventContext.link(\"https://www.elastic.co/products/x-pack/alerting\", \"Go to the Elastic.co Alerting website\"), IncidentEventContext.image(\"https://www.elastic.co/assets/blte5d899fd0b0e6808/icon-alerting-bb.svg\", \"https://www.elastic.co/products/x-pack/alerting\", \"X-Pack-Alerting website link with log\") };\r\n    IncidentEvent event = new IncidentEvent(\"foo\", null, null, null, null, account.getName(), true, contexts, HttpProxy.NO_PROXY);\r\n    account.send(event, Payload.EMPTY, null);\r\n    HttpRequest request = argumentCaptor.getValue();\r\n    ObjectPath source = ObjectPath.createFromXContent(JsonXContent.jsonXContent, new BytesArray(request.body()));\r\n    assertThat(source.evaluate(\"contexts\"), nullValue());\r\n    assertThat(source.evaluate(\"links\"), notNullValue());\r\n    assertThat(source.evaluate(\"images\"), notNullValue());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.dash.offline.DashDownloadHelper.getManifest",
	"Comment": "returns the dash manifest. must not be called until after preparation completes.",
	"Method": "DashManifest getManifest(){\r\n    Assertions.checkNotNull(manifest);\r\n    return manifest;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.jdbc.PreparedQuery.params",
	"Comment": "returns the parameters if the sql statement is parametrized",
	"Method": "List<SqlTypedParamValue> params(){\r\n    return Arrays.stream(this.params).map(paramInfo -> new SqlTypedParamValue(paramInfo.type.name(), paramInfo.value)).collect(Collectors.toList());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.DebugTextViewHelper.getPlayerStateString",
	"Comment": "returns a string containing player state debugging information.",
	"Method": "String getPlayerStateString(){\r\n    String playbackStateString;\r\n    switch(player.getPlaybackState()) {\r\n        case Player.STATE_BUFFERING:\r\n            playbackStateString = \"buffering\";\r\n            break;\r\n        case Player.STATE_ENDED:\r\n            playbackStateString = \"ended\";\r\n            break;\r\n        case Player.STATE_IDLE:\r\n            playbackStateString = \"idle\";\r\n            break;\r\n        case Player.STATE_READY:\r\n            playbackStateString = \"ready\";\r\n            break;\r\n        default:\r\n            playbackStateString = \"unknown\";\r\n            break;\r\n    }\r\n    return String.format(\"playWhenReady:%s playbackState:%s window:%s\", player.getPlayWhenReady(), playbackStateString, player.getCurrentWindowIndex());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.ffmpeg.FfmpegLibrary.getVersion",
	"Comment": "returns the version of the underlying library if available, or null otherwise.",
	"Method": "String getVersion(){\r\n    return isAvailable() ? ffmpegGetVersion() : null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.updateQueuedPeriods",
	"Comment": "updates media periods in the queue to take into account the latest timeline, and returnswhether the timeline change has been fully handled. if not, it is necessary to seek to thecurrent playback position. the method assumes that the first media period in the queue is stillconsistent with the new timeline.",
	"Method": "boolean updateQueuedPeriods(MediaPeriodId playingPeriodId,long rendererPositionUs){\r\n    int periodIndex = timeline.getIndexOfPeriod(playingPeriodId.periodUid);\r\n    MediaPeriodHolder previousPeriodHolder = null;\r\n    MediaPeriodHolder periodHolder = getFrontPeriod();\r\n    while (periodHolder != null) {\r\n        if (previousPeriodHolder == null) {\r\n            periodHolder.info = getUpdatedMediaPeriodInfo(periodHolder.info);\r\n        } else {\r\n            if (periodIndex == C.INDEX_UNSET || !periodHolder.uid.equals(timeline.getUidOfPeriod(periodIndex))) {\r\n                return !removeAfter(previousPeriodHolder);\r\n            }\r\n            MediaPeriodInfo periodInfo = getFollowingMediaPeriodInfo(previousPeriodHolder, rendererPositionUs);\r\n            if (periodInfo == null) {\r\n                return !removeAfter(previousPeriodHolder);\r\n            }\r\n            periodHolder.info = getUpdatedMediaPeriodInfo(periodHolder.info);\r\n            if (!canKeepMediaPeriodHolder(periodHolder, periodInfo)) {\r\n                return !removeAfter(previousPeriodHolder);\r\n            }\r\n        }\r\n        if (periodHolder.info.isLastInTimelinePeriod) {\r\n            periodIndex = timeline.getNextPeriodIndex(periodIndex, period, window, repeatMode, shuffleModeEnabled);\r\n        }\r\n        previousPeriodHolder = periodHolder;\r\n        periodHolder = periodHolder.next;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.ts.Ac3Reader.skipToNextSync",
	"Comment": "locates the next syncword, advancing the position to the byte that immediately follows it. if asyncword was not located, the position is advanced to the limit.",
	"Method": "boolean skipToNextSync(ParsableByteArray pesBuffer){\r\n    while (pesBuffer.bytesLeft() > 0) {\r\n        if (!lastByteWas0B) {\r\n            lastByteWas0B = pesBuffer.readUnsignedByte() == 0x0B;\r\n            continue;\r\n        }\r\n        int secondByte = pesBuffer.readUnsignedByte();\r\n        if (secondByte == 0x77) {\r\n            lastByteWas0B = false;\r\n            return true;\r\n        } else {\r\n            lastByteWas0B = secondByte == 0x0B;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.categorization.CategorizationAnalyzer.tokenizeField",
	"Comment": "given a field value, convert it to a list of tokens using the configured analyzer.",
	"Method": "List<String> tokenizeField(String fieldName,String fieldValue){\r\n    List<String> tokens = new ArrayList();\r\n    try (TokenStream stream = analyzer.tokenStream(fieldName, fieldValue)) {\r\n        stream.reset();\r\n        CharTermAttribute term = stream.addAttribute(CharTermAttribute.class);\r\n        while (stream.incrementToken()) {\r\n            String token = term.toString();\r\n            if (token.isEmpty() == false) {\r\n                tokens.add(term.toString());\r\n            }\r\n        }\r\n        stream.end();\r\n    } catch (IOException e) {\r\n        throw new ElasticsearchException(\"Failed to analyze value [\" + fieldValue + \"] of field [\" + fieldName + \"]\", e);\r\n    }\r\n    return tokens;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authz.store.FileRolesStoreTests.testDefaultRolesFile",
	"Comment": "this test is mainly to make sure we can read the default roles.yml config",
	"Method": "void testDefaultRolesFile(){\r\n    Path path = getDataPath(\"default_roles.yml\");\r\n    Map<String, RoleDescriptor> roles = FileRolesStore.parseFile(path, logger, Settings.EMPTY, new XPackLicenseState(Settings.EMPTY));\r\n    assertThat(roles, notNullValue());\r\n    assertThat(roles.size(), is(0));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.FileStructureFinderManager.findFileStructure",
	"Comment": "given a stream of data from some file, determine its structure.",
	"Method": "FileStructureFinder findFileStructure(Integer idealSampleLineCount,InputStream fromFile,FileStructureFinder findFileStructure,Integer idealSampleLineCount,InputStream fromFile,FileStructureOverrides overrides,TimeValue timeout,FileStructureFinder findFileStructure,List<String> explanation,int idealSampleLineCount,InputStream fromFile,FileStructureFinder findFileStructure,List<String> explanation,int idealSampleLineCount,InputStream fromFile,FileStructureOverrides overrides,TimeValue timeout){\r\n    try (TimeoutChecker timeoutChecker = new TimeoutChecker(\"structure analysis\", timeout, scheduler)) {\r\n        String charsetName = overrides.getCharset();\r\n        Reader sampleReader;\r\n        if (charsetName != null) {\r\n            sampleReader = new InputStreamReader(fromFile, charsetName);\r\n            explanation.add(\"Using specified character encoding [\" + charsetName + \"]\");\r\n        } else {\r\n            CharsetMatch charsetMatch = findCharset(explanation, fromFile, timeoutChecker);\r\n            charsetName = charsetMatch.getName();\r\n            sampleReader = charsetMatch.getReader();\r\n        }\r\n        Tuple<String, Boolean> sampleInfo = sampleFile(sampleReader, charsetName, MIN_SAMPLE_LINE_COUNT, Math.max(MIN_SAMPLE_LINE_COUNT, idealSampleLineCount), timeoutChecker);\r\n        return makeBestStructureFinder(explanation, sampleInfo.v1(), charsetName, sampleInfo.v2(), overrides, timeoutChecker);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.proto.SqlQueryRequest.cursor",
	"Comment": "the key that must be sent back to sql to access the next page ofresults.",
	"Method": "String cursor(){\r\n    return cursor;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.ffmpeg.FfmpegLibrary.supportsFormat",
	"Comment": "returns whether the underlying library supports the specified mime type.",
	"Method": "boolean supportsFormat(String mimeType,int encoding){\r\n    if (!isAvailable()) {\r\n        return false;\r\n    }\r\n    String codecName = getCodecName(mimeType, encoding);\r\n    return codecName != null && ffmpegHasDecoder(codecName);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.UserSettings.getAuthentication",
	"Comment": "returns the authentication information, or null if the current request has no authentication info.",
	"Method": "Authentication getAuthentication(){\r\n    try {\r\n        return Authentication.readFromContext(threadContext);\r\n    } catch (IOException e) {\r\n        logger.error(\"failed to read authentication\", e);\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.trigger.TriggerService.stats",
	"Comment": "returns some statistics about the watches loaded in the trigger service",
	"Method": "Counters stats(){\r\n    Counters counters = new Counters();\r\n    int watchCount = perWatchStats.size();\r\n    counters.inc(\"count.active\", watchCount);\r\n    counters.inc(\"count.total\", watchCount);\r\n    counters.inc(\"watch.trigger._all.active\", watchCount);\r\n    counters.inc(\"watch.trigger._all.total\", watchCount);\r\n    counters.inc(\"watch.input._all.total\", watchCount);\r\n    counters.inc(\"watch.input._all.active\", watchCount);\r\n    perWatchStats.values().forEach(stats -> {\r\n        if (stats.metadata) {\r\n            counters.inc(\"watch.metadata.active\");\r\n            counters.inc(\"watch.metadata.total\");\r\n        }\r\n        counters.inc(\"watch.trigger.\" + stats.triggerType + \".total\");\r\n        counters.inc(\"watch.trigger.\" + stats.triggerType + \".active\");\r\n        if (Strings.isNullOrEmpty(stats.scheduleType) == false) {\r\n            counters.inc(\"watch.trigger.schedule.\" + stats.scheduleType + \".total\");\r\n            counters.inc(\"watch.trigger.schedule.\" + stats.scheduleType + \".active\");\r\n            counters.inc(\"watch.trigger.schedule._all.total\");\r\n            counters.inc(\"watch.trigger.schedule._all.active\");\r\n        }\r\n        counters.inc(\"watch.input.\" + stats.inputType + \".active\");\r\n        counters.inc(\"watch.input.\" + stats.inputType + \".total\");\r\n        counters.inc(\"watch.condition.\" + stats.conditionType + \".active\");\r\n        counters.inc(\"watch.condition.\" + stats.conditionType + \".total\");\r\n        counters.inc(\"watch.condition._all.total\");\r\n        counters.inc(\"watch.condition._all.active\");\r\n        if (Strings.isNullOrEmpty(stats.transformType) == false) {\r\n            counters.inc(\"watch.transform.\" + stats.transformType + \".active\");\r\n            counters.inc(\"watch.transform.\" + stats.transformType + \".total\");\r\n            counters.inc(\"watch.transform._all.active\");\r\n            counters.inc(\"watch.transform._all.total\");\r\n        }\r\n        for (TriggerWatchStats.ActionStats action : stats.actions) {\r\n            counters.inc(\"watch.action.\" + action.actionType + \".active\");\r\n            counters.inc(\"watch.action.\" + action.actionType + \".total\");\r\n            counters.inc(\"watch.action._all.active\");\r\n            counters.inc(\"watch.action._all.total\");\r\n            if (Strings.isNullOrEmpty(action.conditionType) == false) {\r\n                counters.inc(\"watch.action.condition.\" + action.conditionType + \".active\");\r\n                counters.inc(\"watch.action.condition.\" + action.conditionType + \".total\");\r\n                counters.inc(\"watch.action.condition._all.active\");\r\n                counters.inc(\"watch.action.condition._all.total\");\r\n            }\r\n            if (Strings.isNullOrEmpty(action.transformType) == false) {\r\n                counters.inc(\"watch.action.transform.\" + action.transformType + \".active\");\r\n                counters.inc(\"watch.action.transform.\" + action.transformType + \".total\");\r\n                counters.inc(\"watch.action.transform._all.active\");\r\n                counters.inc(\"watch.action.transform._all.total\");\r\n            }\r\n        }\r\n    });\r\n    return counters;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.getFrontPeriod",
	"Comment": "returns the period holder in the front of the queue which is the playing period holder whenplaying, or null if the queue is empty.",
	"Method": "MediaPeriodHolder getFrontPeriod(){\r\n    return hasPlayingPeriod() ? playing : loading;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.drm.OfflineLicenseHelper.release",
	"Comment": "releases the helper. should be called when the helper is no longer required.",
	"Method": "void release(){\r\n    handlerThread.quit();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateGenerateTool.readPrivateKey",
	"Comment": "helper method to read a private key and support prompting of user for a key. to avoid passwords being placed as an argument wecan prompt the user for their password if we encounter an encrypted key.",
	"Method": "PrivateKey readPrivateKey(String path,char[] password,Terminal terminal,boolean prompt){\r\n    AtomicReference<char[]> passwordReference = new AtomicReference(password);\r\n    try {\r\n        return PemUtils.readPrivateKey(resolvePath(path), () -> {\r\n            if (password != null || prompt == false) {\r\n                return password;\r\n            }\r\n            char[] promptedValue = terminal.readSecret(\"Enter password for CA private key: \");\r\n            passwordReference.set(promptedValue);\r\n            return promptedValue;\r\n        });\r\n    } finally {\r\n        if (passwordReference.get() != null) {\r\n            Arrays.fill(passwordReference.get(), (char) 0);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.drm.WidevineUtil.getLicenseDurationRemainingSec",
	"Comment": "returns license and playback durations remaining in seconds.",
	"Method": "Pair<Long, Long> getLicenseDurationRemainingSec(DrmSession<?> drmSession){\r\n    Map<String, String> keyStatus = drmSession.queryKeyStatus();\r\n    if (keyStatus == null) {\r\n        return null;\r\n    }\r\n    return new Pair(getDurationRemainingSec(keyStatus, PROPERTY_LICENSE_DURATION_REMAINING), getDurationRemainingSec(keyStatus, PROPERTY_PLAYBACK_DURATION_REMAINING));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.cast.CastTimelineTrackerTest.testGetCastTimeline",
	"Comment": "tests that duration of the current media info is correctly propagated to the timeline.",
	"Method": "void testGetCastTimeline(){\r\n    MediaInfo mediaInfo;\r\n    MediaStatus status = mockMediaStatus(new int[] { 1, 2, 3 }, new String[] { \"contentId1\", \"contentId2\", \"contentId3\" }, new long[] { DURATION_1_MS, MediaInfo.UNKNOWN_DURATION, MediaInfo.UNKNOWN_DURATION });\r\n    CastTimelineTracker tracker = new CastTimelineTracker();\r\n    mediaInfo = getMediaInfo(\"contentId1\", DURATION_1_MS);\r\n    Mockito.when(status.getMediaInfo()).thenReturn(mediaInfo);\r\n    TimelineAsserts.assertPeriodDurations(tracker.getCastTimeline(status), C.msToUs(DURATION_1_MS), C.TIME_UNSET, C.TIME_UNSET);\r\n    mediaInfo = getMediaInfo(\"contentId3\", DURATION_3_MS);\r\n    Mockito.when(status.getMediaInfo()).thenReturn(mediaInfo);\r\n    TimelineAsserts.assertPeriodDurations(tracker.getCastTimeline(status), C.msToUs(DURATION_1_MS), C.TIME_UNSET, C.msToUs(DURATION_3_MS));\r\n    mediaInfo = getMediaInfo(\"contentId2\", DURATION_2_MS);\r\n    Mockito.when(status.getMediaInfo()).thenReturn(mediaInfo);\r\n    TimelineAsserts.assertPeriodDurations(tracker.getCastTimeline(status), C.msToUs(DURATION_1_MS), C.msToUs(DURATION_2_MS), C.msToUs(DURATION_3_MS));\r\n    MediaStatus newStatus = mockMediaStatus(new int[] { 4, 1, 5, 3 }, new String[] { \"contentId4\", \"contentId1\", \"contentId5\", \"contentId3\" }, new long[] { MediaInfo.UNKNOWN_DURATION, MediaInfo.UNKNOWN_DURATION, DURATION_5_MS, MediaInfo.UNKNOWN_DURATION });\r\n    mediaInfo = getMediaInfo(\"contentId5\", DURATION_5_MS);\r\n    Mockito.when(newStatus.getMediaInfo()).thenReturn(mediaInfo);\r\n    TimelineAsserts.assertPeriodDurations(tracker.getCastTimeline(newStatus), C.TIME_UNSET, C.msToUs(DURATION_1_MS), C.msToUs(DURATION_5_MS), C.msToUs(DURATION_3_MS));\r\n    mediaInfo = getMediaInfo(\"contentId3\", DURATION_3_MS);\r\n    Mockito.when(newStatus.getMediaInfo()).thenReturn(mediaInfo);\r\n    TimelineAsserts.assertPeriodDurations(tracker.getCastTimeline(newStatus), C.TIME_UNSET, C.msToUs(DURATION_1_MS), C.msToUs(DURATION_5_MS), C.msToUs(DURATION_3_MS));\r\n    mediaInfo = getMediaInfo(\"contentId4\", DURATION_4_MS);\r\n    Mockito.when(newStatus.getMediaInfo()).thenReturn(mediaInfo);\r\n    TimelineAsserts.assertPeriodDurations(tracker.getCastTimeline(newStatus), C.msToUs(DURATION_4_MS), C.msToUs(DURATION_1_MS), C.msToUs(DURATION_5_MS), C.msToUs(DURATION_3_MS));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleMetadataQueue.getRelativeIndex",
	"Comment": "returns the relative index for a given offset from the start of the queue.",
	"Method": "int getRelativeIndex(int offset){\r\n    int relativeIndex = relativeFirstIndex + offset;\r\n    return relativeIndex < capacity ? relativeIndex : relativeIndex - capacity;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.updateShuffleModeEnabled",
	"Comment": "sets whether shuffling is enabled and returns whether the shuffle mode change has been fullyhandled. if not, it is necessary to seek to the current playback position.",
	"Method": "boolean updateShuffleModeEnabled(boolean shuffleModeEnabled){\r\n    this.shuffleModeEnabled = shuffleModeEnabled;\r\n    return updateForPlaybackModeChange();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlSpMetadataBuilder.encryptionCredentials",
	"Comment": "the certificate credential that should be used to send encrypted data to the service provider.",
	"Method": "SamlSpMetadataBuilder encryptionCredentials(Collection<X509Credential> credentials){\r\n    return encryptionCertificates(credentials == null ? Collections.emptyList() : credentials.stream().map(credential -> credential.getEntityCertificate()).collect(Collectors.toList()));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.text.dvb.DvbParser.parseObjectData",
	"Comment": "parses an object data segment, as defined by etsi en 300 743 7.2.5.",
	"Method": "ObjectData parseObjectData(ParsableBitArray data){\r\n    int objectId = data.readBits(16);\r\n    data.skipBits(4);\r\n    int objectCodingMethod = data.readBits(2);\r\n    boolean nonModifyingColorFlag = data.readBit();\r\n    data.skipBits(1);\r\n    byte[] topFieldData = null;\r\n    byte[] bottomFieldData = null;\r\n    if (objectCodingMethod == OBJECT_CODING_STRING) {\r\n        int numberOfCodes = data.readBits(8);\r\n        data.skipBits(numberOfCodes * 16);\r\n    } else if (objectCodingMethod == OBJECT_CODING_PIXELS) {\r\n        int topFieldDataLength = data.readBits(16);\r\n        int bottomFieldDataLength = data.readBits(16);\r\n        if (topFieldDataLength > 0) {\r\n            topFieldData = new byte[topFieldDataLength];\r\n            data.readBytes(topFieldData, 0, topFieldDataLength);\r\n        }\r\n        if (bottomFieldDataLength > 0) {\r\n            bottomFieldData = new byte[bottomFieldDataLength];\r\n            data.readBytes(bottomFieldData, 0, bottomFieldDataLength);\r\n        } else {\r\n            bottomFieldData = topFieldData;\r\n        }\r\n    }\r\n    return new ObjectData(objectId, nonModifyingColorFlag, topFieldData, bottomFieldData);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.exporter.local.LocalExporterIntegTests.checkMonitoringPipelines",
	"Comment": "checks that the monitoring ingest pipelines have been created by the local exporter",
	"Method": "void checkMonitoringPipelines(){\r\n    final Set<String> expectedPipelines = Arrays.stream(PIPELINE_IDS).map(MonitoringTemplateUtils::pipelineName).collect(Collectors.toSet());\r\n    final GetPipelineResponse response = client().admin().cluster().prepareGetPipeline(\"xpack_monitoring_*\").get();\r\n    final Set<String> pipelines = response.pipelines().stream().map(PipelineConfiguration::getId).collect(Collectors.toSet());\r\n    assertEquals(\"Missing expected pipelines\", expectedPipelines, pipelines);\r\n    assertTrue(\"monitoring ingest pipeline not found\", response.isFound());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecUtil.maxH264DecodableFrameSize",
	"Comment": "returns the maximum frame size supported by the default h264 decoder.",
	"Method": "int maxH264DecodableFrameSize(){\r\n    if (maxH264DecodableFrameSize == -1) {\r\n        int result = 0;\r\n        MediaCodecInfo decoderInfo = getDecoderInfo(MimeTypes.VIDEO_H264, false);\r\n        if (decoderInfo != null) {\r\n            for (CodecProfileLevel profileLevel : decoderInfo.getProfileLevels()) {\r\n                result = Math.max(avcLevelToMaxFrameSize(profileLevel.level), result);\r\n            }\r\n            result = Math.max(result, Util.SDK_INT >= 21 ? (720 * 480) : (480 * 360));\r\n        }\r\n        maxH264DecodableFrameSize = result;\r\n    }\r\n    return maxH264DecodableFrameSize;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.spherical.GlUtil.compileProgram",
	"Comment": "builds a gl shader program from vertex & fragment shader code. the vertex and fragment shadersare passed as arrays of strings in order to make debugging compilation issues easier.",
	"Method": "int compileProgram(String[] vertexCode,String[] fragmentCode){\r\n    checkGlError();\r\n    int vertexShader = GLES20.glCreateShader(GLES20.GL_VERTEX_SHADER);\r\n    GLES20.glShaderSource(vertexShader, TextUtils.join(\"\\n\", vertexCode));\r\n    GLES20.glCompileShader(vertexShader);\r\n    checkGlError();\r\n    int fragmentShader = GLES20.glCreateShader(GLES20.GL_FRAGMENT_SHADER);\r\n    GLES20.glShaderSource(fragmentShader, TextUtils.join(\"\\n\", fragmentCode));\r\n    GLES20.glCompileShader(fragmentShader);\r\n    checkGlError();\r\n    int program = GLES20.glCreateProgram();\r\n    GLES20.glAttachShader(program, vertexShader);\r\n    GLES20.glAttachShader(program, fragmentShader);\r\n    GLES20.glLinkProgram(program);\r\n    int[] linkStatus = new int[1];\r\n    GLES20.glGetProgramiv(program, GLES20.GL_LINK_STATUS, linkStatus, 0);\r\n    if (linkStatus[0] != GLES20.GL_TRUE) {\r\n        String errorMsg = \"Unable to link shader program: \\n\" + GLES20.glGetProgramInfoLog(program);\r\n        Log.e(TAG, errorMsg);\r\n        if (ExoPlayerLibraryInfo.GL_ASSERTIONS_ENABLED) {\r\n            throw new RuntimeException(errorMsg);\r\n        }\r\n    }\r\n    checkGlError();\r\n    return program;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.qa.jdbc.CsvTestUtils.executeCsvQuery",
	"Comment": "executes a query on provided csv connection.the supplied table name is only used for the test identification.",
	"Method": "ResultSet executeCsvQuery(Connection csv,String csvTableName){\r\n    ResultSet expected = csv.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE, ResultSet.CONCUR_READ_ONLY).executeQuery(\"SELECT * FROM \" + csvTableName);\r\n    expected.beforeFirst();\r\n    return expected;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.resolvePeriodIndexToWindowSequenceNumber",
	"Comment": "resolves the specified period uid to a corresponding window sequence number. either by reusingthe window sequence number of an existing matching media period or by creating a new windowsequence number.",
	"Method": "long resolvePeriodIndexToWindowSequenceNumber(Object periodUid){\r\n    int windowIndex = timeline.getPeriodByUid(periodUid, period).windowIndex;\r\n    if (oldFrontPeriodUid != null) {\r\n        int oldFrontPeriodIndex = timeline.getIndexOfPeriod(oldFrontPeriodUid);\r\n        if (oldFrontPeriodIndex != C.INDEX_UNSET) {\r\n            int oldFrontWindowIndex = timeline.getPeriod(oldFrontPeriodIndex, period).windowIndex;\r\n            if (oldFrontWindowIndex == windowIndex) {\r\n                return oldFrontPeriodWindowSequenceNumber;\r\n            }\r\n        }\r\n    }\r\n    MediaPeriodHolder mediaPeriodHolder = getFrontPeriod();\r\n    while (mediaPeriodHolder != null) {\r\n        if (mediaPeriodHolder.uid.equals(periodUid)) {\r\n            return mediaPeriodHolder.info.id.windowSequenceNumber;\r\n        }\r\n        mediaPeriodHolder = mediaPeriodHolder.next;\r\n    }\r\n    mediaPeriodHolder = getFrontPeriod();\r\n    while (mediaPeriodHolder != null) {\r\n        int indexOfHolderInTimeline = timeline.getIndexOfPeriod(mediaPeriodHolder.uid);\r\n        if (indexOfHolderInTimeline != C.INDEX_UNSET) {\r\n            int holderWindowIndex = timeline.getPeriod(indexOfHolderInTimeline, period).windowIndex;\r\n            if (holderWindowIndex == windowIndex) {\r\n                return mediaPeriodHolder.info.id.windowSequenceNumber;\r\n            }\r\n        }\r\n        mediaPeriodHolder = mediaPeriodHolder.next;\r\n    }\r\n    return nextWindowSequenceNumber++;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLService.isSSLClientAuthEnabled",
	"Comment": "indicates whether client authentication is enabled for a particular configuration",
	"Method": "boolean isSSLClientAuthEnabled(SSLConfiguration sslConfiguration){\r\n    Objects.requireNonNull(sslConfiguration, \"SSLConfiguration cannot be null\");\r\n    return sslConfiguration.sslClientAuth().enabled();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.AbstractDataToProcessWriterTests.testInputFields",
	"Comment": "testing methods of abstractdatatoprocesswriter but uses the concrete instances.",
	"Method": "void testInputFields(){\r\n    DataDescription.Builder dd = new DataDescription.Builder();\r\n    dd.setTimeField(\"time_field\");\r\n    Detector.Builder detector = new Detector.Builder(\"metric\", \"value\");\r\n    detector.setByFieldName(\"metric\");\r\n    detector.setPartitionFieldName(\"host\");\r\n    detector.setDetectorDescription(\"metric(value) by metric partitionfield=host\");\r\n    AnalysisConfig ac = new AnalysisConfig.Builder(Collections.singletonList(detector.build())).build();\r\n    boolean includeTokensFields = randomBoolean();\r\n    AbstractDataToProcessWriter writer = new CsvDataToProcessWriter(true, includeTokensFields, autodetectProcess, dd.build(), ac, dataCountsReporter);\r\n    writer.writeHeader();\r\n    Set<String> inputFields = new HashSet(writer.inputFields());\r\n    assertEquals(4, inputFields.size());\r\n    assertTrue(inputFields.contains(\"time_field\"));\r\n    assertTrue(inputFields.contains(\"value\"));\r\n    assertTrue(inputFields.contains(\"host\"));\r\n    assertTrue(inputFields.contains(\"metric\"));\r\n    String[] header = { \"time_field\", \"metric\", \"host\", \"value\" };\r\n    writer.buildFieldIndexMapping(header);\r\n    Map<String, Integer> inputIndexes = writer.getInputFieldIndexes();\r\n    assertEquals(4, inputIndexes.size());\r\n    assertEquals(Integer.valueOf(0), inputIndexes.get(\"time_field\"));\r\n    assertEquals(Integer.valueOf(1), inputIndexes.get(\"metric\"));\r\n    assertEquals(Integer.valueOf(2), inputIndexes.get(\"host\"));\r\n    assertEquals(Integer.valueOf(3), inputIndexes.get(\"value\"));\r\n    Map<String, Integer> outputIndexes = writer.outputFieldIndexes();\r\n    assertEquals(includeTokensFields ? 6 : 5, outputIndexes.size());\r\n    assertEquals(Integer.valueOf(0), outputIndexes.get(\"time_field\"));\r\n    assertEquals(Integer.valueOf(1), outputIndexes.get(\"host\"));\r\n    assertEquals(Integer.valueOf(2), outputIndexes.get(\"metric\"));\r\n    assertEquals(Integer.valueOf(3), outputIndexes.get(\"value\"));\r\n    if (includeTokensFields) {\r\n        assertEquals(Integer.valueOf(4), outputIndexes.get(LengthEncodedWriter.PRETOKENISED_TOKEN_FIELD));\r\n        assertEquals(Integer.valueOf(5), outputIndexes.get(LengthEncodedWriter.CONTROL_FIELD_NAME));\r\n    } else {\r\n        assertEquals(Integer.valueOf(4), outputIndexes.get(LengthEncodedWriter.CONTROL_FIELD_NAME));\r\n    }\r\n    List<InputOutputMap> inOutMaps = writer.getInputOutputMap();\r\n    assertEquals(4, inOutMaps.size());\r\n    assertEquals(0, inOutMaps.get(0).inputIndex);\r\n    assertEquals(0, inOutMaps.get(0).outputIndex);\r\n    assertEquals(2, inOutMaps.get(1).inputIndex);\r\n    assertEquals(1, inOutMaps.get(1).outputIndex);\r\n    assertEquals(1, inOutMaps.get(2).inputIndex);\r\n    assertEquals(2, inOutMaps.get(2).outputIndex);\r\n    assertEquals(3, inOutMaps.get(3).inputIndex);\r\n    assertEquals(3, inOutMaps.get(3).outputIndex);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleMetadataQueue.setReadPosition",
	"Comment": "attempts to set the read position to the specified sample index.",
	"Method": "boolean setReadPosition(int sampleIndex){\r\n    if (absoluteFirstIndex <= sampleIndex && sampleIndex <= absoluteFirstIndex + length) {\r\n        readPosition = sampleIndex - absoluteFirstIndex;\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.chunk.Chunk.bytesLoaded",
	"Comment": "returns the number of bytes that have been loaded. must only be called after the loadcompleted, failed, or was canceled.",
	"Method": "long bytesLoaded(){\r\n    return dataSource.getBytesRead();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleQueue.setReadPosition",
	"Comment": "attempts to set the read position to the specified sample index.",
	"Method": "boolean setReadPosition(int sampleIndex){\r\n    return metadataQueue.setReadPosition(sampleIndex);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.readLittleEndianInt24",
	"Comment": "reads the next three bytes as a signed value in little endian order.",
	"Method": "int readLittleEndianInt24(){\r\n    return (data[position++] & 0xFF) | (data[position++] & 0xFF) << 8 | (data[position++] & 0xFF) << 16;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.trigger.TriggerService.addToStats",
	"Comment": "create statistics for a single watch, and store it in a local mapallowing for easy deletion in case the watch gets removed from the trigger service",
	"Method": "void addToStats(Watch watch){\r\n    TriggerWatchStats watchStats = TriggerWatchStats.create(watch);\r\n    perWatchStats.put(watch.id(), watchStats);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.action.TransportGetJobsStatsAction.gatherStatsForClosedJobs",
	"Comment": "this method will fetch the stats for missing jobs, that was stored in the jobs index",
	"Method": "void gatherStatsForClosedJobs(MlMetadata mlMetadata,GetJobsStatsAction.Request request,GetJobsStatsAction.Response response,ActionListener<GetJobsStatsAction.Response> listener){\r\n    List<String> jobIds = determineNonDeletedJobIdsWithoutLiveStats(mlMetadata, request.getExpandedJobsIds(), response.getResponse().results());\r\n    if (jobIds.isEmpty()) {\r\n        listener.onResponse(response);\r\n        return;\r\n    }\r\n    AtomicInteger counter = new AtomicInteger(jobIds.size());\r\n    AtomicArray<GetJobsStatsAction.Response.JobStats> jobStats = new AtomicArray(jobIds.size());\r\n    PersistentTasksCustomMetaData tasks = clusterService.state().getMetaData().custom(PersistentTasksCustomMetaData.TYPE);\r\n    for (int i = 0; i < jobIds.size(); i++) {\r\n        int slot = i;\r\n        String jobId = jobIds.get(i);\r\n        gatherForecastStats(jobId, forecastStats -> {\r\n            gatherDataCountsAndModelSizeStats(jobId, (dataCounts, modelSizeStats) -> {\r\n                JobState jobState = MlTasks.getJobState(jobId, tasks);\r\n                PersistentTasksCustomMetaData.PersistentTask<?> pTask = MlTasks.getJobTask(jobId, tasks);\r\n                String assignmentExplanation = null;\r\n                if (pTask != null) {\r\n                    assignmentExplanation = pTask.getAssignment().getExplanation();\r\n                }\r\n                jobStats.set(slot, new GetJobsStatsAction.Response.JobStats(jobId, dataCounts, modelSizeStats, forecastStats, jobState, null, assignmentExplanation, null));\r\n                if (counter.decrementAndGet() == 0) {\r\n                    List<GetJobsStatsAction.Response.JobStats> results = response.getResponse().results();\r\n                    results.addAll(jobStats.asList());\r\n                    listener.onResponse(new GetJobsStatsAction.Response(response.getTaskFailures(), response.getNodeFailures(), new QueryPage(results, results.size(), Job.RESULTS_FIELD)));\r\n                }\r\n            }, listener::onFailure);\r\n        }, listener::onFailure);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.integration.MonitoringIT.enableMonitoring",
	"Comment": "enable the monitoring service and the local exporter, waiting for some monitoring documentsto be indexed before it returns.",
	"Method": "void enableMonitoring(){\r\n    assertAcked(client().admin().indices().prepareDelete(\".monitoring-*\"));\r\n    assertThat(\"Must be no enabled exporters before enabling monitoring\", getMonitoringUsageExportersDefined(), is(false));\r\n    final Settings settings = Settings.builder().put(\"xpack.monitoring.collection.enabled\", true).put(\"xpack.monitoring.exporters._local.enabled\", true).build();\r\n    assertAcked(client().admin().cluster().prepareUpdateSettings().setTransientSettings(settings));\r\n    assertBusy(() -> assertThat(\"[_local] exporter not enabled yet\", getMonitoringUsageExportersDefined(), is(true)));\r\n    assertBusy(() -> {\r\n        ensureGreen(\".monitoring-es-*\");\r\n        assertThat(client().admin().indices().prepareRefresh(\".monitoring-es-*\").get().getStatus(), is(RestStatus.OK));\r\n        assertThat(\"No monitoring documents yet\", client().prepareSearch(\".monitoring-es-\" + TEMPLATE_VERSION + \"-*\").setSize(0).get().getHits().getTotalHits(), greaterThan(0L));\r\n    });\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlSpMetadataBuilder.encryptionCertificates",
	"Comment": "the certificate that should be used to send encrypted data to the service provider.",
	"Method": "SamlSpMetadataBuilder encryptionCertificates(Collection<X509Certificate> encryptionCertificates){\r\n    if (encryptionCertificates != null) {\r\n        this.encryptionCertificates.addAll(encryptionCertificates);\r\n    }\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.diagnostics.DataStreamDiagnosticsTests.testSparseBucketsLast",
	"Comment": "test for sparsity on the last bucket should not create a sparse bucketsignal",
	"Method": "void testSparseBucketsLast(){\r\n    DataStreamDiagnostics d = new DataStreamDiagnostics(job, dataCounts);\r\n    sendManyDataPoints(d, 10000, 69000, 1000);\r\n    sendManyDataPoints(d, 70000, 129000, 1200);\r\n    sendManyDataPoints(d, 130000, 189000, 1);\r\n    sendManyDataPoints(d, 190000, 249000, 1100);\r\n    sendManyDataPoints(d, 250000, 309000, 1300);\r\n    sendManyDataPoints(d, 310000, 369000, 1050);\r\n    sendManyDataPoints(d, 370000, 429000, 1022);\r\n    sendManyDataPoints(d, 430000, 489000, 1400);\r\n    sendManyDataPoints(d, 490000, 549000, 1333);\r\n    sendManyDataPoints(d, 550000, 609000, 10);\r\n    d.flush();\r\n    assertEquals(9, d.getBucketCount());\r\n    assertEquals(0, d.getEmptyBucketCount());\r\n    assertEquals(1, d.getSparseBucketCount());\r\n    assertEquals(new Date(120000), d.getLatestSparseBucketTime());\r\n    assertEquals(null, d.getLatestEmptyBucketTime());\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ByteVector.putShort",
	"Comment": "puts a short into this byte vector. the byte vector is automatically enlarged if necessary.",
	"Method": "ByteVector putShort(int s){\r\n    int length = this.length;\r\n    if (length + 2 > data.length) {\r\n        enlarge(2);\r\n    }\r\n    byte[] data = this.data;\r\n    data[length++] = (byte) (s >>> 8);\r\n    data[length++] = (byte) s;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "com.alibaba.fastjson.support.jaxrs.FastJsonProvider.isValidType",
	"Comment": "check whether a class can be serialized or deserialized. it can checkbased on packages, annotations on entities or explicit classes.",
	"Method": "boolean isValidType(Class<?> type,Annotation[] classAnnotations){\r\n    if (type == null)\r\n        return false;\r\n    if (clazzes != null) {\r\n        for (Class<?> cls : clazzes) {\r\n            if (cls == type)\r\n                return true;\r\n        }\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.TrackSelectorResult.isRendererEnabled",
	"Comment": "returns whether the renderer at the specified index is enabled.",
	"Method": "boolean isRendererEnabled(int index){\r\n    return rendererConfigurations[index] != null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.dash.DashMediaPeriod.identifyEmbeddedTracks",
	"Comment": "iterates through list of primary track groups and identifies embedded tracks.",
	"Method": "int identifyEmbeddedTracks(int primaryGroupCount,List<AdaptationSet> adaptationSets,int[][] groupedAdaptationSetIndices,boolean[] primaryGroupHasEventMessageTrackFlags,boolean[] primaryGroupHasCea608TrackFlags){\r\n    int numEmbeddedTrack = 0;\r\n    for (int i = 0; i < primaryGroupCount; i++) {\r\n        if (hasEventMessageTrack(adaptationSets, groupedAdaptationSetIndices[i])) {\r\n            primaryGroupHasEventMessageTrackFlags[i] = true;\r\n            numEmbeddedTrack++;\r\n        }\r\n        if (hasCea608Track(adaptationSets, groupedAdaptationSetIndices[i])) {\r\n            primaryGroupHasCea608TrackFlags[i] = true;\r\n            numEmbeddedTrack++;\r\n        }\r\n    }\r\n    return numEmbeddedTrack;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.AudioTrackPositionTracker.isStalled",
	"Comment": "returns whether the track is in an invalid state and must be recreated.",
	"Method": "boolean isStalled(long writtenFrames){\r\n    return forceResetWorkaroundTimeMs != C.TIME_UNSET && writtenFrames > 0 && SystemClock.elapsedRealtime() - forceResetWorkaroundTimeMs >= FORCE_RESET_WORKAROUND_TIMEOUT_MS;\r\n}"
}, {
	"Path": "com.alibaba.fastjson.util.AntiCollisionHashMap.addEntry",
	"Comment": "adds a new entry with the specified key, value and hash code to thespecified bucket. it is the responsibility of this method to resize thetable if appropriate.subclass overrides this to alter the behavior of put method.",
	"Method": "void addEntry(int hash,K key,V value,int bucketIndex){\r\n    Entry<K, V> e = table[bucketIndex];\r\n    table[bucketIndex] = new Entry<K, V>(hash, key, value, e);\r\n    if (size++ >= threshold)\r\n        resize(2 * table.length);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.ExtractorMediaPeriod.seekInsideBufferUs",
	"Comment": "attempts to seek to the specified position within the sample queues.",
	"Method": "boolean seekInsideBufferUs(boolean[] trackIsAudioVideoFlags,long positionUs){\r\n    int trackCount = sampleQueues.length;\r\n    for (int i = 0; i < trackCount; i++) {\r\n        SampleQueue sampleQueue = sampleQueues[i];\r\n        sampleQueue.rewind();\r\n        boolean seekInsideQueue = sampleQueue.advanceTo(positionUs, true, false) != SampleQueue.ADVANCE_FAILED;\r\n        if (!seekInsideQueue && (trackIsAudioVideoFlags[i] || !haveAudioVideoTracks)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.transport.ssl.SslMultiPortTests.testThatTransportClientWithOnlyTruststoreCannotConnectToDefaultProfile",
	"Comment": "uses a transport client that only trusts the testnode certificate. this test connects to the default profile, which usesthe testnode certificate and requires the client to present a certificate, so this connection will never work asthe client has no certificate to present",
	"Method": "void testThatTransportClientWithOnlyTruststoreCannotConnectToDefaultProfile(){\r\n    Settings settings = Settings.builder().put(SecurityField.USER_SETTING.getKey(), TEST_USER_NAME + \":\" + TEST_PASSWORD).put(\"cluster.name\", internalCluster().getClusterName()).put(\"xpack.security.transport.ssl.enabled\", true).put(\"xpack.ssl.client_authentication\", SSLClientAuth.REQUIRED).put(\"xpack.ssl.certificate_authorities\", getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.crt\")).build();\r\n    try (TransportClient transportClient = new TestXPackTransportClient(settings, Collections.singletonList(LocalStateSecurity.class))) {\r\n        transportClient.addTransportAddress(randomFrom(internalCluster().getInstance(Transport.class).boundAddress().boundAddresses()));\r\n        assertGreenClusterState(transportClient);\r\n        fail(\"Expected NoNodeAvailableException\");\r\n    } catch (NoNodeAvailableException e) {\r\n        assertThat(e.getMessage(), containsString(\"None of the configured nodes are available: [{#transport#-\"));\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.datafeed.ProblemTracker.reportAnalysisProblem",
	"Comment": "reports as analysis problem if it is different than the last seen problem",
	"Method": "void reportAnalysisProblem(String problemMessage){\r\n    reportProblem(Messages.JOB_AUDIT_DATAFEED_DATA_ANALYSIS_ERROR, problemMessage);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.vp9.VpxOutputBuffer.initForRgbFrame",
	"Comment": "resizes the buffer based on the given dimensions. called via jni after decoding completes.",
	"Method": "boolean initForRgbFrame(int width,int height){\r\n    this.width = width;\r\n    this.height = height;\r\n    this.yuvPlanes = null;\r\n    if (!isSafeToMultiply(width, height) || !isSafeToMultiply(width * height, 2)) {\r\n        return false;\r\n    }\r\n    int minimumRgbSize = width * height * 2;\r\n    initData(minimumRgbSize);\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.TimestampAdjuster.waitUntilInitialized",
	"Comment": "blocks the calling thread until this adjuster is initialized.",
	"Method": "void waitUntilInitialized(){\r\n    while (lastSampleTimestampUs == C.TIME_UNSET) {\r\n        wait();\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.cache.SimpleCacheSpan.createCacheEntry",
	"Comment": "creates a cache span from an underlying cache file. upgrades the file if necessary.",
	"Method": "SimpleCacheSpan createCacheEntry(File file,CachedContentIndex index){\r\n    String name = file.getName();\r\n    if (!name.endsWith(SUFFIX)) {\r\n        file = upgradeFile(file, index);\r\n        if (file == null) {\r\n            return null;\r\n        }\r\n        name = file.getName();\r\n    }\r\n    Matcher matcher = CACHE_FILE_PATTERN_V3.matcher(name);\r\n    if (!matcher.matches()) {\r\n        return null;\r\n    }\r\n    long length = file.length();\r\n    int id = Integer.parseInt(matcher.group(1));\r\n    String key = index.getKeyForId(id);\r\n    return key == null ? null : new SimpleCacheSpan(key, Long.parseLong(matcher.group(2)), length, Long.parseLong(matcher.group(3)), file);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authz.privilege.ApplicationPrivilege.validateApplicationNameOrWildcard",
	"Comment": "validate that the provided name is a valid application, or a wildcard pattern for an application and throws an exception otherwise",
	"Method": "void validateApplicationNameOrWildcard(String application){\r\n    validateApplicationName(application, true);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.normalizer.Normalizer.normalize",
	"Comment": "launches a normalization process seeded with the quantiles state providedand normalizes the given results.",
	"Method": "void normalize(Integer bucketSpan,List<? extends Normalizable> results,String quantilesState){\r\n    NormalizerProcess process = processFactory.createNormalizerProcess(jobId, quantilesState, bucketSpan, executorService);\r\n    NormalizerResultHandler resultsHandler = process.createNormalizedResultsHandler();\r\n    Future<?> resultsHandlerFuture = executorService.submit(() -> {\r\n        try {\r\n            resultsHandler.process();\r\n        } catch (IOException e) {\r\n            LOGGER.error(new ParameterizedMessage(\"[{}] Error reading normalizer results\", new Object[] { jobId }), e);\r\n        }\r\n    });\r\n    try {\r\n        process.writeRecord(new String[] { NormalizerResult.LEVEL_FIELD.getPreferredName(), NormalizerResult.PARTITION_FIELD_NAME_FIELD.getPreferredName(), NormalizerResult.PARTITION_FIELD_VALUE_FIELD.getPreferredName(), NormalizerResult.PERSON_FIELD_NAME_FIELD.getPreferredName(), NormalizerResult.PERSON_FIELD_VALUE_FIELD.getPreferredName(), NormalizerResult.FUNCTION_NAME_FIELD.getPreferredName(), NormalizerResult.VALUE_FIELD_NAME_FIELD.getPreferredName(), NormalizerResult.PROBABILITY_FIELD.getPreferredName(), NormalizerResult.NORMALIZED_SCORE_FIELD.getPreferredName() });\r\n        for (Normalizable result : results) {\r\n            writeNormalizableAndChildrenRecursively(result, process);\r\n        }\r\n    } catch (IOException e) {\r\n        LOGGER.error(\"[\" + jobId + \"] Error writing to the normalizer\", e);\r\n    } finally {\r\n        try {\r\n            process.close();\r\n        } catch (IOException e) {\r\n            LOGGER.error(\"[\" + jobId + \"] Error closing normalizer\", e);\r\n        }\r\n    }\r\n    try {\r\n        resultsHandlerFuture.get();\r\n        mergeNormalizedScoresIntoResults(resultsHandler.getNormalizedResults(), results);\r\n    } catch (ExecutionException e) {\r\n        LOGGER.error(new ParameterizedMessage(\"[{}] Error processing normalizer results\", new Object[] { jobId }), e);\r\n    } catch (InterruptedException e) {\r\n        Thread.currentThread().interrupt();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlAuthenticator.authenticate",
	"Comment": "processes the provided saml response within the provided token and, if valid, extracts the relevant attributes from it.",
	"Method": "SamlAttributes authenticate(SamlToken token){\r\n    final Element root = parseSamlMessage(token.getContent());\r\n    if (RESPONSE_TAG_NAME.equals(root.getLocalName()) && SAML_NAMESPACE.equals(root.getNamespaceURI())) {\r\n        try {\r\n            return authenticateResponse(root, token.getAllowedSamlRequestIds());\r\n        } catch (ElasticsearchSecurityException e) {\r\n            logger.trace(\"Rejecting SAML response {} because {}\", SamlUtils.toString(root), e.getMessage());\r\n            throw e;\r\n        }\r\n    } else {\r\n        throw samlException(\"SAML content [{}] should have a root element of Namespace=[{}] Tag=[{}]\", root, SAML_NAMESPACE, RESPONSE_TAG_NAME);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.qa.jdbc.ConnectionTestCase.testTransactionIsolation",
	"Comment": "tests that we throw report no transaction isolation and throw sensible errors if you ask for any.",
	"Method": "void testTransactionIsolation(){\r\n    try (Connection c = esJdbc()) {\r\n        assertEquals(Connection.TRANSACTION_NONE, c.getTransactionIsolation());\r\n        SQLException e = expectThrows(SQLException.class, () -> c.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE));\r\n        assertEquals(\"Transactions not supported\", e.getMessage());\r\n        assertEquals(Connection.TRANSACTION_NONE, c.getTransactionIsolation());\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.watch.ClockMock.fastForward",
	"Comment": "freeze the clock if not frozen and advance it by the given time",
	"Method": "void fastForward(TimeValue timeValue){\r\n    setTime(instant().plusMillis(timeValue.getMillis()));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.test.feature_aware.FeatureAwareCheckTests.runCustomTest",
	"Comment": "runs a test on an actual class implementing a custom interface and the expected marker interface.",
	"Method": "void runCustomTest(Class<? extends ClusterState.FeatureAware> clazz,Class<?> outerClazz,Class<? extends ClusterState.FeatureAware> interfaceClazz,Class<? extends ClusterState.FeatureAware> expectedInterfaceClazz){\r\n    runTest(clazz, outerClazz, interfaceClazz, expectedInterfaceClazz, false);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.flac.FlacDecoderJni.decodeSample",
	"Comment": "decodes and consumes the next sample from the flac stream into the given byte buffer.",
	"Method": "void decodeSample(ByteBuffer output){\r\n    output.clear();\r\n    int frameSize = output.isDirect() ? flacDecodeToBuffer(nativeDecoderContext, output) : flacDecodeToArray(nativeDecoderContext, output.array());\r\n    if (frameSize < 0) {\r\n        if (!isDecoderAtEndOfInput()) {\r\n            throw new FlacFrameDecodeException(\"Cannot decode FLAC frame\", frameSize);\r\n        }\r\n        output.limit(0);\r\n    } else {\r\n        output.limit(frameSize);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.playlist.HlsMediaPlaylist.copyWithEndTag",
	"Comment": "returns a playlist identical to this one except that an end tag is added. if an end tag isalready present then the playlist will return itself.",
	"Method": "HlsMediaPlaylist copyWithEndTag(){\r\n    if (this.hasEndTag) {\r\n        return this;\r\n    }\r\n    return new HlsMediaPlaylist(playlistType, baseUri, tags, startOffsetUs, startTimeUs, hasDiscontinuitySequence, discontinuitySequence, mediaSequence, version, targetDurationUs, hasIndependentSegments, true, hasProgramDateTime, protectionSchemes, segments);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.chunk.ChunkSampleStream.haveReadFromMediaChunk",
	"Comment": "returns whether samples have been read from media chunk at given index.",
	"Method": "boolean haveReadFromMediaChunk(int mediaChunkIndex){\r\n    BaseMediaChunk mediaChunk = mediaChunks.get(mediaChunkIndex);\r\n    if (primarySampleQueue.getReadIndex() > mediaChunk.getFirstSampleIndex(0)) {\r\n        return true;\r\n    }\r\n    for (int i = 0; i < embeddedSampleQueues.length; i++) {\r\n        if (embeddedSampleQueues[i].getReadIndex() > mediaChunk.getFirstSampleIndex(i + 1)) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.text.dvb.DvbParser.parseDisplayDefinition",
	"Comment": "parses a display definition segment, as defined by etsi en 300 743 7.2.1.",
	"Method": "DisplayDefinition parseDisplayDefinition(ParsableBitArray data){\r\n    data.skipBits(4);\r\n    boolean displayWindowFlag = data.readBit();\r\n    data.skipBits(3);\r\n    int width = data.readBits(16);\r\n    int height = data.readBits(16);\r\n    int horizontalPositionMinimum;\r\n    int horizontalPositionMaximum;\r\n    int verticalPositionMinimum;\r\n    int verticalPositionMaximum;\r\n    if (displayWindowFlag) {\r\n        horizontalPositionMinimum = data.readBits(16);\r\n        horizontalPositionMaximum = data.readBits(16);\r\n        verticalPositionMinimum = data.readBits(16);\r\n        verticalPositionMaximum = data.readBits(16);\r\n    } else {\r\n        horizontalPositionMinimum = 0;\r\n        horizontalPositionMaximum = width;\r\n        verticalPositionMinimum = 0;\r\n        verticalPositionMaximum = height;\r\n    }\r\n    return new DisplayDefinition(width, height, horizontalPositionMinimum, horizontalPositionMaximum, verticalPositionMinimum, verticalPositionMaximum);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerView.setShowMultiWindowTimeBar",
	"Comment": "sets whether the time bar should show all windows, as opposed to just the current one.",
	"Method": "void setShowMultiWindowTimeBar(boolean showMultiWindowTimeBar){\r\n    Assertions.checkState(controller != null);\r\n    controller.setShowMultiWindowTimeBar(showMultiWindowTimeBar);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecUtil.isCodecUsableDecoder",
	"Comment": "returns whether the specified codec is usable for decoding on the current device.",
	"Method": "boolean isCodecUsableDecoder(android.media.MediaCodecInfo info,String name,boolean secureDecodersExplicit,String requestedMimeType){\r\n    if (info.isEncoder() || (!secureDecodersExplicit && name.endsWith(\".secure\"))) {\r\n        return false;\r\n    }\r\n    if (Util.SDK_INT < 21 && (\"CIPAACDecoder\".equals(name) || \"CIPMP3Decoder\".equals(name) || \"CIPVorbisDecoder\".equals(name) || \"CIPAMRNBDecoder\".equals(name) || \"AACDecoder\".equals(name) || \"MP3Decoder\".equals(name))) {\r\n        return false;\r\n    }\r\n    if (Util.SDK_INT < 18 && \"OMX.SEC.MP3.Decoder\".equals(name)) {\r\n        return false;\r\n    }\r\n    if (\"OMX.SEC.mp3.dec\".equals(name) && \"SM-T530\".equals(Util.MODEL)) {\r\n        return false;\r\n    }\r\n    if (Util.SDK_INT < 18 && \"OMX.MTK.AUDIO.DECODER.AAC\".equals(name) && (\"a70\".equals(Util.DEVICE) || (\"Xiaomi\".equals(Util.MANUFACTURER) && Util.DEVICE.startsWith(\"HM\")))) {\r\n        return false;\r\n    }\r\n    if (Util.SDK_INT == 16 && \"OMX.qcom.audio.decoder.mp3\".equals(name) && (\"dlxu\".equals(Util.DEVICE) || \"protou\".equals(Util.DEVICE) || \"ville\".equals(Util.DEVICE) || \"villeplus\".equals(Util.DEVICE) || \"villec2\".equals(Util.DEVICE) || Util.DEVICE.startsWith(\"gee\") || \"C6602\".equals(Util.DEVICE) || \"C6603\".equals(Util.DEVICE) || \"C6606\".equals(Util.DEVICE) || \"C6616\".equals(Util.DEVICE) || \"L36h\".equals(Util.DEVICE) || \"SO-02E\".equals(Util.DEVICE))) {\r\n        return false;\r\n    }\r\n    if (Util.SDK_INT == 16 && \"OMX.qcom.audio.decoder.aac\".equals(name) && (\"C1504\".equals(Util.DEVICE) || \"C1505\".equals(Util.DEVICE) || \"C1604\".equals(Util.DEVICE) || \"C1605\".equals(Util.DEVICE))) {\r\n        return false;\r\n    }\r\n    if (Util.SDK_INT < 24 && (\"OMX.SEC.aac.dec\".equals(name) || \"OMX.Exynos.AAC.Decoder\".equals(name)) && \"samsung\".equals(Util.MANUFACTURER) && (Util.DEVICE.startsWith(\"zeroflte\") || Util.DEVICE.startsWith(\"zerolte\") || Util.DEVICE.startsWith(\"zenlte\") || \"SC-05G\".equals(Util.DEVICE) || \"marinelteatt\".equals(Util.DEVICE) || \"404SC\".equals(Util.DEVICE) || \"SC-04G\".equals(Util.DEVICE) || \"SCV31\".equals(Util.DEVICE))) {\r\n        return false;\r\n    }\r\n    if (Util.SDK_INT <= 19 && \"OMX.SEC.vp8.dec\".equals(name) && \"samsung\".equals(Util.MANUFACTURER) && (Util.DEVICE.startsWith(\"d2\") || Util.DEVICE.startsWith(\"serrano\") || Util.DEVICE.startsWith(\"jflte\") || Util.DEVICE.startsWith(\"santos\") || Util.DEVICE.startsWith(\"t0\"))) {\r\n        return false;\r\n    }\r\n    if (Util.SDK_INT <= 19 && Util.DEVICE.startsWith(\"jflte\") && \"OMX.qcom.video.decoder.vp8\".equals(name)) {\r\n        return false;\r\n    }\r\n    if (MimeTypes.AUDIO_E_AC3_JOC.equals(requestedMimeType) && \"OMX.MTK.AUDIO.DECODER.DSPAC3\".equals(name)) {\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.cast.CastPlayer.loadItems",
	"Comment": "loads a media queue. if no session is available, does nothing.",
	"Method": "PendingResult<MediaChannelResult> loadItems(MediaQueueItem[] items,int startIndex,long positionMs,int repeatMode){\r\n    if (remoteMediaClient != null) {\r\n        positionMs = positionMs != C.TIME_UNSET ? positionMs : 0;\r\n        waitingForInitialTimeline = true;\r\n        return remoteMediaClient.queueLoad(items, startIndex, getCastRepeatMode(repeatMode), positionMs, null);\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.MappingTrackSelectorTest.testMappingReverseOrder",
	"Comment": "tests that the video and audio track groups are mapped onto the correct renderers when therenderer ordering is reversed.",
	"Method": "void testMappingReverseOrder(){\r\n    FakeMappingTrackSelector trackSelector = new FakeMappingTrackSelector();\r\n    RendererCapabilities[] reverseOrderRendererCapabilities = new RendererCapabilities[] { AUDIO_CAPABILITIES, VIDEO_CAPABILITIES };\r\n    trackSelector.selectTracks(reverseOrderRendererCapabilities, TRACK_GROUPS);\r\n    trackSelector.assertMappedTrackGroups(0, AUDIO_TRACK_GROUP);\r\n    trackSelector.assertMappedTrackGroups(1, VIDEO_TRACK_GROUP);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.test.feature_aware.FeatureAwareCheckTests.runTest",
	"Comment": "runs a test on an actual class implementing a custom interface and should implement the expected marker interface if and only ifthe specified violation parameter is false.",
	"Method": "void runTest(Class<? extends ClusterState.FeatureAware> clazz,Class<?> outerClazz,Class<? extends ClusterState.FeatureAware> interfaceClazz,Class<? extends ClusterState.FeatureAware> expectedInterfaceClazz,boolean violation){\r\n    final String name = clazz.getName();\r\n    final FeatureAwareViolationConsumer callback = new FeatureAwareViolationConsumer(FeatureAwareCheck.formatClassName(clazz), FeatureAwareCheck.formatClassName(interfaceClazz), FeatureAwareCheck.formatClassName(expectedInterfaceClazz));\r\n    FeatureAwareCheck.checkClass(outerClazz.getResourceAsStream(name.substring(1 + name.lastIndexOf(\".\")) + \".class\"), callback);\r\n    assertThat(callback.called.get(), equalTo(violation));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.vp9.LibvpxVideoRenderer.shouldDropBuffersToKeyframe",
	"Comment": "returns whether to drop all buffers from the buffer being processed to the keyframe at or afterthe current playback position, if possible.",
	"Method": "boolean shouldDropBuffersToKeyframe(long earlyUs,long elapsedRealtimeUs){\r\n    return isBufferVeryLate(earlyUs);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.CodecSpecificDataUtil.findNalStartCode",
	"Comment": "finds the next occurrence of the nal start code from a given index.",
	"Method": "int findNalStartCode(byte[] data,int index){\r\n    int endIndex = data.length - NAL_START_CODE.length;\r\n    for (int i = index; i <= endIndex; i++) {\r\n        if (isNalStartCode(data, i)) {\r\n            return i;\r\n        }\r\n    }\r\n    return C.INDEX_UNSET;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.DefaultMediaClock.syncAndGetPositionUs",
	"Comment": "syncs internal clock if needed and returns current clock position in microseconds.",
	"Method": "long syncAndGetPositionUs(){\r\n    if (isUsingRendererClock()) {\r\n        ensureSynced();\r\n        return rendererClock.getPositionUs();\r\n    } else {\r\n        return standaloneMediaClock.getPositionUs();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.FieldConfigWriter.write",
	"Comment": "write the ml autodetect field options to the outputindex stream.",
	"Method": "void write(){\r\n    StringBuilder contents = new StringBuilder();\r\n    writeFilters(contents);\r\n    writeDetectors(contents);\r\n    writeScheduledEvents(contents);\r\n    writeCategorizationFilters(contents);\r\n    writeAsEnumeratedSettings(INFLUENCER_PREFIX, config.getInfluencers(), contents, false);\r\n    logger.debug(\"FieldConfig:\\n\" + contents.toString());\r\n    writer.write(contents.toString());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.jdbc.JdbcStatement.initResultSet",
	"Comment": "execute the query and handle the rs closing and initialization",
	"Method": "void initResultSet(String sql,List<SqlTypedParamValue> params){\r\n    closeResultSet();\r\n    Cursor cursor = con.client.query(sql, params, requestMeta);\r\n    rs = new JdbcResultSet(cfg, this, cursor);\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ByteVector.put11",
	"Comment": "puts two bytes into this byte vector. the byte vector is automatically enlarged if necessary.",
	"Method": "ByteVector put11(int b1,int b2){\r\n    int length = this.length;\r\n    if (length + 2 > data.length) {\r\n        enlarge(2);\r\n    }\r\n    byte[] data = this.data;\r\n    data[length++] = (byte) b1;\r\n    data[length++] = (byte) b2;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ByteVector.put12",
	"Comment": "puts a byte and a short into this byte vector. the byte vector is automatically enlarged if necessary.",
	"Method": "ByteVector put12(int b,int s){\r\n    int length = this.length;\r\n    if (length + 3 > data.length) {\r\n        enlarge(3);\r\n    }\r\n    byte[] data = this.data;\r\n    data[length++] = (byte) b;\r\n    data[length++] = (byte) (s >>> 8);\r\n    data[length++] = (byte) s;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.scheduler.Cron.setCalendarHour",
	"Comment": "advance the calendar to the particular hour paying particular attentionto daylight saving problems.",
	"Method": "void setCalendarHour(Calendar cal,int hour){\r\n    cal.set(java.util.Calendar.HOUR_OF_DAY, hour);\r\n    if (cal.get(java.util.Calendar.HOUR_OF_DAY) != hour && hour != 24) {\r\n        cal.set(java.util.Calendar.HOUR_OF_DAY, hour + 1);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.getAndValidateToken",
	"Comment": "looks in the context to see if the request provided a header with a user token and if so thetoken is validated, which includes authenticated decryption and verification that the tokenhas not been revoked or is expired.",
	"Method": "void getAndValidateToken(ThreadContext ctx,ActionListener<UserToken> listener){\r\n    if (enabled) {\r\n        final String token = getFromHeader(ctx);\r\n        if (token == null) {\r\n            listener.onResponse(null);\r\n        } else {\r\n            try {\r\n                decodeAndValidateToken(token, ActionListener.wrap(listener::onResponse, e -> {\r\n                    if (e instanceof IOException) {\r\n                        logger.debug(\"invalid token\", e);\r\n                        listener.onResponse(null);\r\n                    } else {\r\n                        listener.onFailure(e);\r\n                    }\r\n                }));\r\n            } catch (IOException e) {\r\n                logger.debug(\"invalid token\", e);\r\n                listener.onResponse(null);\r\n            }\r\n        }\r\n    } else {\r\n        listener.onResponse(null);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.innerRefresh",
	"Comment": "performs the actual refresh of the token with retries in case of certain exceptions thatmay be recoverable. the refresh involves retrieval of the token document and thenupdating the token document to indicate that the document has been refreshed.",
	"Method": "void innerRefresh(String tokenDocId,Authentication userAuth,ActionListener<Tuple<UserToken, String>> listener,AtomicInteger attemptCount){\r\n    if (attemptCount.getAndIncrement() > MAX_RETRY_ATTEMPTS) {\r\n        logger.warn(\"Failed to refresh token for doc [{}] after [{}] attempts\", tokenDocId, attemptCount.get());\r\n        listener.onFailure(invalidGrantException(\"could not refresh the requested token\"));\r\n    } else {\r\n        Consumer<Exception> onFailure = ex -> listener.onFailure(traceLog(\"refresh token\", tokenDocId, ex));\r\n        GetRequest getRequest = client.prepareGet(SecurityIndexManager.SECURITY_INDEX_NAME, TYPE, tokenDocId).request();\r\n        executeAsyncWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN, getRequest, ActionListener.<GetResponse>wrap(response -> {\r\n            if (response.isExists()) {\r\n                final Map<String, Object> source = response.getSource();\r\n                final Optional<ElasticsearchSecurityException> invalidSource = checkTokenDocForRefresh(source, userAuth);\r\n                if (invalidSource.isPresent()) {\r\n                    onFailure.accept(invalidSource.get());\r\n                } else {\r\n                    final Map<String, Object> userTokenSource = (Map<String, Object>) ((Map<String, Object>) source.get(\"access_token\")).get(\"user_token\");\r\n                    final String authString = (String) userTokenSource.get(\"authentication\");\r\n                    final Integer version = (Integer) userTokenSource.get(\"version\");\r\n                    final Map<String, Object> metadata = (Map<String, Object>) userTokenSource.get(\"metadata\");\r\n                    Version authVersion = Version.fromId(version);\r\n                    try (StreamInput in = StreamInput.wrap(Base64.getDecoder().decode(authString))) {\r\n                        in.setVersion(authVersion);\r\n                        Authentication authentication = new Authentication(in);\r\n                        UpdateRequest updateRequest = client.prepareUpdate(SecurityIndexManager.SECURITY_INDEX_NAME, TYPE, tokenDocId).setVersion(response.getVersion()).setDoc(\"refresh_token\", Collections.singletonMap(\"refreshed\", true)).setRefreshPolicy(RefreshPolicy.WAIT_UNTIL).request();\r\n                        executeAsyncWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN, updateRequest, ActionListener.<UpdateResponse>wrap(updateResponse -> createUserToken(authentication, userAuth, listener, metadata, true), e -> {\r\n                            Throwable cause = ExceptionsHelper.unwrapCause(e);\r\n                            if (cause instanceof VersionConflictEngineException || isShardNotAvailableException(e)) {\r\n                                innerRefresh(tokenDocId, userAuth, listener, attemptCount);\r\n                            } else {\r\n                                onFailure.accept(e);\r\n                            }\r\n                        }), client::update);\r\n                    }\r\n                }\r\n            } else {\r\n                logger.info(\"could not find token document [{}] for refresh\", tokenDocId);\r\n                onFailure.accept(invalidGrantException(\"could not refresh the requested token\"));\r\n            }\r\n        }, e -> {\r\n            if (isShardNotAvailableException(e)) {\r\n                innerRefresh(tokenDocId, userAuth, listener, attemptCount);\r\n            } else {\r\n                listener.onFailure(e);\r\n            }\r\n        }), client::get);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.normalizer.ScoresUpdater.update",
	"Comment": "update the anomaly score field on all previously persisted bucketsand all contained records",
	"Method": "void update(String quantilesState,long endBucketEpochMs,long windowExtensionMs){\r\n    Normalizer normalizer = normalizerFactory.create(jobId);\r\n    int[] counts = { 0, 0 };\r\n    updateBuckets(normalizer, quantilesState, endBucketEpochMs, windowExtensionMs, counts);\r\n    updateRecords(normalizer, quantilesState, endBucketEpochMs, windowExtensionMs, counts);\r\n    updateInfluencers(normalizer, quantilesState, endBucketEpochMs, windowExtensionMs, counts);\r\n    updatesPersister.executeRequest();\r\n    LOGGER.debug(\"[{}] Normalization resulted in: {} updates, {} no-ops\", jobId, counts[0], counts[1]);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.DefaultTrackSelector.compareInts",
	"Comment": "compares two integers in a safe way and avoiding potential overflow.",
	"Method": "int compareInts(int first,int second){\r\n    return first > second ? 1 : (second > first ? -1 : 0);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.common.stats.Counters.set",
	"Comment": "sets a counter. this ensures that the counter is there, even though it is never incremented.",
	"Method": "void set(String name){\r\n    counters.put(name, 0);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.jdbc.TypeConverter.convert",
	"Comment": "converts the object from json representation to the specified jdbctype",
	"Method": "T convert(Object val,EsType columnType,Class<T> type,String typeString,Object convert,Object v,EsType columnType,String typeString){\r\n    switch(columnType) {\r\n        case NULL:\r\n            return null;\r\n        case BOOLEAN:\r\n        case TEXT:\r\n        case KEYWORD:\r\n            return v;\r\n        case BYTE:\r\n            return ((Number) v).byteValue();\r\n        case SHORT:\r\n            return ((Number) v).shortValue();\r\n        case INTEGER:\r\n            return ((Number) v).intValue();\r\n        case LONG:\r\n            return ((Number) v).longValue();\r\n        case HALF_FLOAT:\r\n        case SCALED_FLOAT:\r\n        case DOUBLE:\r\n            return doubleValue(v);\r\n        case FLOAT:\r\n            return floatValue(v);\r\n        case DATE:\r\n            return new Timestamp(((Number) v).longValue());\r\n        case INTERVAL_YEAR:\r\n        case INTERVAL_MONTH:\r\n        case INTERVAL_YEAR_TO_MONTH:\r\n            return Period.parse(v.toString());\r\n        case INTERVAL_DAY:\r\n        case INTERVAL_HOUR:\r\n        case INTERVAL_MINUTE:\r\n        case INTERVAL_SECOND:\r\n        case INTERVAL_DAY_TO_HOUR:\r\n        case INTERVAL_DAY_TO_MINUTE:\r\n        case INTERVAL_DAY_TO_SECOND:\r\n        case INTERVAL_HOUR_TO_MINUTE:\r\n        case INTERVAL_HOUR_TO_SECOND:\r\n        case INTERVAL_MINUTE_TO_SECOND:\r\n            return Duration.parse(v.toString());\r\n        default:\r\n            throw new SQLException(\"Unexpected column type [\" + typeString + \"]\");\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.readLittleEndianInt",
	"Comment": "reads the next four bytes as a signed value in little endian order.",
	"Method": "int readLittleEndianInt(){\r\n    return (data[position++] & 0xFF) | (data[position++] & 0xFF) << 8 | (data[position++] & 0xFF) << 16 | (data[position++] & 0xFF) << 24;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.token.CreateTokenRequestBuilder.setPassword",
	"Comment": "set the password credentials associated with the user. these credentials will be used forauthentication and the resulting token will be for this user",
	"Method": "CreateTokenRequestBuilder setPassword(SecureString password){\r\n    request.setPassword(password);\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.qa.cli.CliIntegrationTestCase.elasticsearchAddress",
	"Comment": "read an address for elasticsearch suitable for the cli from the system properties.",
	"Method": "String elasticsearchAddress(){\r\n    String cluster = System.getProperty(\"tests.rest.cluster\");\r\n    return cluster.split(\",\")[0];\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ByteVector.putInt",
	"Comment": "puts an int into this byte vector. the byte vector is automatically enlarged if necessary.",
	"Method": "ByteVector putInt(int i){\r\n    int length = this.length;\r\n    if (length + 4 > data.length) {\r\n        enlarge(4);\r\n    }\r\n    byte[] data = this.data;\r\n    data[length++] = (byte) (i >>> 24);\r\n    data[length++] = (byte) (i >>> 16);\r\n    data[length++] = (byte) (i >>> 8);\r\n    data[length++] = (byte) i;\r\n    this.length = length;\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.process.writer.LengthEncodedWriterTests.testLengthEncodedWriter",
	"Comment": "simple test push a list of records through the writer andcheck the outputthe writer accepts empty strings but not null strings",
	"Method": "void testLengthEncodedWriter(){\r\n    {\r\n        String[] header = { \"one\", \"two\", \"three\", \"four\", \"five\" };\r\n        String[] record1 = { \"r1\", \"r2\", \"\", \"rrr4\", \"r5\" };\r\n        String[] record2 = { \"y1\", \"y2\", \"yy3\", \"yyy4\", \"y5\" };\r\n        ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\r\n        LengthEncodedWriter writer = new LengthEncodedWriter(bos);\r\n        writer.writeRecord(header);\r\n        final int NUM_RECORDS = 5;\r\n        for (int i = 0; i < NUM_RECORDS; i++) {\r\n            writer.writeRecord(record1);\r\n            writer.writeRecord(record2);\r\n        }\r\n        ByteBuffer bb = ByteBuffer.wrap(bos.toByteArray());\r\n        int numFields = bb.getInt();\r\n        Assert.assertEquals(numFields, header.length);\r\n        for (int i = 0; i < numFields; i++) {\r\n            int recordSize = bb.getInt();\r\n            byte[] charBuff = new byte[recordSize];\r\n            for (int j = 0; j < recordSize; j++) {\r\n                charBuff[j] = bb.get();\r\n            }\r\n            String value = new String(charBuff, StandardCharsets.UTF_8);\r\n            Assert.assertEquals(header[i], value);\r\n        }\r\n        for (int n = 0; n < NUM_RECORDS; n++) {\r\n            numFields = bb.getInt();\r\n            Assert.assertEquals(numFields, record1.length);\r\n            for (int i = 0; i < numFields; i++) {\r\n                int recordSize = bb.getInt();\r\n                byte[] charBuff = new byte[recordSize];\r\n                for (int j = 0; j < recordSize; j++) {\r\n                    charBuff[j] = bb.get();\r\n                }\r\n                String value = new String(charBuff, StandardCharsets.UTF_8);\r\n                Assert.assertEquals(value, record1[i]);\r\n            }\r\n            numFields = bb.getInt();\r\n            Assert.assertEquals(numFields, record2.length);\r\n            for (int i = 0; i < numFields; i++) {\r\n                int recordSize = bb.getInt();\r\n                byte[] charBuff = new byte[recordSize];\r\n                for (int j = 0; j < recordSize; j++) {\r\n                    charBuff[j] = bb.get();\r\n                }\r\n                String value = new String(charBuff, StandardCharsets.UTF_8);\r\n                Assert.assertEquals(value, record2[i]);\r\n            }\r\n        }\r\n    }\r\n    {\r\n        List<String> header = Arrays.asList(new String[] { \"one\", \"two\", \"three\", \"four\", \"five\" });\r\n        List<String> record1 = Arrays.asList(new String[] { \"r1\", \"r2\", \"rr3\", \"rrr4\", \"r5\" });\r\n        List<String> record2 = Arrays.asList(new String[] { \"y1\", \"y2\", \"yy3\", \"yyy4\", \"y5\" });\r\n        ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\r\n        LengthEncodedWriter writer = new LengthEncodedWriter(bos);\r\n        writer.writeRecord(header);\r\n        final int NUM_RECORDS = 5;\r\n        for (int i = 0; i < NUM_RECORDS; i++) {\r\n            writer.writeRecord(record1);\r\n            writer.writeRecord(record2);\r\n        }\r\n        ByteBuffer bb = ByteBuffer.wrap(bos.toByteArray());\r\n        int numFields = bb.getInt();\r\n        Assert.assertEquals(numFields, header.size());\r\n        for (int i = 0; i < numFields; i++) {\r\n            int recordSize = bb.getInt();\r\n            byte[] charBuff = new byte[recordSize];\r\n            for (int j = 0; j < recordSize; j++) {\r\n                charBuff[j] = bb.get();\r\n            }\r\n            String value = new String(charBuff, StandardCharsets.UTF_8);\r\n            Assert.assertEquals(header.get(i), value);\r\n        }\r\n        for (int n = 0; n < NUM_RECORDS; n++) {\r\n            numFields = bb.getInt();\r\n            Assert.assertEquals(numFields, record1.size());\r\n            for (int i = 0; i < numFields; i++) {\r\n                int recordSize = bb.getInt();\r\n                byte[] charBuff = new byte[recordSize];\r\n                for (int j = 0; j < recordSize; j++) {\r\n                    charBuff[j] = bb.get();\r\n                }\r\n                String value = new String(charBuff, StandardCharsets.UTF_8);\r\n                Assert.assertEquals(record1.get(i), value);\r\n            }\r\n            numFields = bb.getInt();\r\n            Assert.assertEquals(numFields, record2.size());\r\n            for (int i = 0; i < numFields; i++) {\r\n                int recordSize = bb.getInt();\r\n                byte[] charBuff = new byte[recordSize];\r\n                for (int j = 0; j < recordSize; j++) {\r\n                    charBuff[j] = bb.get();\r\n                }\r\n                String value = new String(charBuff, StandardCharsets.UTF_8);\r\n                Assert.assertEquals(record2.get(i), value);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.SpnegoClient.getBase64EncodedTokenForSpnegoHeader",
	"Comment": "gsscontext initiator side handling, initiates context establishment and returns thebase64 encoded token to be sent to server.",
	"Method": "String getBase64EncodedTokenForSpnegoHeader(){\r\n    final byte[] outToken = KerberosTestCase.doAsWrapper(loginContext.getSubject(), (PrivilegedExceptionAction<byte[]>) () -> gssContext.initSecContext(new byte[0], 0, 0));\r\n    return Base64.getEncoder().encodeToString(outToken);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerNotificationManager.getActionIndicesForCompactView",
	"Comment": "gets an array with the indices of the buttons to be shown in compact mode.this method can be overridden. the indices must refer to the list of actions passed as thefirst parameter.",
	"Method": "int[] getActionIndicesForCompactView(List<String> actionNames,Player player){\r\n    int pauseActionIndex = actionNames.indexOf(ACTION_PAUSE);\r\n    int playActionIndex = actionNames.indexOf(ACTION_PLAY);\r\n    return pauseActionIndex != -1 ? new int[] { pauseActionIndex } : (playActionIndex != -1 ? new int[] { playActionIndex } : new int[0]);\r\n}"
}, {
	"Path": "org.elasticsearch.test.http.MockWebServer.takeRequest",
	"Comment": "removes the first request in the list of requests and returns it to the caller.this can be used as a queue if you are sure the order of your requests.",
	"Method": "MockRequest takeRequest(){\r\n    return requests.poll();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.action.TransportStopRollupAction.awaitBusy",
	"Comment": "lifted from estestcase, must stay private and do not reuse!this is temporary untilthe rollup state refactor makes it unnecessary to await on a status change",
	"Method": "boolean awaitBusy(BooleanSupplier breakSupplier,TimeValue maxWaitTime){\r\n    long maxTimeInMillis = maxWaitTime.getMillis();\r\n    long timeInMillis = 1;\r\n    long sum = 0;\r\n    while (sum + timeInMillis < maxTimeInMillis) {\r\n        if (breakSupplier.getAsBoolean()) {\r\n            return true;\r\n        }\r\n        Thread.sleep(timeInMillis);\r\n        sum += timeInMillis;\r\n        timeInMillis = Math.min(1000L, timeInMillis * 2);\r\n    }\r\n    timeInMillis = maxTimeInMillis - sum;\r\n    Thread.sleep(Math.max(timeInMillis, 0));\r\n    return breakSupplier.getAsBoolean();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.TriggeredWatchStoreTests.testTriggeredWatchesIndexIsClosed",
	"Comment": "this is a special condition that could lead to an npe in earlier versions",
	"Method": "void testTriggeredWatchesIndexIsClosed(){\r\n    ClusterState.Builder csBuilder = new ClusterState.Builder(new ClusterName(\"_name\"));\r\n    MetaData.Builder metaDataBuilder = MetaData.builder();\r\n    metaDataBuilder.put(IndexMetaData.builder(TriggeredWatchStoreField.INDEX_NAME).settings(indexSettings).state(IndexMetaData.State.CLOSE));\r\n    csBuilder.metaData(metaDataBuilder);\r\n    assertThat(TriggeredWatchStore.validate(csBuilder.build()), is(false));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.Util.getStringForTime",
	"Comment": "returns the specified millisecond time formatted as a string.",
	"Method": "String getStringForTime(StringBuilder builder,Formatter formatter,long timeMs){\r\n    if (timeMs == C.TIME_UNSET) {\r\n        timeMs = 0;\r\n    }\r\n    long totalSeconds = (timeMs + 500) / 1000;\r\n    long seconds = totalSeconds % 60;\r\n    long minutes = (totalSeconds / 60) % 60;\r\n    long hours = totalSeconds / 3600;\r\n    builder.setLength(0);\r\n    return hours > 0 ? formatter.format(\"%d:d:d\", hours, minutes, seconds).toString() : formatter.format(\"d:d\", minutes, seconds).toString();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.AbstractDataToProcessWriter.outputFieldIndexes",
	"Comment": "create indexes of the output fields.this is the time field and all the fields configured for analysisand the control field.time is the first field and the last is the control field",
	"Method": "Map<String, Integer> outputFieldIndexes(){\r\n    Map<String, Integer> fieldIndexes = new HashMap();\r\n    fieldIndexes.put(dataDescription.getTimeField(), TIME_FIELD_OUT_INDEX);\r\n    int index = TIME_FIELD_OUT_INDEX + 1;\r\n    for (String field : analysisConfig.analysisFields()) {\r\n        if (AnalysisConfig.ML_CATEGORY_FIELD.equals(field) == false) {\r\n            fieldIndexes.put(field, index++);\r\n        }\r\n    }\r\n    if (includeTokensField) {\r\n        fieldIndexes.put(LengthEncodedWriter.PRETOKENISED_TOKEN_FIELD, index++);\r\n    }\r\n    if (includeControlField) {\r\n        fieldIndexes.put(LengthEncodedWriter.CONTROL_FIELD_NAME, index++);\r\n    }\r\n    return fieldIndexes;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleQueue.peekSourceId",
	"Comment": "peeks the source id of the next sample to be read, or the current upstream source id if thequeue is empty or if the read position is at the end of the queue.",
	"Method": "int peekSourceId(){\r\n    return metadataQueue.peekSourceId();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.datafeed.DatafeedManager.innerRun",
	"Comment": "the datafeedtask without stopping datafeed, which causes the datafeed to keep on running.",
	"Method": "void innerRun(Holder holder,long startTime,Long endTime){\r\n    holder.future = threadPool.executor(MachineLearning.DATAFEED_THREAD_POOL_NAME).submit(new AbstractRunnable() {\r\n        @Override\r\n        public void onFailure(Exception e) {\r\n            logger.error(\"Failed lookback import for job [\" + holder.datafeed.getJobId() + \"]\", e);\r\n            holder.stop(\"general_lookback_failure\", TimeValue.timeValueSeconds(20), e);\r\n        }\r\n        @Override\r\n        protected void doRun() {\r\n            Long next = null;\r\n            try {\r\n                next = holder.executeLoopBack(startTime, endTime);\r\n            } catch (DatafeedJob.ExtractionProblemException e) {\r\n                if (endTime == null) {\r\n                    next = e.nextDelayInMsSinceEpoch;\r\n                }\r\n                holder.problemTracker.reportExtractionProblem(e.getCause().getMessage());\r\n            } catch (DatafeedJob.AnalysisProblemException e) {\r\n                if (endTime == null) {\r\n                    next = e.nextDelayInMsSinceEpoch;\r\n                }\r\n                holder.problemTracker.reportAnalysisProblem(e.getCause().getMessage());\r\n                if (e.shouldStop) {\r\n                    holder.stop(\"lookback_analysis_error\", TimeValue.timeValueSeconds(20), e);\r\n                    return;\r\n                }\r\n            } catch (DatafeedJob.EmptyDataCountException e) {\r\n                if (endTime == null) {\r\n                    holder.problemTracker.reportEmptyDataCount();\r\n                    next = e.nextDelayInMsSinceEpoch;\r\n                } else {\r\n                    String lookbackNoDataMsg = Messages.getMessage(Messages.JOB_AUDIT_DATAFEED_LOOKBACK_NO_DATA);\r\n                    logger.warn(\"[{}] {}\", holder.datafeed.getJobId(), lookbackNoDataMsg);\r\n                    auditor.warning(holder.datafeed.getJobId(), lookbackNoDataMsg);\r\n                }\r\n            } catch (Exception e) {\r\n                logger.error(\"Failed lookback import for job [\" + holder.datafeed.getJobId() + \"]\", e);\r\n                holder.stop(\"general_lookback_failure\", TimeValue.timeValueSeconds(20), e);\r\n                return;\r\n            }\r\n            if (isolated == false) {\r\n                if (next != null) {\r\n                    doDatafeedRealtime(next, holder.datafeed.getJobId(), holder);\r\n                } else {\r\n                    holder.stop(\"no_realtime\", TimeValue.timeValueSeconds(20), null);\r\n                    holder.problemTracker.finishReport();\r\n                }\r\n            }\r\n        }\r\n    });\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.datafeed.DatafeedManager.innerRun",
	"Comment": "the datafeedtask without stopping datafeed, which causes the datafeed to keep on running.",
	"Method": "void innerRun(Holder holder,long startTime,Long endTime){\r\n    logger.error(\"Failed lookback import for job [\" + holder.datafeed.getJobId() + \"]\", e);\r\n    holder.stop(\"general_lookback_failure\", TimeValue.timeValueSeconds(20), e);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.datafeed.DatafeedManager.innerRun",
	"Comment": "the datafeedtask without stopping datafeed, which causes the datafeed to keep on running.",
	"Method": "void innerRun(Holder holder,long startTime,Long endTime){\r\n    Long next = null;\r\n    try {\r\n        next = holder.executeLoopBack(startTime, endTime);\r\n    } catch (DatafeedJob.ExtractionProblemException e) {\r\n        if (endTime == null) {\r\n            next = e.nextDelayInMsSinceEpoch;\r\n        }\r\n        holder.problemTracker.reportExtractionProblem(e.getCause().getMessage());\r\n    } catch (DatafeedJob.AnalysisProblemException e) {\r\n        if (endTime == null) {\r\n            next = e.nextDelayInMsSinceEpoch;\r\n        }\r\n        holder.problemTracker.reportAnalysisProblem(e.getCause().getMessage());\r\n        if (e.shouldStop) {\r\n            holder.stop(\"lookback_analysis_error\", TimeValue.timeValueSeconds(20), e);\r\n            return;\r\n        }\r\n    } catch (DatafeedJob.EmptyDataCountException e) {\r\n        if (endTime == null) {\r\n            holder.problemTracker.reportEmptyDataCount();\r\n            next = e.nextDelayInMsSinceEpoch;\r\n        } else {\r\n            String lookbackNoDataMsg = Messages.getMessage(Messages.JOB_AUDIT_DATAFEED_LOOKBACK_NO_DATA);\r\n            logger.warn(\"[{}] {}\", holder.datafeed.getJobId(), lookbackNoDataMsg);\r\n            auditor.warning(holder.datafeed.getJobId(), lookbackNoDataMsg);\r\n        }\r\n    } catch (Exception e) {\r\n        logger.error(\"Failed lookback import for job [\" + holder.datafeed.getJobId() + \"]\", e);\r\n        holder.stop(\"general_lookback_failure\", TimeValue.timeValueSeconds(20), e);\r\n        return;\r\n    }\r\n    if (isolated == false) {\r\n        if (next != null) {\r\n            doDatafeedRealtime(next, holder.datafeed.getJobId(), holder);\r\n        } else {\r\n            holder.stop(\"no_realtime\", TimeValue.timeValueSeconds(20), null);\r\n            holder.problemTracker.finishReport();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.SpnegoHttpClientConfigCallbackHandler.doAsPrivilegedWrapper",
	"Comment": "privileged wrapper that invokes action with subject.doas to perform work asgiven subject.",
	"Method": "T doAsPrivilegedWrapper(Subject subject,PrivilegedExceptionAction<T> action,AccessControlContext acc){\r\n    try {\r\n        return AccessController.doPrivileged((PrivilegedExceptionAction<T>) () -> Subject.doAsPrivileged(subject, action, acc));\r\n    } catch (PrivilegedActionException pae) {\r\n        if (pae.getCause() instanceof PrivilegedActionException) {\r\n            throw (PrivilegedActionException) pae.getCause();\r\n        }\r\n        throw pae;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.crypto.CryptoService.encrypt",
	"Comment": "encrypts the provided char array and returns the encrypted values in a char array",
	"Method": "char[] encrypt(char[] chars){\r\n    byte[] charBytes = CharArrays.toUtf8Bytes(chars);\r\n    String base64 = Base64.getEncoder().encodeToString(encryptInternal(charBytes, encryptionKey));\r\n    return ENCRYPTED_TEXT_PREFIX.concat(base64).toCharArray();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherIndexingListenerTests.testOnNonDataNodes",
	"Comment": "ensure that non data nodes, deal properly with this cluster state listener",
	"Method": "void testOnNonDataNodes(){\r\n    listener.setConfiguration(INACTIVE);\r\n    Index index = new Index(Watch.INDEX, \"foo\");\r\n    ShardId shardId = new ShardId(index, 0);\r\n    ShardRouting shardRouting = TestShardRouting.newShardRouting(shardId, \"node2\", true, STARTED);\r\n    IndexRoutingTable.Builder indexRoutingTable = IndexRoutingTable.builder(index).addShard(shardRouting);\r\n    DiscoveryNode node1 = new DiscoveryNode(\"node_1\", ESTestCase.buildNewFakeTransportAddress(), Collections.emptyMap(), new HashSet(Collections.singletonList(randomFrom(DiscoveryNode.Role.INGEST, DiscoveryNode.Role.MASTER))), Version.CURRENT);\r\n    DiscoveryNode node2 = new DiscoveryNode(\"node_2\", ESTestCase.buildNewFakeTransportAddress(), Collections.emptyMap(), new HashSet(Collections.singletonList(DiscoveryNode.Role.DATA)), Version.CURRENT);\r\n    DiscoveryNode node3 = new DiscoveryNode(\"node_3\", ESTestCase.buildNewFakeTransportAddress(), Collections.emptyMap(), new HashSet(Collections.singletonList(DiscoveryNode.Role.DATA)), Version.CURRENT);\r\n    IndexMetaData.Builder indexMetaDataBuilder = createIndexBuilder(Watch.INDEX, 1, 0);\r\n    ClusterState previousState = ClusterState.builder(new ClusterName(\"my-cluster\")).metaData(MetaData.builder().put(indexMetaDataBuilder)).nodes(new DiscoveryNodes.Builder().masterNodeId(\"node_1\").localNodeId(\"node_1\").add(node1).add(node2).add(node3)).routingTable(RoutingTable.builder().add(indexRoutingTable).build()).build();\r\n    IndexMetaData.Builder newIndexMetaDataBuilder = createIndexBuilder(Watch.INDEX, 1, 1);\r\n    ShardRouting replicaShardRouting = TestShardRouting.newShardRouting(shardId, \"node3\", false, STARTED);\r\n    IndexRoutingTable.Builder newRoutingTable = IndexRoutingTable.builder(index).addShard(shardRouting).addShard(replicaShardRouting);\r\n    ClusterState currentState = ClusterState.builder(new ClusterName(\"my-cluster\")).metaData(MetaData.builder().put(newIndexMetaDataBuilder)).nodes(new DiscoveryNodes.Builder().masterNodeId(\"node_1\").localNodeId(\"node_1\").add(node1).add(node2).add(node3)).routingTable(RoutingTable.builder().add(newRoutingTable).build()).build();\r\n    ClusterChangedEvent event = new ClusterChangedEvent(\"something\", currentState, previousState);\r\n    listener.clusterChanged(event);\r\n    assertThat(listener.getConfiguration(), is(INACTIVE));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfiguration.trustConfig",
	"Comment": "the configuration of trust material that will be used as part of this ssl configuration",
	"Method": "TrustConfig trustConfig(){\r\n    return trustConfig;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.proto.SqlQueryRequest.params",
	"Comment": "an optional list of parameters if the sql query is parametrized",
	"Method": "List<SqlTypedParamValue> params(){\r\n    return params;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.MediaCodecVideoRenderer.shouldDropBuffersToKeyframe",
	"Comment": "returns whether to drop all buffers from the buffer being processed to the keyframe at or afterthe current playback position, if possible.",
	"Method": "boolean shouldDropBuffersToKeyframe(long earlyUs,long elapsedRealtimeUs){\r\n    return isBufferVeryLate(earlyUs);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.AbstractDataToProcessWriter.transformTimeAndWrite",
	"Comment": "transform the date in the input data and write all fields to the length encoded writer.fieldsmust be copied from input to output before this function is called.",
	"Method": "boolean transformTimeAndWrite(String[] record,long numberOfFieldsRead){\r\n    long epochMs;\r\n    try {\r\n        epochMs = dateTransformer.transform(record[TIME_FIELD_OUT_INDEX]);\r\n    } catch (CannotParseTimestampException e) {\r\n        dataCountsReporter.reportDateParseError(numberOfFieldsRead);\r\n        logger.error(e.getMessage());\r\n        return false;\r\n    }\r\n    record[TIME_FIELD_OUT_INDEX] = Long.toString(epochMs / MS_IN_SECOND);\r\n    if (epochMs / MS_IN_SECOND < latestEpochMs / MS_IN_SECOND - latencySeconds) {\r\n        dataCountsReporter.reportOutOfOrderRecord(numberOfFieldsRead);\r\n        if (epochMs > latestEpochMsThisUpload) {\r\n            latestEpochMsThisUpload = epochMs;\r\n            dataCountsReporter.reportLatestTimeIncrementalStats(latestEpochMsThisUpload);\r\n        }\r\n        return false;\r\n    }\r\n    latestEpochMs = Math.max(latestEpochMs, epochMs);\r\n    latestEpochMsThisUpload = latestEpochMs;\r\n    autodetectProcess.writeRecord(record);\r\n    dataCountsReporter.reportRecordWritten(numberOfFieldsRead, epochMs);\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.NoSampleRenderer.getConfiguration",
	"Comment": "returns the configuration set when the renderer was most recently enabled.",
	"Method": "RendererConfiguration getConfiguration(){\r\n    return configuration;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.crypto.AesFlushingCipherTest.testAligned",
	"Comment": "test several encrypt and decrypt calls, each aligned on a 16 byte block size.",
	"Method": "void testAligned(){\r\n    byte[] reference = TestUtil.buildTestData(DATA_LENGTH);\r\n    byte[] data = reference.clone();\r\n    Random random = new Random(RANDOM_SEED);\r\n    int offset = 0;\r\n    while (offset < data.length) {\r\n        int bytes = (1 + random.nextInt(50)) * 16;\r\n        bytes = Math.min(bytes, data.length - offset);\r\n        assertThat(bytes % 16).isEqualTo(0);\r\n        encryptCipher.updateInPlace(data, offset, bytes);\r\n        offset += bytes;\r\n    }\r\n    int unchangedByteCount = data.length - getDifferingByteCount(reference, data);\r\n    assertThat(unchangedByteCount <= getMaxUnchangedBytesAllowedPostEncryption(data.length)).isTrue();\r\n    offset = 0;\r\n    while (offset < data.length) {\r\n        int bytes = (1 + random.nextInt(50)) * 16;\r\n        bytes = Math.min(bytes, data.length - offset);\r\n        assertThat(bytes % 16).isEqualTo(0);\r\n        decryptCipher.updateInPlace(data, offset, bytes);\r\n        offset += bytes;\r\n    }\r\n    int differingByteCount = getDifferingByteCount(reference, data);\r\n    assertThat(differingByteCount).isEqualTo(0);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.watch.ClockMock.fastForwardSeconds",
	"Comment": "freeze the clock if not frozen and advance it by the given amount of seconds",
	"Method": "void fastForwardSeconds(int seconds){\r\n    fastForward(TimeValue.timeValueSeconds(seconds));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.HlsChunkSource.maybeThrowError",
	"Comment": "if the source is currently having difficulty providing chunks, then this method throws theunderlying error. otherwise does nothing.",
	"Method": "void maybeThrowError(){\r\n    if (fatalError != null) {\r\n        throw fatalError;\r\n    }\r\n    if (expectedPlaylistUrl != null && seenExpectedPlaylistError) {\r\n        playlistTracker.maybeThrowPlaylistRefreshError(expectedPlaylistUrl);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.token.CreateTokenRequestBuilder.setGrantType",
	"Comment": "specifies the grant type for this request. currently only password is supported",
	"Method": "CreateTokenRequestBuilder setGrantType(String grantType){\r\n    request.setGrantType(grantType);\r\n    return this;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.TrackFragment.sampleHasSubsampleEncryptionTable",
	"Comment": "returns whether the sample at the given index has a subsample encryption table.",
	"Method": "boolean sampleHasSubsampleEncryptionTable(int index){\r\n    return definesEncryptionData && sampleHasSubsampleEncryptionTable[index];\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLService.supportedCiphers",
	"Comment": "returns the intersection of the supported ciphers with the requested ciphers. this method will also optionally log if unsupportedciphers were requested.",
	"Method": "String[] supportedCiphers(String[] supportedCiphers,List<String> requestedCiphers,boolean log){\r\n    List<String> supportedCiphersList = new ArrayList(requestedCiphers.size());\r\n    List<String> unsupportedCiphers = new LinkedList();\r\n    boolean found;\r\n    for (String requestedCipher : requestedCiphers) {\r\n        found = false;\r\n        for (String supportedCipher : supportedCiphers) {\r\n            if (supportedCipher.equals(requestedCipher)) {\r\n                found = true;\r\n                supportedCiphersList.add(requestedCipher);\r\n                break;\r\n            }\r\n        }\r\n        if (!found) {\r\n            unsupportedCiphers.add(requestedCipher);\r\n        }\r\n    }\r\n    if (supportedCiphersList.isEmpty()) {\r\n        throw new IllegalArgumentException(\"none of the ciphers \" + Arrays.toString(requestedCiphers.toArray()) + \" are supported by this JVM\");\r\n    }\r\n    if (log && !unsupportedCiphers.isEmpty()) {\r\n        logger.error(\"unsupported ciphers [{}] were requested but cannot be used in this JVM, however there are supported ciphers \" + \"that will be used [{}]. If you are trying to use ciphers with a key length greater than 128 bits on an Oracle JVM, \" + \"you will need to install the unlimited strength JCE policy files.\", unsupportedCiphers, supportedCiphersList);\r\n    }\r\n    return supportedCiphersList.toArray(new String[supportedCiphersList.size()]);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.dash.manifest.DashManifestParser.parseAdaptationSetChild",
	"Comment": "parses children of adaptationset elements not specifically parsed elsewhere.",
	"Method": "void parseAdaptationSetChild(XmlPullParser xpp){\r\n    maybeSkipTag(xpp);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.test.rest.XPackRestIT.enableMonitoring",
	"Comment": "enable monitoring and waits for monitoring documents to be collected and indexed inmonitoring indices.this is the signal that the local exporter is started and readyfor the tests.",
	"Method": "void enableMonitoring(){\r\n    if (isMonitoringTest()) {\r\n        final ClientYamlTestResponse xpackUsage = callApi(\"xpack.usage\", singletonMap(\"filter_path\", \"monitoring.enabled_exporters\"), emptyList(), getApiCallHeaders());\r\n        @SuppressWarnings(\"unchecked\")\r\n        final Map<String, Object> exporters = (Map<String, Object>) xpackUsage.evaluate(\"monitoring.enabled_exporters\");\r\n        assertNotNull(\"List of monitoring exporters must not be null\", exporters);\r\n        assertThat(\"List of enabled exporters must be empty before enabling monitoring\", XContentMapValues.extractRawValues(\"monitoring.enabled_exporters\", exporters), hasSize(0));\r\n        final Map<String, Object> settings = new HashMap();\r\n        settings.put(\"xpack.monitoring.collection.enabled\", true);\r\n        settings.put(\"xpack.monitoring.collection.interval\", \"1s\");\r\n        settings.put(\"xpack.monitoring.exporters._local.enabled\", true);\r\n        awaitCallApi(\"cluster.put_settings\", emptyMap(), singletonList(singletonMap(\"transient\", settings)), response -> {\r\n            Object acknowledged = response.evaluate(\"acknowledged\");\r\n            return acknowledged != null && (Boolean) acknowledged;\r\n        }, () -> \"Exception when enabling monitoring\");\r\n        awaitCallApi(\"search\", singletonMap(\"index\", \".monitoring-*\"), emptyList(), response -> ((Number) response.evaluate(\"hits.total\")).intValue() > 0, () -> \"Exception when waiting for monitoring documents to be indexed\");\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.exporter.Exporter.isSingleton",
	"Comment": "returns true if only one instance of this exporter should be allowed.",
	"Method": "boolean isSingleton(){\r\n    return false;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.vp9.VpxLibrary.getVersion",
	"Comment": "returns the version of the underlying library if available, or null otherwise.",
	"Method": "String getVersion(){\r\n    return isAvailable() ? vpxGetVersion() : null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.SimpleExoPlayer.getVideoFormat",
	"Comment": "returns the video format currently being played, or null if no video is being played.",
	"Method": "Format getVideoFormat(){\r\n    return videoFormat;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.token.InvalidateTokenResponse.isCreated",
	"Comment": "if the token is already invalidated then created will be false",
	"Method": "boolean isCreated(){\r\n    return created;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.persistence.JobResultsPersister.commitStateWrites",
	"Comment": "once the job state has been written calling this function makes itimmediately searchable.",
	"Method": "void commitStateWrites(String jobId){\r\n    String indexName = AnomalyDetectorsIndex.jobStateIndexName();\r\n    logger.trace(\"[{}] ES API CALL: refresh index {}\", jobId, indexName);\r\n    RefreshRequest refreshRequest = new RefreshRequest(indexName);\r\n    refreshRequest.indicesOptions(IndicesOptions.lenientExpandOpen());\r\n    try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {\r\n        client.admin().indices().refresh(refreshRequest).actionGet();\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.MediaCodecVideoRenderer.shouldDropOutputBuffer",
	"Comment": "returns whether the buffer being processed should be dropped.",
	"Method": "boolean shouldDropOutputBuffer(long earlyUs,long elapsedRealtimeUs){\r\n    return isBufferLate(earlyUs);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.spherical.ProjectionDecoder.isProj",
	"Comment": "returns true if the input contains a proj box. indicates mp4 container.",
	"Method": "boolean isProj(ParsableByteArray input){\r\n    input.skipBytes(4);\r\n    int type = input.readInt();\r\n    input.setPosition(0);\r\n    return type == TYPE_PROJ;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.AbstractDataToProcessWriter.writeHeader",
	"Comment": "write the header.the header is created from the list of analysis input fields, the time field and the control field.",
	"Method": "void writeHeader(){\r\n    Map<String, Integer> outFieldIndexes = outputFieldIndexes();\r\n    int numFields = outFieldIndexes.size();\r\n    String[] record = new String[numFields];\r\n    for (Map.Entry<String, Integer> entry : outFieldIndexes.entrySet()) {\r\n        record[entry.getValue()] = entry.getKey();\r\n    }\r\n    autodetectProcess.writeRecord(record);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.history.HistoryStore.put",
	"Comment": "stores the specified watchrecord.if the specified watchrecord already was stored this call will fail with a version conflict.",
	"Method": "void put(WatchRecord watchRecord){\r\n    String index = HistoryStoreField.getHistoryIndexNameForTime(watchRecord.triggerEvent().triggeredTime());\r\n    try (XContentBuilder builder = XContentFactory.jsonBuilder()) {\r\n        watchRecord.toXContent(builder, WatcherParams.HIDE_SECRETS);\r\n        IndexRequest request = new IndexRequest(index, DOC_TYPE, watchRecord.id().value()).source(builder);\r\n        request.opType(IndexRequest.OpType.CREATE);\r\n        bulkProcessor.add(request);\r\n    } catch (IOException ioe) {\r\n        throw ioException(\"failed to persist watch record [{}]\", ioe, watchRecord);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfiguration.filesToMonitor",
	"Comment": "provides the list of paths to files that back this configuration",
	"Method": "List<Path> filesToMonitor(Environment environment){\r\n    if (keyConfig() == trustConfig()) {\r\n        return keyConfig().filesToMonitor(environment);\r\n    }\r\n    List<Path> paths = new ArrayList(keyConfig().filesToMonitor(environment));\r\n    paths.addAll(trustConfig().filesToMonitor(environment));\r\n    return paths;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.mediasession.MediaSessionConnector.invalidateMediaSessionMetadata",
	"Comment": "updates the metadata of the media session.apps normally only need to call this method when the backing data for a given media item haschanged and the metadata should be updated immediately.",
	"Method": "void invalidateMediaSessionMetadata(){\r\n    if (mediaMetadataProvider != null && player != null) {\r\n        mediaSession.setMetadata(mediaMetadataProvider.getMetadata(player));\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.offline.HlsDownloadHelper.getPlaylist",
	"Comment": "returns the hls playlist. must not be called until after preparation completes.",
	"Method": "HlsPlaylist getPlaylist(){\r\n    Assertions.checkNotNull(playlist);\r\n    return playlist;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.FileStructureUtils.isMoreLikelyTextThanKeyword",
	"Comment": "the thinking is that the longer the field value and the more spaces it contains,the more likely it is that it should be indexed as text rather than keyword.",
	"Method": "boolean isMoreLikelyTextThanKeyword(String str){\r\n    int length = str.length();\r\n    return length > KEYWORD_MAX_LEN || length - str.replaceAll(\"\\\\s\", \"\").length() > KEYWORD_MAX_SPACES;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.plugin.CliFormatterCursor.wrap",
	"Comment": "if the newcursor is empty, returns an empty cursor. otherwise, creates a newcliformattercursor that wraps the newcursor.",
	"Method": "Cursor wrap(Cursor newCursor,CliFormatter formatter){\r\n    if (newCursor == EMPTY) {\r\n        return EMPTY;\r\n    }\r\n    return new CliFormatterCursor(newCursor, formatter);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.Sonic.flush",
	"Comment": "clears state in preparation for receiving a new stream of input buffers.",
	"Method": "void flush(){\r\n    inputFrameCount = 0;\r\n    outputFrameCount = 0;\r\n    pitchFrameCount = 0;\r\n    oldRatePosition = 0;\r\n    newRatePosition = 0;\r\n    remainingInputToCopyFrameCount = 0;\r\n    prevPeriod = 0;\r\n    prevMinDiff = 0;\r\n    minDiff = 0;\r\n    maxDiff = 0;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.execution.ExecutionService.createTriggeredWatchesAndContext",
	"Comment": "create a tuple of triggered watches and their corresponding contexts, usable for sync and async processing",
	"Method": "Tuple<List<TriggeredWatch>, List<TriggeredExecutionContext>> createTriggeredWatchesAndContext(Iterable<TriggerEvent> events){\r\n    final LinkedList<TriggeredWatch> triggeredWatches = new LinkedList();\r\n    final LinkedList<TriggeredExecutionContext> contexts = new LinkedList();\r\n    DateTime now = new DateTime(clock.millis(), UTC);\r\n    for (TriggerEvent event : events) {\r\n        GetResponse response = getWatch(event.jobName());\r\n        if (response.isExists() == false) {\r\n            logger.warn(\"unable to find watch [{}] in watch index, perhaps it has been deleted\", event.jobName());\r\n            continue;\r\n        }\r\n        TriggeredExecutionContext ctx = new TriggeredExecutionContext(event.jobName(), now, event, defaultThrottlePeriod);\r\n        contexts.add(ctx);\r\n        triggeredWatches.add(new TriggeredWatch(ctx.id(), event));\r\n    }\r\n    return Tuple.tuple(triggeredWatches, contexts);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.MediaSourceTestRunner.assertTimelineChangeBlocking",
	"Comment": "asserts that the source notifies its listener of a single timeline change. if the source hasnot yet notified its listener, it has up to the timeout passed to the constructor to do so.",
	"Method": "Timeline assertTimelineChangeBlocking(){\r\n    try {\r\n        timeline = timelines.poll(TIMEOUT_MS, TimeUnit.MILLISECONDS);\r\n        assertThat(timeline).isNotNull();\r\n        assertNoTimelineChange();\r\n        return timeline;\r\n    } catch (InterruptedException e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.realm.ClearRealmCacheRequest.realms",
	"Comment": "sets the realms for which caches will be evicted. when not set all the caches of all realms will beevicted.",
	"Method": "String[] realms(ClearRealmCacheRequest realms,String realms){\r\n    this.realms = realms;\r\n    return this;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.PsshAtomUtil.buildPsshAtom",
	"Comment": "builds a pssh atom for the given system id, containing the given key ids and data.",
	"Method": "byte[] buildPsshAtom(UUID systemId,byte[] data,byte[] buildPsshAtom,UUID systemId,UUID[] keyIds,byte[] data){\r\n    int dataLength = data != null ? data.length : 0;\r\n    int psshBoxLength = Atom.FULL_HEADER_SIZE + 16 + 4 + dataLength;\r\n    if (keyIds != null) {\r\n        psshBoxLength += 4 + (keyIds.length * 16);\r\n    }\r\n    ByteBuffer psshBox = ByteBuffer.allocate(psshBoxLength);\r\n    psshBox.putInt(psshBoxLength);\r\n    psshBox.putInt(Atom.TYPE_pssh);\r\n    psshBox.putInt(keyIds != null ? 0x01000000 : 0);\r\n    psshBox.putLong(systemId.getMostSignificantBits());\r\n    psshBox.putLong(systemId.getLeastSignificantBits());\r\n    if (keyIds != null) {\r\n        psshBox.putInt(keyIds.length);\r\n        for (UUID keyId : keyIds) {\r\n            psshBox.putLong(keyId.getMostSignificantBits());\r\n            psshBox.putLong(keyId.getLeastSignificantBits());\r\n        }\r\n    }\r\n    if (data != null && data.length != 0) {\r\n        psshBox.putInt(data.length);\r\n        psshBox.put(data);\r\n    }\r\n    return psshBox.array();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.AutodetectControlMsgWriter.create",
	"Comment": "create the control message writer with a outputstream. alengthencodedwriter is created on the outputstream parameter",
	"Method": "AutodetectControlMsgWriter create(OutputStream os,int numberOfFields){\r\n    return new AutodetectControlMsgWriter(new LengthEncodedWriter(os), numberOfFields);\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.Type.getType",
	"Comment": "returns the java type corresponding to the given type descriptor.",
	"Method": "Type getType(String typeDescriptor,Type getType,char[] buf,int off){\r\n    int len;\r\n    switch(buf[off]) {\r\n        case 'V':\r\n            return VOID_TYPE;\r\n        case 'Z':\r\n            return BOOLEAN_TYPE;\r\n        case 'C':\r\n            return CHAR_TYPE;\r\n        case 'B':\r\n            return BYTE_TYPE;\r\n        case 'S':\r\n            return SHORT_TYPE;\r\n        case 'I':\r\n            return INT_TYPE;\r\n        case 'F':\r\n            return FLOAT_TYPE;\r\n        case 'J':\r\n            return LONG_TYPE;\r\n        case 'D':\r\n            return DOUBLE_TYPE;\r\n        case '[':\r\n            len = 1;\r\n            while (buf[off + len] == '[') {\r\n                ++len;\r\n            }\r\n            if (buf[off + len] == 'L') {\r\n                ++len;\r\n                while (buf[off + len] != ';') {\r\n                    ++len;\r\n                }\r\n            }\r\n            return new Type(9, buf, off, len + 1);\r\n        default:\r\n            len = 1;\r\n            while (buf[off + len] != ';') {\r\n                ++len;\r\n            }\r\n            return new Type(10, buf, off + 1, len - 1);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.execution.WatchExecutionContext.getUsernameFromWatch",
	"Comment": "given a watch, this extracts and decodes the relevant auth header and returns the principal of the user that isexecuting the watch.",
	"Method": "String getUsernameFromWatch(Watch watch){\r\n    if (watch != null && watch.status() != null && watch.status().getHeaders() != null) {\r\n        String header = watch.status().getHeaders().get(AuthenticationField.AUTHENTICATION_KEY);\r\n        if (header != null) {\r\n            Authentication auth = Authentication.decode(header);\r\n            return auth.getUser().principal();\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerControlView.getShowTimeoutMs",
	"Comment": "returns the playback controls timeout. the playback controls are automatically hidden afterthis duration of time has elapsed without user input.",
	"Method": "int getShowTimeoutMs(){\r\n    return showTimeoutMs;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.Util.isLocalFileUri",
	"Comment": "returns true if the uri is a path to a local file or a reference to a local file.",
	"Method": "boolean isLocalFileUri(Uri uri){\r\n    String scheme = uri.getScheme();\r\n    return TextUtils.isEmpty(scheme) || \"file\".equals(scheme);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authz.AuthorizationUtils.shouldSetUserBasedOnActionOrigin",
	"Comment": "returns true if the thread context contains the origin of the action and does not have any authentication",
	"Method": "boolean shouldSetUserBasedOnActionOrigin(ThreadContext context){\r\n    final String actionOrigin = context.getTransient(ClientHelper.ACTION_ORIGIN_TRANSIENT_NAME);\r\n    final Authentication authentication = context.getTransient(AuthenticationField.AUTHENTICATION_KEY);\r\n    return actionOrigin != null && authentication == null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.text.webvtt.WebvttCueParser.parseCue",
	"Comment": "parses the next valid webvtt cue in a parsable array, including timestamps, settings and text.",
	"Method": "boolean parseCue(ParsableByteArray webvttData,WebvttCue.Builder builder,List<WebvttCssStyle> styles,boolean parseCue,String id,Matcher cueHeaderMatcher,ParsableByteArray webvttData,WebvttCue.Builder builder,StringBuilder textBuilder,List<WebvttCssStyle> styles){\r\n    try {\r\n        builder.setStartTime(WebvttParserUtil.parseTimestampUs(cueHeaderMatcher.group(1))).setEndTime(WebvttParserUtil.parseTimestampUs(cueHeaderMatcher.group(2)));\r\n    } catch (NumberFormatException e) {\r\n        Log.w(TAG, \"Skipping cue with bad header: \" + cueHeaderMatcher.group());\r\n        return false;\r\n    }\r\n    parseCueSettingsList(cueHeaderMatcher.group(3), builder);\r\n    textBuilder.setLength(0);\r\n    String line;\r\n    while (!TextUtils.isEmpty(line = webvttData.readLine())) {\r\n        if (textBuilder.length() > 0) {\r\n            textBuilder.append(\"\\n\");\r\n        }\r\n        textBuilder.append(line.trim());\r\n    }\r\n    parseCueText(id, textBuilder.toString(), builder, styles);\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.NalUnitUtil.isNalUnitSei",
	"Comment": "returns whether the nal unit with the specified header contains supplemental enhancementinformation.",
	"Method": "boolean isNalUnitSei(String mimeType,byte nalUnitHeaderFirstByte){\r\n    return (MimeTypes.VIDEO_H264.equals(mimeType) && (nalUnitHeaderFirstByte & 0x1F) == H264_NAL_UNIT_TYPE_SEI) || (MimeTypes.VIDEO_H265.equals(mimeType) && ((nalUnitHeaderFirstByte & 0x7E) >> 1) == H265_NAL_UNIT_TYPE_PREFIX_SEI);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.DefaultTimeBar.setBufferedColor",
	"Comment": "sets the color for the portion of the time bar after the current played position up to thecurrent buffered position.",
	"Method": "void setBufferedColor(int bufferedColor){\r\n    bufferedPaint.setColor(bufferedColor);\r\n    invalidate(seekBounds);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.flac.FlacDecoderJni.reset",
	"Comment": "resets internal state of the decoder and sets the stream position.",
	"Method": "void reset(long newPosition){\r\n    flacReset(nativeDecoderContext, newPosition);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.AudioTrackPositionTracker.handleEndOfStream",
	"Comment": "records the writing position at which the stream ended, so that the reported position cancontinue to increment while remaining data is played out.",
	"Method": "void handleEndOfStream(long writtenFrames){\r\n    stopPlaybackHeadPosition = getPlaybackHeadPosition();\r\n    stopTimestampUs = SystemClock.elapsedRealtime() * 1000;\r\n    endPlaybackHeadPosition = writtenFrames;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.ExoPlayerTestRunner.start",
	"Comment": "starts the test runner on its own thread. this will trigger the creation of the player, thelistener registration, the start of the action schedule, and the preparation of the playerwith the provided media source.",
	"Method": "ExoPlayerTestRunner start(){\r\n    handler.post(() -> {\r\n        try {\r\n            player = new TestSimpleExoPlayer(context, renderersFactory, trackSelector, loadControl, bandwidthMeter, clock);\r\n            player.addListener(ExoPlayerTestRunner.this);\r\n            if (eventListener != null) {\r\n                player.addListener(eventListener);\r\n            }\r\n            if (analyticsListener != null) {\r\n                player.addAnalyticsListener(analyticsListener);\r\n            }\r\n            player.setPlayWhenReady(true);\r\n            if (actionSchedule != null) {\r\n                actionSchedule.start(player, trackSelector, null, handler, ExoPlayerTestRunner.this);\r\n            }\r\n            player.prepare(mediaSource);\r\n        } catch (Exception e) {\r\n            handleException(e);\r\n        }\r\n    });\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.UserSettings.getUser",
	"Comment": "returns the current user information, or null if the current request has no authentication info.",
	"Method": "User getUser(){\r\n    Authentication authentication = getAuthentication();\r\n    return authentication == null ? null : authentication.getUser();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.PlayerMessage.setPosition",
	"Comment": "sets a position in a window at which the message will be delivered.",
	"Method": "PlayerMessage setPosition(long positionMs,PlayerMessage setPosition,int windowIndex,long positionMs){\r\n    Assertions.checkState(!isSent);\r\n    Assertions.checkArgument(positionMs != C.TIME_UNSET);\r\n    if (windowIndex < 0 || (!timeline.isEmpty() && windowIndex >= timeline.getWindowCount())) {\r\n        throw new IllegalSeekPositionException(timeline, windowIndex, positionMs);\r\n    }\r\n    this.windowIndex = windowIndex;\r\n    this.positionMs = positionMs;\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherService.parseWatchOnThisNode",
	"Comment": "find out if the watch with this id, should be parsed and triggered on this node",
	"Method": "boolean parseWatchOnThisNode(String id,int totalShardCount,int index){\r\n    int hash = Murmur3HashFunction.hash(id);\r\n    int shardIndex = Math.floorMod(hash, totalShardCount);\r\n    return shardIndex == index;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.collector.cluster.ClusterStatsMonitoringDoc.nodesHash",
	"Comment": "create a simple hash value that can be used to determine if the nodes listing has changed since the last report.",
	"Method": "int nodesHash(DiscoveryNodes nodes){\r\n    final StringBuilder temp = new StringBuilder();\r\n    for (final DiscoveryNode node : nodes) {\r\n        temp.append(node.getEphemeralId());\r\n    }\r\n    return temp.toString().hashCode();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.DataCountsReporter.reportLatestTimeIncrementalStats",
	"Comment": "update only the incremental stats with the newest record time",
	"Method": "void reportLatestTimeIncrementalStats(long latestRecordTimeMs){\r\n    incrementalRecordStats.setLatestRecordTimeStamp(new Date(latestRecordTimeMs));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.LibraryLoader.isAvailable",
	"Comment": "returns whether the underlying libraries are available, loading them if necessary.",
	"Method": "boolean isAvailable(){\r\n    if (loadAttempted) {\r\n        return isAvailable;\r\n    }\r\n    loadAttempted = true;\r\n    try {\r\n        for (String lib : nativeLibraries) {\r\n            System.loadLibrary(lib);\r\n        }\r\n        isAvailable = true;\r\n    } catch (UnsatisfiedLinkError exception) {\r\n    }\r\n    return isAvailable;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.token.CreateTokenRequestBuilder.setUsername",
	"Comment": "set the username to be used for authentication with a password grant",
	"Method": "CreateTokenRequestBuilder setUsername(String username){\r\n    request.setUsername(username);\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.categorization.GrokPatternCreator.findBestGrokMatchFromExamples",
	"Comment": "given a category definition regex and a collection of examples from the category, returna grok pattern that will match the category and pull out any likely fields.the extractedfields are given pretty generic names, but unique within the grok pattern provided.theexpectation is that a user will adjust the extracted field names based on their domainknowledge.",
	"Method": "String findBestGrokMatchFromExamples(String jobId,String regex,Collection<String> examples){\r\n    String[] fixedRegexBits = regex.split(\"\\\\.[*+]\\\\??\");\r\n    Pattern exampleProcessor = Pattern.compile(regex.replaceAll(\"(\\\\.[*+]\\\\??)\", \"($1)\"), Pattern.DOTALL);\r\n    List<Collection<String>> groupsMatchesFromExamples = new ArrayList(fixedRegexBits.length);\r\n    for (int i = 0; i < fixedRegexBits.length; ++i) {\r\n        groupsMatchesFromExamples.add(new ArrayList(examples.size()));\r\n    }\r\n    for (String example : examples) {\r\n        Matcher matcher = exampleProcessor.matcher(example);\r\n        if (matcher.matches()) {\r\n            assert matcher.groupCount() == fixedRegexBits.length;\r\n            for (int groupNum = 1; groupNum <= matcher.groupCount(); ++groupNum) {\r\n                groupsMatchesFromExamples.get(groupNum - 1).add(matcher.group(groupNum));\r\n            }\r\n        } else {\r\n            assert matcher.matches() : exampleProcessor.pattern() + \" did not match \" + example;\r\n            LogManager.getLogger(GrokPatternCreator.class).error(\"[{}] Pattern [{}] did not match example [{}]\", jobId, exampleProcessor.pattern(), example);\r\n        }\r\n    }\r\n    Map<String, Integer> fieldNameCountStore = new HashMap();\r\n    StringBuilder overallGrokPatternBuilder = new StringBuilder();\r\n    for (int inBetweenBitNum = 0; inBetweenBitNum < groupsMatchesFromExamples.size(); ++inBetweenBitNum) {\r\n        overallGrokPatternBuilder.append(fixedRegexBits[inBetweenBitNum]);\r\n        appendBestGrokMatchForStrings(fieldNameCountStore, overallGrokPatternBuilder, inBetweenBitNum == 0, inBetweenBitNum == fixedRegexBits.length - 1, groupsMatchesFromExamples.get(inBetweenBitNum));\r\n    }\r\n    return overallGrokPatternBuilder.toString();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.CompositeMediaSource.getWindowIndexForChildWindowIndex",
	"Comment": "returns the window index in the composite source corresponding to the specified window index ina child source. the default implementation does not change the window index.",
	"Method": "int getWindowIndexForChildWindowIndex(T id,int windowIndex){\r\n    return windowIndex;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.readLittleEndianLong",
	"Comment": "reads the next eight bytes as a signed value in little endian order.",
	"Method": "long readLittleEndianLong(){\r\n    return (data[position++] & 0xFFL) | (data[position++] & 0xFFL) << 8 | (data[position++] & 0xFFL) << 16 | (data[position++] & 0xFFL) << 24 | (data[position++] & 0xFFL) << 32 | (data[position++] & 0xFFL) << 40 | (data[position++] & 0xFFL) << 48 | (data[position++] & 0xFFL) << 56;\r\n}"
}, {
	"Path": "org.greenrobot.eventbus.EventBus.unsubscribeByEventType",
	"Comment": "only updates subscriptionsbyeventtype, not typesbysubscriber! caller must update typesbysubscriber.",
	"Method": "void unsubscribeByEventType(Object subscriber,Class<?> eventType){\r\n    List<Subscription> subscriptions = subscriptionsByEventType.get(eventType);\r\n    if (subscriptions != null) {\r\n        int size = subscriptions.size();\r\n        for (int i = 0; i < size; i++) {\r\n            Subscription subscription = subscriptions.get(i);\r\n            if (subscription.subscriber == subscriber) {\r\n                subscription.active = false;\r\n                subscriptions.remove(i);\r\n                i--;\r\n                size--;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.updateCodecOperatingRate",
	"Comment": "updates the codec operating rate, and the codec itself if necessary.",
	"Method": "void updateCodecOperatingRate(){\r\n    if (format == null || Util.SDK_INT < 23) {\r\n        return;\r\n    }\r\n    float codecOperatingRate = getCodecOperatingRate(rendererOperatingRate, format, getStreamFormats());\r\n    if (this.codecOperatingRate == codecOperatingRate) {\r\n        return;\r\n    }\r\n    this.codecOperatingRate = codecOperatingRate;\r\n    if (codec == null || codecReinitializationState != REINITIALIZATION_STATE_NONE) {\r\n    } else if (codecOperatingRate == CODEC_OPERATING_RATE_UNSET && codecConfiguredWithOperatingRate) {\r\n        reinitializeCodec();\r\n    } else if (codecOperatingRate != CODEC_OPERATING_RATE_UNSET && (codecConfiguredWithOperatingRate || codecOperatingRate > assumedMinimumCodecOperatingRate)) {\r\n        Bundle codecParameters = new Bundle();\r\n        codecParameters.putFloat(MediaFormat.KEY_OPERATING_RATE, codecOperatingRate);\r\n        codec.setParameters(codecParameters);\r\n        codecConfiguredWithOperatingRate = true;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.qa.cli.EmbeddedCli.forceClose",
	"Comment": "shutdown the connection to the remote cli without attempting to shutthe remote down in an orderly way.",
	"Method": "void forceClose(){\r\n    closed = true;\r\n    IOUtils.close(out, in, cli);\r\n    try {\r\n        exec.join(TimeUnit.SECONDS.toMillis(10));\r\n    } catch (InterruptedException e) {\r\n        Thread.currentThread().interrupt();\r\n        throw new RuntimeException(e);\r\n    }\r\n    Exception e = failure.get();\r\n    if (e != null) {\r\n        throw new RuntimeException(\"CLI thread failed\", e);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleMetadataQueue.rewind",
	"Comment": "rewinds the read position to the first sample retained in the queue.",
	"Method": "void rewind(){\r\n    readPosition = 0;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ClientHelperTests.assertExecutionWithOrigin",
	"Comment": "this method executes a search and checks if the thread context wasenriched with the ml origin",
	"Method": "void assertExecutionWithOrigin(Map<String, String> storedHeaders,Client client){\r\n    String originName = randomFrom(ClientHelper.ML_ORIGIN, ClientHelper.WATCHER_ORIGIN, ClientHelper.ROLLUP_ORIGIN);\r\n    ClientHelper.executeWithHeaders(storedHeaders, originName, client, () -> {\r\n        Object origin = client.threadPool().getThreadContext().getTransient(ACTION_ORIGIN_TRANSIENT_NAME);\r\n        assertThat(origin, is(originName));\r\n        Map<String, String> headers = client.threadPool().getThreadContext().getHeaders();\r\n        assertThat(headers, not(hasEntry(AuthenticationField.AUTHENTICATION_KEY, \"anything\")));\r\n        assertThat(headers, not(hasEntry(AuthenticationServiceField.RUN_AS_USER_HEADER, \"anything\")));\r\n        return client.search(new SearchRequest()).actionGet();\r\n    });\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateGenerateTool.getCAInfo",
	"Comment": "returns the ca certificate and private key that will be used to sign certificates. these may be specified by the user orautomatically generated",
	"Method": "CAInfo getCAInfo(Terminal terminal,String dn,String caCertPath,String caKeyPath,char[] keyPass,boolean prompt,Environment env,int keysize,int days){\r\n    if (caCertPath != null) {\r\n        assert caKeyPath != null;\r\n        final String resolvedCaCertPath = resolvePath(caCertPath).toAbsolutePath().toString();\r\n        Certificate[] certificates = CertParsingUtils.readCertificates(Collections.singletonList(resolvedCaCertPath), env);\r\n        if (certificates.length != 1) {\r\n            throw new IllegalArgumentException(\"expected a single certificate in file [\" + caCertPath + \"] but found [\" + certificates.length + \"]\");\r\n        }\r\n        Certificate caCert = certificates[0];\r\n        PrivateKey privateKey = readPrivateKey(caKeyPath, keyPass, terminal, prompt);\r\n        return new CAInfo((X509Certificate) caCert, privateKey);\r\n    }\r\n    X500Principal x500Principal = new X500Principal(dn);\r\n    KeyPair keyPair = CertGenUtils.generateKeyPair(keysize);\r\n    Certificate caCert = CertGenUtils.generateCACertificate(x500Principal, keyPair, days);\r\n    final char[] password;\r\n    if (prompt) {\r\n        password = terminal.readSecret(\"Enter password for CA private key: \");\r\n    } else {\r\n        password = keyPass;\r\n    }\r\n    return new CAInfo((X509Certificate) caCert, keyPair.getPrivate(), true, password);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.EventLogger.getTrackStatusString",
	"Comment": "must point to the exact track group object to be considered part of it.",
	"Method": "String getTrackStatusString(TrackSelection selection,TrackGroup group,int trackIndex,String getTrackStatusString,boolean enabled){\r\n    return enabled ? \"[X]\" : \"[ ]\";\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.offline.DownloadManager.isInitialized",
	"Comment": "returns whether the manager has completed initialization.",
	"Method": "boolean isInitialized(){\r\n    Assertions.checkState(!released);\r\n    return initialized;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.Mp4Extractor.calculateAccumulatedSampleSizes",
	"Comment": "for each sample of each track, calculates accumulated size of all samples which need to be readbefore this sample can be used.",
	"Method": "long[][] calculateAccumulatedSampleSizes(Mp4Track[] tracks){\r\n    long[][] accumulatedSampleSizes = new long[tracks.length][];\r\n    int[] nextSampleIndex = new int[tracks.length];\r\n    long[] nextSampleTimesUs = new long[tracks.length];\r\n    boolean[] tracksFinished = new boolean[tracks.length];\r\n    for (int i = 0; i < tracks.length; i++) {\r\n        accumulatedSampleSizes[i] = new long[tracks[i].sampleTable.sampleCount];\r\n        nextSampleTimesUs[i] = tracks[i].sampleTable.timestampsUs[0];\r\n    }\r\n    long accumulatedSampleSize = 0;\r\n    int finishedTracks = 0;\r\n    while (finishedTracks < tracks.length) {\r\n        long minTimeUs = Long.MAX_VALUE;\r\n        int minTimeTrackIndex = -1;\r\n        for (int i = 0; i < tracks.length; i++) {\r\n            if (!tracksFinished[i] && nextSampleTimesUs[i] <= minTimeUs) {\r\n                minTimeTrackIndex = i;\r\n                minTimeUs = nextSampleTimesUs[i];\r\n            }\r\n        }\r\n        int trackSampleIndex = nextSampleIndex[minTimeTrackIndex];\r\n        accumulatedSampleSizes[minTimeTrackIndex][trackSampleIndex] = accumulatedSampleSize;\r\n        accumulatedSampleSize += tracks[minTimeTrackIndex].sampleTable.sizes[trackSampleIndex];\r\n        nextSampleIndex[minTimeTrackIndex] = ++trackSampleIndex;\r\n        if (trackSampleIndex < accumulatedSampleSizes[minTimeTrackIndex].length) {\r\n            nextSampleTimesUs[minTimeTrackIndex] = tracks[minTimeTrackIndex].sampleTable.timestampsUs[trackSampleIndex];\r\n        } else {\r\n            tracksFinished[minTimeTrackIndex] = true;\r\n            finishedTracks++;\r\n        }\r\n    }\r\n    return accumulatedSampleSizes;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.hls.playlist.HlsMediaPlaylist.getEndTimeUs",
	"Comment": "returns the result of adding the duration of the playlist to its start time.",
	"Method": "long getEndTimeUs(){\r\n    return startTimeUs + durationUs;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.LongArray.toArray",
	"Comment": "copies the current values into a newly allocated primitive array.",
	"Method": "long[] toArray(){\r\n    return Arrays.copyOf(values, size);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.indexlifecycle.PolicyStepsRegistry.stepExists",
	"Comment": "given a policy and stepkey, return true if a step exists, false otherwise",
	"Method": "boolean stepExists(String policy,Step.StepKey stepKey){\r\n    Map<Step.StepKey, Step> steps = stepMap.get(policy);\r\n    if (steps == null) {\r\n        return false;\r\n    } else {\r\n        return steps.containsKey(stepKey);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.MappingTrackSelector.selectTracks",
	"Comment": "given mapped track information, returns a track selection and configuration for each renderer.",
	"Method": "TrackSelectorResult selectTracks(RendererCapabilities[] rendererCapabilities,TrackGroupArray trackGroups,Pair<@NullableType RendererConfiguration[], @NullableType TrackSelection[]> selectTracks,MappedTrackInfo mappedTrackInfo,int[][][] rendererFormatSupports,int[] rendererMixedMimeTypeAdaptationSupport){\r\n    int[] rendererTrackGroupCounts = new int[rendererCapabilities.length + 1];\r\n    TrackGroup[][] rendererTrackGroups = new TrackGroup[rendererCapabilities.length + 1][];\r\n    int[][][] rendererFormatSupports = new int[rendererCapabilities.length + 1][][];\r\n    for (int i = 0; i < rendererTrackGroups.length; i++) {\r\n        rendererTrackGroups[i] = new TrackGroup[trackGroups.length];\r\n        rendererFormatSupports[i] = new int[trackGroups.length][];\r\n    }\r\n    int[] rendererMixedMimeTypeAdaptationSupports = getMixedMimeTypeAdaptationSupports(rendererCapabilities);\r\n    for (int groupIndex = 0; groupIndex < trackGroups.length; groupIndex++) {\r\n        TrackGroup group = trackGroups.get(groupIndex);\r\n        int rendererIndex = findRenderer(rendererCapabilities, group);\r\n        int[] rendererFormatSupport = rendererIndex == rendererCapabilities.length ? new int[group.length] : getFormatSupport(rendererCapabilities[rendererIndex], group);\r\n        int rendererTrackGroupCount = rendererTrackGroupCounts[rendererIndex];\r\n        rendererTrackGroups[rendererIndex][rendererTrackGroupCount] = group;\r\n        rendererFormatSupports[rendererIndex][rendererTrackGroupCount] = rendererFormatSupport;\r\n        rendererTrackGroupCounts[rendererIndex]++;\r\n    }\r\n    TrackGroupArray[] rendererTrackGroupArrays = new TrackGroupArray[rendererCapabilities.length];\r\n    int[] rendererTrackTypes = new int[rendererCapabilities.length];\r\n    for (int i = 0; i < rendererCapabilities.length; i++) {\r\n        int rendererTrackGroupCount = rendererTrackGroupCounts[i];\r\n        rendererTrackGroupArrays[i] = new TrackGroupArray(Util.nullSafeArrayCopy(rendererTrackGroups[i], rendererTrackGroupCount));\r\n        rendererFormatSupports[i] = Util.nullSafeArrayCopy(rendererFormatSupports[i], rendererTrackGroupCount);\r\n        rendererTrackTypes[i] = rendererCapabilities[i].getTrackType();\r\n    }\r\n    int unmappedTrackGroupCount = rendererTrackGroupCounts[rendererCapabilities.length];\r\n    TrackGroupArray unmappedTrackGroupArray = new TrackGroupArray(Util.nullSafeArrayCopy(rendererTrackGroups[rendererCapabilities.length], unmappedTrackGroupCount));\r\n    MappedTrackInfo mappedTrackInfo = new MappedTrackInfo(rendererTrackTypes, rendererTrackGroupArrays, rendererMixedMimeTypeAdaptationSupports, rendererFormatSupports, unmappedTrackGroupArray);\r\n    Pair<@NullableType RendererConfiguration[], @NullableType TrackSelection[]> result = selectTracks(mappedTrackInfo, rendererFormatSupports, rendererMixedMimeTypeAdaptationSupports);\r\n    return new TrackSelectorResult(result.first, result.second, mappedTrackInfo);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.dash.manifest.RangedUri.resolveUriString",
	"Comment": "returns the resolved uri represented by the instance as a string.",
	"Method": "String resolveUriString(String baseUri){\r\n    return UriUtil.resolve(baseUri, referenceUri);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.MediaCodecVideoRenderer.renderOutputBuffer",
	"Comment": "renders the output buffer with the specified index. this method is only called if the platformapi version of the device is less than 21.",
	"Method": "void renderOutputBuffer(MediaCodec codec,int index,long presentationTimeUs){\r\n    maybeNotifyVideoSizeChanged();\r\n    TraceUtil.beginSection(\"releaseOutputBuffer\");\r\n    codec.releaseOutputBuffer(index, true);\r\n    TraceUtil.endSection();\r\n    lastRenderTimeUs = SystemClock.elapsedRealtime() * 1000;\r\n    decoderCounters.renderedOutputBufferCount++;\r\n    consecutiveDroppedFrameCount = 0;\r\n    maybeNotifyRenderedFirstFrame();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.ActiveDirectoryRealmTests.setupRealm",
	"Comment": "creates a realm with the provided settings, rebuilds the ssl service to be aware of the new realm, and then returnsthe realmconfig",
	"Method": "RealmConfig setupRealm(RealmConfig.RealmIdentifier realmIdentifier,Settings localSettings){\r\n    final Settings mergedSettings = Settings.builder().put(globalSettings).put(localSettings).build();\r\n    final Environment env = TestEnvironment.newEnvironment(mergedSettings);\r\n    this.sslService = new SSLService(mergedSettings, env);\r\n    return new RealmConfig(realmIdentifier, mergedSettings, env, new ThreadContext(mergedSettings));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleQueue.discardToEnd",
	"Comment": "discards to the end of the queue. the read position is also advanced.",
	"Method": "void discardToEnd(){\r\n    discardDownstreamTo(metadataQueue.discardToEnd());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.ads.AdPlaybackState.withAdDurationsUs",
	"Comment": "returns an instance with the specified ad durations, in microseconds.",
	"Method": "AdGroup withAdDurationsUs(long[] durationsUs,AdPlaybackState withAdDurationsUs,long[][] adDurationUs){\r\n    AdGroup[] adGroups = Arrays.copyOf(this.adGroups, this.adGroups.length);\r\n    for (int adGroupIndex = 0; adGroupIndex < adGroupCount; adGroupIndex++) {\r\n        adGroups[adGroupIndex] = adGroups[adGroupIndex].withAdDurationsUs(adDurationUs[adGroupIndex]);\r\n    }\r\n    return new AdPlaybackState(adGroupTimesUs, adGroups, adResumePositionUs, contentDurationUs);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.rest.RemoteHostHeader.process",
	"Comment": "extracts the remote address from the given rest request and puts in the request context. this willthen be copied to the subsequent action requests.",
	"Method": "void process(RestRequest request,ThreadContext threadContext){\r\n    threadContext.putTransient(KEY, request.getHttpChannel().getRemoteAddress());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.chunk.BaseMediaChunk.getFirstSampleIndex",
	"Comment": "returns the index of the first sample in the specified track of the output that will originatefrom this chunk.",
	"Method": "int getFirstSampleIndex(int trackIndex){\r\n    return firstSampleIndices[trackIndex];\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateGenerateTool.getOutputFile",
	"Comment": "checks for output file in the user specified options or prompts the user for the output file",
	"Method": "Path getOutputFile(Terminal terminal,String outputPath,String defaultFilename){\r\n    Path file;\r\n    if (outputPath != null) {\r\n        file = resolvePath(outputPath);\r\n    } else {\r\n        file = resolvePath(defaultFilename);\r\n        String input = terminal.readText(\"Please enter the desired output file [\" + file + \"]: \");\r\n        if (input.isEmpty() == false) {\r\n            file = resolvePath(input);\r\n        }\r\n    }\r\n    return file.toAbsolutePath();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.user.PutUserRequestBuilder.source",
	"Comment": "populate the put user request using the given source and username",
	"Method": "PutUserRequestBuilder source(String username,BytesReference source,XContentType xContentType,Hasher hasher){\r\n    Objects.requireNonNull(xContentType);\r\n    username(username);\r\n    try (InputStream stream = source.streamInput();\r\n        XContentParser parser = xContentType.xContent().createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, stream)) {\r\n        XContentUtils.verifyObject(parser);\r\n        XContentParser.Token token;\r\n        String currentFieldName = null;\r\n        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\r\n            if (token == XContentParser.Token.FIELD_NAME) {\r\n                currentFieldName = parser.currentName();\r\n            } else if (User.Fields.PASSWORD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                if (token == XContentParser.Token.VALUE_STRING) {\r\n                    String password = parser.text();\r\n                    char[] passwordChars = password.toCharArray();\r\n                    password(passwordChars, hasher);\r\n                    Arrays.fill(passwordChars, (char) 0);\r\n                } else {\r\n                    throw new ElasticsearchParseException(\"expected field [{}] to be of type string, but found [{}] instead\", currentFieldName, token);\r\n                }\r\n            } else if (User.Fields.PASSWORD_HASH.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                if (token == XContentParser.Token.VALUE_STRING) {\r\n                    char[] passwordChars = parser.text().toCharArray();\r\n                    passwordHash(passwordChars, hasher);\r\n                } else {\r\n                    throw new ElasticsearchParseException(\"expected field [{}] to be of type string, but found [{}] instead\", currentFieldName, token);\r\n                }\r\n            } else if (User.Fields.ROLES.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                if (token == XContentParser.Token.VALUE_STRING) {\r\n                    roles(Strings.commaDelimitedListToStringArray(parser.text()));\r\n                } else {\r\n                    roles(XContentUtils.readStringArray(parser, false));\r\n                }\r\n            } else if (User.Fields.FULL_NAME.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                if (token == XContentParser.Token.VALUE_STRING) {\r\n                    fullName(parser.text());\r\n                } else if (token != XContentParser.Token.VALUE_NULL) {\r\n                    throw new ElasticsearchParseException(\"expected field [{}] to be of type string, but found [{}] instead\", currentFieldName, token);\r\n                }\r\n            } else if (User.Fields.EMAIL.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                if (token == XContentParser.Token.VALUE_STRING) {\r\n                    email(parser.text());\r\n                } else if (token != XContentParser.Token.VALUE_NULL) {\r\n                    throw new ElasticsearchParseException(\"expected field [{}] to be of type string, but found [{}] instead\", currentFieldName, token);\r\n                }\r\n            } else if (User.Fields.METADATA.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                if (token == XContentParser.Token.START_OBJECT) {\r\n                    metadata(parser.map());\r\n                } else {\r\n                    throw new ElasticsearchParseException(\"expected field [{}] to be of type object, but found [{}] instead\", currentFieldName, token);\r\n                }\r\n            } else if (User.Fields.ENABLED.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                if (token == XContentParser.Token.VALUE_BOOLEAN) {\r\n                    enabled(parser.booleanValue());\r\n                } else {\r\n                    throw new ElasticsearchParseException(\"expected field [{}] to be of type boolean, but found [{}] instead\", currentFieldName, token);\r\n                }\r\n            } else if (User.Fields.USERNAME.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                if (token == Token.VALUE_STRING) {\r\n                    if (username.equals(parser.text()) == false) {\r\n                        throw new IllegalArgumentException(\"[username] in source does not match the username provided [\" + username + \"]\");\r\n                    }\r\n                } else {\r\n                    throw new ElasticsearchParseException(\"expected field [{}] to be of type string, but found [{}] instead\", currentFieldName, token);\r\n                }\r\n            } else {\r\n                throw new ElasticsearchParseException(\"failed to parse add user request. unexpected field [{}]\", currentFieldName);\r\n            }\r\n        }\r\n        return this;\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.readSynchSafeInt",
	"Comment": "reads a synchsafe integer.synchsafe integers keep the highest bit of every byte zeroed. a 32 bit synchsafe integer canstore 28 bits of information.",
	"Method": "int readSynchSafeInt(){\r\n    int b1 = readUnsignedByte();\r\n    int b2 = readUnsignedByte();\r\n    int b3 = readUnsignedByte();\r\n    int b4 = readUnsignedByte();\r\n    return (b1 << 21) | (b2 << 14) | (b3 << 7) | b4;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.SimpleExoPlayer.setMetadataOutput",
	"Comment": "sets an output to receive metadata events, removing all existing outputs.",
	"Method": "void setMetadataOutput(MetadataOutput output){\r\n    metadataOutputs.retainAll(Collections.singleton(analyticsCollector));\r\n    if (output != null) {\r\n        addMetadataOutput(output);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectCommunicator.destroyCategorizationAnalyzer",
	"Comment": "care must be taken to ensure this method is not called while data is being posted.the methods in this class that call it wait for all processing to complete first.the expectation is that external calls are only made when cleaning up after a fatalerror.",
	"Method": "void destroyCategorizationAnalyzer(){\r\n    if (categorizationAnalyzer != null) {\r\n        categorizationAnalyzer.close();\r\n        categorizationAnalyzer = null;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.parser.SqlParserTests.stringForDirection",
	"Comment": "convert a direction into a string that represents that parses tothat direction.",
	"Method": "String stringForDirection(Order.OrderDirection dir){\r\n    String dirStr = dir.toString();\r\n    return randomBoolean() && dirStr.equals(\"ASC\") ? \"\" : \" \" + dirStr;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.crypto.AesFlushingCipherTest.testUnAligned",
	"Comment": "test several encrypt and decrypt calls, not aligned on block boundary.",
	"Method": "void testUnAligned(){\r\n    byte[] reference = TestUtil.buildTestData(DATA_LENGTH);\r\n    byte[] data = reference.clone();\r\n    Random random = new Random(RANDOM_SEED);\r\n    int offset = 0;\r\n    while (offset < data.length) {\r\n        int bytes = 1 + random.nextInt(4095);\r\n        bytes = Math.min(bytes, data.length - offset);\r\n        encryptCipher.updateInPlace(data, offset, bytes);\r\n        offset += bytes;\r\n    }\r\n    int unchangedByteCount = data.length - getDifferingByteCount(reference, data);\r\n    assertThat(unchangedByteCount <= getMaxUnchangedBytesAllowedPostEncryption(data.length)).isTrue();\r\n    offset = 0;\r\n    while (offset < data.length) {\r\n        int bytes = 1 + random.nextInt(4095);\r\n        bytes = Math.min(bytes, data.length - offset);\r\n        decryptCipher.updateInPlace(data, offset, bytes);\r\n        offset += bytes;\r\n    }\r\n    int differingByteCount = getDifferingByteCount(reference, data);\r\n    assertThat(differingByteCount).isEqualTo(0);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.MediaSourceTestRunner.assertTimelineChange",
	"Comment": "asserts that the source has notified its listener of a single timeline change.",
	"Method": "Timeline assertTimelineChange(){\r\n    timeline = timelines.removeFirst();\r\n    assertNoTimelineChange();\r\n    return timeline;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.Atom.getAtomTypeString",
	"Comment": "converts a numeric atom type to the corresponding four character string.",
	"Method": "String getAtomTypeString(int type){\r\n    return \"\" + (char) ((type >> 24) & 0xFF) + (char) ((type >> 16) & 0xFF) + (char) ((type >> 8) & 0xFF) + (char) (type & 0xFF);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.role.ClearRolesCacheRequest.names",
	"Comment": "sets the roles for which caches will be evicted. when not set all the roles will be evicted from the cache.",
	"Method": "ClearRolesCacheRequest names(String names,String[] names){\r\n    return names;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testPEMKeyConfigReloading",
	"Comment": "tests the reloading of sslcontext when a pem key and certificate are used.",
	"Method": "void testPEMKeyConfigReloading(){\r\n    Path tempDir = createTempDir();\r\n    Path keyPath = tempDir.resolve(\"testnode.pem\");\r\n    Path updatedKeyPath = tempDir.resolve(\"testnode_updated.pem\");\r\n    Path certPath = tempDir.resolve(\"testnode.crt\");\r\n    Path updatedCertPath = tempDir.resolve(\"testnode_updated.crt\");\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.pem\"), keyPath);\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode_updated.pem\"), updatedKeyPath);\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode_updated.crt\"), updatedCertPath);\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.crt\"), certPath);\r\n    MockSecureSettings secureSettings = new MockSecureSettings();\r\n    secureSettings.setString(\"xpack.ssl.secure_key_passphrase\", \"testnode\");\r\n    final Settings settings = Settings.builder().put(\"path.home\", createTempDir()).put(\"xpack.ssl.key\", keyPath).put(\"xpack.ssl.certificate\", certPath).setSecureSettings(secureSettings).build();\r\n    final Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(Settings.builder().put(\"path.home\", createTempDir()).build());\r\n    try (CloseableHttpClient client = getSSLClient(Collections.singletonList(certPath))) {\r\n        final Consumer<SSLContext> keyMaterialPreChecks = (context) -> {\r\n            try (MockWebServer server = new MockWebServer(context, false)) {\r\n                server.enqueue(new MockResponse().setResponseCode(200).setBody(\"body\"));\r\n                server.start();\r\n                privilegedConnect(() -> client.execute(new HttpGet(\"https://localhost:\" + server.getPort())).close());\r\n            } catch (Exception e) {\r\n                throw new RuntimeException(\"Exception starting or connecting to the mock server\", e);\r\n            }\r\n        };\r\n        final Runnable modifier = () -> {\r\n            try {\r\n                atomicMoveIfPossible(updatedKeyPath, keyPath);\r\n                atomicMoveIfPossible(updatedCertPath, certPath);\r\n            } catch (Exception e) {\r\n                throw new RuntimeException(\"failed to modify file\", e);\r\n            }\r\n        };\r\n        final Consumer<SSLContext> keyMaterialPostChecks = (updatedContext) -> {\r\n            try (MockWebServer server = new MockWebServer(updatedContext, false)) {\r\n                server.enqueue(new MockResponse().setResponseCode(200).setBody(\"body\"));\r\n                server.start();\r\n                SSLHandshakeException sslException = expectThrows(SSLHandshakeException.class, () -> privilegedConnect(() -> client.execute(new HttpGet(\"https://localhost:\" + server.getPort())).close()));\r\n                assertThat(sslException.getCause().getMessage(), containsString(\"PKIX path validation failed\"));\r\n            } catch (Exception e) {\r\n                throw new RuntimeException(\"Exception starting or connecting to the mock server\", e);\r\n            }\r\n        };\r\n        validateSSLConfigurationIsReloaded(settings, env, keyMaterialPreChecks, modifier, keyMaterialPostChecks);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authz.IndicesAndAliasesResolver.replaceWildcardsWithAuthorizedIndices",
	"Comment": "todo investigate reusing code from vanilla es to resolve index names and wildcards",
	"Method": "List<String> replaceWildcardsWithAuthorizedIndices(Iterable<String> indices,IndicesOptions indicesOptions,MetaData metaData,List<String> authorizedIndices,boolean replaceWildcards){\r\n    List<String> finalIndices = new ArrayList();\r\n    boolean wildcardSeen = false;\r\n    for (String index : indices) {\r\n        String aliasOrIndex;\r\n        boolean minus = false;\r\n        if (index.charAt(0) == '-' && wildcardSeen) {\r\n            aliasOrIndex = index.substring(1);\r\n            minus = true;\r\n        } else {\r\n            aliasOrIndex = index;\r\n        }\r\n        final String dateMathName = nameExpressionResolver.resolveDateMathExpression(aliasOrIndex);\r\n        if (dateMathName != aliasOrIndex) {\r\n            assert dateMathName.equals(aliasOrIndex) == false;\r\n            if (replaceWildcards && Regex.isSimpleMatchPattern(dateMathName)) {\r\n                aliasOrIndex = dateMathName;\r\n            } else if (authorizedIndices.contains(dateMathName) && isIndexVisible(dateMathName, indicesOptions, metaData, true)) {\r\n                if (minus) {\r\n                    finalIndices.remove(dateMathName);\r\n                } else {\r\n                    finalIndices.add(dateMathName);\r\n                }\r\n            } else {\r\n                if (indicesOptions.ignoreUnavailable() == false) {\r\n                    throw new IndexNotFoundException(dateMathName);\r\n                }\r\n            }\r\n        }\r\n        if (replaceWildcards && Regex.isSimpleMatchPattern(aliasOrIndex)) {\r\n            wildcardSeen = true;\r\n            Set<String> resolvedIndices = new HashSet();\r\n            for (String authorizedIndex : authorizedIndices) {\r\n                if (Regex.simpleMatch(aliasOrIndex, authorizedIndex) && isIndexVisible(authorizedIndex, indicesOptions, metaData)) {\r\n                    resolvedIndices.add(authorizedIndex);\r\n                }\r\n            }\r\n            if (resolvedIndices.isEmpty()) {\r\n                if (indicesOptions.allowNoIndices() == false) {\r\n                    throw new IndexNotFoundException(aliasOrIndex);\r\n                }\r\n            } else {\r\n                if (minus) {\r\n                    finalIndices.removeAll(resolvedIndices);\r\n                } else {\r\n                    finalIndices.addAll(resolvedIndices);\r\n                }\r\n            }\r\n        } else if (dateMathName == aliasOrIndex) {\r\n            assert dateMathName.equals(aliasOrIndex);\r\n            if (minus) {\r\n                finalIndices.remove(aliasOrIndex);\r\n            } else {\r\n                finalIndices.add(aliasOrIndex);\r\n            }\r\n        }\r\n    }\r\n    return finalIndices;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlRequestHandler.samlSignatureException",
	"Comment": "constructs a saml specific exception with a consistent message regarding saml signature validation failures",
	"Method": "ElasticsearchSecurityException samlSignatureException(List<Credential> credentials,String signature,Exception cause,ElasticsearchSecurityException samlSignatureException,List<Credential> credentials,String signature){\r\n    logger.warn(\"The XML Signature of this SAML message cannot be validated. Please verify that the saml realm uses the correct SAML\" + \"metadata file/URL for this Identity Provider\");\r\n    final String msg = \"SAML Signature [{}] could not be validated against [{}]\";\r\n    return samlException(msg, signature, describeCredentials(credentials));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.realm.ClearRealmCacheRequestBuilder.realms",
	"Comment": "sets the realms for which caches will be evicted. when not set all the caches of all realms will beevicted.",
	"Method": "ClearRealmCacheRequestBuilder realms(String realms){\r\n    request.realms(realms);\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.SecurityContext.getUser",
	"Comment": "returns the current user information, or null if the current request has no authentication info.",
	"Method": "User getUser(){\r\n    Authentication authentication = getAuthentication();\r\n    return authentication == null ? null : authentication.getUser();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.process.logging.CppLogMessageHandler.getNativeCodeInfo",
	"Comment": "extracts version information from the copyright string which assumes a certain format.",
	"Method": "Map<String, Object> getNativeCodeInfo(Duration timeout){\r\n    String copyrightMessage = getCppCopyright(timeout);\r\n    Matcher matcher = Pattern.compile(\"Version (.+) \\\\(Build ([^)]+)\\\\) Copyright \").matcher(copyrightMessage);\r\n    if (matcher.find()) {\r\n        Map<String, Object> info = new HashMap(2);\r\n        info.put(\"version\", matcher.group(1));\r\n        info.put(\"build_hash\", matcher.group(2));\r\n        return info;\r\n    } else {\r\n        String msg = \"Unexpected native process copyright format: \" + copyrightMessage;\r\n        LOGGER.error(msg);\r\n        throw new ElasticsearchException(msg);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleMetadataQueue.discardTo",
	"Comment": "discards up to but not including the sample immediately before or at the specified time.",
	"Method": "long discardTo(long timeUs,boolean toKeyframe,boolean stopAtReadPosition){\r\n    if (length == 0 || timeUs < timesUs[relativeFirstIndex]) {\r\n        return C.POSITION_UNSET;\r\n    }\r\n    int searchLength = stopAtReadPosition && readPosition != length ? readPosition + 1 : length;\r\n    int discardCount = findSampleBefore(relativeFirstIndex, searchLength, timeUs, toKeyframe);\r\n    if (discardCount == -1) {\r\n        return C.POSITION_UNSET;\r\n    }\r\n    return discardSamples(discardCount);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.template.TemplateUtils.checkTemplateExistsAndVersionMatches",
	"Comment": "checks if template with given name exists and if it matches the version predicate given",
	"Method": "boolean checkTemplateExistsAndVersionMatches(String templateName,String versionKey,ClusterState state,Logger logger,Predicate<Version> predicate){\r\n    IndexTemplateMetaData templateMeta = state.metaData().templates().get(templateName);\r\n    if (templateMeta == null) {\r\n        return false;\r\n    }\r\n    ImmutableOpenMap<String, CompressedXContent> mappings = templateMeta.getMappings();\r\n    for (Object typeMapping : mappings.values().toArray()) {\r\n        CompressedXContent typeMappingXContent = (CompressedXContent) typeMapping;\r\n        try {\r\n            Map<String, Object> typeMappingMap = convertToMap(new BytesArray(typeMappingXContent.uncompressed()), false, XContentType.JSON).v2();\r\n            assert (typeMappingMap.size() == 1);\r\n            String key = typeMappingMap.keySet().iterator().next();\r\n            @SuppressWarnings(\"unchecked\")\r\n            Map<String, Object> mappingMap = (Map<String, Object>) typeMappingMap.get(key);\r\n            if (containsCorrectVersion(versionKey, mappingMap, predicate) == false) {\r\n                return false;\r\n            }\r\n        } catch (ElasticsearchParseException e) {\r\n            logger.error(new ParameterizedMessage(\"Cannot parse the template [{}]\", templateName), e);\r\n            throw new IllegalStateException(\"Cannot parse the template \" + templateName, e);\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.PlayerMessage.getDeleteAfterDelivery",
	"Comment": "returns whether the message will be deleted after delivery.",
	"Method": "boolean getDeleteAfterDelivery(){\r\n    return deleteAfterDelivery;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.setEnabled",
	"Comment": "asynchronous method that will update the enabled flag of a user. if the user is reserved and the document does not exist, a documentwill be created. if the user is not reserved, the user must exist otherwise the operation will fail.",
	"Method": "void setEnabled(String username,boolean enabled,RefreshPolicy refreshPolicy,ActionListener<Void> listener){\r\n    if (ClientReservedRealm.isReserved(username, settings)) {\r\n        setReservedUserEnabled(username, enabled, refreshPolicy, true, listener);\r\n    } else {\r\n        setRegularUserEnabled(username, enabled, refreshPolicy, listener);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.BaseRenderer.getConfiguration",
	"Comment": "returns the configuration set when the renderer was most recently enabled.",
	"Method": "RendererConfiguration getConfiguration(){\r\n    return configuration;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecInfo.isAudioChannelCountSupportedV21",
	"Comment": "whether the decoder supports audio with a given channel count.must not be called if the device sdk version is less than 21.",
	"Method": "boolean isAudioChannelCountSupportedV21(int channelCount){\r\n    if (capabilities == null) {\r\n        logNoSupport(\"channelCount.caps\");\r\n        return false;\r\n    }\r\n    AudioCapabilities audioCapabilities = capabilities.getAudioCapabilities();\r\n    if (audioCapabilities == null) {\r\n        logNoSupport(\"channelCount.aCaps\");\r\n        return false;\r\n    }\r\n    int maxInputChannelCount = adjustMaxInputChannelCount(name, mimeType, audioCapabilities.getMaxInputChannelCount());\r\n    if (maxInputChannelCount < channelCount) {\r\n        logNoSupport(\"channelCount.support, \" + channelCount);\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlSpMetadataBuilder.signingCredential",
	"Comment": "the certificate credential that should be used to send encrypted data to the service provider.",
	"Method": "SamlSpMetadataBuilder signingCredential(X509Credential credential){\r\n    return signingCertificate(credential == null ? null : credential.getEntityCertificate());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherService.validate",
	"Comment": "ensure that watcher can be reloaded, by checking if all indices are marked as up and ready in the cluster state",
	"Method": "boolean validate(ClusterState state){\r\n    boolean hasValidWatcherTemplates = WatcherIndexTemplateRegistry.validate(state);\r\n    if (hasValidWatcherTemplates == false) {\r\n        logger.debug(\"missing watcher index templates, not starting watcher service\");\r\n        return false;\r\n    }\r\n    IndexMetaData watcherIndexMetaData = WatchStoreUtils.getConcreteIndex(Watch.INDEX, state.metaData());\r\n    IndexMetaData triggeredWatchesIndexMetaData = WatchStoreUtils.getConcreteIndex(TriggeredWatchStoreField.INDEX_NAME, state.metaData());\r\n    boolean isIndexInternalFormatWatchIndex = watcherIndexMetaData == null || UpgradeField.checkInternalIndexFormat(watcherIndexMetaData);\r\n    boolean isIndexInternalFormatTriggeredWatchIndex = triggeredWatchesIndexMetaData == null || UpgradeField.checkInternalIndexFormat(triggeredWatchesIndexMetaData);\r\n    if (isIndexInternalFormatTriggeredWatchIndex == false || isIndexInternalFormatWatchIndex == false) {\r\n        logger.warn(\"not starting watcher, upgrade API run required: .watches[{}], .triggered_watches[{}]\", isIndexInternalFormatWatchIndex, isIndexInternalFormatTriggeredWatchIndex);\r\n        return false;\r\n    }\r\n    try {\r\n        boolean storesValid = TriggeredWatchStore.validate(state) && HistoryStore.validate(state);\r\n        if (storesValid == false) {\r\n            return false;\r\n        }\r\n        return watcherIndexMetaData == null || (watcherIndexMetaData.getState() == IndexMetaData.State.OPEN && state.routingTable().index(watcherIndexMetaData.getIndex()).allPrimaryShardsActive());\r\n    } catch (IllegalStateException e) {\r\n        logger.debug(\"error validating to start watcher\", e);\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.VideoFrameReleaseTimeHelper.adjustReleaseTime",
	"Comment": "adjusts a frame release timestamp. must be called from the playback thread.",
	"Method": "long adjustReleaseTime(long framePresentationTimeUs,long unadjustedReleaseTimeNs){\r\n    long framePresentationTimeNs = framePresentationTimeUs * 1000;\r\n    long adjustedFrameTimeNs = framePresentationTimeNs;\r\n    long adjustedReleaseTimeNs = unadjustedReleaseTimeNs;\r\n    if (haveSync) {\r\n        if (framePresentationTimeUs != lastFramePresentationTimeUs) {\r\n            frameCount++;\r\n            adjustedLastFrameTimeNs = pendingAdjustedFrameTimeNs;\r\n        }\r\n        if (frameCount >= MIN_FRAMES_FOR_ADJUSTMENT) {\r\n            long averageFrameDurationNs = (framePresentationTimeNs - syncFramePresentationTimeNs) / frameCount;\r\n            long candidateAdjustedFrameTimeNs = adjustedLastFrameTimeNs + averageFrameDurationNs;\r\n            if (isDriftTooLarge(candidateAdjustedFrameTimeNs, unadjustedReleaseTimeNs)) {\r\n                haveSync = false;\r\n            } else {\r\n                adjustedFrameTimeNs = candidateAdjustedFrameTimeNs;\r\n                adjustedReleaseTimeNs = syncUnadjustedReleaseTimeNs + adjustedFrameTimeNs - syncFramePresentationTimeNs;\r\n            }\r\n        } else {\r\n            if (isDriftTooLarge(framePresentationTimeNs, unadjustedReleaseTimeNs)) {\r\n                haveSync = false;\r\n            }\r\n        }\r\n    }\r\n    if (!haveSync) {\r\n        syncFramePresentationTimeNs = framePresentationTimeNs;\r\n        syncUnadjustedReleaseTimeNs = unadjustedReleaseTimeNs;\r\n        frameCount = 0;\r\n        haveSync = true;\r\n    }\r\n    lastFramePresentationTimeUs = framePresentationTimeUs;\r\n    pendingAdjustedFrameTimeNs = adjustedFrameTimeNs;\r\n    if (vsyncSampler == null || vsyncDurationNs == C.TIME_UNSET) {\r\n        return adjustedReleaseTimeNs;\r\n    }\r\n    long sampledVsyncTimeNs = vsyncSampler.sampledVsyncTimeNs;\r\n    if (sampledVsyncTimeNs == C.TIME_UNSET) {\r\n        return adjustedReleaseTimeNs;\r\n    }\r\n    long snappedTimeNs = closestVsync(adjustedReleaseTimeNs, sampledVsyncTimeNs, vsyncDurationNs);\r\n    return snappedTimeNs - vsyncOffsetNs;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.cleaner.CleanerService.getRetention",
	"Comment": "get the retention that can be used.this will ignore the global retention if the license does not allow retention updates.",
	"Method": "TimeValue getRetention(){\r\n    if (licenseState.isUpdateRetentionAllowed() && globalRetention != null) {\r\n        return globalRetention;\r\n    } else {\r\n        return MonitoringField.HISTORY_DURATION.getDefault(Settings.EMPTY);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.client.SecurityClient.clearRolesCache",
	"Comment": "clears the roles cache. this api only works for the naitve roles that are stored in an elasticsearch index. it ispossible to clear the cache of all roles or to specify the names of individual roles that should have their cachecleared.",
	"Method": "void clearRolesCache(ClearRolesCacheRequest request,ActionListener<ClearRolesCacheResponse> listener,ActionFuture<ClearRolesCacheResponse> clearRolesCache,ClearRolesCacheRequest request){\r\n    return client.execute(ClearRolesCacheAction.INSTANCE, request);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.client.WatcherClient.prepareWatcherStats",
	"Comment": "creates a request builder to build a request to get the watcher stats",
	"Method": "WatcherStatsRequestBuilder prepareWatcherStats(){\r\n    return new WatcherStatsRequestBuilder(client);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.exporter.local.LocalExporterResourceIntegTests.generateTemplateSource",
	"Comment": "generates a basic template that loosely represents a monitoring template.",
	"Method": "BytesReference generateTemplateSource(String name,Integer version){\r\n    final XContentBuilder builder = jsonBuilder().startObject();\r\n    builder.field(\"index_patterns\", name).startObject(\"settings\").field(\"index.number_of_shards\", 1).field(\"index.number_of_replicas\", 0).endObject().startObject(\"mappings\").startObject(\"doc\").startObject(\"_meta\").field(\"test\", true).endObject().field(\"enabled\", false).endObject().endObject();\r\n    if (version != null) {\r\n        builder.field(\"version\", version);\r\n    }\r\n    return BytesReference.bytes(builder.endObject());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.ts.DtsReader.skipToNextSync",
	"Comment": "locates the next sync value in the buffer, advancing the position to the byte that immediatelyfollows it. if sync was not located, the position is advanced to the limit.",
	"Method": "boolean skipToNextSync(ParsableByteArray pesBuffer){\r\n    while (pesBuffer.bytesLeft() > 0) {\r\n        syncBytes <<= 8;\r\n        syncBytes |= pesBuffer.readUnsignedByte();\r\n        if (DtsUtil.isSyncWord(syncBytes)) {\r\n            headerScratchBytes.data[0] = (byte) ((syncBytes >> 24) & 0xFF);\r\n            headerScratchBytes.data[1] = (byte) ((syncBytes >> 16) & 0xFF);\r\n            headerScratchBytes.data[2] = (byte) ((syncBytes >> 8) & 0xFF);\r\n            headerScratchBytes.data[3] = (byte) (syncBytes & 0xFF);\r\n            bytesRead = 4;\r\n            syncBytes = 0;\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.TimedValueQueue.poll",
	"Comment": "returns the value with the closest timestamp to the given timestamp. removes all older valuesincluding the returned one from the buffer.",
	"Method": "V poll(long timestamp,V poll,long timestamp,boolean onlyOlder){\r\n    V value = null;\r\n    long previousTimeDiff = Long.MAX_VALUE;\r\n    while (size > 0) {\r\n        long timeDiff = timestamp - timestamps[first];\r\n        if (timeDiff < 0 && (onlyOlder || -timeDiff >= previousTimeDiff)) {\r\n            break;\r\n        }\r\n        previousTimeDiff = timeDiff;\r\n        value = values[first];\r\n        values[first] = null;\r\n        first = (first + 1) % values.length;\r\n        size--;\r\n    }\r\n    return value;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mp4.Atom.parseFullAtomVersion",
	"Comment": "parses the version number out of the additional integer component of a full atom.",
	"Method": "int parseFullAtomVersion(int fullAtomInt){\r\n    return 0x000000FF & (fullAtomInt >> 24);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.reinitializeCodec",
	"Comment": "starts the process of releasing the existing codec and initializing a new one. this may occurimmediately, or be deferred until any final output buffers have been dequeued.",
	"Method": "void reinitializeCodec(){\r\n    availableCodecInfos = null;\r\n    if (codecReceivedBuffers) {\r\n        codecReinitializationState = REINITIALIZATION_STATE_SIGNAL_END_OF_STREAM;\r\n    } else {\r\n        releaseCodec();\r\n        maybeInitCodec();\r\n    }\r\n}"
}, {
	"Path": "com.alibaba.fastjson.util.AntiCollisionHashMap.putAll",
	"Comment": "copies all of the mappings from the specified map to this map. thesemappings will replace any mappings that this map had for any of the keyscurrently in the specified map.",
	"Method": "void putAll(Map<? extends K, ? extends V> m){\r\n    int numKeysToBeAdded = m.size();\r\n    if (numKeysToBeAdded == 0)\r\n        return;\r\n    if (numKeysToBeAdded > threshold) {\r\n        int targetCapacity = (int) (numKeysToBeAdded / loadFactor + 1);\r\n        if (targetCapacity > MAXIMUM_CAPACITY)\r\n            targetCapacity = MAXIMUM_CAPACITY;\r\n        int newCapacity = table.length;\r\n        while (newCapacity < targetCapacity) newCapacity <<= 1;\r\n        if (newCapacity > table.length)\r\n            resize(newCapacity);\r\n    }\r\n    for (Iterator<? extends Map.Entry<? extends K, ? extends V>> i = m.entrySet().iterator(); i.hasNext(); ) {\r\n        Map.Entry<? extends K, ? extends V> e = i.next();\r\n        put(e.getKey(), e.getValue());\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authc.support.BCrypt.hashpw",
	"Comment": "hash a password using the openbsd bcrypt scheme.modified from the original to take a securestring instead of the original",
	"Method": "String hashpw(SecureString password,String salt){\r\n    BCrypt B;\r\n    String real_salt;\r\n    byte[] passwordb, saltb, hashed;\r\n    char minor = (char) 0;\r\n    int rounds, off = 0;\r\n    StringBuffer rs = new StringBuffer();\r\n    if (salt.charAt(0) != '$' || salt.charAt(1) != '2')\r\n        throw new IllegalArgumentException(\"Invalid salt version\");\r\n    if (salt.charAt(2) == '$')\r\n        off = 3;\r\n    else {\r\n        minor = salt.charAt(2);\r\n        if (minor != 'a' || salt.charAt(3) != '$')\r\n            throw new IllegalArgumentException(\"Invalid salt revision\");\r\n        off = 4;\r\n    }\r\n    if (salt.charAt(off + 2) > '$')\r\n        throw new IllegalArgumentException(\"Missing salt rounds\");\r\n    rounds = Integer.parseInt(salt.substring(off, off + 2));\r\n    real_salt = salt.substring(off + 3, off + 25);\r\n    if (minor >= 'a') {\r\n        final char[] suffix = \"\\000\".toCharArray();\r\n        final char[] result = new char[password.length() + suffix.length];\r\n        System.arraycopy(password.getChars(), 0, result, 0, password.length());\r\n        System.arraycopy(suffix, 0, result, password.length(), suffix.length);\r\n        try (SecureString secureString = new SecureString(result)) {\r\n            passwordb = CharArrays.toUtf8Bytes(secureString.getChars());\r\n        }\r\n    } else {\r\n        passwordb = CharArrays.toUtf8Bytes(password.getChars());\r\n    }\r\n    saltb = decode_base64(real_salt, BCRYPT_SALT_LEN);\r\n    B = new BCrypt();\r\n    hashed = B.crypt_raw(passwordb, saltb, rounds, bf_crypt_ciphertext.clone());\r\n    rs.append(\"$2\");\r\n    if (minor >= 'a')\r\n        rs.append(minor);\r\n    rs.append(\"$\");\r\n    if (rounds < 10)\r\n        rs.append(\"0\");\r\n    if (rounds > 30) {\r\n        throw new IllegalArgumentException(\"rounds exceeds maximum (30)\");\r\n    }\r\n    rs.append(Integer.toString(rounds));\r\n    rs.append(\"$\");\r\n    rs.append(encode_base64(saltb, saltb.length));\r\n    rs.append(encode_base64(hashed, bf_crypt_ciphertext.length * 4 - 1));\r\n    return rs.toString();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.upgrade.IndexUpgradeCheck.actionRequired",
	"Comment": "this method is called by upgrade api to verify if upgrade or reindex for this index is required",
	"Method": "UpgradeActionRequired actionRequired(IndexMetaData indexMetaData){\r\n    return actionRequired.apply(indexMetaData);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.PkiRealmBootstrapCheck.check",
	"Comment": "if a pki realm is enabled, checks to see if ssl and client authentication are enabled on atleast one network communication layer.",
	"Method": "BootstrapCheckResult check(BootstrapContext context){\r\n    final Settings settings = context.settings;\r\n    final Map<RealmConfig.RealmIdentifier, Settings> realms = RealmSettings.getRealmSettings(settings);\r\n    final boolean pkiRealmEnabled = realms.entrySet().stream().filter(e -> PkiRealmSettings.TYPE.equals(e.getKey().getType())).map(Map.Entry::getValue).anyMatch(s -> s.getAsBoolean(\"enabled\", true));\r\n    if (pkiRealmEnabled) {\r\n        for (String contextName : getSslContextNames(settings)) {\r\n            final SSLConfiguration configuration = sslService.getSSLConfiguration(contextName);\r\n            if (sslService.isSSLClientAuthEnabled(configuration)) {\r\n                return BootstrapCheckResult.success();\r\n            }\r\n        }\r\n        return BootstrapCheckResult.failure(\"a PKI realm is enabled but cannot be used as neither HTTP or Transport have SSL and client authentication enabled\");\r\n    } else {\r\n        return BootstrapCheckResult.success();\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.mediacodec.MediaCodecUtil.getPassthroughDecoderInfo",
	"Comment": "returns information about a decoder suitable for audio passthrough.",
	"Method": "MediaCodecInfo getPassthroughDecoderInfo(){\r\n    MediaCodecInfo decoderInfo = getDecoderInfo(MimeTypes.AUDIO_RAW, false);\r\n    return decoderInfo == null ? null : MediaCodecInfo.newPassthroughInstance(decoderInfo.name);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.proto.ColumnInfo.jdbcType",
	"Comment": "the type of the column as it would be returned by a jdbc driver.",
	"Method": "Integer jdbcType(){\r\n    return jdbcType;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.RollupResponseTranslator.unrollMultiBucket",
	"Comment": "helper method which unrolls a generic multibucket agg. prefer to use the other overloadas a consumer of the api",
	"Method": "InternalAggregation unrollMultiBucket(InternalMultiBucketAggregation rolled,InternalMultiBucketAggregation original,InternalMultiBucketAggregation currentTree,InternalAggregation unrollMultiBucket,T source,T original,T currentTree,TriFunction<InternalBucket, Long, InternalAggregations, B> bucketFactory){\r\n    Map<Object, InternalBucket> originalKeys = new HashMap();\r\n    Map<Object, InternalBucket> currentKeys = new HashMap();\r\n    if (original != null) {\r\n        original.getBuckets().forEach(b -> originalKeys.put(b.getKey(), b));\r\n    }\r\n    if (currentTree != null) {\r\n        currentTree.getBuckets().forEach(b -> currentKeys.put(b.getKey(), b));\r\n    }\r\n    List<B> buckets = // If the original has this key, ignore the rolled version\r\n    source.getBuckets().stream().filter(b -> originalKeys.containsKey(b.getKey()) == false).map(bucket -> {\r\n        long bucketCount = getAggCount(source, bucket.getAggregations().getAsMap());\r\n        if (bucketCount == 0) {\r\n            return null;\r\n        }\r\n        if (currentKeys.containsKey(bucket.getKey()) && currentKeys.get(bucket.getKey()).getDocCount() != 0) {\r\n            bucketCount = 0;\r\n        }\r\n        InternalAggregations subAggs = unrollSubAggsFromMulti(bucket, originalKeys.get(bucket.getKey()), currentKeys.get(bucket.getKey()));\r\n        return bucketFactory.apply(bucket, bucketCount, subAggs);\r\n    }).filter(Objects::nonNull).collect(Collectors.toList());\r\n    return source.create(buckets);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.support.LdapUtils.maybeForkAndRun",
	"Comment": "if necessary, fork before executing the runnable. a deadlock will happen ifthe same thread which handles bind responses blocks on the bind call, waitingfor the response which he itself should handle.",
	"Method": "void maybeForkAndRun(ThreadPool threadPool,Runnable runnable){\r\n    if (isLdapConnectionThread(Thread.currentThread())) {\r\n        threadPool.executor(ThreadPool.Names.GENERIC).execute(runnable);\r\n    } else {\r\n        runnable.run();\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.SimpleExoPlayer.getAudioFormat",
	"Comment": "returns the audio format currently being played, or null if no audio is being played.",
	"Method": "Format getAudioFormat(){\r\n    return audioFormat;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.MediaCodecVideoRenderer.renderOutputBufferV21",
	"Comment": "renders the output buffer with the specified index. this method is only called if the platformapi version of the device is 21 or later.",
	"Method": "void renderOutputBufferV21(MediaCodec codec,int index,long presentationTimeUs,long releaseTimeNs){\r\n    maybeNotifyVideoSizeChanged();\r\n    TraceUtil.beginSection(\"releaseOutputBuffer\");\r\n    codec.releaseOutputBuffer(index, releaseTimeNs);\r\n    TraceUtil.endSection();\r\n    lastRenderTimeUs = SystemClock.elapsedRealtime() * 1000;\r\n    decoderCounters.renderedOutputBufferCount++;\r\n    consecutiveDroppedFrameCount = 0;\r\n    maybeNotifyRenderedFirstFrame();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherIndexingListener.hasShardAllocationIdChanged",
	"Comment": "check if the routing table has changed and local shards are affected",
	"Method": "boolean hasShardAllocationIdChanged(String watchIndex,ClusterState state){\r\n    List<ShardRouting> allStartedRelocatedShards = state.getRoutingTable().index(watchIndex).shardsWithState(STARTED);\r\n    allStartedRelocatedShards.addAll(state.getRoutingTable().index(watchIndex).shardsWithState(RELOCATING));\r\n    if (allStartedRelocatedShards.isEmpty() == false && configuration == INACTIVE) {\r\n        return true;\r\n    }\r\n    String localNodeId = state.nodes().getLocalNodeId();\r\n    Set<ShardId> clusterStateLocalShardIds = state.getRoutingNodes().node(localNodeId).shardsWithState(watchIndex, STARTED, RELOCATING).stream().map(ShardRouting::shardId).collect(Collectors.toSet());\r\n    Set<ShardId> configuredLocalShardIds = new HashSet(configuration.localShards.keySet());\r\n    Set<ShardId> differenceSet = Sets.difference(clusterStateLocalShardIds, configuredLocalShardIds);\r\n    if (differenceSet.isEmpty() == false) {\r\n        return true;\r\n    }\r\n    Map<ShardId, List<String>> shards = allStartedRelocatedShards.stream().collect(Collectors.groupingBy(ShardRouting::shardId, Collectors.mapping(sr -> sr.allocationId().getId(), Collectors.toCollection(ArrayList::new))));\r\n    shards.values().forEach(Collections::sort);\r\n    for (Map.Entry<ShardId, ShardAllocationConfiguration> entry : configuration.localShards.entrySet()) {\r\n        if (shards.containsKey(entry.getKey()) == false) {\r\n            return true;\r\n        }\r\n        Collection<String> allocationIds = shards.get(entry.getKey());\r\n        if (allocationIds.equals(entry.getValue().allocationIds) == false) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.chunk.ChunkSampleStream.getBufferedPositionUs",
	"Comment": "returns an estimate of the position up to which data is buffered.",
	"Method": "long getBufferedPositionUs(){\r\n    if (loadingFinished) {\r\n        return C.TIME_END_OF_SOURCE;\r\n    } else if (isPendingReset()) {\r\n        return pendingResetPositionUs;\r\n    } else {\r\n        long bufferedPositionUs = lastSeekPositionUs;\r\n        BaseMediaChunk lastMediaChunk = getLastMediaChunk();\r\n        BaseMediaChunk lastCompletedMediaChunk = lastMediaChunk.isLoadCompleted() ? lastMediaChunk : mediaChunks.size() > 1 ? mediaChunks.get(mediaChunks.size() - 2) : null;\r\n        if (lastCompletedMediaChunk != null) {\r\n            bufferedPositionUs = Math.max(bufferedPositionUs, lastCompletedMediaChunk.endTimeUs);\r\n        }\r\n        return Math.max(bufferedPositionUs, primarySampleQueue.getLargestQueuedTimestampUs());\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.expression.Literal.of",
	"Comment": "utility method for creating a literal out of a foldable expression.throws an exception if the expression is not foldable.",
	"Method": "Literal of(Location loc,Object value,Literal of,Expression foldable,Literal of,String name,Expression foldable,Literal of,Expression source,Object value){\r\n    String name = source instanceof NamedExpression ? ((NamedExpression) source).name() : String.valueOf(value);\r\n    return new Literal(source.location(), name, value, source.dataType());\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerView.getControllerHideOnTouch",
	"Comment": "returns whether the playback controls are hidden by touch events.",
	"Method": "boolean getControllerHideOnTouch(){\r\n    return controllerHideOnTouch;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherIndexingListener.reloadConfiguration",
	"Comment": "reload the configuration if the alias pointing to the watch index was changed orthe index routing table for an index was changed",
	"Method": "void reloadConfiguration(String watchIndex,List<ShardRouting> localShardRouting,ClusterChangedEvent event){\r\n    boolean isAliasChanged = watchIndex.equals(configuration.index) == false;\r\n    if (isAliasChanged || hasShardAllocationIdChanged(watchIndex, event.state())) {\r\n        IndexRoutingTable watchIndexRoutingTable = event.state().routingTable().index(watchIndex);\r\n        Map<ShardId, ShardAllocationConfiguration> ids = getLocalShardAllocationIds(localShardRouting, watchIndexRoutingTable);\r\n        configuration = new Configuration(watchIndex, ids);\r\n    }\r\n}"
}, {
	"Path": "com.alibaba.fastjson.asm.ClassWriter.newFieldItem",
	"Comment": "adds a field reference to the constant pool of the class being build. does nothing if the constant pool alreadycontains a similar item.",
	"Method": "Item newFieldItem(String owner,String name,String desc){\r\n    key3.set(9, owner, name, desc);\r\n    Item result = get(key3);\r\n    if (result == null) {\r\n        int s1 = newClassItem(owner).index, s2 = newNameTypeItem(name, desc).index;\r\n        pool.put12(9, s1).putShort(s2);\r\n        result = new Item(index++, key3);\r\n        put(result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.DefaultTrackSelectorTest.testSelectPreferredAudioTrackMultipleRenderers",
	"Comment": "tests audio track selection when there are multiple audio renderers.",
	"Method": "void testSelectPreferredAudioTrackMultipleRenderers(){\r\n    Format english = buildAudioFormat(\"en\", \"en\");\r\n    Format german = buildAudioFormat(\"de\", \"de\");\r\n    Map<String, Integer> firstRendererMappedCapabilities = new HashMap();\r\n    firstRendererMappedCapabilities.put(english.id, FORMAT_HANDLED);\r\n    firstRendererMappedCapabilities.put(german.id, FORMAT_UNSUPPORTED_SUBTYPE);\r\n    RendererCapabilities firstRendererCapabilities = new FakeMappedRendererCapabilities(C.TRACK_TYPE_AUDIO, firstRendererMappedCapabilities);\r\n    Map<String, Integer> secondRendererMappedCapabilities = new HashMap();\r\n    secondRendererMappedCapabilities.put(english.id, FORMAT_UNSUPPORTED_SUBTYPE);\r\n    secondRendererMappedCapabilities.put(german.id, FORMAT_HANDLED);\r\n    RendererCapabilities secondRendererCapabilities = new FakeMappedRendererCapabilities(C.TRACK_TYPE_AUDIO, secondRendererMappedCapabilities);\r\n    RendererCapabilities[] rendererCapabilities = new RendererCapabilities[] { firstRendererCapabilities, secondRendererCapabilities };\r\n    TrackSelectorResult result = trackSelector.selectTracks(rendererCapabilities, wrapFormats(english, german));\r\n    assertThat(result.selections.get(0).getFormat(0)).isSameAs(english);\r\n    assertThat(result.selections.get(1)).isNull();\r\n    trackSelector.setParameters(trackSelector.buildUponParameters().setPreferredAudioLanguage(\"en\"));\r\n    result = trackSelector.selectTracks(rendererCapabilities, wrapFormats(english, german));\r\n    assertThat(result.selections.get(0).getFormat(0)).isSameAs(english);\r\n    assertThat(result.selections.get(1)).isNull();\r\n    trackSelector.setParameters(trackSelector.buildUponParameters().setPreferredAudioLanguage(\"de\"));\r\n    result = trackSelector.selectTracks(rendererCapabilities, wrapFormats(english, german));\r\n    assertThat(result.selections.get(0)).isNull();\r\n    assertThat(result.selections.get(1).getFormat(0)).isSameAs(german);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.video.VideoFrameReleaseTimeHelper.enable",
	"Comment": "enables the helper. must be called from the playback thread.",
	"Method": "void enable(){\r\n    haveSync = false;\r\n    if (windowManager != null) {\r\n        vsyncSampler.addObserver();\r\n        if (displayListener != null) {\r\n            displayListener.register();\r\n        }\r\n        updateDefaultDisplayRefreshRateParams();\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.FakeMediaPeriod.setPreparationComplete",
	"Comment": "allows the fake media period to complete preparation. may be called on any thread.",
	"Method": "void setPreparationComplete(){\r\n    deferOnPrepared = false;\r\n    if (playerHandler != null && prepareCallback != null) {\r\n        playerHandler.post(this::finishPreparation);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.watch.ClockMock.freeze",
	"Comment": "freeze the time for this clock, preventing it from advancing",
	"Method": "ClockMock freeze(){\r\n    setTime(instant());\r\n    return this;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.ParsingLoadable.getResponseHeaders",
	"Comment": "returns the response headers associated with the load. must only be called after the loadcompleted, failed, or was canceled.",
	"Method": "Map<String, List<String>> getResponseHeaders(){\r\n    return dataSource.getLastResponseHeaders();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodHolder.getBufferedPositionUs",
	"Comment": "returns the buffered position in microseconds. if the period is buffered to the end, then theperiod duration is returned.",
	"Method": "long getBufferedPositionUs(){\r\n    if (!prepared) {\r\n        return info.startPositionUs;\r\n    }\r\n    long bufferedPositionUs = hasEnabledTracks ? mediaPeriod.getBufferedPositionUs() : C.TIME_END_OF_SOURCE;\r\n    return bufferedPositionUs == C.TIME_END_OF_SOURCE ? info.durationUs : bufferedPositionUs;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.ima.FakePlayer.updateTimeline",
	"Comment": "sets the timeline on this fake player, which notifies listeners with the changed timeline.",
	"Method": "void updateTimeline(Timeline timeline){\r\n    for (Player.EventListener listener : listeners) {\r\n        listener.onTimelineChanged(timeline, null, prepared ? TIMELINE_CHANGE_REASON_DYNAMIC : TIMELINE_CHANGE_REASON_PREPARED);\r\n    }\r\n    prepared = true;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleMetadataQueue.getLargestTimestamp",
	"Comment": "finds the largest timestamp of any sample from the start of the queue up to the specifiedlength, assuming that the timestamps prior to a keyframe are always less than the timestamp ofthe keyframe itself, and of subsequent frames.",
	"Method": "long getLargestTimestamp(int length){\r\n    if (length == 0) {\r\n        return Long.MIN_VALUE;\r\n    }\r\n    long largestTimestampUs = Long.MIN_VALUE;\r\n    int relativeSampleIndex = getRelativeIndex(length - 1);\r\n    for (int i = 0; i < length; i++) {\r\n        largestTimestampUs = Math.max(largestTimestampUs, timesUs[relativeSampleIndex]);\r\n        if ((flags[relativeSampleIndex] & C.BUFFER_FLAG_KEY_FRAME) != 0) {\r\n            break;\r\n        }\r\n        relativeSampleIndex--;\r\n        if (relativeSampleIndex == -1) {\r\n            relativeSampleIndex = capacity - 1;\r\n        }\r\n    }\r\n    return largestTimestampUs;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.DefaultTimeBar.setPlayedColor",
	"Comment": "sets the color for the portion of the time bar representing media before the playback position.",
	"Method": "void setPlayedColor(int playedColor){\r\n    playedPaint.setColor(playedColor);\r\n    invalidate(seekBounds);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.jdbc.JdbcHttpClient.nextPage",
	"Comment": "read the next page of results and returningthe scroll id to use to fetch the next page.",
	"Method": "Tuple<String, List<List<Object>>> nextPage(String cursor,RequestMeta meta){\r\n    SqlQueryRequest sqlRequest = new SqlQueryRequest(cursor, TimeValue.timeValueMillis(meta.timeoutInMs()), TimeValue.timeValueMillis(meta.queryTimeoutInMs()), new RequestInfo(Mode.JDBC));\r\n    SqlQueryResponse response = httpClient.query(sqlRequest);\r\n    return new Tuple(response.cursor(), response.rows());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.type.DataTypeConversion.convert",
	"Comment": "converts arbitrary object to the desired data type.throws sqlillegalargumentexception if such conversion is not possible",
	"Method": "Object convert(Object value,DataType dataType){\r\n    DataType detectedType = DataTypes.fromJava(value);\r\n    if (detectedType == dataType || value == null) {\r\n        return value;\r\n    }\r\n    return conversionFor(detectedType, dataType).convert(value);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.upgrade.IndexUpgradeService.upgradeInfo",
	"Comment": "returns the information about required upgrade action for the given indices",
	"Method": "Map<String, UpgradeActionRequired> upgradeInfo(String[] indices,IndicesOptions options,ClusterState state,UpgradeActionRequired upgradeInfo,IndexMetaData indexMetaData,String index){\r\n    for (IndexUpgradeCheck check : upgradeChecks) {\r\n        UpgradeActionRequired upgradeActionRequired = check.actionRequired(indexMetaData);\r\n        logger.trace(\"[{}] check [{}] returned [{}]\", index, check.getName(), upgradeActionRequired);\r\n        switch(upgradeActionRequired) {\r\n            case UPGRADE:\r\n            case REINDEX:\r\n                return upgradeActionRequired;\r\n            case UP_TO_DATE:\r\n                return null;\r\n            case NOT_APPLICABLE:\r\n                break;\r\n            default:\r\n                throw new IllegalStateException(\"unknown upgrade action \" + upgradeActionRequired + \" for the index \" + index);\r\n        }\r\n    }\r\n    if (indexMetaData.getCreationVersion().before(Version.V_6_0_0)) {\r\n        return UpgradeActionRequired.REINDEX;\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.common.http.HttpResponse.headers",
	"Comment": "returns all the headers, with keys being lowercased, so they are always consistentin the payload",
	"Method": "Map<String, List<String>> headers(){\r\n    MapBuilder<String, List<String>> builder = MapBuilder.newMapBuilder();\r\n    for (Map.Entry<String, String[]> entry : headers.entrySet()) {\r\n        builder.put(entry.getKey().toLowerCase(Locale.ROOT), Arrays.asList(entry.getValue()));\r\n    }\r\n    return builder.immutableMap();\r\n}"
}, {
	"Path": "org.elasticsearch.test.SecuritySingleNodeTestCase.destroyDefaultSettings",
	"Comment": "set the static default settings to null to prevent a memory leak. the test framework also checks for memory leaksand computes the size, this can cause issues when running with the security manager as it tries to do reflectioninto protected sun packages.",
	"Method": "void destroyDefaultSettings(){\r\n    SECURITY_DEFAULT_SETTINGS = null;\r\n    customSecuritySettingsSource = null;\r\n    if (BOOTSTRAP_PASSWORD != null) {\r\n        BOOTSTRAP_PASSWORD.close();\r\n        BOOTSTRAP_PASSWORD = null;\r\n    }\r\n    tearDownRestClient();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.readUnsignedFixedPoint1616",
	"Comment": "reads the next four bytes, returning the integer portion of the fixed point 16.16 integer.",
	"Method": "int readUnsignedFixedPoint1616(){\r\n    int result = (data[position++] & 0xFF) << 8 | (data[position++] & 0xFF);\r\n    position += 2;\r\n    return result;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.SecurityContext.executeAfterRewritingAuthentication",
	"Comment": "runs the consumer in a new context after setting a new version of the authentication that is compatible with the version provided.the original context is provided to the consumer. when this method returns, the original context is restored.",
	"Method": "void executeAfterRewritingAuthentication(Consumer<StoredContext> consumer,Version version){\r\n    final StoredContext original = threadContext.newStoredContext(true);\r\n    final Authentication authentication = Objects.requireNonNull(userSettings.getAuthentication());\r\n    try (ThreadContext.StoredContext ctx = threadContext.stashContext()) {\r\n        setAuthentication(new Authentication(authentication.getUser(), authentication.getAuthenticatedBy(), authentication.getLookedUpBy(), version));\r\n        consumer.accept(original);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.AutodetectBuilder.build",
	"Comment": "requests that the controller daemon start an autodetect process.",
	"Method": "void build(){\r\n    List<String> command = buildAutodetectCommand();\r\n    buildLimits(command);\r\n    buildModelPlotConfig(command);\r\n    buildQuantiles(command);\r\n    buildFieldConfig(command);\r\n    processPipes.addArgs(command);\r\n    controller.startProcess(command);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherLifeCycleServiceTests.testWatcherReloadsOnNodeOutageWithWatcherShard",
	"Comment": "previously we only checked the local shard allocations, but we also need to check if shards in the cluster have changed",
	"Method": "void testWatcherReloadsOnNodeOutageWithWatcherShard(){\r\n    Index watchIndex = new Index(Watch.INDEX, \"foo\");\r\n    ShardId shardId = new ShardId(watchIndex, 0);\r\n    String localNodeId = randomFrom(\"node_1\", \"node_2\");\r\n    String outageNodeId = localNodeId.equals(\"node_1\") ? \"node_2\" : \"node_1\";\r\n    DiscoveryNodes previousDiscoveryNodes = new DiscoveryNodes.Builder().masterNodeId(localNodeId).localNodeId(localNodeId).add(newNode(localNodeId)).add(newNode(outageNodeId)).build();\r\n    ShardRouting replicaShardRouting = TestShardRouting.newShardRouting(shardId, localNodeId, false, STARTED);\r\n    ShardRouting primartShardRouting = TestShardRouting.newShardRouting(shardId, outageNodeId, true, STARTED);\r\n    IndexRoutingTable previousWatchRoutingTable = IndexRoutingTable.builder(watchIndex).addShard(replicaShardRouting).addShard(primartShardRouting).build();\r\n    IndexMetaData indexMetaData = IndexMetaData.builder(Watch.INDEX).settings(Settings.builder().put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1).put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0).put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT).put(IndexMetaData.INDEX_FORMAT_SETTING.getKey(), 6)).build();\r\n    ClusterState previousState = ClusterState.builder(new ClusterName(\"my-cluster\")).nodes(previousDiscoveryNodes).routingTable(RoutingTable.builder().add(previousWatchRoutingTable).build()).metaData(MetaData.builder().put(indexMetaData, false)).build();\r\n    ShardRouting nowPrimaryShardRouting = replicaShardRouting.moveActiveReplicaToPrimary();\r\n    IndexRoutingTable currentWatchRoutingTable = IndexRoutingTable.builder(watchIndex).addShard(nowPrimaryShardRouting).build();\r\n    DiscoveryNodes currentDiscoveryNodes = new DiscoveryNodes.Builder().masterNodeId(localNodeId).localNodeId(localNodeId).add(newNode(localNodeId)).build();\r\n    ClusterState currentState = ClusterState.builder(new ClusterName(\"my-cluster\")).nodes(currentDiscoveryNodes).routingTable(RoutingTable.builder().add(currentWatchRoutingTable).build()).metaData(MetaData.builder().put(indexMetaData, false)).build();\r\n    when(watcherService.validate(anyObject())).thenReturn(true);\r\n    lifeCycleService.clusterChanged(new ClusterChangedEvent(\"whatever\", previousState, currentState));\r\n    reset(watcherService);\r\n    when(watcherService.validate(anyObject())).thenReturn(true);\r\n    ClusterChangedEvent event = new ClusterChangedEvent(\"whatever\", currentState, previousState);\r\n    lifeCycleService.clusterChanged(event);\r\n    verify(watcherService).reload(eq(event.state()), anyString());\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.TimestampFormatFinder.findFirstMatch",
	"Comment": "find the first timestamp format that matches part of the supplied value,excluding a specified number of candidate formats.",
	"Method": "TimestampMatch findFirstMatch(String text,TimestampMatch findFirstMatch,String text,String requiredFormat,TimestampMatch findFirstMatch,String text,int ignoreCandidates,TimestampMatch findFirstMatch,String text,int ignoreCandidates,String requiredFormat){\r\n    if (ignoreCandidates >= ORDERED_CANDIDATE_FORMATS.size()) {\r\n        return null;\r\n    }\r\n    Boolean[] quickRuleoutMatches = new Boolean[QUICK_RULE_OUT_PATTERNS.size()];\r\n    int index = ignoreCandidates;\r\n    String adjustedRequiredFormat = adjustRequiredFormat(requiredFormat);\r\n    for (CandidateTimestampFormat candidate : ORDERED_CANDIDATE_FORMATS.subList(ignoreCandidates, ORDERED_CANDIDATE_FORMATS.size())) {\r\n        if (adjustedRequiredFormat == null || candidate.jodaTimestampFormats.contains(adjustedRequiredFormat) || candidate.javaTimestampFormats.contains(adjustedRequiredFormat)) {\r\n            boolean quicklyRuledOut = false;\r\n            for (Integer quickRuleOutIndex : candidate.quickRuleOutIndices) {\r\n                if (quickRuleoutMatches[quickRuleOutIndex] == null) {\r\n                    quickRuleoutMatches[quickRuleOutIndex] = QUICK_RULE_OUT_PATTERNS.get(quickRuleOutIndex).matcher(text).find();\r\n                }\r\n                if (quickRuleoutMatches[quickRuleOutIndex] == false) {\r\n                    quicklyRuledOut = true;\r\n                    break;\r\n                }\r\n            }\r\n            if (quicklyRuledOut == false) {\r\n                Map<String, Object> captures = candidate.strictSearchGrok.captures(text);\r\n                if (captures != null) {\r\n                    String preface = captures.getOrDefault(PREFACE, \"\").toString();\r\n                    String epilogue = captures.getOrDefault(EPILOGUE, \"\").toString();\r\n                    return makeTimestampMatch(candidate, index, preface, text.substring(preface.length(), text.length() - epilogue.length()), epilogue);\r\n                }\r\n            }\r\n        }\r\n        ++index;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.trackselection.MappingTrackSelector.getCurrentMappedTrackInfo",
	"Comment": "returns the mapping information for the currently active track selection, or null if noselection is currently active.",
	"Method": "MappedTrackInfo getCurrentMappedTrackInfo(){\r\n    return currentMappedTrackInfo;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.dash.manifest.DashManifestParserTest.testParseMediaPresentationDescription",
	"Comment": "simple test to ensure the sample manifests parse without any exceptions being thrown.",
	"Method": "void testParseMediaPresentationDescription(){\r\n    DashManifestParser parser = new DashManifestParser();\r\n    parser.parse(Uri.parse(\"https://example.com/test.mpd\"), TestUtil.getInputStream(RuntimeEnvironment.application, SAMPLE_MPD_1));\r\n    parser.parse(Uri.parse(\"https://example.com/test.mpd\"), TestUtil.getInputStream(RuntimeEnvironment.application, SAMPLE_MPD_2_UNKNOWN_MIME_TYPE));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.TokenService.createUserToken",
	"Comment": "create a token based on the provided authentication and metadata.the created token will be stored in the security index.",
	"Method": "void createUserToken(Authentication authentication,Authentication originatingClientAuth,ActionListener<Tuple<UserToken, String>> listener,Map<String, Object> metadata,boolean includeRefreshToken){\r\n    ensureEnabled();\r\n    if (authentication == null) {\r\n        listener.onFailure(traceLog(\"create token\", null, new IllegalArgumentException(\"authentication must be provided\")));\r\n    } else if (originatingClientAuth == null) {\r\n        listener.onFailure(traceLog(\"create token\", null, new IllegalArgumentException(\"originating client authentication must be provided\")));\r\n    } else {\r\n        final Instant created = clock.instant();\r\n        final Instant expiration = getExpirationTime(created);\r\n        final Version version = clusterService.state().nodes().getMinNodeVersion();\r\n        final Authentication matchingVersionAuth = version.equals(authentication.getVersion()) ? authentication : new Authentication(authentication.getUser(), authentication.getAuthenticatedBy(), authentication.getLookedUpBy(), version);\r\n        final UserToken userToken = new UserToken(version, matchingVersionAuth, expiration, metadata);\r\n        final String refreshToken = includeRefreshToken ? UUIDs.randomBase64UUID() : null;\r\n        try (XContentBuilder builder = XContentFactory.jsonBuilder()) {\r\n            builder.startObject();\r\n            builder.field(\"doc_type\", \"token\");\r\n            builder.field(\"creation_time\", created.toEpochMilli());\r\n            if (includeRefreshToken) {\r\n                builder.startObject(\"refresh_token\").field(\"token\", refreshToken).field(\"invalidated\", false).field(\"refreshed\", false).startObject(\"client\").field(\"type\", \"unassociated_client\").field(\"user\", originatingClientAuth.getUser().principal()).field(\"realm\", originatingClientAuth.getAuthenticatedBy().getName()).endObject().endObject();\r\n            }\r\n            builder.startObject(\"access_token\").field(\"invalidated\", false).field(\"user_token\", userToken).field(\"realm\", authentication.getAuthenticatedBy().getName()).endObject();\r\n            builder.endObject();\r\n            final String documentId = getTokenDocumentId(userToken);\r\n            IndexRequest request = client.prepareIndex(SecurityIndexManager.SECURITY_INDEX_NAME, TYPE, documentId).setOpType(OpType.CREATE).setSource(builder).setRefreshPolicy(RefreshPolicy.WAIT_UNTIL).request();\r\n            securityIndex.prepareIndexIfNeededThenExecute(ex -> listener.onFailure(traceLog(\"prepare security index\", documentId, ex)), () -> executeAsyncWithOrigin(client, SECURITY_ORIGIN, IndexAction.INSTANCE, request, ActionListener.wrap(indexResponse -> listener.onResponse(new Tuple(userToken, refreshToken)), listener::onFailure)));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLService.loadSSLConfigurations",
	"Comment": "parses the settings to load all sslconfiguration objects that will be used.",
	"Method": "Map<SSLConfiguration, SSLContextHolder> loadSSLConfigurations(){\r\n    Map<SSLConfiguration, SSLContextHolder> sslContextHolders = new HashMap();\r\n    sslContextHolders.put(globalSSLConfiguration, createSslContext(globalSSLConfiguration));\r\n    this.sslConfigurations.put(\"xpack.ssl\", globalSSLConfiguration);\r\n    Map<String, Settings> sslSettingsMap = new HashMap();\r\n    sslSettingsMap.put(XPackSettings.HTTP_SSL_PREFIX, getHttpTransportSSLSettings(settings));\r\n    sslSettingsMap.put(\"xpack.http.ssl\", settings.getByPrefix(\"xpack.http.ssl.\"));\r\n    sslSettingsMap.putAll(getRealmsSSLSettings(settings));\r\n    sslSettingsMap.putAll(getMonitoringExporterSettings(settings));\r\n    sslSettingsMap.forEach((key, sslSettings) -> {\r\n        if (sslSettings.isEmpty()) {\r\n            storeSslConfiguration(key, globalSSLConfiguration);\r\n        } else {\r\n            final SSLConfiguration configuration = new SSLConfiguration(sslSettings, globalSSLConfiguration);\r\n            storeSslConfiguration(key, configuration);\r\n            sslContextHolders.computeIfAbsent(configuration, this::createSslContext);\r\n        }\r\n    });\r\n    final Settings transportSSLSettings = settings.getByPrefix(XPackSettings.TRANSPORT_SSL_PREFIX);\r\n    final SSLConfiguration transportSSLConfiguration = new SSLConfiguration(transportSSLSettings, globalSSLConfiguration);\r\n    this.transportSSLConfiguration.set(transportSSLConfiguration);\r\n    storeSslConfiguration(XPackSettings.TRANSPORT_SSL_PREFIX, transportSSLConfiguration);\r\n    Map<String, Settings> profileSettings = getTransportProfileSSLSettings(settings);\r\n    sslContextHolders.computeIfAbsent(transportSSLConfiguration, this::createSslContext);\r\n    profileSettings.forEach((key, profileSetting) -> {\r\n        final SSLConfiguration configuration = new SSLConfiguration(profileSetting, transportSSLConfiguration);\r\n        storeSslConfiguration(key, configuration);\r\n        sslContextHolders.computeIfAbsent(configuration, this::createSslContext);\r\n    });\r\n    return Collections.unmodifiableMap(sslContextHolders);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.ts.AdtsExtractor.getBitrateFromFrameSize",
	"Comment": "returns the stream bitrate, given a frame size and the duration of that frame in microseconds.",
	"Method": "int getBitrateFromFrameSize(int frameSize,long durationUsPerFrame){\r\n    return (int) ((frameSize * C.BITS_PER_BYTE * C.MICROS_PER_SECOND) / durationUsPerFrame);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleMetadataQueue.discardToEnd",
	"Comment": "discards all samples in the queue. the read position is also advanced.",
	"Method": "long discardToEnd(){\r\n    if (length == 0) {\r\n        return C.POSITION_UNSET;\r\n    }\r\n    return discardSamples(length);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.testutil.ExoPlayerTestRunner.assertPlayedPeriodIndices",
	"Comment": "asserts that the indices of played periods is equal to the provided list of periods. a periodis considered to be played if it was the current period after a position discontinuity or amedia source preparation. when the same period is repeated automatically due to enabled repeatmodes, it is reported twice. seeks within the current period are not reported.",
	"Method": "void assertPlayedPeriodIndices(Integer periodIndices){\r\n    assertThat(this.periodIndices).containsExactlyElementsIn(Arrays.asList(periodIndices)).inOrder();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.persistence.BatchedResultsIterator.timeRange",
	"Comment": "query documents whose timestamp is within the given time range",
	"Method": "BatchedResultsIterator<T> timeRange(long startEpochMs,long endEpochMs){\r\n    filterBuilder.timeRange(Result.TIMESTAMP.getPreferredName(), startEpochMs, endEpochMs);\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.rollup.job.RollupJobTask.onCancelled",
	"Comment": "this is called when the persistent task signals that the allocated task should be terminated.termination in the task framework is essentially voluntary, as the allocated task can only beshut down from the inside.",
	"Method": "void onCancelled(){\r\n    logger.info(\"Received cancellation request for Rollup job [\" + job.getConfig().getId() + \"], state: [\" + indexer.getState() + \"]\");\r\n    if (indexer.abort()) {\r\n        shutdown();\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.extractor.mkv.VarintReader.getLastLength",
	"Comment": "returns the number of bytes occupied by the most recently parsed varint.",
	"Method": "int getLastLength(){\r\n    return length;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.vp9.VpxLibrary.getBuildConfig",
	"Comment": "returns the configuration string with which the underlying library was built if available, ornull otherwise.",
	"Method": "String getBuildConfig(){\r\n    return isAvailable() ? vpxGetBuildConfig() : null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.jdbc.SqlQueryParameterAnalyzer.skipJdbcEscape",
	"Comment": "skips jdbc escape sequence starting at the current position i, returns the length of the sequence",
	"Method": "int skipJdbcEscape(int i,String sql){\r\n    throw new SQLException(\"Jdbc escape sequences are not supported yet\");\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerView.getUseArtwork",
	"Comment": "returns whether artwork is displayed if present in the media.",
	"Method": "boolean getUseArtwork(){\r\n    return useArtwork;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.authc.support.BCrypt.crypt_raw",
	"Comment": "perform the central password hashing step in thebcrypt scheme",
	"Method": "byte[] crypt_raw(byte password,byte salt,int log_rounds,int cdata){\r\n    int rounds, i, j;\r\n    int clen = cdata.length;\r\n    byte[] ret;\r\n    if (log_rounds < 4 || log_rounds > 30)\r\n        throw new IllegalArgumentException(\"Bad number of rounds\");\r\n    rounds = 1 << log_rounds;\r\n    if (salt.length != BCRYPT_SALT_LEN)\r\n        throw new IllegalArgumentException(\"Bad salt length\");\r\n    init_key();\r\n    ekskey(salt, password);\r\n    for (i = 0; i != rounds; i++) {\r\n        key(password);\r\n        key(salt);\r\n    }\r\n    for (i = 0; i < 64; i++) {\r\n        for (j = 0; j < (clen >> 1); j++) encipher(cdata, j << 1);\r\n    }\r\n    ret = new byte[clen * 4];\r\n    for (i = 0, j = 0; i < clen; i++) {\r\n        ret[j++] = (byte) ((cdata[i] >> 24) & 0xff);\r\n        ret[j++] = (byte) ((cdata[i] >> 16) & 0xff);\r\n        ret[j++] = (byte) ((cdata[i] >> 8) & 0xff);\r\n        ret[j++] = (byte) (cdata[i] & 0xff);\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "org.elasticsearch.test.http.MockWebServer.createRequest",
	"Comment": "creates a mockrequest from an incoming http request, that can later be checked in your test assertions",
	"Method": "MockRequest createRequest(HttpExchange exchange){\r\n    MockRequest request = new MockRequest(exchange.getRequestMethod(), exchange.getRequestURI(), exchange.getRequestHeaders());\r\n    if (exchange.getRequestBody() != null) {\r\n        String body = Streams.copyToString(new InputStreamReader(exchange.getRequestBody(), StandardCharsets.UTF_8));\r\n        if (Strings.isEmpty(body) == false) {\r\n            request.setBody(body);\r\n        }\r\n    }\r\n    return request;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.action.CliFormatterTests.testEstimateSize",
	"Comment": "ensure that our estimates are perfect in at least some cases.",
	"Method": "void testEstimateSize(){\r\n    assertEquals(formatter.formatWithHeader(firstResponse.columns(), firstResponse.rows()).length(), formatter.estimateSize(firstResponse.rows().size() + 2));\r\n    assertEquals(formatter.formatWithoutHeader(firstResponse.rows()).length(), formatter.estimateSize(firstResponse.rows().size()));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.updateUserWithoutPassword",
	"Comment": "handles updating a user that should already exist where their password should not change",
	"Method": "void updateUserWithoutPassword(PutUserRequest putUserRequest,ActionListener<Boolean> listener){\r\n    assert putUserRequest.passwordHash() == null;\r\n    securityIndex.prepareIndexIfNeededThenExecute(listener::onFailure, () -> {\r\n        executeAsyncWithOrigin(client.threadPool().getThreadContext(), SECURITY_ORIGIN, client.prepareUpdate(SECURITY_INDEX_NAME, INDEX_TYPE, getIdForUser(USER_DOC_TYPE, putUserRequest.username())).setDoc(Requests.INDEX_CONTENT_TYPE, Fields.USERNAME.getPreferredName(), putUserRequest.username(), Fields.ROLES.getPreferredName(), putUserRequest.roles(), Fields.FULL_NAME.getPreferredName(), putUserRequest.fullName(), Fields.EMAIL.getPreferredName(), putUserRequest.email(), Fields.METADATA.getPreferredName(), putUserRequest.metadata(), Fields.ENABLED.getPreferredName(), putUserRequest.enabled(), Fields.TYPE.getPreferredName(), USER_DOC_TYPE).setRefreshPolicy(putUserRequest.getRefreshPolicy()).request(), new ActionListener<UpdateResponse>() {\r\n            @Override\r\n            public void onResponse(UpdateResponse updateResponse) {\r\n                assert updateResponse.getResult() == DocWriteResponse.Result.UPDATED || updateResponse.getResult() == DocWriteResponse.Result.NOOP : \"Expected 'UPDATED' or 'NOOP' result [\" + updateResponse + \"] for request [\" + putUserRequest + \"]\";\r\n                clearRealmCache(putUserRequest.username(), listener, false);\r\n            }\r\n            @Override\r\n            public void onFailure(Exception e) {\r\n                Exception failure = e;\r\n                if (isIndexNotFoundOrDocumentMissing(e)) {\r\n                    logger.debug((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage(\"failed to update user document with username [{}]\", putUserRequest.username()), e);\r\n                    ValidationException validationException = new ValidationException();\r\n                    validationException.addValidationError(\"password must be specified unless you are updating an existing user\");\r\n                    failure = validationException;\r\n                }\r\n                listener.onFailure(failure);\r\n            }\r\n        }, client::update);\r\n    });\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.updateUserWithoutPassword",
	"Comment": "handles updating a user that should already exist where their password should not change",
	"Method": "void updateUserWithoutPassword(PutUserRequest putUserRequest,ActionListener<Boolean> listener){\r\n    assert updateResponse.getResult() == DocWriteResponse.Result.UPDATED || updateResponse.getResult() == DocWriteResponse.Result.NOOP : \"Expected 'UPDATED' or 'NOOP' result [\" + updateResponse + \"] for request [\" + putUserRequest + \"]\";\r\n    clearRealmCache(putUserRequest.username(), listener, false);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.esnative.NativeUsersStore.updateUserWithoutPassword",
	"Comment": "handles updating a user that should already exist where their password should not change",
	"Method": "void updateUserWithoutPassword(PutUserRequest putUserRequest,ActionListener<Boolean> listener){\r\n    Exception failure = e;\r\n    if (isIndexNotFoundOrDocumentMissing(e)) {\r\n        logger.debug((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage(\"failed to update user document with username [{}]\", putUserRequest.username()), e);\r\n        ValidationException validationException = new ValidationException();\r\n        validationException.addValidationError(\"password must be specified unless you are updating an existing user\");\r\n        failure = validationException;\r\n    }\r\n    listener.onFailure(failure);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ui.PlayerControlView.setShowTimeoutMs",
	"Comment": "sets the playback controls timeout. the playback controls are automatically hidden after thisduration of time has elapsed without user input.",
	"Method": "void setShowTimeoutMs(int showTimeoutMs){\r\n    this.showTimeoutMs = showTimeoutMs;\r\n    if (isVisible()) {\r\n        hideAfterTimeout();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.action.SecurityActionMapper.action",
	"Comment": "returns the security specific action name given the incoming action name and request",
	"Method": "String action(String action,TransportRequest request){\r\n    switch(action) {\r\n        case ClearScrollAction.NAME:\r\n            assert request instanceof ClearScrollRequest;\r\n            boolean isClearAllScrollRequest = ((ClearScrollRequest) request).scrollIds().contains(\"_all\");\r\n            if (isClearAllScrollRequest) {\r\n                return CLUSTER_PERMISSION_SCROLL_CLEAR_ALL_NAME;\r\n            }\r\n            break;\r\n        case AnalyzeAction.NAME:\r\n        case AnalyzeAction.NAME + \"[s]\":\r\n            assert request instanceof AnalyzeRequest;\r\n            String[] indices = ((AnalyzeRequest) request).indices();\r\n            if (indices == null || (indices.length == 1 && indices[0] == null)) {\r\n                return CLUSTER_PERMISSION_ANALYZE;\r\n            }\r\n            break;\r\n    }\r\n    return action;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.history.HistoryStore.forcePut",
	"Comment": "stores the specified watchrecord.any existing watchrecord will be overwritten.",
	"Method": "void forcePut(WatchRecord watchRecord){\r\n    String index = HistoryStoreField.getHistoryIndexNameForTime(watchRecord.triggerEvent().triggeredTime());\r\n    try (XContentBuilder builder = XContentFactory.jsonBuilder()) {\r\n        watchRecord.toXContent(builder, WatcherParams.HIDE_SECRETS);\r\n        IndexRequest request = new IndexRequest(index, DOC_TYPE, watchRecord.id().value()).source(builder);\r\n        bulkProcessor.add(request);\r\n    } catch (IOException ioe) {\r\n        final WatchRecord wr = watchRecord;\r\n        logger.error((Supplier<?>) () -> new ParameterizedMessage(\"failed to persist watch record [{}]\", wr), ioe);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testReloadingPEMKeyConfigException",
	"Comment": "tests the reloading of a key config backed by pem files when there is an exception during reloading. an exception is caused bytruncating the key file that is being monitored",
	"Method": "void testReloadingPEMKeyConfigException(){\r\n    Path tempDir = createTempDir();\r\n    Path keyPath = tempDir.resolve(\"testnode.pem\");\r\n    Path certPath = tempDir.resolve(\"testnode.crt\");\r\n    Path clientCertPath = tempDir.resolve(\"testclient.crt\");\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.pem\"), keyPath);\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testnode.crt\"), certPath);\r\n    Files.copy(getDataPath(\"/org/elasticsearch/xpack/security/transport/ssl/certs/simple/testclient.crt\"), clientCertPath);\r\n    MockSecureSettings secureSettings = new MockSecureSettings();\r\n    secureSettings.setString(\"xpack.ssl.secure_key_passphrase\", \"testnode\");\r\n    Settings settings = Settings.builder().put(\"xpack.ssl.key\", keyPath).put(\"xpack.ssl.certificate\", certPath).putList(\"xpack.ssl.certificate_authorities\", certPath.toString(), clientCertPath.toString()).put(\"path.home\", createTempDir()).setSecureSettings(secureSettings).build();\r\n    Environment env = randomBoolean() ? null : TestEnvironment.newEnvironment(settings);\r\n    final SSLService sslService = new SSLService(settings, env);\r\n    final SSLConfiguration config = sslService.getSSLConfiguration(\"xpack.ssl\");\r\n    new SSLConfigurationReloader(env, sslService, resourceWatcherService) {\r\n        @Override\r\n        void reloadSSLContext(SSLConfiguration configuration) {\r\n            fail(\"reload should not be called! [pem key reload exception]\");\r\n        }\r\n    };\r\n    final SSLContext context = sslService.sslContextHolder(config).sslContext();\r\n    try (OutputStream os = Files.newOutputStream(keyPath, StandardOpenOption.TRUNCATE_EXISTING)) {\r\n    }\r\n    assertThat(sslService.sslContextHolder(config).sslContext(), sameInstance(context));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloaderTests.testReloadingPEMKeyConfigException",
	"Comment": "tests the reloading of a key config backed by pem files when there is an exception during reloading. an exception is caused bytruncating the key file that is being monitored",
	"Method": "void testReloadingPEMKeyConfigException(){\r\n    fail(\"reload should not be called! [pem key reload exception]\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.support.SecurityIndexManager.isIndexUpToDate",
	"Comment": "returns whether the index is on the current format if it exists. if the index does not existwe treat the index as up to date as we expect it to be created with the current format.",
	"Method": "boolean isIndexUpToDate(){\r\n    return this.indexState.isIndexUpToDate;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.ads.AdPlaybackState.withAdResumePositionUs",
	"Comment": "returns an instance with the specified ad resume position, in microseconds.",
	"Method": "AdPlaybackState withAdResumePositionUs(long adResumePositionUs){\r\n    if (this.adResumePositionUs == adResumePositionUs) {\r\n        return this;\r\n    } else {\r\n        return new AdPlaybackState(adGroupTimesUs, adGroups, adResumePositionUs, contentDurationUs);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.ssl.SSLConfigurationReloader.reloadSSLContext",
	"Comment": "reloads the ssl context associated with this configuration. it is visible so that tests can override as needed",
	"Method": "void reloadSSLContext(SSLConfiguration configuration){\r\n    logger.debug(\"reloading ssl configuration [{}]\", configuration);\r\n    sslService.sslContextHolder(configuration).reload();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.TimestampFormatFinder.findFirstFullMatch",
	"Comment": "find the best timestamp format for matching an entire field value,excluding a specified number of candidate formats.",
	"Method": "TimestampMatch findFirstFullMatch(String text,TimestampMatch findFirstFullMatch,String text,String requiredFormat,TimestampMatch findFirstFullMatch,String text,int ignoreCandidates,TimestampMatch findFirstFullMatch,String text,int ignoreCandidates,String requiredFormat){\r\n    if (ignoreCandidates >= ORDERED_CANDIDATE_FORMATS.size()) {\r\n        return null;\r\n    }\r\n    int index = ignoreCandidates;\r\n    String adjustedRequiredFormat = adjustRequiredFormat(requiredFormat);\r\n    for (CandidateTimestampFormat candidate : ORDERED_CANDIDATE_FORMATS.subList(ignoreCandidates, ORDERED_CANDIDATE_FORMATS.size())) {\r\n        if (adjustedRequiredFormat == null || candidate.jodaTimestampFormats.contains(adjustedRequiredFormat) || candidate.javaTimestampFormats.contains(adjustedRequiredFormat)) {\r\n            Map<String, Object> captures = candidate.strictFullMatchGrok.captures(text);\r\n            if (captures != null) {\r\n                return makeTimestampMatch(candidate, index, \"\", text, \"\");\r\n            }\r\n        }\r\n        ++index;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.support.search.WatcherSearchTemplateRequest.fromXContent",
	"Comment": "reads a new watcher search request instance for the specified parser.",
	"Method": "WatcherSearchTemplateRequest fromXContent(XContentParser parser,SearchType searchType){\r\n    List<String> indices = new ArrayList();\r\n    List<String> types = new ArrayList();\r\n    IndicesOptions indicesOptions = DEFAULT_INDICES_OPTIONS;\r\n    BytesReference searchSource = null;\r\n    Script template = null;\r\n    boolean totalHitsAsInt = false;\r\n    XContentParser.Token token;\r\n    String currentFieldName = null;\r\n    while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\r\n        if (token == XContentParser.Token.FIELD_NAME) {\r\n            currentFieldName = parser.currentName();\r\n        } else if (token == XContentParser.Token.START_ARRAY) {\r\n            if (INDICES_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\r\n                    if (token == XContentParser.Token.VALUE_STRING) {\r\n                        indices.add(parser.textOrNull());\r\n                    } else {\r\n                        throw new ElasticsearchParseException(\"could not read search request. expected string values in [\" + currentFieldName + \"] field, but instead found [\" + token + \"]\");\r\n                    }\r\n                }\r\n            } else if (TYPES_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {\r\n                    if (token == XContentParser.Token.VALUE_STRING) {\r\n                        types.add(parser.textOrNull());\r\n                    } else {\r\n                        throw new ElasticsearchParseException(\"could not read search request. expected string values in [\" + currentFieldName + \"] field, but instead found [\" + token + \"]\");\r\n                    }\r\n                }\r\n            } else {\r\n                throw new ElasticsearchParseException(\"could not read search request. unexpected array field [\" + currentFieldName + \"]\");\r\n            }\r\n        } else if (token == XContentParser.Token.START_OBJECT) {\r\n            if (BODY_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                try (XContentBuilder builder = XContentFactory.jsonBuilder()) {\r\n                    builder.copyCurrentStructure(parser);\r\n                    searchSource = BytesReference.bytes(builder);\r\n                }\r\n            } else if (INDICES_OPTIONS_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                boolean expandOpen = DEFAULT_INDICES_OPTIONS.expandWildcardsOpen();\r\n                boolean expandClosed = DEFAULT_INDICES_OPTIONS.expandWildcardsClosed();\r\n                boolean allowNoIndices = DEFAULT_INDICES_OPTIONS.allowNoIndices();\r\n                boolean ignoreUnavailable = DEFAULT_INDICES_OPTIONS.ignoreUnavailable();\r\n                while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\r\n                    if (token == XContentParser.Token.FIELD_NAME) {\r\n                        currentFieldName = parser.currentName();\r\n                    } else if (token.isValue()) {\r\n                        if (EXPAND_WILDCARDS_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                            switch(parser.text()) {\r\n                                case \"all\":\r\n                                    expandOpen = true;\r\n                                    expandClosed = true;\r\n                                    break;\r\n                                case \"open\":\r\n                                    expandOpen = true;\r\n                                    expandClosed = false;\r\n                                    break;\r\n                                case \"closed\":\r\n                                    expandOpen = false;\r\n                                    expandClosed = true;\r\n                                    break;\r\n                                case \"none\":\r\n                                    expandOpen = false;\r\n                                    expandClosed = false;\r\n                                    break;\r\n                                default:\r\n                                    throw new ElasticsearchParseException(\"could not read search request. unknown value [\" + parser.text() + \"] for [\" + currentFieldName + \"] field \");\r\n                            }\r\n                        } else if (IGNORE_UNAVAILABLE_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                            ignoreUnavailable = parser.booleanValue();\r\n                        } else if (ALLOW_NO_INDICES_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                            allowNoIndices = parser.booleanValue();\r\n                        } else {\r\n                            throw new ElasticsearchParseException(\"could not read search request. unexpected index option [\" + currentFieldName + \"]\");\r\n                        }\r\n                    } else {\r\n                        throw new ElasticsearchParseException(\"could not read search request. unexpected object field [\" + currentFieldName + \"]\");\r\n                    }\r\n                }\r\n                indicesOptions = IndicesOptions.fromOptions(ignoreUnavailable, allowNoIndices, expandOpen, expandClosed, DEFAULT_INDICES_OPTIONS);\r\n            } else if (TEMPLATE_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                template = Script.parse(parser, Script.DEFAULT_TEMPLATE_LANG);\r\n            } else {\r\n                throw new ElasticsearchParseException(\"could not read search request. unexpected object field [\" + currentFieldName + \"]\");\r\n            }\r\n        } else if (token == XContentParser.Token.VALUE_STRING) {\r\n            if (INDICES_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                String indicesStr = parser.text();\r\n                indices.addAll(Arrays.asList(Strings.delimitedListToStringArray(indicesStr, \",\", \" \\t\")));\r\n            } else if (TYPES_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                String typesStr = parser.text();\r\n                types.addAll(Arrays.asList(Strings.delimitedListToStringArray(typesStr, \",\", \" \\t\")));\r\n            } else if (SEARCH_TYPE_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                searchType = SearchType.fromString(parser.text().toLowerCase(Locale.ROOT));\r\n            } else if (REST_TOTAL_HITS_AS_INT_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                totalHitsAsInt = parser.booleanValue();\r\n            } else {\r\n                throw new ElasticsearchParseException(\"could not read search request. unexpected string field [\" + currentFieldName + \"]\");\r\n            }\r\n        } else if (token == XContentParser.Token.VALUE_BOOLEAN) {\r\n            if (REST_TOTAL_HITS_AS_INT_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                totalHitsAsInt = parser.booleanValue();\r\n            } else {\r\n                throw new ElasticsearchParseException(\"could not read search request. unexpected boolean field [\" + currentFieldName + \"]\");\r\n            }\r\n        } else {\r\n            throw new ElasticsearchParseException(\"could not read search request. unexpected token [\" + token + \"]\");\r\n        }\r\n    }\r\n    if (searchSource == null) {\r\n        searchSource = BytesArray.EMPTY;\r\n    }\r\n    WatcherSearchTemplateRequest request = new WatcherSearchTemplateRequest(indices.toArray(new String[0]), types.toArray(new String[0]), searchType, indicesOptions, searchSource, template);\r\n    request.setRestTotalHitsAsInt(totalHitsAsInt);\r\n    return request;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.audio.AudioTrackPositionTracker.hasPendingData",
	"Comment": "returns whether the audio track has any pending data to play out at its current position.",
	"Method": "boolean hasPendingData(long writtenFrames){\r\n    return writtenFrames > getPlaybackHeadPosition() || forceHasPendingData();\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.TimedValueQueue.add",
	"Comment": "associates the specified value with the specified timestamp. all new values should have agreater timestamp than the previously added values. otherwise all values are removed beforeadding the new one.",
	"Method": "void add(long timestamp,V value){\r\n    clearBufferOnTimeDiscontinuity(timestamp);\r\n    doubleCapacityIfFull();\r\n    addUnchecked(timestamp, value);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.exporter.http.HttpExportBulkResponseListener.onFailure",
	"Comment": "log obvious failures.in the future, we should queue replayable failures.",
	"Method": "void onFailure(Exception exception){\r\n    onError(\"bulk request failed unexpectedly\", exception);\r\n}"
}, {
	"Path": "org.greenrobot.eventbus.EventBus.lookupAllEventTypes",
	"Comment": "looks up all class objects including super classes and interfaces. should also work for interfaces.",
	"Method": "List<Class<?>> lookupAllEventTypes(Class<?> eventClass){\r\n    synchronized (eventTypesCache) {\r\n        List<Class<?>> eventTypes = eventTypesCache.get(eventClass);\r\n        if (eventTypes == null) {\r\n            eventTypes = new ArrayList();\r\n            Class<?> clazz = eventClass;\r\n            while (clazz != null) {\r\n                eventTypes.add(clazz);\r\n                addInterfaces(eventTypes, clazz.getInterfaces());\r\n                clazz = clazz.getSuperclass();\r\n            }\r\n            eventTypesCache.put(eventClass, eventTypes);\r\n        }\r\n        return eventTypes;\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.LdapUserSearchSessionFactory.getSessionWithPool",
	"Comment": "sets up a ldapsession using the connection pool that potentially holds existing connections to the server",
	"Method": "void getSessionWithPool(LDAPConnectionPool connectionPool,String user,SecureString password,ActionListener<LdapSession> listener){\r\n    findUser(user, connectionPool, ActionListener.wrap((entry) -> {\r\n        if (entry == null) {\r\n            listener.onResponse(null);\r\n        } else {\r\n            final String dn = entry.getDN();\r\n            final byte[] passwordBytes = CharArrays.toUtf8Bytes(password.getChars());\r\n            final SimpleBindRequest bind = new SimpleBindRequest(dn, passwordBytes);\r\n            LdapUtils.maybeForkThenBindAndRevert(connectionPool, bind, threadPool, new ActionRunnable<LdapSession>(listener) {\r\n                @Override\r\n                protected void doRun() throws Exception {\r\n                    listener.onResponse(new LdapSession(logger, config, connectionPool, dn, groupResolver, metaDataResolver, timeout, entry.getAttributes()));\r\n                }\r\n            });\r\n        }\r\n    }, listener::onFailure));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.LdapUserSearchSessionFactory.getSessionWithPool",
	"Comment": "sets up a ldapsession using the connection pool that potentially holds existing connections to the server",
	"Method": "void getSessionWithPool(LDAPConnectionPool connectionPool,String user,SecureString password,ActionListener<LdapSession> listener){\r\n    listener.onResponse(new LdapSession(logger, config, connectionPool, dn, groupResolver, metaDataResolver, timeout, entry.getAttributes()));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.action.user.ChangePasswordRequestBuilder.source",
	"Comment": "populate the change password request from the source in the provided content type",
	"Method": "ChangePasswordRequestBuilder source(BytesReference source,XContentType xContentType,Hasher hasher){\r\n    try (InputStream stream = source.streamInput();\r\n        XContentParser parser = xContentType.xContent().createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, stream)) {\r\n        XContentUtils.verifyObject(parser);\r\n        XContentParser.Token token;\r\n        String currentFieldName = null;\r\n        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {\r\n            if (token == XContentParser.Token.FIELD_NAME) {\r\n                currentFieldName = parser.currentName();\r\n            } else if (User.Fields.PASSWORD.match(currentFieldName, parser.getDeprecationHandler())) {\r\n                if (token == XContentParser.Token.VALUE_STRING) {\r\n                    String password = parser.text();\r\n                    final char[] passwordChars = password.toCharArray();\r\n                    password(passwordChars, hasher);\r\n                    assert CharBuffer.wrap(passwordChars).chars().noneMatch((i) -> (char) i != (char) 0) : \"expected password to \" + \"clear the char[] but it did not!\";\r\n                } else {\r\n                    throw new ElasticsearchParseException(\"expected field [{}] to be of type string, but found [{}] instead\", currentFieldName, token);\r\n                }\r\n            } else {\r\n                throw new ElasticsearchParseException(\"failed to parse change password request. unexpected field [{}]\", currentFieldName);\r\n            }\r\n        }\r\n    }\r\n    return this;\r\n}"
}, {
	"Path": "org.elasticsearch.test.SecurityIntegTestCase.destroyDefaultSettings",
	"Comment": "set the static default settings to null to prevent a memory leak. the test framework also checks for memory leaksand computes the size, this can cause issues when running with the security manager as it tries to do reflectioninto protected sun packages.",
	"Method": "void destroyDefaultSettings(){\r\n    SECURITY_DEFAULT_SETTINGS = null;\r\n    customSecuritySettingsSource = null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.watcher.WatcherIndexingListener.preDelete",
	"Comment": "if the index operation happened on a watcher shard and is of doc type watcher, we willremove the watch id from the trigger service",
	"Method": "Engine.Delete preDelete(ShardId shardId,Engine.Delete delete){\r\n    if (isWatchDocument(shardId.getIndexName(), delete.type())) {\r\n        triggerService.remove(delete.id());\r\n    }\r\n    return delete;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.flac.FlacDecoderJni.getNextFrameFirstSampleIndex",
	"Comment": "returns the first sample index of the frame to be extracted next.",
	"Method": "long getNextFrameFirstSampleIndex(){\r\n    return flacGetNextFrameFirstSampleIndex(nativeDecoderContext);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.Util.newSingleThreadExecutor",
	"Comment": "instantiates a new single threaded executor whose thread has the specified name.",
	"Method": "ExecutorService newSingleThreadExecutor(String threadName){\r\n    return Executors.newSingleThreadExecutor(runnable -> new Thread(runnable, threadName));\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.readLittleEndianUnsignedIntToInt",
	"Comment": "reads the next four bytes as a little endian unsigned integer into an integer, if the top bitis a zero.",
	"Method": "int readLittleEndianUnsignedIntToInt(){\r\n    int result = readLittleEndianInt();\r\n    if (result < 0) {\r\n        throw new IllegalStateException(\"Top bit not zero: \" + result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.CompositeMediaSource.getMediaTimeForChildMediaTime",
	"Comment": "returns the media time in the composite source corresponding to the specified media time in achild source. the default implementation does not change the media time.",
	"Method": "long getMediaTimeForChildMediaTime(T id,long mediaTimeMs){\r\n    return mediaTimeMs;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.cast.CastPlayer.updateTracksAndSelections",
	"Comment": "updates the internal tracks and selection and returns whether they have changed.",
	"Method": "boolean updateTracksAndSelections(){\r\n    if (remoteMediaClient == null) {\r\n        return false;\r\n    }\r\n    MediaStatus mediaStatus = getMediaStatus();\r\n    MediaInfo mediaInfo = mediaStatus != null ? mediaStatus.getMediaInfo() : null;\r\n    List<MediaTrack> castMediaTracks = mediaInfo != null ? mediaInfo.getMediaTracks() : null;\r\n    if (castMediaTracks == null || castMediaTracks.isEmpty()) {\r\n        boolean hasChanged = !currentTrackGroups.isEmpty();\r\n        currentTrackGroups = TrackGroupArray.EMPTY;\r\n        currentTrackSelection = EMPTY_TRACK_SELECTION_ARRAY;\r\n        return hasChanged;\r\n    }\r\n    long[] activeTrackIds = mediaStatus.getActiveTrackIds();\r\n    if (activeTrackIds == null) {\r\n        activeTrackIds = EMPTY_TRACK_ID_ARRAY;\r\n    }\r\n    TrackGroup[] trackGroups = new TrackGroup[castMediaTracks.size()];\r\n    TrackSelection[] trackSelections = new TrackSelection[RENDERER_COUNT];\r\n    for (int i = 0; i < castMediaTracks.size(); i++) {\r\n        MediaTrack mediaTrack = castMediaTracks.get(i);\r\n        trackGroups[i] = new TrackGroup(CastUtils.mediaTrackToFormat(mediaTrack));\r\n        long id = mediaTrack.getId();\r\n        int trackType = MimeTypes.getTrackType(mediaTrack.getContentType());\r\n        int rendererIndex = getRendererIndexForTrackType(trackType);\r\n        if (isTrackActive(id, activeTrackIds) && rendererIndex != C.INDEX_UNSET && trackSelections[rendererIndex] == null) {\r\n            trackSelections[rendererIndex] = new FixedTrackSelection(trackGroups[i], 0);\r\n        }\r\n    }\r\n    TrackGroupArray newTrackGroups = new TrackGroupArray(trackGroups);\r\n    TrackSelectionArray newTrackSelections = new TrackSelectionArray(trackSelections);\r\n    if (!newTrackGroups.equals(currentTrackGroups) || !newTrackSelections.equals(currentTrackSelection)) {\r\n        currentTrackSelection = new TrackSelectionArray(trackSelections);\r\n        currentTrackGroups = new TrackGroupArray(trackGroups);\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.filestructurefinder.GrokPatternCreator.createGrokPatternFromExamples",
	"Comment": "build a grok pattern that will match all of the sample messages in their entirety.",
	"Method": "String createGrokPatternFromExamples(String seedPatternName,String seedFieldName){\r\n    overallGrokPatternBuilder.setLength(0);\r\n    GrokPatternCandidate seedCandidate = new NoMappingGrokPatternCandidate(seedPatternName, seedFieldName);\r\n    processCandidateAndSplit(seedCandidate, true, sampleMessages, false, 0, false, 0);\r\n    return overallGrokPatternBuilder.toString().replace(\"\\t\", \"\\\\t\").replace(\"\\n\", \"\\\\n\");\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authz.store.CompositeRolesStoreTests.testMergingRolesWithFls",
	"Comment": "this test is a direct result of a issue where field level security permissions were notbeing merged correctly. the improper merging resulted in an allow all result when mergingpermissions from different roles instead of properly creating a union of their languages",
	"Method": "void testMergingRolesWithFls(){\r\n    RoleDescriptor flsRole = new RoleDescriptor(\"fls\", null, new IndicesPrivileges[] { IndicesPrivileges.builder().grantedFields(\"*\").deniedFields(\"L1.*\", \"L2.*\").indices(\"*\").privileges(\"read\").query(\"{ \\\"match\\\": {\\\"eventType.typeCode\\\": \\\"foo\\\"} }\").build() }, null);\r\n    RoleDescriptor addsL1Fields = new RoleDescriptor(\"dls\", null, new IndicesPrivileges[] { IndicesPrivileges.builder().indices(\"*\").grantedFields(\"L1.*\").privileges(\"read\").query(\"{ \\\"match\\\": {\\\"eventType.typeCode\\\": \\\"foo\\\"} }\").build() }, null);\r\n    FieldPermissionsCache cache = new FieldPermissionsCache(Settings.EMPTY);\r\n    PlainActionFuture<Role> future = new PlainActionFuture();\r\n    CompositeRolesStore.buildRoleFromDescriptors(Sets.newHashSet(flsRole, addsL1Fields), cache, null, future);\r\n    Role role = future.actionGet();\r\n    MetaData metaData = MetaData.builder().put(new IndexMetaData.Builder(\"test\").settings(Settings.builder().put(\"index.version.created\", Version.CURRENT).build()).numberOfShards(1).numberOfReplicas(0).build(), true).build();\r\n    Map<String, IndicesAccessControl.IndexAccessControl> acls = role.indices().authorize(\"indices:data/read/search\", Collections.singleton(\"test\"), metaData, cache);\r\n    assertFalse(acls.isEmpty());\r\n    assertTrue(acls.get(\"test\").getFieldPermissions().grantsAccessTo(\"L1.foo\"));\r\n    assertFalse(acls.get(\"test\").getFieldPermissions().grantsAccessTo(\"L2.foo\"));\r\n    assertTrue(acls.get(\"test\").getFieldPermissions().grantsAccessTo(\"L3.foo\"));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.monitoring.exporter.http.WatcherExistsHttpResource.checkXPackForWatcher",
	"Comment": "reach out to the remote cluster to determine the usability of watcher.",
	"Method": "void checkXPackForWatcher(RestClient client,ActionListener<Boolean> listener){\r\n    final CheckedFunction<Response, Boolean, IOException> responseChecker = (response) -> canUseWatcher(response, XContentType.JSON.xContent());\r\n    final CheckedFunction<Response, Boolean, IOException> doesNotExistChecker = (response) -> false;\r\n    checkForResource(client, listener, logger, \"\", \"_xpack\", \"watcher check\", resourceOwnerName, \"monitoring cluster\", GET_EXISTS, Sets.newHashSet(RestStatus.NOT_FOUND.getStatus(), RestStatus.BAD_REQUEST.getStatus()), responseChecker, doesNotExistChecker);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.LdapSessionFactory.session",
	"Comment": "this iterates through the configured user templates attempting to open.if all attempts fail, the last exceptionis kept as the cause of the thrown exception",
	"Method": "void session(String username,SecureString password,ActionListener<LdapSession> listener){\r\n    try {\r\n        new AbstractRunnable() {\r\n            final LDAPConnection connection = LdapUtils.privilegedConnect(serverSet::getConnection);\r\n            final byte[] passwordBytes = CharArrays.toUtf8Bytes(password.getChars());\r\n            Exception containerException = null;\r\n            int loopIndex = 0;\r\n            @Override\r\n            protected void doRun() throws Exception {\r\n                listener.onResponse((new LdapSession(logger, config, connection, ((SimpleBindRequest) connection.getLastBindRequest()).getBindDN(), groupResolver, metaDataResolver, timeout, null)));\r\n            }\r\n            @Override\r\n            public void onFailure(Exception e) {\r\n                if (containerException == null) {\r\n                    containerException = e;\r\n                } else {\r\n                    containerException.addSuppressed(e);\r\n                }\r\n                if (loopIndex > userDnTemplates.length) {\r\n                    listener.onFailure(new IllegalStateException(\"User DN template iteration index out of bounds.\"));\r\n                } else if (loopIndex == userDnTemplates.length) {\r\n                    IOUtils.closeWhileHandlingException(connection);\r\n                    listener.onFailure(containerException);\r\n                } else {\r\n                    loop();\r\n                }\r\n            }\r\n            void loop() {\r\n                final String template = userDnTemplates[loopIndex++];\r\n                final SimpleBindRequest bind = new SimpleBindRequest(buildDnFromTemplate(username, template), passwordBytes);\r\n                LdapUtils.maybeForkThenBind(connection, bind, threadPool, this);\r\n            }\r\n        }.loop();\r\n    } catch (LDAPException e) {\r\n        listener.onFailure(e);\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.LdapSessionFactory.session",
	"Comment": "this iterates through the configured user templates attempting to open.if all attempts fail, the last exceptionis kept as the cause of the thrown exception",
	"Method": "void session(String username,SecureString password,ActionListener<LdapSession> listener){\r\n    listener.onResponse((new LdapSession(logger, config, connection, ((SimpleBindRequest) connection.getLastBindRequest()).getBindDN(), groupResolver, metaDataResolver, timeout, null)));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.LdapSessionFactory.session",
	"Comment": "this iterates through the configured user templates attempting to open.if all attempts fail, the last exceptionis kept as the cause of the thrown exception",
	"Method": "void session(String username,SecureString password,ActionListener<LdapSession> listener){\r\n    if (containerException == null) {\r\n        containerException = e;\r\n    } else {\r\n        containerException.addSuppressed(e);\r\n    }\r\n    if (loopIndex > userDnTemplates.length) {\r\n        listener.onFailure(new IllegalStateException(\"User DN template iteration index out of bounds.\"));\r\n    } else if (loopIndex == userDnTemplates.length) {\r\n        IOUtils.closeWhileHandlingException(connection);\r\n        listener.onFailure(containerException);\r\n    } else {\r\n        loop();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.ldap.LdapSessionFactory.session",
	"Comment": "this iterates through the configured user templates attempting to open.if all attempts fail, the last exceptionis kept as the cause of the thrown exception",
	"Method": "void session(String username,SecureString password,ActionListener<LdapSession> listener){\r\n    final String template = userDnTemplates[loopIndex++];\r\n    final SimpleBindRequest bind = new SimpleBindRequest(buildDnFromTemplate(username, template), passwordBytes);\r\n    LdapUtils.maybeForkThenBind(connection, bind, threadPool, this);\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.saml.SamlSpMetadataBuilder.signingCertificate",
	"Comment": "the certificate that the service provider users to sign saml requests.",
	"Method": "SamlSpMetadataBuilder signingCertificate(X509Certificate signingCertificate){\r\n    this.signingCertificate = signingCertificate;\r\n    return this;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.TraceUtil.endSection",
	"Comment": "writes a trace message to indicate that a given section of code has ended.",
	"Method": "void endSection(){\r\n    if (ExoPlayerLibraryInfo.TRACE_ENABLED && Util.SDK_INT >= 18) {\r\n        endSectionV18();\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.Timeline.getFirstWindowIndex",
	"Comment": "returns the index of the first window in the playback order depending on whether shuffling isenabled.",
	"Method": "int getFirstWindowIndex(boolean shuffleModeEnabled){\r\n    return isEmpty() ? C.INDEX_UNSET : 0;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.ml.job.process.autodetect.writer.JsonDataToProcessWriter.write",
	"Comment": "read the json inputindex, transform to length encoded values and pipe tothe outputstream. no transformation is applied to the data the timestampis expected in seconds from the epoch. if any of the fields inanalysisfields or the datadescriptionstimefield is missing from the josn inputindex an exception is thrown",
	"Method": "void write(InputStream inputStream,CategorizationAnalyzer categorizationAnalyzer,XContentType xContentType,BiConsumer<DataCounts, Exception> handler){\r\n    dataCountsReporter.startNewIncrementalCount();\r\n    if (xContentType.equals(XContentType.JSON)) {\r\n        writeJsonXContent(categorizationAnalyzer, inputStream);\r\n    } else if (xContentType.equals(XContentType.SMILE)) {\r\n        writeSmileXContent(categorizationAnalyzer, inputStream);\r\n    } else {\r\n        throw new RuntimeException(\"XContentType [\" + xContentType + \"] is not supported by JsonDataToProcessWriter\");\r\n    }\r\n    dataCountsReporter.finishReporting(ActionListener.wrap(response -> handler.accept(dataCountsReporter.incrementalStats(), null), e -> handler.accept(null, e)));\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.security.user.User.isRunAs",
	"Comment": "return true if this user was not the originally authenticated user, false otherwise.",
	"Method": "boolean isRunAs(){\r\n    return authenticatedUser != null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateGenerateTool.generateAndWriteCsrs",
	"Comment": "generates certificate signing requests and writes them out to the specified file in zip format",
	"Method": "void generateAndWriteCsrs(Path outputFile,Collection<CertificateInformation> certInfo,int keysize){\r\n    fullyWriteFile(outputFile, (outputStream, pemWriter) -> {\r\n        for (CertificateInformation certificateInformation : certInfo) {\r\n            KeyPair keyPair = CertGenUtils.generateKeyPair(keysize);\r\n            GeneralNames sanList = getSubjectAlternativeNamesValue(certificateInformation.ipAddresses, certificateInformation.dnsNames, certificateInformation.commonNames);\r\n            PKCS10CertificationRequest csr = CertGenUtils.generateCSR(keyPair, certificateInformation.name.x500Principal, sanList);\r\n            final String dirName = certificateInformation.name.filename + \"/\";\r\n            ZipEntry zipEntry = new ZipEntry(dirName);\r\n            assert zipEntry.isDirectory();\r\n            outputStream.putNextEntry(zipEntry);\r\n            outputStream.putNextEntry(new ZipEntry(dirName + certificateInformation.name.filename + \".csr\"));\r\n            pemWriter.writeObject(csr);\r\n            pemWriter.flush();\r\n            outputStream.closeEntry();\r\n            outputStream.putNextEntry(new ZipEntry(dirName + certificateInformation.name.filename + \".key\"));\r\n            pemWriter.writeObject(keyPair.getPrivate());\r\n            pemWriter.flush();\r\n            outputStream.closeEntry();\r\n        }\r\n    });\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.upstream.StatsDataSource.getBytesRead",
	"Comment": "returns the total number of bytes that have been read from the data source.",
	"Method": "long getBytesRead(){\r\n    return bytesRead;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.util.ParsableByteArray.readLittleEndianUnsignedInt",
	"Comment": "reads the next four bytes as an unsigned value in little endian order.",
	"Method": "long readLittleEndianUnsignedInt(){\r\n    return (data[position++] & 0xFFL) | (data[position++] & 0xFFL) << 8 | (data[position++] & 0xFFL) << 16 | (data[position++] & 0xFFL) << 24;\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.BaseMediaSource.refreshSourceInfo",
	"Comment": "updates timeline and manifest and notifies all listeners of the update.",
	"Method": "void refreshSourceInfo(Timeline timeline,Object manifest){\r\n    this.timeline = timeline;\r\n    this.manifest = manifest;\r\n    for (SourceInfoRefreshListener listener : sourceInfoListeners) {\r\n        listener.onSourceInfoRefreshed(this, timeline, manifest);\r\n    }\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.ext.flac.FlacDecoderJni.decodeMetadata",
	"Comment": "decodes and consumes the streaminfo section from the flac stream.",
	"Method": "FlacStreamInfo decodeMetadata(){\r\n    return flacDecodeMetadata(nativeDecoderContext);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.MediaPeriodQueue.updateForPlaybackModeChange",
	"Comment": "updates the queue for any playback mode change, and returns whether the change was fullyhandled. if not, it is necessary to seek to the current playback position.",
	"Method": "boolean updateForPlaybackModeChange(){\r\n    MediaPeriodHolder lastValidPeriodHolder = getFrontPeriod();\r\n    if (lastValidPeriodHolder == null) {\r\n        return true;\r\n    }\r\n    int currentPeriodIndex = timeline.getIndexOfPeriod(lastValidPeriodHolder.uid);\r\n    while (true) {\r\n        int nextPeriodIndex = timeline.getNextPeriodIndex(currentPeriodIndex, period, window, repeatMode, shuffleModeEnabled);\r\n        while (lastValidPeriodHolder.next != null && !lastValidPeriodHolder.info.isLastInTimelinePeriod) {\r\n            lastValidPeriodHolder = lastValidPeriodHolder.next;\r\n        }\r\n        if (nextPeriodIndex == C.INDEX_UNSET || lastValidPeriodHolder.next == null) {\r\n            break;\r\n        }\r\n        int nextPeriodHolderPeriodIndex = timeline.getIndexOfPeriod(lastValidPeriodHolder.next.uid);\r\n        if (nextPeriodHolderPeriodIndex != nextPeriodIndex) {\r\n            break;\r\n        }\r\n        lastValidPeriodHolder = lastValidPeriodHolder.next;\r\n        currentPeriodIndex = nextPeriodIndex;\r\n    }\r\n    boolean readingPeriodRemoved = removeAfter(lastValidPeriodHolder);\r\n    lastValidPeriodHolder.info = getUpdatedMediaPeriodInfo(lastValidPeriodHolder.info);\r\n    return !readingPeriodRemoved || !hasPlayingPeriod();\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.core.watcher.client.WatcherClient.watcherService",
	"Comment": "perform an watcher service request to either start, stop or restart the service.",
	"Method": "void watcherService(WatcherServiceRequest request,ActionListener<AcknowledgedResponse> listener,ActionFuture<AcknowledgedResponse> watcherService,WatcherServiceRequest request){\r\n    return client.execute(WatcherServiceAction.INSTANCE, request);\r\n}"
}, {
	"Path": "com.google.android.exoplayer2.source.SampleQueue.setUpstreamFormatChangeListener",
	"Comment": "sets a listener to be notified of changes to the upstream format.",
	"Method": "void setUpstreamFormatChangeListener(UpstreamFormatChangedListener listener){\r\n    upstreamFormatChangeListener = listener;\r\n}"
}, {
	"Path": "com.alibaba.fastjson.parser.SymbolTable.addSymbol",
	"Comment": "adds the specified symbol to the symbol table and returns a reference to the unique symbol. if the symbol alreadyexists, the previous symbol reference is returned instead, in order guarantee that symbol references remainunique.",
	"Method": "String addSymbol(char[] buffer,int offset,int len,String addSymbol,char[] buffer,int offset,int len,int hash,String addSymbol,String buffer,int offset,int len,int hash,String addSymbol,String buffer,int offset,int len,int hash,boolean replace){\r\n    final int bucket = hash & indexMask;\r\n    String symbol = symbols[bucket];\r\n    if (symbol != null) {\r\n        if (hash == symbol.hashCode() && len == symbol.length() && buffer.startsWith(symbol, offset)) {\r\n            return symbol;\r\n        }\r\n        String str = subString(buffer, offset, len);\r\n        if (replace) {\r\n            symbols[bucket] = str;\r\n        }\r\n        return str;\r\n    }\r\n    symbol = len == buffer.length() ? buffer : subString(buffer, offset, len);\r\n    symbol = symbol.intern();\r\n    symbols[bucket] = symbol;\r\n    return symbol;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.sql.type.EsField.getProperties",
	"Comment": "returns list of properties for the nested and object fields, list of subfield if the fieldwas indexed in a few different ways or null otherwise",
	"Method": "Map<String, EsField> getProperties(){\r\n    return properties;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.cli.CertificateGenerateTool.writeCAInfoIfGenerated",
	"Comment": "this method handles writing out the certificate authority cert and private key if the certificate authority was generated bythis invocation of the tool",
	"Method": "void writeCAInfoIfGenerated(ZipOutputStream outputStream,JcaPEMWriter pemWriter,CAInfo info){\r\n    if (info.generated) {\r\n        final String caDirName = \"ca/\";\r\n        ZipEntry zipEntry = new ZipEntry(caDirName);\r\n        assert zipEntry.isDirectory();\r\n        outputStream.putNextEntry(zipEntry);\r\n        outputStream.putNextEntry(new ZipEntry(caDirName + \"ca.crt\"));\r\n        pemWriter.writeObject(info.caCert);\r\n        pemWriter.flush();\r\n        outputStream.closeEntry();\r\n        outputStream.putNextEntry(new ZipEntry(caDirName + \"ca.key\"));\r\n        if (info.password != null && info.password.length > 0) {\r\n            try {\r\n                PEMEncryptor encryptor = new JcePEMEncryptorBuilder(\"DES-EDE3-CBC\").setProvider(BC_PROV).build(info.password);\r\n                pemWriter.writeObject(info.privateKey, encryptor);\r\n            } finally {\r\n                Arrays.fill(info.password, (char) 0);\r\n            }\r\n        } else {\r\n            pemWriter.writeObject(info.privateKey);\r\n        }\r\n        pemWriter.flush();\r\n        outputStream.closeEntry();\r\n    }\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.KerberosTicketValidator.encodeToString",
	"Comment": "encodes the specified byte array using base64 encoding scheme",
	"Method": "String encodeToString(byte[] outToken){\r\n    if (outToken != null && outToken.length > 0) {\r\n        return Base64.getEncoder().encodeToString(outToken);\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "org.elasticsearch.xpack.security.authc.kerberos.KerberosTicketValidator.privilegedLogoutNoThrow",
	"Comment": "privileged wrapper for closing logincontext, does not throw exceptions butlogs them as a debug message.",
	"Method": "void privilegedLogoutNoThrow(LoginContext loginContext){\r\n    if (loginContext != null) {\r\n        try {\r\n            AccessController.doPrivileged((PrivilegedExceptionAction<Void>) () -> {\r\n                loginContext.logout();\r\n                return null;\r\n            });\r\n        } catch (PrivilegedActionException e) {\r\n            LOGGER.debug(\"Could not close LoginContext\", e.getCause());\r\n        }\r\n    }\r\n}"
}]