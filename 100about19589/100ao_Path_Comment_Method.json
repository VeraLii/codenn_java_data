[{
	"Path": "com.facebook.presto.hive.metastore.thrift.ThriftHiveMetastore.dropExtraColumnStatisticsAfterAlterPartition",
	"Comment": "after altering a partition metastore preserves all column statistics for that partition.the old statistics are supposed to be replaced by storing the new partition statistics.in case when the new statistics are not present for some columns, or if the table schema has changedif is needed to explicitly remove the statistics from the metastore for that columns.",
	"Method": "void dropExtraColumnStatisticsAfterAlterPartition(String databaseName,String tableName,PartitionWithStatistics partitionWithStatistics){\r\n    List<String> dataColumns = partitionWithStatistics.getPartition().getColumns().stream().map(Column::getName).collect(toImmutableList());\r\n    Set<String> columnsWithMissingStatistics = new HashSet(dataColumns);\r\n    columnsWithMissingStatistics.removeAll(partitionWithStatistics.getStatistics().getColumnStatistics().keySet());\r\n    if (columnsWithMissingStatistics.isEmpty()) {\r\n        return;\r\n    }\r\n    String partitionName = partitionWithStatistics.getPartitionName();\r\n    List<ColumnStatisticsObj> statisticsToBeRemoved = getMetastorePartitionColumnStatistics(databaseName, tableName, ImmutableSet.of(partitionName), ImmutableList.copyOf(columnsWithMissingStatistics)).getOrDefault(partitionName, ImmutableList.of());\r\n    for (ColumnStatisticsObj statistics : statisticsToBeRemoved) {\r\n        deletePartitionColumnStatistics(databaseName, tableName, partitionName, statistics.getColName());\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.AccumuloClient.getRangesFromDomain",
	"Comment": "gets a collection of accumulo range objects from the given presto domain.this maps the column constraints of the given domain to an accumulo range scan.",
	"Method": "Collection<Range> getRangesFromDomain(Optional<Domain> domain,AccumuloRowSerializer serializer){\r\n    if (!domain.isPresent()) {\r\n        return ImmutableSet.of(new Range());\r\n    }\r\n    ImmutableSet.Builder<Range> rangeBuilder = ImmutableSet.builder();\r\n    for (com.facebook.presto.spi.predicate.Range range : domain.get().getValues().getRanges().getOrderedRanges()) {\r\n        rangeBuilder.add(getRangeFromPrestoRange(range, serializer));\r\n    }\r\n    return rangeBuilder.build();\r\n}"
}, {
	"Path": "com.facebook.presto.array.DoubleBigArray.ensureCapacity",
	"Comment": "ensures this big array is at least the specified length.if the array is smaller, segmentsare added until the array is larger then the specified length.",
	"Method": "void ensureCapacity(long length){\r\n    if (capacity > length) {\r\n        return;\r\n    }\r\n    grow(length);\r\n}"
}, {
	"Path": "com.facebook.presto.array.ShortBigArray.add",
	"Comment": "adds the specified value to the specified element of this big array.",
	"Method": "void add(long index,long value){\r\n    array[segment(index)][offset(index)] += value;\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.profiler.context.DefaultBaseTraceFactory.continueTraceObject",
	"Comment": "continue to trace the request that has been determined to be sampled on previous nodes",
	"Method": "Trace continueTraceObject(TraceId traceId){\r\n    final TraceRoot traceRoot = traceRootFactory.continueTraceRoot(traceId);\r\n    final Span span = spanFactory.newSpan(traceRoot);\r\n    final Storage storage = storageFactory.createStorage(traceRoot);\r\n    final CallStack<SpanEvent> callStack = callStackFactory.newCallStack();\r\n    final boolean samplingEnable = true;\r\n    final SpanRecorder spanRecorder = recorderFactory.newSpanRecorder(span, traceId.isRoot(), samplingEnable);\r\n    final WrappedSpanEventRecorder wrappedSpanEventRecorder = recorderFactory.newWrappedSpanEventRecorder(traceRoot);\r\n    final ActiveTraceHandle handle = registerActiveTrace(traceRoot);\r\n    final DefaultTrace trace = new DefaultTrace(span, callStack, storage, asyncContextFactory, samplingEnable, spanRecorder, wrappedSpanEventRecorder, handle);\r\n    return trace;\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.rpc.client.DefaultPinpointClientHandler.closeResources",
	"Comment": "calling this method on a closed pinpointclienthandler has no effect.",
	"Method": "void closeResources(){\r\n    logger.debug(\"{} closeResources() started.\", objectUniqName);\r\n    Channel channel = this.channel;\r\n    closeStreamChannelManager(channel);\r\n    this.handshaker.handshakeAbort();\r\n    this.requestManager.close();\r\n    this.channelTimer.stop();\r\n}"
}, {
	"Path": "com.facebook.presto.hive.HiveSplitSource.getBufferedInternalSplitCount",
	"Comment": "the upper bound of outstanding split count.it might be larger than the actual number when called concurrently with other methods.",
	"Method": "int getBufferedInternalSplitCount(){\r\n    return bufferedInternalSplitCount.get();\r\n}"
}, {
	"Path": "com.facebook.presto.connector.jmx.util.RebindSafeMBeanServer.registerMBean",
	"Comment": "delegates to the wrapped mbean server, but if a mbean is already registeredwith the specified name, the existing instance is returned.",
	"Method": "ObjectInstance registerMBean(Object object,ObjectName name){\r\n    while (true) {\r\n        try {\r\n            return mbeanServer.registerMBean(object, name);\r\n        } catch (InstanceAlreadyExistsException ignored) {\r\n        }\r\n        try {\r\n            ObjectInstance objectInstance = mbeanServer.getObjectInstance(name);\r\n            log.debug(\"%s already bound to %s\", name, objectInstance);\r\n            return objectInstance;\r\n        } catch (InstanceNotFoundException ignored) {\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.web.vo.LoadFactor.setDefaultHistogramSlotList",
	"Comment": "empty slots in the view is shown as 0 if the histogram slot is set.if not, value cannot be shown as the key is unknown.",
	"Method": "void setDefaultHistogramSlotList(HistogramSchema schema){\r\n    if (successCount > 0 || failedCount > 0) {\r\n        throw new IllegalStateException(\"Can't set slot list while containing the data.\");\r\n    }\r\n    timeseriesSlotIndex.clear();\r\n    timeseriesValueList.clear();\r\n    timeseriesSlotIndex.put((int) schema.getFastSlot().getSlotTime(), timeseriesSlotIndex.size());\r\n    timeseriesValueList.add(makeEmptyTimeseriesValueMap());\r\n    timeseriesSlotIndex.put((int) schema.getNormalSlot().getSlotTime(), timeseriesSlotIndex.size());\r\n    timeseriesValueList.add(makeEmptyTimeseriesValueMap());\r\n    timeseriesSlotIndex.put((int) schema.getSlowSlot().getSlotTime(), timeseriesSlotIndex.size());\r\n    timeseriesValueList.add(makeEmptyTimeseriesValueMap());\r\n    timeseriesSlotIndex.put(SLOT_VERY_SLOW, timeseriesSlotIndex.size());\r\n    timeseriesSlotIndex.put(SLOT_ERROR, timeseriesSlotIndex.size());\r\n    timeseriesValueList.add(makeEmptyTimeseriesValueMap());\r\n    timeseriesValueList.add(makeEmptyTimeseriesValueMap());\r\n}"
}, {
	"Path": "com.facebook.presto.array.IntBigArray.ensureCapacity",
	"Comment": "ensures this big array is at least the specified length.if the array is smaller, segmentsare added until the array is larger then the specified length.",
	"Method": "void ensureCapacity(long length){\r\n    if (capacity > length) {\r\n        return;\r\n    }\r\n    grow(length);\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.profiler.context.DefaultTraceFactory.currentTraceObject",
	"Comment": "return trace object after validating whether it can be sampled or not.",
	"Method": "Trace currentTraceObject(){\r\n    final Reference<Trace> reference = threadLocalBinder.get();\r\n    final Trace trace = reference.get();\r\n    if (trace == null) {\r\n        return null;\r\n    }\r\n    if (trace.canSampled()) {\r\n        return trace;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.web.vo.scatter.Dot.getSimpleExceptionCode",
	"Comment": "simple statecode used in the ui. may need to be fleshed out with state transitions in the future.",
	"Method": "int getSimpleExceptionCode(){\r\n    if (getExceptionCode() == Dot.EXCEPTION_NONE) {\r\n        return Dot.SUCCESS_STATE;\r\n    } else {\r\n        return Dot.FAILED_STATE;\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.memory.DefaultQueryContext.reserveSpill",
	"Comment": "todo move spill tracking to the new memory tracking framework",
	"Method": "ListenableFuture<?> reserveSpill(long bytes){\r\n    checkArgument(bytes >= 0, \"bytes is negative\");\r\n    if (spillUsed + bytes > maxSpill) {\r\n        throw exceededPerQueryLocalLimit(succinctBytes(maxSpill));\r\n    }\r\n    ListenableFuture<?> future = spillSpaceTracker.reserve(bytes);\r\n    spillUsed += bytes;\r\n    return future;\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.profiler.util.jdk.Striped64.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    try {\r\n        return sun.misc.Unsafe.getUnsafe();\r\n    } catch (SecurityException tryReflectionInstead) {\r\n    }\r\n    try {\r\n        return java.security.AccessController.doPrivileged(new java.security.PrivilegedExceptionAction<sun.misc.Unsafe>() {\r\n            public sun.misc.Unsafe run() throws Exception {\r\n                Class<sun.misc.Unsafe> k = sun.misc.Unsafe.class;\r\n                for (java.lang.reflect.Field f : k.getDeclaredFields()) {\r\n                    f.setAccessible(true);\r\n                    Object x = f.get(null);\r\n                    if (k.isInstance(x))\r\n                        return k.cast(x);\r\n                }\r\n                throw new NoSuchFieldError(\"the Unsafe\");\r\n            }\r\n        });\r\n    } catch (java.security.PrivilegedActionException e) {\r\n        throw new RuntimeException(\"Could not initialize intrinsics\", e.getCause());\r\n    }\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.profiler.util.jdk.Striped64.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    Class<sun.misc.Unsafe> k = sun.misc.Unsafe.class;\r\n    for (java.lang.reflect.Field f : k.getDeclaredFields()) {\r\n        f.setAccessible(true);\r\n        Object x = f.get(null);\r\n        if (k.isInstance(x))\r\n            return k.cast(x);\r\n    }\r\n    throw new NoSuchFieldError(\"the Unsafe\");\r\n}"
}, {
	"Path": "com.facebook.presto.client.FixJsonDataUtils.fixValue",
	"Comment": "force values coming from jackson to have the expected object type.",
	"Method": "Object fixValue(TypeSignature signature,Object value){\r\n    if (value == null) {\r\n        return null;\r\n    }\r\n    if (signature.getBase().equals(ARRAY)) {\r\n        List<Object> fixedValue = new ArrayList();\r\n        for (Object object : List.class.cast(value)) {\r\n            fixedValue.add(fixValue(signature.getTypeParametersAsTypeSignatures().get(0), object));\r\n        }\r\n        return fixedValue;\r\n    }\r\n    if (signature.getBase().equals(MAP)) {\r\n        TypeSignature keySignature = signature.getTypeParametersAsTypeSignatures().get(0);\r\n        TypeSignature valueSignature = signature.getTypeParametersAsTypeSignatures().get(1);\r\n        Map<Object, Object> fixedValue = new HashMap();\r\n        for (Map.Entry<?, ?> entry : (Set<Map.Entry<?, ?>>) Map.class.cast(value).entrySet()) {\r\n            fixedValue.put(fixValue(keySignature, entry.getKey()), fixValue(valueSignature, entry.getValue()));\r\n        }\r\n        return fixedValue;\r\n    }\r\n    if (signature.getBase().equals(ROW)) {\r\n        Map<String, Object> fixedValue = new LinkedHashMap();\r\n        List<Object> listValue = List.class.cast(value);\r\n        checkArgument(listValue.size() == signature.getParameters().size(), \"Mismatched data values and row type\");\r\n        for (int i = 0; i < listValue.size(); i++) {\r\n            TypeSignatureParameter parameter = signature.getParameters().get(i);\r\n            checkArgument(parameter.getKind() == ParameterKind.NAMED_TYPE, \"Unexpected parameter [%s] for row type\", parameter);\r\n            NamedTypeSignature namedTypeSignature = parameter.getNamedTypeSignature();\r\n            String key = namedTypeSignature.getName().orElse(\"field\" + i);\r\n            fixedValue.put(key, fixValue(namedTypeSignature.getTypeSignature(), listValue.get(i)));\r\n        }\r\n        return fixedValue;\r\n    }\r\n    switch(signature.getBase()) {\r\n        case BIGINT:\r\n            if (value instanceof String) {\r\n                return Long.parseLong((String) value);\r\n            }\r\n            return ((Number) value).longValue();\r\n        case INTEGER:\r\n            if (value instanceof String) {\r\n                return Integer.parseInt((String) value);\r\n            }\r\n            return ((Number) value).intValue();\r\n        case SMALLINT:\r\n            if (value instanceof String) {\r\n                return Short.parseShort((String) value);\r\n            }\r\n            return ((Number) value).shortValue();\r\n        case TINYINT:\r\n            if (value instanceof String) {\r\n                return Byte.parseByte((String) value);\r\n            }\r\n            return ((Number) value).byteValue();\r\n        case DOUBLE:\r\n            if (value instanceof String) {\r\n                return Double.parseDouble((String) value);\r\n            }\r\n            return ((Number) value).doubleValue();\r\n        case REAL:\r\n            if (value instanceof String) {\r\n                return Float.parseFloat((String) value);\r\n            }\r\n            return ((Number) value).floatValue();\r\n        case BOOLEAN:\r\n            if (value instanceof String) {\r\n                return Boolean.parseBoolean((String) value);\r\n            }\r\n            return Boolean.class.cast(value);\r\n        case VARCHAR:\r\n        case JSON:\r\n        case TIME:\r\n        case TIME_WITH_TIME_ZONE:\r\n        case TIMESTAMP:\r\n        case TIMESTAMP_WITH_TIME_ZONE:\r\n        case DATE:\r\n        case INTERVAL_YEAR_TO_MONTH:\r\n        case INTERVAL_DAY_TO_SECOND:\r\n        case IPADDRESS:\r\n        case DECIMAL:\r\n        case CHAR:\r\n        case GEOMETRY:\r\n            return String.class.cast(value);\r\n        case BING_TILE:\r\n            return value;\r\n        default:\r\n            if (value instanceof String) {\r\n                return Base64.getDecoder().decode((String) value);\r\n            }\r\n            return value;\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.execution.QueryStateMachine.begin",
	"Comment": "created querystatemachines must be transitioned to terminal states to clean up resources.",
	"Method": "QueryStateMachine begin(String query,Session session,URI self,ResourceGroupId resourceGroup,boolean transactionControl,TransactionManager transactionManager,AccessControl accessControl,Executor executor,Metadata metadata,WarningCollector warningCollector){\r\n    return beginWithTicker(query, session, self, resourceGroup, transactionControl, transactionManager, accessControl, executor, Ticker.systemTicker(), metadata, warningCollector);\r\n}"
}, {
	"Path": "com.facebook.presto.execution.StateMachine.get",
	"Comment": "state changes are atomic and state is volatile, so a direct read is safe here",
	"Method": "T get(){\r\n    return state;\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.rpc.client.DefaultPinpointClient.sendPing",
	"Comment": "write ping packet on tcp channelpinpointsocketexception throws when writing fails.",
	"Method": "void sendPing(){\r\n    PinpointClientHandler pinpointClientHandler = this.pinpointClientHandler;\r\n    if (pinpointClientHandler == null) {\r\n        return;\r\n    }\r\n    pinpointClientHandler.sendPing();\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.index.ColumnCardinalityCache.getColumnCardinality",
	"Comment": "gets the column cardinality for all of the given range values. may reach out to themetrics table in accumulo to retrieve new cache elements.",
	"Method": "long getColumnCardinality(String schema,String table,Authorizations auths,String family,String qualifier,Collection<Range> colValues){\r\n    LOG.debug(\"Getting cardinality for %s:%s\", family, qualifier);\r\n    Collection<CacheKey> exactRanges = colValues.stream().filter(ColumnCardinalityCache::isExact).map(range -> new CacheKey(schema, table, family, qualifier, range, auths)).collect(Collectors.toList());\r\n    LOG.debug(\"Column values contain %s exact ranges of %s\", exactRanges.size(), colValues.size());\r\n    long sum = cache.getAll(exactRanges).values().stream().mapToLong(Long::longValue).sum();\r\n    if (exactRanges.size() != colValues.size()) {\r\n        for (Range range : colValues) {\r\n            if (!isExact(range)) {\r\n                sum += cache.get(new CacheKey(schema, table, family, qualifier, range, auths));\r\n            }\r\n        }\r\n    }\r\n    return sum;\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.Types.getValueType",
	"Comment": "gets the value type of the given map type. does not validate that the given type is a map.",
	"Method": "Type getValueType(Type type){\r\n    return type.getTypeParameters().get(1);\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.thrift.io.UnsafeByteArrayOutputStream.reset",
	"Comment": "resets the count field of this byte array outputstream to zero, so that all currently accumulated output in theoutput stream is discarded. the output stream can be used again,reusing the already allocated buffer space.",
	"Method": "void reset(){\r\n    count = 0;\r\n}"
}, {
	"Path": "com.facebook.presto.hive.HiveColumnHandle.bucketColumnHandle",
	"Comment": "the column indicating the bucket id.when table bucketing differs from partition bucketing, this column indicateswhat bucket the row will fall in under the table bucketing scheme.",
	"Method": "HiveColumnHandle bucketColumnHandle(){\r\n    return new HiveColumnHandle(BUCKET_COLUMN_NAME, BUCKET_HIVE_TYPE, BUCKET_TYPE_SIGNATURE, BUCKET_COLUMN_INDEX, SYNTHESIZED, Optional.empty());\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.index.Indexer.getIndexColumnFamily",
	"Comment": "gets the column family of the index table based on the given column family and qualifier.",
	"Method": "ByteBuffer getIndexColumnFamily(byte[] columnFamily,byte[] columnQualifier){\r\n    return wrap(ArrayUtils.addAll(ArrayUtils.add(columnFamily, UNDERSCORE), columnQualifier));\r\n}"
}, {
	"Path": "com.facebook.presto.hive.AbstractTestHiveClient.getFilePrefix",
	"Comment": "these are protected so extensions to the hive connector can replace the handle classes",
	"Method": "String getFilePrefix(ConnectorOutputTableHandle outputTableHandle,String getFilePrefix,ConnectorInsertTableHandle insertTableHandle){\r\n    return ((HiveWritableTableHandle) insertTableHandle).getFilePrefix();\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.Types.getElementType",
	"Comment": "gets the element type of the given array type. does not validate that the given type is an array.",
	"Method": "Type getElementType(Type type){\r\n    return type.getTypeParameters().get(0);\r\n}"
}, {
	"Path": "com.facebook.presto.operator.aggregation.InternalAggregationFunction.isDecomposable",
	"Comment": "indicates that the aggregation can be decomposed, and run as partial aggregations followed by a final aggregation to combine the intermediate results",
	"Method": "boolean isDecomposable(){\r\n    return decomposable;\r\n}"
}, {
	"Path": "com.facebook.presto.operator.aggregation.builder.InMemoryHashAggregationBuilder.getGroupIdsSortingSize",
	"Comment": "building hash sorted results requires memory for sorting group ids.this method returns size of that memory requirement.",
	"Method": "long getGroupIdsSortingSize(){\r\n    return getGroupCount() * Integer.BYTES;\r\n}"
}, {
	"Path": "com.facebook.presto.execution.SqlStageExecution.getAllTasks",
	"Comment": "this is used for query info building which should be independent of scheduling work",
	"Method": "List<RemoteTask> getAllTasks(){\r\n    return tasks.values().stream().flatMap(Set::stream).collect(toImmutableList());\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.common.server.cluster.zookeeper.ConnectionTest.curatorExpiredTest",
	"Comment": "even if the instance of the zookeeperserver changes, the curator will automatically reconnect.",
	"Method": "void curatorExpiredTest(){\r\n    CuratorZookeeperClient curatorZookeeperClient = new CuratorZookeeperClient(ts.getConnectString(), 5000, new LoggingZookeeperEventWatcher());\r\n    try {\r\n        curatorZookeeperClient.connect();\r\n        boolean pass = awaitState(curatorZookeeperClient, true);\r\n        Assert.assertTrue(pass);\r\n        ts.restart();\r\n        pass = awaitState(curatorZookeeperClient, true);\r\n        Assert.assertTrue(pass);\r\n        ts.stop();\r\n        ts.close();\r\n        pass = awaitState(curatorZookeeperClient, false);\r\n        Assert.assertTrue(pass);\r\n        ts = createTestingServer();\r\n        pass = awaitState(curatorZookeeperClient, true);\r\n        Assert.assertTrue(pass);\r\n    } finally {\r\n        if (curatorZookeeperClient != null) {\r\n            curatorZookeeperClient.close();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.thrift.io.UnsafeByteArrayOutputStream.toByteArray",
	"Comment": "creates a newly allocated byte array. its size is the currentsize of this output stream and the valid contents of the bufferhave been copied into it.",
	"Method": "byte toByteArray(){\r\n    return buf;\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.common.server.cluster.zookeeper.ConnectionTest.zookeeperReconnectTest",
	"Comment": "if the instance of zookeeperserver is changed, zookeeper will not automatically reconnect.",
	"Method": "void zookeeperReconnectTest(){\r\n    ZooKeeper zookeeper = new ZooKeeper(ts.getConnectString(), 5000, null);\r\n    try {\r\n        boolean pass = awaitState(zookeeper, ZooKeeper.States.CONNECTED);\r\n        Assert.assertTrue(pass);\r\n        ts.restart();\r\n        pass = awaitState(zookeeper, ZooKeeper.States.CONNECTED);\r\n        Assert.assertTrue(pass);\r\n    } finally {\r\n        if (zookeeper != null) {\r\n            zookeeper.close();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.hive.TableParameterCodec.encode",
	"Comment": "encode additional presto table properties into hive table parameters.",
	"Method": "Map<String, String> encode(Map<String, Object> tableProperties){\r\n    return ImmutableMap.of();\r\n}"
}, {
	"Path": "com.facebook.presto.hive.util.AsyncQueue.isFinished",
	"Comment": "returns true if all future attempts to retrieve elements from this queueare guaranteed to return empty.",
	"Method": "boolean isFinished(){\r\n    return finishing && borrowerCount == 0 && elements.size() == 0;\r\n}"
}, {
	"Path": "com.facebook.presto.metadata.Signature.withVariadicBound",
	"Comment": "similar to t extends myclass, if java supported varargs wildcards",
	"Method": "TypeVariableConstraint withVariadicBound(String name,String variadicBound){\r\n    return new TypeVariableConstraint(name, false, false, variadicBound);\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.test.classloader.TransformClassLoader.findClass",
	"Comment": "finds the specified class using classpath.if the source throws an exception, this returns null.this method can be overridden by a subclass ofloader.note that the overridden method must not throwan exception when it just fails to find a class file.",
	"Method": "Class<?> findClass(String name){\r\n    byte[] classfile;\r\n    try {\r\n        if (translator != null) {\r\n            try {\r\n                classfile = translator.transform(name);\r\n            } catch (ClassNotFoundException e) {\r\n                return null;\r\n            }\r\n        } else {\r\n            String jarname = \"/\" + JavaAssistUtils.javaClassNameToJvmResourceName(name);\r\n            InputStream in = this.getClass().getClassLoader().getResourceAsStream(jarname);\r\n            if (in == null) {\r\n                return null;\r\n            }\r\n            classfile = IOUtils.toByteArray(in);\r\n        }\r\n    } catch (Exception e) {\r\n        throw new ClassNotFoundException(\"caught an exception while obtaining a class file for \" + name, e);\r\n    }\r\n    final int i = name.lastIndexOf('.');\r\n    if (i != -1) {\r\n        String pname = name.substring(0, i);\r\n        if (getPackage(pname) == null)\r\n            try {\r\n                definePackage(pname, null, null, null, null, null, null, null);\r\n            } catch (IllegalArgumentException e) {\r\n            }\r\n    }\r\n    if (domain == null) {\r\n        if (logger.isLoggable(Level.FINE)) {\r\n            this.logger.fine(\"defineClass:\" + name);\r\n        }\r\n        return defineClass(name, classfile, 0, classfile.length);\r\n    } else {\r\n        if (logger.isLoggable(Level.FINE)) {\r\n            this.logger.fine(\"defineClass:\" + name);\r\n        }\r\n        return defineClass(name, classfile, 0, classfile.length, domain);\r\n    }\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.plugin.dubbo.DubboPlugin.addApplicationTypeDetector",
	"Comment": "pinpoint profiler agent uses this detector to find out the service type of current application.",
	"Method": "void addApplicationTypeDetector(ProfilerPluginSetupContext context,DubboConfiguration config){\r\n    context.addApplicationTypeDetector(new DubboProviderDetector(config.getDubboBootstrapMains()));\r\n}"
}, {
	"Path": "com.facebook.presto.operator.aggregation.histogram.ValueStore.addAndGetPosition",
	"Comment": "this will add an item if not already in the system. it returns a pointer that is unique for multiple instances of the value. if item present,returns the pointer into the system",
	"Method": "int addAndGetPosition(Type type,Block block,int position,long valueHash){\r\n    if (values.getPositionCount() >= maxFill) {\r\n        rehash();\r\n    }\r\n    int bucketId = getBucketId(valueHash, mask);\r\n    int valuePointer;\r\n    int probeCount = 1;\r\n    int originalBucketId = bucketId;\r\n    while (true) {\r\n        checkState(probeCount < bucketCount, \"could not find match for value nor empty slot in %s buckets\", bucketCount);\r\n        valuePointer = buckets.get(bucketId);\r\n        if (valuePointer == EMPTY_BUCKET) {\r\n            valuePointer = values.getPositionCount();\r\n            valueHashes.set(valuePointer, (int) valueHash);\r\n            type.appendTo(block, position, values);\r\n            buckets.set(bucketId, valuePointer);\r\n            return valuePointer;\r\n        } else if (type.equalTo(block, position, values, valuePointer)) {\r\n            return valuePointer;\r\n        } else {\r\n            int probe = nextProbe(probeCount);\r\n            bucketId = nextBucketId(originalBucketId, mask, probe);\r\n            probeCount++;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.hive.RebindSafeMBeanServer.registerMBean",
	"Comment": "delegates to the wrapped mbean server, but if a mbean is already registeredwith the specified name, the existing instance is returned.",
	"Method": "ObjectInstance registerMBean(Object object,ObjectName name){\r\n    while (true) {\r\n        try {\r\n            return mbeanServer.registerMBean(object, name);\r\n        } catch (InstanceAlreadyExistsException ignored) {\r\n        }\r\n        try {\r\n            ObjectInstance objectInstance = mbeanServer.getObjectInstance(name);\r\n            log.debug(\"%s already bound to %s\", name, objectInstance);\r\n            return objectInstance;\r\n        } catch (InstanceNotFoundException ignored) {\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.array.LongBigArray.add",
	"Comment": "adds the specified value to the specified element of this big array.",
	"Method": "void add(long index,long value){\r\n    array[segment(index)][offset(index)] += value;\r\n}"
}, {
	"Path": "com.facebook.presto.hive.parquet.write.TestDataWritableWriter.writePrimitive",
	"Comment": "it writes the primitive value to the parquet recordconsumer.",
	"Method": "void writePrimitive(Object value,PrimitiveObjectInspector inspector){\r\n    if (value == null) {\r\n        return;\r\n    }\r\n    switch(inspector.getPrimitiveCategory()) {\r\n        case VOID:\r\n            return;\r\n        case DOUBLE:\r\n            recordConsumer.addDouble(((DoubleObjectInspector) inspector).get(value));\r\n            break;\r\n        case BOOLEAN:\r\n            recordConsumer.addBoolean(((BooleanObjectInspector) inspector).get(value));\r\n            break;\r\n        case FLOAT:\r\n            recordConsumer.addFloat(((FloatObjectInspector) inspector).get(value));\r\n            break;\r\n        case BYTE:\r\n            recordConsumer.addInteger(((ByteObjectInspector) inspector).get(value));\r\n            break;\r\n        case INT:\r\n            recordConsumer.addInteger(((IntObjectInspector) inspector).get(value));\r\n            break;\r\n        case LONG:\r\n            recordConsumer.addLong(((LongObjectInspector) inspector).get(value));\r\n            break;\r\n        case SHORT:\r\n            recordConsumer.addInteger(((ShortObjectInspector) inspector).get(value));\r\n            break;\r\n        case STRING:\r\n            String v = ((StringObjectInspector) inspector).getPrimitiveJavaObject(value);\r\n            recordConsumer.addBinary(Binary.fromString(v));\r\n            break;\r\n        case CHAR:\r\n            String vChar = ((HiveCharObjectInspector) inspector).getPrimitiveJavaObject(value).getStrippedValue();\r\n            recordConsumer.addBinary(Binary.fromString(vChar));\r\n            break;\r\n        case VARCHAR:\r\n            String vVarchar = ((HiveVarcharObjectInspector) inspector).getPrimitiveJavaObject(value).getValue();\r\n            recordConsumer.addBinary(Binary.fromString(vVarchar));\r\n            break;\r\n        case BINARY:\r\n            byte[] vBinary = ((BinaryObjectInspector) inspector).getPrimitiveJavaObject(value);\r\n            recordConsumer.addBinary(Binary.fromByteArray(vBinary));\r\n            break;\r\n        case TIMESTAMP:\r\n            Timestamp ts = ((TimestampObjectInspector) inspector).getPrimitiveJavaObject(value);\r\n            recordConsumer.addBinary(NanoTimeUtils.getNanoTime(ts, false).toBinary());\r\n            break;\r\n        case DECIMAL:\r\n            HiveDecimal vDecimal = ((HiveDecimal) inspector.getPrimitiveJavaObject(value));\r\n            DecimalTypeInfo decTypeInfo = (DecimalTypeInfo) inspector.getTypeInfo();\r\n            recordConsumer.addBinary(decimalToBinary(vDecimal, decTypeInfo));\r\n            break;\r\n        case DATE:\r\n            Date vDate = ((DateObjectInspector) inspector).getPrimitiveJavaObject(value);\r\n            recordConsumer.addInteger(DateWritable.dateToDays(vDate));\r\n            break;\r\n        default:\r\n            throw new IllegalArgumentException(\"Unsupported primitive data type: \" + inspector.getPrimitiveCategory());\r\n    }\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.web.view.HistogramSerializerTest.internalJson",
	"Comment": "moved this testcase for testing the old version histogram with manually created json code",
	"Method": "String internalJson(Histogram histogram){\r\n    HistogramSchema histogramSchema = histogram.getHistogramSchema();\r\n    final StringBuilder sb = new StringBuilder(128);\r\n    sb.append(\"{ \");\r\n    appendSlotTimeAndCount(sb, histogramSchema.getFastSlot().getSlotName(), histogram.getFastCount());\r\n    sb.append(\", \");\r\n    appendSlotTimeAndCount(sb, histogramSchema.getNormalSlot().getSlotName(), histogram.getNormalCount());\r\n    sb.append(\", \");\r\n    appendSlotTimeAndCount(sb, histogramSchema.getSlowSlot().getSlotName(), histogram.getSlowCount());\r\n    sb.append(\", \");\r\n    appendSlotTimeAndCount(sb, histogramSchema.getVerySlowSlot().getSlotName(), histogram.getVerySlowCount());\r\n    sb.append(\", \");\r\n    appendSlotTimeAndCount(sb, histogramSchema.getErrorSlot().getSlotName(), histogram.getTotalErrorCount());\r\n    sb.append(\" }\");\r\n    return sb.toString();\r\n}"
}, {
	"Path": "com.facebook.presto.array.IntBigArrays.swap",
	"Comment": "swaps the element of the given big array of specified indices.",
	"Method": "void swap(int[][] array,long first,long second){\r\n    final int t = array[segment(first)][displacement(first)];\r\n    array[segment(first)][displacement(first)] = array[segment(second)][displacement(second)];\r\n    array[segment(second)][displacement(second)] = t;\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.rpc.util.ClassUtils.wrapperToPrimitive",
	"Comment": "converts the specified array of primitive class objects to an array ofits corresponding wrapper class objects.",
	"Method": "Class wrapperToPrimitive(Class cls){\r\n    return wrapperPrimitiveMap.get(cls);\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.model.Row.getFields",
	"Comment": "gets a list of all internal fields. any changes to this list will affect this row.",
	"Method": "List<Field> getFields(){\r\n    return fields;\r\n}"
}, {
	"Path": "com.facebook.presto.array.ByteBigArray.ensureCapacity",
	"Comment": "ensures this big array is at least the specified length.if the array is smaller, segmentsare added until the array is larger then the specified length.",
	"Method": "void ensureCapacity(long length){\r\n    if (capacity > length) {\r\n        return;\r\n    }\r\n    grow(length);\r\n}"
}, {
	"Path": "com.facebook.presto.execution.buffer.ClientBuffer.loadPagesIfNecessary",
	"Comment": "if there no data, attempt to load some from the pages supplier.",
	"Method": "void loadPagesIfNecessary(PagesSupplier pagesSupplier,boolean loadPagesIfNecessary,PagesSupplier pagesSupplier,DataSize maxSize){\r\n    checkState(!Thread.holdsLock(this), \"Can not load pages while holding a lock on this\");\r\n    boolean dataAddedOrNoMorePages;\r\n    List<SerializedPageReference> pageReferences;\r\n    synchronized (this) {\r\n        if (noMorePages) {\r\n            return false;\r\n        }\r\n        if (!pages.isEmpty()) {\r\n            return false;\r\n        }\r\n        pageReferences = pagesSupplier.getPages(maxSize);\r\n        addPages(pageReferences);\r\n        if (!pagesSupplier.mayHaveMorePages()) {\r\n            noMorePages = true;\r\n        }\r\n        dataAddedOrNoMorePages = !pageReferences.isEmpty() || noMorePages;\r\n    }\r\n    pageReferences.forEach(SerializedPageReference::dereferencePage);\r\n    return dataAddedOrNoMorePages;\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.profiler.util.jdk.LongAdder.reset",
	"Comment": "resets variables maintaining the sum to zero.this method maybe a useful alternative to creating a new adder, but is onlyeffective if there are no concurrent updates.because thismethod is intrinsically racy, it should only be used when it isknown that no threads are concurrently updating.",
	"Method": "void reset(){\r\n    internalReset(0L);\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.serializers.AccumuloRowSerializer.getArrayFromBlock",
	"Comment": "given the array element type and presto block, decodes the block into a list of values.",
	"Method": "List<Object> getArrayFromBlock(Type elementType,Block block){\r\n    ImmutableList.Builder<Object> arrayBuilder = ImmutableList.builder();\r\n    for (int i = 0; i < block.getPositionCount(); ++i) {\r\n        arrayBuilder.add(readObject(elementType, block, i));\r\n    }\r\n    return arrayBuilder.build();\r\n}"
}, {
	"Path": "com.facebook.presto.geospatial.serde.TestGeometrySerialization.ensureEnvelopeLoaded",
	"Comment": "there is a weird bug in geometry comparison. if a geometry envelope is not loaded it may returnfalse for two empty line strings or multiline strings",
	"Method": "void ensureEnvelopeLoaded(OGCGeometry geometry){\r\n    geometry.envelope();\r\n}"
}, {
	"Path": "com.facebook.presto.execution.executor.MultilevelSplitQueue.pollSplit",
	"Comment": "presto attempts to give each level a target amount of scheduled time, which is configurableusing leveltimemultiplier.this function selects the level that has the the lowest ratio of actual to the target timewith the objective of minimizing deviation from the target scheduled time. from this level,we pick the split with the lowest priority.",
	"Method": "PrioritizedSplitRunner pollSplit(){\r\n    long targetScheduledTime = getLevel0TargetTime();\r\n    double worstRatio = 1;\r\n    int selectedLevel = -1;\r\n    for (int level = 0; level < LEVEL_THRESHOLD_SECONDS.length; level++) {\r\n        if (!levelWaitingSplits.get(level).isEmpty()) {\r\n            long levelTime = levelScheduledTime[level].get();\r\n            double ratio = levelTime == 0 ? 0 : targetScheduledTime / (1.0 * levelTime);\r\n            if (selectedLevel == -1 || ratio > worstRatio) {\r\n                worstRatio = ratio;\r\n                selectedLevel = level;\r\n            }\r\n        }\r\n        targetScheduledTime /= levelTimeMultiplier;\r\n    }\r\n    if (selectedLevel == -1) {\r\n        return null;\r\n    }\r\n    PrioritizedSplitRunner result = levelWaitingSplits.get(selectedLevel).poll();\r\n    checkState(result != null, \"pollSplit cannot return null\");\r\n    return result;\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.AccumuloQueryRunner.createMiniAccumuloCluster",
	"Comment": "creates and starts an instance of miniaccumulocluster, returning the new instance.",
	"Method": "MiniAccumuloCluster createMiniAccumuloCluster(){\r\n    File macDir = Files.createTempDirectory(\"mac-\").toFile();\r\n    LOG.info(\"MAC is enabled, starting MiniAccumuloCluster at %s\", macDir);\r\n    MiniAccumuloCluster accumulo = new MiniAccumuloCluster(macDir, MAC_PASSWORD);\r\n    accumulo.getConfig().setDefaultMemory(512, MEGABYTE);\r\n    setConfigClassPath(accumulo.getConfig());\r\n    accumulo.start();\r\n    Runtime.getRuntime().addShutdownHook(new Thread(() -> {\r\n        try {\r\n            LOG.info(\"Shutting down MAC\");\r\n            accumulo.stop();\r\n        } catch (IOException | InterruptedException e) {\r\n            Thread.currentThread().interrupt();\r\n            throw new PrestoException(MINI_ACCUMULO, \"Failed to shut down MAC instance\", e);\r\n        }\r\n        try {\r\n            LOG.info(\"Cleaning up MAC directory\");\r\n            FileUtils.forceDelete(macDir);\r\n        } catch (IOException e) {\r\n            throw new PrestoException(MINI_ACCUMULO, \"Failed to clean up MAC directory\", e);\r\n        }\r\n    }));\r\n    return accumulo;\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.Types.getKeyType",
	"Comment": "gets the key type of the given map type. does not validate that the given type is a map.",
	"Method": "Type getKeyType(Type type){\r\n    return type.getTypeParameters().get(0);\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.AccumuloQueryRunner.getAccumuloConnector",
	"Comment": "gets the accumuloconnector singleton, starting the miniaccumulocluster on initialization.this singleton instance is required so all test cases access the same miniaccumulocluster.",
	"Method": "Connector getAccumuloConnector(){\r\n    if (connector != null) {\r\n        return connector;\r\n    }\r\n    try {\r\n        MiniAccumuloCluster accumulo = createMiniAccumuloCluster();\r\n        Instance instance = new ZooKeeperInstance(accumulo.getInstanceName(), accumulo.getZooKeepers());\r\n        connector = instance.getConnector(MAC_USER, new PasswordToken(MAC_PASSWORD));\r\n        LOG.info(\"Connection to MAC instance %s at %s established, user %s password %s\", accumulo.getInstanceName(), accumulo.getZooKeepers(), MAC_USER, MAC_PASSWORD);\r\n        return connector;\r\n    } catch (AccumuloException | AccumuloSecurityException | InterruptedException | IOException e) {\r\n        throw new PrestoException(UNEXPECTED_ACCUMULO_ERROR, \"Failed to get connector to Accumulo\", e);\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.hive.parquet.write.TestDataWritableWriter.writeValue",
	"Comment": "it writes the field value to the parquet recordconsumer. it detects the field type, and callsthe correct write function.",
	"Method": "void writeValue(Object value,ObjectInspector inspector,Type type){\r\n    if (type.isPrimitive()) {\r\n        checkInspectorCategory(inspector, ObjectInspector.Category.PRIMITIVE);\r\n        writePrimitive(value, (PrimitiveObjectInspector) inspector);\r\n    } else {\r\n        GroupType groupType = type.asGroupType();\r\n        OriginalType originalType = type.getOriginalType();\r\n        if (originalType != null && originalType.equals(OriginalType.LIST)) {\r\n            checkInspectorCategory(inspector, ObjectInspector.Category.LIST);\r\n            if (singleLevelArray) {\r\n                writeSingleLevelArray(value, (ListObjectInspector) inspector, groupType);\r\n            } else {\r\n                writeArray(value, (ListObjectInspector) inspector, groupType);\r\n            }\r\n        } else if (originalType != null && (originalType.equals(OriginalType.MAP) || originalType.equals(OriginalType.MAP_KEY_VALUE))) {\r\n            checkInspectorCategory(inspector, ObjectInspector.Category.MAP);\r\n            writeMap(value, (MapObjectInspector) inspector, groupType);\r\n        } else {\r\n            checkInspectorCategory(inspector, ObjectInspector.Category.STRUCT);\r\n            writeGroup(value, (StructObjectInspector) inspector, groupType);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.model.Row.valueFromString",
	"Comment": "converts the given string into a java object based on the given presto type",
	"Method": "Object valueFromString(String str,Type type){\r\n    if (str == null || str.isEmpty()) {\r\n        return null;\r\n    } else if (Types.isArrayType(type)) {\r\n        Type elementType = Types.getElementType(type);\r\n        ImmutableList.Builder<Object> listBuilder = ImmutableList.builder();\r\n        for (String element : Splitter.on(',').split(str)) {\r\n            listBuilder.add(valueFromString(element, elementType));\r\n        }\r\n        return AccumuloRowSerializer.getBlockFromArray(elementType, listBuilder.build());\r\n    } else if (Types.isMapType(type)) {\r\n        Type keyType = Types.getKeyType(type);\r\n        Type valueType = Types.getValueType(type);\r\n        ImmutableMap.Builder<Object, Object> mapBuilder = ImmutableMap.builder();\r\n        for (String element : Splitter.on(',').split(str)) {\r\n            ImmutableList.Builder<String> builder = ImmutableList.builder();\r\n            List<String> keyValue = builder.addAll(Splitter.on(\"->\").split(element)).build();\r\n            checkArgument(keyValue.size() == 2, format(\"Map element %s has %d entries, not 2\", element, keyValue.size()));\r\n            mapBuilder.put(valueFromString(keyValue.get(0), keyType), valueFromString(keyValue.get(1), valueType));\r\n        }\r\n        return AccumuloRowSerializer.getBlockFromMap(type, mapBuilder.build());\r\n    } else if (type.equals(BIGINT)) {\r\n        return Long.parseLong(str);\r\n    } else if (type.equals(BOOLEAN)) {\r\n        return Boolean.parseBoolean(str);\r\n    } else if (type.equals(DATE)) {\r\n        return new Date(DATE_PARSER.parseDateTime(str).getMillis());\r\n    } else if (type.equals(DOUBLE)) {\r\n        return Double.parseDouble(str);\r\n    } else if (type.equals(INTEGER)) {\r\n        return Integer.parseInt(str);\r\n    } else if (type.equals(REAL)) {\r\n        return Float.parseFloat(str);\r\n    } else if (type.equals(SMALLINT)) {\r\n        return Short.parseShort(str);\r\n    } else if (type.equals(TIME)) {\r\n        return new Time(TIME_PARSER.parseDateTime(str).getMillis());\r\n    } else if (type.equals(TIMESTAMP)) {\r\n        return new Timestamp(TIMESTAMP_PARSER.parseDateTime(str).getMillis());\r\n    } else if (type.equals(TINYINT)) {\r\n        return Byte.valueOf(str);\r\n    } else if (type.equals(VARBINARY)) {\r\n        return str.getBytes(UTF_8);\r\n    } else if (type instanceof VarcharType) {\r\n        return str;\r\n    } else {\r\n        throw new PrestoException(NOT_SUPPORTED, \"Unsupported type \" + type);\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.array.BlockBigArray.ensureCapacity",
	"Comment": "ensures this big array is at least the specified length.if the array is smaller, segmentsare added until the array is larger then the specified length.",
	"Method": "void ensureCapacity(long length){\r\n    array.ensureCapacity(length);\r\n}"
}, {
	"Path": "com.facebook.presto.execution.resourceGroups.InternalResourceGroup.internalRefreshStats",
	"Comment": "memory usage stats are expensive to maintain, so this method must be called periodically to update them",
	"Method": "void internalRefreshStats(){\r\n    checkState(Thread.holdsLock(root), \"Must hold lock to refresh stats\");\r\n    synchronized (root) {\r\n        if (subGroups.isEmpty()) {\r\n            cachedMemoryUsageBytes = 0;\r\n            for (ManagedQueryExecution query : runningQueries) {\r\n                cachedMemoryUsageBytes += query.getUserMemoryReservation().toBytes();\r\n            }\r\n        } else {\r\n            for (Iterator<InternalResourceGroup> iterator = dirtySubGroups.iterator(); iterator.hasNext(); ) {\r\n                InternalResourceGroup subGroup = iterator.next();\r\n                long oldMemoryUsageBytes = subGroup.cachedMemoryUsageBytes;\r\n                cachedMemoryUsageBytes -= oldMemoryUsageBytes;\r\n                subGroup.internalRefreshStats();\r\n                cachedMemoryUsageBytes += subGroup.cachedMemoryUsageBytes;\r\n                if (!subGroup.isDirty()) {\r\n                    iterator.remove();\r\n                }\r\n                if (oldMemoryUsageBytes != subGroup.cachedMemoryUsageBytes) {\r\n                    subGroup.updateEligibility();\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.hive.util.SerDeUtils.serializeObject",
	"Comment": "that contain null map keys.for production, null map keys are not allowed.",
	"Method": "Block serializeObject(Type type,BlockBuilder builder,Object object,ObjectInspector inspector,Block serializeObject,Type type,BlockBuilder builder,Object object,ObjectInspector inspector,boolean filterNullMapKeys){\r\n    switch(inspector.getCategory()) {\r\n        case PRIMITIVE:\r\n            serializePrimitive(type, builder, object, (PrimitiveObjectInspector) inspector);\r\n            return null;\r\n        case LIST:\r\n            return serializeList(type, builder, object, (ListObjectInspector) inspector);\r\n        case MAP:\r\n            return serializeMap(type, builder, object, (MapObjectInspector) inspector, filterNullMapKeys);\r\n        case STRUCT:\r\n            return serializeStruct(type, builder, object, (StructObjectInspector) inspector);\r\n    }\r\n    throw new RuntimeException(\"Unknown object inspector category: \" + inspector.getCategory());\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.thrift.io.HeaderTBaseSerializer.serialize",
	"Comment": "serialize the thrift object into a byte array. the process is simple,just clear the byte array output, write the object into it, and grab theraw bytes.",
	"Method": "byte[] serialize(TBase<?, ?> base,byte[] serialize,TBase<?, ?> base,HeaderEntity headerEntity){\r\n    baos.reset();\r\n    writeHeader(base, headerEntity);\r\n    base.write(protocol);\r\n    return baos.toByteArray();\r\n}"
}, {
	"Path": "org.apache.log4j.JulAppender.append",
	"Comment": "append a log event at the appropriate jul level, depending on the log4j level.",
	"Method": "void append(LoggingEvent loggingEvent){\r\n    java.util.logging.Logger logger = java.util.logging.Logger.getLogger(loggingEvent.getLoggerName());\r\n    if (logger == null) {\r\n        LogLog.warn(format(\"Cannot obtain JUL %s. Verify that this appender is used while an appropriate LogManager is active.\", loggingEvent.getLoggerName()));\r\n        return;\r\n    }\r\n    Level level = loggingEvent.getLevel();\r\n    java.util.logging.Level julLevel = convertLog4jLevel(level);\r\n    LogRecord record = new LogRecord(julLevel, loggingEvent.getRenderedMessage());\r\n    record.setMillis(loggingEvent.getTimeStamp());\r\n    LocationInfo location = loggingEvent.getLocationInformation();\r\n    if (location != null) {\r\n        record.setSourceClassName(location.getClassName());\r\n        record.setSourceMethodName(location.getMethodName());\r\n    }\r\n    logger.log(record);\r\n}"
}, {
	"Path": "com.facebook.presto.cassandra.RebindSafeMBeanServer.registerMBean",
	"Comment": "delegates to the wrapped mbean server, but if a mbean is already registeredwith the specified name, the existing instance is returned.",
	"Method": "ObjectInstance registerMBean(Object object,ObjectName name){\r\n    while (true) {\r\n        try {\r\n            return mbeanServer.registerMBean(object, name);\r\n        } catch (InstanceAlreadyExistsException ignored) {\r\n        }\r\n        try {\r\n            ObjectInstance objectInstance = mbeanServer.getObjectInstance(name);\r\n            log.debug(\"%s already bound to %s\", name, objectInstance);\r\n            return objectInstance;\r\n        } catch (InstanceNotFoundException ignored) {\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.AccumuloClient.getTabletSplits",
	"Comment": "fetches the tabletsplitmetadata for a query against an accumulo table.does a whole bunch of fun stuff! splitting on row id ranges, applying secondary indexes, column pruning,all sorts of sweet optimizations. what you have here is an important method.",
	"Method": "List<TabletSplitMetadata> getTabletSplits(ConnectorSession session,String schema,String table,Optional<Domain> rowIdDomain,List<AccumuloColumnConstraint> constraints,AccumuloRowSerializer serializer){\r\n    try {\r\n        String tableName = AccumuloTable.getFullTableName(schema, table);\r\n        LOG.debug(\"Getting tablet splits for table %s\", tableName);\r\n        Collection<Range> rowIdRanges = getRangesFromDomain(rowIdDomain, serializer);\r\n        List<TabletSplitMetadata> tabletSplits = new ArrayList();\r\n        if (AccumuloSessionProperties.isOptimizeIndexEnabled(session)) {\r\n            Authorizations auths = getScanAuthorizations(session, schema, table);\r\n            if (indexLookup.applyIndex(schema, table, session, constraints, rowIdRanges, tabletSplits, serializer, auths)) {\r\n                return tabletSplits;\r\n            }\r\n        }\r\n        Collection<Range> splitRanges;\r\n        if (AccumuloSessionProperties.isOptimizeSplitRangesEnabled(session)) {\r\n            splitRanges = splitByTabletBoundaries(tableName, rowIdRanges);\r\n        } else {\r\n            splitRanges = rowIdRanges;\r\n        }\r\n        boolean fetchTabletLocations = AccumuloSessionProperties.isOptimizeLocalityEnabled(session);\r\n        LOG.debug(\"Fetching tablet locations: %s\", fetchTabletLocations);\r\n        for (Range range : splitRanges) {\r\n            if (fetchTabletLocations) {\r\n                tabletSplits.add(new TabletSplitMetadata(getTabletLocation(tableName, range.getStartKey()), ImmutableList.of(range)));\r\n            } else {\r\n                tabletSplits.add(new TabletSplitMetadata(Optional.empty(), ImmutableList.of(range)));\r\n            }\r\n        }\r\n        LOG.debug(\"Number of splits for table %s is %d with %d ranges\", tableName, tabletSplits.size(), splitRanges.size());\r\n        return tabletSplits;\r\n    } catch (Exception e) {\r\n        throw new PrestoException(UNEXPECTED_ACCUMULO_ERROR, \"Failed to get splits from Accumulo\", e);\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.plugin.geospatial.GeoFunctions.computeLineCentroid",
	"Comment": "lines centroid is weighted mean of each line segment, weight in terms of line length",
	"Method": "Point computeLineCentroid(Polyline polyline){\r\n    double xSum = 0;\r\n    double ySum = 0;\r\n    double weightSum = 0;\r\n    for (int i = 0; i < polyline.getPathCount(); i++) {\r\n        Point startPoint = polyline.getPoint(polyline.getPathStart(i));\r\n        Point endPoint = polyline.getPoint(polyline.getPathEnd(i) - 1);\r\n        double dx = endPoint.getX() - startPoint.getX();\r\n        double dy = endPoint.getY() - startPoint.getY();\r\n        double length = sqrt(dx * dx + dy * dy);\r\n        weightSum += length;\r\n        xSum += (startPoint.getX() + endPoint.getX()) * length / 2;\r\n        ySum += (startPoint.getY() + endPoint.getY()) * length / 2;\r\n    }\r\n    return new Point(xSum / weightSum, ySum / weightSum);\r\n}"
}, {
	"Path": "com.facebook.presto.plugin.geospatial.GeoFunctions.computeMultiPolygonCentroid",
	"Comment": "multipolygon centroid is weighted mean of each polygon, weight in terms of polygon area",
	"Method": "Point computeMultiPolygonCentroid(OGCMultiPolygon multiPolygon){\r\n    double xSum = 0;\r\n    double ySum = 0;\r\n    double weightSum = 0;\r\n    for (int i = 0; i < multiPolygon.numGeometries(); i++) {\r\n        Point centroid = computePolygonCentroid((Polygon) multiPolygon.geometryN(i).getEsriGeometry());\r\n        Polygon polygon = (Polygon) multiPolygon.geometryN(i).getEsriGeometry();\r\n        double weight = polygon.calculateArea2D();\r\n        weightSum += weight;\r\n        xSum += centroid.getX() * weight;\r\n        ySum += centroid.getY() * weight;\r\n    }\r\n    return new Point(xSum / weightSum, ySum / weightSum);\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.web.service.map.LinkSelectorTestBase.testVirtual_3tier_callee_limited",
	"Comment": "for situations where virtual nodes are visited, but their callee data are not fetched due to callee search limit.",
	"Method": "void testVirtual_3tier_callee_limited(){\r\n    final Application APP_A = new Application(\"APP_A\", ServiceType.TEST_STAND_ALONE);\r\n    final Application APP_B = new Application(\"APP_B\", ServiceType.TEST_STAND_ALONE);\r\n    final Application APP_C = new Application(\"APP_C\", ServiceType.TEST_STAND_ALONE);\r\n    final Application APP_D = new Application(\"APP_D\", ServiceType.TEST_STAND_ALONE);\r\n    final String gwUri = \"gw.test.com/api\";\r\n    final String apiUri = \"api.test.com/test\";\r\n    final Application RPC_GW = new Application(gwUri, testRpcServiceType);\r\n    final Application RPC_API = new Application(apiUri, testRpcServiceType);\r\n    final Set<AcceptApplication> gwAcceptApplications = Sets.newHashSet(new AcceptApplication(gwUri, APP_B), new AcceptApplication(gwUri, APP_C));\r\n    final Set<AcceptApplication> apiAcceptApplications = Sets.newHashSet(new AcceptApplication(apiUri, APP_D));\r\n    final int callCount_A_B = 4, callCount_A_C = 6;\r\n    final int callCount_B_D = 4, callCount_C_D = 6;\r\n    LinkDataMap callerlinkDataMap_A = new LinkDataMap();\r\n    callerlinkDataMap_A.addLinkData(APP_A, \"agentA\", RPC_GW, gwUri, 1000, testRpcServiceType.getHistogramSchema().getNormalSlot().getSlotTime(), callCount_A_B);\r\n    LinkDataMap callerLinkDataMap_B = new LinkDataMap();\r\n    callerLinkDataMap_B.addLinkData(APP_B, \"agentB\", RPC_API, apiUri, 1000, testRpcServiceType.getHistogramSchema().getNormalSlot().getSlotTime(), callCount_B_D);\r\n    LinkDataMap callerLinkDataMap_C = new LinkDataMap();\r\n    callerLinkDataMap_C.addLinkData(APP_C, \"agentC\", RPC_API, apiUri, 1000, testRpcServiceType.getHistogramSchema().getNormalSlot().getSlotTime(), callCount_C_D);\r\n    LinkDataMap calleeLinkDataMap_B = new LinkDataMap();\r\n    calleeLinkDataMap_B.addLinkData(APP_A, \"agentA\", APP_B, \"agentB\", 1000, ServiceType.TEST_STAND_ALONE.getHistogramSchema().getNormalSlot().getSlotTime(), callCount_A_B);\r\n    LinkDataMap calleeLinkDataMap_C = new LinkDataMap();\r\n    calleeLinkDataMap_C.addLinkData(APP_A, \"agentA\", APP_C, \"agentC\", 1000, ServiceType.TEST_STAND_ALONE.getHistogramSchema().getNormalSlot().getSlotTime(), callCount_A_C);\r\n    LinkDataMap calleeLinkDataMap_D = new LinkDataMap();\r\n    calleeLinkDataMap_D.addLinkData(APP_B, \"agentB\", APP_D, \"agentD\", 1000, ServiceType.TEST_STAND_ALONE.getHistogramSchema().getNormalSlot().getSlotTime(), callCount_B_D);\r\n    calleeLinkDataMap_D.addLinkData(APP_C, \"agentC\", APP_D, \"agentD\", 1000, ServiceType.TEST_STAND_ALONE.getHistogramSchema().getNormalSlot().getSlotTime(), callCount_C_D);\r\n    when(linkDataMapService.selectCallerLinkDataMap(eq(APP_A), any(Range.class))).thenReturn(callerlinkDataMap_A);\r\n    when(linkDataMapService.selectCalleeLinkDataMap(eq(APP_A), any(Range.class))).thenReturn(newEmptyLinkDataMap());\r\n    when(linkDataMapService.selectCallerLinkDataMap(eq(APP_B), any(Range.class))).thenReturn(callerLinkDataMap_B);\r\n    when(linkDataMapService.selectCalleeLinkDataMap(eq(APP_B), any(Range.class))).thenReturn(calleeLinkDataMap_B);\r\n    when(linkDataMapService.selectCallerLinkDataMap(eq(APP_C), any(Range.class))).thenReturn(callerLinkDataMap_C);\r\n    when(linkDataMapService.selectCalleeLinkDataMap(eq(APP_C), any(Range.class))).thenReturn(calleeLinkDataMap_C);\r\n    when(linkDataMapService.selectCallerLinkDataMap(eq(APP_D), any(Range.class))).thenReturn(newEmptyLinkDataMap());\r\n    when(linkDataMapService.selectCalleeLinkDataMap(eq(APP_D), any(Range.class))).thenReturn(calleeLinkDataMap_D);\r\n    when(hostApplicationMapDao.findAcceptApplicationName(eq(APP_A), any(Range.class))).thenReturn(gwAcceptApplications);\r\n    when(hostApplicationMapDao.findAcceptApplicationName(eq(APP_B), any(Range.class))).thenReturn(apiAcceptApplications);\r\n    when(hostApplicationMapDao.findAcceptApplicationName(eq(APP_C), any(Range.class))).thenReturn(apiAcceptApplications);\r\n    LinkSelector linkSelector = linkSelectorFactory.createLinkSelector(getLinkSelectorType());\r\n    LinkDataDuplexMap linkData = linkSelector.select(Collections.singletonList(APP_A), range, 2, 1);\r\n    LinkData linkData_A_B = linkData.getSourceLinkData(new LinkKey(APP_A, APP_B));\r\n    LinkData linkData_A_C = linkData.getSourceLinkData(new LinkKey(APP_A, APP_C));\r\n    Assert.assertEquals(callCount_A_B, linkData_A_B.getTotalCount());\r\n    Assert.assertEquals(callCount_A_C, linkData_A_C.getTotalCount());\r\n    LinkData linkData_B_D = linkData.getSourceLinkData(new LinkKey(APP_B, APP_D));\r\n    Assert.assertEquals(callCount_B_D, linkData_B_D.getTotalCount());\r\n    LinkData linkData_C_D = linkData.getSourceLinkData(new LinkKey(APP_C, APP_D));\r\n    Assert.assertEquals(callCount_C_D, linkData_C_D.getTotalCount());\r\n    LinkData targetLinkData_A_B = linkData.getTargetLinkData(new LinkKey(APP_A, APP_B));\r\n    LinkData targetLinkData_A_C = linkData.getTargetLinkData(new LinkKey(APP_A, APP_C));\r\n    Assert.assertEquals(callCount_A_B, targetLinkData_A_B.getTotalCount());\r\n    Assert.assertEquals(callCount_A_C, targetLinkData_A_C.getTotalCount());\r\n}"
}, {
	"Path": "com.facebook.presto.hive.HiveTableLayoutHandle.getPartitions",
	"Comment": "partitions are dropped when hivetablelayouthandle is serialized.",
	"Method": "Optional<List<HivePartition>> getPartitions(){\r\n    return Optional.ofNullable(partitions);\r\n}"
}, {
	"Path": "com.facebook.presto.hive.parquet.write.TestDataWritableWriter.writeGroup",
	"Comment": "it writes a group type and all its values to the parquet recordconsumer.this is used only for optional and required groups.",
	"Method": "void writeGroup(Object value,StructObjectInspector inspector,GroupType type){\r\n    recordConsumer.startGroup();\r\n    writeGroupFields(value, inspector, type);\r\n    recordConsumer.endGroup();\r\n}"
}, {
	"Path": "com.facebook.presto.array.SliceBigArray.ensureCapacity",
	"Comment": "ensures this big array is at least the specified length.if the array is smaller, segmentsare added until the array is larger then the specified length.",
	"Method": "void ensureCapacity(long length){\r\n    array.ensureCapacity(length);\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.rpc.client.DefaultPinpointClientHandler.close",
	"Comment": "calling this method on a closed pinpointclienthandler has no effect.",
	"Method": "void close(){\r\n    logger.debug(\"{} close() started.\", objectUniqName);\r\n    SocketStateCode currentStateCode = state.getCurrentStateCode();\r\n    if (currentStateCode.isRun()) {\r\n        state.toBeingClose();\r\n        closeChannel();\r\n    } else if (currentStateCode.isBeforeConnected()) {\r\n        state.toClosed();\r\n        closeResources();\r\n    } else if (currentStateCode.onClose() || currentStateCode.isClosed()) {\r\n        logger.warn(\"close() failed. Already closed.\");\r\n    } else {\r\n        logger.warn(\"Illegal State :{}.\", currentStateCode);\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.serializers.AccumuloRowSerializer.getMapFromBlock",
	"Comment": "given the map type and presto block, decodes the block into a map of values.",
	"Method": "Map<Object, Object> getMapFromBlock(Type type,Block block){\r\n    Map<Object, Object> map = new HashMap(block.getPositionCount() / 2);\r\n    Type keyType = Types.getKeyType(type);\r\n    Type valueType = Types.getValueType(type);\r\n    for (int i = 0; i < block.getPositionCount(); i += 2) {\r\n        map.put(readObject(keyType, block, i), readObject(valueType, block, i + 1));\r\n    }\r\n    return map;\r\n}"
}, {
	"Path": "com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore.getTableSource",
	"Comment": "this method can only be called when the table is known to exist",
	"Method": "TableSource getTableSource(String databaseName,String tableName){\r\n    checkHoldsLock();\r\n    checkReadable();\r\n    Action<TableAndMore> tableAction = tableActions.get(new SchemaTableName(databaseName, tableName));\r\n    if (tableAction == null) {\r\n        return TableSource.PRE_EXISTING_TABLE;\r\n    }\r\n    switch(tableAction.getType()) {\r\n        case ADD:\r\n            return TableSource.CREATED_IN_THIS_TRANSACTION;\r\n        case ALTER:\r\n            throw new IllegalStateException(\"Tables are never altered in the current implementation\");\r\n        case DROP:\r\n            throw new TableNotFoundException(new SchemaTableName(databaseName, tableName));\r\n        case INSERT_EXISTING:\r\n            return TableSource.PRE_EXISTING_TABLE;\r\n        default:\r\n            throw new IllegalStateException(\"Unknown action type\");\r\n    }\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.index.IndexLookup.inRange",
	"Comment": "gets a boolean value indicating if the given value is in one of the ranges in the given collection",
	"Method": "boolean inRange(Text text,Collection<Range> ranges){\r\n    Key kCq = new Key(text);\r\n    return ranges.stream().anyMatch(r -> !r.beforeStartKey(kCq) && !r.afterEndKey(kCq));\r\n}"
}, {
	"Path": "com.facebook.presto.array.ShortBigArray.ensureCapacity",
	"Comment": "ensures this big array is at least the specified length.if the array is smaller, segmentsare added until the array is larger then the specified length.",
	"Method": "void ensureCapacity(long length){\r\n    if (capacity > length) {\r\n        return;\r\n    }\r\n    grow(length);\r\n}"
}, {
	"Path": "com.facebook.presto.memory.LegacyQueryContext.reserveSpill",
	"Comment": "todo move spill tracking to the new memory tracking framework",
	"Method": "ListenableFuture<?> reserveSpill(long bytes){\r\n    checkArgument(bytes >= 0, \"bytes is negative\");\r\n    if (spillUsed + bytes > maxSpill) {\r\n        throw exceededPerQueryLocalLimit(succinctBytes(maxSpill));\r\n    }\r\n    ListenableFuture<?> future = spillSpaceTracker.reserve(bytes);\r\n    spillUsed += bytes;\r\n    return future;\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.web.cluster.zookeeper.ZookeeperClusterTest.clusterTest1",
	"Comment": "test for zookeeper agents to be registered correctly at the cluster as expected",
	"Method": "void clusterTest1(){\r\n    ZooKeeper zookeeper = null;\r\n    ZookeeperClusterDataManager manager = null;\r\n    try {\r\n        zookeeper = new ZooKeeper(DEFAULT_IP + \":\" + zookeeperPort, 5000, null);\r\n        createPath(zookeeper, COLLECTOR_TEST_NODE_PATH, true);\r\n        zookeeper.setData(COLLECTOR_TEST_NODE_PATH, \"a:b:1\".getBytes(), -1);\r\n        manager = new ZookeeperClusterDataManager(DEFAULT_IP + \":\" + zookeeperPort, 5000, 60000);\r\n        manager.start();\r\n        awaitClusterManagerConnected(manager);\r\n        awaitCheckAgentRegistered(manager, \"a\", \"b\", 1L);\r\n        List<String> agentList = manager.getRegisteredAgentList(\"a\", \"b\", 1L);\r\n        Assert.assertEquals(1, agentList.size());\r\n        Assert.assertEquals(\"test\", agentList.get(0));\r\n        agentList = manager.getRegisteredAgentList(\"b\", \"c\", 1L);\r\n        Assert.assertEquals(0, agentList.size());\r\n        zookeeper.setData(COLLECTOR_TEST_NODE_PATH, \"\".getBytes(), -1);\r\n        final ZookeeperClusterDataManager finalManager = manager;\r\n        boolean await = awaitUtils.await(new TestAwaitTaskUtils() {\r\n            @Override\r\n            public boolean checkCompleted() {\r\n                return finalManager.getRegisteredAgentList(\"a\", \"b\", 1L).isEmpty();\r\n            }\r\n        });\r\n        Assert.assertTrue(await);\r\n    } finally {\r\n        if (zookeeper != null) {\r\n            zookeeper.close();\r\n        }\r\n        if (manager != null) {\r\n            manager.stop();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.navercorp.pinpoint.web.cluster.zookeeper.ZookeeperClusterTest.clusterTest1",
	"Comment": "test for zookeeper agents to be registered correctly at the cluster as expected",
	"Method": "void clusterTest1(){\r\n    return finalManager.getRegisteredAgentList(\"a\", \"b\", 1L).isEmpty();\r\n}"
}, {
	"Path": "com.facebook.presto.hive.parquet.AbstractTestParquetReader.setParquetLogging",
	"Comment": "parquet has excessive logging at info level, set them to warning",
	"Method": "void setParquetLogging(){\r\n    Logger.getLogger(ParquetOutputFormat.class.getName()).setLevel(Level.WARNING);\r\n    Logger.getLogger(CodecConfig.class.getName()).setLevel(Level.WARNING);\r\n    Logger.getLogger(\"parquet.hadoop.InternalParquetRecordWriter\").setLevel(Level.WARNING);\r\n    Logger.getLogger(\"parquet.hadoop.ColumnChunkPageWriteStore\").setLevel(Level.WARNING);\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.AccumuloClient.getColumnLocalityGroup",
	"Comment": "searches through the given locality groups to find if this column has a locality group.",
	"Method": "Optional<String> getColumnLocalityGroup(String columnName,Optional<Map<String, Set<String>>> groups){\r\n    if (groups.isPresent()) {\r\n        for (Map.Entry<String, Set<String>> group : groups.get().entrySet()) {\r\n            if (group.getValue().contains(columnName.toLowerCase(Locale.ENGLISH))) {\r\n                return Optional.of(group.getKey());\r\n            }\r\n        }\r\n    }\r\n    return Optional.empty();\r\n}"
}, {
	"Path": "com.facebook.presto.array.ObjectBigArray.ensureCapacity",
	"Comment": "ensures this big array is at least the specified length.if the array is smaller, segmentsare added until the array is larger then the specified length.",
	"Method": "void ensureCapacity(long length){\r\n    if (capacity > length) {\r\n        return;\r\n    }\r\n    grow(length);\r\n}"
}, {
	"Path": "com.facebook.presto.cassandra.TestCassandraConnector.testGetTableNamesException",
	"Comment": "disabled until metadata manager is updated to handle invalid catalogs and schemas",
	"Method": "void testGetTableNamesException(){\r\n    metadata.listTables(SESSION, INVALID_DATABASE);\r\n}"
}, {
	"Path": "com.facebook.presto.accumulo.AccumuloClient.getRowIdColumn",
	"Comment": "gets the row id based on a table properties or the first column name.",
	"Method": "String getRowIdColumn(ConnectorTableMetadata meta){\r\n    Optional<String> rowIdColumn = AccumuloTableProperties.getRowId(meta.getProperties());\r\n    return rowIdColumn.orElse(meta.getColumns().get(0).getName()).toLowerCase(Locale.ENGLISH);\r\n}"
}, {
	"Path": "com.facebook.presto.array.IntBigArray.add",
	"Comment": "adds the specified value to the specified element of this big array.",
	"Method": "void add(long index,int value){\r\n    array[segment(index)][offset(index)] += value;\r\n}"
}]