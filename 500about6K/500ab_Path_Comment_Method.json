[{
	"Path": "com.google.errorprone.matchers.Matchers.anyOf",
	"Comment": "compose several matchers together, such that the composite matches an ast node if any of thegiven matchers do.",
	"Method": "Matcher<T> anyOf(Iterable<? extends Matcher<? super T>> matchers,Matcher<T> anyOf,Matcher<? super T> matchers){\r\n    return anyOf(Arrays.<Matcher<? super T>>asList(matchers));\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.methodReturnsNonNull",
	"Comment": "matches a whitelisted method invocation that is known to never return null",
	"Method": "Matcher<ExpressionTree> methodReturnsNonNull(){\r\n    return anyOf(instanceMethod().onDescendantOf(\"java.lang.Object\").named(\"toString\"), instanceMethod().onExactClass(\"java.lang.String\"), staticMethod().onClass(\"java.lang.String\"), instanceMethod().onExactClass(\"java.util.StringTokenizer\").named(\"nextToken\"));\r\n}"
}, {
	"Path": "graphql.schema.idl.WiringFactory.getDefaultDataFetcher",
	"Comment": "all fields need a data fetcher of some sort and this method is called to provide the data fetcherthat will be used if no specific one has been provided",
	"Method": "DataFetcher getDefaultDataFetcher(FieldWiringEnvironment environment){\r\n    return null;\r\n}"
}, {
	"Path": "org.flywaydb.commandline.Main.determineConfigurationFileEncoding",
	"Comment": "determines the encoding to use for loading the configuration.",
	"Method": "String determineConfigurationFileEncoding(String[] args,Map<String, String> envVars){\r\n    if (envVars.containsKey(ConfigUtils.CONFIG_FILE_ENCODING)) {\r\n        return envVars.get(ConfigUtils.CONFIG_FILE_ENCODING);\r\n    }\r\n    for (String arg : args) {\r\n        if (isPropertyArgument(arg) && ConfigUtils.CONFIG_FILE_ENCODING.equals(getArgumentProperty(arg))) {\r\n            return getArgumentValue(arg);\r\n        }\r\n    }\r\n    return \"UTF-8\";\r\n}"
}, {
	"Path": "water.persist.PersistManager.afterPrefix",
	"Comment": "returns the part of the string that occurs after the first index of the substring",
	"Method": "String afterPrefix(String wholeString,String substring){\r\n    int posSubstring = wholeString.lastIndexOf(substring);\r\n    if (posSubstring == -1) {\r\n        return \"\";\r\n    }\r\n    int adjustedPosSubstring = posSubstring + substring.length();\r\n    if (adjustedPosSubstring >= wholeString.length()) {\r\n        return \"\";\r\n    }\r\n    return wholeString.substring(adjustedPosSubstring);\r\n}"
}, {
	"Path": "com.alibaba.excel.util.ObjectUtils.addObjectToArray",
	"Comment": "append the given object to the given array, returning a new arrayconsisting of the input array contents plus the given object.",
	"Method": "A[] addObjectToArray(A[] array,O obj){\r\n    Class<?> compType = Object.class;\r\n    if (array != null) {\r\n        compType = array.getClass().getComponentType();\r\n    } else if (obj != null) {\r\n        compType = obj.getClass();\r\n    }\r\n    int newArrLength = (array != null ? array.length + 1 : 1);\r\n    @SuppressWarnings(\"unchecked\")\r\n    A[] newArr = (A[]) Array.newInstance(compType, newArrLength);\r\n    if (array != null) {\r\n        System.arraycopy(array, 0, newArr, 0, array.length);\r\n    }\r\n    newArr[newArr.length - 1] = obj;\r\n    return newArr;\r\n}"
}, {
	"Path": "ai.h2o.automl.targetencoding.TargetEncodingTargetColumnTest.groupThenAggregateWithoutFoldsForBinaryTargetTest",
	"Comment": "test that we can do sum and count on binary categorical column due to numerical representation under the hood.",
	"Method": "void groupThenAggregateWithoutFoldsForBinaryTargetTest(){\r\n    String tmpName = null;\r\n    Frame parsedFrame = null;\r\n    try {\r\n        fr = new TestFrameBuilder().withName(\"testFrame\").withColNames(\"ColA\", \"ColB\").withVecTypes(Vec.T_CAT, Vec.T_CAT).withDataForCol(0, ar(\"a\", \"a\", \"b\")).withDataForCol(1, ar(\"NO\", \"YES\", \"NO\")).build();\r\n        tmpName = UUID.randomUUID().toString();\r\n        Frame.export(fr, tmpName, fr._key.toString(), true, 1);\r\n        try {\r\n            Thread.sleep(1000);\r\n        } catch (InterruptedException ex) {\r\n        }\r\n        parsedFrame = parse_test_file(Key.make(\"parsed\"), tmpName, true);\r\n        String[] teColumns = { \"ColA\" };\r\n        TargetEncoder tec = new TargetEncoder(teColumns);\r\n        Frame res = tec.groupThenAggregateForNumeratorAndDenominator(parsedFrame, teColumns[0], null, 1);\r\n        Vec expectedSumColumn = vec(1, 0);\r\n        Vec expectedCountColumn = vec(2, 1);\r\n        assertVecEquals(expectedSumColumn, res.vec(1), 1e-5);\r\n        assertVecEquals(expectedCountColumn, res.vec(2), 1e-5);\r\n        expectedSumColumn.remove();\r\n        expectedCountColumn.remove();\r\n        res.delete();\r\n    } finally {\r\n        new File(tmpName).delete();\r\n        fr.delete();\r\n        parsedFrame.delete();\r\n    }\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.crawler.WebCrawler.shouldVisit",
	"Comment": "classes that extends webcrawler should overwrite this function to tell thecrawler whether the given url should be crawled or not. the followingdefault implementation indicates that all urls should be included in the crawlexcept those with a nofollow flag.",
	"Method": "boolean shouldVisit(Page referringPage,WebURL url){\r\n    if (myController.getConfig().isRespectNoFollow()) {\r\n        return !((referringPage != null && referringPage.getContentType() != null && referringPage.getContentType().contains(\"html\") && ((HtmlParseData) referringPage.getParseData()).getMetaTagValue(\"robots\").contains(\"nofollow\")) || url.getAttribute(\"rel\").contains(\"nofollow\"));\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "water.parser.SVMLightParser.guessSetup",
	"Comment": "try to parse the bytes as svm light format, return a parsesetuphandler with typesvmlight if the input is in svm light format, throw an exception otherwise.",
	"Method": "ParseSetup guessSetup(byte[] bits){\r\n    int lastNewline = bits.length - 1;\r\n    while (lastNewline > 0 && !CsvParser.isEOL(bits[lastNewline])) lastNewline--;\r\n    if (lastNewline > 0)\r\n        bits = Arrays.copyOf(bits, lastNewline + 1);\r\n    SVMLightParser p = new SVMLightParser(new ParseSetup(SVMLight_INFO, ParseSetup.GUESS_SEP, false, ParseSetup.GUESS_HEADER, ParseSetup.GUESS_COL_CNT, null, null, null, null, null), null);\r\n    SVMLightInspectParseWriter dout = new SVMLightInspectParseWriter();\r\n    p.parseChunk(0, new ByteAryData(bits, 0), dout);\r\n    if (dout._ncols > 0 && dout._nlines > 0 && dout._nlines > dout._invalidLines)\r\n        return new ParseSetup(SVMLight_INFO, ParseSetup.GUESS_SEP, false, ParseSetup.NO_HEADER, dout._ncols, null, dout.guessTypes(), null, null, dout._data, dout.removeErrors());\r\n    else\r\n        throw new ParseDataset.H2OParseException(\"Could not parse file as an SVMLight file.\");\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.BugChecker.describeMatch",
	"Comment": "helper to create a description for the common case where there is no fix.",
	"Method": "Description describeMatch(Tree node,Fix fix,Description describeMatch,Tree node,Description describeMatch,Tree node,Optional<? extends Fix> fix){\r\n    return buildDescription(node).addFix(fix).build();\r\n}"
}, {
	"Path": "graphql.execution.instrumentation.Instrumentation.createState",
	"Comment": "this will be called just before execution to create an object that is given back to all instrumentation methodsto allow them to have per execution request state",
	"Method": "InstrumentationState createState(InstrumentationState createState,InstrumentationCreateStateParameters parameters){\r\n    return createState();\r\n}"
}, {
	"Path": "graphql.TypeResolutionEnvironment.getObject",
	"Comment": "you will be passed the specific source object that needs to be resolve into a concrete graphql object type",
	"Method": "T getObject(){\r\n    return (T) object;\r\n}"
}, {
	"Path": "graphql.validation.rules.ExecutableDefinitions.checkDocument",
	"Comment": "executable definitionsa graphql document is only valid for execution if all definitions are eitheroperation or fragment definitions.",
	"Method": "void checkDocument(Document document){\r\n    document.getDefinitions().forEach(definition -> {\r\n        if (!(definition instanceof OperationDefinition) && !(definition instanceof FragmentDefinition)) {\r\n            String message = nonExecutableDefinitionMessage(definition);\r\n            addError(ValidationErrorType.NonExecutableDefinition, definition.getSourceLocation(), message);\r\n        }\r\n    });\r\n}"
}, {
	"Path": "graphql.execution.AbortExecutionException.toExecutionResult",
	"Comment": "this is useful for turning this abort signal into an execution result whichis an error state with the underlying errors in it.",
	"Method": "ExecutionResult toExecutionResult(){\r\n    ExecutionResult executionResult = new ExecutionResultImpl(this);\r\n    if (!this.getUnderlyingErrors().isEmpty()) {\r\n        executionResult = new ExecutionResultImpl(this.getUnderlyingErrors());\r\n    }\r\n    return executionResult;\r\n}"
}, {
	"Path": "graphql.execution.Async.toCompletableFuture",
	"Comment": "turns an object t into a completablefuture if its not already",
	"Method": "CompletableFuture<T> toCompletableFuture(T t){\r\n    if (t instanceof CompletionStage) {\r\n        return ((CompletionStage<T>) t).toCompletableFuture();\r\n    } else {\r\n        return CompletableFuture.completedFuture(t);\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.SqlStatementBuilder.lineTerminatesStatement",
	"Comment": "checks whether this line terminates the current statement.",
	"Method": "boolean lineTerminatesStatement(String line,Delimiter delimiter){\r\n    if (delimiter == null || (defaultDelimiter.equals(delimiter) && nestedBlockDepth > 0)) {\r\n        return false;\r\n    }\r\n    String upperCaseDelimiter = delimiter.getDelimiter().toUpperCase();\r\n    if (delimiter.isAloneOnLine()) {\r\n        return line.equals(upperCaseDelimiter);\r\n    }\r\n    return line.endsWith(upperCaseDelimiter);\r\n}"
}, {
	"Path": "water.H2O.setEmbeddedH2OConfig",
	"Comment": "register embedded h2o configuration object with h2o instance.",
	"Method": "void setEmbeddedH2OConfig(AbstractEmbeddedH2OConfig c){\r\n    embeddedH2OConfig = c;\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.hasDirectAnnotationWithSimpleName",
	"Comment": "check for the presence of an annotation with a specific simple name directly on this symbol.consider annotation inheritance.",
	"Method": "boolean hasDirectAnnotationWithSimpleName(Symbol sym,String simpleName,boolean hasDirectAnnotationWithSimpleName,Tree tree,String simpleName){\r\n    return hasDirectAnnotationWithSimpleName(getDeclaredSymbol(tree), simpleName);\r\n}"
}, {
	"Path": "feign.RequestTemplate.from",
	"Comment": "create a request template from an existing request template.",
	"Method": "RequestTemplate from(RequestTemplate requestTemplate){\r\n    RequestTemplate template = new RequestTemplate(requestTemplate.target, requestTemplate.uriTemplate, requestTemplate.method, requestTemplate.charset, requestTemplate.body, requestTemplate.decodeSlash, requestTemplate.collectionFormat);\r\n    if (!requestTemplate.queries().isEmpty()) {\r\n        template.queries.putAll(requestTemplate.queries);\r\n    }\r\n    if (!requestTemplate.headers().isEmpty()) {\r\n        template.headers.putAll(requestTemplate.headers);\r\n    }\r\n    return template;\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlusBuilder.setMargin",
	"Comment": "add margins to your dialog. they are set to 0 except when gravity is center. in that case basic marginsare applied",
	"Method": "DialogPlusBuilder setMargin(int left,int top,int right,int bottom){\r\n    this.margin[0] = left;\r\n    this.margin[1] = top;\r\n    this.margin[2] = right;\r\n    this.margin[3] = bottom;\r\n    return this;\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaDirectiveWiring.onScalar",
	"Comment": "this is called when a custom scalar is encountered, which gives the schema directive a chance to modify the shape and behaviourof that dslelement",
	"Method": "GraphQLScalarType onScalar(SchemaDirectiveWiringEnvironment<GraphQLScalarType> environment){\r\n    return environment.getElement();\r\n}"
}, {
	"Path": "graphql.GraphQL.execute",
	"Comment": "executes the graphql query using the provided input object builder",
	"Method": "ExecutionResult execute(String query,ExecutionResult execute,String query,Object context,ExecutionResult execute,String query,String operationName,Object context,ExecutionResult execute,String query,Object context,Map<String, Object> variables,ExecutionResult execute,String query,String operationName,Object context,Map<String, Object> variables,ExecutionResult execute,ExecutionInput.Builder executionInputBuilder,ExecutionResult execute,UnaryOperator<ExecutionInput.Builder> builderFunction,ExecutionResult execute,ExecutionInput executionInput,CompletableFuture<ExecutionResult> execute,ExecutionInput executionInput,Document document,GraphQLSchema graphQLSchema,InstrumentationState instrumentationState){\r\n    String query = executionInput.getQuery();\r\n    String operationName = executionInput.getOperationName();\r\n    Object context = executionInput.getContext();\r\n    Execution execution = new Execution(queryStrategy, mutationStrategy, subscriptionStrategy, instrumentation);\r\n    ExecutionId executionId = idProvider.provide(query, operationName, context);\r\n    log.debug(\"Executing '{}'. operation name: '{}'. query: '{}'. variables '{}'\", executionId, executionInput.getOperationName(), executionInput.getQuery(), executionInput.getVariables());\r\n    CompletableFuture<ExecutionResult> future = execution.execute(document, graphQLSchema, executionId, executionInput, instrumentationState);\r\n    future = future.whenComplete((result, throwable) -> {\r\n        if (throwable != null) {\r\n            log.error(String.format(\"Execution '%s' threw exception when executing : query : '%s'. variables '%s'\", executionId, executionInput.getQuery(), executionInput.getVariables()), throwable);\r\n        } else {\r\n            int errorCount = result.getErrors().size();\r\n            if (errorCount > 0) {\r\n                log.debug(\"Execution '{}' completed with '{}' errors\", executionId, errorCount);\r\n            } else {\r\n                log.debug(\"Execution '{}' completed with zero errors\", executionId);\r\n            }\r\n        }\r\n    });\r\n    return future;\r\n}"
}, {
	"Path": "graphql.schema.idl.TypeDefinitionRegistry.getTypesMap",
	"Comment": "returns a map of types in the registry of that specified class keyed by name",
	"Method": "Map<String, T> getTypesMap(Class<T> targetClass){\r\n    List<T> list = getTypes(targetClass);\r\n    return FpKit.getByName(list, TypeDefinition::getName, FpKit.mergeFirst());\r\n}"
}, {
	"Path": "water.fvec.Frame.bulkAdd",
	"Comment": "append multiple named vecs to the frame.names are forced unique, by appending a unique number if needed.",
	"Method": "void bulkAdd(String[] names,Vec[] vecs){\r\n    String[] tmpnames = names.clone();\r\n    int N = names.length;\r\n    assert (names.length == vecs.length) : \"names = \" + Arrays.toString(names) + \", vecs len = \" + vecs.length;\r\n    for (int i = 0; i < N; ++i) {\r\n        vecs[i] = vecs[i] != null ? makeCompatible(new Frame(vecs[i]))[0] : null;\r\n        checkCompatibility(tmpnames[i] = uniquify(tmpnames[i]), vecs[i]);\r\n    }\r\n    int ncols = _keys.length;\r\n    String[] tmpnam = Arrays.copyOf(_names, ncols + N);\r\n    Key<Vec>[] tmpkeys = Arrays.copyOf(_keys, ncols + N);\r\n    Vec[] tmpvecs = Arrays.copyOf(_vecs, ncols + N);\r\n    for (int i = 0; i < N; ++i) {\r\n        tmpnam[ncols + i] = tmpnames[i];\r\n        tmpkeys[ncols + i] = vecs[i]._key;\r\n        tmpvecs[ncols + i] = vecs[i];\r\n    }\r\n    _keys = tmpkeys;\r\n    _vecs = tmpvecs;\r\n    setNames(tmpnam);\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.util.OSXAdapter.setQuitHandler",
	"Comment": "the method passed should return a boolean stating whether or not the quit should occur",
	"Method": "void setQuitHandler(Object target,Method quitHandler){\r\n    setHandler(new OSXAdapter(\"handleQuit\", target, quitHandler));\r\n}"
}, {
	"Path": "hex.tree.drf.DRFCheckpointTest.testCheckpointReconstruction4Binomial",
	"Comment": "test if reconstructed initial frame match the last iterationof drf model builder.this test verify binominal model.",
	"Method": "void testCheckpointReconstruction4Binomial(){\r\n    testCheckPointReconstruction(\"smalldata/logreg/prostate.csv\", 1, true, 5, 3);\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.examples.localdata.LocalDataCollectorCrawler.onBeforeExit",
	"Comment": "this function is called by controller before finishing the job.you can put whatever stuff you need here.",
	"Method": "void onBeforeExit(){\r\n    dumpMyData();\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.threadsafety.ImmutableCheckerTest.negativeAnonymousMutableBound",
	"Comment": "the type arguments are checked everywhere the super type is used",
	"Method": "void negativeAnonymousMutableBound(){\r\n    compilationHelper.addSourceLines(\"threadsafety/Super.java\", \"package threadsafety;\", \"import com.google.errorprone.annotations.Immutable;\", \"@Immutable(containerOf=\\\"T\\\") class Super<T> {\", \"  private final T t = null;\", \"}\").addSourceLines(\"threadsafety/Test.java\", \"package threadsafety;\", \"import com.google.errorprone.annotations.Immutable;\", \"class Test {{\", \"  new Super<Object>() {};\", \"}}\").doTest();\r\n}"
}, {
	"Path": "water.persist.PersistManager.useHdfsAsFallback",
	"Comment": "should hdfs persist layer be used as default persist layerfor unknown url schema.",
	"Method": "boolean useHdfsAsFallback(){\r\n    return System.getProperty(PROP_ENABLE_HDFS_FALLBACK, \"true\").equals(\"true\");\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.getRunningThreadCount",
	"Comment": "returns an estimate of the number of worker threads that arenot blocked waiting to join tasks or for other managedsynchronization. this method may overestimate thenumber of running threads.",
	"Method": "int getRunningThreadCount(){\r\n    int rc = 0;\r\n    WorkQueue[] ws;\r\n    WorkQueue w;\r\n    if ((ws = workQueues) != null) {\r\n        for (int i = 1; i < ws.length; i += 2) {\r\n            if ((w = ws[i]) != null && w.isApparentlyUnblocked())\r\n                ++rc;\r\n        }\r\n    }\r\n    return rc;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.postgresql.PostgreSQLSchema.generateDropStatementsForDomains",
	"Comment": "generates the statements for dropping the domains in this schema.",
	"Method": "List<String> generateDropStatementsForDomains(){\r\n    List<String> domainNames = jdbcTemplate.queryForStringList(\"SELECT domain_name FROM information_schema.domains WHERE domain_schema=?\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (String domainName : domainNames) {\r\n        statements.add(\"DROP DOMAIN \" + database.quote(name, domainName));\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "jsr166y.ForkJoinTask.quietlyInvoke",
	"Comment": "commences performing this task and awaits its completion ifnecessary, without returning its result or throwing itsexception.",
	"Method": "void quietlyInvoke(){\r\n    doInvoke();\r\n}"
}, {
	"Path": "water.api.FramesHandler.list",
	"Comment": "return all the frames. the frames list will be instances of framesynopsisv3,which only contains a few fields, for performance reasons.",
	"Method": "FramesListV3 list(int version,FramesListV3 s){\r\n    Frames f = s.createAndFillImpl();\r\n    f.frames = Frame.fetchAll();\r\n    s.fillFromImplWithSynopsis(f);\r\n    return s;\r\n}"
}, {
	"Path": "water.api.SchemaServer.getExperimentalVersion",
	"Comment": "get the experimental schema version, which indicates that a schema is not guaranteed to be stable between h2oreleases.",
	"Method": "int getExperimentalVersion(){\r\n    return EXPERIMENTAL_VERSION;\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaTypeExtensionsChecker.checkEnumTypeExtensions",
	"Comment": "enum type extensions have the potential to be invalid if incorrectly defined.the named type must already be defined and must be an enum type.all values of an enum type extension must be unique.all values of an enum type extension must not already be a value of the original enum.any directives provided must not already apply to the original enum type.",
	"Method": "void checkEnumTypeExtensions(List<GraphQLError> errors,TypeDefinitionRegistry typeRegistry){\r\n    typeRegistry.enumTypeExtensions().forEach((name, extensions) -> {\r\n        checkTypeExtensionHasCorrespondingType(errors, typeRegistry, name, extensions, EnumTypeDefinition.class);\r\n        checkTypeExtensionDirectiveRedefinition(errors, typeRegistry, name, extensions, EnumTypeDefinition.class);\r\n        extensions.forEach(extension -> {\r\n            List<EnumValueDefinition> enumValueDefinitions = extension.getEnumValueDefinitions();\r\n            checkNamedUniqueness(errors, enumValueDefinitions, EnumValueDefinition::getName, (namedField, enumValue) -> new NonUniqueNameError(extension, enumValue));\r\n            forEachBut(extension, extensions, otherTypeExt -> checkForEnumValueRedefinition(errors, otherTypeExt, otherTypeExt.getEnumValueDefinitions(), enumValueDefinitions));\r\n            Optional<EnumTypeDefinition> baseTypeOpt = typeRegistry.getType(extension.getName(), EnumTypeDefinition.class);\r\n            baseTypeOpt.ifPresent(baseTypeDef -> checkForEnumValueRedefinition(errors, extension, enumValueDefinitions, baseTypeDef.getEnumValueDefinitions()));\r\n        });\r\n    });\r\n}"
}, {
	"Path": "hex.ModelBuilder.trainModel",
	"Comment": "method to launch training of a model, based on its parameters.",
	"Method": "Job<M> trainModel(){\r\n    if (error_count() > 0)\r\n        throw H2OModelBuilderIllegalArgumentException.makeFromBuilder(this);\r\n    _start_time = System.currentTimeMillis();\r\n    if (!nFoldCV())\r\n        return _job.start(trainModelImpl(), _parms.progressUnits(), _parms._max_runtime_secs);\r\n    return _job.start(new H2O.H2OCountedCompleter() {\r\n        @Override\r\n        public void compute2() {\r\n            computeCrossValidation();\r\n            tryComplete();\r\n        }\r\n        @Override\r\n        public boolean onExceptionalCompletion(Throwable ex, CountedCompleter caller) {\r\n            Log.warn(\"Model training job \" + _job._description + \" completed with exception: \" + ex);\r\n            if (_job._result != null) {\r\n                try {\r\n                    _job._result.remove();\r\n                } catch (Exception logged) {\r\n                    Log.warn(\"Exception thrown when removing result from job \" + _job._description, logged);\r\n                }\r\n            }\r\n            return true;\r\n        }\r\n    }, (nFoldWork() + 1) * _parms.progressUnits(), _parms._max_runtime_secs);\r\n}"
}, {
	"Path": "hex.ModelBuilder.trainModel",
	"Comment": "method to launch training of a model, based on its parameters.",
	"Method": "Job<M> trainModel(){\r\n    computeCrossValidation();\r\n    tryComplete();\r\n}"
}, {
	"Path": "hex.ModelBuilder.trainModel",
	"Comment": "method to launch training of a model, based on its parameters.",
	"Method": "Job<M> trainModel(){\r\n    Log.warn(\"Model training job \" + _job._description + \" completed with exception: \" + ex);\r\n    if (_job._result != null) {\r\n        try {\r\n            _job._result.remove();\r\n        } catch (Exception logged) {\r\n            Log.warn(\"Exception thrown when removing result from job \" + _job._description, logged);\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.flywaydb.maven.AbstractFlywayMojo.determineConfigurationFileEncoding",
	"Comment": "determines the encoding to use for loading the configuration files.",
	"Method": "String determineConfigurationFileEncoding(Map<String, String> envVars){\r\n    if (envVars.containsKey(ConfigUtils.CONFIG_FILE_ENCODING)) {\r\n        return envVars.get(ConfigUtils.CONFIG_FILE_ENCODING);\r\n    }\r\n    if (System.getProperties().containsKey(ConfigUtils.CONFIG_FILE_ENCODING)) {\r\n        return System.getProperties().getProperty(ConfigUtils.CONFIG_FILE_ENCODING);\r\n    }\r\n    if (configFileEncoding != null) {\r\n        return configFileEncoding;\r\n    }\r\n    return \"UTF-8\";\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.findMethod",
	"Comment": "returns the method tree that matches the given symbol within the compilation unit, or null ifnone was found.",
	"Method": "MethodTree findMethod(MethodSymbol symbol,VisitorState state){\r\n    return JavacTrees.instance(state.context).getTree(symbol);\r\n}"
}, {
	"Path": "water.ExternalFrameWriterClient.waitUntilAllWritten",
	"Comment": "this method ensures the application waits for all bytes to be written before continuing in the control flow.it has to be called at the end of writing.",
	"Method": "void waitUntilAllWritten(int timeout){\r\n    try {\r\n        final AutoBuffer confirmAb = new AutoBuffer(channel, null);\r\n        try {\r\n            byte flag = ExternalFrameConfirmationCheck.getConfirmation(confirmAb, timeout);\r\n            assert (flag == ExternalFrameHandler.CONFIRM_WRITING_DONE);\r\n        } catch (TimeoutException ex) {\r\n            throw new ExternalFrameConfirmationException(\"Timeout for confirmation exceeded!\");\r\n        } catch (InterruptedException e) {\r\n            throw new ExternalFrameConfirmationException(\"Confirmation thread interrupted!\");\r\n        } catch (ExecutionException e) {\r\n            throw new ExternalFrameConfirmationException(\"Confirmation failed!\");\r\n        }\r\n    } catch (IOException e) {\r\n        throw new ExternalFrameConfirmationException(\"Confirmation failed\");\r\n    }\r\n}"
}, {
	"Path": "water.nbhm.NonBlockingIdentityHashMap.putIfMatch",
	"Comment": "putifmatch only returns a null if passed in an expected null.",
	"Method": "TypeV putIfMatch(Object key,Object newVal,Object oldVal,Object putIfMatch,NonBlockingIdentityHashMap topmap,Object[] kvs,Object key,Object putval,Object expVal){\r\n    assert putval != null;\r\n    assert !(putval instanceof Prime);\r\n    assert !(expVal instanceof Prime);\r\n    final int fullhash = hash(key);\r\n    final int len = len(kvs);\r\n    final CHM chm = chm(kvs);\r\n    int idx = fullhash & (len - 1);\r\n    int reprobe_cnt = 0;\r\n    Object K = null, V = null;\r\n    Object[] newkvs = null;\r\n    while (true) {\r\n        V = val(kvs, idx);\r\n        K = key(kvs, idx);\r\n        if (K == null) {\r\n            if (putval == TOMBSTONE)\r\n                return putval;\r\n            if (CAS_key(kvs, idx, null, key)) {\r\n                chm._slots.add(1);\r\n                break;\r\n            }\r\n            K = key(kvs, idx);\r\n            assert K != null;\r\n        }\r\n        newkvs = chm._newkvs;\r\n        if (K == key)\r\n            break;\r\n        if (++reprobe_cnt >= reprobe_limit(len) || key == TOMBSTONE) {\r\n            newkvs = chm.resize(topmap, kvs);\r\n            if (expVal != null)\r\n                topmap.help_copy(newkvs);\r\n            return putIfMatch(topmap, newkvs, key, putval, expVal);\r\n        }\r\n        idx = (idx + 1) & (len - 1);\r\n    }\r\n    if (putval == V)\r\n        return V;\r\n    if (newkvs == null && ((V == null && chm.tableFull(reprobe_cnt, len)) || V instanceof Prime))\r\n        newkvs = chm.resize(topmap, kvs);\r\n    if (newkvs != null)\r\n        return putIfMatch(topmap, chm.copy_slot_and_check(topmap, kvs, idx, expVal), key, putval, expVal);\r\n    assert !(V instanceof Prime);\r\n    if (expVal != NO_MATCH_OLD && V != expVal && (expVal != MATCH_ANY || V == TOMBSTONE || V == null) && !(V == null && expVal == TOMBSTONE) && (expVal == null || !expVal.equals(V)))\r\n        return V;\r\n    if (CAS_val(kvs, idx, V, putval)) {\r\n        if (expVal != null) {\r\n            if ((V == null || V == TOMBSTONE) && putval != TOMBSTONE)\r\n                chm._size.add(1);\r\n            if (!(V == null || V == TOMBSTONE) && putval == TOMBSTONE)\r\n                chm._size.add(-1);\r\n        }\r\n    } else {\r\n        V = val(kvs, idx);\r\n        if (V instanceof Prime)\r\n            return putIfMatch(topmap, chm.copy_slot_and_check(topmap, kvs, idx, expVal), key, putval, expVal);\r\n    }\r\n    return (V == null && expVal != null) ? TOMBSTONE : V;\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setBaselineVersion",
	"Comment": "sets the version to tag an existing schema with when executing baseline.",
	"Method": "void setBaselineVersion(MigrationVersion baselineVersion){\r\n    this.baselineVersion = baselineVersion;\r\n}"
}, {
	"Path": "com.alibaba.excel.util.CollectionUtils.hasUniqueObject",
	"Comment": "determine whether the given collection only contains a single unique object.",
	"Method": "boolean hasUniqueObject(Collection<?> collection){\r\n    if (isEmpty(collection)) {\r\n        return false;\r\n    }\r\n    boolean hasCandidate = false;\r\n    Object candidate = null;\r\n    for (Object elem : collection) {\r\n        if (!hasCandidate) {\r\n            hasCandidate = true;\r\n            candidate = elem;\r\n        } else if (candidate != elem) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "water.rapids.ast.params.AstNumList.index",
	"Comment": "finds index of a given value in this number sequence, indexing start at 0.",
	"Method": "long index(long v){\r\n    int bIdx = findBase(v);\r\n    if (bIdx >= 0)\r\n        return water.util.ArrayUtils.sum(_cnts, 0, bIdx);\r\n    bIdx = -bIdx - 2;\r\n    if (bIdx < 0)\r\n        return -1L;\r\n    assert _bases[bIdx] < v;\r\n    long offset = v - (long) _bases[bIdx];\r\n    long stride = (long) _strides[bIdx];\r\n    if ((offset >= _cnts[bIdx] * stride) || (offset % stride != 0))\r\n        return -1L;\r\n    return water.util.ArrayUtils.sum(_cnts, 0, bIdx) + (offset / stride);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.NonAtomicVolatileUpdate.expressionFromUnaryTree",
	"Comment": "extracts the expression from a unarytree and applies a matcher to it.",
	"Method": "Matcher<UnaryTree> expressionFromUnaryTree(Matcher<ExpressionTree> exprMatcher){\r\n    return new Matcher<UnaryTree>() {\r\n        @Override\r\n        public boolean matches(UnaryTree tree, VisitorState state) {\r\n            return exprMatcher.matches(tree.getExpression(), state);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.NonAtomicVolatileUpdate.expressionFromUnaryTree",
	"Comment": "extracts the expression from a unarytree and applies a matcher to it.",
	"Method": "Matcher<UnaryTree> expressionFromUnaryTree(Matcher<ExpressionTree> exprMatcher){\r\n    return exprMatcher.matches(tree.getExpression(), state);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.ExceptionUtils.toMessage",
	"Comment": "transforms the details of this sqlexception into a nice readable message.",
	"Method": "String toMessage(SQLException e){\r\n    SQLException cause = e;\r\n    while (cause.getNextException() != null) {\r\n        cause = cause.getNextException();\r\n    }\r\n    String message = \"SQL State  : \" + cause.getSQLState() + \"\\n\" + \"Error Code : \" + cause.getErrorCode() + \"\\n\";\r\n    if (cause.getMessage() != null) {\r\n        message += \"Message    : \" + cause.getMessage().trim() + \"\\n\";\r\n    }\r\n    return message;\r\n}"
}, {
	"Path": "jsr166y.ForkJoinTask.reportException",
	"Comment": "throws exception, if any, associated with the given status.",
	"Method": "void reportException(int s){\r\n    Throwable ex = ((s == CANCELLED) ? new CancellationException() : (s == EXCEPTIONAL) ? getThrowableException() : null);\r\n    if (ex != null)\r\n        U.throwException(ex);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.h2.H2Schema.generateDropStatementsForCurrentSchema",
	"Comment": "generate the statements for dropping all the objects of this type in the current schema.",
	"Method": "List<String> generateDropStatementsForCurrentSchema(String objectType,List<String> objectNames){\r\n    List<String> statements = new ArrayList();\r\n    for (String objectName : objectNames) {\r\n        String dropStatement = \"DROP \" + objectType + database.quote(objectName);\r\n        statements.add(dropStatement);\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.StringUtils.countOccurrencesOf",
	"Comment": "counts the number of occurrences of this token in this string.",
	"Method": "int countOccurrencesOf(String str,String token){\r\n    if (str == null || token == null || str.length() == 0 || token.length() == 0) {\r\n        return 0;\r\n    }\r\n    int count = 0;\r\n    int pos = 0;\r\n    int idx;\r\n    while ((idx = str.indexOf(token, pos)) != -1) {\r\n        ++count;\r\n        pos = idx + token.length();\r\n    }\r\n    return count;\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.getAnnotation",
	"Comment": "retrieves an annotation, considering annotation inheritance.",
	"Method": "T getAnnotation(Tree tree,Class<T> annotationClass,T getAnnotation,Symbol sym,Class<T> annotationClass){\r\n    return sym == null ? null : sym.getAnnotation(annotationClass);\r\n}"
}, {
	"Path": "graphql.schema.idl.TypeDefinitionRegistry.merge",
	"Comment": "this will merge these type registries together and return this one",
	"Method": "TypeDefinitionRegistry merge(TypeDefinitionRegistry typeRegistry){\r\n    List<GraphQLError> errors = new ArrayList();\r\n    Map<String, TypeDefinition> tempTypes = new LinkedHashMap();\r\n    typeRegistry.types.values().forEach(newEntry -> {\r\n        Optional<GraphQLError> defined = define(this.types, tempTypes, newEntry);\r\n        defined.ifPresent(errors::add);\r\n    });\r\n    Map<String, DirectiveDefinition> tempDirectiveDefs = new LinkedHashMap();\r\n    typeRegistry.directiveDefinitions.values().forEach(newEntry -> {\r\n        Optional<GraphQLError> defined = define(this.directiveDefinitions, tempDirectiveDefs, newEntry);\r\n        defined.ifPresent(errors::add);\r\n    });\r\n    Map<String, ScalarTypeDefinition> tempScalarTypes = new LinkedHashMap();\r\n    typeRegistry.scalarTypes.values().forEach(newEntry -> define(this.scalarTypes, tempScalarTypes, newEntry).ifPresent(errors::add));\r\n    if (typeRegistry.schema != null && this.schema != null) {\r\n        errors.add(new SchemaRedefinitionError(this.schema, typeRegistry.schema));\r\n    }\r\n    if (!errors.isEmpty()) {\r\n        throw new SchemaProblem(errors);\r\n    }\r\n    if (this.schema == null) {\r\n        this.schema = typeRegistry.schema;\r\n    }\r\n    this.types.putAll(tempTypes);\r\n    this.scalarTypes.putAll(tempScalarTypes);\r\n    this.directiveDefinitions.putAll(tempDirectiveDefs);\r\n    typeRegistry.objectTypeExtensions.forEach((key, value) -> {\r\n        List<ObjectTypeExtensionDefinition> currentList = this.objectTypeExtensions.computeIfAbsent(key, k -> new ArrayList());\r\n        currentList.addAll(value);\r\n    });\r\n    typeRegistry.interfaceTypeExtensions.forEach((key, value) -> {\r\n        List<InterfaceTypeExtensionDefinition> currentList = this.interfaceTypeExtensions.computeIfAbsent(key, k -> new ArrayList());\r\n        currentList.addAll(value);\r\n    });\r\n    typeRegistry.unionTypeExtensions.forEach((key, value) -> {\r\n        List<UnionTypeExtensionDefinition> currentList = this.unionTypeExtensions.computeIfAbsent(key, k -> new ArrayList());\r\n        currentList.addAll(value);\r\n    });\r\n    typeRegistry.enumTypeExtensions.forEach((key, value) -> {\r\n        List<EnumTypeExtensionDefinition> currentList = this.enumTypeExtensions.computeIfAbsent(key, k -> new ArrayList());\r\n        currentList.addAll(value);\r\n    });\r\n    typeRegistry.scalarTypeExtensions.forEach((key, value) -> {\r\n        List<ScalarTypeExtensionDefinition> currentList = this.scalarTypeExtensions.computeIfAbsent(key, k -> new ArrayList());\r\n        currentList.addAll(value);\r\n    });\r\n    typeRegistry.inputObjectTypeExtensions.forEach((key, value) -> {\r\n        List<InputObjectTypeExtensionDefinition> currentList = this.inputObjectTypeExtensions.computeIfAbsent(key, k -> new ArrayList());\r\n        currentList.addAll(value);\r\n    });\r\n    return this;\r\n}"
}, {
	"Path": "com.google.errorprone.refaster.ExpressionTemplate.getPrecedence",
	"Comment": "returns the precedence level appropriate for unambiguously printing leaf as a subexpression ofits parent.",
	"Method": "int getPrecedence(JCTree leaf,Context context){\r\n    JCCompilationUnit comp = context.get(JCCompilationUnit.class);\r\n    JCTree parent = TreeInfo.pathFor(leaf, comp).get(1);\r\n    if (parent instanceof JCConditional) {\r\n        JCConditional conditional = (JCConditional) parent;\r\n        return TreeInfo.condPrec + ((conditional.cond == leaf) ? 1 : 0);\r\n    } else if (parent instanceof JCAssign) {\r\n        JCAssign assign = (JCAssign) parent;\r\n        return TreeInfo.assignPrec + ((assign.lhs == leaf) ? 1 : 0);\r\n    } else if (parent instanceof JCAssignOp) {\r\n        JCAssignOp assignOp = (JCAssignOp) parent;\r\n        return TreeInfo.assignopPrec + ((assignOp.lhs == leaf) ? 1 : 0);\r\n    } else if (parent instanceof JCUnary) {\r\n        return TreeInfo.opPrec(parent.getTag());\r\n    } else if (parent instanceof JCBinary) {\r\n        JCBinary binary = (JCBinary) parent;\r\n        return TreeInfo.opPrec(parent.getTag()) + ((binary.rhs == leaf) ? 1 : 0);\r\n    } else if (parent instanceof JCTypeCast) {\r\n        JCTypeCast typeCast = (JCTypeCast) parent;\r\n        return (typeCast.expr == leaf) ? TreeInfo.prefixPrec : TreeInfo.noPrec;\r\n    } else if (parent instanceof JCInstanceOf) {\r\n        JCInstanceOf instanceOf = (JCInstanceOf) parent;\r\n        return TreeInfo.ordPrec + ((instanceOf.clazz == leaf) ? 1 : 0);\r\n    } else if (parent instanceof JCArrayAccess) {\r\n        JCArrayAccess arrayAccess = (JCArrayAccess) parent;\r\n        return (arrayAccess.indexed == leaf) ? TreeInfo.postfixPrec : TreeInfo.noPrec;\r\n    } else if (parent instanceof JCFieldAccess) {\r\n        JCFieldAccess fieldAccess = (JCFieldAccess) parent;\r\n        return (fieldAccess.selected == leaf) ? TreeInfo.postfixPrec : TreeInfo.noPrec;\r\n    } else {\r\n        return TreeInfo.noPrec;\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.connectRetries",
	"Comment": "the maximum number of retries when attempting to connect to the database. after each failed attempt, flyway willwait 1 second before attempting to connect again, up to the maximum number of times specified by connectretries.",
	"Method": "FluentConfiguration connectRetries(int connectRetries){\r\n    config.setConnectRetries(connectRetries);\r\n    return this;\r\n}"
}, {
	"Path": "jsr166y.ForkJoinTask.expungeStaleExceptions",
	"Comment": "poll stale refs and remove them. call only while holding lock.",
	"Method": "void expungeStaleExceptions(){\r\n    for (Object x; (x = exceptionTableRefQueue.poll()) != null; ) {\r\n        if (x instanceof ExceptionNode) {\r\n            ForkJoinTask<?> key = ((ExceptionNode) x).get();\r\n            ExceptionNode[] t = exceptionTable;\r\n            int i = System.identityHashCode(key) & (t.length - 1);\r\n            ExceptionNode e = t[i];\r\n            ExceptionNode pred = null;\r\n            while (e != null) {\r\n                ExceptionNode next = e.next;\r\n                if (e == x) {\r\n                    if (pred == null)\r\n                        t[i] = next;\r\n                    else\r\n                        pred.next = next;\r\n                    break;\r\n                }\r\n                pred = e;\r\n                e = next;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "feign.template.QueryTemplate.expand",
	"Comment": "expand this template. unresolved variables are removed. if all values remain unresolved, theresult is an empty string.",
	"Method": "String expand(Map<String, ?> variables){\r\n    String name = this.name.expand(variables);\r\n    return this.queryString(name, super.expand(variables));\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.model.GCModel.get",
	"Comment": "get all types of events in the order they were added to the model.",
	"Method": "AbstractGCEvent<?> get(int index){\r\n    return allEvents.get(index);\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.TestDataReaderSun1_7_0G1.printAdaptiveSizePolicy",
	"Comment": "test parsing gc logs that have printadaptivesizepolicy turned on",
	"Method": "void printAdaptiveSizePolicy(){\r\n    TestLogHandler handler = new TestLogHandler();\r\n    handler.setLevel(Level.WARNING);\r\n    GCResource gcResource = new GcResourceFile(\"SampleSun1_7_0_12PrintAdaptiveSizePolicy.txt\");\r\n    gcResource.getLogger().addHandler(handler);\r\n    DataReader reader = getDataReader(gcResource);\r\n    GCModel model = reader.read();\r\n    assertEquals(\"gc pause\", 0.158757, model.getPause().getMax(), 0.000000001);\r\n    GCEvent heap = (GCEvent) model.getEvents().next();\r\n    assertEquals(\"heap\", 65 * 1024 * 1024, heap.getPreUsed());\r\n    assertEquals(\"heap\", 64.3 * 1024 * 1024, heap.getPostUsed(), 1e2);\r\n    assertEquals(\"heap\", 92.0 * 1024 * 1024, heap.getTotal(), 1e2);\r\n    assertEquals(\"number of errors\", 0, handler.getCount());\r\n}"
}, {
	"Path": "jsr166y.ConcurrentLinkedDeque.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    try {\r\n        return sun.misc.Unsafe.getUnsafe();\r\n    } catch (SecurityException se) {\r\n        try {\r\n            return java.security.AccessController.doPrivileged(new java.security.PrivilegedExceptionAction<sun.misc.Unsafe>() {\r\n                public sun.misc.Unsafe run() throws Exception {\r\n                    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n                    f.setAccessible(true);\r\n                    return (sun.misc.Unsafe) f.get(null);\r\n                }\r\n            });\r\n        } catch (java.security.PrivilegedActionException e) {\r\n            throw new RuntimeException(\"Could not initialize intrinsics\", e.getCause());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "jsr166y.ConcurrentLinkedDeque.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n    f.setAccessible(true);\r\n    return (sun.misc.Unsafe) f.get(null);\r\n}"
}, {
	"Path": "water.parser.CsvParser.determineSeparatorCounts",
	"Comment": "dermines the number of separators in given line.correctly handles quoted tokens.",
	"Method": "int[] determineSeparatorCounts(String from,byte singleQuote){\r\n    int[] result = new int[separators.length];\r\n    byte[] bits = StringUtils.bytesOf(from);\r\n    boolean inQuote = false;\r\n    for (byte c : bits) {\r\n        if ((c == singleQuote) || (c == CsvParser.CHAR_DOUBLE_QUOTE))\r\n            inQuote ^= true;\r\n        if (!inQuote || c == HIVE_SEP)\r\n            for (int i = 0; i < separators.length; ++i) if (c == separators[i])\r\n                ++result[i];\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.cockroachdb.CockroachDBSchema.generateDropStatementsForViews",
	"Comment": "generates the statements for dropping the views in this schema.",
	"Method": "List<String> generateDropStatementsForViews(){\r\n    List<String> names = jdbcTemplate.queryForStringList(\"SELECT table_name FROM information_schema.views\" + \" WHERE table_catalog=? AND table_schema='public'\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (String name : names) {\r\n        statements.add(\"DROP VIEW IF EXISTS \" + database.quote(this.name, name) + \" CASCADE\");\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.oracle.OracleSchema.locatorMetadataExists",
	"Comment": "checks whether oracle locator metadata exists for the schema.",
	"Method": "boolean locatorMetadataExists(){\r\n    return database.queryReturnsRows(\"SELECT * FROM ALL_SDO_GEOM_METADATA WHERE OWNER = ?\", name);\r\n}"
}, {
	"Path": "hex.glrm.GLRM.assignLossByCol",
	"Comment": "need to assign column loss for each column.however, due to constant columns being dropping, theloss function specified for a constant columns will no longer apply since we dropped that column.need to take care of this case to avoid errors.",
	"Method": "void assignLossByCol(int num_loss_by_cols,ArrayList<String> newColumnNames,String[] origColumnNames){\r\n    for (int i = 0; i < num_loss_by_cols; i++) {\r\n        int cidx = _parms._loss_by_col_idx == null ? i : _parms._loss_by_col_idx[i];\r\n        String colNames = origColumnNames[cidx];\r\n        if (cidx < 0 || cidx >= origColumnNames.length)\r\n            error(\"_loss_by_col_idx\", \"Column index \" + cidx + \" must be in [0,\" + _ncolA + \")\");\r\n        else if (newColumnNames.contains(colNames))\r\n            _lossFunc[newColumnNames.indexOf(colNames)] = _parms._loss_by_col[i];\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.AbbreviationUtils.abbreviateDescription",
	"Comment": "abbreviates this description to a length that will fit in the database.",
	"Method": "String abbreviateDescription(String description){\r\n    if (description == null) {\r\n        return null;\r\n    }\r\n    if (description.length() <= 200) {\r\n        return description;\r\n    }\r\n    return description.substring(0, 197) + \"...\";\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.ctrl.impl.GCViewerGuiController.copyPreferencesFromGui",
	"Comment": "copies values that are stored in menu items into gcpreferences instance.",
	"Method": "GCPreferences copyPreferencesFromGui(GCViewerGui gui){\r\n    GCPreferences preferences = gui.getPreferences();\r\n    for (Entry<String, JCheckBoxMenuItem> menuEntry : ((GCViewerGuiMenuBar) gui.getJMenuBar()).getViewMenuItems().entrySet()) {\r\n        JCheckBoxMenuItem item = menuEntry.getValue();\r\n        preferences.setGcLineProperty(item.getActionCommand(), item.getState());\r\n    }\r\n    preferences.setWindowWidth(gui.getWidth());\r\n    preferences.setWindowHeight(gui.getHeight());\r\n    preferences.setWindowX(gui.getX());\r\n    preferences.setWindowY(gui.getY());\r\n    OpenFile openFileAction = (OpenFile) gui.getActionMap().get(ActionCommands.OPEN_FILE.toString());\r\n    if (openFileAction.getLastSelectedFiles().length != 0) {\r\n        preferences.setLastFile(openFileAction.getLastSelectedFiles()[0].getAbsolutePath());\r\n    }\r\n    List<String> recentFileList = new LinkedList<String>();\r\n    for (GCResourceGroup urlSet : ((GCViewerGuiMenuBar) gui.getJMenuBar()).getRecentGCResourcesModel().getResourceNameGroups()) {\r\n        recentFileList.add(urlSet.getUrlGroupString());\r\n    }\r\n    preferences.setRecentFiles(recentFileList);\r\n    return preferences;\r\n}"
}, {
	"Path": "hex.Model.deleteCrossValidationPreds",
	"Comment": "delete from the output all associated cv predictions from dkv.",
	"Method": "void deleteCrossValidationPreds(){\r\n    if (_output._cross_validation_predictions != null) {\r\n        Log.info(\"Cleaning up CV Predictions for \" + this._key.toString());\r\n        int count = deleteAll(_output._cross_validation_predictions);\r\n        Log.info(count + \" CV predictions were removed\");\r\n    }\r\n    if (_output._cross_validation_holdout_predictions_frame_id != null) {\r\n        _output._cross_validation_holdout_predictions_frame_id.remove();\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.fixes.Fix.getShortDescription",
	"Comment": "a short description which can be attached to the fix to differentiate multiple fixes providedto the user.empty string generates the default description.",
	"Method": "String getShortDescription(){\r\n    return \"\";\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.contains",
	"Comment": "applies the given matcher recursively to all descendants of an ast node, and matches if anymatching descendant node is found.",
	"Method": "Matcher<Tree> contains(Matcher<Tree> treeMatcher,Matcher<T> contains,Class<V> clazz,Matcher<V> treeMatcher){\r\n    final Matcher<Tree> contains = new Contains(toType(clazz, treeMatcher));\r\n    return contains::matches;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.postgresql.PostgreSQLSchema.generateDropStatementsForEnums",
	"Comment": "generates the statements for dropping the enums in this schema.",
	"Method": "List<String> generateDropStatementsForEnums(){\r\n    List<String> enumNames = jdbcTemplate.queryForStringList(\"SELECT t.typname FROM pg_catalog.pg_type t INNER JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace WHERE n.nspname = ? and t.typtype = 'e'\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (String enumName : enumNames) {\r\n        statements.add(\"DROP TYPE \" + database.quote(name, enumName));\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "com.google.errorprone.refaster.URepeated.getUnderlyingBinding",
	"Comment": "gets the binding of the underlying identifier in the unifier.",
	"Method": "JCExpression getUnderlyingBinding(Unifier unifier){\r\n    return (unifier == null) ? null : unifier.getBinding(new UFreeIdent.Key(identifier()));\r\n}"
}, {
	"Path": "com.google.errorprone.CompilationTestHelper.withClasspath",
	"Comment": "sets the classpath for the test compilation, overriding the default of using the runtimeclasspath of the test execution. this is useful to verify correct behavior when the classpathis incomplete.",
	"Method": "CompilationTestHelper withClasspath(Class<?> classes){\r\n    this.overrideClasspath = ImmutableList.copyOf(classes);\r\n    return this;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.SqlStatementBuilder.tokenizeLine",
	"Comment": "ignore all special characters that naturally occur in sql, but are not opening or closing string literals.",
	"Method": "Collection<String> tokenizeLine(String line){\r\n    return StringUtils.tokenizeToStringCollection(line, \" @<>;:=|(),+{}\");\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.AbstractTestExceptionChecker.buildFix",
	"Comment": "if this is a problem, consider trying to detect and avoid that case.",
	"Method": "SuggestedFix buildFix(VisitorState state,SuggestedFix.Builder fix,JCExpression expectedException,List<? extends StatementTree> statements){\r\n    fix.addStaticImport(\"org.junit.Assert.assertThrows\");\r\n    StringBuilder prefix = new StringBuilder();\r\n    prefix.append(String.format(\"assertThrows(%s, () -> \", state.getSourceForNode(expectedException)));\r\n    if (statements.size() == 1 && getOnlyElement(statements) instanceof ExpressionStatementTree) {\r\n        ExpressionTree expression = ((ExpressionStatementTree) getOnlyElement(statements)).getExpression();\r\n        fix.prefixWith(expression, prefix.toString());\r\n        fix.postfixWith(expression, \")\");\r\n    } else if (!statements.isEmpty()) {\r\n        prefix.append(\" {\");\r\n        fix.prefixWith(statements.iterator().next(), prefix.toString());\r\n        fix.postfixWith(getLast(statements), \"});\");\r\n    }\r\n    return fix.build();\r\n}"
}, {
	"Path": "graphql.schema.GraphQLUnionType.transform",
	"Comment": "this helps you transform the current graphqluniontype into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLUnionType transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newUnionType(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "hex.ModelBuilder.desiredChunks",
	"Comment": "find desired number of chunks. if fewer, dataset will be rebalanced.",
	"Method": "int desiredChunks(Frame original_fr,boolean local){\r\n    if (H2O.getCloudSize() > 1 && Boolean.parseBoolean(getSysProperty(\"rebalance.enableMulti\", \"false\")))\r\n        return desiredChunkMulti(original_fr);\r\n    else\r\n        return desiredChunkSingle(original_fr);\r\n}"
}, {
	"Path": "water.nbhm.NonBlockingIdentityHashMap.clone",
	"Comment": "creates a shallow copy of this hashtable. all the structure of thehashtable itself is copied, but the keys and values are not cloned.this is a relatively expensive operation.",
	"Method": "Object clone(){\r\n    try {\r\n        NonBlockingIdentityHashMap<TypeK, TypeV> t = (NonBlockingIdentityHashMap<TypeK, TypeV>) super.clone();\r\n        t.clear();\r\n        for (TypeK K : keySet()) {\r\n            final TypeV V = get(K);\r\n            t.put(K, V);\r\n        }\r\n        return t;\r\n    } catch (CloneNotSupportedException e) {\r\n        throw new InternalError();\r\n    }\r\n}"
}, {
	"Path": "ai.h2o.automl.targetencoding.TargetEncodingLeaveOneOutStrategyTest.comparisonBetweenEmptyStringAndNonEmptyStringForLOOStrategyTest",
	"Comment": "test that empty strings create same encodings as nonempty strings",
	"Method": "void comparisonBetweenEmptyStringAndNonEmptyStringForLOOStrategyTest(){\r\n    String targetColumnName = \"ColB\";\r\n    fr = new TestFrameBuilder().withName(\"testFrame\").withColNames(\"ColA\", targetColumnName).withVecTypes(Vec.T_CAT, Vec.T_CAT).withDataForCol(0, ar(\"a\", \"b\", \"\", \"\", \"\")).withDataForCol(1, ar(\"2\", \"6\", \"2\", \"2\", \"6\")).build();\r\n    Frame fr2 = new TestFrameBuilder().withName(\"testFrame2\").withColNames(\"ColA\", targetColumnName).withVecTypes(Vec.T_CAT, Vec.T_CAT).withDataForCol(0, ar(\"a\", \"b\", \"na\", \"na\", \"na\")).withDataForCol(1, ar(\"2\", \"6\", \"2\", \"2\", \"6\")).build();\r\n    BlendingParams params = new BlendingParams(20, 10);\r\n    String[] teColumns = { \"ColA\" };\r\n    TargetEncoder tec = new TargetEncoder(teColumns, params);\r\n    Map<String, Frame> targetEncodingMap = tec.prepareEncodingMap(fr, targetColumnName, null);\r\n    Frame resultWithEncoding = tec.applyTargetEncoding(fr, targetColumnName, targetEncodingMap, TargetEncoder.DataLeakageHandlingStrategy.LeaveOneOut, true, 0.0, false, 1234, true);\r\n    Map<String, Frame> targetEncodingMap2 = tec.prepareEncodingMap(fr2, targetColumnName, null);\r\n    Frame resultWithEncoding2 = tec.applyTargetEncoding(fr2, targetColumnName, targetEncodingMap2, TargetEncoder.DataLeakageHandlingStrategy.LeaveOneOut, true, 0.0, false, 1234, true);\r\n    printOutFrameAsTable(resultWithEncoding);\r\n    printOutFrameAsTable(resultWithEncoding2);\r\n    assertVecEquals(resultWithEncoding.vec(\"ColA_te\"), resultWithEncoding2.vec(\"ColA_te\"), 1e-5);\r\n    encodingMapCleanUp(targetEncodingMap);\r\n    encodingMapCleanUp(targetEncodingMap2);\r\n    fr2.delete();\r\n    resultWithEncoding.delete();\r\n    resultWithEncoding2.delete();\r\n}"
}, {
	"Path": "jsr166y.Phaser.awaitAdvance",
	"Comment": "awaits the phase of this phaser to advance from the given phasevalue, returning immediately if the current phase is not equalto the given phase value or this phaser is terminated.",
	"Method": "int awaitAdvance(int phase){\r\n    final Phaser root = this.root;\r\n    long s = (root == this) ? state : reconcileState();\r\n    int p = (int) (s >>> PHASE_SHIFT);\r\n    if (phase < 0)\r\n        return phase;\r\n    if (p == phase)\r\n        return root.internalAwaitAdvance(phase, null);\r\n    return p;\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.crawler.CrawlConfig.setProcessBinaryContentInCrawling",
	"Comment": "should we process binary content such as images, audio, ... using tika?",
	"Method": "void setProcessBinaryContentInCrawling(boolean processBinaryContentInCrawling){\r\n    this.processBinaryContentInCrawling = processBinaryContentInCrawling;\r\n}"
}, {
	"Path": "hex.AUC2.compute_auc",
	"Comment": "points.tpr and fpr are monotonically increasing from 0 to 1.",
	"Method": "double compute_auc(){\r\n    if (_fps[_nBins - 1] == 0)\r\n        return 1.0;\r\n    if (_tps[_nBins - 1] == 0)\r\n        return 0.0;\r\n    double tp0 = 0, fp0 = 0;\r\n    double area = 0;\r\n    for (int i = 0; i < _nBins; i++) {\r\n        area += (_fps[i] - fp0) * (_tps[i] + tp0) / 2.0;\r\n        tp0 = _tps[i];\r\n        fp0 = _fps[i];\r\n    }\r\n    return area / _p / _n;\r\n}"
}, {
	"Path": "hex.glm.GLMTest.test_COD_Airlines_SingleLambda",
	"Comment": "once on explicitly expanded data, once on h2o autoexpanded and compare the results",
	"Method": "void test_COD_Airlines_SingleLambda(){\r\n    GLMModel model1 = null;\r\n    Frame fr = parse_test_file(Key.make(\"Airlines\"), \"smalldata/airlines/AirlinesTrain.csv.zip\");\r\n    String[] ignoredCols = new String[] { \"IsDepDelayed_REC\" };\r\n    try {\r\n        Scope.enter();\r\n        GLMParameters params = new GLMParameters(Family.binomial);\r\n        params._response_column = \"IsDepDelayed\";\r\n        params._ignored_columns = ignoredCols;\r\n        params._train = fr._key;\r\n        params._valid = fr._key;\r\n        params._lambda = new double[] { 0.01 };\r\n        params._alpha = new double[] { 1 };\r\n        params._standardize = false;\r\n        params._solver = Solver.COORDINATE_DESCENT_NAIVE;\r\n        params._lambda_search = true;\r\n        params._nlambdas = 5;\r\n        GLM glm = new GLM(params);\r\n        model1 = glm.trainModel().get();\r\n        double[] beta = model1.beta();\r\n        double l1pen = ArrayUtils.l1norm(beta, true);\r\n        double l2pen = ArrayUtils.l2norm2(beta, true);\r\n    } finally {\r\n        fr.delete();\r\n        if (model1 != null)\r\n            model1.delete();\r\n    }\r\n}"
}, {
	"Path": "graphql.schema.GraphQLFieldDefinition.getDataFetcher",
	"Comment": "to be removed in a future version when all code is in the code registry",
	"Method": "DataFetcher getDataFetcher(){\r\n    return dataFetcherFactory.get(newDataFetchingFactoryEnvironment().fieldDefinition(this).build());\r\n}"
}, {
	"Path": "water.api.Schema.createAndFillImpl",
	"Comment": "convenience helper which creates and fills an impl object from this schema.",
	"Method": "I createAndFillImpl(){\r\n    return this.fillImpl(this.createImpl());\r\n}"
}, {
	"Path": "feign.benchmark.WhatShouldWeCacheBenchmarks.buildAndQuery_fake_cachedApi",
	"Comment": "how fast is our advice to use a cached api for each http request, without considering network?",
	"Method": "Response buildAndQuery_fake_cachedApi(){\r\n    return cachedFakeApi.query();\r\n}"
}, {
	"Path": "com.google.errorprone.names.NeedlemanWunschEditDistance.getWorstCaseEditDistance",
	"Comment": "return the worst case edit distance between strings of this length",
	"Method": "int getWorstCaseEditDistance(int sourceLength,int targetLength,int changeCost,int openGapCost,int continueGapCost){\r\n    int maxLen = Math.max(sourceLength, targetLength);\r\n    int minLen = Math.min(sourceLength, targetLength);\r\n    int totChangeCost = scriptCost(openGapCost, continueGapCost, maxLen - minLen) + minLen * changeCost;\r\n    int blowAwayCost = scriptCost(openGapCost, continueGapCost, sourceLength) + scriptCost(openGapCost, continueGapCost, targetLength);\r\n    return Math.min(totChangeCost, blowAwayCost);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.DatabaseFactory.createDatabase",
	"Comment": "initializes the appropriate database class for the database product used by the data source.",
	"Method": "Database createDatabase(Configuration configuration,boolean printInfo,Database createDatabase,DatabaseType databaseType,Configuration configuration,Connection connection,boolean originalAutoCommit){\r\n    switch(databaseType) {\r\n        case COCKROACHDB:\r\n            return new CockroachDBDatabase(configuration, connection, originalAutoCommit);\r\n        case DB2:\r\n            return new DB2Database(configuration, connection, originalAutoCommit);\r\n        case DERBY:\r\n            return new DerbyDatabase(configuration, connection, originalAutoCommit);\r\n        case H2:\r\n            return new H2Database(configuration, connection, originalAutoCommit);\r\n        case HSQLDB:\r\n            return new HSQLDBDatabase(configuration, connection, originalAutoCommit);\r\n        case INFORMIX:\r\n            return new InformixDatabase(configuration, connection, originalAutoCommit);\r\n        case MARIADB:\r\n        case MYSQL:\r\n            return new MySQLDatabase(configuration, connection, originalAutoCommit);\r\n        case ORACLE:\r\n            return new OracleDatabase(configuration, connection, originalAutoCommit);\r\n        case POSTGRESQL:\r\n            return new PostgreSQLDatabase(configuration, connection, originalAutoCommit);\r\n        case REDSHIFT:\r\n            return new RedshiftDatabase(configuration, connection, originalAutoCommit);\r\n        case SQLITE:\r\n            return new SQLiteDatabase(configuration, connection, originalAutoCommit);\r\n        case SAPHANA:\r\n            return new SAPHANADatabase(configuration, connection, originalAutoCommit);\r\n        case SQLSERVER:\r\n            return new SQLServerDatabase(configuration, connection, originalAutoCommit);\r\n        case SYBASEASE_JCONNECT:\r\n        case SYBASEASE_JTDS:\r\n            return new SybaseASEDatabase(configuration, connection, originalAutoCommit);\r\n        default:\r\n            throw new FlywayException(\"Unsupported Database: \" + databaseType.name());\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.names.TermEditDistance.computeCost",
	"Comment": "compute the total cost of this assignment including the costs of unassigned source and targetterms.",
	"Method": "double computeCost(int[] assignments,double[][] costMatrix,double[] sourceTermDeletionCosts,double[] targetTermDeletionCosts){\r\n    double totalCost = DoubleStream.of(targetTermDeletionCosts).sum();\r\n    for (int sourceTermIndex = 0; sourceTermIndex < assignments.length; sourceTermIndex++) {\r\n        int targetTermIndex = assignments[sourceTermIndex];\r\n        if (targetTermIndex == -1) {\r\n            totalCost += sourceTermDeletionCosts[sourceTermIndex];\r\n        } else {\r\n            totalCost += costMatrix[sourceTermIndex][targetTermIndex];\r\n            totalCost -= targetTermDeletionCosts[targetTermIndex];\r\n        }\r\n    }\r\n    return totalCost;\r\n}"
}, {
	"Path": "hex.tree.drf.DRFModel.score0",
	"Comment": "bulk scoring api for one row.chunks are all compatible with the model, and expect the last chunks are for the final distribution and prediction. default method is to just load the data into the tmp array, then call subclass scoring logic.",
	"Method": "double[] score0(double[] data,double[] preds,double offset,int ntrees){\r\n    super.score0(data, preds, offset, ntrees);\r\n    int N = _output._ntrees;\r\n    if (_output.nclasses() == 1) {\r\n        if (N >= 1)\r\n            preds[0] /= N;\r\n    } else {\r\n        if (_output.nclasses() == 2 && binomialOpt()) {\r\n            if (N >= 1) {\r\n                preds[1] /= N;\r\n            }\r\n            preds[2] = 1. - preds[1];\r\n        } else {\r\n            double sum = MathUtils.sum(preds);\r\n            if (sum > 0)\r\n                MathUtils.div(preds, sum);\r\n        }\r\n    }\r\n    return preds;\r\n}"
}, {
	"Path": "com.google.errorprone.apply.SourceFile.getFragmentByLines",
	"Comment": "returns a fragment of the source code between the two stated line numbers. the parametersrepresent inclusive line numbers.the returned fragment will end in a newline.",
	"Method": "String getFragmentByLines(int startLine,int endLine){\r\n    Preconditions.checkArgument(startLine <= endLine);\r\n    return Joiner.on(\"\\n\").join(getLines(startLine, endLine)) + \"\\n\";\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.command.DbMigrate.applyMigrations",
	"Comment": "applies this migration to the database. the migration state and the execution time are updated accordingly.",
	"Method": "void applyMigrations(LinkedHashMap<MigrationInfoImpl, Boolean> group){\r\n    boolean executeGroupInTransaction = isExecuteGroupInTransaction(group);\r\n    final StopWatch stopWatch = new StopWatch();\r\n    try {\r\n        if (executeGroupInTransaction) {\r\n            new TransactionTemplate(connectionUserObjects.getJdbcConnection()).execute(new Callable<Object>() {\r\n                @Override\r\n                public Object call() {\r\n                    doMigrateGroup(group, stopWatch);\r\n                    return null;\r\n                }\r\n            });\r\n        } else {\r\n            doMigrateGroup(group, stopWatch);\r\n        }\r\n    } catch (FlywayMigrateException e) {\r\n        MigrationInfoImpl migration = e.getMigration();\r\n        String failedMsg = \"Migration of \" + toMigrationText(migration, e.isOutOfOrder()) + \" failed!\";\r\n        if (database.supportsDdlTransactions() && executeGroupInTransaction) {\r\n            LOG.error(failedMsg + \" Changes successfully rolled back.\");\r\n        } else {\r\n            LOG.error(failedMsg + \" Please restore backups and roll back database and code!\");\r\n            stopWatch.stop();\r\n            int executionTime = (int) stopWatch.getTotalTimeMillis();\r\n            schemaHistory.addAppliedMigration(migration.getVersion(), migration.getDescription(), migration.getType(), migration.getScript(), migration.getResolvedMigration().getChecksum(), executionTime, false);\r\n        }\r\n        throw e;\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.command.DbMigrate.applyMigrations",
	"Comment": "applies this migration to the database. the migration state and the execution time are updated accordingly.",
	"Method": "void applyMigrations(LinkedHashMap<MigrationInfoImpl, Boolean> group){\r\n    doMigrateGroup(group, stopWatch);\r\n    return null;\r\n}"
}, {
	"Path": "hex.glm.GLMTest.testBigPOJO",
	"Comment": "test large glm pojo model generation. make a 10k predictor model, emit, javac, and score with it.",
	"Method": "void testBigPOJO(){\r\n    GLMModel model = null;\r\n    Frame fr = parse_test_file(Key.make(\"arcene_parsed\"), \"smalldata/glm_test/arcene.csv\"), res = null;\r\n    try {\r\n        Scope.enter();\r\n        GLMParameters params = new GLMParameters(Family.gaussian);\r\n        params._lambda = null;\r\n        params._response_column = fr._names[0];\r\n        params._train = fr._key;\r\n        params._max_active_predictors = 100000;\r\n        params._alpha = new double[] { 0 };\r\n        params._solver = Solver.L_BFGS;\r\n        GLM glm = new GLM(params);\r\n        model = glm.trainModel().get();\r\n        res = model.score(fr);\r\n        model.testJavaScoring(fr, res, 0.0);\r\n    } finally {\r\n        fr.delete();\r\n        if (model != null)\r\n            model.delete();\r\n        if (res != null)\r\n            res.delete();\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaDirectiveWiring.onInputObjectField",
	"Comment": "this is called when an input object field is encountered, which gives the schema directive a chance to modify the shape and behaviourof that dslelement",
	"Method": "GraphQLInputObjectField onInputObjectField(SchemaDirectiveWiringEnvironment<GraphQLInputObjectField> environment){\r\n    return environment.getElement();\r\n}"
}, {
	"Path": "water.parser.Parser.getNextFile",
	"Comment": "this method will try to get the next file to be parsed.it will skip over directories if encountered.",
	"Method": "void getNextFile(InputStream is){\r\n    if (is instanceof java.util.zip.ZipInputStream) {\r\n        ZipEntry ze = ((ZipInputStream) is).getNextEntry();\r\n        while (ze != null && ze.isDirectory()) ze = ((ZipInputStream) is).getNextEntry();\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.SqlStatementBuilder.isTerminated",
	"Comment": "checks whether the statement being built is now properly terminated.",
	"Method": "boolean isTerminated(){\r\n    return terminated;\r\n}"
}, {
	"Path": "org.flywaydb.core.Flyway.baseline",
	"Comment": "baselines an existing database, excluding all migrations up to and including baselineversion.",
	"Method": "void baseline(){\r\n    execute(new Command<Void>() {\r\n        public Void execute(MigrationResolver migrationResolver, SchemaHistory schemaHistory, Database database, Schema[] schemas, CallbackExecutor callbackExecutor) {\r\n            new DbSchemas(database, schemas, schemaHistory).create();\r\n            doBaseline(schemaHistory, database, schemas, callbackExecutor);\r\n            return null;\r\n        }\r\n    }, false);\r\n}"
}, {
	"Path": "org.flywaydb.core.Flyway.baseline",
	"Comment": "baselines an existing database, excluding all migrations up to and including baselineversion.",
	"Method": "void baseline(){\r\n    new DbSchemas(database, schemas, schemaHistory).create();\r\n    doBaseline(schemaHistory, database, schemas, callbackExecutor);\r\n    return null;\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlusBuilder.setCancelable",
	"Comment": "define if the dialog is cancelable and should be closed when back pressed or click outside is pressed",
	"Method": "DialogPlusBuilder setCancelable(boolean isCancelable){\r\n    this.isCancelable = isCancelable;\r\n    return this;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.ReturnValueIgnored.methodReceiverHasType",
	"Comment": "matches method calls whose receiver objects are of a type included in the set.",
	"Method": "Matcher<ExpressionTree> methodReceiverHasType(Set<String> typeSet){\r\n    return new Matcher<ExpressionTree>() {\r\n        @Override\r\n        public boolean matches(ExpressionTree expressionTree, VisitorState state) {\r\n            Type receiverType = ASTHelpers.getReceiverType(expressionTree);\r\n            return typeSet.contains(receiverType.toString());\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.ReturnValueIgnored.methodReceiverHasType",
	"Comment": "matches method calls whose receiver objects are of a type included in the set.",
	"Method": "Matcher<ExpressionTree> methodReceiverHasType(Set<String> typeSet){\r\n    Type receiverType = ASTHelpers.getReceiverType(expressionTree);\r\n    return typeSet.contains(receiverType.toString());\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.JUnitMatchers.hasJUnitAttr",
	"Comment": "checks if a method symbol has any attribute from the org.junit package.",
	"Method": "boolean hasJUnitAttr(MethodSymbol methodSym){\r\n    return methodSym.getRawAttributes().stream().anyMatch(attr -> attr.type.tsym.getQualifiedName().toString().startsWith(\"org.junit.\"));\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.argumentselectiondefects.Costs.invalidateAllAlternatives",
	"Comment": "set the cost of all the alternatives for this formal parameter to be inf.",
	"Method": "void invalidateAllAlternatives(Parameter formal){\r\n    for (int actualIndex = 0; actualIndex < costMatrix[formal.index()].length; actualIndex++) {\r\n        if (actualIndex != formal.index()) {\r\n            costMatrix[formal.index()][actualIndex] = Double.POSITIVE_INFINITY;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "graphql.GraphQL.transform",
	"Comment": "this helps you transform the current graphql object into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQL transform(Consumer<GraphQL.Builder> builderConsumer){\r\n    Builder builder = new Builder(this.graphQLSchema);\r\n    builder.queryExecutionStrategy(nvl(this.queryStrategy, builder.queryExecutionStrategy)).mutationExecutionStrategy(nvl(this.mutationStrategy, builder.mutationExecutionStrategy)).subscriptionExecutionStrategy(nvl(this.subscriptionStrategy, builder.subscriptionExecutionStrategy)).executionIdProvider(nvl(this.idProvider, builder.idProvider)).instrumentation(nvl(this.instrumentation, builder.instrumentation)).preparsedDocumentProvider(nvl(this.preparsedDocumentProvider, builder.preparsedDocumentProvider));\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "graphql.util.FpKit.toCollection",
	"Comment": "converts an object that should be an iterable into a collection efficiently, leavingit alone if it is already is one.useful when you want to get the size of something",
	"Method": "Collection<T> toCollection(Object iterableResult){\r\n    if (iterableResult.getClass().isArray()) {\r\n        List<Object> collect = IntStream.range(0, Array.getLength(iterableResult)).mapToObj(i -> Array.get(iterableResult, i)).collect(Collectors.toList());\r\n        return (List<T>) collect;\r\n    }\r\n    if (iterableResult instanceof Collection) {\r\n        return (Collection<T>) iterableResult;\r\n    }\r\n    Iterable<T> iterable = (Iterable<T>) iterableResult;\r\n    Iterator<T> iterator = iterable.iterator();\r\n    List<T> list = new ArrayList();\r\n    while (iterator.hasNext()) {\r\n        list.add(iterator.next());\r\n    }\r\n    return list;\r\n}"
}, {
	"Path": "feign.RequestTemplate.hasRequestVariable",
	"Comment": "return if the variable exists on the uri, query, or headers, in this template.",
	"Method": "boolean hasRequestVariable(String variable){\r\n    return this.getRequestVariables().contains(variable);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.jdbc.JdbcTemplate.queryForBoolean",
	"Comment": "executes this query with these parameters against this connection.",
	"Method": "boolean queryForBoolean(String query,String params){\r\n    PreparedStatement statement = null;\r\n    ResultSet resultSet = null;\r\n    boolean result;\r\n    try {\r\n        statement = prepareStatement(query, params);\r\n        resultSet = statement.executeQuery();\r\n        resultSet.next();\r\n        result = resultSet.getBoolean(1);\r\n    } finally {\r\n        JdbcUtils.closeResultSet(resultSet);\r\n        JdbcUtils.closeStatement(statement);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.scanner.filesystem.FileSystemScanner.findResourceNamesFromFileSystem",
	"Comment": "finds all the resource names contained in this file system folder.",
	"Method": "Set<String> findResourceNamesFromFileSystem(String scanRootLocation,File folder){\r\n    LOG.debug(\"Scanning for resources in path: \" + folder.getPath() + \" (\" + scanRootLocation + \")\");\r\n    Set<String> resourceNames = new TreeSet();\r\n    File[] files = folder.listFiles();\r\n    for (File file : files) {\r\n        if (file.canRead()) {\r\n            if (file.isDirectory()) {\r\n                if (file.isHidden()) {\r\n                    LOG.debug(\"Skipping hidden directory: \" + file.getAbsolutePath());\r\n                } else {\r\n                    resourceNames.addAll(findResourceNamesFromFileSystem(scanRootLocation, file));\r\n                }\r\n            } else {\r\n                resourceNames.add(file.getPath());\r\n            }\r\n        }\r\n    }\r\n    return resourceNames;\r\n}"
}, {
	"Path": "water.H2O.nidx",
	"Comment": "find the node index for this h2onode, or a negative number on a miss",
	"Method": "int nidx(H2ONode h2o){\r\n    return java.util.Arrays.binarySearch(_memary, h2o);\r\n}"
}, {
	"Path": "graphql.execution.instrumentation.SimpleInstrumentationContext.whenCompleted",
	"Comment": "allows for the more fluent away to return an instrumentation context that runs the specifiedcode on instrumentation step completion.",
	"Method": "SimpleInstrumentationContext<U> whenCompleted(BiConsumer<U, Throwable> codeToRun){\r\n    return new SimpleInstrumentationContext(null, codeToRun);\r\n}"
}, {
	"Path": "water.api.MetadataHandler.listRoutes",
	"Comment": "return a list of all rest api routes and a markdown table of contents.",
	"Method": "MetadataV3 listRoutes(int version,MetadataV3 docs){\r\n    MarkdownBuilder builder = new MarkdownBuilder();\r\n    builder.comment(\"Preview with http://jbt.github.io/markdown-editor\");\r\n    builder.heading1(\"REST API Routes Table of Contents\");\r\n    builder.hline();\r\n    builder.tableHeader(\"HTTP method\", \"URI pattern\", \"Input schema\", \"Output schema\", \"Summary\");\r\n    docs.routes = new RouteV3[RequestServer.numRoutes()];\r\n    int i = 0;\r\n    for (Route route : RequestServer.routes()) {\r\n        RouteV3 schema = new RouteV3(route);\r\n        docs.routes[i] = schema;\r\n        MetadataV3 look = new MetadataV3();\r\n        look.routes = new RouteV3[1];\r\n        look.routes[0] = schema;\r\n        look.path = route._url;\r\n        look.http_method = route._http_method;\r\n        fetchRoute(version, look);\r\n        schema.input_schema = look.routes[0].input_schema;\r\n        schema.output_schema = look.routes[0].output_schema;\r\n        builder.tableRow(route._http_method, route._url, Handler.getHandlerMethodInputSchema(route._handler_method).getSimpleName(), Handler.getHandlerMethodOutputSchema(route._handler_method).getSimpleName(), route._summary);\r\n        i++;\r\n    }\r\n    docs.markdown = builder.toString();\r\n    return docs;\r\n}"
}, {
	"Path": "hex.tree.Score.getScoringChunks",
	"Comment": "scoring chunks are those chunks that make the input to one of the scoring functions",
	"Method": "Chunk[] getScoringChunks(Chunk[] allChunks){\r\n    if (_preds == null)\r\n        return allChunks;\r\n    Chunk[] chks = new Chunk[allChunks.length - _preds.numCols()];\r\n    System.arraycopy(allChunks, 0, chks, 0, chks.length);\r\n    return chks;\r\n}"
}, {
	"Path": "jsr166y.ForkJoinTask.get",
	"Comment": "waits if necessary for at most the given time for the computationto complete, and then retrieves its result, if available.",
	"Method": "V get(V get,long timeout,TimeUnit unit){\r\n    if (Thread.interrupted())\r\n        throw new InterruptedException();\r\n    int s;\r\n    long ns, ms;\r\n    if ((s = status) >= 0 && (ns = unit.toNanos(timeout)) > 0L) {\r\n        long deadline = System.nanoTime() + ns;\r\n        ForkJoinPool p = null;\r\n        ForkJoinPool.WorkQueue w = null;\r\n        Thread t = Thread.currentThread();\r\n        if (t instanceof ForkJoinWorkerThread) {\r\n            ForkJoinWorkerThread wt = (ForkJoinWorkerThread) t;\r\n            p = wt.pool;\r\n            w = wt.workQueue;\r\n            s = p.helpJoinOnce(w, this);\r\n        }\r\n        boolean canBlock = false;\r\n        boolean interrupted = false;\r\n        try {\r\n            while ((s = status) >= 0) {\r\n                if (w != null && w.runState < 0)\r\n                    cancelIgnoringExceptions(this);\r\n                else if (!canBlock) {\r\n                    if (p == null || p.tryCompensate(this, null))\r\n                        canBlock = true;\r\n                } else {\r\n                    if ((ms = TimeUnit.NANOSECONDS.toMillis(ns)) > 0L && U.compareAndSwapInt(this, STATUS, s, s | SIGNAL)) {\r\n                        synchronized (this) {\r\n                            if (status >= 0) {\r\n                                try {\r\n                                    wait(ms);\r\n                                } catch (InterruptedException ie) {\r\n                                    if (p == null)\r\n                                        interrupted = true;\r\n                                }\r\n                            } else\r\n                                notifyAll();\r\n                        }\r\n                    }\r\n                    if ((s = status) < 0 || interrupted || (ns = deadline - System.nanoTime()) <= 0L)\r\n                        break;\r\n                }\r\n            }\r\n        } finally {\r\n            if (p != null && canBlock)\r\n                p.incrementActiveCount();\r\n        }\r\n        if (interrupted)\r\n            throw new InterruptedException();\r\n    }\r\n    if ((s &= DONE_MASK) != NORMAL) {\r\n        Throwable ex;\r\n        if (s == CANCELLED)\r\n            throw new CancellationException();\r\n        if (s != EXCEPTIONAL)\r\n            throw new TimeoutException();\r\n        if ((ex = getThrowableException()) != null)\r\n            throw new ExecutionException(ex);\r\n    }\r\n    return getRawResult();\r\n}"
}, {
	"Path": "water.parser.BufferedString.equalsAsciiString",
	"Comment": "tests whether this bufferedstring is equal to a given ascii string",
	"Method": "boolean equalsAsciiString(String str){\r\n    if (str == null || str.length() != _len)\r\n        return false;\r\n    for (int i = 0; i < _len; ++i) if (_buf[_off + i] != str.charAt(i))\r\n        return false;\r\n    return true;\r\n}"
}, {
	"Path": "com.google.errorprone.apply.ImportStatementsTest.shouldAddImportInCorrectPosition",
	"Comment": "test that adding a new import inserts it in the correct position.",
	"Method": "void shouldAddImportInCorrectPosition(){\r\n    ImportStatements imports = createImportStatements(basePackage, baseImportList);\r\n    boolean added = imports.add(\"import static org.junit.Assert.assertEquals\");\r\n    assertTrue(added);\r\n    assertEquals(\"import static com.google.ads.pebl.AdGroupCriterionPredicate.PAUSED;\\n\" + \"import static com.google.common.base.Preconditions.checkNotNull;\\n\" + \"import static org.junit.Assert.assertEquals;\\n\" + \"\\n\" + \"import com.google.common.collect.ImmutableList;\\n\" + \"import com.google.common.collect.ImmutableMap;\\n\" + \"import com.sun.source.tree.CompilationUnitTree;\\n\" + \"import com.sun.source.tree.ImportTree;\\n\" + \"import com.sun.tools.javac.tree.JCTree;\\n\" + \"import com.sun.tools.javac.tree.JCTree.JCExpression;\\n\" + \"import java.io.File;\\n\" + \"import java.io.IOException;\\n\" + \"import java.util.Iterator;\\n\" + \"import javax.tools.JavaCompiler;\\n\" + \"import javax.tools.JavaFileObject;\\n\" + \"import javax.tools.StandardJavaFileManager;\\n\" + \"import javax.tools.ToolProvider;\\n\" + \"import org.joda.time.DateTime;\\n\" + \"import org.joda.time.DateTimeZone;\\n\" + \"import org.joda.time.Interval;\", imports.toString());\r\n}"
}, {
	"Path": "graphql.execution.reactive.SingleSubscriberPublisher.offer",
	"Comment": "called from the producing code to offer data up ready for a subscriber to read it",
	"Method": "void offer(T data){\r\n    mutex.execute(() -> dataQ.offer(data));\r\n}"
}, {
	"Path": "feign.client.AbstractClientTest.noResponseBodyForPatch",
	"Comment": "some client implementation tests should override this test if the patch operation isunsupported.",
	"Method": "void noResponseBodyForPatch(){\r\n    server.enqueue(new MockResponse());\r\n    TestInterface api = newBuilder().target(TestInterface.class, \"http://localhost:\" + server.getPort());\r\n    api.noPatchBody();\r\n}"
}, {
	"Path": "hex.deeplearning.DeepLearningTask.chunkDone",
	"Comment": "after each chunk, add the number of processed rows to the counter",
	"Method": "void chunkDone(long n){\r\n    if (_training)\r\n        _localmodel.add_processed_local(n);\r\n}"
}, {
	"Path": "hex.grid.Grid.getFailedRawParameters",
	"Comment": "returns list of raw model parameters causing model building failure.",
	"Method": "String[][] getFailedRawParameters(){\r\n    return _failed_raw_params;\r\n}"
}, {
	"Path": "water.fvec.Frame.checkCompatibility",
	"Comment": "check that the vectors are all compatible.all vecs have their content sharded using same number of rows per chunk, and all names are unique. throw an iae if something does not match.",
	"Method": "void checkCompatibility(String name,Vec vec){\r\n    if (vec instanceof AppendableVec)\r\n        return;\r\n    Vec v0 = anyVec();\r\n    if (v0 == null)\r\n        return;\r\n    if (!v0.isCompatibleWith(vec)) {\r\n        if (!Vec.VectorGroup.sameGroup(v0, vec))\r\n            Log.err(\"Unexpected incompatible vector group, \" + v0.group() + \" != \" + vec.group());\r\n        if (!Arrays.equals(v0.espc(), vec.espc()))\r\n            Log.err(\"Unexpected incompatible espc, \" + Arrays.toString(v0.espc()) + \" != \" + Arrays.toString(vec.espc()));\r\n        throw new IllegalArgumentException(\"Vec \" + name + \" is not compatible with the rest of the frame\");\r\n    }\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlusBuilder.setOnClickListener",
	"Comment": "set a global click listener to you dialog in order to handle all the possible click events. you can thenidentify the view by using its id and handle the correct behaviour",
	"Method": "DialogPlusBuilder setOnClickListener(OnClickListener listener){\r\n    this.onClickListener = listener;\r\n    return this;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.DataReaderIBMi5OS1_4_2.parseTotalAfterGC",
	"Comment": "parses the line which holds the current heap size andreturns the heap size after gc completed.",
	"Method": "int parseTotalAfterGC(String line){\r\n    final int start = line.indexOf(\"current heap(KB) \") + 17;\r\n    final int end = line.indexOf(';', start);\r\n    return Integer.parseInt(line.substring(start, end));\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.previousStatement",
	"Comment": "matches a statement ast node if the previous statement in the enclosing block matches the givenmatcher.",
	"Method": "Matcher<T> previousStatement(Matcher<StatementTree> matcher){\r\n    return (T statement, VisitorState state) -> {\r\n        BlockTree block = state.findEnclosing(BlockTree.class);\r\n        if (block == null) {\r\n            return false;\r\n        }\r\n        List<? extends StatementTree> statements = block.getStatements();\r\n        int idx = statements.indexOf(statement);\r\n        if (idx <= 0) {\r\n            return false;\r\n        }\r\n        return matcher.matches(statements.get(idx - 1), state);\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.doesNotHaveArgument",
	"Comment": "matches an annotation ast node if an argument to the annotation does not exist.",
	"Method": "Matcher<AnnotationTree> doesNotHaveArgument(String argumentName){\r\n    return new AnnotationDoesNotHaveArgument(argumentName);\r\n}"
}, {
	"Path": "graphql.schema.GraphQLTypeUtil.unwrapOne",
	"Comment": "unwraps one layer of the type or just returns the type again if its not a wrapped type",
	"Method": "GraphQLType unwrapOne(GraphQLType type){\r\n    if (isNonNull(type)) {\r\n        return ((GraphQLNonNull) type).getWrappedType();\r\n    } else if (isList(type)) {\r\n        return ((GraphQLList) type).getWrappedType();\r\n    }\r\n    return type;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.threadsafety.HeldLockAnalyzer.analyze",
	"Comment": "analyzes a method body, tracking the set of held locks and checking accesses to guardedmembers.",
	"Method": "void analyze(VisitorState state,LockEventListener listener,Predicate<Tree> isSuppressed){\r\n    HeldLockSet locks = HeldLockSet.empty();\r\n    locks = handleMonitorGuards(state, locks);\r\n    new LockScanner(state, listener, isSuppressed).scan(state.getPath(), locks);\r\n}"
}, {
	"Path": "hex.Model.fillScoringInfo",
	"Comment": "fill a scoringinfo with data from the modelmetrics for this model.",
	"Method": "void fillScoringInfo(ScoringInfo scoringInfo){\r\n    scoringInfo.is_classification = this._output.isClassifier();\r\n    scoringInfo.is_autoencoder = _output.isAutoencoder();\r\n    scoringInfo.scored_train = new ScoreKeeper(this._output._training_metrics);\r\n    scoringInfo.scored_valid = new ScoreKeeper(this._output._validation_metrics);\r\n    scoringInfo.scored_xval = new ScoreKeeper(this._output._cross_validation_metrics);\r\n    scoringInfo.validation = _output._validation_metrics != null;\r\n    scoringInfo.cross_validation = _output._cross_validation_metrics != null;\r\n    if (this._output.isBinomialClassifier()) {\r\n        scoringInfo.training_AUC = this._output._training_metrics == null ? null : ((ModelMetricsBinomial) this._output._training_metrics)._auc;\r\n        scoringInfo.validation_AUC = this._output._validation_metrics == null ? null : ((ModelMetricsBinomial) this._output._validation_metrics)._auc;\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.enclosingClass",
	"Comment": "matches an ast node which is enclosed by a class node that matches the given matcher.",
	"Method": "Enclosing.Class<T> enclosingClass(Matcher<ClassTree> matcher){\r\n    return new Enclosing.Class(matcher);\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.baselineVersion",
	"Comment": "sets the version to tag an existing schema with when executing baseline.",
	"Method": "FluentConfiguration baselineVersion(MigrationVersion baselineVersion,FluentConfiguration baselineVersion,String baselineVersion){\r\n    config.setBaselineVersion(MigrationVersion.fromVersion(baselineVersion));\r\n    return this;\r\n}"
}, {
	"Path": "com.google.errorprone.CompilationTestHelper.ignoreJavacErrors",
	"Comment": "by default, the compilation helper will not run error prone on compilations that fail withjavac errors. this behaviour can be disabled to test the interaction between error prone checksand javac diagnostics.",
	"Method": "CompilationTestHelper ignoreJavacErrors(){\r\n    this.checkWellFormed = false;\r\n    return this;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.util.LocalisationHelper.getString",
	"Comment": "returns localised text as result of lookup with key using valuesas parameters for the text.",
	"Method": "String getString(String key,String getString,String key,Object values){\r\n    if (getBundle().containsKey(key)) {\r\n        return MessageFormat.format(getBundle().getString(key), values);\r\n    } else {\r\n        return \"\\\"\" + key + \"\\\" not found\";\r\n    }\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlusBuilder.setOutAnimation",
	"Comment": "customize the out animation by passing an animation resource",
	"Method": "DialogPlusBuilder setOutAnimation(int outAnimResource){\r\n    this.outAnimation = outAnimResource;\r\n    return this;\r\n}"
}, {
	"Path": "jsr166y.LinkedTransferQueue.firstOfMode",
	"Comment": "returns the first unmatched node of the given mode, or null ifnone.used by methods isempty, haswaitingconsumer.",
	"Method": "Node firstOfMode(boolean isData){\r\n    for (Node p = head; p != null; p = succ(p)) {\r\n        if (!p.isMatched())\r\n            return (p.isData == isData) ? p : null;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "water.fvec.Chunk.chk2",
	"Comment": "exposed for internal testing only.not a publically visible api.",
	"Method": "Chunk chk2(){\r\n    return _chk2;\r\n}"
}, {
	"Path": "water.Key.compareTo",
	"Comment": "lexically ordered key comparison, so keys can be sorted.modestly expensive.",
	"Method": "int compareTo(Object o){\r\n    assert (o instanceof Key);\r\n    return this.toString().compareTo(o.toString());\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlusBuilder.setOutMostMargin",
	"Comment": "add margins to your outmost view which contains everything. as default they are 0are applied",
	"Method": "DialogPlusBuilder setOutMostMargin(int left,int top,int right,int bottom){\r\n    this.outMostMargin[0] = left;\r\n    this.outMostMargin[1] = top;\r\n    this.outMostMargin[2] = right;\r\n    this.outMostMargin[3] = bottom;\r\n    return this;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.methodInvocation",
	"Comment": "matches an ast node if it is a method invocation and the given matchers match.",
	"Method": "Matcher<ExpressionTree> methodInvocation(Matcher<ExpressionTree> methodSelectMatcher,MatchType matchType,Matcher<ExpressionTree> methodArgumentMatcher,Matcher<ExpressionTree> methodInvocation,Matcher<ExpressionTree> methodSelectMatcher){\r\n    return new Matcher<ExpressionTree>() {\r\n        @Override\r\n        public boolean matches(ExpressionTree expressionTree, VisitorState state) {\r\n            if (!(expressionTree instanceof MethodInvocationTree)) {\r\n                return false;\r\n            }\r\n            MethodInvocationTree tree = (MethodInvocationTree) expressionTree;\r\n            return methodSelectMatcher.matches(tree.getMethodSelect(), state);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.methodInvocation",
	"Comment": "matches an ast node if it is a method invocation and the given matchers match.",
	"Method": "Matcher<ExpressionTree> methodInvocation(Matcher<ExpressionTree> methodSelectMatcher,MatchType matchType,Matcher<ExpressionTree> methodArgumentMatcher,Matcher<ExpressionTree> methodInvocation,Matcher<ExpressionTree> methodSelectMatcher){\r\n    if (!(expressionTree instanceof MethodInvocationTree)) {\r\n        return false;\r\n    }\r\n    MethodInvocationTree tree = (MethodInvocationTree) expressionTree;\r\n    return methodSelectMatcher.matches(tree.getMethodSelect(), state);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.ReturnValueIgnored.methodReturnsSameTypeAsReceiver",
	"Comment": "matches method invocations that return the same type as the receiver object.",
	"Method": "Matcher<ExpressionTree> methodReturnsSameTypeAsReceiver(){\r\n    return new Matcher<ExpressionTree>() {\r\n        @Override\r\n        public boolean matches(ExpressionTree expressionTree, VisitorState state) {\r\n            return isSameType(ASTHelpers.getReceiverType(expressionTree), ASTHelpers.getReturnType(expressionTree), state);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.ReturnValueIgnored.methodReturnsSameTypeAsReceiver",
	"Comment": "matches method invocations that return the same type as the receiver object.",
	"Method": "Matcher<ExpressionTree> methodReturnsSameTypeAsReceiver(){\r\n    return isSameType(ASTHelpers.getReceiverType(expressionTree), ASTHelpers.getReturnType(expressionTree), state);\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaDirectiveWiring.onUnion",
	"Comment": "this is called when a union is encountered, which gives the schema directive a chance to modify the shape and behaviourof that dslelement",
	"Method": "GraphQLUnionType onUnion(SchemaDirectiveWiringEnvironment<GraphQLUnionType> environment){\r\n    return environment.getElement();\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.AbstractReturnValueIgnored.expectedExceptionTest",
	"Comment": "allow return values to be ignored in tests that expect an exception to be thrown.",
	"Method": "boolean expectedExceptionTest(Tree tree,VisitorState state){\r\n    if (mockitoInvocation(tree, state)) {\r\n        return true;\r\n    }\r\n    StatementTree statement = ASTHelpers.findEnclosingNode(state.getPath(), StatementTree.class);\r\n    if (statement != null && EXPECTED_EXCEPTION_MATCHER.matches(statement, state)) {\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.info.MigrationInfoServiceImpl.future",
	"Comment": "retrieves the full set of infos about future migrations applied to the db.",
	"Method": "MigrationInfo[] future(){\r\n    List<MigrationInfo> futureMigrations = new ArrayList();\r\n    for (MigrationInfo migrationInfo : migrationInfos) {\r\n        if ((migrationInfo.getState() == MigrationState.FUTURE_SUCCESS) || (migrationInfo.getState() == MigrationState.FUTURE_FAILED)) {\r\n            futureMigrations.add(migrationInfo);\r\n        }\r\n    }\r\n    return futureMigrations.toArray(new MigrationInfo[0]);\r\n}"
}, {
	"Path": "jsr166y.LinkedTransferQueue.countOfMode",
	"Comment": "traverses and counts unmatched nodes of the given mode.used by methods size and getwaitingconsumercount.",
	"Method": "int countOfMode(boolean data){\r\n    int count = 0;\r\n    for (Node p = head; p != null; ) {\r\n        if (!p.isMatched()) {\r\n            if (p.isData != data)\r\n                return 0;\r\n            if (++count == Integer.MAX_VALUE)\r\n                break;\r\n        }\r\n        Node n = p.next;\r\n        if (n != p)\r\n            p = n;\r\n        else {\r\n            count = 0;\r\n            p = head;\r\n        }\r\n    }\r\n    return count;\r\n}"
}, {
	"Path": "jsr166y.LinkedTransferQueue.put",
	"Comment": "inserts the specified element at the tail of this queue.as the queue is unbounded, this method will never block.",
	"Method": "void put(E e){\r\n    xfer(e, true, ASYNC, 0);\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.UnittestHelper.getResourceAsStream",
	"Comment": "load resource as stream if it is present somewhere in the classpath.",
	"Method": "InputStream getResourceAsStream(String name,InputStream getResourceAsStream,FOLDER folder,String name){\r\n    return getResourceAsStream(folder.getFolderName() + File.separator + name);\r\n}"
}, {
	"Path": "jsr166y.LinkedTransferQueue.xfer",
	"Comment": "implements all queuing methods. see above for explanation.",
	"Method": "E xfer(E e,boolean haveData,int how,long nanos){\r\n    if (haveData && (e == null))\r\n        throw new NullPointerException();\r\n    Node s = null;\r\n    retry: for (; ; ) {\r\n        for (Node h = head, p = h; p != null; ) {\r\n            boolean isData = p.isData;\r\n            Object item = p.item;\r\n            if (item != p && (item != null) == isData) {\r\n                if (isData == haveData)\r\n                    break;\r\n                if (p.casItem(item, e)) {\r\n                    for (Node q = p; q != h; ) {\r\n                        Node n = q.next;\r\n                        if (head == h && casHead(h, n == null ? q : n)) {\r\n                            h.forgetNext();\r\n                            break;\r\n                        }\r\n                        if ((h = head) == null || (q = h.next) == null || !q.isMatched())\r\n                            break;\r\n                    }\r\n                    LockSupport.unpark(p.waiter);\r\n                    return LinkedTransferQueue.<E>cast(item);\r\n                }\r\n            }\r\n            Node n = p.next;\r\n            p = (p != n) ? n : (h = head);\r\n        }\r\n        if (how != NOW) {\r\n            if (s == null)\r\n                s = new Node(e, haveData);\r\n            Node pred = tryAppend(s, haveData);\r\n            if (pred == null)\r\n                continue retry;\r\n            if (how != ASYNC)\r\n                return awaitMatch(s, pred, e, (how == TIMED), nanos);\r\n        }\r\n        return e;\r\n    }\r\n}"
}, {
	"Path": "graphql.execution.Execution.deferSupport",
	"Comment": "adds the deferred publisher if its needed at the end of the query.this is also a good time for the deferred code to start running",
	"Method": "CompletableFuture<ExecutionResult> deferSupport(ExecutionContext executionContext,CompletableFuture<ExecutionResult> result){\r\n    return result.thenApply(er -> {\r\n        DeferSupport deferSupport = executionContext.getDeferSupport();\r\n        if (deferSupport.isDeferDetected()) {\r\n            Publisher<ExecutionResult> publisher = deferSupport.startDeferredCalls();\r\n            return ExecutionResultImpl.newExecutionResult().from((ExecutionResultImpl) er).addExtension(GraphQL.DEFERRED_RESULTS, publisher).build();\r\n        }\r\n        return er;\r\n    });\r\n}"
}, {
	"Path": "com.google.errorprone.SuppressionHelper.isSuppressed",
	"Comment": "returns true if this checker should be suppressed on the current tree path.",
	"Method": "boolean isSuppressed(Suppressible suppressible,Set<String> suppressionsOnCurrentPath,Set<Class<? extends Annotation>> customSuppressionsOnCurrentPath,SeverityLevel severityLevel,boolean inGeneratedCode,boolean disableWarningsInGeneratedCode){\r\n    if (inGeneratedCode && disableWarningsInGeneratedCode && severityLevel != SeverityLevel.ERROR) {\r\n        return true;\r\n    }\r\n    if (suppressible.supportsSuppressWarnings() && !Collections.disjoint(suppressible.allNames(), suppressionsOnCurrentPath)) {\r\n        return true;\r\n    }\r\n    return !Collections.disjoint(suppressible.customSuppressionAnnotations(), customSuppressionsOnCurrentPath);\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.getUncaughtExceptionHandler",
	"Comment": "returns the handler for internal worker threads that terminatedue to unrecoverable errors encountered while executing tasks.",
	"Method": "Thread.UncaughtExceptionHandler getUncaughtExceptionHandler(){\r\n    return ueh;\r\n}"
}, {
	"Path": "jsr166y.Phaser.abortWait",
	"Comment": "variant of releasewaiters that additionally tries to remove anynodes no longer waiting for advance due to timeout orinterrupt. currently, nodes are removed only if they are athead of queue, which suffices to reduce memory footprint inmost usages.",
	"Method": "int abortWait(int phase){\r\n    AtomicReference<QNode> head = (phase & 1) == 0 ? evenQ : oddQ;\r\n    for (; ; ) {\r\n        Thread t;\r\n        QNode q = head.get();\r\n        int p = (int) (root.state >>> PHASE_SHIFT);\r\n        if (q == null || ((t = q.thread) != null && q.phase == p))\r\n            return p;\r\n        if (head.compareAndSet(q, q.next) && t != null) {\r\n            q.thread = null;\r\n            LockSupport.unpark(t);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "hex.deeplearning.DeepLearningModelInfo.checkMissingCats",
	"Comment": "check whether a missing value was found for every categorical predictor",
	"Method": "void checkMissingCats(int[] cats){\r\n    if (cats == null)\r\n        return;\r\n    if (_saw_missing_cats == null)\r\n        return;\r\n    for (int i = 0; i < cats.length; ++i) {\r\n        assert (data_info._catMissing[i]);\r\n        if (_saw_missing_cats[i])\r\n            continue;\r\n        _saw_missing_cats[i] = (cats[i] == data_info._catOffsets[i + 1] - 1);\r\n    }\r\n}"
}, {
	"Path": "water.H2O.unimpl",
	"Comment": "throw an exception that will cause the request to fail, but the cluster to continue.",
	"Method": "H2OIllegalArgumentException unimpl(H2OIllegalArgumentException unimpl,String msg){\r\n    return new H2OIllegalArgumentException(\"unimplemented: \" + msg);\r\n}"
}, {
	"Path": "water.MRTask.outputFrame",
	"Comment": "get the resulting frame from this invoked mrtask. if the passed in keyis not null, then the resulting frame will appear in the dkv. appendablevec instancesare closed into vec instances, which then appear in the dkv.",
	"Method": "Frame outputFrame(Frame outputFrame,String[] names,String[][] domains,Frame outputFrame,Key<Frame> key,String[] names,String[][] domains){\r\n    Futures fs = new Futures();\r\n    Frame res = closeFrame(key, names, domains, fs);\r\n    if (key != null)\r\n        DKV.put(res, fs);\r\n    fs.blockForPending();\r\n    return res;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.model.GCModel.getEvents",
	"Comment": "returns an iterator to all events in the order they were added to the model.",
	"Method": "Iterator<AbstractGCEvent<?>> getEvents(){\r\n    return allEvents.iterator();\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.methodHasArity",
	"Comment": "matches if the method accepts the given number of arguments.",
	"Method": "Matcher<MethodTree> methodHasArity(int arity){\r\n    return new Matcher<MethodTree>() {\r\n        @Override\r\n        public boolean matches(MethodTree methodTree, VisitorState state) {\r\n            return methodTree.getParameters().size() == arity;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.methodHasArity",
	"Comment": "matches if the method accepts the given number of arguments.",
	"Method": "Matcher<MethodTree> methodHasArity(int arity){\r\n    return methodTree.getParameters().size() == arity;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.AnnotationPosition.checkAnnotations",
	"Comment": "checks that annotations are on the right side of the modifiers.",
	"Method": "Description checkAnnotations(Tree tree,int treePos,List<? extends AnnotationTree> annotations,Comment danglingJavadoc,int firstModifierPos,int lastModifierPos,VisitorState state){\r\n    SuggestedFix.Builder builder = SuggestedFix.builder();\r\n    List<AnnotationTree> moveBefore = new ArrayList();\r\n    List<AnnotationTree> moveAfter = new ArrayList();\r\n    boolean annotationProblem = false;\r\n    for (AnnotationTree annotation : annotations) {\r\n        int annotationPos = ((JCTree) annotation).getStartPosition();\r\n        if (annotationPos <= firstModifierPos) {\r\n            continue;\r\n        }\r\n        AnnotationType annotationType = ASTHelpers.getAnnotationType(annotation, getSymbol(tree), state);\r\n        if (annotationPos >= lastModifierPos) {\r\n            if (tree instanceof ClassTree || annotationType == AnnotationType.DECLARATION) {\r\n                annotationProblem = true;\r\n                moveBefore.add(annotation);\r\n            }\r\n        } else {\r\n            annotationProblem = true;\r\n            if (tree instanceof ClassTree || annotationType == AnnotationType.DECLARATION || annotationType == null) {\r\n                moveBefore.add(annotation);\r\n            } else {\r\n                moveAfter.add(annotation);\r\n            }\r\n        }\r\n    }\r\n    if (annotationProblem) {\r\n        for (AnnotationTree annotation : moveBefore) {\r\n            builder.delete(annotation);\r\n        }\r\n        for (AnnotationTree annotation : moveAfter) {\r\n            builder.delete(annotation);\r\n        }\r\n        String javadoc = danglingJavadoc == null ? \"\" : removeJavadoc(state, treePos, danglingJavadoc, builder);\r\n        builder.replace(firstModifierPos, firstModifierPos, String.format(\"%s%s \", javadoc, joinSource(state, moveBefore))).replace(lastModifierPos, lastModifierPos, String.format(\"%s \", joinSource(state, moveAfter)));\r\n        ImmutableList<String> names = annotations.stream().map(ASTHelpers::getSymbol).filter(Objects::nonNull).map(Symbol::getSimpleName).map(a -> \"@\" + a).collect(toImmutableList());\r\n        String flattened = names.stream().collect(joining(\", \"));\r\n        String isAre = names.size() > 1 ? \"are not type annotations\" : \"is not a type annotation\";\r\n        String message = String.format(\"%s %s, so should appear before any modifiers and after Javadocs.\", flattened, isAre);\r\n        return buildDescription(tree).setMessage(message).addFix(builder.build()).build();\r\n    }\r\n    return NO_MATCH;\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaDirectiveWiring.onEnum",
	"Comment": "this is called when an enum is encountered, which gives the schema directive a chance to modify the shape and behaviourof that dslelement",
	"Method": "GraphQLEnumType onEnum(SchemaDirectiveWiringEnvironment<GraphQLEnumType> environment){\r\n    return environment.getElement();\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.packageStartsWith",
	"Comment": "matches an ast node whose compilation unit starts with this prefix.",
	"Method": "Matcher<T> packageStartsWith(String prefix){\r\n    return (tree, state) -> getPackageFullName(state).startsWith(prefix);\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Description.linkTextForDiagnostic",
	"Comment": "construct the link text to include in the compiler error message. returns null if there is nolink.",
	"Method": "String linkTextForDiagnostic(String linkUrl){\r\n    return isNullOrEmpty(linkUrl) ? null : \"  (see \" + linkUrl + \")\";\r\n}"
}, {
	"Path": "water.parser.ParseSetup.hasHeader",
	"Comment": "return true iff the first line is all strings and second line has at least one number",
	"Method": "boolean hasHeader(String[] l1,String[] l2){\r\n    return allStrings(l1) && !allStrings(l2);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.threadsafety.GuardedBySymbolResolver.resolveType",
	"Comment": "resolves a simple name as a type. considers super classes, lexically enclosing classes, andthen arbitrary types available in the current environment.",
	"Method": "Symbol resolveType(String name,SearchSuperTypes searchSuperTypes){\r\n    Symbol type = null;\r\n    if (searchSuperTypes == SearchSuperTypes.YES) {\r\n        type = getSuperType(enclosingClass, name);\r\n    }\r\n    if (enclosingClass.getSimpleName().contentEquals(name)) {\r\n        type = enclosingClass;\r\n    }\r\n    if (type == null) {\r\n        type = getLexicallyEnclosing(enclosingClass, name);\r\n    }\r\n    if (type == null) {\r\n        type = attribIdent(name);\r\n    }\r\n    checkGuardedBy(!(type instanceof Symbol.PackageSymbol), \"All we could find for '%s' was a package symbol.\", name);\r\n    return type;\r\n}"
}, {
	"Path": "water.api.SchemaServer.schema",
	"Comment": "for a given version and iced class return an appropriate schema instance, if any.",
	"Method": "Schema schema(int version,Iced impl,Schema schema,int version,Class<? extends Iced> impl_class,Schema schema,int version,String type){\r\n    Class<? extends Schema> clz = schemaClass(version, type);\r\n    if (clz == null)\r\n        clz = schemaClass(EXPERIMENTAL_VERSION, type);\r\n    if (clz == null)\r\n        throw new H2ONotFoundArgumentException(\"Failed to find schema for version: \" + version + \" and type: \" + type, \"Failed to find schema for version: \" + version + \" and type: \" + type + \"\\n\" + \"Did you forget to add an entry into META-INF/services/water.api.Schema?\");\r\n    return Schema.newInstance(clz);\r\n}"
}, {
	"Path": "water.fvec.Vec.align",
	"Comment": "always makes a copy of the given vector which shares the same group as this vec.this can be expensive operation since it can force copy of data among nodes.",
	"Method": "Vec align(Vec vec){\r\n    return new Frame(this).makeCompatible(new Frame(vec), true)[0];\r\n}"
}, {
	"Path": "com.google.errorprone.refaster.Choice.any",
	"Comment": "returns a choice between any of the options from any of the specified choices.",
	"Method": "Choice<T> any(Collection<Choice<T>> choices){\r\n    return from(choices).thenChoose(Functions.<Choice<T>>identity());\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.cockroachdb.CockroachDBDatabase.isCockroachDB",
	"Comment": "checks whether this connection is pointing at a cockroachdb instance.",
	"Method": "boolean isCockroachDB(Connection connection){\r\n    try {\r\n        return new JdbcTemplate(connection).queryForString(\"SELECT version()\").contains(\"CockroachDB\");\r\n    } catch (Exception e) {\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.oracle.OracleDatabase.isPrivOrRoleGranted",
	"Comment": "checks whether the specified privilege or role is granted to the current user.",
	"Method": "boolean isPrivOrRoleGranted(String name){\r\n    return queryReturnsRows(\"SELECT 1 FROM SESSION_PRIVS WHERE PRIVILEGE = ? UNION ALL \" + \"SELECT 1 FROM SESSION_ROLES WHERE ROLE = ?\", name, name);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.argumentselectiondefects.NamedParameterComment.match",
	"Comment": "determine the kind of match we have between the comments on this argument and the formalparameter name.",
	"Method": "MatchedComment match(Commented<ExpressionTree> actual,String formal){\r\n    Optional<Comment> lastBlockComment = Streams.findLast(actual.beforeComments().stream().filter(c -> c.getStyle() == CommentStyle.BLOCK));\r\n    if (lastBlockComment.isPresent()) {\r\n        Matcher m = PARAMETER_COMMENT_PATTERN.matcher(Comments.getTextFromComment(lastBlockComment.get()));\r\n        if (m.matches()) {\r\n            return MatchedComment.create(lastBlockComment.get(), m.group(1).equals(formal) ? MatchType.EXACT_MATCH : MatchType.BAD_MATCH);\r\n        }\r\n    }\r\n    Optional<Comment> approximateMatchComment = Stream.concat(actual.beforeComments().stream(), actual.afterComments().stream()).filter(comment -> isApproximateMatchingComment(comment, formal)).findFirst();\r\n    if (approximateMatchComment.isPresent()) {\r\n        String text = CharMatcher.anyOf(\"=:\").trimTrailingFrom(Comments.getTextFromComment(approximateMatchComment.get()).trim());\r\n        return MatchedComment.create(approximateMatchComment.get(), text.equals(formal) ? MatchType.EXACT_MATCH : MatchType.APPROXIMATE_MATCH);\r\n    }\r\n    return MatchedComment.notAnnotated();\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.cleanOnValidationError",
	"Comment": "whether to automatically call clean or not when a validation error occurs. this is exclusively intended as a convenience for development. even tough westrongly recommend not to change migration scripts once they have been checked into scm and run, this provides away of dealing with this case in a smooth manner. the database will be wiped clean automatically, ensuring thatthe next migration will bring you back to the state checked into scm.warning ! do not enable in production !",
	"Method": "FluentConfiguration cleanOnValidationError(boolean cleanOnValidationError){\r\n    config.setCleanOnValidationError(cleanOnValidationError);\r\n    return this;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.util.OSXAdapter.setHandler",
	"Comment": "sethandler creates a proxy object from the passed osxadapter and adds it as an applicationlistener",
	"Method": "void setHandler(OSXAdapter adapter){\r\n    try {\r\n        Class<?> applicationClass = Class.forName(\"com.apple.eawt.Application\");\r\n        if (macOSXApplication == null) {\r\n            macOSXApplication = applicationClass.getConstructor((Class[]) null).newInstance((Object[]) null);\r\n        }\r\n        Class<?> applicationListenerClass = Class.forName(\"com.apple.eawt.ApplicationListener\");\r\n        Method addListenerMethod = applicationClass.getDeclaredMethod(\"addApplicationListener\", new Class[] { applicationListenerClass });\r\n        Object osxAdapterProxy = Proxy.newProxyInstance(OSXAdapter.class.getClassLoader(), new Class[] { applicationListenerClass }, adapter);\r\n        addListenerMethod.invoke(macOSXApplication, new Object[] { osxAdapterProxy });\r\n    } catch (ClassNotFoundException cnfe) {\r\n        LoggerHelper.logException(LOGGER, Level.WARNING, \"This version of Mac OS X does not support the Apple EAWT. \" + \"ApplicationEvent handling has been disabled\", cnfe);\r\n        System.err.println(\"This version of Mac OS X does not support the Apple EAWT.  ApplicationEvent handling has been disabled (\" + cnfe + \")\");\r\n    } catch (Exception ex) {\r\n        LoggerHelper.logException(LOGGER, Level.SEVERE, \"Mac OS X Adapter could not talk to EAWT:\", ex);\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.formatstring.FormatStringAnnotationChecker.matchInvocation",
	"Comment": "matches a method or constructor invocation. the input symbol should match the invoked method orcontructor and the args should be the parameters in the invocation.",
	"Method": "Description matchInvocation(ExpressionTree tree,MethodSymbol symbol,List<? extends ExpressionTree> args,VisitorState state){\r\n    if (!ASTHelpers.hasAnnotation(symbol, FormatMethod.class, state)) {\r\n        return Description.NO_MATCH;\r\n    }\r\n    Type stringType = state.getSymtab().stringType;\r\n    List<VarSymbol> params = symbol.getParameters();\r\n    int firstStringIndex = -1;\r\n    int formatString = -1;\r\n    for (int i = 0; i < params.size(); i++) {\r\n        VarSymbol param = params.get(i);\r\n        if (ASTHelpers.hasAnnotation(param, FormatString.class, state)) {\r\n            formatString = i;\r\n            break;\r\n        }\r\n        if (firstStringIndex < 0 && ASTHelpers.isSameType(params.get(i).type, stringType, state)) {\r\n            firstStringIndex = i;\r\n        }\r\n    }\r\n    if (formatString < 0) {\r\n        formatString = firstStringIndex;\r\n    }\r\n    FormatStringValidation.ValidationResult result = StrictFormatStringValidation.validate(args.get(formatString), args.subList(formatString + 1, args.size()), state);\r\n    if (result != null) {\r\n        return buildDescription(tree).setMessage(result.message()).build();\r\n    } else {\r\n        return Description.NO_MATCH;\r\n    }\r\n}"
}, {
	"Path": "feign.RequestTemplate.query",
	"Comment": "specify a query string parameter, with the specified values. values can be literals or templateexpressions.",
	"Method": "RequestTemplate query(String name,String values,RequestTemplate query,String name,Iterable<String> values){\r\n    return appendQuery(name, values);\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaDirectiveWiring.onObject",
	"Comment": "this is called when an object is encountered, which gives the schema directive a chance to modify the shape and behaviourof that dslelement",
	"Method": "GraphQLObjectType onObject(SchemaDirectiveWiringEnvironment<GraphQLObjectType> environment){\r\n    return environment.getElement();\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.checkPermission",
	"Comment": "if there is a security manager, makes sure caller haspermission to modify threads.",
	"Method": "void checkPermission(){\r\n    SecurityManager security = System.getSecurityManager();\r\n    if (security != null)\r\n        security.checkPermission(modifyThreadPermission);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.base.Database.ensureDatabaseNotOlderThanOtherwiseRecommendUpgradeToFlywayEdition",
	"Comment": "ensures this database it at least at recent as this version otherwise suggest upgrade to this higher edition offlyway.",
	"Method": "void ensureDatabaseNotOlderThanOtherwiseRecommendUpgradeToFlywayEdition(String oldestSupportedVersionInThisEdition,Edition editionWhereStillSupported){\r\n    if (!version.isAtLeast(oldestSupportedVersionInThisEdition)) {\r\n        throw new FlywayEditionUpgradeRequiredException(editionWhereStillSupported, databaseType, computeVersionDisplayName(version));\r\n    }\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.util.ImageHelper.loadImageIcon",
	"Comment": "loads an image from a given path and returns it as an imageicon.",
	"Method": "ImageIcon loadImageIcon(String imageName){\r\n    return new ImageIcon(loadImage(imageName));\r\n}"
}, {
	"Path": "water.parser.FVecParseReader.getChunk",
	"Comment": "exposes directly the underlying chunk. this function is safe to be used onlyin implementations of parsers that cannot be used in a streaming context.use with caution.",
	"Method": "Chunk getChunk(){\r\n    return _chk;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.h2.H2Schema.generateDropStatements",
	"Comment": "generate the statements for dropping all the objects of this type in this schema.",
	"Method": "List<String> generateDropStatements(String objectType,List<String> objectNames){\r\n    List<String> statements = new ArrayList();\r\n    for (String objectName : objectNames) {\r\n        String dropStatement = \"DROP \" + objectType + database.quote(name, objectName);\r\n        statements.add(dropStatement);\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "ai.h2o.automl.targetencoding.TargetEncoder.applyTargetEncoding",
	"Comment": "overloaded for the case when user had not specified the noise parameter",
	"Method": "Frame applyTargetEncoding(Frame data,String targetColumnName,Map<String, Frame> columnToEncodingMap,byte dataLeakageHandlingStrategy,String foldColumnName,boolean withBlendedAvg,double noiseLevel,boolean imputeNAsWithNewCategory,long seed,boolean isTrainOrValidSet,Frame applyTargetEncoding,Frame data,String targetColumnName,Map<String, Frame> targetEncodingMap,byte dataLeakageHandlingStrategy,String foldColumn,boolean withBlendedAvg,boolean imputeNAs,long seed,boolean isTrainOrValidSet,Frame applyTargetEncoding,Frame data,String targetColumnName,Map<String, Frame> targetEncodingMap,byte dataLeakageHandlingStrategy,boolean withBlendedAvg,boolean imputeNAs,long seed,boolean isTrainOrValidSet,Frame applyTargetEncoding,Frame data,String targetColumnName,Map<String, Frame> targetEncodingMap,byte dataLeakageHandlingStrategy,boolean withBlendedAvg,double noiseLevel,boolean imputeNAs,long seed,boolean isTrainOrValidSet){\r\n    assert dataLeakageHandlingStrategy != DataLeakageHandlingStrategy.KFold : \"Use another overloaded method for KFold dataLeakageHandlingStrategy.\";\r\n    return applyTargetEncoding(data, targetColumnName, targetEncodingMap, dataLeakageHandlingStrategy, null, withBlendedAvg, noiseLevel, true, seed, isTrainOrValidSet);\r\n}"
}, {
	"Path": "feign.template.UriUtils.encodeChunk",
	"Comment": "encode a uri chunk, ensuring that all reserved characters are also encoded.",
	"Method": "String encodeChunk(String value,String reserved,Charset charset){\r\n    StringBuilder encoded = null;\r\n    int length = value.length();\r\n    int index = 0;\r\n    for (int i = 0; i < length; i++) {\r\n        char character = value.charAt(i);\r\n        if (reserved.indexOf(character) != -1) {\r\n            if (encoded == null) {\r\n                encoded = new StringBuilder(length + 8);\r\n            }\r\n            if (i != index) {\r\n                encoded.append(urlEncode(value.substring(index, i), charset));\r\n            }\r\n            encoded.append(character);\r\n            index = i + 1;\r\n        }\r\n    }\r\n    if (encoded == null) {\r\n        return urlEncode(value, charset);\r\n    }\r\n    if (index < length) {\r\n        encoded.append(urlEncode(value.substring(index, length), charset));\r\n    }\r\n    return encoded.toString();\r\n}"
}, {
	"Path": "com.alibaba.excel.util.CollectionUtils.findCommonElementType",
	"Comment": "find the common element type of the given collection, if any.",
	"Method": "Class<?> findCommonElementType(Collection<?> collection){\r\n    if (isEmpty(collection)) {\r\n        return null;\r\n    }\r\n    Class<?> candidate = null;\r\n    for (Object val : collection) {\r\n        if (val != null) {\r\n            if (candidate == null) {\r\n                candidate = val.getClass();\r\n            } else if (candidate != val.getClass()) {\r\n                return null;\r\n            }\r\n        }\r\n    }\r\n    return candidate;\r\n}"
}, {
	"Path": "feign.client.AbstractClientTest.testPatch",
	"Comment": "some client implementation tests should override this test if the patch operation isunsupported.",
	"Method": "void testPatch(){\r\n    server.enqueue(new MockResponse().setBody(\"foo\"));\r\n    server.enqueue(new MockResponse());\r\n    TestInterface api = newBuilder().target(TestInterface.class, \"http://localhost:\" + server.getPort());\r\n    assertEquals(\"foo\", api.patch(\"\"));\r\n    MockWebServerAssertions.assertThat(server.takeRequest()).hasHeaders(entry(\"Accept\", Collections.singletonList(\"text/plain\")), entry(\"Content-Length\", Collections.singletonList(\"0\"))).hasNoHeaderNamed(\"Content-Type\").hasMethod(\"PATCH\");\r\n}"
}, {
	"Path": "water.api.RequestServer.registerEndpoint",
	"Comment": "register an http request handler method for a given url pattern, with parameters extracted from the uri.uris which match this pattern will have their parameters collected from the path and from the query params",
	"Method": "Route registerEndpoint(String api_name,String method_uri,Class<? extends Handler> handler_class,String handler_method,String summary,Route registerEndpoint,String api_name,String http_method,String url,Class<? extends Handler> handler_class,String handler_method,String summary,HandlerFactory handler_factory,Route registerEndpoint,String method_uri,Class<? extends RestApiHandler> handler_clz,Route registerEndpoint,String apiName,String methodUri,Class<? extends Handler> handlerClass,String handlerMethod,String summary,Route registerEndpoint,String apiName,String httpMethod,String url,Class<? extends Handler> handlerClass,String handlerMethod,String summary,HandlerFactory handlerFactory,Route registerEndpoint,String methodUri,Class<? extends RestApiHandler> handlerClass){\r\n    try {\r\n        RestApiHandler handler = handler_clz.newInstance();\r\n        return registerEndpoint(handler.name(), method_uri, handler_clz, null, handler.help());\r\n    } catch (Exception e) {\r\n        throw H2O.fail(e.getMessage());\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.sybasease.SybaseASESchema.doClean",
	"Comment": "this clean method is equivalent to cleaning the whole database.",
	"Method": "void doClean(){\r\n    dropObjects(\"V\");\r\n    dropObjects(\"U\");\r\n    dropObjects(\"P\");\r\n    dropObjects(\"TR\");\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.crawler.Page.toByteArray",
	"Comment": "read contents from an entity, with a specified maximum. this is a replacement ofentityutils.tobytearray because that function does not impose a maximum size.",
	"Method": "byte[] toByteArray(HttpEntity entity,int maxBytes){\r\n    if (entity == null) {\r\n        return new byte[0];\r\n    }\r\n    try (InputStream is = entity.getContent()) {\r\n        int size = (int) entity.getContentLength();\r\n        int readBufferLength = size;\r\n        if (readBufferLength <= 0) {\r\n            readBufferLength = 4096;\r\n        }\r\n        readBufferLength = Math.min(readBufferLength, maxBytes);\r\n        ByteArrayBuffer buffer = new ByteArrayBuffer(readBufferLength);\r\n        byte[] tmpBuff = new byte[4096];\r\n        int dataLength;\r\n        while ((dataLength = is.read(tmpBuff)) != -1) {\r\n            if (maxBytes > 0 && (buffer.length() + dataLength) > maxBytes) {\r\n                truncated = true;\r\n                dataLength = maxBytes - buffer.length();\r\n            }\r\n            buffer.append(tmpBuff, 0, dataLength);\r\n            if (truncated) {\r\n                break;\r\n            }\r\n        }\r\n        return buffer.toByteArray();\r\n    }\r\n}"
}, {
	"Path": "water.H2ONode.index",
	"Comment": "index of this node in the current cloud... can change at the next cloud.",
	"Method": "int index(){\r\n    return H2O.CLOUD.nidx(this);\r\n}"
}, {
	"Path": "graphql.schema.GraphQLEnumType.transform",
	"Comment": "this helps you transform the current graphqlenumtype into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLEnumType transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newEnum(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "hex.AAA_PreCloudLock.testBasicStatusPages",
	"Comment": "should be able to load basic status pages without locking the cloud.",
	"Method": "void testBasicStatusPages(){\r\n    TypeMap._check_no_locking = true;\r\n    assertFalse(testRan);\r\n    assertFalse(Paxos._cloudLocked);\r\n    stall();\r\n    assertFalse(Paxos._cloudLocked);\r\n    try {\r\n        serve(\"/\", null);\r\n        serve(\"/Cloud.json\", null);\r\n        serve(\"/junk\", null);\r\n        serve(\"/HTTP404\", null);\r\n        Properties parms = new Properties();\r\n        parms.setProperty(\"src\", \"./smalldata/iris\");\r\n        serve(\"/Typeahead/files\", parms);\r\n        new hex.schemas.CoxPHV3();\r\n        new hex.schemas.DRFModelV3();\r\n        new hex.schemas.DRFV3();\r\n        new hex.schemas.DeepLearningModelV3();\r\n        new hex.schemas.DeepLearningV3();\r\n        new hex.schemas.ExampleModelV3();\r\n        new hex.schemas.ExampleV3();\r\n        new hex.schemas.GBMModelV3();\r\n        new hex.schemas.GBMV3();\r\n        new hex.schemas.GLMModelV3();\r\n        new hex.schemas.GLMV3();\r\n        new hex.schemas.GLRMV3();\r\n        new hex.schemas.GLRMModelV3();\r\n        new hex.schemas.GrepModelV3();\r\n        new hex.schemas.GrepV3();\r\n        new hex.schemas.KMeansModelV3();\r\n        new hex.schemas.KMeansV3();\r\n        new hex.schemas.MakeGLMModelV3();\r\n        new hex.schemas.NaiveBayesModelV3();\r\n        new hex.schemas.NaiveBayesV3();\r\n        new PCAModelV3();\r\n        new PCAV3();\r\n        new hex.schemas.SharedTreeModelV3();\r\n        new hex.schemas.SharedTreeV3();\r\n        new hex.schemas.Word2VecSynonymsV3();\r\n        new hex.schemas.TreeStatsV3();\r\n        new hex.schemas.Word2VecModelV3();\r\n        new hex.schemas.Word2VecV3();\r\n        assertFalse(\"Check of pre-cloud classes failed.  You likely made a Key before any outside action triggers cloud-lock.  \", Paxos._cloudLocked);\r\n    } finally {\r\n        testRan = true;\r\n        TypeMap._check_no_locking = false;\r\n    }\r\n}"
}, {
	"Path": "water.Key.toString",
	"Comment": "converts the key to html displayable string.for user keys returns the key itself, for system keys returns theirhexadecimal values.",
	"Method": "String toString(){\r\n    int len = _kb.length;\r\n    while (--len >= 0) {\r\n        char a = (char) _kb[len];\r\n        if (' ' <= a && a <= '#')\r\n            continue;\r\n        if ('%' <= a && a <= '~')\r\n            continue;\r\n        break;\r\n    }\r\n    if (len >= 0) {\r\n        StringBuilder sb = new StringBuilder();\r\n        sb.append(MAGIC_CHAR);\r\n        for (int i = 0; i <= len; ++i) {\r\n            byte a = _kb[i];\r\n            sb.append(HEX[(a >> 4) & 0x0F]);\r\n            sb.append(HEX[(a >> 0) & 0x0F]);\r\n        }\r\n        sb.append(MAGIC_CHAR);\r\n        for (int i = len + 1; i < _kb.length; ++i) sb.append((char) _kb[i]);\r\n        return sb.toString();\r\n    } else {\r\n        return new String(_kb);\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.PreconditionsCheckNotNullPrimitive.createCheckArgumentOrStateCall",
	"Comment": "creates a suggestedfix that replaces the checknotnull call with a checkargument or checkstatecall.",
	"Method": "Fix createCheckArgumentOrStateCall(MethodInvocationTree methodInvocationTree,VisitorState state,ExpressionTree arg1){\r\n    SuggestedFix.Builder fix = SuggestedFix.builder();\r\n    String replacementMethod = \"checkState\";\r\n    if (hasMethodParameter(state.getPath(), arg1)) {\r\n        replacementMethod = \"checkArgument\";\r\n    }\r\n    StringBuilder replacement = new StringBuilder();\r\n    if (methodInvocationTree.getMethodSelect().getKind() == Kind.IDENTIFIER) {\r\n        fix.addStaticImport(\"com.google.common.base.Preconditions.\" + replacementMethod);\r\n    } else {\r\n        replacement.append(\"Preconditions.\");\r\n    }\r\n    replacement.append(replacementMethod).append('(');\r\n    Joiner.on(\", \").appendTo(replacement, methodInvocationTree.getArguments());\r\n    replacement.append(\")\");\r\n    fix.replace(methodInvocationTree, replacement.toString());\r\n    return fix.build();\r\n}"
}, {
	"Path": "water.jdbc.SQLManager.initializeDatabaseDriver",
	"Comment": "initializes database driver for databases with jdbc driver version lower than 4.0",
	"Method": "void initializeDatabaseDriver(String databaseType){\r\n    String driverClass = System.getProperty(JDBC_DRIVER_CLASS_KEY_PREFIX + databaseType);\r\n    if (driverClass != null) {\r\n        Log.debug(\"Loading \" + driverClass + \" to initialize database of type \" + databaseType);\r\n        try {\r\n            Class.forName(driverClass);\r\n        } catch (ClassNotFoundException e) {\r\n            throw new RuntimeException(\"Connection to '\" + databaseType + \"' database is not possible due to missing JDBC driver. \" + \"User specified driver class: \" + driverClass, e);\r\n        }\r\n        return;\r\n    }\r\n    switch(databaseType) {\r\n        case HIVE_DB_TYPE:\r\n            try {\r\n                Class.forName(HIVE_JDBC_DRIVER_CLASS);\r\n            } catch (ClassNotFoundException e) {\r\n                throw new RuntimeException(\"Connection to HIVE database is not possible due to missing JDBC driver.\", e);\r\n            }\r\n            break;\r\n        case NETEZZA_DB_TYPE:\r\n            try {\r\n                Class.forName(NETEZZA_JDBC_DRIVER_CLASS);\r\n            } catch (ClassNotFoundException e) {\r\n                throw new RuntimeException(\"Connection to Netezza database is not possible due to missing JDBC driver.\", e);\r\n            }\r\n            break;\r\n        default:\r\n    }\r\n}"
}, {
	"Path": "feign.RequestTemplate.url",
	"Comment": "the url for the request. if the template has not been resolved, the url will represent a uritemplate.",
	"Method": "String url(){\r\n    StringBuilder url = new StringBuilder(this.path());\r\n    if (!this.queries.isEmpty()) {\r\n        url.append(this.queryLine());\r\n    }\r\n    return url.toString();\r\n}"
}, {
	"Path": "feign.RequestTemplate.uri",
	"Comment": "set the uri for the request, replacing the existing uri if set.",
	"Method": "RequestTemplate uri(String uri,RequestTemplate uri,String uri,boolean append){\r\n    if (UriUtils.isAbsolute(uri)) {\r\n        throw new IllegalArgumentException(\"url values must be not be absolute.\");\r\n    }\r\n    if (uri == null) {\r\n        uri = \"/\";\r\n    } else if ((!uri.isEmpty() && !uri.startsWith(\"/\") && !uri.startsWith(\"{\"))) {\r\n        uri = \"/\" + uri;\r\n    }\r\n    Matcher queryMatcher = QUERY_STRING_PATTERN.matcher(uri);\r\n    if (queryMatcher.find()) {\r\n        String queryString = uri.substring(queryMatcher.start() + 1);\r\n        this.extractQueryTemplates(queryString, append);\r\n        uri = uri.substring(0, queryMatcher.start());\r\n    }\r\n    if (append && this.uriTemplate != null) {\r\n        this.uriTemplate = UriTemplate.append(this.uriTemplate, uri);\r\n    } else {\r\n        this.uriTemplate = UriTemplate.create(uri, !this.decodeSlash, this.charset);\r\n    }\r\n    return this;\r\n}"
}, {
	"Path": "graphql.schema.GraphQLInputObjectType.transform",
	"Comment": "this helps you transform the current graphqlinputobjecttype into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLInputObjectType transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newInputObject(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "feign.template.Expression.matches",
	"Comment": "checks if the provided value matches the variable pattern, if one is defined. always true if nopattern is defined.",
	"Method": "boolean matches(String value){\r\n    if (pattern == null) {\r\n        return true;\r\n    }\r\n    return pattern.matcher(value).matches();\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.model.TestRecentGCResourcesModel.getPathExpansion",
	"Comment": "return the missing part of a relative path compared to its absolute path.",
	"Method": "String getPathExpansion(){\r\n    String resourceNameAsUrlString = new GcResourceFile(\"temp\").getResourceNameAsUrlString();\r\n    return resourceNameAsUrlString.substring(\"file:/\".length(), resourceNameAsUrlString.indexOf(\"temp\"));\r\n}"
}, {
	"Path": "hex.deeplearning.DeepLearningModel.makeWeightsBiases",
	"Comment": "helper to allocate keys for output frames for weights and biases",
	"Method": "void makeWeightsBiases(Key destKey){\r\n    if (!model_info.get_params()._export_weights_and_biases) {\r\n        _output.weights = null;\r\n        _output.biases = null;\r\n        _output.normmul = null;\r\n        _output.normsub = null;\r\n        _output.normrespmul = null;\r\n        _output.normrespsub = null;\r\n        _output.catoffsets = null;\r\n    } else {\r\n        _output.weights = new Key[get_params()._hidden.length + 1];\r\n        for (int i = 0; i < _output.weights.length; ++i) {\r\n            _output.weights[i] = Key.make(destKey + \".weights.\" + i);\r\n        }\r\n        _output.biases = new Key[get_params()._hidden.length + 1];\r\n        for (int i = 0; i < _output.biases.length; ++i) {\r\n            _output.biases[i] = Key.make(destKey + \".biases.\" + i);\r\n        }\r\n        _output.normmul = model_info.data_info._normMul;\r\n        _output.normsub = model_info.data_info._normSub;\r\n        _output.normrespmul = model_info.data_info._normRespMul;\r\n        _output.normrespsub = model_info.data_info._normRespSub;\r\n        _output.catoffsets = model_info.data_info._catOffsets;\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.CompilationTestHelper.matchAllDiagnostics",
	"Comment": "by default, the compilation helper will only inspect diagnostics generated by the check beingtested. this behaviour can be disabled to test the interaction between error prone checks andjavac diagnostics.",
	"Method": "CompilationTestHelper matchAllDiagnostics(){\r\n    this.lookForCheckNameInDiagnostic = LookForCheckNameInDiagnostic.NO;\r\n    return this;\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setConnectRetries",
	"Comment": "the maximum number of retries when attempting to connect to the database. after each failed attempt, flyway willwait 1 second before attempting to connect again, up to the maximum number of times specified by connectretries.",
	"Method": "void setConnectRetries(int connectRetries){\r\n    if (connectRetries < 0) {\r\n        throw new FlywayException(\"Invalid number of connectRetries (must be 0 or greater): \" + connectRetries);\r\n    }\r\n    this.connectRetries = connectRetries;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.renderer.PolygonChartRenderer.initClippedPolygon",
	"Comment": "updates the clippedpolygon instance in this class to contain only the pointsneeded to fill the current clipped area.",
	"Method": "Polygon initClippedPolygon(Polygon polygon,Shape clip){\r\n    int xMin = (int) clip.getBounds2D().getMinX();\r\n    int xMax = (int) Math.ceil(clip.getBounds2D().getMaxX());\r\n    if (polygon.npoints > 1000 && (xMin > polygon.xpoints[0] || xMax < polygon.xpoints[polygon.npoints - 1])) {\r\n        InsertionBoundary insertionPoint = findInsertionBoundary(polygon, xMin, xMax);\r\n        int[] xpoints = new int[insertionPoint.getDistance() + 2];\r\n        int[] ypoints = new int[insertionPoint.getDistance() + 2];\r\n        System.arraycopy(polygon.xpoints, insertionPoint.getStartX(), xpoints, 1, insertionPoint.getDistance() + 1);\r\n        System.arraycopy(polygon.ypoints, insertionPoint.getStartX(), ypoints, 1, insertionPoint.getDistance() + 1);\r\n        xpoints[0] = xpoints[1] - 1;\r\n        if (drawPolygon) {\r\n            ypoints[0] = (int) Math.ceil(clip.getBounds2D().getMaxY());\r\n        } else {\r\n            ypoints[0] = ypoints[1];\r\n        }\r\n        clippedPolygon.xpoints = xpoints;\r\n        clippedPolygon.ypoints = ypoints;\r\n        clippedPolygon.npoints = insertionPoint.getDistance() + 2;\r\n        clippedPolygon.addPoint(xpoints[xpoints.length - 1] + 1, ypoints[0]);\r\n    } else {\r\n        clippedPolygon.xpoints = polygon.xpoints;\r\n        clippedPolygon.ypoints = polygon.ypoints;\r\n        clippedPolygon.npoints = polygon.npoints;\r\n    }\r\n    clippedPolygon.invalidate();\r\n    return clippedPolygon;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.model.GCEvent.getPerm",
	"Comment": "returns information on perm generation. if it was not present in the gc log,null will be returned, because the values cannot be inferred.",
	"Method": "GCEvent getPerm(){\r\n    return perm;\r\n}"
}, {
	"Path": "water.ExternalFrameReaderClient.isLastNA",
	"Comment": "this method is used to check if the last received value was marked as na by h2o backend",
	"Method": "boolean isLastNA(){\r\n    return isLastNA;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.DataReaderTools.getMemoryInKiloByte",
	"Comment": "returns the amount of memory in kilobyte. depending on memunit, input isconverted to kilobyte.",
	"Method": "int getMemoryInKiloByte(double memoryValue,char memUnit,String line){\r\n    if ('B' == memUnit) {\r\n        return (int) Math.rint(memoryValue / 1024);\r\n    } else if ('K' == memUnit) {\r\n        return (int) Math.rint(memoryValue);\r\n    } else if ('M' == memUnit) {\r\n        return (int) Math.rint(memoryValue * 1024);\r\n    } else if ('G' == memUnit) {\r\n        return (int) Math.rint(memoryValue * 1024 * 1024);\r\n    } else {\r\n        if (logger.isLoggable(Level.WARNING)) {\r\n            logger.warning(\"unknown memoryunit '\" + memUnit + \"' in line \" + line);\r\n        }\r\n        return 1;\r\n    }\r\n}"
}, {
	"Path": "hex.deepwater.DeepWater.haveBackend",
	"Comment": "check whether we have any deep water native backends available",
	"Method": "boolean haveBackend(boolean haveBackend,DeepWaterParameters.Backend b){\r\n    return DeepwaterMojoModel.createDeepWaterBackend(b.toString()) != null;\r\n}"
}, {
	"Path": "jsr166y.Phaser.getArrivedParties",
	"Comment": "returns the number of registered parties that have arrived atthe current phase of this phaser. if this phaser has terminated,the returned value is meaningless and arbitrary.",
	"Method": "int getArrivedParties(){\r\n    return arrivedOf(reconcileState());\r\n}"
}, {
	"Path": "com.google.errorprone.apply.ImportStatements.toString",
	"Comment": "returns a string representation of the imports as java code in correct order.",
	"Method": "String toString(){\r\n    if (importStrings.isEmpty()) {\r\n        return \"\";\r\n    }\r\n    StringBuilder result = new StringBuilder();\r\n    if (!hasExistingImports) {\r\n        result.append('\\n');\r\n    }\r\n    List<ImportOrganizer.Import> imports = importStrings.stream().map(ImportOrganizer.Import::importOf).collect(Collectors.toList());\r\n    ImportOrganizer.OrganizedImports organizedImports = importOrganizer.organizeImports(imports);\r\n    int expectedImportCount = imports.size();\r\n    int importCount = organizedImports.getImportCount();\r\n    if (importCount != expectedImportCount) {\r\n        throw new IllegalStateException(String.format(\"Expected %d import(s) in the organized imports but it contained %d\", expectedImportCount, importCount));\r\n    }\r\n    result.append(organizedImports.asImportBlock());\r\n    String replacementString = result.toString();\r\n    if (!hasExistingImports) {\r\n        return replacementString;\r\n    } else {\r\n        return CharMatcher.whitespace().trimTrailingFrom(replacementString);\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.scanner.Scanner.isSuppressed",
	"Comment": "returns true if this checker should be suppressed on the current tree path.",
	"Method": "boolean isSuppressed(Suppressible suppressible,ErrorProneOptions errorProneOptions){\r\n    initSuppressionHelper();\r\n    return SuppressionHelper.isSuppressed(suppressible, suppressions, customSuppressions, severityMap().get(suppressible.canonicalName()), inGeneratedCode, errorProneOptions.disableWarningsInGeneratedCode());\r\n}"
}, {
	"Path": "water.persist.PersistManager.isWritableDirectory",
	"Comment": "check whether given path represents a writable directory. if such path does not existit will try to create the directory and if successful it is safe to assume that suchdirectory is writable.",
	"Method": "boolean isWritableDirectory(String path){\r\n    URI pathAsUri = FileUtils.getURI(path);\r\n    Persist persist = getPersistForURI(pathAsUri);\r\n    String pathUriStr = pathAsUri.toString();\r\n    if (persist.isDirectory(pathUriStr)) {\r\n        return isDirectoryWritable(persist, path);\r\n    } else if (persist.exists(pathUriStr)) {\r\n        return false;\r\n    } else {\r\n        String existingParent = getExistingParent(persist, pathUriStr);\r\n        if (existingParent != null) {\r\n            return isDirectoryWritable(persist, existingParent);\r\n        } else {\r\n            return false;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.hasIdentifier",
	"Comment": "matches any ast that contains an identifier with a certain property. this matcher can be used,for instance, to locate identifiers with a certain name or which is defined in a certain class.",
	"Method": "Matcher<Tree> hasIdentifier(Matcher<IdentifierTree> nodeMatcher){\r\n    return new HasIdentifier(nodeMatcher);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.SqlStatementBuilder.cleanToken",
	"Comment": "performs additional cleanup on this token, such as removing charset casting that prefixes string literals.must be implemented in dialect specific sub classes.",
	"Method": "String cleanToken(String token){\r\n    return token;\r\n}"
}, {
	"Path": "graphql.schema.GraphQLInterfaceType.getTypeResolver",
	"Comment": "to be removed in a future version when all code is in the code registry",
	"Method": "TypeResolver getTypeResolver(){\r\n    return typeResolver;\r\n}"
}, {
	"Path": "water.MRTask.remote_compute",
	"Comment": "pending completion to self, so that we complete when the rpc completes.",
	"Method": "RPC<T> remote_compute(int nlo,int nhi){\r\n    if (nlo < nhi) {\r\n        int node = addShift(nlo);\r\n        assert node != H2O.SELF.index();\r\n        T mrt = copyAndInit();\r\n        mrt._nhi = (short) nhi;\r\n        addToPendingCount(1);\r\n        return new RPC(H2O.CLOUD._memary[node], mrt).addCompleter(this).call();\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.NarrowingCompoundAssignmentTest.testBitTwiddle",
	"Comment": "bit twiddling deficient types with masks of the same width is fine",
	"Method": "void testBitTwiddle(){\r\n    compilationHelper.addSourceLines(\"Test.java\", \"class Test {\", \"  void m() {\", \"    short smask = 0b1;\", \"    byte bmask = 0b1;\", \"\", \"    short s = 0;\", \"    byte b = 0;\", \"\", \"    s &= smask;\", \"    s |= smask;\", \"    s ^= smask;\", \"\", \"    s &= bmask;\", \"    s |= bmask;\", \"    s ^= bmask;\", \"\", \"    b &= bmask;\", \"    b |= bmask;\", \"    b ^= bmask;\", \"  }\", \"}\").doTest();\r\n}"
}, {
	"Path": "org.flywaydb.core.api.MigrationVersion.fromVersion",
	"Comment": "factory for creating a migrationversion from a version string",
	"Method": "MigrationVersion fromVersion(String version){\r\n    if (\"current\".equalsIgnoreCase(version))\r\n        return CURRENT;\r\n    if (LATEST.getVersion().equals(version))\r\n        return LATEST;\r\n    if (version == null)\r\n        return EMPTY;\r\n    return new MigrationVersion(version);\r\n}"
}, {
	"Path": "water.fvec.Vec.makeCon",
	"Comment": "make a new constant vector with the given row count, and redistribute the dataevenly around the cluster.",
	"Method": "Vec makeCon(double x,long len,Vec makeCon,double x,long len,byte type,Vec makeCon,double x,long len,boolean redistribute,Vec makeCon,double x,long len,boolean redistribute,byte typeCode,Vec makeCon,double x,long len,int log_rows_per_chunk,Vec makeCon,long totSize,long len,Vec makeCon,double x,long len,int log_rows_per_chunk,boolean redistribute,Vec makeCon,double x,long len,int log_rows_per_chunk,boolean redistribute,byte type,Vec makeCon,long l,String[] domain,VectorGroup group,int rowLayout,Vec makeCon,long l,String[] domain,VectorGroup group,int rowLayout,byte type,Vec makeCon,double d,Vec makeCon,double d,byte type,Vec makeCon,double d,VectorGroup group,int rowLayout,byte type,Vec makeCon,String s,Vec makeCon,String s,VectorGroup group,int rowLayout,byte type,Vec makeCon,Key<Vec> k,double rows){\r\n    k = k == null ? Vec.VectorGroup.VG_LEN1.addVec() : k;\r\n    Futures fs = new Futures();\r\n    AppendableVec avec = new AppendableVec(k, T_NUM);\r\n    NewChunk chunk = new NewChunk(avec, 0);\r\n    for (double r : rows) chunk.addNum(r);\r\n    chunk.close(0, fs);\r\n    Vec vec = avec.layout_and_close(fs);\r\n    fs.blockForPending();\r\n    return vec;\r\n}"
}, {
	"Path": "org.flywaydb.core.api.MigrationVersion.isMajorNewerThan",
	"Comment": "convenience method for quickly checking whether this major version is newer than this other major version.",
	"Method": "boolean isMajorNewerThan(String otherVersion){\r\n    return getMajor().compareTo(MigrationVersion.fromVersion(otherVersion).getMajor()) > 0;\r\n}"
}, {
	"Path": "org.flywaydb.core.api.MigrationVersion.isAtLeast",
	"Comment": "convenience method for quickly checking whether this version is at least as new as this other version.",
	"Method": "boolean isAtLeast(String otherVersion){\r\n    return compareTo(MigrationVersion.fromVersion(otherVersion)) >= 0;\r\n}"
}, {
	"Path": "graphql.execution.instrumentation.fieldvalidation.SimpleFieldValidation.addRule",
	"Comment": "adds the rule against the field address path.if the rule returns an error, it will be added to the list of errors",
	"Method": "SimpleFieldValidation addRule(ExecutionPath fieldPath,BiFunction<FieldAndArguments, FieldValidationEnvironment, Optional<GraphQLError>> rule){\r\n    rules.put(fieldPath, rule);\r\n    return this;\r\n}"
}, {
	"Path": "graphql.schema.PropertyDataFetcher.clearReflectionCache",
	"Comment": "propertydatafetcher caches the methods and fields that map from a class to a property for runtime performance reasons.however during development you might be using an assistance tool like jrebel to allow you to tweak your code base and thiscaching may interfere with this.so you can call this method to clear the cache.a jrebel plugin couldbe developed to do just that.",
	"Method": "void clearReflectionCache(){\r\n    METHOD_CACHE.clear();\r\n    FIELD_CACHE.clear();\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.stripParentheses",
	"Comment": "given an expressiontree, removes any enclosing parentheses.",
	"Method": "Tree stripParentheses(Tree tree,ExpressionTree stripParentheses,ExpressionTree tree){\r\n    while (tree instanceof ParenthesizedTree) {\r\n        tree = ((ParenthesizedTree) tree).getExpression();\r\n    }\r\n    return tree;\r\n}"
}, {
	"Path": "hex.deeplearning.DeepLearningTest.unifyFrame",
	"Comment": "put response as the last vector in the frame and return possible frames to clean up later",
	"Method": "Vec unifyFrame(DeepLearningParameters drf,Frame fr,PrepData prep,boolean classification){\r\n    int idx = prep.prep(fr);\r\n    if (idx < 0) {\r\n        idx = ~idx;\r\n    }\r\n    String rname = fr._names[idx];\r\n    drf._response_column = fr.names()[idx];\r\n    Vec resp = fr.vecs()[idx];\r\n    Vec ret = null;\r\n    if (classification) {\r\n        ret = fr.remove(idx);\r\n        fr.add(rname, resp.toCategoricalVec());\r\n    } else {\r\n        fr.remove(idx);\r\n        fr.add(rname, resp);\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "hex.glm.GLMTest.testAirlines",
	"Comment": "once on explicitly expanded data, once on h2o autoexpanded and compare the results",
	"Method": "void testAirlines(){\r\n    GLMModel model1 = null, model2 = null, model3 = null, model4 = null;\r\n    Frame frMM = parse_test_file(Key.make(\"AirlinesMM\"), \"smalldata/airlines/AirlinesTrainMM.csv.zip\");\r\n    Frame frG = parse_test_file(Key.make(\"gram\"), \"smalldata/airlines/gram_std.csv\", true);\r\n    Vec xy = frG.remove(\"xy\");\r\n    frMM.remove(\"C1\").remove();\r\n    Vec v;\r\n    frMM.add(\"IsDepDelayed\", (v = frMM.remove(\"IsDepDelayed\")).makeCopy(null));\r\n    v.remove();\r\n    DKV.put(frMM._key, frMM);\r\n    Frame fr = parse_test_file(Key.make(\"Airlines\"), \"smalldata/airlines/AirlinesTrain.csv.zip\"), res = null;\r\n    fr.add(\"IsDepDelayed\", (v = fr.remove(\"IsDepDelayed\")).makeCopy(null));\r\n    v.remove();\r\n    DKV.put(fr._key, fr);\r\n    String[] ignoredCols = new String[] { \"fYear\", \"fMonth\", \"fDayofMonth\", \"fDayOfWeek\", \"DepTime\", \"ArrTime\", \"IsDepDelayed_REC\" };\r\n    try {\r\n        Scope.enter();\r\n        GLMParameters params = new GLMParameters(Family.gaussian);\r\n        params._response_column = \"IsDepDelayed\";\r\n        params._ignored_columns = ignoredCols;\r\n        params._train = fr._key;\r\n        params._lambda = new double[] { 0 };\r\n        params._alpha = new double[] { 0 };\r\n        params._standardize = false;\r\n        params._use_all_factor_levels = false;\r\n        model1 = new GLM(params).trainModel().get();\r\n        testScoring(model1, fr);\r\n        Frame score1 = model1.score(fr);\r\n        ModelMetricsRegressionGLM mm = (ModelMetricsRegressionGLM) ModelMetrics.getFromDKV(model1, fr);\r\n        Assert.assertEquals(((ModelMetricsRegressionGLM) model1._output._training_metrics)._resDev, mm._resDev, 1e-4);\r\n        Assert.assertEquals(((ModelMetricsRegressionGLM) model1._output._training_metrics)._resDev, mm._MSE * score1.numRows(), 1e-4);\r\n        score1.delete();\r\n        mm.remove();\r\n        res = model1.score(fr);\r\n        params._train = frMM._key;\r\n        params._ignored_columns = new String[] { \"X\" };\r\n        model2 = new GLM(params).trainModel().get();\r\n        HashMap<String, Double> coefs1 = model1.coefficients();\r\n        testScoring(model2, frMM);\r\n        HashMap<String, Double> coefs2 = model2.coefficients();\r\n        boolean failed = false;\r\n        for (String s : coefs2.keySet()) {\r\n            String s1 = s;\r\n            if (s.startsWith(\"Origin\"))\r\n                s1 = \"Origin.\" + s.substring(6);\r\n            if (s.startsWith(\"Dest\"))\r\n                s1 = \"Dest.\" + s.substring(4);\r\n            if (s.startsWith(\"UniqueCarrier\"))\r\n                s1 = \"UniqueCarrier.\" + s.substring(13);\r\n            if (Math.abs(coefs1.get(s1) - coefs2.get(s)) > 1e-4) {\r\n                System.out.println(\"coeff \" + s1 + \" differs, \" + coefs1.get(s1) + \" != \" + coefs2.get(s));\r\n                failed = true;\r\n            }\r\n        }\r\n        assertFalse(failed);\r\n        params._standardize = true;\r\n        params._train = frMM._key;\r\n        params._use_all_factor_levels = true;\r\n        DataInfo dinfo = new DataInfo(frMM, null, 1, true, DataInfo.TransformType.STANDARDIZE, DataInfo.TransformType.NONE, true, false, false, false, false, false);\r\n        GLMIterationTask glmt = new GLMIterationTask(null, dinfo, new GLMWeightsFun(params), null).doAll(dinfo._adaptedFrame);\r\n        for (int i = 0; i < glmt._xy.length; ++i) {\r\n            for (int j = 0; j <= i; ++j) {\r\n                assertEquals(frG.vec(j).at(i), glmt._gram.get(i, j), 1e-5);\r\n            }\r\n            assertEquals(xy.at(i), glmt._xy[i], 1e-5);\r\n        }\r\n        xy.remove();\r\n        params = (GLMParameters) params.clone();\r\n        params._standardize = false;\r\n        params._family = Family.binomial;\r\n        params._link = Link.logit;\r\n        model3 = new GLM(params).trainModel().get();\r\n        testScoring(model3, frMM);\r\n        params._train = fr._key;\r\n        params._ignored_columns = ignoredCols;\r\n        model4 = new GLM(params).trainModel().get();\r\n        testScoring(model4, fr);\r\n        assertEquals(nullDeviance(model3), nullDeviance(model4), 1e-4);\r\n        assertEquals(residualDeviance(model4), residualDeviance(model3), nullDeviance(model3) * 1e-3);\r\n        assertEquals(nullDeviance(model1), nullDeviance(model2), 1e-4);\r\n        assertEquals(residualDeviance(model1), residualDeviance(model2), 1e-4);\r\n        assertEquals(5336.918, residualDeviance(model1), 1);\r\n        assertEquals(6051.613, nullDeviance(model2), 1);\r\n    } finally {\r\n        fr.delete();\r\n        frMM.delete();\r\n        frG.delete();\r\n        if (res != null)\r\n            res.delete();\r\n        if (model1 != null)\r\n            model1.delete();\r\n        if (model2 != null)\r\n            model2.delete();\r\n        if (model3 != null)\r\n            model3.delete();\r\n        if (model4 != null)\r\n            model4.delete();\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.refaster.PlaceholderMethod.requiredParameters",
	"Comment": "parameters which must be referenced in any tree matched to this placeholder.",
	"Method": "Set<UVariableDecl> requiredParameters(){\r\n    return Maps.filterValues(annotatedParameters(), (ImmutableClassToInstanceMap<Annotation> annotations) -> !annotations.containsKey(MayOptionallyUse.class)).keySet();\r\n}"
}, {
	"Path": "com.google.errorprone.fixes.SuggestedFix.replace",
	"Comment": "replace the characters from startpos, inclusive, until endpos, exclusive, with the givenstring.",
	"Method": "SuggestedFix replace(Tree tree,String replaceWith,SuggestedFix replace,int startPos,int endPos,String replaceWith,SuggestedFix replace,Tree node,String replaceWith,int startPosAdjustment,int endPosAdjustment,Builder replace,Tree node,String replaceWith,Builder replace,int startPos,int endPos,String replaceWith,Builder replace,Tree node,String replaceWith,int startPosAdjustment,int endPosAdjustment){\r\n    return builder().replace(node, replaceWith, startPosAdjustment, endPosAdjustment).build();\r\n}"
}, {
	"Path": "com.google.errorprone.util.FindIdentifiers.findIdent",
	"Comment": "finds a declaration with the given name and type that is in scope at the current location.",
	"Method": "Symbol findIdent(String name,VisitorState state,Symbol findIdent,String name,VisitorState state,KindSelector kind){\r\n    ClassType enclosingClass = ASTHelpers.getType(state.findEnclosing(ClassTree.class));\r\n    if (enclosingClass == null || enclosingClass.tsym == null) {\r\n        return null;\r\n    }\r\n    Env<AttrContext> env = Enter.instance(state.context).getClassEnv(enclosingClass.tsym);\r\n    MethodTree enclosingMethod = state.findEnclosing(MethodTree.class);\r\n    if (enclosingMethod != null) {\r\n        env = MemberEnter.instance(state.context).getMethodEnv((JCMethodDecl) enclosingMethod, env);\r\n    }\r\n    try {\r\n        Method method = Resolve.class.getDeclaredMethod(\"findIdent\", Env.class, Name.class, KindSelector.class);\r\n        method.setAccessible(true);\r\n        Symbol result = (Symbol) method.invoke(Resolve.instance(state.context), env, state.getName(name), kind);\r\n        return result.exists() ? result : null;\r\n    } catch (ReflectiveOperationException e) {\r\n        throw new LinkageError(e.getMessage(), e);\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.db2.DB2Schema.generateDropStatementsForProcedures",
	"Comment": "generates drop statements for the procedures in this schema.",
	"Method": "List<String> generateDropStatementsForProcedures(){\r\n    String dropProcGenQuery = \"select SPECIFICNAME from SYSCAT.PROCEDURES where PROCSCHEMA = '\" + name + \"'\";\r\n    return buildDropStatements(\"DROP SPECIFIC PROCEDURE\", dropProcGenQuery);\r\n}"
}, {
	"Path": "graphql.execution.ExecutionStrategy.completeValueForObject",
	"Comment": "called to turn an java object value into an graphql object value",
	"Method": "CompletableFuture<ExecutionResult> completeValueForObject(ExecutionContext executionContext,ExecutionStrategyParameters parameters,GraphQLObjectType resolvedObjectType,Object result){\r\n    ExecutionStepInfo executionStepInfo = parameters.getExecutionStepInfo();\r\n    FieldCollectorParameters collectorParameters = newParameters().schema(executionContext.getGraphQLSchema()).objectType(resolvedObjectType).fragments(executionContext.getFragmentsByName()).variables(executionContext.getVariables()).build();\r\n    Map<String, List<Field>> subFields = fieldCollector.collectFields(collectorParameters, parameters.getField());\r\n    ExecutionStepInfo newExecutionStepInfo = executionStepInfo.changeTypeWithPreservedNonNull(resolvedObjectType);\r\n    NonNullableFieldValidator nonNullableFieldValidator = new NonNullableFieldValidator(executionContext, newExecutionStepInfo);\r\n    ExecutionStrategyParameters newParameters = parameters.transform(builder -> builder.executionStepInfo(newExecutionStepInfo).fields(subFields).nonNullFieldValidator(nonNullableFieldValidator).source(result));\r\n    return executionContext.getQueryStrategy().execute(executionContext, newParameters);\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.skipDefaultCallbacks",
	"Comment": "whether flyway should skip the default callbacks. if true, only custom callbacks are used.",
	"Method": "FluentConfiguration skipDefaultCallbacks(boolean skipDefaultCallbacks){\r\n    config.setSkipDefaultCallbacks(skipDefaultCallbacks);\r\n    return this;\r\n}"
}, {
	"Path": "graphql.schema.visibility.GraphqlFieldVisibility.getFieldDefinitions",
	"Comment": "called to get the list of fields from an object type or interface",
	"Method": "List<GraphQLFieldDefinition> getFieldDefinitions(GraphQLFieldsContainer fieldsContainer,List<GraphQLInputObjectField> getFieldDefinitions,GraphQLInputFieldsContainer fieldsContainer){\r\n    return fieldsContainer.getFieldDefinitions();\r\n}"
}, {
	"Path": "feign.RequestTemplate.bodyTemplate",
	"Comment": "specify the body template to use. can contain literals and expressions.",
	"Method": "RequestTemplate bodyTemplate(String bodyTemplate,String bodyTemplate){\r\n    return body.bodyTemplate();\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.allOf",
	"Comment": "compose several matchers together, such that the composite matches an ast node iff all thegiven matchers do.",
	"Method": "Matcher<T> allOf(Matcher<? super T> matchers){\r\n    return new Matcher<T>() {\r\n        @Override\r\n        public boolean matches(T t, VisitorState state) {\r\n            for (Matcher<? super T> matcher : matchers) {\r\n                if (!matcher.matches(t, state)) {\r\n                    return false;\r\n                }\r\n            }\r\n            return true;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.allOf",
	"Comment": "compose several matchers together, such that the composite matches an ast node iff all thegiven matchers do.",
	"Method": "Matcher<T> allOf(Matcher<? super T> matchers){\r\n    for (Matcher<? super T> matcher : matchers) {\r\n        if (!matcher.matches(t, state)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.postgresql.PostgreSQLSchema.generateDropStatementsForViews",
	"Comment": "generates the statements for dropping the views in this schema.",
	"Method": "List<String> generateDropStatementsForViews(){\r\n    List<String> viewNames = // Search for all views\r\n    jdbcTemplate.queryForStringList(\"SELECT relname FROM pg_catalog.pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace\" + \" LEFT JOIN pg_depend dep ON dep.objid = c.oid AND dep.deptype = 'e'\" + \" WHERE c.relkind = 'v' AND  n.nspname = ? AND dep.objid IS NULL\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (String domainName : viewNames) {\r\n        statements.add(\"DROP VIEW IF EXISTS \" + database.quote(name, domainName) + \" CASCADE\");\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "hex.glm.GLMBasicTestOrdinal.testOrdinalMultinomial",
	"Comment": "alternate calculation without the distributed framework.the datasets contains only numerical columns.",
	"Method": "void testOrdinalMultinomial(){\r\n    try {\r\n        Scope.enter();\r\n        Frame trainMultinomial = Scope.track(parse_test_file(\"smalldata/glm_ordinal_logit/ordinal_multinomial_training_set_small.csv\"));\r\n        convert2Enum(trainMultinomial, new int[] { 25 });\r\n        final int iterNum = new Random().nextInt(10) + 2;\r\n        Log.info(\"testOrdinalMultinomial will use iterNum = \" + iterNum);\r\n        GLMModel.GLMParameters paramsO = new GLMModel.GLMParameters(GLMModel.GLMParameters.Family.ordinal, GLMModel.GLMParameters.Family.ordinal.defaultLink, new double[] { 0 }, new double[] { 0 }, 0, 0);\r\n        paramsO._train = trainMultinomial._key;\r\n        paramsO._lambda_search = false;\r\n        paramsO._response_column = \"C26\";\r\n        paramsO._lambda = new double[] { 1e-6 };\r\n        paramsO._alpha = new double[] { 1e-5 };\r\n        paramsO._objective_epsilon = 1e-6;\r\n        paramsO._beta_epsilon = 1e-4;\r\n        paramsO._max_iterations = iterNum;\r\n        paramsO._standardize = false;\r\n        paramsO._seed = 987654321;\r\n        paramsO._obj_reg = 1e-7;\r\n        GLMModel model = new GLM(paramsO).trainModel().get();\r\n        Scope.track_generic(model);\r\n        double[] interceptPDF = model._ymu;\r\n        double[][] coeffs = model._output._global_beta_multinomial;\r\n        double[] beta = new double[coeffs[0].length - 1];\r\n        double[] icpt = new double[coeffs.length - 1];\r\n        updateOrdinalCoeff(trainMultinomial, 25, paramsO, interceptPDF, coeffs[0].length, Integer.parseInt(model._output._model_summary.getCellValues()[0][5].toString()), beta, icpt);\r\n        compareMultCoeffs(coeffs, beta, icpt);\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "water.api.Handler.handle",
	"Comment": "invoke the handler with parameters.can throw any exception the called handler can throw.",
	"Method": "Schema handle(int version,Route route,Properties parms,String post_body){\r\n    Class<? extends Schema> handler_schema_class = getHandlerMethodInputSchema(route._handler_method);\r\n    Schema schema = Schema.newInstance(handler_schema_class);\r\n    Class<? extends Iced> iced_class = schema.getImplClass();\r\n    if (iced_class != Iced.class) {\r\n        Iced defaults = schema.createImpl();\r\n        schema.fillFromImpl(defaults);\r\n    }\r\n    boolean is_post_of_json = (null != post_body);\r\n    schema = schema.fillFromParms(parms, !is_post_of_json);\r\n    if (schema == null)\r\n        throw H2O.fail(\"fillFromParms returned a null schema for version: \" + version + \" in: \" + this.getClass() + \" with params: \" + parms);\r\n    if (is_post_of_json) {\r\n        PojoUtils.fillFromJson(schema, post_body);\r\n    }\r\n    Schema result = null;\r\n    try {\r\n        route._handler_method.setAccessible(true);\r\n        result = (Schema) route._handler_method.invoke(this, version, schema);\r\n    } catch (InvocationTargetException ite) {\r\n        Throwable t = ite.getCause();\r\n        if (t instanceof RuntimeException)\r\n            throw (RuntimeException) t;\r\n        if (t instanceof Error)\r\n            throw (Error) t;\r\n        throw new RuntimeException(t);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.ConstantOverflow.longFix",
	"Comment": "if the left operand of an int binary expression is an int literal, suggest making it a long.",
	"Method": "Fix longFix(ExpressionTree expr,VisitorState state){\r\n    BinaryTree binExpr = null;\r\n    while (expr instanceof BinaryTree) {\r\n        binExpr = (BinaryTree) expr;\r\n        expr = binExpr.getLeftOperand();\r\n    }\r\n    if (!(expr instanceof LiteralTree) || expr.getKind() != Kind.INT_LITERAL) {\r\n        return null;\r\n    }\r\n    Type intType = state.getSymtab().intType;\r\n    if (!isSameType(getType(binExpr), intType, state)) {\r\n        return null;\r\n    }\r\n    SuggestedFix.Builder fix = SuggestedFix.builder().postfixWith(expr, \"L\");\r\n    Tree parent = state.getPath().getParentPath().getLeaf();\r\n    if (parent instanceof VariableTree && isSameType(getType(parent), intType, state)) {\r\n        fix.replace(((VariableTree) parent).getType(), \"long\");\r\n    }\r\n    return fix.build();\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.enclosingBlock",
	"Comment": "matches an ast node which is enclosed by a block node that matches the given matcher.",
	"Method": "Enclosing.Block<T> enclosingBlock(Matcher<BlockTree> matcher){\r\n    return new Enclosing.Block(matcher);\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.inSamePackage",
	"Comment": "return true if the given symbol is defined in the current package.",
	"Method": "boolean inSamePackage(Symbol targetSymbol,VisitorState state){\r\n    JCCompilationUnit compilationUnit = (JCCompilationUnit) state.getPath().getCompilationUnit();\r\n    PackageSymbol usePackage = compilationUnit.packge;\r\n    PackageSymbol targetPackage = targetSymbol.packge();\r\n    return targetPackage != null && usePackage != null && targetPackage.getQualifiedName().equals(usePackage.getQualifiedName());\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.schemahistory.JdbcTableSchemaHistory.determineTable",
	"Comment": "checks whether flyway has to fallback to the old default table.",
	"Method": "Table determineTable(Table table){\r\n    if (table.getName().equals(\"flyway_schema_history\") && !table.exists()) {\r\n        Table fallbackTable = table.getSchema().getTable(\"schema_version\");\r\n        if (fallbackTable.exists()) {\r\n            LOG.warn(\"Could not find schema history table \" + table + \", but found \" + fallbackTable + \" instead.\" + \" You are seeing this message because Flyway changed its default for flyway.table in\" + \" version 5.0.0 to flyway_schema_history and you are still relying on the old default (schema_version).\" + \" Set flyway.table=schema_version in your configuration to fix this.\" + \" This fallback mechanism will be removed in Flyway 6.0.0.\");\r\n            table = fallbackTable;\r\n        }\r\n    }\r\n    return table;\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.matchBinaryTree",
	"Comment": "given a binarytree to match against and a list of two matchers, applies the matchers to theoperands in both orders. if both matchers match, returns a list with the operand that matchedeach matcher in the corresponding position.",
	"Method": "List<ExpressionTree> matchBinaryTree(BinaryTree tree,List<Matcher<ExpressionTree>> matchers,VisitorState state){\r\n    ExpressionTree leftOperand = tree.getLeftOperand();\r\n    ExpressionTree rightOperand = tree.getRightOperand();\r\n    if (matchers.get(0).matches(leftOperand, state) && matchers.get(1).matches(rightOperand, state)) {\r\n        return Arrays.asList(leftOperand, rightOperand);\r\n    } else if (matchers.get(0).matches(rightOperand, state) && matchers.get(1).matches(leftOperand, state)) {\r\n        return Arrays.asList(rightOperand, leftOperand);\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.argumentselectiondefects.NameInCommentHeuristic.isAcceptableChange",
	"Comment": "return true if there are no comments on the original actual parameter of a change which matchthe name of the formal parameter.",
	"Method": "boolean isAcceptableChange(Changes changes,Tree node,MethodSymbol symbol,VisitorState state){\r\n    ImmutableList<Commented<ExpressionTree>> comments = findCommentsForArguments(node, state);\r\n    return changes.changedPairs().stream().noneMatch(p -> {\r\n        MatchType match = NamedParameterComment.match(comments.get(p.formal().index()), p.formal().name()).matchType();\r\n        return match == MatchType.EXACT_MATCH || match == MatchType.APPROXIMATE_MATCH;\r\n    });\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.inSynchronized",
	"Comment": "matches if this tree is enclosed by either a synchronized block or a synchronized method.",
	"Method": "Matcher<T> inSynchronized(){\r\n    return new Matcher<T>() {\r\n        @Override\r\n        public boolean matches(T tree, VisitorState state) {\r\n            SynchronizedTree synchronizedTree = ASTHelpers.findEnclosingNode(state.getPath(), SynchronizedTree.class);\r\n            if (synchronizedTree != null) {\r\n                return true;\r\n            }\r\n            MethodTree methodTree = ASTHelpers.findEnclosingNode(state.getPath(), MethodTree.class);\r\n            return methodTree != null && methodTree.getModifiers().getFlags().contains(Modifier.SYNCHRONIZED);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.inSynchronized",
	"Comment": "matches if this tree is enclosed by either a synchronized block or a synchronized method.",
	"Method": "Matcher<T> inSynchronized(){\r\n    SynchronizedTree synchronizedTree = ASTHelpers.findEnclosingNode(state.getPath(), SynchronizedTree.class);\r\n    if (synchronizedTree != null) {\r\n        return true;\r\n    }\r\n    MethodTree methodTree = ASTHelpers.findEnclosingNode(state.getPath(), MethodTree.class);\r\n    return methodTree != null && methodTree.getModifiers().getFlags().contains(Modifier.SYNCHRONIZED);\r\n}"
}, {
	"Path": "org.flywaydb.core.Flyway.info",
	"Comment": "retrieves the complete information about all the migrations including applied, pending and current migrations withdetails and status.",
	"Method": "MigrationInfoService info(){\r\n    return execute(new Command<MigrationInfoService>() {\r\n        public MigrationInfoService execute(MigrationResolver migrationResolver, SchemaHistory schemaHistory, final Database database, final Schema[] schemas, CallbackExecutor callbackExecutor) {\r\n            return new DbInfo(migrationResolver, schemaHistory, configuration, callbackExecutor).info();\r\n        }\r\n    }, true);\r\n}"
}, {
	"Path": "org.flywaydb.core.Flyway.info",
	"Comment": "retrieves the complete information about all the migrations including applied, pending and current migrations withdetails and status.",
	"Method": "MigrationInfoService info(){\r\n    return new DbInfo(migrationResolver, schemaHistory, configuration, callbackExecutor).info();\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.scanner.Scanner.getResources",
	"Comment": "scans this location for resources, starting with the specified prefix and ending with the specified suffix.",
	"Method": "Collection<LoadableResource> getResources(String prefix,String suffixes){\r\n    List<LoadableResource> result = new ArrayList();\r\n    for (LoadableResource resource : resources) {\r\n        String fileName = resource.getFilename();\r\n        if (StringUtils.startsAndEndsWith(fileName, prefix, suffixes)) {\r\n            result.add(resource);\r\n        } else {\r\n            LOG.debug(\"Filtering out resource: \" + resource.getAbsolutePath() + \" (filename: \" + fileName + \")\");\r\n        }\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "graphql.execution.reactive.SingleSubscriberPublisher.noMoreData",
	"Comment": "called by the producing code to say there is no more data to offer and the streamis complete",
	"Method": "void noMoreData(){\r\n    mutex.execute(() -> {\r\n        noMoreData = true;\r\n        maybeReadInMutex();\r\n    });\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.JUnit3FloatingPointComparisonWithoutDelta.getArgumentTypesWithoutMessage",
	"Comment": "gets the argument types, excluding the message argument if present.",
	"Method": "List<Type> getArgumentTypesWithoutMessage(MethodInvocationTree methodInvocationTree,VisitorState state){\r\n    List<Type> argumentTypes = new ArrayList();\r\n    for (ExpressionTree argument : methodInvocationTree.getArguments()) {\r\n        JCTree tree = (JCTree) argument;\r\n        argumentTypes.add(tree.type);\r\n    }\r\n    removeMessageArgumentIfPresent(state, argumentTypes);\r\n    return argumentTypes;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.ThreeLetterTimeZoneID.handleNonDaylightSavingsZone",
	"Comment": "how we handle it depends upon whether we are in a jodatime context or not.",
	"Method": "Replacement handleNonDaylightSavingsZone(boolean inJodaTimeContext,String daylightSavingsZone,String fixedOffset){\r\n    if (inJodaTimeContext) {\r\n        String newDescription = SUMMARY + \"\\n\\n\" + observesDaylightSavingsMessage(\"DateTimeZone\", daylightSavingsZone, fixedOffset);\r\n        return new Replacement(newDescription, ImmutableList.of(daylightSavingsZone, fixedOffset));\r\n    } else {\r\n        String newDescription = SUMMARY + \"\\n\\n\" + \"This TimeZone will not observe daylight savings. \" + \"If this is intended, use \" + fixedOffset + \" instead; to observe daylight savings, use \" + daylightSavingsZone + \".\";\r\n        return new Replacement(newDescription, ImmutableList.of(fixedOffset, daylightSavingsZone));\r\n    }\r\n}"
}, {
	"Path": "water.fvec.UploadFileVec.close",
	"Comment": "close, and possible replace the prior chunk with a new, larger chunk",
	"Method": "void close(C1NChunk c,int cidx,Futures fs){\r\n    assert _len == -1;\r\n    c._vec = this;\r\n    DKV.put(chunkKey(cidx), c, fs);\r\n    long l = _nchunks - 1L;\r\n    _len = l * _chunkSize + c._len;\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.robotstxt.HostDirectives.checkAccess",
	"Comment": "check if any of the rules say anything about the specified path",
	"Method": "int checkAccess(String path){\r\n    timeLastAccessed = System.currentTimeMillis();\r\n    int result = UNDEFINED;\r\n    String myUA = config.getUserAgentName();\r\n    boolean ignoreUADisc = config.getIgnoreUADiscrimination();\r\n    for (UserAgentDirectives ua : rules) {\r\n        int score = ua.match(myUA);\r\n        if (score == 0 && !ignoreUADisc) {\r\n            break;\r\n        }\r\n        result = ua.checkAccess(path, userAgent);\r\n        if (result != DISALLOWED || (!ua.isWildcard() || !ignoreUADisc)) {\r\n            break;\r\n        }\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "com.google.errorprone.fixes.SuggestedFixes.addModifiers",
	"Comment": "adds modifiers to the given class, method, or field declaration.",
	"Method": "Optional<SuggestedFix> addModifiers(Tree tree,VisitorState state,Modifier modifiers){\r\n    ModifiersTree originalModifiers = getModifiers(tree);\r\n    if (originalModifiers == null) {\r\n        return Optional.empty();\r\n    }\r\n    Set<Modifier> toAdd = Sets.difference(new TreeSet(Arrays.asList(modifiers)), originalModifiers.getFlags());\r\n    SuggestedFix.Builder fix = SuggestedFix.builder();\r\n    List<Modifier> modifiersToWrite = new ArrayList();\r\n    if (!originalModifiers.getFlags().isEmpty()) {\r\n        Map<Modifier, Integer> modifierPositions = new TreeMap();\r\n        for (Modifier mod : toAdd) {\r\n            modifierPositions.put(mod, -1);\r\n        }\r\n        List<ErrorProneToken> tokens = state.getTokensForNode(originalModifiers);\r\n        int base = ((JCTree) originalModifiers).getStartPosition();\r\n        for (ErrorProneToken tok : tokens) {\r\n            Modifier mod = getTokModifierKind(tok);\r\n            if (mod != null) {\r\n                modifierPositions.put(mod, base + tok.pos());\r\n            }\r\n        }\r\n        for (Modifier mod : modifierPositions.keySet()) {\r\n            int p = modifierPositions.get(mod);\r\n            if (p == -1) {\r\n                modifiersToWrite.add(mod);\r\n            } else if (!modifiersToWrite.isEmpty()) {\r\n                fix.replace(p, p, Joiner.on(' ').join(modifiersToWrite) + \" \");\r\n                modifiersToWrite.clear();\r\n            }\r\n        }\r\n    } else {\r\n        modifiersToWrite.addAll(toAdd);\r\n    }\r\n    addRemainingModifiers(tree, state, originalModifiers, modifiersToWrite, fix);\r\n    return Optional.of(fix.build());\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.SqlStatementBuilder.applyStateChanges",
	"Comment": "applies any state changes resulting from this line being added.",
	"Method": "void applyStateChanges(String line){\r\n    Collection<String> tokens = tokenizeLine(line);\r\n    List<TokenType> delimitingTokens = extractStringLiteralDelimitingTokens(tokens);\r\n    lineEndsWithSingleLineComment = false;\r\n    for (TokenType delimitingToken : delimitingTokens) {\r\n        if (!insideQuoteStringLiteral && !insideAlternateQuoteStringLiteral && TokenType.MULTI_LINE_COMMENT_OPEN.equals(delimitingToken)) {\r\n            insideMultiLineComment = true;\r\n        }\r\n        if (!insideQuoteStringLiteral && !insideAlternateQuoteStringLiteral && TokenType.MULTI_LINE_COMMENT_CLOSE.equals(delimitingToken)) {\r\n            insideMultiLineComment = false;\r\n        }\r\n        if (!insideQuoteStringLiteral && !insideAlternateQuoteStringLiteral && !insideMultiLineComment && TokenType.SINGLE_LINE_COMMENT.equals(delimitingToken)) {\r\n            lineEndsWithSingleLineComment = true;\r\n            return;\r\n        }\r\n        if (!insideMultiLineComment && !insideQuoteStringLiteral && TokenType.ALTERNATE_QUOTE.equals(delimitingToken)) {\r\n            insideAlternateQuoteStringLiteral = !insideAlternateQuoteStringLiteral;\r\n        }\r\n        if (!insideMultiLineComment && !insideAlternateQuoteStringLiteral && TokenType.QUOTE.equals(delimitingToken)) {\r\n            insideQuoteStringLiteral = !insideQuoteStringLiteral;\r\n        }\r\n        if (!insideMultiLineComment && !insideQuoteStringLiteral && !insideAlternateQuoteStringLiteral && (TokenType.OTHER.equals(delimitingToken) || TokenType.BLOCK_BEGIN.equals(delimitingToken) || TokenType.BLOCK_END.equals(delimitingToken))) {\r\n            if (!hasNonCommentPart()) {\r\n                firstNonCommentLine = lines.size();\r\n            }\r\n            if (isBlockStatement()) {\r\n                if (TokenType.BLOCK_BEGIN.equals(delimitingToken)) {\r\n                    nestedBlockDepth++;\r\n                } else if (TokenType.BLOCK_END.equals(delimitingToken)) {\r\n                    nestedBlockDepth--;\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlus.onBackPressed",
	"Comment": "invoked when back button is pressed. automatically dismiss the dialog.",
	"Method": "void onBackPressed(DialogPlus dialogPlus){\r\n    if (onCancelListener != null) {\r\n        onCancelListener.onCancel(DialogPlus.this);\r\n    }\r\n    dismiss();\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.AbstractDataReaderSun.getTimestamp",
	"Comment": "if the next thing in line is a timestamp, it is parsed and returned. if thereis no timestamp present, the timestamp is calculated",
	"Method": "double getTimestamp(String line,ParseInformation pos,ZonedDateTime datestamp){\r\n    double timestamp = 0;\r\n    if (nextIsTimestamp(line, pos)) {\r\n        timestamp = parseTimestamp(line, pos);\r\n    } else if (datestamp != null && pos.getFirstDateStamp() != null) {\r\n        timestamp = pos.getFirstDateStamp().until(datestamp, ChronoUnit.MILLIS) / (double) 1000;\r\n    }\r\n    return timestamp;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.scanner.classpath.ClassPathScanner.findResourceNames",
	"Comment": "finds the resources names present at this location and below on the classpath starting with this prefix andending with this suffix.",
	"Method": "Set<String> findResourceNames(){\r\n    Set<String> resourceNames = new TreeSet();\r\n    List<URL> locationUrls = getLocationUrlsForPath(location);\r\n    for (URL locationUrl : locationUrls) {\r\n        LOG.debug(\"Scanning URL: \" + locationUrl.toExternalForm());\r\n        UrlResolver urlResolver = createUrlResolver(locationUrl.getProtocol());\r\n        URL resolvedUrl = urlResolver.toStandardJavaUrl(locationUrl);\r\n        String protocol = resolvedUrl.getProtocol();\r\n        ClassPathLocationScanner classPathLocationScanner = createLocationScanner(protocol);\r\n        if (classPathLocationScanner == null) {\r\n            String scanRoot = UrlUtils.toFilePath(resolvedUrl);\r\n            LOG.warn(\"Unable to scan location: \" + scanRoot + \" (unsupported protocol: \" + protocol + \")\");\r\n        } else {\r\n            Set<String> names = resourceNameCache.get(classPathLocationScanner).get(resolvedUrl);\r\n            if (names == null) {\r\n                names = classPathLocationScanner.findResourceNames(location.getPath(), resolvedUrl);\r\n                resourceNameCache.get(classPathLocationScanner).put(resolvedUrl, names);\r\n            }\r\n            resourceNames.addAll(names);\r\n        }\r\n    }\r\n    boolean locationResolved = !locationUrls.isEmpty();\r\n    if (!locationResolved) {\r\n        if (classLoader instanceof URLClassLoader) {\r\n            URLClassLoader urlClassLoader = (URLClassLoader) classLoader;\r\n            for (URL url : urlClassLoader.getURLs()) {\r\n                if (\"file\".equals(url.getProtocol()) && url.getPath().endsWith(\".jar\") && !url.getPath().matches(\".*\" + Pattern.quote(\"/jre/lib/\") + \".*\")) {\r\n                    JarFile jarFile;\r\n                    try {\r\n                        try {\r\n                            jarFile = new JarFile(url.toURI().getSchemeSpecificPart());\r\n                        } catch (URISyntaxException ex) {\r\n                            jarFile = new JarFile(url.getPath().substring(\"file:\".length()));\r\n                        }\r\n                    } catch (IOException e) {\r\n                        LOG.warn(\"Skipping unloadable jar file: \" + url + \" (\" + e.getMessage() + \")\");\r\n                        continue;\r\n                    } catch (SecurityException e) {\r\n                        LOG.warn(\"Skipping unloadable jar file: \" + url + \" (\" + e.getMessage() + \")\");\r\n                        continue;\r\n                    }\r\n                    try {\r\n                        Enumeration<JarEntry> entries = jarFile.entries();\r\n                        while (entries.hasMoreElements()) {\r\n                            String entryName = entries.nextElement().getName();\r\n                            if (entryName.startsWith(location.getPath())) {\r\n                                locationResolved = true;\r\n                                resourceNames.add(entryName);\r\n                            }\r\n                        }\r\n                    } finally {\r\n                        try {\r\n                            jarFile.close();\r\n                        } catch (IOException e) {\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n    if (!locationResolved) {\r\n        LOG.warn(\"Unable to resolve location \" + location);\r\n    }\r\n    return resourceNames;\r\n}"
}, {
	"Path": "feign.Request.create",
	"Comment": "builds a request. all parameters must be effectively immutable, via safe copies.",
	"Method": "Request create(String method,String url,Map<String, Collection<String>> headers,byte[] body,Charset charset,Request create,HttpMethod httpMethod,String url,Map<String, Collection<String>> headers,byte[] body,Charset charset,Request create,HttpMethod httpMethod,String url,Map<String, Collection<String>> headers,Body body){\r\n    return new Request(httpMethod, url, headers, body);\r\n}"
}, {
	"Path": "graphql.schema.GraphQLUnionType.getTypeResolver",
	"Comment": "to be removed in a future version when all code is in the code registry",
	"Method": "TypeResolver getTypeResolver(){\r\n    return typeResolver;\r\n}"
}, {
	"Path": "water.api.Schema.newInstance",
	"Comment": "returns a new schema instance.does not throw, nor returns null.",
	"Method": "T newInstance(Class<T> clz,Schema newInstance,String schema_name){\r\n    return Schema.newInstance(SchemaServer.getSchema(schema_name));\r\n}"
}, {
	"Path": "com.google.errorprone.scanner.Scanner.scan",
	"Comment": "scan a single node. the current path is updated for the duration of the scan.",
	"Method": "Void scan(TreePath path,VisitorState state,Void scan,Tree tree,VisitorState state){\r\n    if (tree == null) {\r\n        return null;\r\n    }\r\n    SuppressionHelper.SuppressionInfo prevSuppressionInfo = updateSuppressions(tree, state);\r\n    try {\r\n        return super.scan(tree, state);\r\n    } finally {\r\n        suppressions = prevSuppressionInfo.suppressWarningsStrings;\r\n        customSuppressions = prevSuppressionInfo.customSuppressions;\r\n        inGeneratedCode = prevSuppressionInfo.inGeneratedCode;\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.NonAtomicVolatileUpdate.variableFromCompoundAssignmentTree",
	"Comment": "extracts the variable from a compoundassignmenttree and applies a matcher to it.",
	"Method": "Matcher<CompoundAssignmentTree> variableFromCompoundAssignmentTree(Matcher<ExpressionTree> exprMatcher){\r\n    return new Matcher<CompoundAssignmentTree>() {\r\n        @Override\r\n        public boolean matches(CompoundAssignmentTree tree, VisitorState state) {\r\n            return exprMatcher.matches(tree.getVariable(), state);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.NonAtomicVolatileUpdate.variableFromCompoundAssignmentTree",
	"Comment": "extracts the variable from a compoundassignmenttree and applies a matcher to it.",
	"Method": "Matcher<CompoundAssignmentTree> variableFromCompoundAssignmentTree(Matcher<ExpressionTree> exprMatcher){\r\n    return exprMatcher.matches(tree.getVariable(), state);\r\n}"
}, {
	"Path": "water.AutoBuffer.putUdp",
	"Comment": "write udp into the bytebuffer with the current node as the sender.this method sets the ctrl, port, task.ready to write more bytes afterwards",
	"Method": "AutoBuffer putUdp(UDP.udp type,int senderPort,AutoBuffer putUdp,UDP.udp type){\r\n    return putUdp(type, H2O.H2O_PORT);\r\n}"
}, {
	"Path": "water.parser.ZipUtil.getDecompressionRatio",
	"Comment": "when a file is a zip file that contains multiple files, this method will return the decompression ratio.",
	"Method": "float getDecompressionRatio(ByteVec bv){\r\n    long totalSize = 0L;\r\n    long totalCompSize = 0L;\r\n    if (bv instanceof FileVec) {\r\n        String strPath = getPathForKey(((FileVec) bv)._key);\r\n        try {\r\n            ZipFile zipFile = new ZipFile(strPath);\r\n            Enumeration<? extends ZipEntry> entries = zipFile.entries();\r\n            while (entries.hasMoreElements()) {\r\n                ZipEntry entry = entries.nextElement();\r\n                if (!entry.isDirectory()) {\r\n                    totalSize = totalSize + entry.getSize();\r\n                    totalCompSize = totalCompSize + entry.getCompressedSize();\r\n                }\r\n            }\r\n            zipFile.close();\r\n        } catch (IOException e) {\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n    if (totalCompSize == 0)\r\n        return 1;\r\n    else\r\n        return totalSize / totalCompSize;\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    try {\r\n        return sun.misc.Unsafe.getUnsafe();\r\n    } catch (SecurityException se) {\r\n        try {\r\n            return java.security.AccessController.doPrivileged(new java.security.PrivilegedExceptionAction<sun.misc.Unsafe>() {\r\n                public sun.misc.Unsafe run() throws Exception {\r\n                    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n                    f.setAccessible(true);\r\n                    return (sun.misc.Unsafe) f.get(null);\r\n                }\r\n            });\r\n        } catch (java.security.PrivilegedActionException e) {\r\n            throw new RuntimeException(\"Could not initialize intrinsics\", e.getCause());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n    f.setAccessible(true);\r\n    return (sun.misc.Unsafe) f.get(null);\r\n}"
}, {
	"Path": "water.api.RequestServer.getResource",
	"Comment": "returns the response containing the given uri with the appropriate mime type.",
	"Method": "NanoResponse getResource(RequestType request_type,String url){\r\n    byte[] bytes = _cache.get(url);\r\n    if (bytes == null) {\r\n        try (InputStream resource = water.init.JarHash.getResource2(url)) {\r\n            if (resource != null) {\r\n                try {\r\n                    bytes = toByteArray(resource);\r\n                } catch (IOException e) {\r\n                    Log.err(e);\r\n                }\r\n            }\r\n        } catch (IOException ignore) {\r\n        }\r\n    }\r\n    if (bytes == null || bytes.length == 0)\r\n        return response404(\"Resource \" + url, request_type);\r\n    int i = url.lastIndexOf('.');\r\n    String mime;\r\n    switch(url.substring(i + 1)) {\r\n        case \"js\":\r\n            mime = MIME_JS;\r\n            break;\r\n        case \"css\":\r\n            mime = MIME_CSS;\r\n            break;\r\n        case \"htm\":\r\n        case \"html\":\r\n            mime = MIME_HTML;\r\n            break;\r\n        case \"jpg\":\r\n        case \"jpeg\":\r\n            mime = MIME_JPEG;\r\n            break;\r\n        case \"png\":\r\n            mime = MIME_PNG;\r\n            break;\r\n        case \"svg\":\r\n            mime = MIME_SVG;\r\n            break;\r\n        case \"gif\":\r\n            mime = MIME_GIF;\r\n            break;\r\n        case \"woff\":\r\n            mime = MIME_WOFF;\r\n            break;\r\n        default:\r\n            mime = MIME_DEFAULT_BINARY;\r\n    }\r\n    NanoResponse res = new NanoResponse(HTTP_OK, mime, new ByteArrayInputStream(bytes));\r\n    res.addHeader(\"Content-Length\", Long.toString(bytes.length));\r\n    return res;\r\n}"
}, {
	"Path": "feign.FeignTest.retryableExceptionInDecoder",
	"Comment": "when you must parse a 2xx status to determine if the operation succeeded or not.",
	"Method": "void retryableExceptionInDecoder(){\r\n    server.enqueue(new MockResponse().setBody(\"retry!\"));\r\n    server.enqueue(new MockResponse().setBody(\"success!\"));\r\n    TestInterface api = new TestInterfaceBuilder().decoder(new StringDecoder() {\r\n        @Override\r\n        public Object decode(Response response, Type type) throws IOException {\r\n            String string = super.decode(response, type).toString();\r\n            if (\"retry!\".equals(string)) {\r\n                throw new RetryableException(string, HttpMethod.POST, null);\r\n            }\r\n            return string;\r\n        }\r\n    }).target(\"http://localhost:\" + server.getPort());\r\n    assertEquals(api.post(), \"success!\");\r\n    assertEquals(2, server.getRequestCount());\r\n}"
}, {
	"Path": "feign.FeignTest.retryableExceptionInDecoder",
	"Comment": "when you must parse a 2xx status to determine if the operation succeeded or not.",
	"Method": "void retryableExceptionInDecoder(){\r\n    String string = super.decode(response, type).toString();\r\n    if (\"retry!\".equals(string)) {\r\n        throw new RetryableException(string, HttpMethod.POST, null);\r\n    }\r\n    return string;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.renderer.PolygonChartRenderer.hasMemoryInformation",
	"Comment": "returns true if event is of a type that contains memory information.",
	"Method": "boolean hasMemoryInformation(GCEvent event){\r\n    return event.getExtendedType().getPattern().equals(GcPattern.GC_MEMORY) || event.getExtendedType().getPattern().equals(GcPattern.GC_MEMORY_PAUSE);\r\n}"
}, {
	"Path": "com.google.errorprone.fixes.SuggestedFixes.removeModifiers",
	"Comment": "remove modifiers from the given class, method, or field declaration.",
	"Method": "Optional<SuggestedFix> removeModifiers(Tree tree,VisitorState state,Modifier modifiers){\r\n    Set<Modifier> toRemove = ImmutableSet.copyOf(modifiers);\r\n    ModifiersTree originalModifiers = getModifiers(tree);\r\n    if (originalModifiers == null) {\r\n        return Optional.empty();\r\n    }\r\n    SuggestedFix.Builder fix = SuggestedFix.builder();\r\n    List<ErrorProneToken> tokens = state.getTokensForNode(originalModifiers);\r\n    int basePos = ((JCTree) originalModifiers).getStartPosition();\r\n    boolean empty = true;\r\n    for (ErrorProneToken tok : tokens) {\r\n        Modifier mod = getTokModifierKind(tok);\r\n        if (toRemove.contains(mod)) {\r\n            empty = false;\r\n            fix.replace(basePos + tok.pos(), basePos + tok.endPos() + 1, \"\");\r\n        }\r\n    }\r\n    if (empty) {\r\n        return Optional.empty();\r\n    }\r\n    return Optional.of(fix.build());\r\n}"
}, {
	"Path": "jsr166y.Phaser.forceTermination",
	"Comment": "forces this phaser to enter termination state.counts ofregistered parties are unaffected.if this phaser is a memberof a tiered set of phasers, then all of the phasers in the setare terminated.if this phaser is already terminated, thismethod has no effect.this method may be useful forcoordinating recovery after one or more tasks encounterunexpected exceptions.",
	"Method": "void forceTermination(){\r\n    final Phaser root = this.root;\r\n    long s;\r\n    while ((s = root.state) >= 0) {\r\n        if (UNSAFE.compareAndSwapLong(root, stateOffset, s, s | TERMINATION_BIT)) {\r\n            releaseWaiters(0);\r\n            releaseWaiters(1);\r\n            return;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.FileCopyUtils.copyToByteArray",
	"Comment": "copy the contents of the given inputstream into a new byte array.closes the stream when done.",
	"Method": "byte[] copyToByteArray(InputStream in){\r\n    ByteArrayOutputStream out = new ByteArrayOutputStream(4096);\r\n    copy(in, out);\r\n    return out.toByteArray();\r\n}"
}, {
	"Path": "water.nbhm.NonBlockingHashMap.clone",
	"Comment": "creates a shallow copy of this hashtable. all the structure of thehashtable itself is copied, but the keys and values are not cloned.this is a relatively expensive operation.",
	"Method": "Object clone(){\r\n    try {\r\n        NonBlockingHashMap<TypeK, TypeV> t = (NonBlockingHashMap<TypeK, TypeV>) super.clone();\r\n        t.clear();\r\n        for (TypeK K : keySet()) {\r\n            final TypeV V = get(K);\r\n            t.put(K, V);\r\n        }\r\n        return t;\r\n    } catch (CloneNotSupportedException e) {\r\n        throw new InternalError();\r\n    }\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlusBuilder.setInAnimation",
	"Comment": "customize the in animation by passing an animation resource",
	"Method": "DialogPlusBuilder setInAnimation(int inAnimResource){\r\n    this.inAnimation = inAnimResource;\r\n    return this;\r\n}"
}, {
	"Path": "hex.svd.SVD.setWideDataset",
	"Comment": "set value of widedataset.note that this routine is used for test purposes only and is not intended\t\tfor users.",
	"Method": "void setWideDataset(boolean isWide){\r\n    _wideDataset = isWide;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.util.OSXSupport.initializeMacOSX",
	"Comment": "initializes various mac os x adaptations, using reflection and proxiesin order to be compilable on other platforms.",
	"Method": "void initializeMacOSX(Action aboutAction,Action quitAction,Action preferencesAction,Image iconImage,Window fullScreenableWindow){\r\n    try {\r\n        if (!isOSX()) {\r\n            return;\r\n        }\r\n        if (isOSXNewEAWT()) {\r\n            if (aboutAction != null) {\r\n                addOSXHandler(\"com.apple.eawt.AboutHandler\", \"handleAbout\", \"setAboutHandler\", aboutAction);\r\n            }\r\n            if (quitAction != null) {\r\n                addOSXHandler(\"com.apple.eawt.QuitHandler\", \"handleQuitRequestWith\", \"setQuitHandler\", quitAction);\r\n            }\r\n            addOSXHandler(\"com.apple.eawt.PreferencesHandler\", \"handlePreferences\", \"setPreferencesHandler\", preferencesAction);\r\n            if (hasOSXFullScreenSupport()) {\r\n                Class.forName(\"com.apple.eawt.FullScreenUtilities\").getDeclaredMethod(\"setWindowCanFullScreen\", Window.class, Boolean.TYPE).invoke(null, fullScreenableWindow, true);\r\n            }\r\n        } else {\r\n            OSXAdapter.setQuitHandler(quitAction, quitAction.getClass().getDeclaredMethod(\"quit\", (Class[]) null));\r\n            OSXAdapter.setAboutHandler(aboutAction, aboutAction.getClass().getDeclaredMethod(\"about\", (Class[]) null));\r\n        }\r\n        System.setProperty(\"apple.laf.useScreenMenuBar\", \"true\");\r\n        if (iconImage != null) {\r\n            Object application = getOSXApplication();\r\n            Method setDockIconImageMethod = application.getClass().getMethod(\"setDockIconImage\", Image.class);\r\n            setDockIconImageMethod.invoke(application, iconImage);\r\n        }\r\n    } catch (Exception e) {\r\n        LoggerHelper.logException(LOGGER, Level.SEVERE, \"Failed to perform OS X initialization\", e);\r\n    }\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlus.setClickListener",
	"Comment": "it is used to setlistener on view that have a valid id associated",
	"Method": "void setClickListener(View view){\r\n    if (view.getId() == INVALID) {\r\n        return;\r\n    }\r\n    if (view instanceof AdapterView) {\r\n        return;\r\n    }\r\n    view.setOnClickListener(new View.OnClickListener() {\r\n        @Override\r\n        public void onClick(View v) {\r\n            if (onClickListener == null) {\r\n                return;\r\n            }\r\n            onClickListener.onClick(DialogPlus.this, v);\r\n        }\r\n    });\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlus.setClickListener",
	"Comment": "it is used to setlistener on view that have a valid id associated",
	"Method": "void setClickListener(View view){\r\n    if (onClickListener == null) {\r\n        return;\r\n    }\r\n    onClickListener.onClick(DialogPlus.this, v);\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.assertionWithCondition",
	"Comment": "matches an assertion ast node if the given matcher matches its condition.",
	"Method": "Matcher<AssertTree> assertionWithCondition(Matcher<ExpressionTree> conditionMatcher){\r\n    return new Matcher<AssertTree>() {\r\n        @Override\r\n        public boolean matches(AssertTree tree, VisitorState state) {\r\n            return conditionMatcher.matches(tree.getCondition(), state);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.assertionWithCondition",
	"Comment": "matches an assertion ast node if the given matcher matches its condition.",
	"Method": "Matcher<AssertTree> assertionWithCondition(Matcher<ExpressionTree> conditionMatcher){\r\n    return conditionMatcher.matches(tree.getCondition(), state);\r\n}"
}, {
	"Path": "hex.tree.gbm.GBMModel.score0",
	"Comment": "bulk scoring api for one row.chunks are all compatible with the model, and expect the last chunks are for the final distribution and prediction. default method is to just load the data into the tmp array, then call subclass scoring logic.",
	"Method": "double[] score0(double data,double preds,double offset,int ntrees){\r\n    super.score0(data, preds, offset, ntrees);\r\n    return score0Probabilities(preds, offset);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.postgresql.PostgreSQLSchema.generateDropStatementsForMaterializedViews",
	"Comment": "generates the statements for dropping the materialized views in this schema.",
	"Method": "List<String> generateDropStatementsForMaterializedViews(){\r\n    List<String> viewNames = jdbcTemplate.queryForStringList(\"SELECT relname FROM pg_catalog.pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace\" + \" WHERE c.relkind = 'm' AND n.nspname = ?\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (String domainName : viewNames) {\r\n        statements.add(\"DROP MATERIALIZED VIEW IF EXISTS \" + database.quote(name, domainName) + \" CASCADE\");\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "graphql.schema.GraphQLScalarType.transform",
	"Comment": "this helps you transform the current graphqlobjecttype into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLScalarType transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newScalar(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "hex.schemas.HyperSpaceSearchCriteriaV99.fillWithDefaults",
	"Comment": "fill with the default values from the corresponding iced object.",
	"Method": "S fillWithDefaults(){\r\n    HyperSpaceSearchCriteria defaults = null;\r\n    if (HyperSpaceSearchCriteria.Strategy.Cartesian == strategy) {\r\n        defaults = new HyperSpaceSearchCriteria.CartesianSearchCriteria();\r\n    } else if (HyperSpaceSearchCriteria.Strategy.RandomDiscrete == strategy) {\r\n        defaults = new HyperSpaceSearchCriteria.RandomDiscreteValueSearchCriteria();\r\n    } else {\r\n        throw new H2OIllegalArgumentException(\"search_criteria.strategy\", strategy.toString());\r\n    }\r\n    fillFromImpl((I) defaults);\r\n    return (S) this;\r\n}"
}, {
	"Path": "water.Key.cloud_info",
	"Comment": "return the info word for this cloud. use the cache if possible",
	"Method": "long cloud_info(H2O cloud){\r\n    long x = _cache;\r\n    if (cloud(x) == cloud._idx)\r\n        return x;\r\n    char home = (char) D(0);\r\n    int desired = desired(x);\r\n    int replica = -1;\r\n    for (int i = 0; i < desired; i++) {\r\n        int idx = D(i);\r\n        if (idx >= 0 && cloud._memary[idx] == H2O.SELF) {\r\n            replica = i;\r\n            break;\r\n        }\r\n    }\r\n    long cache = build_cache(cloud._idx, home, replica, desired);\r\n    set_cache(cache);\r\n    return cache;\r\n}"
}, {
	"Path": "feign.template.Template.isLiteral",
	"Comment": "flag to indicate that this template is a literal string, with no variable expressions.",
	"Method": "boolean isLiteral(){\r\n    return this.getVariables().isEmpty();\r\n}"
}, {
	"Path": "com.google.errorprone.util.ErrorProneTokens.getTokens",
	"Comment": "returns the tokens for the given source text, including comments.",
	"Method": "ImmutableList<ErrorProneToken> getTokens(ImmutableList<ErrorProneToken> getTokens,String source,Context context){\r\n    return new ErrorProneTokens(source, context).getTokens();\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.JUnit3FloatingPointComparisonWithoutDelta.unboxedTypeOrType",
	"Comment": "gets the unboxed type, or the original type if it is not unboxable.",
	"Method": "Type unboxedTypeOrType(VisitorState state,Type type){\r\n    Types types = state.getTypes();\r\n    return types.unboxedTypeOrType(type);\r\n}"
}, {
	"Path": "feign.Util.valuesOrEmpty",
	"Comment": "returns an unmodifiable collection which may be empty, but is never null.",
	"Method": "Collection<T> valuesOrEmpty(Map<String, Collection<T>> map,String key){\r\n    return map.containsKey(key) && map.get(key) != null ? map.get(key) : Collections.<T>emptyList();\r\n}"
}, {
	"Path": "jsr166y.ConcurrentLinkedDeque.screenNullResult",
	"Comment": "returns element unless it is null, in which case throwsnosuchelementexception.",
	"Method": "E screenNullResult(E v){\r\n    if (v == null)\r\n        throw new NoSuchElementException();\r\n    return v;\r\n}"
}, {
	"Path": "water.parser.ZipUtil.unzipForHeader",
	"Comment": "this method will read a compressed zip file and return the uncompressed bits so that we cancheck the beginning of the file and make sure it does not contain the column names.",
	"Method": "byte[] unzipForHeader(byte[] bs,int chkSize){\r\n    ByteArrayInputStream bais = new ByteArrayInputStream(bs);\r\n    ZipInputStream zis = new ZipInputStream(bais);\r\n    InputStream is = zis;\r\n    int off = 0;\r\n    try {\r\n        while (off < bs.length) {\r\n            int len = 0;\r\n            len = is.read(bs, off, bs.length - off);\r\n            if (len < 0)\r\n                break;\r\n            off += len;\r\n            if (off == bs.length) {\r\n                if (bs.length >= chkSize)\r\n                    break;\r\n                bs = Arrays.copyOf(bs, bs.length * 2);\r\n            }\r\n        }\r\n    } catch (IOException e) {\r\n        e.printStackTrace();\r\n    }\r\n    try {\r\n        is.close();\r\n    } catch (IOException e) {\r\n        e.printStackTrace();\r\n    }\r\n    return bs;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.redshift.RedshiftDatabase.isRedshift",
	"Comment": "checks whether this connection is pointing at a redshift instance.",
	"Method": "boolean isRedshift(Connection connection){\r\n    try {\r\n        return new JdbcTemplate(connection).queryForString(\"SELECT version()\").contains(\"Redshift\");\r\n    } catch (Exception e) {\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "hex.grid.GridSearch.getModelCount",
	"Comment": "returns expected number of models in resulting grid object.the number can differ from final number of models due to visiting duplicate points in hyperspace.",
	"Method": "long getModelCount(){\r\n    return _hyperSpaceWalker.getMaxHyperSpaceSize();\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.util.BuildInfoReader.getBuildDate",
	"Comment": "read build date from properties file in classpath if it can be found.",
	"Method": "String getBuildDate(){\r\n    return readPropertyValue(BUILD_TIMESTAMP);\r\n}"
}, {
	"Path": "water.init.NetworkTest.send_recv_collective",
	"Comment": "broadcast a message from this node to all nodes and reduce it back",
	"Method": "double send_recv_collective(int msg_size,int repeats){\r\n    byte[] payload = new byte[msg_size];\r\n    new Random().nextBytes(payload);\r\n    Vec v = Vec.makeZero(1);\r\n    Timer t = new Timer();\r\n    for (int l = 0; l < repeats; ++l) {\r\n        new CollectiveTask(payload).doAll(v);\r\n    }\r\n    v.remove(new Futures()).blockForPending();\r\n    return (double) t.nanos() / repeats;\r\n}"
}, {
	"Path": "hex.tree.gbm.GBMTest.testModelAdaptMultinomial",
	"Comment": "adapt a trained model to a test dataset with different categoricals",
	"Method": "void testModelAdaptMultinomial(){\r\n    GBMModel gbm = null;\r\n    GBMModel.GBMParameters parms = new GBMModel.GBMParameters();\r\n    try {\r\n        Scope.enter();\r\n        Frame v;\r\n        parms._train = (parse_test_file(\"smalldata/junit/mixcat_train.csv\"))._key;\r\n        parms._valid = (v = parse_test_file(\"smalldata/junit/mixcat_test.csv\"))._key;\r\n        parms._response_column = \"Response\";\r\n        parms._ntrees = 1;\r\n        parms._learn_rate = 1.0f;\r\n        parms._min_rows = 1;\r\n        parms._distribution = DistributionFamily.multinomial;\r\n        gbm = new GBM(parms).trainModel().get();\r\n        Frame res = gbm.score(v);\r\n        int[] ps = new int[(int) v.numRows()];\r\n        Vec.Reader vr = res.vecs()[0].new Reader();\r\n        for (int i = 0; i < ps.length; i++) ps[i] = (int) vr.at8(i);\r\n        Assert.assertArrayEquals(\"\", ps, new int[] { 1, 1, 2, 2, 1, 2, 3, 1, 2 });\r\n        hex.ModelMetricsMultinomial mm = hex.ModelMetricsMultinomial.getFromDKV(gbm, parms.valid());\r\n        Assert.assertTrue(gbm.testJavaScoring(v, res, 1e-15));\r\n        res.remove();\r\n    } finally {\r\n        parms._train.remove();\r\n        parms._valid.remove();\r\n        if (gbm != null)\r\n            gbm.delete();\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "hex.glm.GLMBasicTestMultinomial.testCODGradients",
	"Comment": "i have manually derived the coefficient updates for cod and they are more accurate than what is currentlyimplemented because i update all the probabilities after a coefficient has been changed.in reality, this willbe very slow and an approximation may be more appropriate.the coefficients generated here is the golden standard.",
	"Method": "void testCODGradients(){\r\n    Scope.enter();\r\n    Frame train;\r\n    GLMParameters params = new GLMParameters(Family.multinomial);\r\n    GLMModel model = null;\r\n    double[] oldGLMCoeffs = new double[] { 0.059094274726151426, 0.013361781886804975, -0.00798977427248744, 0.007467359562151555, 0.06737827548293934, -1.002393430927568, -0.04066511294457045, -0.018960901996125427, 0.07330281133353159, -0.02285669809606731, 0.002805290931441751, -1.1394632268347782, 0.021976767313534512, 0.01013967640490087, -0.03999288928633559, 0.012385348397898913, -0.0017922461738315199, -1.159667420372168 };\r\n    try {\r\n        train = parse_test_file(\"smalldata/glm_test/multinomial_3_class.csv\");\r\n        Scope.track(train);\r\n        params._response_column = \"response\";\r\n        params._train = train._key;\r\n        params._lambda = new double[] { 4.881e-05 };\r\n        params._alpha = new double[] { 0.5 };\r\n        params._objective_epsilon = 1e-6;\r\n        params._beta_epsilon = 1e-4;\r\n        params._max_iterations = 1;\r\n        params._seed = 12345;\r\n        Solver s = Solver.COORDINATE_DESCENT;\r\n        System.out.println(\"solver = \" + s);\r\n        params._solver = s;\r\n        model = new GLM(params).trainModel().get();\r\n        Scope.track_generic(model);\r\n        DataInfo tinfo = new DataInfo(train.clone(), null, 0, true, DataInfo.TransformType.STANDARDIZE, DataInfo.TransformType.NONE, false, false, false, false, false, false);\r\n        double[] manualCoeff = getCODCoeff(train, params._alpha[0], params._lambda[0], model._ymu, tinfo);\r\n        Scope.track_generic(tinfo);\r\n        compareGLMCoeffs(manualCoeff, model._output._submodels[0].beta, 2e-2);\r\n        compareGLMCoeffs(model._output._submodels[0].beta, oldGLMCoeffs, 1e-10);\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.FlywaySqlScriptException.getLineNumber",
	"Comment": "returns the line number in migration sql script where exception occurred.",
	"Method": "int getLineNumber(){\r\n    return statement == null ? -1 : statement.getLineNumber();\r\n}"
}, {
	"Path": "graphql.schema.GraphQLTypeUtil.isWrapped",
	"Comment": "returns true if the given type is a non null or list type, that is a wrapped type",
	"Method": "boolean isWrapped(GraphQLType type){\r\n    return isList(type) || isNonNull(type);\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.findClass",
	"Comment": "returns the class tree that matches the given symbol within the compilation unit, or null ifnone was found.",
	"Method": "ClassTree findClass(ClassSymbol symbol,VisitorState state){\r\n    return JavacTrees.instance(state.context).getTree(symbol);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.android.FragmentInjection.getMethod",
	"Comment": "return the first method tree on the given class tree that matches the given method matcher,or null if one does not exist.",
	"Method": "MethodTree getMethod(Matcher<MethodTree> methodMatcher,ClassTree classTree,VisitorState state){\r\n    for (Tree member : classTree.getMembers()) {\r\n        if (member instanceof MethodTree) {\r\n            MethodTree memberTree = (MethodTree) member;\r\n            if (methodMatcher.matches(memberTree, state)) {\r\n                return memberTree;\r\n            }\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaDirectiveWiring.onInputObjectType",
	"Comment": "this is called when an input object is encountered, which gives the schema directive a chance to modify the shape and behaviourof that dslelement",
	"Method": "GraphQLInputObjectType onInputObjectType(SchemaDirectiveWiringEnvironment<GraphQLInputObjectType> environment){\r\n    return environment.getElement();\r\n}"
}, {
	"Path": "graphql.schema.GraphQLSchema.transform",
	"Comment": "this helps you transform the current graphqlschema object into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLSchema transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newSchema(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.examples.basic.BasicCrawler.visit",
	"Comment": "this function is called when a page is fetched and ready to be processedby your program.",
	"Method": "void visit(Page page){\r\n    int docid = page.getWebURL().getDocid();\r\n    String url = page.getWebURL().getURL();\r\n    String domain = page.getWebURL().getDomain();\r\n    String path = page.getWebURL().getPath();\r\n    String subDomain = page.getWebURL().getSubDomain();\r\n    String parentUrl = page.getWebURL().getParentUrl();\r\n    String anchor = page.getWebURL().getAnchor();\r\n    logger.debug(\"Docid: {}\", docid);\r\n    logger.info(\"URL: {}\", url);\r\n    logger.debug(\"Domain: '{}'\", domain);\r\n    logger.debug(\"Sub-domain: '{}'\", subDomain);\r\n    logger.debug(\"Path: '{}'\", path);\r\n    logger.debug(\"Parent page: {}\", parentUrl);\r\n    logger.debug(\"Anchor text: {}\", anchor);\r\n    if (page.getParseData() instanceof HtmlParseData) {\r\n        HtmlParseData htmlParseData = (HtmlParseData) page.getParseData();\r\n        String text = htmlParseData.getText();\r\n        String html = htmlParseData.getHtml();\r\n        Set<WebURL> links = htmlParseData.getOutgoingUrls();\r\n        logger.debug(\"Text length: {}\", text.length());\r\n        logger.debug(\"Html length: {}\", html.length());\r\n        logger.debug(\"Number of outgoing links: {}\", links.size());\r\n    }\r\n    Header[] responseHeaders = page.getFetchResponseHeaders();\r\n    if (responseHeaders != null) {\r\n        logger.debug(\"Response headers:\");\r\n        for (Header header : responseHeaders) {\r\n            logger.debug(\"\\t{}: {}\", header.getName(), header.getValue());\r\n        }\r\n    }\r\n    logger.debug(\"=============\");\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.redshift.RedshiftSchema.generateDropStatementsForRoutines",
	"Comment": "generates the statements for dropping the routines in this schema.",
	"Method": "List<String> generateDropStatementsForRoutines(){\r\n    List<Map<String, String>> rows = // Search for all functions\r\n    jdbcTemplate.queryForList(\"SELECT proname, oidvectortypes(proargtypes) AS args \" + \"FROM pg_proc INNER JOIN pg_namespace ns ON (pg_proc.pronamespace = ns.oid) \" + \"LEFT JOIN pg_depend dep ON dep.objid = pg_proc.oid AND dep.deptype = 'e' \" + \"WHERE pg_proc.proisagg = false AND ns.nspname = ? AND dep.objid IS NULL\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (Map<String, String> row : rows) {\r\n        statements.add(\"DROP FUNCTION \" + database.quote(name, row.get(\"proname\")) + \"(\" + row.get(\"args\") + \") CASCADE\");\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "water.IcedWrapper.writeUnwrappedJSON",
	"Comment": "write json for the wrapped value without putting it inside a json object.",
	"Method": "AutoBuffer writeUnwrappedJSON(AutoBuffer ab){\r\n    if (is_array) {\r\n        if (t.equals(\"B\"))\r\n            return ab.putJSONA4(i_ar);\r\n        else if (t.equals(\"I\"))\r\n            return ab.putJSONA4(i_ar);\r\n        else if (t.equals(\"L\"))\r\n            return ab.putJSONA8(l_ar);\r\n        else if (t.equals(\"F\"))\r\n            return ab.putJSONA4f(f_ar);\r\n        else if (t.equals(\"D\"))\r\n            return ab.putJSONA8d(d_ar);\r\n        else if (t.equals(\"Bo\"))\r\n            return ab.putJSONAStr(null);\r\n        else if (t.equals(\"S\"))\r\n            return ab.putJSONAStr(s_ar);\r\n        else if (t.equals(\"E\"))\r\n            return ab.putJSONAStr(e_ar);\r\n        else if (t.equals(\"K\"))\r\n            return ab.putJSONA(k_ar);\r\n        else if (t.equals(\"Iced\"))\r\n            return ab.putJSONA(iced_ar);\r\n    } else {\r\n        if (t.equals(\"B\"))\r\n            return ab.putJSON1((byte) i);\r\n        else if (t.equals(\"I\"))\r\n            return ab.putJSON4(i);\r\n        else if (t.equals(\"L\"))\r\n            return ab.putJSON8(l);\r\n        else if (t.equals(\"F\"))\r\n            return ab.putJSON4f(f);\r\n        else if (t.equals(\"D\"))\r\n            return ab.putJSON8d(d);\r\n        else if (t.equals(\"Bo\"))\r\n            return ab.putJSONStrUnquoted(b ? \"true\" : \"false\");\r\n        else if (t.equals(\"S\"))\r\n            return ab.putJSONName(s);\r\n        else if (t.equals(\"E\"))\r\n            return ab.putJSONName(e);\r\n        else if (t.equals(\"K\"))\r\n            return ab.putJSON(k);\r\n    }\r\n    throw H2O.fail(\"Unhandled type: \" + t);\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.dataSource",
	"Comment": "sets the datasource to use. must have the necessary privileges to execute ddl.",
	"Method": "FluentConfiguration dataSource(DataSource dataSource,FluentConfiguration dataSource,String url,String user,String password){\r\n    config.setDataSource(url, user, password);\r\n    return this;\r\n}"
}, {
	"Path": "com.google.errorprone.apply.ImportStatementsTest.emptyImportListShouldGivePositionOfPackageStmt",
	"Comment": "test empty initial import list. positions should match package end positions.",
	"Method": "void emptyImportListShouldGivePositionOfPackageStmt(){\r\n    ImportStatements imports = createImportStatements(basePackage, new ArrayList<JCImport>());\r\n    assertEquals(81, imports.getStartPos());\r\n    assertEquals(81, imports.getEndPos());\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.testdata.FinallyPositiveCase1.test6",
	"Comment": "continue statement jumps to outer labeled for, not inner one.",
	"Method": "void test6(){\r\n    label: for (; ; ) {\r\n        try {\r\n        } finally {\r\n            for (; ; ) {\r\n                continue label;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.postgresql.PostgreSQLSchema.generateDropStatementsForBaseTypes",
	"Comment": "generates the statements for dropping the types in this schema.",
	"Method": "List<String> generateDropStatementsForBaseTypes(boolean recreate){\r\n    List<Map<String, String>> rows = jdbcTemplate.queryForList(\"select typname, typcategory from pg_catalog.pg_type t \" + \"left join pg_depend dep on dep.objid = t.oid and dep.deptype = 'e' \" + \"where (t.typrelid = 0 OR (SELECT c.relkind = 'c' FROM pg_catalog.pg_class c WHERE c.oid = t.typrelid)) \" + \"and NOT EXISTS(SELECT 1 FROM pg_catalog.pg_type el WHERE el.oid = t.typelem AND el.typarray = t.oid) \" + \"and t.typnamespace in (select oid from pg_catalog.pg_namespace where nspname = ?) \" + \"and dep.objid is null \" + \"and t.typtype != 'd'\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (Map<String, String> row : rows) {\r\n        statements.add(\"DROP TYPE IF EXISTS \" + database.quote(name, row.get(\"typname\")) + \" CASCADE\");\r\n    }\r\n    if (recreate) {\r\n        for (Map<String, String> row : rows) {\r\n            if (Arrays.asList(\"P\", \"U\").contains(row.get(\"typcategory\"))) {\r\n                statements.add(\"CREATE TYPE \" + database.quote(name, row.get(\"typname\")));\r\n            }\r\n        }\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Description.getLink",
	"Comment": "returns a link associated with this finding or null if there is no link.",
	"Method": "String getLink(){\r\n    return linkUrl;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.testdata.FinallyPositiveCase1.test5",
	"Comment": "break statement jumps to outer labeled while, not inner one.",
	"Method": "void test5(){\r\n    label: while (true) {\r\n        try {\r\n        } finally {\r\n            while (true) {\r\n                break label;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.VisitorState.validateTypeStr",
	"Comment": "validates a type string, ensuring it is not generic and not an array type.",
	"Method": "void validateTypeStr(String typeStr){\r\n    if (typeStr.contains(\"[\") || typeStr.contains(\"]\")) {\r\n        throw new IllegalArgumentException(String.format(\"Cannot convert array types (%s), please build them using getType()\", typeStr));\r\n    }\r\n    if (typeStr.contains(\"<\") || typeStr.contains(\">\")) {\r\n        throw new IllegalArgumentException(String.format(\"Cannot convert generic types (%s), please build them using getType()\", typeStr));\r\n    }\r\n}"
}, {
	"Path": "water.Key.make",
	"Comment": "make new keys.optimistically attempt interning, but no guarantee.",
	"Method": "Key<P> make(byte[] kb,byte rf,Key<P> make,byte[] kb,Key<P> make,String s,Key<P> make,H2ONode node,Key<P> make,String s,byte rf,Key<P> make,Key<P> make,String s,byte rf,byte systemType,boolean hint,H2ONode replicas,Key<P> make,byte rf,byte systemType,boolean hint,H2ONode replicas,Key<P> make,byte[] kb,byte rf,byte systemType,boolean required,H2ONode replicas){\r\n    assert 0 <= replicas.length && replicas.length <= 3;\r\n    assert systemType < 32;\r\n    boolean inCloud = true;\r\n    for (H2ONode h2o : replicas) if (!H2O.CLOUD.contains(h2o))\r\n        inCloud = false;\r\n    if (required)\r\n        assert inCloud;\r\n    else if (!inCloud)\r\n        replicas = new H2ONode[0];\r\n    AutoBuffer ab = new AutoBuffer();\r\n    ab.put1(systemType).put1(replicas.length);\r\n    for (H2ONode h2o : replicas) h2o.write(ab);\r\n    ab.put4(-1);\r\n    ab.putA1(kb, kb.length);\r\n    return make(Arrays.copyOf(ab.buf(), ab.position()), rf);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.SqlScript.executeInTransaction",
	"Comment": "whether the execution should take place inside a transaction. this is useful for databaseslike postgresql where certain statement can only execute outside a transaction.",
	"Method": "boolean executeInTransaction(){\r\n    return !nonTransactionalStatementFound;\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.crawler.WebCrawler.onParseError",
	"Comment": "this function is called if there has been an error in parsing the content.",
	"Method": "void onParseError(WebURL webUrl){\r\n    logger.warn(\"Parsing error of: {}\", webUrl.getURL());\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.DataReaderFacade.loadModel",
	"Comment": "loads a model from a given gcresource logging all exceptions that occur.",
	"Method": "GCModel loadModel(GCResource gcResource){\r\n    if (gcResource == null) {\r\n        throw new NullPointerException(\"gcResource must never be null\");\r\n    }\r\n    if (gcResource instanceof GcResourceSeries) {\r\n        return loadModelFromSeries((GcResourceSeries) gcResource);\r\n    }\r\n    if (!(gcResource instanceof GcResourceFile))\r\n        throw new UnsupportedOperationException(\"Only supported for files!\");\r\n    DataReaderException dataReaderException = new DataReaderException();\r\n    GCModel model = null;\r\n    Logger logger = gcResource.getLogger();\r\n    try {\r\n        logger.info(\"GCViewer version \" + BuildInfoReader.getVersion() + \" (\" + BuildInfoReader.getBuildDate() + \")\");\r\n        model = readModel((GcResourceFile) gcResource);\r\n    } catch (RuntimeException | IOException e) {\r\n        dataReaderException.initCause(e);\r\n        logger.warning(LocalisationHelper.getString(\"fileopen_dialog_read_file_failed\") + \"\\n\" + e.toString() + \" \" + e.getLocalizedMessage());\r\n    }\r\n    if (dataReaderException.getCause() != null) {\r\n        throw dataReaderException;\r\n    }\r\n    return model;\r\n}"
}, {
	"Path": "hex.pca.PCA.setWideDataset",
	"Comment": "set value of widedataset.note that this routine is used for test purposes only and not for users.",
	"Method": "void setWideDataset(boolean isWide){\r\n    _wideDataset = isWide;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.argumentselectiondefects.LowInformationNameHeuristic.findMatch",
	"Comment": "return the first regular expression from the list of overloaded words which matches theparameter name.",
	"Method": "String findMatch(Parameter parameter){\r\n    for (String regex : overloadedNamesRegexs) {\r\n        if (parameter.name().matches(regex)) {\r\n            return regex;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.apidiff.ApiDiff.isClassUnsupported",
	"Comment": "returns true if the class with the given binary name is unsupported.",
	"Method": "boolean isClassUnsupported(String className){\r\n    return unsupportedClasses().contains(className);\r\n}"
}, {
	"Path": "water.api.Schema.markdown",
	"Comment": "generate markdown documentation for this schema, given we already have the metadata constructed.",
	"Method": "StringBuffer markdown(boolean include_input_fields,boolean include_output_fields,StringBuffer markdown,SchemaMetadata meta,boolean include_input_fields,boolean include_output_fields){\r\n    MarkdownBuilder builder = new MarkdownBuilder();\r\n    builder.comment(\"Preview with http://jbt.github.io/markdown-editor\");\r\n    builder.heading1(\"schema \", this.getClass().getSimpleName());\r\n    builder.hline();\r\n    boolean first;\r\n    try {\r\n        if (include_input_fields) {\r\n            first = true;\r\n            builder.heading2(\"input fields\");\r\n            for (SchemaMetadata.FieldMetadata field_meta : meta.fields) {\r\n                if (field_meta.direction == API.Direction.INPUT || field_meta.direction == API.Direction.INOUT) {\r\n                    if (first) {\r\n                        builder.tableHeader(\"name\", \"required?\", \"level\", \"type\", \"schema?\", \"schema\", \"default\", \"description\", \"values\", \"is member of frames\", \"is mutually exclusive with\");\r\n                        first = false;\r\n                    }\r\n                    // Something better for toString()?\r\n                    builder.tableRow(// Something better for toString()?\r\n                    field_meta.name, // Something better for toString()?\r\n                    String.valueOf(field_meta.required), // Something better for toString()?\r\n                    field_meta.level.name(), // Something better for toString()?\r\n                    field_meta.type, String.valueOf(field_meta.is_schema), field_meta.is_schema ? field_meta.schema_name : \"\", (null == field_meta.value ? \"(null)\" : field_meta.value.toString()), field_meta.help, (field_meta.values == null || field_meta.values.length == 0 ? \"\" : Arrays.toString(field_meta.values)), (field_meta.is_member_of_frames == null ? \"[]\" : Arrays.toString(field_meta.is_member_of_frames)), (field_meta.is_mutually_exclusive_with == null ? \"[]\" : Arrays.toString(field_meta.is_mutually_exclusive_with)));\r\n                }\r\n            }\r\n            if (first)\r\n                builder.paragraph(\"(none)\");\r\n        }\r\n        if (include_output_fields) {\r\n            first = true;\r\n            builder.heading2(\"output fields\");\r\n            for (SchemaMetadata.FieldMetadata field_meta : meta.fields) {\r\n                if (field_meta.direction == API.Direction.OUTPUT || field_meta.direction == API.Direction.INOUT) {\r\n                    if (first) {\r\n                        builder.tableHeader(\"name\", \"type\", \"schema?\", \"schema\", \"default\", \"description\", \"values\", \"is member of frames\", \"is mutually exclusive with\");\r\n                        first = false;\r\n                    }\r\n                    // something better than toString()?\r\n                    builder.tableRow(// something better than toString()?\r\n                    field_meta.name, // something better than toString()?\r\n                    field_meta.type, // something better than toString()?\r\n                    String.valueOf(field_meta.is_schema), field_meta.is_schema ? field_meta.schema_name : \"\", (null == field_meta.value ? \"(null)\" : field_meta.value.toString()), field_meta.help, (field_meta.values == null || field_meta.values.length == 0 ? \"\" : Arrays.toString(field_meta.values)), (field_meta.is_member_of_frames == null ? \"[]\" : Arrays.toString(field_meta.is_member_of_frames)), (field_meta.is_mutually_exclusive_with == null ? \"[]\" : Arrays.toString(field_meta.is_mutually_exclusive_with)));\r\n                }\r\n            }\r\n            if (first)\r\n                builder.paragraph(\"(none)\");\r\n        }\r\n    } catch (Exception e) {\r\n        IcedHashMapGeneric.IcedHashMapStringObject values = new IcedHashMapGeneric.IcedHashMapStringObject();\r\n        values.put(\"schema\", this);\r\n        throw new H2OIllegalArgumentException(\"Caught exception using reflection on schema: \" + this, \"Caught exception using reflection on schema: \" + this + \": \" + e, values);\r\n    }\r\n    return builder.stringBuffer();\r\n}"
}, {
	"Path": "eu.siacs.conversations.utils.MimeUtils.hasExtension",
	"Comment": "returns true if the given extension has a registered mime type.",
	"Method": "boolean hasExtension(String extension){\r\n    if (extension == null || extension.isEmpty()) {\r\n        return false;\r\n    }\r\n    return extensionToMimeTypeMap.containsKey(extension);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.FutureReturnValueIgnored.matchReturn",
	"Comment": "returning a type of future from a lambda or method that returns object loses the future type,which can result in suppressed errors or race conditions.",
	"Method": "Description matchReturn(ReturnTree tree,VisitorState state){\r\n    Type objectType = state.getTypeFromString(\"java.lang.Object\");\r\n    Type futureType = state.getTypeFromString(\"java.util.concurrent.Future\");\r\n    if (futureType == null) {\r\n        return Description.NO_MATCH;\r\n    }\r\n    Type resultType = ASTHelpers.getResultType(tree.getExpression());\r\n    if (resultType == null) {\r\n        return Description.NO_MATCH;\r\n    }\r\n    if (resultType.getKind() == TypeKind.NULL || resultType.getKind() == TypeKind.NONE) {\r\n        return Description.NO_MATCH;\r\n    }\r\n    if (ASTHelpers.isSubtype(resultType, futureType, state)) {\r\n        for (Tree enclosing : state.getPath()) {\r\n            if (enclosing instanceof MethodTree) {\r\n                MethodTree methodTree = (MethodTree) enclosing;\r\n                MethodSymbol symbol = ASTHelpers.getSymbol(methodTree);\r\n                if (ASTHelpers.isSubtype(objectType, symbol.getReturnType(), state) && !isWhitelistedInterfaceMethod(symbol, state)) {\r\n                    return buildDescription(tree).setMessage(String.format(\"Returning %s from method that returns %s. Errors from the returned future\" + \" may be ignored.\", resultType, symbol.getReturnType())).build();\r\n                } else {\r\n                    break;\r\n                }\r\n            }\r\n            if (enclosing instanceof LambdaExpressionTree) {\r\n                LambdaExpressionTree lambdaTree = (LambdaExpressionTree) enclosing;\r\n                if (isObjectReturningLambdaExpression(lambdaTree, state)) {\r\n                    return buildDescription(tree).setMessage(String.format(\"Returning %s from method that returns Object. Errors from the returned\" + \" future will be ignored.\", resultType)).build();\r\n                } else {\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return Description.NO_MATCH;\r\n}"
}, {
	"Path": "jsr166y.ConcurrentLinkedDeque.succ",
	"Comment": "returns the successor of p, or the first node if p.next has beenlinked to self, which will only be true if traversing with astale pointer that is now off the list.",
	"Method": "Node<E> succ(Node<E> p){\r\n    Node<E> q = p.next;\r\n    return (p == q) ? first() : q;\r\n}"
}, {
	"Path": "jsr166y.ForkJoinTask.trySetSignal",
	"Comment": "tries to set signal status unless already completed. used byforkjoinpool. other variants are directly incorporated intoexternalawaitdone etc.",
	"Method": "boolean trySetSignal(){\r\n    int s = status;\r\n    return s >= 0 && U.compareAndSwapInt(this, STATUS, s, s | SIGNAL);\r\n}"
}, {
	"Path": "hex.ConfusionMatrix.recall",
	"Comment": "the percentage of positive labeled instances that were predicted as positive.",
	"Method": "double recall(){\r\n    if (!isBinary())\r\n        throw new UnsupportedOperationException(\"recall is only implemented for 2 class problems.\");\r\n    if (tooLarge())\r\n        throw new UnsupportedOperationException(\"recall cannot be computed: too many classes\");\r\n    double tp = _cm[1][1];\r\n    double fn = _cm[1][0];\r\n    return tp / (tp + fn);\r\n}"
}, {
	"Path": "com.google.errorprone.ErrorProneFlags.isEmpty",
	"Comment": "whether this flags object is empty, i.e. no flags have been set.",
	"Method": "boolean isEmpty(){\r\n    return this.flagsMap.isEmpty();\r\n}"
}, {
	"Path": "com.google.errorprone.DocGenProcessor.cleanup",
	"Comment": "perform cleanup after last round of annotation processing.",
	"Method": "void cleanup(){\r\n    pw.close();\r\n}"
}, {
	"Path": "ai.h2o.automl.targetencoding.TargetEncoder.prepareEncodingMap",
	"Comment": "todo at least it seems that way in the case of kfold. but even if we need to preprocess for other types of te calculations... we should not affect kfold case anyway.",
	"Method": "Map<String, Frame> prepareEncodingMap(Frame data,String targetColumnName,String foldColumnName,boolean imputeNAsWithNewCategory,Map<String, Frame> prepareEncodingMap,Frame data,String targetColumnName,String foldColumnName){\r\n    boolean imputeNAsWithNewCategory = true;\r\n    return prepareEncodingMap(data, targetColumnName, foldColumnName, imputeNAsWithNewCategory);\r\n}"
}, {
	"Path": "eu.siacs.conversations.crypto.axolotl.SQLiteAxolotlStore.getSubDeviceSessions",
	"Comment": "returns all known devices with active sessions for a recipient",
	"Method": "List<Integer> getSubDeviceSessions(String name){\r\n    return mXmppConnectionService.databaseBackend.getSubDeviceSessions(account, new SignalProtocolAddress(name, 0));\r\n}"
}, {
	"Path": "water.fvec.Vec.toCategoricalVec",
	"Comment": "convenience method for converting to a categorical vector.",
	"Method": "Vec toCategoricalVec(){\r\n    return VecUtils.toCategoricalVec(this);\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.model.GCModel.updatePromotion",
	"Comment": "promotion is the amount of memory that is promoted from young to tenured space duringa collection of the young space.",
	"Method": "void updatePromotion(GCEvent event){\r\n    if (event.getGeneration().equals(Generation.YOUNG) && event.hasDetails() && !event.isFull()) {\r\n        GCEvent youngEvent = null;\r\n        for (Iterator<GCEvent> i = event.details(); i.hasNext(); ) {\r\n            GCEvent ev = i.next();\r\n            if (ev.getGeneration().equals(Generation.YOUNG)) {\r\n                youngEvent = ev;\r\n                break;\r\n            }\r\n        }\r\n        if (youngEvent != null) {\r\n            promotion.add((youngEvent.getPreUsed() - youngEvent.getPostUsed()) - (event.getPreUsed() - event.getPostUsed()));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.baselineDescription",
	"Comment": "sets the description to tag an existing schema with when executing baseline.",
	"Method": "FluentConfiguration baselineDescription(String baselineDescription){\r\n    config.setBaselineDescription(baselineDescription);\r\n    return this;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.info.MigrationInfoServiceImpl.refresh",
	"Comment": "refreshes the info about all known migrations from both the classpath and the db.",
	"Method": "void refresh(){\r\n    Collection<ResolvedMigration> resolvedMigrations = migrationResolver.resolveMigrations(context);\r\n    List<AppliedMigration> appliedMigrations = schemaHistory.allAppliedMigrations();\r\n    MigrationInfoContext context = new MigrationInfoContext();\r\n    context.outOfOrder = outOfOrder;\r\n    context.pending = pending;\r\n    context.missing = missing;\r\n    context.ignored = ignored;\r\n    context.future = future;\r\n    context.target = target;\r\n    Map<Pair<MigrationVersion, Boolean>, ResolvedMigration> resolvedVersioned = new TreeMap();\r\n    Map<String, ResolvedMigration> resolvedRepeatable = new TreeMap();\r\n    for (ResolvedMigration resolvedMigration : resolvedMigrations) {\r\n        MigrationVersion version = resolvedMigration.getVersion();\r\n        if (version != null) {\r\n            if (version.compareTo(context.lastResolved) > 0) {\r\n                context.lastResolved = version;\r\n            }\r\n            resolvedVersioned.put(Pair.of(version, false), resolvedMigration);\r\n        } else {\r\n            resolvedRepeatable.put(resolvedMigration.getDescription(), resolvedMigration);\r\n        }\r\n    }\r\n    List<Pair<AppliedMigration, AppliedMigrationAttributes>> appliedVersioned = new ArrayList();\r\n    List<AppliedMigration> appliedRepeatable = new ArrayList();\r\n    for (AppliedMigration appliedMigration : appliedMigrations) {\r\n        MigrationVersion version = appliedMigration.getVersion();\r\n        if (version == null) {\r\n            appliedRepeatable.add(appliedMigration);\r\n            continue;\r\n        }\r\n        if (appliedMigration.getType() == MigrationType.SCHEMA) {\r\n            context.schema = version;\r\n        }\r\n        if (appliedMigration.getType() == MigrationType.BASELINE) {\r\n            context.baseline = version;\r\n        }\r\n        appliedVersioned.add(Pair.of(appliedMigration, new AppliedMigrationAttributes()));\r\n    }\r\n    for (Pair<AppliedMigration, AppliedMigrationAttributes> av : appliedVersioned) {\r\n        MigrationVersion version = av.getLeft().getVersion();\r\n        if (version != null) {\r\n            if (version.compareTo(context.lastApplied) > 0) {\r\n                context.lastApplied = version;\r\n            } else {\r\n                av.getRight().outOfOrder = true;\r\n            }\r\n        }\r\n    }\r\n    if (MigrationVersion.CURRENT == target) {\r\n        context.target = context.lastApplied;\r\n    }\r\n    List<MigrationInfoImpl> migrationInfos1 = new ArrayList();\r\n    Set<ResolvedMigration> pendingResolvedVersioned = new HashSet(resolvedVersioned.values());\r\n    for (Pair<AppliedMigration, AppliedMigrationAttributes> av : appliedVersioned) {\r\n        ResolvedMigration resolvedMigration = resolvedVersioned.get(Pair.of(av.getLeft().getVersion(), av.getLeft().getType().isUndo()));\r\n        if (resolvedMigration != null) {\r\n            pendingResolvedVersioned.remove(resolvedMigration);\r\n        }\r\n        migrationInfos1.add(new MigrationInfoImpl(resolvedMigration, av.getLeft(), context, av.getRight().outOfOrder));\r\n    }\r\n    for (ResolvedMigration prv : pendingResolvedVersioned) {\r\n        migrationInfos1.add(new MigrationInfoImpl(prv, null, context, false));\r\n    }\r\n    for (AppliedMigration appliedRepeatableMigration : appliedRepeatable) {\r\n        if (!context.latestRepeatableRuns.containsKey(appliedRepeatableMigration.getDescription()) || (appliedRepeatableMigration.getInstalledRank() > context.latestRepeatableRuns.get(appliedRepeatableMigration.getDescription()))) {\r\n            context.latestRepeatableRuns.put(appliedRepeatableMigration.getDescription(), appliedRepeatableMigration.getInstalledRank());\r\n        }\r\n    }\r\n    Set<ResolvedMigration> pendingResolvedRepeatable = new HashSet(resolvedRepeatable.values());\r\n    for (AppliedMigration appliedRepeatableMigration : appliedRepeatable) {\r\n        ResolvedMigration resolvedMigration = resolvedRepeatable.get(appliedRepeatableMigration.getDescription());\r\n        int latestRank = context.latestRepeatableRuns.get(appliedRepeatableMigration.getDescription());\r\n        if (resolvedMigration != null && appliedRepeatableMigration.getInstalledRank() == latestRank && ObjectUtils.nullSafeEquals(appliedRepeatableMigration.getChecksum(), resolvedMigration.getChecksum())) {\r\n            pendingResolvedRepeatable.remove(resolvedMigration);\r\n        }\r\n        migrationInfos1.add(new MigrationInfoImpl(resolvedMigration, appliedRepeatableMigration, context, false));\r\n    }\r\n    for (ResolvedMigration prr : pendingResolvedRepeatable) {\r\n        migrationInfos1.add(new MigrationInfoImpl(prr, null, context, false));\r\n    }\r\n    Collections.sort(migrationInfos1);\r\n    migrationInfos = migrationInfos1;\r\n}"
}, {
	"Path": "com.yalantis.contextmenu.lib.MenuObject.setMenuTextAppearanceStyle",
	"Comment": "set style resource id, it will be used for setting text appearance of menu item title.for better effect your style should extend textview.defaultstyle",
	"Method": "void setMenuTextAppearanceStyle(int mMenuTextAppearanceStyle){\r\n    this.mMenuTextAppearenseStyle = mMenuTextAppearanceStyle;\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlusBuilder.setContentHolder",
	"Comment": "set the content of the dialog by passing one of the provided holders",
	"Method": "DialogPlusBuilder setContentHolder(Holder holder){\r\n    this.holder = holder;\r\n    return this;\r\n}"
}, {
	"Path": "water.api.ModelMetricsHandler.predictAsync",
	"Comment": "score a frame with the given model and return the metrics and the prediction frame.",
	"Method": "JobV3 predictAsync(int version,ModelMetricsListSchemaV3 s){\r\n    if (null == s.model)\r\n        throw new H2OIllegalArgumentException(\"model\", \"predict\", s.model);\r\n    if (null == DKV.get(s.model.name))\r\n        throw new H2OKeyNotFoundArgumentException(\"model\", \"predict\", s.model.name);\r\n    if (null == s.frame)\r\n        throw new H2OIllegalArgumentException(\"frame\", \"predict\", s.frame);\r\n    if (null == DKV.get(s.frame.name))\r\n        throw new H2OKeyNotFoundArgumentException(\"frame\", \"predict\", s.frame.name);\r\n    if (s.deviances || null != s.deviances_frame)\r\n        throw new H2OIllegalArgumentException(\"deviances\", \"not supported for async\", s.deviances_frame);\r\n    final ModelMetricsList parms = s.createAndFillImpl();\r\n    if (s.deep_features_hidden_layer > 0 || s.deep_features_hidden_layer_name != null) {\r\n        if (null == parms._predictions_name)\r\n            parms._predictions_name = \"deep_features\" + Key.make().toString().substring(0, 5) + \"_\" + parms._model._key.toString() + \"_on_\" + parms._frame._key.toString();\r\n    } else if (null == parms._predictions_name) {\r\n        if (parms._exemplar_index >= 0) {\r\n            parms._predictions_name = \"members_\" + parms._model._key.toString() + \"_for_exemplar_\" + parms._exemplar_index;\r\n        } else {\r\n            parms._predictions_name = \"predictions\" + Key.make().toString().substring(0, 5) + \"_\" + parms._model._key.toString() + \"_on_\" + parms._frame._key.toString();\r\n        }\r\n    }\r\n    final Job<Frame> j = new Job(Key.make(parms._predictions_name), Frame.class.getName(), \"prediction\");\r\n    H2O.H2OCountedCompleter work = new H2O.H2OCountedCompleter() {\r\n        @Override\r\n        public void compute2() {\r\n            if (s.deep_features_hidden_layer < 0 && s.deep_features_hidden_layer_name == null) {\r\n                parms._model.score(parms._frame, parms._predictions_name, j, true, CFuncRef.from(s.custom_metric_func));\r\n            } else if (s.deep_features_hidden_layer_name != null) {\r\n                Frame predictions = null;\r\n                try {\r\n                    predictions = ((Model.DeepFeatures) parms._model).scoreDeepFeatures(parms._frame, s.deep_features_hidden_layer_name, j);\r\n                } catch (IllegalArgumentException e) {\r\n                    Log.warn(e.getMessage());\r\n                    throw e;\r\n                }\r\n                if (predictions != null) {\r\n                    predictions = new Frame(Key.<Frame>make(parms._predictions_name), predictions.names(), predictions.vecs());\r\n                    DKV.put(predictions._key, predictions);\r\n                }\r\n            } else {\r\n                Frame predictions = ((Model.DeepFeatures) parms._model).scoreDeepFeatures(parms._frame, s.deep_features_hidden_layer, j);\r\n                predictions = new Frame(Key.<Frame>make(parms._predictions_name), predictions.names(), predictions.vecs());\r\n                DKV.put(predictions._key, predictions);\r\n            }\r\n            if ((parms._model._warningsP != null) && (parms._model._warningsP.length > 0)) {\r\n                String[] allWarnings = (String[]) ArrayUtils.addAll(j.warns(), parms._model._warningsP);\r\n                j.setWarnings(allWarnings);\r\n            }\r\n            tryComplete();\r\n        }\r\n    };\r\n    j.start(work, parms._frame.anyVec().nChunks());\r\n    return new JobV3().fillFromImpl(j);\r\n}"
}, {
	"Path": "water.api.ModelMetricsHandler.predictAsync",
	"Comment": "score a frame with the given model and return the metrics and the prediction frame.",
	"Method": "JobV3 predictAsync(int version,ModelMetricsListSchemaV3 s){\r\n    if (s.deep_features_hidden_layer < 0 && s.deep_features_hidden_layer_name == null) {\r\n        parms._model.score(parms._frame, parms._predictions_name, j, true, CFuncRef.from(s.custom_metric_func));\r\n    } else if (s.deep_features_hidden_layer_name != null) {\r\n        Frame predictions = null;\r\n        try {\r\n            predictions = ((Model.DeepFeatures) parms._model).scoreDeepFeatures(parms._frame, s.deep_features_hidden_layer_name, j);\r\n        } catch (IllegalArgumentException e) {\r\n            Log.warn(e.getMessage());\r\n            throw e;\r\n        }\r\n        if (predictions != null) {\r\n            predictions = new Frame(Key.<Frame>make(parms._predictions_name), predictions.names(), predictions.vecs());\r\n            DKV.put(predictions._key, predictions);\r\n        }\r\n    } else {\r\n        Frame predictions = ((Model.DeepFeatures) parms._model).scoreDeepFeatures(parms._frame, s.deep_features_hidden_layer, j);\r\n        predictions = new Frame(Key.<Frame>make(parms._predictions_name), predictions.names(), predictions.vecs());\r\n        DKV.put(predictions._key, predictions);\r\n    }\r\n    if ((parms._model._warningsP != null) && (parms._model._warningsP.length > 0)) {\r\n        String[] allWarnings = (String[]) ArrayUtils.addAll(j.warns(), parms._model._warningsP);\r\n        j.setWarnings(allWarnings);\r\n    }\r\n    tryComplete();\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.SqlStatementBuilder.executeInTransaction",
	"Comment": "whether the execution should take place inside a transaction. this is useful for databaseslike postgresql or sql server where certain statements can only execute outside a transaction.",
	"Method": "boolean executeInTransaction(){\r\n    return executeInTransaction;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.nextStatement",
	"Comment": "matches a statement ast node if the following statement in the enclosing block matches thegiven matcher.",
	"Method": "NextStatement<T> nextStatement(Matcher<StatementTree> matcher){\r\n    return new NextStatement(matcher);\r\n}"
}, {
	"Path": "hex.ModelMojoWriter.writeModelDetails",
	"Comment": "create file that contains model details in json format.this information is pulled from the models schema.",
	"Method": "void writeModelDetails(){\r\n    ModelSchemaV3 modelSchema = (ModelSchemaV3) SchemaServer.schema(3, model).fillFromImpl(model);\r\n    startWritingTextFile(\"experimental/modelDetails.json\");\r\n    writeln(modelSchema.toJsonString());\r\n    finishWritingTextFile();\r\n}"
}, {
	"Path": "jsr166y.CountedCompleter.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    try {\r\n        return sun.misc.Unsafe.getUnsafe();\r\n    } catch (SecurityException se) {\r\n        try {\r\n            return java.security.AccessController.doPrivileged(new java.security.PrivilegedExceptionAction<sun.misc.Unsafe>() {\r\n                public sun.misc.Unsafe run() throws Exception {\r\n                    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n                    f.setAccessible(true);\r\n                    return (sun.misc.Unsafe) f.get(null);\r\n                }\r\n            });\r\n        } catch (java.security.PrivilegedActionException e) {\r\n            throw new RuntimeException(\"Could not initialize intrinsics\", e.getCause());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "jsr166y.CountedCompleter.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n    f.setAccessible(true);\r\n    return (sun.misc.Unsafe) f.get(null);\r\n}"
}, {
	"Path": "water.parser.ParseSetup.createHexName",
	"Comment": "cleans up the file name to make .hex nameto be used as a destination key.eliminatescommon file extensions, and replaces oddcharacters.",
	"Method": "String createHexName(String n){\r\n    int sep = n.lastIndexOf(java.io.File.separatorChar);\r\n    if (sep > 0)\r\n        n = n.substring(sep + 1);\r\n    int dot = n.lastIndexOf('.');\r\n    while (dot > 0 && (n.endsWith(\"zip\") || n.endsWith(\"gz\") || n.endsWith(\"csv\") || n.endsWith(\"xls\") || n.endsWith(\"txt\") || n.endsWith(\"svm\") || n.endsWith(\"orc\") || n.endsWith(\"arff\"))) {\r\n        n = n.substring(0, dot);\r\n        dot = n.lastIndexOf('.');\r\n    }\r\n    if (!Character.isJavaIdentifierStart(n.charAt(0)))\r\n        n = \"X\" + n;\r\n    char[] cs = n.toCharArray();\r\n    for (int i = 1; i < cs.length; i++) if (!Character.isJavaIdentifierPart(cs[i]))\r\n        cs[i] = '_';\r\n    n = new String(cs);\r\n    int i = 0;\r\n    String res = n + \".hex\";\r\n    Key k = Key.make(res);\r\n    while (DKV.get(k) != null) k = Key.make(res = n + ++i + \".hex\");\r\n    return res;\r\n}"
}, {
	"Path": "hex.Model.scoreMetrics",
	"Comment": "score an already adapted frame.returns a metricbuilder that can be used to make a model metrics.",
	"Method": "ModelMetrics.MetricBuilder scoreMetrics(Frame adaptFrm){\r\n    final boolean computeMetrics = (!isSupervised() || (adaptFrm.vec(_output.responseName()) != null && !adaptFrm.vec(_output.responseName()).isBad()));\r\n    String[][] domains = new String[1][];\r\n    domains[0] = _output.nclasses() == 1 ? null : !computeMetrics ? _output._domains[_output._domains.length - 1] : adaptFrm.lastVec().domain();\r\n    if (domains[0] == null && _parms._distribution == DistributionFamily.quasibinomial) {\r\n        domains[0] = new String[] { \"0\", \"1\" };\r\n    }\r\n    BigScore bs = makeBigScoreTask(domains, null, adaptFrm, computeMetrics, false, null, CFuncRef.from(_parms._custom_metric_func)).doAll(adaptFrm);\r\n    return bs._mb;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.UrlUtils.toFilePath",
	"Comment": "retrieves the file path of this url, with any trailing slashes removed.",
	"Method": "String toFilePath(URL url){\r\n    try {\r\n        String filePath = new File(URLDecoder.decode(url.getPath().replace(\"+\", \"+\"), \"UTF-8\")).getAbsolutePath();\r\n        if (filePath.endsWith(\"/\")) {\r\n            return filePath.substring(0, filePath.length() - 1);\r\n        }\r\n        return filePath;\r\n    } catch (UnsupportedEncodingException e) {\r\n        throw new IllegalStateException(\"Can never happen\", e);\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.placeholder.DefaultPlaceholderReplacer.checkForUnmatchedPlaceholderExpression",
	"Comment": "check for unmatched placeholder expressions in the input string and throwa flywayexception if they do not have corresponding values.",
	"Method": "void checkForUnmatchedPlaceholderExpression(String input){\r\n    Matcher matcher = anyPlaceholderPattern.matcher(input);\r\n    Set<String> unmatchedPlaceHolderExpressions = new TreeSet();\r\n    while (matcher.find()) {\r\n        unmatchedPlaceHolderExpressions.add(matcher.group());\r\n    }\r\n    if (!unmatchedPlaceHolderExpressions.isEmpty()) {\r\n        throw new FlywayException(\"No value provided for placeholder expressions: \" + StringUtils.collectionToCommaDelimitedString(unmatchedPlaceHolderExpressions) + \".  Check your configuration!\");\r\n    }\r\n}"
}, {
	"Path": "hex.deepwater.DeepWaterAbstractIntegrationTest.testCheckpointOverwriteWithBestModel2",
	"Comment": "check that the restarted model honors the previous model as a best model so far",
	"Method": "void testCheckpointOverwriteWithBestModel2(){\r\n    Frame tfr = null;\r\n    DeepWaterModel dl = null;\r\n    DeepWaterModel dl2 = null;\r\n    Frame train = null, valid = null;\r\n    try {\r\n        tfr = parse_test_file(\"./smalldata/iris/iris.csv\");\r\n        FrameSplitter fs = new FrameSplitter(tfr, new double[] { 0.8 }, new Key[] { Key.make(\"train\"), Key.make(\"valid\") }, null);\r\n        fs.compute2();\r\n        train = fs.getResult()[0];\r\n        valid = fs.getResult()[1];\r\n        DeepWaterParameters parms = new DeepWaterParameters();\r\n        parms._backend = getBackend();\r\n        parms._train = train._key;\r\n        parms._valid = valid._key;\r\n        parms._epochs = 10;\r\n        parms._response_column = \"C5\";\r\n        parms._hidden = new int[] { 50, 50 };\r\n        parms._seed = 0xdecaf;\r\n        parms._train_samples_per_iteration = 0;\r\n        parms._score_duty_cycle = 1;\r\n        parms._score_interval = 0;\r\n        parms._stopping_rounds = 0;\r\n        parms._overwrite_with_best_model = true;\r\n        dl = new DeepWater(parms).trainModel().get();\r\n        double ll1 = ((ModelMetricsMultinomial) dl._output._validation_metrics).logloss();\r\n        DeepWaterParameters parms2 = (DeepWaterParameters) parms.clone();\r\n        parms2._epochs = 20;\r\n        parms2._checkpoint = dl._key;\r\n        dl2 = new DeepWater(parms2).trainModel().get();\r\n        double ll2 = ((ModelMetricsMultinomial) dl2._output._validation_metrics).logloss();\r\n        Assert.assertTrue(ll2 <= ll1);\r\n    } finally {\r\n        if (tfr != null)\r\n            tfr.delete();\r\n        if (dl != null)\r\n            dl.delete();\r\n        if (dl2 != null)\r\n            dl2.delete();\r\n        if (train != null)\r\n            train.delete();\r\n        if (valid != null)\r\n            valid.delete();\r\n    }\r\n}"
}, {
	"Path": "water.Job.progress",
	"Comment": "returns a float from 0 to 1 representing progress.polled periodically. can default to returning e.g. 0 always.",
	"Method": "float progress(){\r\n    update_from_remote();\r\n    float regularProgress = _work == 0 ? 0f : Math.min(1, (float) _worked / _work);\r\n    if (_max_runtime_msecs > 0)\r\n        return Math.min(1, Math.max(regularProgress, (float) msec() / _max_runtime_msecs));\r\n    return regularProgress;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.postgresql.PostgreSQLSchema.generateDropStatementsForSequences",
	"Comment": "generates the statements for dropping the sequences in this schema.",
	"Method": "List<String> generateDropStatementsForSequences(){\r\n    List<String> sequenceNames = jdbcTemplate.queryForStringList(\"SELECT sequence_name FROM information_schema.sequences WHERE sequence_schema=?\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (String sequenceName : sequenceNames) {\r\n        statements.add(\"DROP SEQUENCE IF EXISTS \" + database.quote(name, sequenceName));\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "water.parser.Parser.readOneFile",
	"Comment": "this method reads in one zip file.before reading the file, it will check if the current file has the samenumber of columns and separator type as the previous files it has parssed.if they do not match, no file willbe parsed in this case.",
	"Method": "StreamInfo readOneFile(InputStream is,StreamParseWriter dout,InputStream bvs,StreamParseWriter nextChunk,int zidx,int fileIndex){\r\n    int cidx = 0;\r\n    StreamData din = new StreamData(is);\r\n    if ((fileIndex > 0) && (!checkFileNHeader(is, dout, din, cidx)))\r\n        return new StreamInfo(zidx, nextChunk);\r\n    int streamAvailable = is.available();\r\n    while (streamAvailable > 0) {\r\n        parseChunk(cidx++, din, nextChunk);\r\n        streamAvailable = is.available();\r\n        int xidx = bvs.read(null, 0, 0);\r\n        if (xidx > zidx) {\r\n            zidx = xidx;\r\n            nextChunk.close();\r\n            if (dout != nextChunk) {\r\n                dout.reduce(nextChunk);\r\n                if (_jobKey != null && _jobKey.get().stop_requested())\r\n                    break;\r\n            }\r\n            nextChunk = nextChunk.nextChunk();\r\n        }\r\n    }\r\n    parseChunk(cidx, din, nextChunk);\r\n    return new StreamInfo(zidx, nextChunk);\r\n}"
}, {
	"Path": "graphql.util.FpKit.getByName",
	"Comment": "from a list of named things, get a map of them by name, merging them first one added",
	"Method": "Map<String, T> getByName(List<T> namedObjects,Function<T, String> nameFn,BinaryOperator<T> mergeFunc,Map<String, T> getByName,List<T> namedObjects,Function<T, String> nameFn){\r\n    return getByName(namedObjects, nameFn, mergeFirst());\r\n}"
}, {
	"Path": "hex.glm.GLMBasicTestBinomial.testCODGradients",
	"Comment": "i have separated fitcod from fitirlsm and here is to test and made sure my changes are correct and they shouldgenerate the same coefficients as the old method.",
	"Method": "void testCODGradients(){\r\n    Scope.enter();\r\n    Frame train;\r\n    GLMParameters params = new GLMParameters(Family.binomial);\r\n    GLMModel model = null;\r\n    double[] goldenCoeffs = new double[] { 3.315139700626461, 0.9929054923448074, -1.0655426388234126, -3.7892948800495154, -2.0865591118999833, 0.7867696413635438, -1.8615599223372965, 1.0643138374753327, 1.0986728686030014, 0.10479049125777502, -1.7812358987823367, 0.8647531123879351, 2.0849120863386665, -0.8774966728502775, -0.42153877552507385, 3.2634187521383566, -1.9624237021260278, -0.34691475925538673, -1.646532127145956, 1.6306397833575321, -3.044501939682644, 0.8944464253207084, 0.9895807015140112, -2.6717292838527205, -3.521867765191535, -2.4013802719175663, 5.1067282883832394, -2.6453709205608122, -3.1305849772174876, -3.431102221875896, 1.9010730022389033, -1.7904328104400145, -0.26701745669682453, -4.546721592533792, 2.711748945952299, 3.8151882842344387, -4.966584969931568, 0.4072915316377201, -1.4716951033978412, -0.9600779293443411, -4.1033253093776505, -0.900138450590691, -3.41567157570875, 3.9532415786014323, -4.152487787492122, -4.816302785007451, -2.0646847130482033, 4.916683882613988, -1.0828334669455186, -1.7535227306034435, 3.543101904113447, 3.365050014714852, 1.09947447201617, 3.801711118872804, -4.327701880800191, 2.949107493656704, 1.2974956967558495, -4.766971479293396, 3.608879061144071, -4.432383409841722, -1.945588990329554, -0.5741123903558344, 3.0082971652620296, 1.2105456702290207, -2.0058145215980505, 4.633057967358068, 4.69177641215046, 3.2313754439814084, -3.87050641561738, 0.3902584675760716, 1.2180174243872703, 0.652166829687263, -2.934162573531005, 1.8163438452614908, -1.1131945394628258, 3.711779285831191, -1.2771611943142913, -3.0180677371604494, -1.0002653053027677, 2.109019933558617, 1.681095046876924, 0.026980109195036545, 4.515676428483863, 3.4584826805338142, -4.884432397071569, -3.089270335492296, -0.2693643511214426, 0.8903491083888826, 4.596551636071276, -1.9091402449943644, 0.42187489841011877, 0.7507290472538346, -0.4545335921717534, -1.843531271821739, -10.450169230334527 };\r\n    try {\r\n        train = parse_test_file(\"smalldata/glm_test/binomial_1000Rows.csv\");\r\n        String[] names = train._names;\r\n        Vec[] en = train.remove(new int[] { 0, 1, 2, 3, 4, 5, 6 });\r\n        for (int cind = 0; cind < 7; cind++) {\r\n            train.add(names[cind], VecUtils.toCategoricalVec(en[cind]));\r\n            Scope.track(en[cind]);\r\n        }\r\n        Scope.track(train);\r\n        params._response_column = \"C79\";\r\n        params._train = train._key;\r\n        params._lambda = new double[] { 4.881e-05 };\r\n        params._alpha = new double[] { 0.5 };\r\n        params._objective_epsilon = 1e-6;\r\n        params._beta_epsilon = 1e-4;\r\n        params._max_iterations = 10;\r\n        params._seed = 12345;\r\n        Solver s = Solver.COORDINATE_DESCENT;\r\n        System.out.println(\"solver = \" + s);\r\n        params._solver = s;\r\n        model = new GLM(params).trainModel().get();\r\n        Scope.track_generic(model);\r\n        compareGLMCoeffs(model._output._submodels[0].beta, goldenCoeffs, 1e-10);\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.suppliers.Suppliers.typeFromClass",
	"Comment": "given the class representation of a type, supplies the corresponding type.",
	"Method": "Supplier<Type> typeFromClass(Class<?> inputClass){\r\n    return typeFromString(inputClass.getName());\r\n}"
}, {
	"Path": "hex.createframe.CreateFrameExecutor.addPostprocessStep",
	"Comment": "add a step to be performed in the end after the frame has been created.this step can then modify the frame in any way.",
	"Method": "void addPostprocessStep(CreateFramePostprocessStep step){\r\n    postprocessSteps.add(step);\r\n    workAmountPostprocess += step.workAmount();\r\n}"
}, {
	"Path": "com.google.errorprone.CompilationTestHelper.expectResult",
	"Comment": "tells the compilation helper to expect a specific result from the compilation, e.g. success orfailure.",
	"Method": "CompilationTestHelper expectResult(Result result){\r\n    expectedResult = Optional.of(result);\r\n    return this;\r\n}"
}, {
	"Path": "water.api.Schema.getImplClass",
	"Comment": "return the class of the implementation type parameter i for this schema. used by generic code which deals with arbitrary schemas and their backing impl classes.never returns null.",
	"Method": "Class<? extends Iced> getImplClass(Class<? extends Schema> clz,Class<I> getImplClass){\r\n    return _impl_class != null ? _impl_class : (_impl_class = ReflectionUtils.findActualClassParameter(this.getClass(), 0));\r\n}"
}, {
	"Path": "com.google.errorprone.refaster.PlaceholderUnificationVisitor.unifyExpressions",
	"Comment": "returns all the ways this placeholder invocation might unify with the specified list of trees.",
	"Method": "Choice<State<List<JCExpression>>> unifyExpressions(Iterable<? extends ExpressionTree> nodes,State<?> state){\r\n    return unify(nodes, state).transform(s -> s.withResult(List.convert(JCExpression.class, s.result())));\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setSkipDefaultResolvers",
	"Comment": "whether flyway should skip the default resolvers. if true, only custom resolvers are used.",
	"Method": "void setSkipDefaultResolvers(boolean skipDefaultResolvers){\r\n    this.skipDefaultResolvers = skipDefaultResolvers;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.isSameType",
	"Comment": "matches an ast node if it has the same erased type as the given class.",
	"Method": "Matcher<T> isSameType(Supplier<Type> type,Matcher<T> isSameType,String typeString,Matcher<T> isSameType,Class<?> clazz){\r\n    return new IsSameType(typeFromClass(clazz));\r\n}"
}, {
	"Path": "graphql.execution.ExecutionContext.transform",
	"Comment": "this helps you transform the current executioncontext object into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "ExecutionContext transform(Consumer<ExecutionContextBuilder> builderConsumer){\r\n    ExecutionContextBuilder builder = ExecutionContextBuilder.newExecutionContextBuilder(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.robotstxt.RobotstxtServer.allows",
	"Comment": "please note that in the case of a bad url, true will be returned",
	"Method": "boolean allows(WebURL webURL){\r\n    if (!config.isEnabled()) {\r\n        return true;\r\n    }\r\n    try {\r\n        URL url = new URL(webURL.getURL());\r\n        String host = getHost(url);\r\n        String path = url.getPath();\r\n        HostDirectives directives = host2directivesCache.get(host);\r\n        if (directives != null && directives.needsRefetch()) {\r\n            synchronized (host2directivesCache) {\r\n                host2directivesCache.remove(host);\r\n                directives = null;\r\n            }\r\n        }\r\n        if (directives == null) {\r\n            directives = fetchDirectives(url);\r\n        }\r\n        return directives.allows(path);\r\n    } catch (MalformedURLException e) {\r\n        logger.error(\"Bad URL in Robots.txt: \" + webURL.getURL(), e);\r\n    }\r\n    logger.warn(\"RobotstxtServer: default: allow\", webURL.getURL());\r\n    return true;\r\n}"
}, {
	"Path": "water.H2O.updateNotIdle",
	"Comment": "update the last time that something happened to reset the idle timer.this is meant to be callable safely from almost anywhere.",
	"Method": "void updateNotIdle(){\r\n    lastTimeSomethingHappenedMillis = System.currentTimeMillis();\r\n}"
}, {
	"Path": "hex.ConfusionMatrix.specificity",
	"Comment": "the percentage of negative labeled instances that were predicted as negative.",
	"Method": "double specificity(){\r\n    if (!isBinary())\r\n        throw new UnsupportedOperationException(\"specificity is only implemented for 2 class problems.\");\r\n    if (tooLarge())\r\n        throw new UnsupportedOperationException(\"specificity cannot be computed: too many classes\");\r\n    double tn = _cm[0][0];\r\n    double fp = _cm[0][1];\r\n    return tn / (tn + fp);\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Description.getMessage",
	"Comment": "returns the message to be printed by the compiler when a match is found in interactive use.includes the name of the check and a link for more information.",
	"Method": "String getMessage(){\r\n    return String.format(\"[%s] %s\", checkName, getMessageWithoutCheckName());\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.shutdown",
	"Comment": "initiates an orderly shutdown in which previously submittedtasks are executed, but no new tasks will be accepted.invocation has no additional effect if already shut down.tasks that are in the process of being submitted concurrentlyduring the course of this method may or may not be rejected.",
	"Method": "void shutdown(){\r\n    checkPermission();\r\n    tryTerminate(false, true);\r\n}"
}, {
	"Path": "water.api.ModelBuilderHandler.handle",
	"Comment": "invoke the handler with parameters.can throw any exception the called handler can throw.",
	"Method": "S handle(int version,Route route,Properties parms,String postBody){\r\n    String[] ss = route._url.split(\"/\");\r\n    String algoURLName = ss[3];\r\n    String algoName = ModelBuilder.algoName(algoURLName);\r\n    String schemaDir = ModelBuilder.schemaDirectory(algoURLName);\r\n    String schemaName = schemaDir + algoName + \"V\" + version;\r\n    S schema = (S) TypeMap.newFreezable(schemaName);\r\n    schema.init_meta();\r\n    String parmName = schemaDir + algoName + \"V\" + version + \"$\" + algoName + \"ParametersV\" + version;\r\n    P parmSchema = (P) TypeMap.newFreezable(parmName);\r\n    schema.parameters = parmSchema;\r\n    String handlerName = route._handler_method.getName();\r\n    boolean doTrain = handlerName.equals(\"train\");\r\n    assert doTrain || handlerName.equals(\"validate_parameters\");\r\n    String model_id = parms.getProperty(\"model_id\");\r\n    String warningStr = null;\r\n    if ((model_id != null) && (model_id.contains(\"/\"))) {\r\n        String tempName = model_id;\r\n        model_id = model_id.replaceAll(\"/\", \"_\");\r\n        warningStr = \"Bad model_id: slash (/) found and replaced with _.  \" + \"Original model_id \" + tempName + \" is now \" + model_id + \".\";\r\n        Log.warn(\"model_id\", warningStr);\r\n    }\r\n    Key<Model> key = doTrain ? (model_id == null ? ModelBuilder.defaultKey(algoName) : Key.<Model>make(model_id)) : null;\r\n    Job job = doTrain ? (warningStr != null ? new Job(key, ModelBuilder.javaName(algoURLName), algoName, warningStr) : new Job(key, ModelBuilder.javaName(algoURLName), algoName)) : null;\r\n    B builder = ModelBuilder.make(algoURLName, job, key);\r\n    schema.parameters.fillFromImpl(builder._parms);\r\n    schema.parameters.fillFromParms(parms);\r\n    schema.parameters.fillImpl(builder._parms);\r\n    builder.init(false);\r\n    schema.fillFromImpl(builder);\r\n    PojoUtils.copyProperties(schema.parameters, builder._parms, PojoUtils.FieldNaming.ORIGIN_HAS_UNDERSCORES, null, new String[] { \"error_count\", \"messages\" });\r\n    schema.setHttpStatus(HttpResponseStatus.OK.getCode());\r\n    if (doTrain)\r\n        schema.job.fillFromImpl(builder.trainModelOnH2ONode());\r\n    return schema;\r\n}"
}, {
	"Path": "water.api.Schema.fillFromImpl",
	"Comment": "fill this schema from the default impl, and then return self.",
	"Method": "S fillFromImpl(S fillFromImpl,I impl,S fillFromImpl,I impl,String[] fieldsToSkip){\r\n    PojoUtils.copyProperties(this, impl, PojoUtils.FieldNaming.ORIGIN_HAS_UNDERSCORES, fieldsToSkip);\r\n    PojoUtils.copyProperties(this, impl, PojoUtils.FieldNaming.CONSISTENT, fieldsToSkip);\r\n    return (S) this;\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.url.UrlResolver.resolveUrl",
	"Comment": "resolves a given relative url against a base url. seerfc1808section 4 for more details.",
	"Method": "String resolveUrl(String baseUrl,String relativeUrl,Url resolveUrl,Url baseUrl,String relativeUrl){\r\n    final Url url = parseUrl(relativeUrl);\r\n    if (baseUrl == null) {\r\n        return url;\r\n    }\r\n    if (relativeUrl.isEmpty()) {\r\n        return new Url(baseUrl);\r\n    }\r\n    if (url.scheme != null) {\r\n        return url;\r\n    }\r\n    url.scheme = baseUrl.scheme;\r\n    if (url.location != null) {\r\n        return url;\r\n    }\r\n    url.location = baseUrl.location;\r\n    if ((url.path != null) && ((!url.path.isEmpty()) && (url.path.charAt(0) == '/'))) {\r\n        url.path = removeLeadingSlashPoints(url.path);\r\n        return url;\r\n    }\r\n    if (url.path == null) {\r\n        url.path = baseUrl.path;\r\n        if (url.parameters != null) {\r\n            return url;\r\n        }\r\n        url.parameters = baseUrl.parameters;\r\n        if (url.query != null) {\r\n            return url;\r\n        }\r\n        url.query = baseUrl.query;\r\n        return url;\r\n    }\r\n    final String basePath = baseUrl.path;\r\n    String path = \"\";\r\n    if (basePath != null) {\r\n        final int lastSlashIndex = basePath.lastIndexOf('/');\r\n        if (lastSlashIndex >= 0) {\r\n            path = basePath.substring(0, lastSlashIndex + 1);\r\n        }\r\n    } else {\r\n        path = \"/\";\r\n    }\r\n    path = path.concat(url.path);\r\n    int pathSegmentIndex;\r\n    while ((pathSegmentIndex = path.indexOf(\"/./\")) >= 0) {\r\n        path = path.substring(0, pathSegmentIndex + 1).concat(path.substring(pathSegmentIndex + 3));\r\n    }\r\n    if (path.endsWith(\"/.\")) {\r\n        path = path.substring(0, path.length() - 1);\r\n    }\r\n    while ((pathSegmentIndex = path.indexOf(\"/../\")) > 0) {\r\n        final String pathSegment = path.substring(0, pathSegmentIndex);\r\n        final int slashIndex = pathSegment.lastIndexOf('/');\r\n        if (slashIndex < 0) {\r\n            continue;\r\n        }\r\n        if (!\"..\".equals(pathSegment.substring(slashIndex))) {\r\n            path = path.substring(0, slashIndex + 1).concat(path.substring(pathSegmentIndex + 4));\r\n        }\r\n    }\r\n    if (path.endsWith(\"/..\")) {\r\n        final String pathSegment = path.substring(0, path.length() - 3);\r\n        final int slashIndex = pathSegment.lastIndexOf('/');\r\n        if (slashIndex >= 0) {\r\n            path = path.substring(0, slashIndex + 1);\r\n        }\r\n    }\r\n    path = removeLeadingSlashPoints(path);\r\n    url.path = path;\r\n    return url;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.scanner.classpath.ClassPathScanner.getLocationUrlsForPath",
	"Comment": "gets the physical location urls for this logical path on the classpath.",
	"Method": "List<URL> getLocationUrlsForPath(Location location){\r\n    if (locationUrlCache.containsKey(location)) {\r\n        return locationUrlCache.get(location);\r\n    }\r\n    LOG.debug(\"Determining location urls for \" + location + \" using ClassLoader \" + classLoader + \" ...\");\r\n    List<URL> locationUrls = new ArrayList();\r\n    if (classLoader.getClass().getName().startsWith(\"com.ibm\")) {\r\n        Enumeration<URL> urls;\r\n        try {\r\n            urls = classLoader.getResources(location.getPath() + \"/flyway.location\");\r\n            if (!urls.hasMoreElements()) {\r\n                LOG.warn(\"Unable to resolve location \" + location + \" (ClassLoader: \" + classLoader + \")\" + \" On WebSphere an empty file named flyway.location must be present on the classpath location for WebSphere to find it!\");\r\n            }\r\n            while (urls.hasMoreElements()) {\r\n                URL url = urls.nextElement();\r\n                locationUrls.add(new URL(URLDecoder.decode(url.toExternalForm(), \"UTF-8\").replace(\"/flyway.location\", \"\")));\r\n            }\r\n        } catch (IOException e) {\r\n            LOG.warn(\"Unable to resolve location \" + location + \" (ClassLoader: \" + classLoader + \")\" + \" On WebSphere an empty file named flyway.location must be present on the classpath location for WebSphere to find it!\");\r\n        }\r\n    } else {\r\n        Enumeration<URL> urls;\r\n        try {\r\n            urls = classLoader.getResources(location.getPath());\r\n            while (urls.hasMoreElements()) {\r\n                locationUrls.add(urls.nextElement());\r\n            }\r\n        } catch (IOException e) {\r\n            LOG.warn(\"Unable to resolve location \" + location + \" (ClassLoader: \" + classLoader + \"): \" + e.getMessage());\r\n        }\r\n    }\r\n    locationUrlCache.put(location, locationUrls);\r\n    return locationUrls;\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.crawler.Page.getFetchResponseHeaders",
	"Comment": "returns headers which were present in the response of the fetch request",
	"Method": "Header[] getFetchResponseHeaders(){\r\n    return fetchResponseHeaders;\r\n}"
}, {
	"Path": "graphql.ExecutionInput.transform",
	"Comment": "this helps you transform the current executioninput object into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "ExecutionInput transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = new Builder().query(this.query).operationName(this.operationName).context(this.context).root(this.root).dataLoaderRegistry(this.dataLoaderRegistry).variables(this.variables);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.jdbc.JdbcTemplate.query",
	"Comment": "executes this query and map the results using this row mapper.",
	"Method": "List<T> query(String query,RowMapper<T> rowMapper){\r\n    Statement statement = null;\r\n    ResultSet resultSet = null;\r\n    List<T> results;\r\n    try {\r\n        statement = connection.createStatement();\r\n        resultSet = statement.executeQuery(query);\r\n        results = new ArrayList();\r\n        while (resultSet.next()) {\r\n            results.add(rowMapper.mapRow(resultSet));\r\n        }\r\n    } finally {\r\n        JdbcUtils.closeResultSet(resultSet);\r\n        JdbcUtils.closeStatement(statement);\r\n    }\r\n    return results;\r\n}"
}, {
	"Path": "water.api.SchemaMetadata.isEnum",
	"Comment": "enum is a field of enum type or of string type with defined and fixed set of values!",
	"Method": "boolean isEnum(Class<?> type,API annotation){\r\n    return Enum.class.isAssignableFrom(type);\r\n}"
}, {
	"Path": "hex.glrm.GLRM.expandCats",
	"Comment": "more efficient implementation assuming sdata cols aligned with adaptedframe",
	"Method": "double[][] expandCats(double[][] sdata,DataInfo dinfo){\r\n    if (sdata == null || dinfo._cats == 0)\r\n        return sdata;\r\n    assert sdata[0].length == dinfo._adaptedFrame.numCols();\r\n    int catsexp = dinfo._catOffsets[dinfo._catOffsets.length - 1];\r\n    double[][] cexp = new double[sdata.length][catsexp + dinfo._nums];\r\n    for (int i = 0; i < sdata.length; i++) LinearAlgebraUtils.expandRow(sdata[i], dinfo, cexp[i], false);\r\n    return cexp;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.jdbc.JdbcTemplate.queryForString",
	"Comment": "executes this query with these parameters against this connection.",
	"Method": "String queryForString(String query,String params){\r\n    PreparedStatement statement = null;\r\n    ResultSet resultSet = null;\r\n    String result;\r\n    try {\r\n        statement = prepareStatement(query, params);\r\n        resultSet = statement.executeQuery();\r\n        result = null;\r\n        if (resultSet.next()) {\r\n            result = resultSet.getString(1);\r\n        }\r\n    } finally {\r\n        JdbcUtils.closeResultSet(resultSet);\r\n        JdbcUtils.closeStatement(statement);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaDirectiveWiring.onEnumValue",
	"Comment": "this is called when an enum value is encountered, which gives the schema directive a chance to modify the shape and behaviourof that dslelement",
	"Method": "GraphQLEnumValueDefinition onEnumValue(SchemaDirectiveWiringEnvironment<GraphQLEnumValueDefinition> environment){\r\n    return environment.getElement();\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.GCDocument.getGCResources",
	"Comment": "returns a list of the gcresources displayed in this document.",
	"Method": "List<GCResource> getGCResources(){\r\n    List<GCResource> gcResourceList = new ArrayList<GCResource>();\r\n    for (ChartPanelView view : chartPanelViews) {\r\n        gcResourceList.add(view.getGCResource());\r\n    }\r\n    return gcResourceList;\r\n}"
}, {
	"Path": "hex.ScoreKeeper.stopEarly",
	"Comment": "based on the given array of scorekeeper and stopping criteria should we stop early?",
	"Method": "boolean stopEarly(ScoreKeeper[] sk,int k,boolean classification,StoppingMetric criterion,double rel_improvement,String what,boolean verbose){\r\n    if (k == 0)\r\n        return false;\r\n    int len = sk.length - 1;\r\n    if (len < 2 * k)\r\n        return false;\r\n    if (criterion == StoppingMetric.AUTO) {\r\n        criterion = classification ? StoppingMetric.logloss : StoppingMetric.deviance;\r\n    }\r\n    boolean moreIsBetter = moreIsBetter(criterion);\r\n    boolean hasLowerBound = hasLowerBound(criterion);\r\n    double[] movingAvg = new double[k + 1];\r\n    double lastBeforeK = moreIsBetter ? -Double.MAX_VALUE : Double.MAX_VALUE;\r\n    double bestInLastK = moreIsBetter ? -Double.MAX_VALUE : Double.MAX_VALUE;\r\n    for (int i = 0; i < movingAvg.length; ++i) {\r\n        movingAvg[i] = 0;\r\n        int startIdx = sk.length - 2 * k + i;\r\n        for (int j = 0; j < k; ++j) {\r\n            ScoreKeeper skj = sk[startIdx + j];\r\n            double val;\r\n            switch(criterion) {\r\n                case AUC:\r\n                    val = skj._AUC;\r\n                    break;\r\n                case MSE:\r\n                    val = skj._mse;\r\n                    break;\r\n                case RMSE:\r\n                    val = skj._rmse;\r\n                    break;\r\n                case MAE:\r\n                    val = skj._mae;\r\n                    break;\r\n                case RMSLE:\r\n                    val = skj._rmsle;\r\n                    break;\r\n                case deviance:\r\n                    val = skj._mean_residual_deviance;\r\n                    break;\r\n                case logloss:\r\n                    val = skj._logloss;\r\n                    break;\r\n                case misclassification:\r\n                    val = skj._classError;\r\n                    break;\r\n                case mean_per_class_error:\r\n                    val = skj._mean_per_class_error;\r\n                    break;\r\n                case lift_top_group:\r\n                    val = skj._lift;\r\n                    break;\r\n                case custom:\r\n                case custom_increasing:\r\n                    val = skj._custom_metric;\r\n                    break;\r\n                default:\r\n                    throw H2O.unimpl(\"Undefined stopping criterion.\");\r\n            }\r\n            movingAvg[i] += val;\r\n        }\r\n        movingAvg[i] /= k;\r\n        if (Double.isNaN(movingAvg[i]))\r\n            return false;\r\n        if (i == 0)\r\n            lastBeforeK = movingAvg[i];\r\n        else\r\n            bestInLastK = moreIsBetter ? Math.max(movingAvg[i], bestInLastK) : Math.min(movingAvg[i], bestInLastK);\r\n    }\r\n    if (Math.signum(ArrayUtils.maxValue(movingAvg)) != Math.signum(ArrayUtils.minValue(movingAvg)))\r\n        return false;\r\n    if (Math.signum(bestInLastK) != Math.signum(lastBeforeK))\r\n        return false;\r\n    assert (lastBeforeK != Double.MAX_VALUE);\r\n    assert (bestInLastK != Double.MAX_VALUE);\r\n    if (verbose)\r\n        Log.info(\"Windowed averages (window size \" + k + \") of \" + what + \" \" + (k + 1) + \" \" + criterion.toString() + \" metrics: \" + Arrays.toString(movingAvg));\r\n    if (lastBeforeK == 0 && !moreIsBetter && hasLowerBound)\r\n        return true;\r\n    double ratio = bestInLastK / lastBeforeK;\r\n    if (Double.isNaN(ratio))\r\n        return false;\r\n    boolean improved = moreIsBetter ? ratio > 1 + rel_improvement : ratio < 1 - rel_improvement;\r\n    if (verbose)\r\n        Log.info(\"Checking convergence with \" + criterion.toString() + \" metric: \" + lastBeforeK + \" --> \" + bestInLastK + (improved ? \" (still improving).\" : \" (converged).\"));\r\n    return !improved;\r\n}"
}, {
	"Path": "graphql.schema.diff.SchemaDiff.diffSchema",
	"Comment": "this will perform a difference on the two schemas.the reporter callbackinterface will be called when differences are encountered.",
	"Method": "int diffSchema(DiffSet diffSet,DifferenceReporter reporter){\r\n    CountingReporter countingReporter = new CountingReporter(reporter);\r\n    diffSchemaImpl(diffSet, countingReporter);\r\n    return countingReporter.breakingCount;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.scanner.filesystem.FileSystemScanner.scanForResources",
	"Comment": "scans the filesystem for resources under the specified location, starting with the specified prefix and ending withthe specified suffix.",
	"Method": "Collection<LoadableResource> scanForResources(Location location){\r\n    String path = location.getPath();\r\n    LOG.debug(\"Scanning for filesystem resources at '\" + path + \"'\");\r\n    File dir = new File(path);\r\n    if (!dir.exists()) {\r\n        LOG.warn(\"Skipping filesystem location:\" + path + \" (not found)\");\r\n        return Collections.emptyList();\r\n    }\r\n    if (!dir.canRead()) {\r\n        LOG.warn(\"Skipping filesystem location:\" + path + \" (not readable)\");\r\n        return Collections.emptyList();\r\n    }\r\n    if (!dir.isDirectory()) {\r\n        LOG.warn(\"Skipping filesystem location:\" + path + \" (not a directory)\");\r\n        return Collections.emptyList();\r\n    }\r\n    Set<LoadableResource> resources = new TreeSet();\r\n    for (String resourceName : findResourceNamesFromFileSystem(path, new File(path))) {\r\n        resources.add(new FileSystemResource(location, resourceName, encoding));\r\n        LOG.debug(\"Found filesystem resource: \" + resourceName);\r\n    }\r\n    return resources;\r\n}"
}, {
	"Path": "hex.ModelBuilder.checkResponseVariable",
	"Comment": "checks response variable attributes and adds errors if response variable is unusable.",
	"Method": "void checkResponseVariable(){\r\n    if (_response != null && (!_response.isNumeric() && !_response.isCategorical() && !_response.isTime())) {\r\n        error(\"_response_column\", \"Use numerical, categorical or time variable. Currently used \" + _response.get_type_str());\r\n    }\r\n}"
}, {
	"Path": "water.fvec.Chunk.byteSize",
	"Comment": "in memory size in bytes of the compressed chunk plus embedded array.",
	"Method": "long byteSize(){\r\n    long s = _mem == null ? 0 : _mem.length;\r\n    s += (2 + 5) * 8 + 12;\r\n    if (_chk2 != null)\r\n        s += _chk2.byteSize();\r\n    return s;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.info.MigrationInfoServiceImpl.outOfOrder",
	"Comment": "retrieves the full set of infos about out of order migrations applied to the db.",
	"Method": "MigrationInfo[] outOfOrder(){\r\n    List<MigrationInfo> outOfOrderMigrations = new ArrayList();\r\n    for (MigrationInfo migrationInfo : migrationInfos) {\r\n        if (migrationInfo.getState() == MigrationState.OUT_OF_ORDER) {\r\n            outOfOrderMigrations.add(migrationInfo);\r\n        }\r\n    }\r\n    return outOfOrderMigrations.toArray(new MigrationInfo[0]);\r\n}"
}, {
	"Path": "com.ramotion.foldingcell.FoldingCell.createAndPrepareFoldingContainer",
	"Comment": "create layout that will be a container for animation elements",
	"Method": "LinearLayout createAndPrepareFoldingContainer(){\r\n    LinearLayout foldingContainer = new LinearLayout(getContext());\r\n    foldingContainer.setClipToPadding(false);\r\n    foldingContainer.setClipChildren(false);\r\n    foldingContainer.setOrientation(LinearLayout.VERTICAL);\r\n    foldingContainer.setLayoutParams(new LinearLayout.LayoutParams(LayoutParams.MATCH_PARENT, LayoutParams.WRAP_CONTENT));\r\n    return foldingContainer;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.derby.DerbySchema.generateDropStatementsForConstraints",
	"Comment": "generate the statements for dropping all the constraints in this schema.",
	"Method": "List<String> generateDropStatementsForConstraints(){\r\n    List<Map<String, String>> results = jdbcTemplate.queryForList(\"SELECT c.constraintname, t.tablename FROM sys.sysconstraints c\" + \" INNER JOIN sys.systables t ON c.tableid = t.tableid\" + \" INNER JOIN sys.sysschemas s ON c.schemaid = s.schemaid\" + \" WHERE c.type = 'F' AND s.schemaname = ?\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (Map<String, String> result : results) {\r\n        String dropStatement = \"ALTER TABLE \" + database.quote(name, result.get(\"TABLENAME\")) + \" DROP CONSTRAINT \" + database.quote(result.get(\"CONSTRAINTNAME\"));\r\n        statements.add(dropStatement);\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.info.MigrationInfoServiceImpl.resolved",
	"Comment": "retrieves the full set of infos about the migrations resolved on the classpath.",
	"Method": "MigrationInfo[] resolved(){\r\n    List<MigrationInfo> resolvedMigrations = new ArrayList();\r\n    for (MigrationInfo migrationInfo : migrationInfos) {\r\n        if (migrationInfo.getState().isResolved()) {\r\n            resolvedMigrations.add(migrationInfo);\r\n        }\r\n    }\r\n    return resolvedMigrations.toArray(new MigrationInfo[0]);\r\n}"
}, {
	"Path": "hex.glrm.GLRM.setWideDataset",
	"Comment": "set value of widedataset.note that this routine is used for test purposes only and not for users.",
	"Method": "void setWideDataset(boolean isWide){\r\n    _wideDataset = isWide;\r\n}"
}, {
	"Path": "ai.h2o.automl.Leaderboard.addModels",
	"Comment": "add the given models to the leaderboard.note that to make this easier to use fromgrid, which returns its models in random order, we allow the caller to add the samemodel multiple times and we eliminate the duplicates here.",
	"Method": "void addModels(Key<Model>[] newModels){\r\n    if (null == this._key)\r\n        throw new H2OIllegalArgumentException(\"Can't add models to a Leaderboard which isn't in the DKV.\");\r\n    if (null == newModels || newModels.length == 0) {\r\n        return;\r\n    }\r\n    if (!this.have_set_sort_metric) {\r\n        setDefaultMetricAndDirection(newModels[0].get());\r\n    }\r\n    final Key<Model>[] newLeader = new Key[1];\r\n    final double[] newLeaderSortMetric = new double[1];\r\n    new TAtomic<Leaderboard>() {\r\n        @Override\r\n        public final Leaderboard atomic(Leaderboard updating) {\r\n            if (updating == null) {\r\n                Log.err(\"trying to update null leaderboard!\");\r\n                throw new H2OIllegalArgumentException(\"Trying to update a null leaderboard.\");\r\n            }\r\n            final Key<Model>[] oldModels = updating.models;\r\n            final Key<Model> oldLeader = (oldModels == null || 0 == oldModels.length) ? null : oldModels[0];\r\n            Set<Key<Model>> uniques = new HashSet(oldModels.length + newModels.length);\r\n            uniques.addAll(Arrays.asList(oldModels));\r\n            uniques.addAll(Arrays.asList(newModels));\r\n            updating.models = uniques.toArray(new Key[0]);\r\n            updating.leaderboard_set_metrics = new IcedHashMap();\r\n            Model aModel = null;\r\n            for (Key<Model> aKey : updating.models) {\r\n                aModel = aKey.get();\r\n                if (null == aModel) {\r\n                    userFeedback.warn(UserFeedbackEvent.Stage.ModelTraining, \"Model in the leaderboard has unexpectedly been deleted from H2O: \" + aKey);\r\n                    continue;\r\n                }\r\n                ModelMetrics mm = null;\r\n                if (leaderboardFrame == null) {\r\n                    mm = aModel._output._cross_validation_metrics;\r\n                } else {\r\n                    mm = ModelMetrics.getFromDKV(aModel, leaderboardFrame);\r\n                    if (mm == null) {\r\n                        aModel.score(leaderboardFrame).delete();\r\n                        mm = ModelMetrics.getFromDKV(aModel, leaderboardFrame);\r\n                    }\r\n                }\r\n                if (mm != null)\r\n                    updating.leaderboard_set_metrics.put(mm._key, mm);\r\n            }\r\n            try {\r\n                List<Key<Model>> modelsSorted = null;\r\n                if (leaderboardFrame == null) {\r\n                    modelsSorted = ModelMetrics.sortModelsByMetric(sort_metric, sort_decreasing, Arrays.asList(updating.models));\r\n                } else {\r\n                    modelsSorted = ModelMetrics.sortModelsByMetric(leaderboardFrame, sort_metric, sort_decreasing, Arrays.asList(updating.models));\r\n                }\r\n                updating.models = modelsSorted.toArray(new Key[0]);\r\n            } catch (H2OIllegalArgumentException e) {\r\n                Log.warn(\"ModelMetrics.sortModelsByMetric failed: \" + e);\r\n                throw e;\r\n            }\r\n            Model[] updating_models = new Model[updating.models.length];\r\n            modelsForModelKeys(updating.models, updating_models);\r\n            updating.sort_metrics = getMetrics(updating.sort_metric, updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n            if (aModel._output.isBinomialClassifier()) {\r\n                updating.auc = getMetrics(\"auc\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.logloss = getMetrics(\"logloss\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.mean_per_class_error = getMetrics(\"mean_per_class_error\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.rmse = getMetrics(\"rmse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.mse = getMetrics(\"mse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n            } else if (aModel._output.isMultinomialClassifier()) {\r\n                updating.mean_per_class_error = getMetrics(\"mean_per_class_error\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.logloss = getMetrics(\"logloss\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.rmse = getMetrics(\"rmse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.mse = getMetrics(\"mse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n            } else {\r\n                updating.mean_residual_deviance = getMetrics(\"mean_residual_deviance\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.rmse = getMetrics(\"rmse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.mse = getMetrics(\"mse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.mae = getMetrics(\"mae\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n                updating.rmsle = getMetrics(\"rmsle\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n            }\r\n            if (oldLeader == null || !oldLeader.equals(updating.models[0])) {\r\n                newLeader[0] = updating.models[0];\r\n                newLeaderSortMetric[0] = updating.sort_metrics[0];\r\n            }\r\n            return updating;\r\n        }\r\n    }.invoke(this._key);\r\n    Leaderboard updated = DKV.getGet(this._key);\r\n    this.models = updated.models;\r\n    this.leaderboard_set_metrics = updated.leaderboard_set_metrics;\r\n    this.sort_metrics = updated.sort_metrics;\r\n    if (updated.getLeader()._output.isBinomialClassifier()) {\r\n        this.auc = updated.auc;\r\n        this.logloss = updated.logloss;\r\n        this.mean_per_class_error = updated.mean_per_class_error;\r\n        this.rmse = updated.rmse;\r\n        this.mse = updated.mse;\r\n    } else if (updated.getLeader()._output.isMultinomialClassifier()) {\r\n        this.mean_per_class_error = updated.mean_per_class_error;\r\n        this.logloss = updated.logloss;\r\n        this.rmse = updated.rmse;\r\n        this.mse = updated.mse;\r\n    } else {\r\n        this.mean_residual_deviance = updated.mean_residual_deviance;\r\n        this.rmse = updated.rmse;\r\n        this.mse = updated.mse;\r\n        this.mae = updated.mae;\r\n        this.rmsle = updated.rmsle;\r\n    }\r\n    if (null != newLeader[0]) {\r\n        userFeedback.info(UserFeedbackEvent.Stage.ModelTraining, \"New leader: \" + newLeader[0] + \", \" + sort_metric + \": \" + newLeaderSortMetric[0]);\r\n    }\r\n}"
}, {
	"Path": "ai.h2o.automl.Leaderboard.addModels",
	"Comment": "add the given models to the leaderboard.note that to make this easier to use fromgrid, which returns its models in random order, we allow the caller to add the samemodel multiple times and we eliminate the duplicates here.",
	"Method": "void addModels(Key<Model>[] newModels){\r\n    if (updating == null) {\r\n        Log.err(\"trying to update null leaderboard!\");\r\n        throw new H2OIllegalArgumentException(\"Trying to update a null leaderboard.\");\r\n    }\r\n    final Key<Model>[] oldModels = updating.models;\r\n    final Key<Model> oldLeader = (oldModels == null || 0 == oldModels.length) ? null : oldModels[0];\r\n    Set<Key<Model>> uniques = new HashSet(oldModels.length + newModels.length);\r\n    uniques.addAll(Arrays.asList(oldModels));\r\n    uniques.addAll(Arrays.asList(newModels));\r\n    updating.models = uniques.toArray(new Key[0]);\r\n    updating.leaderboard_set_metrics = new IcedHashMap();\r\n    Model aModel = null;\r\n    for (Key<Model> aKey : updating.models) {\r\n        aModel = aKey.get();\r\n        if (null == aModel) {\r\n            userFeedback.warn(UserFeedbackEvent.Stage.ModelTraining, \"Model in the leaderboard has unexpectedly been deleted from H2O: \" + aKey);\r\n            continue;\r\n        }\r\n        ModelMetrics mm = null;\r\n        if (leaderboardFrame == null) {\r\n            mm = aModel._output._cross_validation_metrics;\r\n        } else {\r\n            mm = ModelMetrics.getFromDKV(aModel, leaderboardFrame);\r\n            if (mm == null) {\r\n                aModel.score(leaderboardFrame).delete();\r\n                mm = ModelMetrics.getFromDKV(aModel, leaderboardFrame);\r\n            }\r\n        }\r\n        if (mm != null)\r\n            updating.leaderboard_set_metrics.put(mm._key, mm);\r\n    }\r\n    try {\r\n        List<Key<Model>> modelsSorted = null;\r\n        if (leaderboardFrame == null) {\r\n            modelsSorted = ModelMetrics.sortModelsByMetric(sort_metric, sort_decreasing, Arrays.asList(updating.models));\r\n        } else {\r\n            modelsSorted = ModelMetrics.sortModelsByMetric(leaderboardFrame, sort_metric, sort_decreasing, Arrays.asList(updating.models));\r\n        }\r\n        updating.models = modelsSorted.toArray(new Key[0]);\r\n    } catch (H2OIllegalArgumentException e) {\r\n        Log.warn(\"ModelMetrics.sortModelsByMetric failed: \" + e);\r\n        throw e;\r\n    }\r\n    Model[] updating_models = new Model[updating.models.length];\r\n    modelsForModelKeys(updating.models, updating_models);\r\n    updating.sort_metrics = getMetrics(updating.sort_metric, updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n    if (aModel._output.isBinomialClassifier()) {\r\n        updating.auc = getMetrics(\"auc\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.logloss = getMetrics(\"logloss\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.mean_per_class_error = getMetrics(\"mean_per_class_error\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.rmse = getMetrics(\"rmse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.mse = getMetrics(\"mse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n    } else if (aModel._output.isMultinomialClassifier()) {\r\n        updating.mean_per_class_error = getMetrics(\"mean_per_class_error\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.logloss = getMetrics(\"logloss\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.rmse = getMetrics(\"rmse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.mse = getMetrics(\"mse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n    } else {\r\n        updating.mean_residual_deviance = getMetrics(\"mean_residual_deviance\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.rmse = getMetrics(\"rmse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.mse = getMetrics(\"mse\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.mae = getMetrics(\"mae\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n        updating.rmsle = getMetrics(\"rmsle\", updating.leaderboard_set_metrics, leaderboardFrame, updating_models);\r\n    }\r\n    if (oldLeader == null || !oldLeader.equals(updating.models[0])) {\r\n        newLeader[0] = updating.models[0];\r\n        newLeaderSortMetric[0] = updating.sort_metrics[0];\r\n    }\r\n    return updating;\r\n}"
}, {
	"Path": "hex.grid.GridSearch.startGridSearch",
	"Comment": "start a new grid search job.this method launches any grid search traversing space of hyperparameters based on specified strategy.",
	"Method": "Job<Grid> startGridSearch(Key<Grid> destKey,MP params,Map<String, Object[]> hyperParams,ModelParametersBuilderFactory<MP> paramsBuilderFactory,HyperSpaceSearchCriteria searchCriteria,Job<Grid> startGridSearch,Key<Grid> destKey,MP params,Map<String, Object[]> hyperParams,Job<Grid> startGridSearch,Key<Grid> destKey,HyperSpaceWalker<MP, ?> hyperSpaceWalker){\r\n    MP params = hyperSpaceWalker.getParams();\r\n    Key<Grid> gridKey = destKey != null ? destKey : gridKeyName(params.algoName(), params.train());\r\n    return new GridSearch(gridKey, hyperSpaceWalker).start();\r\n}"
}, {
	"Path": "graphql.language.AstPrinter.printAstCompact",
	"Comment": "this will print the ast node in graphql language format.the format is derived from the pretty print version by replacingall newlines and indentations through single space.",
	"Method": "String printAstCompact(Node node){\r\n    StringWriter sw = new StringWriter();\r\n    printAst(sw, node);\r\n    return sw.toString().replaceAll(\"\\\\s+\", \" \").trim();\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlusBuilder.setGravity",
	"Comment": "set the gravity you want the dialog to have among the ones that are provided",
	"Method": "DialogPlusBuilder setGravity(int gravity){\r\n    this.gravity = gravity;\r\n    params.gravity = gravity;\r\n    return this;\r\n}"
}, {
	"Path": "org.flywaydb.maven.AbstractFlywayMojo.getProperty",
	"Comment": "retrieves this property from either the system or the maven properties.",
	"Method": "String getProperty(String name){\r\n    String systemProperty = System.getProperty(name);\r\n    if (systemProperty != null) {\r\n        return systemProperty;\r\n    }\r\n    return mavenProject.getProperties().getProperty(name);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.schemahistory.SchemaHistory.getBaselineMarker",
	"Comment": "retrieves the baseline marker from the schema history table.",
	"Method": "AppliedMigration getBaselineMarker(){\r\n    List<AppliedMigration> appliedMigrations = allAppliedMigrations();\r\n    for (int i = 0; i < Math.min(appliedMigrations.size(), 2); i++) {\r\n        AppliedMigration appliedMigration = appliedMigrations.get(i);\r\n        if (appliedMigration.getType() == MigrationType.BASELINE) {\r\n            return appliedMigration;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "water.nbhm.ConcurrentAutoTable.internal_size",
	"Comment": "return the internal counter striping factor.useful for diagnosingperformance problems.",
	"Method": "int internal_size(){\r\n    return _cat._t.length;\r\n}"
}, {
	"Path": "com.google.errorprone.util.FindIdentifiers.findAllFields",
	"Comment": "finds all the visible fields declared or inherited in the target class",
	"Method": "List<VarSymbol> findAllFields(Type classType,VisitorState state){\r\n    return state.getTypes().closure(classType).stream().flatMap(type -> {\r\n        TypeSymbol tsym = type.tsym;\r\n        if (tsym == null) {\r\n            return ImmutableList.<VarSymbol>of().stream();\r\n        }\r\n        WriteableScope scope = tsym.members();\r\n        if (scope == null) {\r\n            return ImmutableList.<VarSymbol>of().stream();\r\n        }\r\n        return ImmutableList.copyOf(scope.getSymbols(VarSymbol.class::isInstance)).reverse().stream().map(v -> (VarSymbol) v).filter(v -> isVisible(v, state.getPath()));\r\n    }).collect(Collectors.toCollection(ArrayList::new));\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.saphana.SAPHANASchema.generateDropStatements",
	"Comment": "generates drop statements for this type of object in this schema.",
	"Method": "List<String> generateDropStatements(String objectType){\r\n    List<String> dropStatements = new ArrayList();\r\n    List<String> dbObjects = getDbObjects(objectType);\r\n    for (String dbObject : dbObjects) {\r\n        dropStatements.add(\"DROP \" + objectType + \" \" + database.quote(name, dbObject) + \" CASCADE\");\r\n    }\r\n    return dropStatements;\r\n}"
}, {
	"Path": "water.nbhm.NonBlockingSetInt.size",
	"Comment": "current count of elements in the set.due to concurrent racing updates,the size is only ever approximate.updates due to the calling thread areimmediately visible to calling thread.",
	"Method": "int size(int size){\r\n    return _nbsi.size();\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.schemahistory.SchemaHistory.calculateInstalledRank",
	"Comment": "calculates the installed rank for the new migration to be inserted.",
	"Method": "int calculateInstalledRank(){\r\n    List<AppliedMigration> appliedMigrations = allAppliedMigrations();\r\n    if (appliedMigrations.isEmpty()) {\r\n        return 1;\r\n    }\r\n    return appliedMigrations.get(appliedMigrations.size() - 1).getInstalledRank() + 1;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.SqlStatementBuilder.extractStringLiteralDelimitingTokens",
	"Comment": "extract the type of all tokens that potentially delimit string literals.",
	"Method": "List<TokenType> extractStringLiteralDelimitingTokens(Collection<String> tokens){\r\n    List<TokenType> delimitingTokens = new ArrayList();\r\n    for (String token : tokens) {\r\n        String cleanToken = cleanToken(token);\r\n        boolean handled = false;\r\n        if (alternateQuote == null) {\r\n            String alternateQuoteFromToken = extractAlternateOpenQuote(cleanToken);\r\n            if (alternateQuoteFromToken != null) {\r\n                String closeQuote = computeAlternateCloseQuote(alternateQuoteFromToken);\r\n                if (cleanToken.length() >= (alternateQuoteFromToken.length() + closeQuote.length()) && cleanToken.startsWith(alternateQuoteFromToken) && cleanToken.endsWith(closeQuote)) {\r\n                    continue;\r\n                }\r\n                alternateQuote = closeQuote;\r\n                delimitingTokens.add(TokenType.ALTERNATE_QUOTE);\r\n                continue;\r\n            }\r\n        }\r\n        if ((alternateQuote != null) && cleanToken.endsWith(alternateQuote)) {\r\n            alternateQuote = null;\r\n            delimitingTokens.add(TokenType.ALTERNATE_QUOTE);\r\n            continue;\r\n        }\r\n        if ((cleanToken.length() >= 2) && cleanToken.startsWith(\"'\") && cleanToken.endsWith(\"'\")) {\r\n            continue;\r\n        }\r\n        if ((cleanToken.length() >= 4)) {\r\n            int numberOfOpeningMultiLineComments = StringUtils.countOccurrencesOf(cleanToken, \"/*\");\r\n            int numberOfClosingMultiLineComments = StringUtils.countOccurrencesOf(cleanToken, \"*/\");\r\n            if (numberOfOpeningMultiLineComments > 0 && numberOfOpeningMultiLineComments == numberOfClosingMultiLineComments) {\r\n                continue;\r\n            }\r\n        }\r\n        if (isSingleLineComment(cleanToken)) {\r\n            delimitingTokens.add(TokenType.SINGLE_LINE_COMMENT);\r\n            handled = true;\r\n        }\r\n        if (cleanToken.contains(\"/*\")) {\r\n            delimitingTokens.add(TokenType.MULTI_LINE_COMMENT_OPEN);\r\n            handled = true;\r\n        } else if (cleanToken.startsWith(\"'\")) {\r\n            delimitingTokens.add(TokenType.QUOTE);\r\n            handled = true;\r\n        }\r\n        if (!cleanToken.contains(\"/*\") && cleanToken.contains(\"*/\")) {\r\n            delimitingTokens.add(TokenType.MULTI_LINE_COMMENT_CLOSE);\r\n            handled = true;\r\n        } else if (!cleanToken.startsWith(\"'\") && cleanToken.endsWith(\"'\")) {\r\n            delimitingTokens.add(TokenType.QUOTE);\r\n            handled = true;\r\n        }\r\n        if (!handled) {\r\n            if (isBlockBeginToken(cleanToken)) {\r\n                delimitingTokens.add(TokenType.BLOCK_BEGIN);\r\n            } else if (isBlockEndToken(cleanToken)) {\r\n                delimitingTokens.add(TokenType.BLOCK_END);\r\n            } else {\r\n                delimitingTokens.add(TokenType.OTHER);\r\n            }\r\n        }\r\n    }\r\n    return delimitingTokens;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.assignment",
	"Comment": "matches an assignment operator ast node if both of the given matchers match.",
	"Method": "Matcher<AssignmentTree> assignment(Matcher<ExpressionTree> variableMatcher,Matcher<? super ExpressionTree> expressionMatcher){\r\n    return new Matcher<AssignmentTree>() {\r\n        @Override\r\n        public boolean matches(AssignmentTree t, VisitorState state) {\r\n            return variableMatcher.matches(t.getVariable(), state) && expressionMatcher.matches(t.getExpression(), state);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.assignment",
	"Comment": "matches an assignment operator ast node if both of the given matchers match.",
	"Method": "Matcher<AssignmentTree> assignment(Matcher<ExpressionTree> variableMatcher,Matcher<? super ExpressionTree> expressionMatcher){\r\n    return variableMatcher.matches(t.getVariable(), state) && expressionMatcher.matches(t.getExpression(), state);\r\n}"
}, {
	"Path": "hex.word2vec.Word2VecModel.transform",
	"Comment": "takes an input string can return the word vector for that word.",
	"Method": "float[] transform(String target,float[] transform,BufferedString word,Frame transform,Vec wordVec,AggregateMethod aggregateMethod){\r\n    if (wordVec.get_type() != Vec.T_STR) {\r\n        throw new IllegalArgumentException(\"Expected a string vector, got \" + wordVec.get_type_str() + \" vector.\");\r\n    }\r\n    byte[] types = new byte[_output._vecSize];\r\n    Arrays.fill(types, Vec.T_NUM);\r\n    MRTask<?> transformTask = aggregateMethod == AggregateMethod.AVERAGE ? new Word2VecAggregateTask(this) : new Word2VecTransformTask(this);\r\n    return transformTask.doAll(types, wordVec).outputFrame(Key.<Frame>make(), null, null);\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.DataReaderIBMi5OS1_4_2.parseInitialHeap",
	"Comment": "parses the line which holds the initial heap size. the sizeis returned as int.",
	"Method": "int parseInitialHeap(String line){\r\n    final int start = line.indexOf(\"initial heap(KB) \") + 17;\r\n    final int end = line.indexOf(';', start);\r\n    return Integer.parseInt(line.substring(start, end));\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.AbstractToString.descriptionMessageForDefaultMatch",
	"Comment": "adds the description message for match on the type without fixes.",
	"Method": "Optional<String> descriptionMessageForDefaultMatch(Type type,VisitorState state){\r\n    return Optional.absent();\r\n}"
}, {
	"Path": "water.parser.DecryptionTool.make",
	"Comment": "instantiates a decryption tool using a given decryption setup and installs it in dkv.",
	"Method": "DecryptionTool make(DecryptionSetup ds){\r\n    if (ds._decrypt_tool_id == null)\r\n        ds._decrypt_tool_id = Key.make();\r\n    try {\r\n        Class<?> dtClass = DecryptionTool.class.getClassLoader().loadClass(ds._decrypt_impl);\r\n        if (!DecryptionTool.class.isAssignableFrom(dtClass)) {\r\n            throw new IllegalArgumentException(\"Class \" + ds._decrypt_impl + \" doesn't implement a Decryption Tool.\");\r\n        }\r\n        Constructor<?> constructor = dtClass.getConstructor(DecryptionSetup.class);\r\n        DecryptionTool dt = (DecryptionTool) constructor.newInstance(ds);\r\n        DKV.put(dt);\r\n        return dt;\r\n    } catch (ClassNotFoundException e) {\r\n        throw new RuntimeException(\"Unknown decrypt tool: \" + ds._decrypt_impl, e);\r\n    } catch (NoSuchMethodException e) {\r\n        throw new RuntimeException(\"Invalid implementation of Decryption Tool (missing constructor).\", e);\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.argumentselectiondefects.CreatesDuplicateCallHeuristic.anyArgumentsMatch",
	"Comment": "return true if the replacement name is equal to the argument name for any replacement position.",
	"Method": "boolean anyArgumentsMatch(List<ParameterPair> changedPairs,List<Parameter> arguments){\r\n    return changedPairs.stream().anyMatch(change -> Objects.equals(change.actual().text(), arguments.get(change.formal().index()).text()));\r\n}"
}, {
	"Path": "feign.Request.body",
	"Comment": "if present, this is the replayable body to send to the server. in some cases, this may beinterpretable as text.",
	"Method": "byte[] body(){\r\n    return body.data;\r\n}"
}, {
	"Path": "graphql.schema.GraphQLFieldDefinition.transform",
	"Comment": "this helps you transform the current graphqlfielddefinition into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLFieldDefinition transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newFieldDefinition(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.JdkObsolete.implementingObsoleteMethod",
	"Comment": "allow creating obsolete types when overriding a method with an obsolete return type.",
	"Method": "boolean implementingObsoleteMethod(MethodTree enclosingMethod,VisitorState state,Type type){\r\n    MethodSymbol method = ASTHelpers.getSymbol(enclosingMethod);\r\n    if (method == null) {\r\n        return false;\r\n    }\r\n    if (ASTHelpers.findSuperMethods(method, state.getTypes()).isEmpty()) {\r\n        return false;\r\n    }\r\n    if (!ASTHelpers.isSameType(method.getReturnType(), type, state)) {\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.hsqldb.HSQLDBSchema.generateDropStatementsForSequences",
	"Comment": "generates the statements to drop the sequences in this schema.",
	"Method": "List<String> generateDropStatementsForSequences(){\r\n    List<String> sequenceNames = jdbcTemplate.queryForStringList(\"SELECT SEQUENCE_NAME FROM INFORMATION_SCHEMA.SYSTEM_SEQUENCES where SEQUENCE_SCHEMA = ?\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (String seqName : sequenceNames) {\r\n        statements.add(\"DROP SEQUENCE \" + database.quote(name, seqName));\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "water.parser.ParseTime.parseToBuilder",
	"Comment": "parses the given pattern and appends the rules to the givendatetimeformatterbuilder. see strptime man page for valid patterns.",
	"Method": "void parseToBuilder(DateTimeFormatterBuilder builder,String pattern){\r\n    int length = pattern.length();\r\n    int[] indexRef = new int[1];\r\n    for (int i = 0; i < length; i++) {\r\n        indexRef[0] = i;\r\n        String token = parseToken(pattern, indexRef);\r\n        i = indexRef[0];\r\n        int tokenLen = token.length();\r\n        if (tokenLen == 0) {\r\n            break;\r\n        }\r\n        char c = token.charAt(0);\r\n        if (c == '%' && token.charAt(1) != '%') {\r\n            c = token.charAt(1);\r\n            switch(c) {\r\n                case 'a':\r\n                    builder.appendDayOfWeekShortText();\r\n                    break;\r\n                case 'A':\r\n                    builder.appendDayOfWeekText();\r\n                    break;\r\n                case 'b':\r\n                case 'h':\r\n                    builder.appendMonthOfYearShortText();\r\n                    break;\r\n                case 'B':\r\n                    builder.appendMonthOfYearText();\r\n                    break;\r\n                case 'c':\r\n                    builder.appendDayOfWeekShortText();\r\n                    builder.appendLiteral(' ');\r\n                    builder.appendMonthOfYearShortText();\r\n                    builder.appendLiteral(' ');\r\n                    builder.appendDayOfMonth(2);\r\n                    builder.appendLiteral(' ');\r\n                    builder.appendHourOfDay(2);\r\n                    builder.appendLiteral(':');\r\n                    builder.appendMinuteOfHour(2);\r\n                    builder.appendLiteral(':');\r\n                    builder.appendSecondOfMinute(2);\r\n                    builder.appendLiteral(' ');\r\n                    builder.appendYear(4, 4);\r\n                    break;\r\n                case 'C':\r\n                    builder.appendCenturyOfEra(1, 2);\r\n                    break;\r\n                case 'd':\r\n                    builder.appendDayOfMonth(2);\r\n                    break;\r\n                case 'D':\r\n                    builder.appendMonthOfYear(2);\r\n                    builder.appendLiteral('/');\r\n                    builder.appendDayOfMonth(2);\r\n                    builder.appendLiteral('/');\r\n                    builder.appendTwoDigitYear(2019);\r\n                    break;\r\n                case 'e':\r\n                    builder.appendOptional(DateTimeFormat.forPattern(\"' '\").getParser());\r\n                    builder.appendDayOfMonth(2);\r\n                    break;\r\n                case 'F':\r\n                    builder.appendYear(4, 4);\r\n                    builder.appendLiteral('-');\r\n                    builder.appendMonthOfYear(2);\r\n                    builder.appendLiteral('-');\r\n                    builder.appendDayOfMonth(2);\r\n                    break;\r\n                case 'g':\r\n                case 'G':\r\n                    break;\r\n                case 'H':\r\n                    builder.appendHourOfDay(2);\r\n                    break;\r\n                case 'I':\r\n                    builder.appendClockhourOfHalfday(2);\r\n                    break;\r\n                case 'j':\r\n                    builder.appendDayOfYear(3);\r\n                    break;\r\n                case 'k':\r\n                    builder.appendOptional(DateTimeFormat.forPattern(\"' '\").getParser());\r\n                    builder.appendHourOfDay(2);\r\n                    break;\r\n                case 'l':\r\n                    builder.appendOptional(DateTimeFormat.forPattern(\"' '\").getParser());\r\n                    builder.appendClockhourOfHalfday(2);\r\n                    break;\r\n                case 'm':\r\n                    builder.appendMonthOfYear(2);\r\n                    break;\r\n                case 'M':\r\n                    builder.appendMinuteOfHour(2);\r\n                    break;\r\n                case 'n':\r\n                    break;\r\n                case 'p':\r\n                    builder.appendHalfdayOfDayText();\r\n                    break;\r\n                case 'r':\r\n                    builder.appendClockhourOfHalfday(2);\r\n                    builder.appendLiteral(':');\r\n                    builder.appendMinuteOfHour(2);\r\n                    builder.appendLiteral(':');\r\n                    builder.appendSecondOfMinute(2);\r\n                    builder.appendLiteral(' ');\r\n                    builder.appendHalfdayOfDayText();\r\n                    break;\r\n                case 'R':\r\n                    builder.appendHourOfDay(2);\r\n                    builder.appendLiteral(':');\r\n                    builder.appendMinuteOfHour(2);\r\n                    break;\r\n                case 'S':\r\n                    builder.appendSecondOfMinute(2);\r\n                    break;\r\n                case 't':\r\n                    break;\r\n                case 'T':\r\n                    builder.appendHourOfDay(2);\r\n                    builder.appendLiteral(':');\r\n                    builder.appendMinuteOfHour(2);\r\n                    builder.appendLiteral(':');\r\n                    builder.appendSecondOfMinute(2);\r\n                    break;\r\n                case 'V':\r\n                    break;\r\n                case 'x':\r\n                    builder.appendTwoDigitYear(2019);\r\n                    builder.appendLiteral('/');\r\n                    builder.appendMonthOfYear(2);\r\n                    builder.appendLiteral('/');\r\n                    builder.appendDayOfMonth(2);\r\n                    break;\r\n                case 'y':\r\n                    builder.appendTwoDigitYear(2019);\r\n                    break;\r\n                case 'Y':\r\n                    builder.appendYear(4, 4);\r\n                    break;\r\n                case 'z':\r\n                    builder.appendTimeZoneOffset(null, \"z\", false, 2, 2);\r\n                    break;\r\n                case 'Z':\r\n                    break;\r\n                default:\r\n                    builder.appendLiteral('\\'');\r\n                    builder.appendLiteral(token);\r\n                    Log.warn(token + \"is not acceptted as a parse token, treating as a literal\");\r\n            }\r\n        } else {\r\n            if (c == '\\'') {\r\n                String sub = token.substring(1);\r\n                if (sub.length() > 0) {\r\n                    builder.appendLiteral(new String(sub));\r\n                }\r\n            } else\r\n                throw new IllegalArgumentException(\"Unexpected token encountered parsing format string:\" + c);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "graphql.schema.GraphQLTypeUtil.isLeaf",
	"Comment": "returns true if the given type is a leaf type, that it cant contain any more fields",
	"Method": "boolean isLeaf(GraphQLType type){\r\n    GraphQLUnmodifiedType unmodifiedType = unwrapAll(type);\r\n    return unmodifiedType instanceof GraphQLScalarType || unmodifiedType instanceof GraphQLEnumType;\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.hasAnnotation",
	"Comment": "check for the presence of an annotation, considering annotation inheritance.",
	"Method": "boolean hasAnnotation(Symbol sym,String annotationClass,VisitorState state,boolean hasAnnotation,Symbol sym,Class<? extends Annotation> annotationClass,VisitorState state,boolean hasAnnotation,Tree tree,String annotationClass,VisitorState state,boolean hasAnnotation,Tree tree,Class<? extends Annotation> annotationClass,VisitorState state){\r\n    return hasAnnotation(tree, annotationClass.getName(), state);\r\n}"
}, {
	"Path": "hex.tree.isofor.IsolationForestModel.score0",
	"Comment": "bulk scoring api for one row.chunks are all compatible with the model, and expect the last chunks are for the final distribution and prediction. default method is to just load the data into the tmp array, then call subclass scoring logic.",
	"Method": "double[] score0(double[] data,double[] preds,double offset,int ntrees){\r\n    super.score0(data, preds, offset, ntrees);\r\n    if (ntrees >= 1)\r\n        preds[1] = preds[0] / ntrees;\r\n    preds[0] = normalizePathLength(preds[0]);\r\n    return preds;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.schemahistory.SchemaHistory.addSchemasMarker",
	"Comment": "indicates in the schema history table that flyway created these schemas.",
	"Method": "void addSchemasMarker(Schema[] schemas){\r\n    addAppliedMigration(null, \"<< Flyway Schema Creation >>\", MigrationType.SCHEMA, StringUtils.arrayToCommaDelimitedString(schemas), null, 0, true);\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.url.UrlResolver.indexOf",
	"Comment": "returns the index within the specified string of the first occurrence ofthe specified search character.",
	"Method": "int indexOf(String s,char searchChar,int beginIndex,int endIndex){\r\n    for (int i = beginIndex; i < endIndex; i++) {\r\n        if (s.charAt(i) == searchChar) {\r\n            return i;\r\n        }\r\n    }\r\n    return -1;\r\n}"
}, {
	"Path": "hex.schemas.ModelBuilderSchema.createImpl",
	"Comment": "create the corresponding impl object, as well as its parameters object.",
	"Method": "B createImpl(){\r\n    return ModelBuilder.make(getSchemaType(), null, null);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.StringUtils.wordWrap",
	"Comment": "wrap this string at the word boundary at or below linesize characters.",
	"Method": "String wordWrap(String str,int lineSize){\r\n    if (str.length() < lineSize) {\r\n        return str;\r\n    }\r\n    StringBuilder result = new StringBuilder();\r\n    int oldPos = 0;\r\n    int pos = lineSize;\r\n    while (pos < str.length()) {\r\n        if (Character.isWhitespace(str.charAt(pos))) {\r\n            pos++;\r\n            continue;\r\n        }\r\n        String part = str.substring(oldPos, pos);\r\n        int spacePos = part.lastIndexOf(' ');\r\n        if (spacePos > 0) {\r\n            pos = spacePos + 1;\r\n        }\r\n        result.append(str.substring(oldPos, pos).trim()).append(\"\\n\");\r\n        oldPos = pos;\r\n        pos += lineSize;\r\n    }\r\n    result.append(str.substring(oldPos));\r\n    return result.toString();\r\n}"
}, {
	"Path": "jsr166y.ConcurrentLinkedDeque.updateHead",
	"Comment": "guarantees that any node which was unlinked before a call tothis method will be unreachable from head after it returns.does not guarantee to eliminate slack, only that head willpoint to a node that was active while this method was running.",
	"Method": "void updateHead(){\r\n    Node<E> h, p, q;\r\n    restartFromHead: while ((h = head).item == null && (p = h.prev) != null) {\r\n        for (; ; ) {\r\n            if ((q = p.prev) == null || (q = (p = q).prev) == null) {\r\n                if (casHead(h, p))\r\n                    return;\r\n                else\r\n                    continue restartFromHead;\r\n            } else if (h != head)\r\n                continue restartFromHead;\r\n            else\r\n                p = q;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "jsr166y.ConcurrentLinkedDeque.pred",
	"Comment": "returns the predecessor of p, or the last node if p.prev has beenlinked to self, which will only be true if traversing with astale pointer that is now off the list.",
	"Method": "Node<E> pred(Node<E> p){\r\n    Node<E> q = p.prev;\r\n    return (p == q) ? last() : q;\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.cleanDisabled",
	"Comment": "whether to disable clean.this is especially useful for production environments where running clean can be quite a career limiting move.",
	"Method": "FluentConfiguration cleanDisabled(boolean cleanDisabled){\r\n    config.setCleanDisabled(cleanDisabled);\r\n    return this;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.jdbc.JdbcTemplate.queryForList",
	"Comment": "executes this query with these parameters against this connection.",
	"Method": "List<Map<String, String>> queryForList(String query,Object params){\r\n    PreparedStatement statement = null;\r\n    ResultSet resultSet = null;\r\n    List<Map<String, String>> result;\r\n    try {\r\n        statement = prepareStatement(query, params);\r\n        resultSet = statement.executeQuery();\r\n        result = new ArrayList();\r\n        while (resultSet.next()) {\r\n            Map<String, String> rowMap = new LinkedHashMap();\r\n            for (int i = 1; i <= resultSet.getMetaData().getColumnCount(); i++) {\r\n                rowMap.put(resultSet.getMetaData().getColumnLabel(i), resultSet.getString(i));\r\n            }\r\n            result.add(rowMap);\r\n        }\r\n    } finally {\r\n        JdbcUtils.closeResultSet(resultSet);\r\n        JdbcUtils.closeStatement(statement);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.jdbc.JdbcTemplate.queryForInt",
	"Comment": "executes this query with these parameters against this connection.",
	"Method": "int queryForInt(String query,String params){\r\n    PreparedStatement statement = null;\r\n    ResultSet resultSet = null;\r\n    int result;\r\n    try {\r\n        statement = prepareStatement(query, params);\r\n        resultSet = statement.executeQuery();\r\n        resultSet.next();\r\n        result = resultSet.getInt(1);\r\n    } finally {\r\n        JdbcUtils.closeResultSet(resultSet);\r\n        JdbcUtils.closeStatement(statement);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.sybasease.SybaseASETable.toString",
	"Comment": "since sybase ase does not support schema, dropping out the schema name for tostring method",
	"Method": "String toString(){\r\n    return name;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.GCDocument.getChartPanelView",
	"Comment": "returns the chartpanelview that displays gcresource. if none is found, thereturn value is null.",
	"Method": "ChartPanelView getChartPanelView(int i,ChartPanelView getChartPanelView,GCResource gcResource){\r\n    for (ChartPanelView view : chartPanelViews) {\r\n        if (view.getGCResource().equals(gcResource)) {\r\n            return view;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "graphql.execution.instrumentation.Instrumentation.instrumentExecutionResult",
	"Comment": "this is called to allow instrumentation to instrument the execution result in some way",
	"Method": "CompletableFuture<ExecutionResult> instrumentExecutionResult(ExecutionResult executionResult,InstrumentationExecutionParameters parameters){\r\n    return CompletableFuture.completedFuture(executionResult);\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.annotations",
	"Comment": "matches if the given annotation matcher matches all of or any of the annotations on this treenode.",
	"Method": "MultiMatcher<T, AnnotationTree> annotations(MatchType matchType,Matcher<AnnotationTree> annotationMatcher){\r\n    return new AnnotationMatcher(matchType, annotationMatcher);\r\n}"
}, {
	"Path": "com.google.errorprone.refaster.ExpressionTemplate.match",
	"Comment": "returns the matches of this template against the specified target ast.",
	"Method": "Iterable<ExpressionTemplateMatch> match(JCTree target,Context context){\r\n    if (target instanceof JCExpression) {\r\n        JCExpression targetExpr = (JCExpression) target;\r\n        Optional<Unifier> unifier = unify(targetExpr, new Unifier(context)).first();\r\n        if (unifier.isPresent()) {\r\n            return ImmutableList.of(new ExpressionTemplateMatch(targetExpr, unifier.get()));\r\n        }\r\n    }\r\n    return ImmutableList.of();\r\n}"
}, {
	"Path": "jsr166y.LinkedTransferQueue.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    try {\r\n        return sun.misc.Unsafe.getUnsafe();\r\n    } catch (SecurityException se) {\r\n        try {\r\n            return java.security.AccessController.doPrivileged(new java.security.PrivilegedExceptionAction<sun.misc.Unsafe>() {\r\n                public sun.misc.Unsafe run() throws Exception {\r\n                    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n                    f.setAccessible(true);\r\n                    return (sun.misc.Unsafe) f.get(null);\r\n                }\r\n            });\r\n        } catch (java.security.PrivilegedActionException e) {\r\n            throw new RuntimeException(\"Could not initialize intrinsics\", e.getCause());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "jsr166y.LinkedTransferQueue.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n    f.setAccessible(true);\r\n    return (sun.misc.Unsafe) f.get(null);\r\n}"
}, {
	"Path": "graphql.schema.GraphQLEnumValueDefinition.transform",
	"Comment": "this helps you transform the current graphqlenumvaluedefinition into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLEnumValueDefinition transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newEnumValueDefinition(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.JUnitMatchers.hasJUnitAnnotation",
	"Comment": "checks if a method, or any overridden method, is annotated with any annotation from theorg.junit package.",
	"Method": "boolean hasJUnitAnnotation(MethodTree tree,VisitorState state){\r\n    MethodSymbol methodSym = getSymbol(tree);\r\n    if (methodSym == null) {\r\n        return false;\r\n    }\r\n    if (hasJUnitAttr(methodSym)) {\r\n        return true;\r\n    }\r\n    return findSuperMethods(methodSym, state.getTypes()).stream().anyMatch(JUnitMatchers::hasJUnitAttr);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.JUnit3FloatingPointComparisonWithoutDelta.canBeConvertedToJUnit4",
	"Comment": "determines if the invocation can be safely converted to junit 4 based on its argument types.",
	"Method": "boolean canBeConvertedToJUnit4(VisitorState state,List<Type> argumentTypes){\r\n    if (argumentTypes.size() > 2) {\r\n        return true;\r\n    }\r\n    Type firstType = argumentTypes.get(0);\r\n    Type secondType = argumentTypes.get(1);\r\n    if (!isFloatingPoint(state, firstType) && !isFloatingPoint(state, secondType)) {\r\n        return true;\r\n    }\r\n    if (!isNumeric(state, firstType) || !isNumeric(state, secondType)) {\r\n        return true;\r\n    }\r\n    if (!firstType.isPrimitive() && !secondType.isPrimitive()) {\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.google.errorprone.DiagnosticTestHelper.assertHasDiagnosticOnAllMatchingLines",
	"Comment": "asserts that the diagnostics contain a diagnostic on each line of the source file that matchesour bug marker pattern. parses the bug marker pattern for the specific string to look for inthe diagnostic.",
	"Method": "void assertHasDiagnosticOnAllMatchingLines(JavaFileObject source,LookForCheckNameInDiagnostic lookForCheckNameInDiagnostic){\r\n    final List<Diagnostic<? extends JavaFileObject>> diagnostics = getDiagnostics();\r\n    final LineNumberReader reader = new LineNumberReader(CharSource.wrap(source.getCharContent(false)).openStream());\r\n    do {\r\n        String line = reader.readLine();\r\n        if (line == null) {\r\n            break;\r\n        }\r\n        List<Predicate<? super String>> predicates = null;\r\n        if (line.contains(BUG_MARKER_COMMENT_INLINE)) {\r\n            List<String> patterns = extractPatterns(line, reader, BUG_MARKER_COMMENT_INLINE);\r\n            predicates = new ArrayList(patterns.size());\r\n            for (String pattern : patterns) {\r\n                predicates.add(new SimpleStringContains(pattern));\r\n            }\r\n        } else if (line.contains(BUG_MARKER_COMMENT_LOOKUP)) {\r\n            int markerLineNumber = reader.getLineNumber();\r\n            List<String> lookupKeys = extractPatterns(line, reader, BUG_MARKER_COMMENT_LOOKUP);\r\n            predicates = new ArrayList(lookupKeys.size());\r\n            for (String lookupKey : lookupKeys) {\r\n                assertTrue(\"No expected error message with key [\" + lookupKey + \"] as expected from line [\" + markerLineNumber + \"] with diagnostic [\" + line.trim() + \"]\", expectedErrorMsgs.containsKey(lookupKey));\r\n                predicates.add(expectedErrorMsgs.get(lookupKey));\r\n                usedLookupKeys.add(lookupKey);\r\n            }\r\n        }\r\n        if (predicates != null) {\r\n            int lineNumber = reader.getLineNumber();\r\n            for (Predicate<? super String> predicate : predicates) {\r\n                Matcher<? super Iterable<Diagnostic<? extends JavaFileObject>>> patternMatcher = hasItem(diagnosticOnLine(source.toUri(), lineNumber, predicate));\r\n                assertTrue(\"Did not see an error on line \" + lineNumber + \" matching \" + predicate + \". \" + allErrors(diagnostics), patternMatcher.matches(diagnostics));\r\n            }\r\n            if (checkName != null && lookForCheckNameInDiagnostic == LookForCheckNameInDiagnostic.YES) {\r\n                Matcher<? super Iterable<Diagnostic<? extends JavaFileObject>>> checkNameMatcher = hasItem(diagnosticOnLine(source.toUri(), lineNumber, new SimpleStringContains(\"[\" + checkName + \"]\")));\r\n                assertTrue(\"Did not see an error on line \" + lineNumber + \" containing [\" + checkName + \"]. \" + allErrors(diagnostics), checkNameMatcher.matches(diagnostics));\r\n            }\r\n        } else {\r\n            int lineNumber = reader.getLineNumber();\r\n            Matcher<? super Iterable<Diagnostic<? extends JavaFileObject>>> matcher = hasItem(diagnosticOnLine(source.toUri(), lineNumber));\r\n            if (matcher.matches(diagnostics)) {\r\n                fail(\"Saw unexpected error on line \" + lineNumber + \". \" + allErrors(diagnostics));\r\n            }\r\n        }\r\n    } while (true);\r\n    reader.close();\r\n}"
}, {
	"Path": "com.google.errorprone.apply.ImportStatementsTest.addingToEmptyImportListOutputShouldStartAndEndWithNewlines",
	"Comment": "test empty initial import list. the output string should start and end with newlines because itis intended to be inserted after the package statement.",
	"Method": "void addingToEmptyImportListOutputShouldStartAndEndWithNewlines(){\r\n    ImportStatements imports = createImportStatements(basePackage, new ArrayList<JCImport>());\r\n    imports.add(\"import org.joda.time.Interval\");\r\n    assertEquals(\"\\n\" + \"import org.joda.time.Interval;\\n\", imports.toString());\r\n}"
}, {
	"Path": "hex.pdp.PartialDependenceTest.prostateBinaryWeights",
	"Comment": "this test will repeat the test in prostatebinary but with weights applied to the final prediction.i will run the pdp with constant weights and without weights.they should arrive at the same answer.",
	"Method": "void prostateBinaryWeights(){\r\n    Scope.enter();\r\n    Frame fr = null;\r\n    GBMModel model = null;\r\n    PartialDependence partialDependence = null;\r\n    PartialDependence partialDependenceW = null;\r\n    try {\r\n        fr = parse_test_file(\"smalldata/prostate/prostate.csv\");\r\n        for (String s : new String[] { \"RACE\", \"GLEASON\", \"DPROS\", \"DCAPS\", \"CAPSULE\" }) {\r\n            Vec v = fr.remove(s);\r\n            fr.add(s, v.toCategoricalVec());\r\n            v.remove();\r\n        }\r\n        Scope.track(fr);\r\n        Vec orig = fr.anyVec();\r\n        Vec[] weights = new Vec[1];\r\n        weights[0] = orig.makeCon(2.0);\r\n        fr.add(new String[] { \"weights\" }, weights);\r\n        Scope.track(orig);\r\n        Scope.track(weights[0]);\r\n        DKV.put(fr);\r\n        Scope.track(orig);\r\n        Scope.track(weights[0]);\r\n        GBMModel.GBMParameters parms = new GBMModel.GBMParameters();\r\n        parms._train = fr._key;\r\n        parms._ignored_columns = new String[] { \"ID\" };\r\n        parms._response_column = \"CAPSULE\";\r\n        model = new GBM(parms).trainModel().get();\r\n        partialDependence = new PartialDependence(Key.<PartialDependence>make());\r\n        partialDependence._nbins = 10;\r\n        partialDependence._model_id = (Key) model._key;\r\n        partialDependence._cols = new String[] { \"AGE\", \"RACE\" };\r\n        partialDependence._frame_id = fr._key;\r\n        partialDependence.execImpl().get();\r\n        partialDependenceW = new PartialDependence(Key.<PartialDependence>make());\r\n        partialDependenceW._nbins = 10;\r\n        partialDependenceW._model_id = (Key) model._key;\r\n        partialDependenceW._cols = new String[] { \"AGE\", \"RACE\" };\r\n        partialDependenceW._weight_column_index = fr.numCols() - 1;\r\n        partialDependenceW._frame_id = fr._key;\r\n        partialDependenceW.execImpl().get();\r\n        Scope.track_generic(model);\r\n        Scope.track_generic(partialDependence);\r\n        Scope.track_generic(partialDependenceW);\r\n        assert equalTwoDimTables(partialDependence._partial_dependence_data[0], partialDependenceW._partial_dependence_data[0], 1e-10) : \"pdp with constant weight and without weight generated different answers for column AGE.\";\r\n        assert equalTwoDimTables(partialDependence._partial_dependence_data[1], partialDependenceW._partial_dependence_data[1], 1e-10) : \"pdp with constant weight and without weight generated different answers for column RACE.\";\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.kindIs",
	"Comment": "matches an ast node of a given kind, for example, an annotation or a switch block.",
	"Method": "Matcher<T> kindIs(Kind kind){\r\n    return new Matcher<T>() {\r\n        @Override\r\n        public boolean matches(T tree, VisitorState state) {\r\n            return tree.getKind() == kind;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.kindIs",
	"Comment": "matches an ast node of a given kind, for example, an annotation or a switch block.",
	"Method": "Matcher<T> kindIs(Kind kind){\r\n    return tree.getKind() == kind;\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.getActiveThreadCount",
	"Comment": "returns an estimate of the number of threads that are currentlystealing or executing tasks. this method may overestimate thenumber of active threads.",
	"Method": "int getActiveThreadCount(){\r\n    int r = parallelism + (int) (ctl >> AC_SHIFT);\r\n    return (r <= 0) ? 0 : r;\r\n}"
}, {
	"Path": "water.H2O.orderlyShutdown",
	"Comment": "orderly shutdown with infinite timeout for confirmations from the nodes in the cluster",
	"Method": "int orderlyShutdown(int orderlyShutdown,int timeout){\r\n    boolean[] confirmations = new boolean[H2O.CLOUD.size()];\r\n    if (H2O.SELF.index() >= 0) {\r\n        confirmations[H2O.SELF.index()] = true;\r\n    }\r\n    Futures fs = new Futures();\r\n    for (H2ONode n : H2O.CLOUD._memary) {\r\n        if (n != H2O.SELF)\r\n            fs.add(new RPC(n, new ShutdownTsk(H2O.SELF, n.index(), 1000, confirmations, 0)).call());\r\n    }\r\n    if (timeout > 0)\r\n        try {\r\n            Thread.sleep(timeout);\r\n        } catch (Exception ignore) {\r\n        }\r\n    else\r\n        fs.blockForPending();\r\n    int failedToShutdown = 0;\r\n    for (boolean b : confirmations) if (!b)\r\n        failedToShutdown++;\r\n    return failedToShutdown;\r\n}"
}, {
	"Path": "hex.glm.GLMTest.testGradientTask",
	"Comment": "make sure all three implementations of ginfo computation in glm get the same results",
	"Method": "void testGradientTask(){\r\n    Key parsed = Key.make(\"cars_parsed\");\r\n    Frame fr = null;\r\n    DataInfo dinfo = null;\r\n    try {\r\n        fr = parse_test_file(parsed, \"smalldata/junit/mixcat_train.csv\");\r\n        GLMParameters params = new GLMParameters(Family.binomial, Family.binomial.defaultLink, new double[] { 0 }, new double[] { 0 }, 0, 0);\r\n        params._train = parsed;\r\n        params._lambda = new double[] { 0 };\r\n        params._use_all_factor_levels = true;\r\n        fr.add(\"Useless\", fr.remove(\"Useless\"));\r\n        dinfo = new DataInfo(fr, null, 1, params._use_all_factor_levels || params._lambda_search, params._standardize ? DataInfo.TransformType.STANDARDIZE : DataInfo.TransformType.NONE, DataInfo.TransformType.NONE, true, false, false, false, false, false);\r\n        DKV.put(dinfo._key, dinfo);\r\n        double[] beta = MemoryManager.malloc8d(dinfo.fullN() + 1);\r\n        Random rnd = new Random(987654321);\r\n        for (int i = 0; i < beta.length; ++i) beta[i] = 1 - 2 * rnd.nextDouble();\r\n        GLMGradientTask grtSpc = new GLMBinomialGradientTask(null, dinfo, params, params._lambda[0], beta).doAll(dinfo._adaptedFrame);\r\n        GLMGradientTask grtGen = new GLMGenericGradientTask(null, dinfo, params, params._lambda[0], beta).doAll(dinfo._adaptedFrame);\r\n        for (int i = 0; i < beta.length; ++i) assertEquals(\"gradients differ\", grtSpc._gradient[i], grtGen._gradient[i], 1e-4);\r\n        params = new GLMParameters(Family.gaussian, Family.gaussian.defaultLink, new double[] { 0 }, new double[] { 0 }, 0, 0);\r\n        params._use_all_factor_levels = false;\r\n        dinfo.remove();\r\n        dinfo = new DataInfo(fr, null, 1, params._use_all_factor_levels || params._lambda_search, params._standardize ? DataInfo.TransformType.STANDARDIZE : DataInfo.TransformType.NONE, DataInfo.TransformType.NONE, true, false, false, false, false, false);\r\n        DKV.put(dinfo._key, dinfo);\r\n        beta = MemoryManager.malloc8d(dinfo.fullN() + 1);\r\n        rnd = new Random(1987654321);\r\n        for (int i = 0; i < beta.length; ++i) beta[i] = 1 - 2 * rnd.nextDouble();\r\n        grtSpc = new GLMGaussianGradientTask(null, dinfo, params, params._lambda[0], beta).doAll(dinfo._adaptedFrame);\r\n        grtGen = new GLMGenericGradientTask(null, dinfo, params, params._lambda[0], beta).doAll(dinfo._adaptedFrame);\r\n        for (int i = 0; i < beta.length; ++i) assertEquals(\"gradients differ: \" + Arrays.toString(grtSpc._gradient) + \" != \" + Arrays.toString(grtGen._gradient), grtSpc._gradient[i], grtGen._gradient[i], 1e-4);\r\n        dinfo.remove();\r\n    } finally {\r\n        if (fr != null)\r\n            fr.delete();\r\n        if (dinfo != null)\r\n            dinfo.remove();\r\n    }\r\n}"
}, {
	"Path": "water.MRTask.isReleasable",
	"Comment": "return true if blocking is unnecessary, which is true if the task isdone.",
	"Method": "boolean isReleasable(){\r\n    return isDone();\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setCleanOnValidationError",
	"Comment": "whether to automatically call clean or not when a validation error occurs. this is exclusively intended as a convenience for development. even tough westrongly recommend not to change migration scripts once they have been checked into scm and run, this provides away of dealing with this case in a smooth manner. the database will be wiped clean automatically, ensuring thatthe next migration will bring you back to the state checked into scm.warning ! do not enable in production !",
	"Method": "void setCleanOnValidationError(boolean cleanOnValidationError){\r\n    this.cleanOnValidationError = cleanOnValidationError;\r\n}"
}, {
	"Path": "graphql.execution.instrumentation.SimpleInstrumentationContext.whenDispatched",
	"Comment": "allows for the more fluent away to return an instrumentation context that runs the specifiedcode on instrumentation step dispatch.",
	"Method": "SimpleInstrumentationContext<U> whenDispatched(Consumer<CompletableFuture<U>> codeToRun){\r\n    return new SimpleInstrumentationContext(codeToRun, null);\r\n}"
}, {
	"Path": "water.parser.Parser.sequentialParse",
	"Comment": "parse the vec sequentially writing out one chunk after another",
	"Method": "StreamParseWriter sequentialParse(Vec vec,StreamParseWriter dout){\r\n    throw new UnsupportedOperationException(\"Sequential Parsing is not supported by \" + this.getClass().getName());\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Description.getMessageWithoutCheckName",
	"Comment": "returns the message, not including the check name but including the link.",
	"Method": "String getMessageWithoutCheckName(){\r\n    return linkUrl != null ? String.format(\"%s\\n%s\", rawMessage, linkTextForDiagnostic(linkUrl)) : String.format(\"%s\", rawMessage);\r\n}"
}, {
	"Path": "graphql.schema.GraphQLCodeRegistry.getDataFetcher",
	"Comment": "returns a data fetcher associated with a field within a container type",
	"Method": "DataFetcher getDataFetcher(GraphQLFieldsContainer parentType,GraphQLFieldDefinition fieldDefinition,DataFetcher getDataFetcher,GraphQLFieldsContainer parentType,GraphQLFieldDefinition fieldDefinition){\r\n    return getDataFetcherImpl(parentType, fieldDefinition, dataFetcherMap, systemDataFetcherMap);\r\n}"
}, {
	"Path": "hex.ModelBuilder.make",
	"Comment": "factory method to create a modelbuilder instance for given the algo name. shallow clone of both the default modelbuilder instance and a parameter.",
	"Method": "B make(String algo,Job job,Key<Model> result){\r\n    int idx = ArrayUtils.find(ALGOBASES, algo.toLowerCase());\r\n    if (idx < 0) {\r\n        StringBuilder sb = new StringBuilder();\r\n        sb.append(\"Unknown algo: '\").append(algo).append(\"'; Extension report: \");\r\n        Log.err(ExtensionManager.getInstance().makeExtensionReport(sb));\r\n        throw new IllegalStateException(\"Algorithm '\" + algo + \"' is not registered. Available algos: [\" + StringUtils.join(\",\", ALGOBASES) + \"]\");\r\n    }\r\n    B mb = (B) BUILDERS[idx].clone();\r\n    mb._job = job;\r\n    mb._result = result;\r\n    mb._parms = BUILDERS[idx]._parms.clone();\r\n    return mb;\r\n}"
}, {
	"Path": "water.init.TimelineSnapshot.processEvent",
	"Comment": "process new event. for sender, check if there are any blocked receiveswaiting for this send. for receiver, try to find matching sender, otherwiseblock.",
	"Method": "void processEvent(Event e){\r\n    assert !_processed;\r\n    if (e.isSend()) {\r\n        _sends.put(e, new ArrayList<TimelineSnapshot.Event>());\r\n        for (Event otherE : _events) {\r\n            if ((otherE != null) && (otherE != e) && (!otherE.equals(e)) && otherE._blocked && otherE.match(e)) {\r\n                _edges.put(otherE, e);\r\n                _sends.get(e).add(otherE);\r\n                otherE._blocked = false;\r\n            }\r\n        }\r\n    } else {\r\n        assert !_edges.containsKey(e);\r\n        int senderIdx = e.packH2O().index();\r\n        if (senderIdx < 0) {\r\n            Log.warn(\"no sender found! port = \" + e.portPack() + \", ip = \" + e.addrPack().toString());\r\n            return;\r\n        }\r\n        Event senderCnd = _events[senderIdx];\r\n        if (senderCnd != null) {\r\n            if (isSenderRecvPair(senderCnd, e)) {\r\n                _edges.put(e, senderCnd.clone());\r\n                _sends.get(senderCnd).add(e);\r\n                return;\r\n            }\r\n            senderCnd = senderCnd.clone();\r\n            while (senderCnd.prev()) {\r\n                if (isSenderRecvPair(senderCnd, e)) {\r\n                    _edges.put(e, senderCnd);\r\n                    _sends.get(senderCnd).add(e);\r\n                    return;\r\n                }\r\n            }\r\n        }\r\n        e._blocked = true;\r\n    }\r\n    assert (e == null) || (e._eventIdx < TimeLine.MAX_EVENTS);\r\n}"
}, {
	"Path": "feign.benchmark.WhatShouldWeCacheBenchmarks.buildAndQuery_fake",
	"Comment": "how fast is creating a feign instance for each http request, without considering network?",
	"Method": "Response buildAndQuery_fake(){\r\n    return Feign.builder().client(fakeClient).target(FeignTestInterface.class, \"http://localhost\").query();\r\n}"
}, {
	"Path": "hex.glm.GLMTest.testSparseGramComputation",
	"Comment": "test we get correct gram on dataset which contains categoricals and sparse and dense numbers",
	"Method": "void testSparseGramComputation(){\r\n    Random rnd = new Random(123456789l);\r\n    double[] d0 = MemoryManager.malloc8d(1000);\r\n    double[] d1 = MemoryManager.malloc8d(1000);\r\n    double[] d2 = MemoryManager.malloc8d(1000);\r\n    double[] d3 = MemoryManager.malloc8d(1000);\r\n    double[] d4 = MemoryManager.malloc8d(1000);\r\n    double[] d5 = MemoryManager.malloc8d(1000);\r\n    double[] d6 = MemoryManager.malloc8d(1000);\r\n    double[] d7 = MemoryManager.malloc8d(1000);\r\n    double[] d8 = MemoryManager.malloc8d(1000);\r\n    double[] d9 = MemoryManager.malloc8d(1000);\r\n    long[] c1 = MemoryManager.malloc8(1000);\r\n    long[] c2 = MemoryManager.malloc8(1000);\r\n    String[] dom = new String[] { \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\" };\r\n    for (int i = 0; i < d1.length; ++i) {\r\n        c1[i] = rnd.nextInt(dom.length);\r\n        c2[i] = rnd.nextInt(dom.length);\r\n        d0[i] = rnd.nextDouble();\r\n        d1[i] = rnd.nextDouble();\r\n    }\r\n    for (int i = 0; i < 30; ++i) {\r\n        d2[rnd.nextInt(d2.length)] = rnd.nextDouble();\r\n        d3[rnd.nextInt(d2.length)] = rnd.nextDouble();\r\n        d4[rnd.nextInt(d2.length)] = rnd.nextDouble();\r\n        d5[rnd.nextInt(d2.length)] = rnd.nextDouble();\r\n        d6[rnd.nextInt(d2.length)] = rnd.nextDouble();\r\n        d7[rnd.nextInt(d2.length)] = rnd.nextDouble();\r\n        d8[rnd.nextInt(d2.length)] = rnd.nextDouble();\r\n        d9[rnd.nextInt(d2.length)] = 1;\r\n    }\r\n    Vec.VectorGroup vg_1 = Vec.VectorGroup.VG_LEN1;\r\n    Vec v01 = Vec.makeVec(c1, dom, vg_1.addVec());\r\n    Vec v02 = Vec.makeVec(c2, dom, vg_1.addVec());\r\n    Vec v03 = Vec.makeVec(d0, vg_1.addVec());\r\n    Vec v04 = Vec.makeVec(d1, vg_1.addVec());\r\n    Vec v05 = Vec.makeVec(d2, vg_1.addVec());\r\n    Vec v06 = Vec.makeVec(d3, vg_1.addVec());\r\n    Vec v07 = Vec.makeVec(d4, vg_1.addVec());\r\n    Vec v08 = Vec.makeVec(d5, vg_1.addVec());\r\n    Vec v09 = Vec.makeVec(d6, vg_1.addVec());\r\n    Vec v10 = Vec.makeVec(d7, vg_1.addVec());\r\n    Vec v11 = Vec.makeVec(d8, vg_1.addVec());\r\n    Vec v12 = Vec.makeVec(d9, vg_1.addVec());\r\n    Frame f = new Frame(Key.<Frame>make(\"TestData\"), null, new Vec[] { v01, v02, v03, v04, v05, v05, v06, v07, v08, v09, v10, v11, v12 });\r\n    DKV.put(f);\r\n    DataInfo dinfo = new DataInfo(f, null, 1, true, DataInfo.TransformType.STANDARDIZE, DataInfo.TransformType.NONE, true, false, false, false, false, false);\r\n    GLMParameters params = new GLMParameters(Family.gaussian);\r\n    final GLMIterationTask glmtSparse = new GLMIterationTask(null, dinfo, new GLMWeightsFun(params), null).setSparse(true).doAll(dinfo._adaptedFrame);\r\n    final GLMIterationTask glmtDense = new GLMIterationTask(null, dinfo, new GLMWeightsFun(params), null).setSparse(false).doAll(dinfo._adaptedFrame);\r\n    for (int i = 0; i < glmtDense._xy.length; ++i) {\r\n        for (int j = 0; j <= i; ++j) {\r\n            assertEquals(glmtDense._gram.get(i, j), glmtSparse._gram.get(i, j), 1e-8);\r\n        }\r\n        assertEquals(glmtDense._xy[i], glmtSparse._xy[i], 1e-8);\r\n    }\r\n    final double[] beta = MemoryManager.malloc8d(dinfo.fullN() + 1);\r\n    H2O.submitTask(new H2OCountedCompleter() {\r\n        @Override\r\n        public void compute2() {\r\n            new GLM.GramSolver(glmtDense._gram, glmtDense._xy, true, 1e-5, 0, null, null, null, null).solve(null, beta);\r\n            tryComplete();\r\n        }\r\n    }).join();\r\n    final GLMIterationTask glmtSparse2 = new GLMIterationTask(null, dinfo, new GLMWeightsFun(params), beta).setSparse(true).doAll(dinfo._adaptedFrame);\r\n    final GLMIterationTask glmtDense2 = new GLMIterationTask(null, dinfo, new GLMWeightsFun(params), beta).setSparse(false).doAll(dinfo._adaptedFrame);\r\n    for (int i = 0; i < glmtDense2._xy.length; ++i) {\r\n        for (int j = 0; j <= i; ++j) {\r\n            assertEquals(glmtDense2._gram.get(i, j), glmtSparse2._gram.get(i, j), 1e-8);\r\n        }\r\n        assertEquals(glmtDense2._xy[i], glmtSparse2._xy[i], 1e-8);\r\n    }\r\n    dinfo.remove();\r\n    f.delete();\r\n}"
}, {
	"Path": "hex.glm.GLMTest.testSparseGramComputation",
	"Comment": "test we get correct gram on dataset which contains categoricals and sparse and dense numbers",
	"Method": "void testSparseGramComputation(){\r\n    new GLM.GramSolver(glmtDense._gram, glmtDense._xy, true, 1e-5, 0, null, null, null, null).solve(null, beta);\r\n    tryComplete();\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.mysql.MySQLSchema.cleanRoutines",
	"Comment": "generate the statements to clean the routines in this schema.",
	"Method": "List<String> cleanRoutines(){\r\n    List<Map<String, String>> routineNames = jdbcTemplate.queryForList(\"SELECT routine_name as 'N', routine_type as 'T' FROM information_schema.routines WHERE routine_schema=?\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (Map<String, String> row : routineNames) {\r\n        String routineName = row.get(\"N\");\r\n        String routineType = row.get(\"T\");\r\n        statements.add(\"DROP \" + routineType + \" \" + database.quote(name, routineName));\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.scanner.classpath.ClassPathScanner.createLocationScanner",
	"Comment": "creates an appropriate location scanner for this url protocol.",
	"Method": "ClassPathLocationScanner createLocationScanner(String protocol){\r\n    if (locationScannerCache.containsKey(protocol)) {\r\n        return locationScannerCache.get(protocol);\r\n    }\r\n    if (\"file\".equals(protocol)) {\r\n        FileSystemClassPathLocationScanner locationScanner = new FileSystemClassPathLocationScanner();\r\n        locationScannerCache.put(protocol, locationScanner);\r\n        resourceNameCache.put(locationScanner, new HashMap());\r\n        return locationScanner;\r\n    }\r\n    if (\"jar\".equals(protocol) || isTomcat(protocol) || isWebLogic(protocol) || isWebSphere(protocol)) {\r\n        String separator = isTomcat(protocol) ? \"*/\" : \"!/\";\r\n        ClassPathLocationScanner locationScanner = new JarFileClassPathLocationScanner(separator);\r\n        locationScannerCache.put(protocol, locationScanner);\r\n        resourceNameCache.put(locationScanner, new HashMap());\r\n        return locationScanner;\r\n    }\r\n    FeatureDetector featureDetector = new FeatureDetector(classLoader);\r\n    if (featureDetector.isJBossVFSv3Available() && \"vfs\".equals(protocol)) {\r\n        JBossVFSv3ClassPathLocationScanner locationScanner = new JBossVFSv3ClassPathLocationScanner();\r\n        locationScannerCache.put(protocol, locationScanner);\r\n        resourceNameCache.put(locationScanner, new HashMap());\r\n        return locationScanner;\r\n    }\r\n    if (featureDetector.isOsgiFrameworkAvailable() && (isFelix(protocol) || isEquinox(protocol))) {\r\n        OsgiClassPathLocationScanner locationScanner = new OsgiClassPathLocationScanner();\r\n        locationScannerCache.put(protocol, locationScanner);\r\n        resourceNameCache.put(locationScanner, new HashMap());\r\n        return locationScanner;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "graphql.schema.idl.WiringFactory.providesDataFetcher",
	"Comment": "this is called to ask if this factory can provide a data fetcher for the definition",
	"Method": "boolean providesDataFetcher(FieldWiringEnvironment environment){\r\n    return false;\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setValidateOnMigrate",
	"Comment": "whether to automatically call validate or not when running migrate.",
	"Method": "void setValidateOnMigrate(boolean validateOnMigrate){\r\n    this.validateOnMigrate = validateOnMigrate;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.base.Table.exists",
	"Comment": "checks whether the database contains a table matching these criteria.",
	"Method": "boolean exists(boolean exists,Schema catalog,Schema schema,String table,String tableTypes){\r\n    String[] types = tableTypes;\r\n    if (types.length == 0) {\r\n        types = null;\r\n    }\r\n    ResultSet resultSet = null;\r\n    boolean found;\r\n    try {\r\n        resultSet = database.jdbcMetaData.getTables(catalog == null ? null : catalog.getName(), schema == null ? null : schema.getName(), table, types);\r\n        found = resultSet.next();\r\n    } finally {\r\n        JdbcUtils.closeResultSet(resultSet);\r\n    }\r\n    return found;\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaDirectiveWiring.onInterface",
	"Comment": "this is called when an interface is encountered, which gives the schema directive a chance to modify the shape and behaviourof that dslelement",
	"Method": "GraphQLInterfaceType onInterface(SchemaDirectiveWiringEnvironment<GraphQLInterfaceType> environment){\r\n    return environment.getElement();\r\n}"
}, {
	"Path": "org.flywaydb.core.api.MigrationVersion.isNewerThan",
	"Comment": "convenience method for quickly checking whether this version is newer than this other version.",
	"Method": "boolean isNewerThan(String otherVersion){\r\n    return compareTo(MigrationVersion.fromVersion(otherVersion)) > 0;\r\n}"
}, {
	"Path": "graphql.schema.idl.WiringFactory.providesScalar",
	"Comment": "this is called to ask if this factory can provide a custom scalar",
	"Method": "boolean providesScalar(ScalarWiringEnvironment environment){\r\n    return false;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.scanner.classpath.JarFileClassPathLocationScanner.findResourceNamesFromJarFile",
	"Comment": "finds all the resource names contained in this directory within this jar file.",
	"Method": "Set<String> findResourceNamesFromJarFile(JarFile jarFile,String prefix,String location){\r\n    String toScan = prefix + location + (location.endsWith(\"/\") ? \"\" : \"/\");\r\n    Set<String> resourceNames = new TreeSet();\r\n    Enumeration<JarEntry> entries = jarFile.entries();\r\n    while (entries.hasMoreElements()) {\r\n        String entryName = entries.nextElement().getName();\r\n        if (entryName.startsWith(toScan)) {\r\n            resourceNames.add(entryName.substring(prefix.length()));\r\n        }\r\n    }\r\n    return resourceNames;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.FileCopyUtils.copyToString",
	"Comment": "copy the contents of the given reader into a string.closes the reader when done.",
	"Method": "String copyToString(Reader in){\r\n    StringWriter out = new StringWriter();\r\n    copy(in, out);\r\n    String str = out.toString();\r\n    if (str.startsWith(\"?\")) {\r\n        return str.substring(1);\r\n    }\r\n    return str;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.StringUtils.startsAndEndsWith",
	"Comment": "checks whether this strings both begins with this prefix and ends withs either of these suffixes.",
	"Method": "boolean startsAndEndsWith(String str,String prefix,String suffixes){\r\n    if (StringUtils.hasLength(prefix) && !str.startsWith(prefix)) {\r\n        return false;\r\n    }\r\n    for (String suffix : suffixes) {\r\n        if (str.endsWith(suffix) && (str.length() > (prefix + suffix).length())) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "water.H2O.startNetworkServices",
	"Comment": "starts the worker threads, receiver threads, heartbeats and all other network related services.",
	"Method": "void startNetworkServices(){\r\n    UDPRebooted.T.reboot.broadcast();\r\n    new MultiReceiverThread().start();\r\n    Cleaner.THE_CLEANER.start();\r\n    new TCPReceiverThread(NetworkInit._tcpSocket).start();\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.util.OSXAdapter.setPreferencesHandler",
	"Comment": "they will be called when the preferences menu item is selected from the application menu",
	"Method": "void setPreferencesHandler(Object target,Method prefsHandler){\r\n    boolean enablePrefsMenu = (target != null && prefsHandler != null);\r\n    if (enablePrefsMenu) {\r\n        setHandler(new OSXAdapter(\"handlePreferences\", target, prefsHandler));\r\n    }\r\n    try {\r\n        Method enablePrefsMethod = macOSXApplication.getClass().getDeclaredMethod(\"setEnabledPreferencesMenu\", new Class[] { boolean.class });\r\n        enablePrefsMethod.invoke(macOSXApplication, new Object[] { Boolean.valueOf(enablePrefsMenu) });\r\n    } catch (Exception ex) {\r\n        LoggerHelper.logException(LOGGER, Level.SEVERE, \"OSXAdapter could not access the Preferences Menu\", ex);\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.target",
	"Comment": "sets the target version up to which flyway should consider migrations.migrations with a higher version number will be ignored.",
	"Method": "FluentConfiguration target(MigrationVersion target,FluentConfiguration target,String target){\r\n    config.setTargetAsString(target);\r\n    return this;\r\n}"
}, {
	"Path": "water.fvec.Frame.closeNewChunks",
	"Comment": "filling them.can be called in parallel for different sets of chunks.",
	"Method": "void closeNewChunks(NewChunk[] nchks){\r\n    Futures fs = new Futures();\r\n    for (NewChunk nchk : nchks) {\r\n        nchk.close(fs);\r\n    }\r\n    fs.blockForPending();\r\n}"
}, {
	"Path": "com.google.errorprone.refaster.Template.infer",
	"Comment": "returns the inferred method type of the template based on the given actual argument types.",
	"Method": "Type infer(Warner warner,Inliner inliner,List<Type> freeTypeVariables,List<Type> expectedArgTypes,Type returnType,List<Type> actualArgTypes){\r\n    Symtab symtab = inliner.symtab();\r\n    Type methodType = new MethodType(expectedArgTypes, returnType, List.<Type>nil(), symtab.methodClass);\r\n    if (!freeTypeVariables.isEmpty()) {\r\n        methodType = new ForAll(freeTypeVariables, methodType);\r\n    }\r\n    Enter enter = inliner.enter();\r\n    MethodSymbol methodSymbol = new MethodSymbol(0, inliner.asName(\"__m__\"), methodType, symtab.unknownSymbol);\r\n    Type site = symtab.methodClass.type;\r\n    Env<AttrContext> env = enter.getTopLevelEnv(TreeMaker.instance(inliner.getContext()).TopLevel(List.<JCTree>nil()));\r\n    try {\r\n        Field field = AttrContext.class.getDeclaredField(\"pendingResolutionPhase\");\r\n        field.setAccessible(true);\r\n        field.set(env.info, newMethodResolutionPhase(autoboxing()));\r\n    } catch (ReflectiveOperationException e) {\r\n        throw new LinkageError(e.getMessage(), e);\r\n    }\r\n    Object resultInfo;\r\n    try {\r\n        Class<?> resultInfoClass = Class.forName(\"com.sun.tools.javac.comp.Attr$ResultInfo\");\r\n        Constructor<?> resultInfoCtor = resultInfoClass.getDeclaredConstructor(Attr.class, KindSelector.class, Type.class);\r\n        resultInfoCtor.setAccessible(true);\r\n        resultInfo = resultInfoCtor.newInstance(Attr.instance(inliner.getContext()), KindSelector.PCK, Type.noType);\r\n    } catch (ReflectiveOperationException e) {\r\n        throw new LinkageError(e.getMessage(), e);\r\n    }\r\n    Log.DeferredDiagnosticHandler handler = new Log.DeferredDiagnosticHandler(Log.instance(inliner.getContext()));\r\n    try {\r\n        MethodType result = callCheckMethod(warner, inliner, resultInfo, actualArgTypes, methodSymbol, site, env);\r\n        if (!handler.getDiagnostics().isEmpty()) {\r\n            throw new InferException(handler.getDiagnostics());\r\n        }\r\n        return result;\r\n    } finally {\r\n        Log.instance(inliner.getContext()).popDiagnosticHandler(handler);\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.ArrayHashCodeTest.testJava7NegativeCase",
	"Comment": "tests java.util.objects hashcode methods, which are only in jdk 7 and above.",
	"Method": "void testJava7NegativeCase(){\r\n    compilationHelper.addSourceFile(\"ArrayHashCodeNegativeCases2.java\").doTest();\r\n}"
}, {
	"Path": "hex.tree.Score.makeModelMetrics",
	"Comment": "run after the doall scoring to convert the metricsbuilder to a modelmetrics",
	"Method": "ModelMetrics makeModelMetrics(SharedTreeModel model,Frame fr,Frame adaptedFr,Frame preds){\r\n    ModelMetrics mm;\r\n    if (model._output.nclasses() == 2 && _computeGainsLift) {\r\n        assert preds != null : \"Predictions were pre-created\";\r\n        mm = _mb.makeModelMetrics(model, fr, adaptedFr, preds);\r\n    } else {\r\n        boolean calculatePreds = preds == null && model._parms._distribution == DistributionFamily.huber;\r\n        if (calculatePreds) {\r\n            Log.warn(\"Going to calculate predictions from scratch. This can be expensive for large models! See PUBDEV-4992\");\r\n            preds = model.score(fr);\r\n        }\r\n        mm = _mb.makeModelMetrics(model, fr, null, preds);\r\n        if (calculatePreds && (preds != null))\r\n            preds.remove();\r\n    }\r\n    return mm;\r\n}"
}, {
	"Path": "hex.grid.Grid.getModel",
	"Comment": "returns model for given combination of model parameters or null if the model does not exist.",
	"Method": "Model getModel(MP params){\r\n    Key<Model> mKey = getModelKey(params);\r\n    return mKey != null ? mKey.get() : null;\r\n}"
}, {
	"Path": "water.persist.PersistManager.isDirectoryWritable",
	"Comment": "check that a directory is writable by creating and deleting a file.",
	"Method": "boolean isDirectoryWritable(Persist persist,String path){\r\n    OutputStream os = null;\r\n    try {\r\n        String testFileUriStr = FileUtils.getURI(path + \"/.h2oWriteCheck\").toString();\r\n        os = persist.create(testFileUriStr, true);\r\n        os.close();\r\n        persist.delete(testFileUriStr);\r\n        return true;\r\n    } catch (IOException | HDFSIOException | FSIOException e) {\r\n        return false;\r\n    } finally {\r\n        FileUtils.close(os);\r\n    }\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.robotstxt.UserAgentDirectives.match",
	"Comment": "match the current user agent directive set with the givenuser agent. the returned value will be the maximum match lengthof any user agent.",
	"Method": "int match(String userAgent){\r\n    userAgent = userAgent.toLowerCase();\r\n    int maxLength = 0;\r\n    for (String ua : userAgents) {\r\n        if (ua.equals(\"*\") || userAgent.contains(ua)) {\r\n            maxLength = Math.max(maxLength, ua.length());\r\n        }\r\n    }\r\n    return maxLength;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.enhancedForLoop",
	"Comment": "matches an enhanced for loop if all the given matchers match.",
	"Method": "Matcher<EnhancedForLoopTree> enhancedForLoop(Matcher<VariableTree> variableMatcher,Matcher<ExpressionTree> expressionMatcher,Matcher<StatementTree> statementMatcher){\r\n    return new Matcher<EnhancedForLoopTree>() {\r\n        @Override\r\n        public boolean matches(EnhancedForLoopTree t, VisitorState state) {\r\n            return variableMatcher.matches(t.getVariable(), state) && expressionMatcher.matches(t.getExpression(), state) && statementMatcher.matches(t.getStatement(), state);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.enhancedForLoop",
	"Comment": "matches an enhanced for loop if all the given matchers match.",
	"Method": "Matcher<EnhancedForLoopTree> enhancedForLoop(Matcher<VariableTree> variableMatcher,Matcher<ExpressionTree> expressionMatcher,Matcher<StatementTree> statementMatcher){\r\n    return variableMatcher.matches(t.getVariable(), state) && expressionMatcher.matches(t.getExpression(), state) && statementMatcher.matches(t.getStatement(), state);\r\n}"
}, {
	"Path": "water.MRTask.addShift",
	"Comment": "compute a permissible node index on which to launch remote work.",
	"Method": "int addShift(int x){\r\n    x += _nlo;\r\n    int sz = H2O.CLOUD.size();\r\n    return x < sz ? x : x - sz;\r\n}"
}, {
	"Path": "com.google.errorprone.apply.ImportStatementsTest.shouldSortImports",
	"Comment": "test that the import statements are sorted according to the google style guide.",
	"Method": "void shouldSortImports(){\r\n    ImportStatements imports = createImportStatements(basePackage, baseImportList);\r\n    assertEquals(\"import static com.google.ads.pebl.AdGroupCriterionPredicate.PAUSED;\\n\" + \"import static com.google.common.base.Preconditions.checkNotNull;\\n\" + \"\\n\" + \"import com.google.common.collect.ImmutableList;\\n\" + \"import com.google.common.collect.ImmutableMap;\\n\" + \"import com.sun.source.tree.CompilationUnitTree;\\n\" + \"import com.sun.source.tree.ImportTree;\\n\" + \"import com.sun.tools.javac.tree.JCTree;\\n\" + \"import com.sun.tools.javac.tree.JCTree.JCExpression;\\n\" + \"import java.io.File;\\n\" + \"import java.io.IOException;\\n\" + \"import java.util.Iterator;\\n\" + \"import javax.tools.JavaCompiler;\\n\" + \"import javax.tools.JavaFileObject;\\n\" + \"import javax.tools.StandardJavaFileManager;\\n\" + \"import javax.tools.ToolProvider;\\n\" + \"import org.joda.time.DateTime;\\n\" + \"import org.joda.time.DateTimeZone;\\n\" + \"import org.joda.time.Interval;\", imports.toString());\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.robotstxt.HostDirectives.disallows",
	"Comment": "check if the host directives explicitly disallow visiting path.",
	"Method": "boolean disallows(String path){\r\n    return checkAccess(path) == DISALLOWED;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.isSame",
	"Comment": "matches an ast node which is the same object reference as the given node.",
	"Method": "Matcher<T> isSame(Tree t){\r\n    return new Matcher<T>() {\r\n        @Override\r\n        public boolean matches(T tree, VisitorState state) {\r\n            return tree == t;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.isSame",
	"Comment": "matches an ast node which is the same object reference as the given node.",
	"Method": "Matcher<T> isSame(Tree t){\r\n    return tree == t;\r\n}"
}, {
	"Path": "graphql.execution.ExecutionStepInfo.getFieldDefinition",
	"Comment": "this returns the field definition that is in play when this type info was created or nullif the type is a root query type",
	"Method": "GraphQLFieldDefinition getFieldDefinition(){\r\n    return fieldDefinition;\r\n}"
}, {
	"Path": "graphql.schema.GraphQLSchema.newSchema",
	"Comment": "this allows you to build a schema from an existing schema.it copies everything from the existingschema and then allows you to replace them.",
	"Method": "Builder newSchema(Builder newSchema,GraphQLSchema existingSchema){\r\n    return new Builder().query(existingSchema.getQueryType()).mutation(existingSchema.getMutationType()).subscription(existingSchema.getSubscriptionType()).codeRegistry(existingSchema.getCodeRegistry()).clearAdditionalTypes().clearDirectives().additionalDirectives(existingSchema.directives).additionalTypes(existingSchema.additionalTypes);\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.initSql",
	"Comment": "the sql statements to run to initialize a new database connection immediately after opening it.",
	"Method": "FluentConfiguration initSql(String initSql){\r\n    config.setInitSql(initSql);\r\n    return this;\r\n}"
}, {
	"Path": "water.fvec.Frame.deepCopy",
	"Comment": "create a copy of the input frame and return that copied frame. all vecs in this are copied in parallel.caller must do the dkv.put",
	"Method": "Frame deepCopy(String keyName){\r\n    final Vec[] vecs = vecs().clone();\r\n    Key[] ks = anyVec().group().addVecs(vecs.length);\r\n    Futures fs = new Futures();\r\n    for (int i = 0; i < vecs.length; ++i) DKV.put(vecs[i] = new Vec(ks[i], anyVec()._rowLayout, vecs[i].domain(), vecs()[i]._type), fs);\r\n    new MRTask() {\r\n        @Override\r\n        public void map(Chunk[] cs) {\r\n            int cidx = cs[0].cidx();\r\n            for (int i = 0; i < cs.length; ++i) DKV.put(vecs[i].chunkKey(cidx), cs[i].deepCopy(), _fs);\r\n        }\r\n    }.doAll(this);\r\n    fs.blockForPending();\r\n    return new Frame((keyName == null ? null : Key.<Frame>make(keyName)), this.names(), vecs);\r\n}"
}, {
	"Path": "water.fvec.Frame.deepCopy",
	"Comment": "create a copy of the input frame and return that copied frame. all vecs in this are copied in parallel.caller must do the dkv.put",
	"Method": "Frame deepCopy(String keyName){\r\n    int cidx = cs[0].cidx();\r\n    for (int i = 0; i < cs.length; ++i) DKV.put(vecs[i].chunkKey(cidx), cs[i].deepCopy(), _fs);\r\n}"
}, {
	"Path": "graphql.schema.diff.DiffSet.diffSet",
	"Comment": "creates a diff set out of the result of 2 introspection queries.",
	"Method": "DiffSet diffSet(Map<String, Object> introspectionOld,Map<String, Object> introspectionNew,DiffSet diffSet,GraphQLSchema schemaOld,GraphQLSchema schemaNew){\r\n    Map<String, Object> introspectionOld = introspect(schemaOld);\r\n    Map<String, Object> introspectionNew = introspect(schemaNew);\r\n    return diffSet(introspectionOld, introspectionNew);\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlusBuilder.setOnItemClickListener",
	"Comment": "set an item click listener when list or grid holder is chosen. in that way you can have callbacks when oneof your items is clicked",
	"Method": "DialogPlusBuilder setOnItemClickListener(OnItemClickListener listener){\r\n    this.onItemClickListener = listener;\r\n    return this;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.enclosingMethod",
	"Comment": "matches an ast node which is enclosed by a method node that matches the given matcher.",
	"Method": "Enclosing.Method<T> enclosingMethod(Matcher<MethodTree> matcher){\r\n    return new Enclosing.Method(matcher);\r\n}"
}, {
	"Path": "feign.reactive.ReactiveDelegatingContract.isReactive",
	"Comment": "ensure that the type provided implements a reactive streams publisher.",
	"Method": "boolean isReactive(Type type){\r\n    if (!ParameterizedType.class.isAssignableFrom(type.getClass())) {\r\n        return false;\r\n    }\r\n    ParameterizedType parameterizedType = (ParameterizedType) type;\r\n    Type raw = parameterizedType.getRawType();\r\n    return Arrays.asList(((Class) raw).getInterfaces()).contains(Publisher.class);\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.model.AbstractGCEvent.getGeneration",
	"Comment": "returns the generation of the event including generation of detail events if present.",
	"Method": "Generation getGeneration(Generation getGeneration,Generation getGeneration){\r\n    if (generation == null) {\r\n        if (!hasDetails()) {\r\n            generation = getExtendedType().getGeneration();\r\n        } else {\r\n            Set<Generation> generationSet = new TreeSet<Generation>();\r\n            for (T detailEvent : details) {\r\n                generationSet.add(detailEvent.getExtendedType().getGeneration());\r\n            }\r\n            if (generationSet.size() > 1 || generationSet.contains(Generation.ALL)) {\r\n                generation = Generation.ALL;\r\n            } else if (generationSet.size() == 1) {\r\n                generation = generationSet.iterator().next();\r\n            } else {\r\n                generation = Generation.YOUNG;\r\n            }\r\n        }\r\n    }\r\n    return generation;\r\n}"
}, {
	"Path": "feign.RequestTemplate.queryLine",
	"Comment": "the query string for the template. expressions are not resolved.",
	"Method": "String queryLine(){\r\n    StringBuilder queryString = new StringBuilder();\r\n    if (!this.queries.isEmpty()) {\r\n        Iterator<QueryTemplate> iterator = this.queries.values().iterator();\r\n        while (iterator.hasNext()) {\r\n            QueryTemplate queryTemplate = iterator.next();\r\n            String query = queryTemplate.toString();\r\n            if (query != null && !query.isEmpty()) {\r\n                queryString.append(query);\r\n                if (iterator.hasNext()) {\r\n                    queryString.append(\"&\");\r\n                }\r\n            }\r\n        }\r\n    }\r\n    String result = queryString.toString();\r\n    if (result.endsWith(\"&\")) {\r\n        result = result.substring(0, result.length() - 1);\r\n    }\r\n    if (!result.isEmpty()) {\r\n        result = \"?\" + result;\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "graphql.execution.NonNullableFieldValidator.validate",
	"Comment": "called to check that a value is non null if the type requires it to be non null",
	"Method": "T validate(ExecutionPath path,T result){\r\n    if (result == null) {\r\n        if (executionStepInfo.isNonNullType()) {\r\n            NonNullableFieldWasNullException nonNullException = new NonNullableFieldWasNullException(executionStepInfo, path);\r\n            executionContext.addError(new NonNullableFieldWasNullError(nonNullException), path);\r\n            throw nonNullException;\r\n        }\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "graphql.schema.GraphQLInterfaceType.transform",
	"Comment": "this helps you transform the current graphqlinterfacetype into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLInterfaceType transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newInterface(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "graphql.schema.GraphQLCodeRegistry.getTypeResolver",
	"Comment": "returns the type resolver associated with this interface type",
	"Method": "TypeResolver getTypeResolver(GraphQLInterfaceType interfaceType,TypeResolver getTypeResolver,GraphQLUnionType unionType,TypeResolver getTypeResolver,GraphQLInterfaceType interfaceType,TypeResolver getTypeResolver,GraphQLUnionType unionType){\r\n    return getTypeResolverForUnion(unionType, typeResolverMap);\r\n}"
}, {
	"Path": "hex.Model.deviance",
	"Comment": "deviance of given distribution function at predicted value f",
	"Method": "double deviance(double w,double y,double f,double deviance){\r\n    if (scoringInfo != null)\r\n        return last_scored().cross_validation ? last_scored().scored_xval._mean_residual_deviance : last_scored().validation ? last_scored().scored_valid._mean_residual_deviance : last_scored().scored_train._mean_residual_deviance;\r\n    ModelMetrics mm = _output._cross_validation_metrics != null ? _output._cross_validation_metrics : _output._validation_metrics != null ? _output._validation_metrics : _output._training_metrics;\r\n    if (mm == null)\r\n        return Double.NaN;\r\n    return ((ModelMetricsRegression) mm)._mean_residual_deviance;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.AbstractReturnValueIgnored.describe",
	"Comment": "fixes the error by assigning the result of the call to the receiver reference, or deleting themethod call.",
	"Method": "Description describe(MethodInvocationTree methodInvocationTree,VisitorState state){\r\n    ExpressionTree identifierExpr = ASTHelpers.getRootAssignable(methodInvocationTree);\r\n    String identifierStr = null;\r\n    Type identifierType = null;\r\n    if (identifierExpr != null) {\r\n        identifierStr = identifierExpr.toString();\r\n        if (identifierExpr instanceof JCIdent) {\r\n            identifierType = ((JCIdent) identifierExpr).sym.type;\r\n        } else if (identifierExpr instanceof JCFieldAccess) {\r\n            identifierType = ((JCFieldAccess) identifierExpr).sym.type;\r\n        } else {\r\n            throw new IllegalStateException(\"Expected a JCIdent or a JCFieldAccess\");\r\n        }\r\n    }\r\n    Type returnType = ASTHelpers.getReturnType(((JCMethodInvocation) methodInvocationTree).getMethodSelect());\r\n    Fix fix;\r\n    if (identifierStr != null && !\"this\".equals(identifierStr) && returnType != null && state.getTypes().isAssignable(returnType, identifierType)) {\r\n        fix = SuggestedFix.prefixWith(methodInvocationTree, identifierStr + \" = \");\r\n    } else {\r\n        Tree parent = state.getPath().getParentPath().getLeaf();\r\n        fix = SuggestedFix.delete(parent);\r\n    }\r\n    return describeMatch(methodInvocationTree, fix);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.argumentselectiondefects.EnclosedByReverseHeuristic.isAcceptableChange",
	"Comment": "return true if this call is not enclosed in a method call about reversing things",
	"Method": "boolean isAcceptableChange(Changes changes,Tree node,MethodSymbol symbol,VisitorState state){\r\n    return findReverseWordsMatchInParentNodes(state) == null;\r\n}"
}, {
	"Path": "graphql.schema.GraphQLInputObjectField.transform",
	"Comment": "this helps you transform the current graphqlinputobjectfield into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLInputObjectField transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newInputObjectField(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "hex.CrossValidFoldAssignmentsTest.checkImplicitFoldAssignmentsAreKeptWithoutMakeCopy",
	"Comment": "checks that implicitly generated fold column is preserved after model is built",
	"Method": "void checkImplicitFoldAssignmentsAreKeptWithoutMakeCopy(){\r\n    final int nfolds = 3;\r\n    Frame tfr = null;\r\n    Frame cvFoldAssignmentFrame = null;\r\n    GBMModel gbm = null;\r\n    try {\r\n        tfr = parse_test_file(\"smalldata/iris/iris_wheader.csv\");\r\n        GBMModel.GBMParameters parms = new GBMModel.GBMParameters();\r\n        parms._train = tfr._key;\r\n        parms._response_column = \"class\";\r\n        parms._ntrees = 1;\r\n        parms._max_depth = 1;\r\n        parms._nfolds = nfolds;\r\n        parms._distribution = DistributionFamily.multinomial;\r\n        parms._keep_cross_validation_predictions = false;\r\n        parms._keep_cross_validation_fold_assignment = true;\r\n        GBM job = new GBM(parms);\r\n        gbm = job.trainModel().get();\r\n        assertNotNull(gbm._output._cross_validation_fold_assignment_frame_id);\r\n        cvFoldAssignmentFrame = DKV.getGet(gbm._output._cross_validation_fold_assignment_frame_id);\r\n        assertNotNull(cvFoldAssignmentFrame);\r\n        assertEquals(tfr.numRows(), cvFoldAssignmentFrame.numRows());\r\n        assertEquals(tfr.numRows(), ArrayUtils.sum(new CheckFoldTask(nfolds).doAll(cvFoldAssignmentFrame)._foldCnt));\r\n    } finally {\r\n        if (tfr != null)\r\n            tfr.remove();\r\n        if (gbm != null) {\r\n            gbm.delete();\r\n            gbm.deleteCrossValidationModels();\r\n        }\r\n        if (cvFoldAssignmentFrame != null)\r\n            cvFoldAssignmentFrame.delete();\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.derby.DerbySchema.generateDropStatements",
	"Comment": "generate the statements for dropping all the objects of this type in this schema.",
	"Method": "List<String> generateDropStatements(String objectType,List<String> objectNames,String dropStatementSuffix){\r\n    List<String> statements = new ArrayList();\r\n    for (String objectName : objectNames) {\r\n        String dropStatement = \"DROP \" + objectType + \" \" + database.quote(name, objectName) + \" \" + dropStatementSuffix;\r\n        statements.add(dropStatement);\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "jsr166y.ForkJoinTask.getPool",
	"Comment": "returns the pool hosting the current task execution, or nullif this task is executing outside of any forkjoinpool.",
	"Method": "ForkJoinPool getPool(){\r\n    Thread t = Thread.currentThread();\r\n    return (t instanceof ForkJoinWorkerThread) ? ((ForkJoinWorkerThread) t).pool : null;\r\n}"
}, {
	"Path": "feign.RequestTemplate.variables",
	"Comment": "list all of the template variable expressions for this template.",
	"Method": "List<String> variables(){\r\n    List<String> variables = new ArrayList(this.uriTemplate.getVariables());\r\n    for (QueryTemplate queryTemplate : this.queries.values()) {\r\n        variables.addAll(queryTemplate.getVariables());\r\n    }\r\n    for (HeaderTemplate headerTemplate : this.headers.values()) {\r\n        variables.addAll(headerTemplate.getVariables());\r\n    }\r\n    variables.addAll(this.body.getVariables());\r\n    return variables;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.db2.DB2Schema.generateDropStatements",
	"Comment": "generates drop statements for this type of table, representing this type of object in this schema.",
	"Method": "List<String> generateDropStatements(String tableType,String objectType){\r\n    String dropTablesGenQuery = \"select TABNAME from SYSCAT.TABLES where TYPE='\" + tableType + \"' and TABSCHEMA = '\" + name + \"'\";\r\n    return buildDropStatements(\"DROP \" + objectType, dropTablesGenQuery);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.AbbreviationUtils.abbreviateScript",
	"Comment": "abbreviates this script to a length that will fit in the database.",
	"Method": "String abbreviateScript(String script){\r\n    if (script == null) {\r\n        return null;\r\n    }\r\n    if (script.length() <= 1000) {\r\n        return script;\r\n    }\r\n    return \"...\" + script.substring(3, 1000);\r\n}"
}, {
	"Path": "graphql.schema.GraphQLTypeUtil.unwrapAll",
	"Comment": "unwraps all layers of the type or just returns the type again if its not a wrapped type",
	"Method": "GraphQLUnmodifiedType unwrapAll(GraphQLType type){\r\n    while (true) {\r\n        if (isNotWrapped(type)) {\r\n            return (GraphQLUnmodifiedType) type;\r\n        }\r\n        type = unwrapOne(type);\r\n    }\r\n}"
}, {
	"Path": "graphql.execution.instrumentation.tracing.TracingSupport.snapshotTracingData",
	"Comment": "this will snapshot this tracing and return a map of the results",
	"Method": "Map<String, Object> snapshotTracingData(){\r\n    Map<String, Object> traceMap = new LinkedHashMap();\r\n    traceMap.put(\"version\", 1L);\r\n    traceMap.put(\"startTime\", rfc3339(startRequestTime));\r\n    traceMap.put(\"endTime\", rfc3339(Instant.now()));\r\n    traceMap.put(\"duration\", System.nanoTime() - startRequestNanos);\r\n    traceMap.put(\"parsing\", copyMap(parseMap));\r\n    traceMap.put(\"validation\", copyMap(validationMap));\r\n    traceMap.put(\"execution\", executionData());\r\n    return traceMap;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.cockroachdb.CockroachDBSchema.generateDropStatementsForSequences",
	"Comment": "generates the statements for dropping the sequences in this schema.",
	"Method": "List<String> generateDropStatementsForSequences(){\r\n    List<String> names = jdbcTemplate.queryForStringList(\"SELECT sequence_name FROM information_schema.sequences\" + \" WHERE sequence_catalog=? AND sequence_schema='public'\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (String name : names) {\r\n        statements.add(\"DROP SEQUENCE IF EXISTS \" + database.quote(this.name, name) + \" CASCADE\");\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.NonAtomicVolatileUpdate.variableFromAssignmentTree",
	"Comment": "extracts the variable from an assignmenttree and applies a matcher to it.",
	"Method": "Matcher<AssignmentTree> variableFromAssignmentTree(Matcher<ExpressionTree> exprMatcher){\r\n    return new Matcher<AssignmentTree>() {\r\n        @Override\r\n        public boolean matches(AssignmentTree tree, VisitorState state) {\r\n            return exprMatcher.matches(tree.getVariable(), state);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.NonAtomicVolatileUpdate.variableFromAssignmentTree",
	"Comment": "extracts the variable from an assignmenttree and applies a matcher to it.",
	"Method": "Matcher<AssignmentTree> variableFromAssignmentTree(Matcher<ExpressionTree> exprMatcher){\r\n    return exprMatcher.matches(tree.getVariable(), state);\r\n}"
}, {
	"Path": "feign.benchmark.RealRequestBenchmarks.query_feignUsingOkHttp",
	"Comment": "how fast can we execute get commands synchronously using feign?",
	"Method": "boolean query_feignUsingOkHttp(){\r\n    try (Response ignored = okFeign.query()) {\r\n        return true;\r\n    }\r\n}"
}, {
	"Path": "com.alibaba.excel.util.CollectionUtils.contains",
	"Comment": "check whether the given enumeration contains the given element.",
	"Method": "boolean contains(Iterator<?> iterator,Object element,boolean contains,Enumeration<?> enumeration,Object element){\r\n    if (enumeration != null) {\r\n        while (enumeration.hasMoreElements()) {\r\n            Object candidate = enumeration.nextElement();\r\n            if (ObjectUtils.nullSafeEquals(candidate, element)) {\r\n                return true;\r\n            }\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "water.rapids.ast.prims.assign.AstRecAsgnHelper.createValueSetter",
	"Comment": "create an instance of valuesetter for a given scalar value.it creates setter of the appropriate type based on the type of the underlying vec.",
	"Method": "ValueSetter createValueSetter(Vec v,Object value){\r\n    if (value == null) {\r\n        return new NAValueSetter();\r\n    }\r\n    switch(v.get_type()) {\r\n        case Vec.T_CAT:\r\n            return new CatValueSetter(v.domain(), value);\r\n        case Vec.T_NUM:\r\n        case Vec.T_TIME:\r\n            return new NumValueSetter(value);\r\n        case Vec.T_STR:\r\n            return new StrValueSetter(value);\r\n        case Vec.T_UUID:\r\n            return new UUIDValueSetter(value);\r\n        default:\r\n            throw new IllegalArgumentException(\"Cannot create ValueSetter for a Vec of type = \" + v.get_type_str());\r\n    }\r\n}"
}, {
	"Path": "water.api.ModelMetricsHandler.make",
	"Comment": "make a model metrics object from actual and predicted values",
	"Method": "ModelMetricsMakerSchemaV3 make(int version,ModelMetricsMakerSchemaV3 s){\r\n    if (null == s.predictions_frame)\r\n        throw new H2OIllegalArgumentException(\"predictions_frame\", \"make\", s.predictions_frame);\r\n    Frame pred = DKV.getGet(s.predictions_frame);\r\n    if (null == pred)\r\n        throw new H2OKeyNotFoundArgumentException(\"predictions_frame\", \"make\", s.predictions_frame);\r\n    if (null == s.actuals_frame)\r\n        throw new H2OIllegalArgumentException(\"actuals_frame\", \"make\", s.actuals_frame);\r\n    Frame act = DKV.getGet(s.actuals_frame);\r\n    if (null == act)\r\n        throw new H2OKeyNotFoundArgumentException(\"actuals_frame\", \"make\", s.actuals_frame);\r\n    if (s.domain == null) {\r\n        if (pred.numCols() != 1) {\r\n            throw new H2OIllegalArgumentException(\"predictions_frame\", \"make\", \"For regression problems (domain=null), the predictions_frame must have exactly 1 column.\");\r\n        }\r\n        ModelMetricsRegression mm = ModelMetricsRegression.make(pred.anyVec(), act.anyVec(), s.distribution);\r\n        s.model_metrics = new ModelMetricsRegressionV3().fillFromImpl(mm);\r\n    } else if (s.domain.length == 2) {\r\n        if (pred.numCols() != 1) {\r\n            throw new H2OIllegalArgumentException(\"predictions_frame\", \"make\", \"For domains with 2 class labels, the predictions_frame must have exactly one column containing the class-1 probabilities.\");\r\n        }\r\n        ModelMetricsBinomial mm = ModelMetricsBinomial.make(pred.anyVec(), act.anyVec(), s.domain);\r\n        s.model_metrics = new ModelMetricsBinomialV3().fillFromImpl(mm);\r\n    } else if (s.domain.length > 2) {\r\n        if (pred.numCols() != s.domain.length) {\r\n            throw new H2OIllegalArgumentException(\"predictions_frame\", \"make\", \"For domains with \" + s.domain.length + \" class labels, the predictions_frame must have exactly \" + s.domain.length + \" columns containing the class-probabilities.\");\r\n        }\r\n        if (s.distribution == DistributionFamily.ordinal) {\r\n            ModelMetricsOrdinal mm = ModelMetricsOrdinal.make(pred, act.anyVec(), s.domain);\r\n            s.model_metrics = new ModelMetricsOrdinalV3().fillFromImpl(mm);\r\n        } else {\r\n            ModelMetricsMultinomial mm = ModelMetricsMultinomial.make(pred, act.anyVec(), s.domain);\r\n            s.model_metrics = new ModelMetricsMultinomialV3().fillFromImpl(mm);\r\n        }\r\n    } else {\r\n        throw H2O.unimpl();\r\n    }\r\n    return s;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.GCViewerGuiMenuBar.removeFromWindowMenuGroup",
	"Comment": "remove a menuitem from the window menu including removal of the group.",
	"Method": "void removeFromWindowMenuGroup(JMenuItem menuItem){\r\n    windowMenu.remove(menuItem);\r\n    windowMenuCheckBoxGroup.remove(menuItem);\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.Utils.getView",
	"Comment": "this will be called in order to create view, if the given view is not null,it will be used directly, otherwise it will check the resourceid",
	"Method": "View getView(Context context,int resourceId,View view){\r\n    LayoutInflater inflater = LayoutInflater.from(context);\r\n    if (view != null) {\r\n        return view;\r\n    }\r\n    if (resourceId != INVALID) {\r\n        view = inflater.inflate(resourceId, null);\r\n    }\r\n    return view;\r\n}"
}, {
	"Path": "water.rapids.ast.prims.advmath.AstCorrelation.scalar",
	"Comment": "pearson correlation for one row, which will return a scalar value.",
	"Method": "ValNum scalar(Frame frx,Frame fry,Mode mode){\r\n    if (frx.numCols() != fry.numCols())\r\n        throw new IllegalArgumentException(\"Single rows must have the same number of columns, found \" + frx.numCols() + \" and \" + fry.numCols());\r\n    Vec[] vecxs = frx.vecs();\r\n    Vec[] vecys = fry.vecs();\r\n    double xmean = 0;\r\n    double ymean = 0;\r\n    double xvar = 0;\r\n    double yvar = 0;\r\n    double xsd;\r\n    double ysd;\r\n    double ncols = fry.numCols();\r\n    double NACount = 0;\r\n    double xval;\r\n    double yval;\r\n    double ss = 0;\r\n    for (int r = 0; r < ncols; r++) {\r\n        xval = vecxs[r].at(0);\r\n        yval = vecys[r].at(0);\r\n        if (Double.isNaN(xval) || Double.isNaN(yval))\r\n            NACount++;\r\n        else {\r\n            xmean += xval;\r\n            ymean += yval;\r\n        }\r\n    }\r\n    xmean /= (ncols - NACount);\r\n    ymean /= (ncols - NACount);\r\n    for (int r = 0; r < ncols; r++) {\r\n        xval = vecxs[r].at(0);\r\n        yval = vecys[r].at(0);\r\n        if (!(Double.isNaN(xval) || Double.isNaN(yval))) {\r\n            xvar += Math.pow((vecxs[r].at(0) - xmean), 2);\r\n            yvar += Math.pow((vecys[r].at(0) - ymean), 2);\r\n            ss += (vecxs[r].at(0) - xmean) * (vecys[r].at(0) - ymean);\r\n        }\r\n    }\r\n    xsd = Math.sqrt(xvar / (ncols - 1 - NACount));\r\n    ysd = Math.sqrt(yvar / (ncols - 1 - NACount));\r\n    double denom = xsd * ysd;\r\n    if (NACount != 0) {\r\n        if (mode.equals(Mode.AllObs))\r\n            throw new IllegalArgumentException(\"Mode is 'all.obs' but NAs are present\");\r\n        if (mode.equals(Mode.Everything))\r\n            return new ValNum(Double.NaN);\r\n    }\r\n    return new ValNum((ss / (ncols - NACount - 1)) / denom);\r\n}"
}, {
	"Path": "water.H2O.technote",
	"Comment": "return an error message with an accompanying list of urls to help the user get more detailed information.",
	"Method": "String technote(int number,String message,String technote,int[] numbers,String message){\r\n    StringBuilder sb = new StringBuilder().append(message).append(\"\\n\").append(\"\\n\").append(\"For more information visit:\\n\");\r\n    for (int number : numbers) {\r\n        sb.append(\"  http://jira.h2o.ai/browse/TN-\").append(Integer.toString(number)).append(\"\\n\");\r\n    }\r\n    return sb.toString();\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.UnittestHelper.getResource",
	"Comment": "get url name of resource and check if it exists somewhere in the classpath.",
	"Method": "URL getResource(String name,URL getResource,FOLDER folder,String name){\r\n    return getResource(folder.getFolderName() + \"/\" + name);\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.AboutDialog.calculatePreferredSize",
	"Comment": "returns the preferred size to set a component at in order to renderan html string.you can specify the size of one dimension.",
	"Method": "Dimension calculatePreferredSize(JLabel labelWithHtmlText,boolean width,int preferredSize){\r\n    View view = (View) labelWithHtmlText.getClientProperty(BasicHTML.propertyKey);\r\n    view.setSize(width ? preferredSize : 0, width ? 0 : preferredSize);\r\n    float w = view.getPreferredSpan(View.X_AXIS);\r\n    float h = view.getPreferredSpan(View.Y_AXIS);\r\n    return new Dimension((int) Math.ceil(w), (int) Math.ceil(h));\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.AbstractMustBeClosedChecker.enclosingMethod",
	"Comment": "returns the enclosing method of the given visitor state. returns null if the state is within alambda expression or anonymous class.",
	"Method": "MethodTree enclosingMethod(VisitorState state){\r\n    for (Tree node : state.getPath().getParentPath()) {\r\n        switch(node.getKind()) {\r\n            case LAMBDA_EXPRESSION:\r\n            case NEW_CLASS:\r\n                return null;\r\n            case METHOD:\r\n                return (MethodTree) node;\r\n            default:\r\n                break;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.google.errorprone.names.LevenshteinEditDistance.getNormalizedEditDistance",
	"Comment": "returns a normalized edit distance between 0 and 1. this is useful if you are comparing oraggregating distances of different pairs of strings",
	"Method": "double getNormalizedEditDistance(String source,String target,boolean caseSensitive){\r\n    if (isEmptyOrWhitespace(source) && isEmptyOrWhitespace(target)) {\r\n        return 0.0;\r\n    }\r\n    return (double) getEditDistance(source, target, caseSensitive) / (double) getWorstCaseEditDistance(source.length(), target.length());\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.GCViewerArgsParser.parseArguments",
	"Comment": "parse arguments given in parameter. if an illegal argument is given, an exception is thrown.",
	"Method": "void parseArguments(String[] args){\r\n    List<String> argsList = new ArrayList<String>(Arrays.asList(args));\r\n    int typeIdx = argsList.indexOf(\"-t\");\r\n    if (typeIdx != -1 && argsList.size() > (typeIdx + 1)) {\r\n        type = parseType(argsList.get(typeIdx + 1));\r\n        argsList.remove(typeIdx);\r\n        argsList.remove(typeIdx);\r\n    } else if (typeIdx != -1) {\r\n        argsList.remove(typeIdx);\r\n    }\r\n    argumentCount = argsList.size();\r\n    gcFile = safeGetArgument(argsList, ARG_POS_GCFILE);\r\n    summaryFilePath = safeGetArgument(argsList, ARG_POS_SUMMARY_FILE);\r\n    chartFilePath = safeGetArgument(argsList, ARG_POS_CHART_FILE);\r\n}"
}, {
	"Path": "graphql.schema.idl.UnExecutableSchemaGenerator.makeUnExecutableSchema",
	"Comment": "creates just enough runtime wiring to allow a schema to be built but which cantbe sensibly executed",
	"Method": "GraphQLSchema makeUnExecutableSchema(TypeDefinitionRegistry registry){\r\n    RuntimeWiring runtimeWiring = EchoingWiringFactory.newEchoingWiring(wiring -> {\r\n        Map<String, ScalarTypeDefinition> scalars = registry.scalars();\r\n        scalars.forEach((name, v) -> {\r\n            if (!ScalarInfo.isStandardScalar(name)) {\r\n                wiring.scalar(fakeScalar(name));\r\n            }\r\n        });\r\n    });\r\n    return new SchemaGenerator().makeExecutableSchema(registry, runtimeWiring);\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.crawler.CrawlConfig.setDbLockTimeout",
	"Comment": "set the lock timeout for the underlying sleepycat db, in milliseconds. default is 500.",
	"Method": "void setDbLockTimeout(long dbLockTimeout){\r\n    this.dbLockTimeout = dbLockTimeout;\r\n}"
}, {
	"Path": "hex.grid.GridSearch.gridSearch",
	"Comment": "invokes grid search based on specified hyper space walk strategy.it updates passed grid object in distributed store.",
	"Method": "void gridSearch(Grid<MP> grid){\r\n    Model model = null;\r\n    String protoModelKey = grid._key + \"_model_\";\r\n    try {\r\n        HyperSpaceWalker.HyperSpaceIterator<MP> it = _hyperSpaceWalker.iterator();\r\n        int counter = grid.getModelCount();\r\n        while (it.hasNext(model)) {\r\n            if (_job.stop_requested())\r\n                throw new Job.JobCancelledException();\r\n            double max_runtime_secs = it.max_runtime_secs();\r\n            double time_remaining_secs = Double.MAX_VALUE;\r\n            if (max_runtime_secs > 0) {\r\n                time_remaining_secs = it.time_remaining_secs();\r\n                if (time_remaining_secs < 0) {\r\n                    Log.info(\"Grid max_runtime_secs of \" + max_runtime_secs + \" secs has expired; stopping early.\");\r\n                    throw new Job.JobCancelledException();\r\n                }\r\n            }\r\n            MP params;\r\n            try {\r\n                params = it.nextModelParameters(model);\r\n                if (max_runtime_secs > 0) {\r\n                    Log.info(\"Grid time is limited to: \" + max_runtime_secs + \" for grid: \" + grid._key + \". Remaining time is: \" + time_remaining_secs);\r\n                    double scale = params._nfolds > 0 ? params._nfolds + 1 : 1;\r\n                    if (params._max_runtime_secs == 0) {\r\n                        params._max_runtime_secs = time_remaining_secs / scale;\r\n                        Log.info(\"Due to the grid time limit, changing model max runtime to: \" + params._max_runtime_secs + \" secs.\");\r\n                    } else {\r\n                        double was = params._max_runtime_secs;\r\n                        params._max_runtime_secs = Math.min(params._max_runtime_secs, time_remaining_secs / scale);\r\n                        Log.info(\"Due to the grid time limit, changing model max runtime from: \" + was + \" secs to: \" + params._max_runtime_secs + \" secs.\");\r\n                    }\r\n                }\r\n                try {\r\n                    ScoringInfo scoringInfo = new ScoringInfo();\r\n                    scoringInfo.time_stamp_ms = System.currentTimeMillis();\r\n                    model = buildModel(params, grid, ++counter, protoModelKey);\r\n                    if (model != null) {\r\n                        model.fillScoringInfo(scoringInfo);\r\n                        grid.setScoringInfos(ScoringInfo.prependScoringInfo(scoringInfo, grid.getScoringInfos()));\r\n                        ScoringInfo.sort(grid.getScoringInfos(), _hyperSpaceWalker.search_criteria().stopping_metric());\r\n                    }\r\n                } catch (RuntimeException e) {\r\n                    if (!Job.isCancelledException(e)) {\r\n                        StringWriter sw = new StringWriter();\r\n                        PrintWriter pw = new PrintWriter(sw);\r\n                        e.printStackTrace(pw);\r\n                        Log.warn(\"Grid search: model builder for parameters \" + params + \" failed! Exception: \", e, sw.toString());\r\n                    }\r\n                    grid.appendFailedModelParameters(params, e);\r\n                }\r\n            } catch (IllegalArgumentException e) {\r\n                Log.warn(\"Grid search: construction of model parameters failed! Exception: \", e);\r\n                it.modelFailed(model);\r\n                Object[] rawParams = it.getCurrentRawParameters();\r\n                grid.appendFailedModelParameters(rawParams, e);\r\n            } finally {\r\n                _job.update(1);\r\n                grid.update(_job);\r\n            }\r\n            if (model != null && grid.getScoringInfos() != null && _hyperSpaceWalker.stopEarly(model, grid.getScoringInfos())) {\r\n                Log.info(\"Convergence detected based on simple moving average of the loss function. Grid building completed.\");\r\n                break;\r\n            }\r\n        }\r\n        Log.info(\"For grid: \" + grid._key + \" built: \" + grid.getModelCount() + \" models.\");\r\n    } finally {\r\n        grid.unlock(_job);\r\n    }\r\n}"
}, {
	"Path": "com.ramotion.foldingcell.FoldingCell.startExpandHeightAnimation",
	"Comment": "prepare and start height expand animation for foldingcelllayout",
	"Method": "void startExpandHeightAnimation(ArrayList<Integer> viewHeights,int partAnimationDuration){\r\n    if (viewHeights == null || viewHeights.isEmpty())\r\n        throw new IllegalArgumentException(\"ViewHeights array must have at least 2 elements\");\r\n    ArrayList<Animation> heightAnimations = new ArrayList();\r\n    int fromHeight = viewHeights.get(0);\r\n    int delay = 0;\r\n    int animationDuration = partAnimationDuration - delay;\r\n    for (int i = 1; i < viewHeights.size(); i++) {\r\n        int toHeight = fromHeight + viewHeights.get(i);\r\n        HeightAnimation heightAnimation = new HeightAnimation(this, fromHeight, toHeight, animationDuration).withInterpolator(new DecelerateInterpolator());\r\n        heightAnimation.setStartOffset(delay);\r\n        heightAnimations.add(heightAnimation);\r\n        fromHeight = toHeight;\r\n    }\r\n    createAnimationChain(heightAnimations, this);\r\n    this.startAnimation(heightAnimations.get(0));\r\n}"
}, {
	"Path": "graphql.schema.idl.TypeDefinitionRegistry.isObjectType",
	"Comment": "returns true if the specified type exists in the registry and is an object type",
	"Method": "boolean isObjectType(Type type){\r\n    return getType(type, ObjectTypeDefinition.class).isPresent();\r\n}"
}, {
	"Path": "hex.deeplearning.Neurons.init",
	"Comment": "initialization of the parameters and connectivity of a neuron layer",
	"Method": "void init(Neurons[] neurons,int index,DeepLearningParameters p,DeepLearningModelInfo minfo,boolean training){\r\n    _index = index - 1;\r\n    params = (DeepLearningParameters) p.clone();\r\n    params._hidden_dropout_ratios = minfo.get_params()._hidden_dropout_ratios;\r\n    params._rate *= Math.pow(params._rate_decay, index - 1);\r\n    params._distribution = minfo.get_params()._distribution;\r\n    _dist = new Distribution(params);\r\n    _a = new Storage.DenseVector[params._mini_batch_size];\r\n    for (int mb = 0; mb < _a.length; ++mb) _a[mb] = new Storage.DenseVector(units);\r\n    if (!(this instanceof Input)) {\r\n        _e = new Storage.DenseVector[params._mini_batch_size];\r\n        for (int mb = 0; mb < _e.length; ++mb) _e[mb] = new Storage.DenseVector(units);\r\n    } else if (params._autoencoder && params._input_dropout_ratio > 0) {\r\n        _origa = new Storage.DenseVector[params._mini_batch_size];\r\n        for (int mb = 0; mb < _origa.length; ++mb) _origa[mb] = new Storage.DenseVector(units);\r\n    }\r\n    if (training && (this instanceof MaxoutDropout || this instanceof TanhDropout || this instanceof RectifierDropout || this instanceof ExpRectifierDropout || this instanceof Input)) {\r\n        _dropout = this instanceof Input ? (params._input_dropout_ratio == 0 ? null : new Dropout(units, params._input_dropout_ratio)) : new Dropout(units, params._hidden_dropout_ratios[_index]);\r\n    }\r\n    if (!(this instanceof Input)) {\r\n        _previous = neurons[_index];\r\n        _minfo = minfo;\r\n        _w = minfo.get_weights(_index);\r\n        _b = minfo.get_biases(_index);\r\n        if (params._autoencoder && params._sparsity_beta > 0 && _index < params._hidden.length) {\r\n            _avg_a = minfo.get_avg_activations(_index);\r\n        }\r\n        if (minfo.has_momenta()) {\r\n            _wm = minfo.get_weights_momenta(_index);\r\n            _bm = minfo.get_biases_momenta(_index);\r\n        }\r\n        if (minfo.adaDelta()) {\r\n            _ada_dx_g = minfo.get_ada_dx_g(_index);\r\n            _bias_ada_dx_g = minfo.get_biases_ada_dx_g(_index);\r\n        }\r\n        _shortcut = (params._fast_mode || (!params._adaptive_rate && !_minfo.has_momenta() && params._l1 == 0.0 && params._l2 == 0.0));\r\n    }\r\n    sanityCheck(training);\r\n}"
}, {
	"Path": "jsr166y.Phaser.getUnarrivedParties",
	"Comment": "returns the number of registered parties that have not yetarrived at the current phase of this phaser. if this phaser hasterminated, the returned value is meaningless and arbitrary.",
	"Method": "int getUnarrivedParties(){\r\n    return unarrivedOf(reconcileState());\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.SqlStatementBuilder.isCommentDirective",
	"Comment": "checks whether this line is in fact a directive disguised as a comment.",
	"Method": "boolean isCommentDirective(String line){\r\n    return false;\r\n}"
}, {
	"Path": "hex.tree.DHistogram.updateHisto",
	"Comment": "update counts in appropriate bins. not thread safe, assumed to have private copy.",
	"Method": "void updateHisto(double[] ws,double[] cs,double[] ys,int[] rows,int hi,int lo){\r\n    for (int r = lo; r < hi; ++r) {\r\n        int k = rows[r];\r\n        double weight = ws[k];\r\n        if (weight == 0)\r\n            continue;\r\n        double col_data = cs[k];\r\n        if (col_data < _min2)\r\n            _min2 = col_data;\r\n        if (col_data > _maxIn)\r\n            _maxIn = col_data;\r\n        double y = ys[k];\r\n        assert (!Double.isNaN(y));\r\n        double wy = weight * y;\r\n        double wyy = wy * y;\r\n        int b = bin(col_data);\r\n        _vals[3 * b + 0] += weight;\r\n        _vals[3 * b + 1] += wy;\r\n        _vals[3 * b + 2] += wyy;\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.constructorOfClass",
	"Comment": "matches a constructor declaration in a specific enclosing class.",
	"Method": "Matcher<MethodTree> constructorOfClass(String className){\r\n    return new Matcher<MethodTree>() {\r\n        @Override\r\n        public boolean matches(MethodTree methodTree, VisitorState state) {\r\n            Symbol symbol = ASTHelpers.getSymbol(methodTree);\r\n            return symbol.getEnclosingElement().getQualifiedName().contentEquals(className) && symbol.isConstructor();\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.constructorOfClass",
	"Comment": "matches a constructor declaration in a specific enclosing class.",
	"Method": "Matcher<MethodTree> constructorOfClass(String className){\r\n    Symbol symbol = ASTHelpers.getSymbol(methodTree);\r\n    return symbol.getEnclosingElement().getQualifiedName().contentEquals(className) && symbol.isConstructor();\r\n}"
}, {
	"Path": "water.api.ModelMetricsHandler.predict",
	"Comment": "score a frame with the given model and return the metrics and the prediction frame.",
	"Method": "ModelMetricsListSchemaV3 predict(int version,ModelMetricsListSchemaV3 s){\r\n    if (s.model == null)\r\n        throw new H2OIllegalArgumentException(\"model\", \"predict\", null);\r\n    if (DKV.get(s.model.name) == null)\r\n        throw new H2OKeyNotFoundArgumentException(\"model\", \"predict\", s.model.name);\r\n    if (s.exemplar_index < 0) {\r\n        if (s.frame == null)\r\n            throw new H2OIllegalArgumentException(\"frame\", \"predict\", null);\r\n        if (DKV.get(s.frame.name) == null)\r\n            throw new H2OKeyNotFoundArgumentException(\"frame\", \"predict\", s.frame.name);\r\n    }\r\n    ModelMetricsList parms = s.createAndFillImpl();\r\n    Frame predictions;\r\n    Frame deviances = null;\r\n    if (!s.reconstruction_error && !s.reconstruction_error_per_feature && s.deep_features_hidden_layer < 0 && !s.project_archetypes && !s.reconstruct_train && !s.leaf_node_assignment && !s.predict_staged_proba && s.exemplar_index < 0) {\r\n        if (null == parms._predictions_name)\r\n            parms._predictions_name = \"predictions\" + Key.make().toString().substring(0, 5) + \"_\" + parms._model._key.toString() + \"_on_\" + parms._frame._key.toString();\r\n        String customMetricFunc = s.custom_metric_func;\r\n        if (customMetricFunc == null) {\r\n            customMetricFunc = parms._model._parms._custom_metric_func;\r\n        }\r\n        predictions = parms._model.score(parms._frame, parms._predictions_name, null, true, CFuncRef.from(customMetricFunc));\r\n        if (s.deviances) {\r\n            if (!parms._model.isSupervised())\r\n                throw new H2OIllegalArgumentException(\"Deviances can only be computed for supervised models.\");\r\n            if (null == parms._deviances_name)\r\n                parms._deviances_name = \"deviances\" + Key.make().toString().substring(0, 5) + \"_\" + parms._model._key.toString() + \"_on_\" + parms._frame._key.toString();\r\n            deviances = parms._model.computeDeviances(parms._frame, predictions, parms._deviances_name);\r\n        }\r\n    } else {\r\n        if (s.deviances)\r\n            throw new H2OIllegalArgumentException(\"Cannot compute deviances in combination with other special predictions.\");\r\n        if (Model.DeepFeatures.class.isAssignableFrom(parms._model.getClass())) {\r\n            if (s.reconstruction_error || s.reconstruction_error_per_feature) {\r\n                if (s.deep_features_hidden_layer >= 0)\r\n                    throw new H2OIllegalArgumentException(\"Can only compute either reconstruction error OR deep features.\", \"\");\r\n                if (null == parms._predictions_name)\r\n                    parms._predictions_name = \"reconstruction_error\" + Key.make().toString().substring(0, 5) + \"_\" + parms._model._key.toString() + \"_on_\" + parms._frame._key.toString();\r\n                predictions = ((Model.DeepFeatures) parms._model).scoreAutoEncoder(parms._frame, Key.make(parms._predictions_name), parms._reconstruction_error_per_feature);\r\n            } else {\r\n                if (s.deep_features_hidden_layer < 0)\r\n                    throw new H2OIllegalArgumentException(\"Deep features hidden layer index must be >= 0.\", \"\");\r\n                if (null == parms._predictions_name)\r\n                    parms._predictions_name = \"deep_features\" + Key.make().toString().substring(0, 5) + \"_\" + parms._model._key.toString() + \"_on_\" + parms._frame._key.toString();\r\n                predictions = ((Model.DeepFeatures) parms._model).scoreDeepFeatures(parms._frame, s.deep_features_hidden_layer);\r\n            }\r\n            predictions = new Frame(Key.<Frame>make(parms._predictions_name), predictions.names(), predictions.vecs());\r\n            DKV.put(predictions._key, predictions);\r\n        } else if (Model.GLRMArchetypes.class.isAssignableFrom(parms._model.getClass())) {\r\n            if (s.project_archetypes) {\r\n                if (parms._predictions_name == null)\r\n                    parms._predictions_name = \"reconstructed_archetypes_\" + Key.make().toString().substring(0, 5) + \"_\" + parms._model._key.toString() + \"_of_\" + parms._frame._key.toString();\r\n                predictions = ((Model.GLRMArchetypes) parms._model).scoreArchetypes(parms._frame, Key.<Frame>make(parms._predictions_name), s.reverse_transform);\r\n            } else {\r\n                assert s.reconstruct_train;\r\n                if (parms._predictions_name == null)\r\n                    parms._predictions_name = \"reconstruction_\" + Key.make().toString().substring(0, 5) + \"_\" + parms._model._key.toString() + \"_of_\" + parms._frame._key.toString();\r\n                predictions = ((Model.GLRMArchetypes) parms._model).scoreReconstruction(parms._frame, Key.<Frame>make(parms._predictions_name), s.reverse_transform);\r\n            }\r\n        } else if (s.leaf_node_assignment) {\r\n            assert (Model.LeafNodeAssignment.class.isAssignableFrom(parms._model.getClass()));\r\n            if (null == parms._predictions_name)\r\n                parms._predictions_name = \"leaf_node_assignment\" + Key.make().toString().substring(0, 5) + \"_\" + parms._model._key.toString() + \"_on_\" + parms._frame._key.toString();\r\n            Model.LeafNodeAssignment.LeafNodeAssignmentType type = null == s.leaf_node_assignment_type ? Model.LeafNodeAssignment.LeafNodeAssignmentType.Path : s.leaf_node_assignment_type;\r\n            predictions = ((Model.LeafNodeAssignment) parms._model).scoreLeafNodeAssignment(parms._frame, type, Key.<Frame>make(parms._predictions_name));\r\n        } else if (s.predict_staged_proba) {\r\n            if (null == parms._predictions_name)\r\n                parms._predictions_name = \"staged_proba_\" + Key.make().toString().substring(0, 5) + \"_\" + parms._model._key.toString() + \"_on_\" + parms._frame._key.toString();\r\n            predictions = ((Model.StagedPredictions) parms._model).scoreStagedPredictions(parms._frame, Key.<Frame>make(parms._predictions_name));\r\n        } else if (s.exemplar_index >= 0) {\r\n            assert (Model.ExemplarMembers.class.isAssignableFrom(parms._model.getClass()));\r\n            if (null == parms._predictions_name)\r\n                parms._predictions_name = \"members_\" + parms._model._key.toString() + \"_for_exemplar_\" + parms._exemplar_index;\r\n            predictions = ((Model.ExemplarMembers) parms._model).scoreExemplarMembers(Key.<Frame>make(parms._predictions_name), parms._exemplar_index);\r\n        } else\r\n            throw new H2OIllegalArgumentException(\"Requires a Deep Learning, GLRM, DRF or GBM model.\", \"Model must implement specific methods.\");\r\n    }\r\n    ModelMetricsListSchemaV3 mm = this.fetch(version, s);\r\n    if (null == mm)\r\n        mm = new ModelMetricsListSchemaV3();\r\n    mm.predictions_frame = new KeyV3.FrameKeyV3(predictions._key);\r\n    if (parms._leaf_node_assignment)\r\n        mm.model_metrics = null;\r\n    if (deviances != null)\r\n        mm.deviances_frame = new KeyV3.FrameKeyV3(deviances._key);\r\n    if (null == mm.model_metrics || 0 == mm.model_metrics.length) {\r\n    } else {\r\n        mm.model_metrics[0].predictions = new FrameV3(predictions, 0, 100);\r\n    }\r\n    return mm;\r\n}"
}, {
	"Path": "water.H2O.getIdleTimeMillis",
	"Comment": "get the number of milliseconds the h2o cluster has been idle.",
	"Method": "long getIdleTimeMillis(){\r\n    long latestEndTimeMillis = -1;\r\n    if (activeRapidsExecs.get() > 0) {\r\n        updateNotIdle();\r\n    } else {\r\n        Job[] jobs = Job.jobs();\r\n        for (int i = jobs.length - 1; i >= 0; i--) {\r\n            Job j = jobs[i];\r\n            if (j.isRunning()) {\r\n                updateNotIdle();\r\n                break;\r\n            }\r\n            if (j.end_time() > latestEndTimeMillis) {\r\n                latestEndTimeMillis = j.end_time();\r\n            }\r\n        }\r\n    }\r\n    long latestTimeMillis = Math.max(latestEndTimeMillis, lastTimeSomethingHappenedMillis);\r\n    long now = System.currentTimeMillis();\r\n    long deltaMillis = now - latestTimeMillis;\r\n    if (deltaMillis < 0) {\r\n        deltaMillis = 0;\r\n    }\r\n    return deltaMillis;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.JUnitMatchers.containsTestMethod",
	"Comment": "returns true if the tree contains a method invocation that looks like a test assertion.",
	"Method": "boolean containsTestMethod(Tree tree){\r\n    return firstNonNull(tree.accept(new TreeScanner<Boolean, Void>() {\r\n        @Override\r\n        public Boolean visitMethodInvocation(MethodInvocationTree node, Void unused) {\r\n            String name = getSymbol(node).getSimpleName().toString();\r\n            return name.contains(\"assert\") || name.contains(\"verify\") || name.contains(\"check\") || name.contains(\"fail\") || name.contains(\"expect\") || firstNonNull(super.visitMethodInvocation(node, null), false);\r\n        }\r\n        @Override\r\n        public Boolean reduce(Boolean a, Boolean b) {\r\n            return firstNonNull(a, false) || firstNonNull(b, false);\r\n        }\r\n    }, null), false);\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.JUnitMatchers.containsTestMethod",
	"Comment": "returns true if the tree contains a method invocation that looks like a test assertion.",
	"Method": "boolean containsTestMethod(Tree tree){\r\n    String name = getSymbol(node).getSimpleName().toString();\r\n    return name.contains(\"assert\") || name.contains(\"verify\") || name.contains(\"check\") || name.contains(\"fail\") || name.contains(\"expect\") || firstNonNull(super.visitMethodInvocation(node, null), false);\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.JUnitMatchers.containsTestMethod",
	"Comment": "returns true if the tree contains a method invocation that looks like a test assertion.",
	"Method": "boolean containsTestMethod(Tree tree){\r\n    return firstNonNull(a, false) || firstNonNull(b, false);\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.validateOnMigrate",
	"Comment": "whether to automatically call validate or not when running migrate.",
	"Method": "FluentConfiguration validateOnMigrate(boolean validateOnMigrate){\r\n    config.setValidateOnMigrate(validateOnMigrate);\r\n    return this;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.schemahistory.SchemaHistory.hasSchemasMarker",
	"Comment": "checks whether the schema history table contains a marker row for schema creation.",
	"Method": "boolean hasSchemasMarker(){\r\n    List<AppliedMigration> appliedMigrations = allAppliedMigrations();\r\n    return !appliedMigrations.isEmpty() && appliedMigrations.get(0).getType() == MigrationType.SCHEMA;\r\n}"
}, {
	"Path": "hex.Model.score0",
	"Comment": "bulk scoring api for one row.chunks are all compatible with the model, and expect the last chunks are for the final distribution and prediction. default method is to just load the data into the tmp array, then call subclass scoring logic.",
	"Method": "double[] score0(Chunk[] chks,double offset,int row_in_chunk,double[] tmp,double[] preds,double[] score0,Chunk chks,double offset,int row_in_chunk,double[] tmp,double[] preds,double[] score0,Chunk chks,int row_in_chunk,double[] tmp,double[] preds,double[] score0,Chunk chks,double offset,int row_in_chunk,double[] tmp,double[] preds,double[] score0,double data,double preds,double[] score0,double data,double preds,double offset){\r\n    assert (offset == 0) : \"Override this method for non-trivial offset!\";\r\n    return score0(data, preds);\r\n}"
}, {
	"Path": "org.cryptomator.ui.controllers.MainController.addVault",
	"Comment": "adds the given directory or selects it if it is already in the list of directories.",
	"Method": "void addVault(Path path,boolean select){\r\n    final Path vaultPath;\r\n    if (path != null && Files.isDirectory(path)) {\r\n        vaultPath = path;\r\n    } else if (path != null && Files.isReadable(path)) {\r\n        vaultPath = path.getParent();\r\n    } else {\r\n        LOG.warn(\"Ignoring attempt to add vault with invalid path: {}\", path);\r\n        return;\r\n    }\r\n    final Vault vault = vaults.stream().filter(v -> v.getPath().equals(vaultPath)).findAny().orElseGet(() -> {\r\n        VaultSettings vaultSettings = VaultSettings.withRandomId();\r\n        vaultSettings.path().set(vaultPath);\r\n        return vaultFactoy.get(vaultSettings);\r\n    });\r\n    if (!vaults.contains(vault)) {\r\n        vaults.add(vault);\r\n    }\r\n    if (select) {\r\n        vaultList.getSelectionModel().select(vault);\r\n        activeController.get().focus();\r\n    }\r\n}"
}, {
	"Path": "jsr166y.Phaser.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    try {\r\n        return sun.misc.Unsafe.getUnsafe();\r\n    } catch (SecurityException se) {\r\n        try {\r\n            return java.security.AccessController.doPrivileged(new java.security.PrivilegedExceptionAction<sun.misc.Unsafe>() {\r\n                public sun.misc.Unsafe run() throws Exception {\r\n                    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n                    f.setAccessible(true);\r\n                    return (sun.misc.Unsafe) f.get(null);\r\n                }\r\n            });\r\n        } catch (java.security.PrivilegedActionException e) {\r\n            throw new RuntimeException(\"Could not initialize intrinsics\", e.getCause());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "jsr166y.Phaser.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n    f.setAccessible(true);\r\n    return (sun.misc.Unsafe) f.get(null);\r\n}"
}, {
	"Path": "graphql.schema.idl.ScalarInfo.isGraphqlSpecifiedScalar",
	"Comment": "returns true if the scalar type is a scalar that is specified by the graphql specification",
	"Method": "boolean isGraphqlSpecifiedScalar(String scalarTypeName,boolean isGraphqlSpecifiedScalar,GraphQLScalarType scalarType){\r\n    return inList(GRAPHQL_SPECIFICATION_SCALARS, scalarType.getName());\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.InconsistentCapitalization.isUpperCaseAndStatic",
	"Comment": "returns true if the given symbol has static modifier and is all upper case.",
	"Method": "boolean isUpperCaseAndStatic(Symbol symbol){\r\n    return symbol.isStatic() && symbol.name.contentEquals(Ascii.toUpperCase(symbol.name.toString()));\r\n}"
}, {
	"Path": "hex.createframe.CreateFrameExecutor.rowsPerChunk",
	"Comment": "compute optimal number of rows per chunk in the resulting frame.",
	"Method": "int rowsPerChunk(){\r\n    return FileVec.calcOptimalChunkSize(estimatedByteSize(), numCols, numCols * 4, Runtime.getRuntime().availableProcessors(), H2O.getCloudSize(), false, false);\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.TestDataReaderJRockit1_6_0.testGenConVerbose",
	"Comment": "this log file sample contains much more information about concurrent eventsthan is currently parsed. still the parser must be able to extract the informationit can parse.",
	"Method": "void testGenConVerbose(){\r\n    DataReader reader = getDataReader(new GcResourceFile(\"SampleJRockit1_6_verbose_gc_mode_gencon.txt\"));\r\n    GCModel model = reader.read();\r\n    assertEquals(\"count\", 15, model.size());\r\n}"
}, {
	"Path": "com.google.errorprone.refaster.Choice.fromOptional",
	"Comment": "returns a choice of the optional value, if it is present, or the empty choice if it is absent.",
	"Method": "Choice<T> fromOptional(Optional<T> optional){\r\n    return optional.isPresent() ? of(optional.get()) : Choice.<T>none();\r\n}"
}, {
	"Path": "com.google.errorprone.suppliers.Suppliers.typeFromString",
	"Comment": "given the string representation of a type, supplies the corresponding type.",
	"Method": "Supplier<Type> typeFromString(String typeString){\r\n    requireNonNull(typeString);\r\n    return new Supplier<Type>() {\r\n        @Override\r\n        public Type get(VisitorState state) {\r\n            return state.getTypeFromString(typeString);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.suppliers.Suppliers.typeFromString",
	"Comment": "given the string representation of a type, supplies the corresponding type.",
	"Method": "Supplier<Type> typeFromString(String typeString){\r\n    return state.getTypeFromString(typeString);\r\n}"
}, {
	"Path": "hex.tree.drf.DRFCheckpointTest.testCheckpointReconstruction4Multinomial",
	"Comment": "test if reconstructed initial frame match the last iterationof drf model builder.this test verify multinominal model.",
	"Method": "void testCheckpointReconstruction4Multinomial(){\r\n    testCheckPointReconstruction(\"smalldata/iris/iris.csv\", 4, true, 5, 3);\r\n}"
}, {
	"Path": "feign.example.wikipedia.WikipediaExample.lazySearch",
	"Comment": "this will lazily continue searches, making new http calls as necessary.",
	"Method": "Iterator<Page> lazySearch(Wikipedia wikipedia,String query){\r\n    final Response<Page> first = wikipedia.search(query);\r\n    if (first.nextOffset == null) {\r\n        return first.iterator();\r\n    }\r\n    return new Iterator<Page>() {\r\n        Iterator<Page> current = first.iterator();\r\n        Long nextOffset = first.nextOffset;\r\n        @Override\r\n        public boolean hasNext() {\r\n            while (!current.hasNext() && nextOffset != null) {\r\n                System.out.println(\"Wow.. even more results than \" + nextOffset);\r\n                Response<Page> nextPage = wikipedia.resumeSearch(query, nextOffset);\r\n                current = nextPage.iterator();\r\n                nextOffset = nextPage.nextOffset;\r\n            }\r\n            return current.hasNext();\r\n        }\r\n        @Override\r\n        public Page next() {\r\n            return current.next();\r\n        }\r\n        @Override\r\n        public void remove() {\r\n            throw new UnsupportedOperationException();\r\n        }\r\n    };\r\n}"
}, {
	"Path": "feign.example.wikipedia.WikipediaExample.lazySearch",
	"Comment": "this will lazily continue searches, making new http calls as necessary.",
	"Method": "Iterator<Page> lazySearch(Wikipedia wikipedia,String query){\r\n    while (!current.hasNext() && nextOffset != null) {\r\n        System.out.println(\"Wow.. even more results than \" + nextOffset);\r\n        Response<Page> nextPage = wikipedia.resumeSearch(query, nextOffset);\r\n        current = nextPage.iterator();\r\n        nextOffset = nextPage.nextOffset;\r\n    }\r\n    return current.hasNext();\r\n}"
}, {
	"Path": "feign.example.wikipedia.WikipediaExample.lazySearch",
	"Comment": "this will lazily continue searches, making new http calls as necessary.",
	"Method": "Iterator<Page> lazySearch(Wikipedia wikipedia,String query){\r\n    return current.next();\r\n}"
}, {
	"Path": "feign.example.wikipedia.WikipediaExample.lazySearch",
	"Comment": "this will lazily continue searches, making new http calls as necessary.",
	"Method": "Iterator<Page> lazySearch(Wikipedia wikipedia,String query){\r\n    throw new UnsupportedOperationException();\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setInitSql",
	"Comment": "the sql statements to run to initialize a new database connection immediately after opening it.",
	"Method": "void setInitSql(String initSql){\r\n    this.initSql = initSql;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.db2.DB2Schema.buildDropStatements",
	"Comment": "builds the drop statements for database objects in this schema.",
	"Method": "List<String> buildDropStatements(String dropPrefix,String query){\r\n    List<String> dropStatements = new ArrayList();\r\n    List<String> dbObjects = jdbcTemplate.queryForStringList(query);\r\n    for (String dbObject : dbObjects) {\r\n        dropStatements.add(dropPrefix + \" \" + database.quote(name, dbObject));\r\n    }\r\n    return dropStatements;\r\n}"
}, {
	"Path": "graphql.schema.GraphQLArgument.transform",
	"Comment": "this helps you transform the current graphqlargument into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLArgument transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newArgument(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.collectionincompatibletype.testdata.CollectionIncompatibleTypeNegativeCases.hashtableContains",
	"Comment": "separate check, hashtablecontains, specifically for them.",
	"Method": "boolean hashtableContains(){\r\n    Hashtable<Integer, String> hashtable = new Hashtable();\r\n    ConcurrentHashMap<Integer, String> concurrentHashMap = new ConcurrentHashMap();\r\n    return hashtable.contains(1) || concurrentHashMap.contains(1);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.oracle.OracleDatabase.getAvailableOptions",
	"Comment": "returns the set of oracle options available on the target database.",
	"Method": "Set<String> getAvailableOptions(){\r\n    return new HashSet(getMainConnection().getJdbcTemplate().queryForStringList(\"SELECT PARAMETER FROM V$OPTION WHERE VALUE = 'TRUE'\"));\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.logging.javautil.JavaUtilLog.log",
	"Comment": "log the message at the specified level with the specified exception if any.",
	"Method": "void log(Level level,String message,Exception e){\r\n    LogRecord record = new LogRecord(level, message);\r\n    record.setLoggerName(logger.getName());\r\n    record.setThrown(e);\r\n    record.setSourceClassName(logger.getName());\r\n    record.setSourceMethodName(getMethodName());\r\n    logger.log(record);\r\n}"
}, {
	"Path": "water.nbhm.ConcurrentAutoTable.get",
	"Comment": "current value of the counter.since other threads are updating furiouslythe value is only approximate, but it includes all counts made by thecurrent thread.requires a pass over the internally striped counters.",
	"Method": "long get(){\r\n    return _cat.sum(0);\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setTarget",
	"Comment": "sets the target version up to which flyway should consider migrations. migrations with a higher version number willbe ignored.",
	"Method": "void setTarget(MigrationVersion target){\r\n    this.target = target;\r\n}"
}, {
	"Path": "jsr166y.ConcurrentLinkedDeque.updateTail",
	"Comment": "guarantees that any node which was unlinked before a call tothis method will be unreachable from tail after it returns.does not guarantee to eliminate slack, only that tail willpoint to a node that was active while this method was running.",
	"Method": "void updateTail(){\r\n    Node<E> t, p, q;\r\n    restartFromTail: while ((t = tail).item == null && (p = t.next) != null) {\r\n        for (; ; ) {\r\n            if ((q = p.next) == null || (q = (p = q).next) == null) {\r\n                if (casTail(t, p))\r\n                    return;\r\n                else\r\n                    continue restartFromTail;\r\n            } else if (t != tail)\r\n                continue restartFromTail;\r\n            else\r\n                p = q;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.batch",
	"Comment": "whether to batch sql statements when executing them. batching can save up to 99 percent of network roundtrips bysending up to 100 statements at once over the network to the database, instead of sending each statementindividually. this is particularly useful for very large sql migrations composed of multiple mb or even gb ofreference data, as this can dramatically reduce the network overhead. this is supported for insert, update,delete, merge and upsert statements. all other statements are automatically executed without batching.flyway pro and flyway enterprise only",
	"Method": "FluentConfiguration batch(boolean batch){\r\n    config.setBatch(batch);\r\n    return this;\r\n}"
}, {
	"Path": "eu.siacs.conversations.utils.MimeUtils.guessExtensionFromMimeType",
	"Comment": "returns the registered extension for the given mime type. note that somemime types map to multiple extensions. this call will return the mostcommon extension for the given mime type.",
	"Method": "String guessExtensionFromMimeType(String mimeType){\r\n    if (mimeType == null || mimeType.isEmpty()) {\r\n        return null;\r\n    }\r\n    return mimeTypeToExtensionMap.get(mimeType.split(\";\")[0]);\r\n}"
}, {
	"Path": "com.google.errorprone.dataflow.nullnesspropagation.NullnessPropagationTransfer.setContext",
	"Comment": "stores the given javac context to find and analyze field initializers. set before analyzing amethod and reset after.",
	"Method": "NullnessPropagationTransfer setContext(Context context){\r\n    Preconditions.checkArgument(context == null || this.context == null, \"Context already set: reset after use and don't use this class concurrently\");\r\n    this.context = context;\r\n    this.traversed.clear();\r\n    this.inferenceResults = null;\r\n    return this;\r\n}"
}, {
	"Path": "graphql.schema.idl.TypeDefinitionRegistry.getTypes",
	"Comment": "returns a list of types in the registry of that specified class",
	"Method": "List<T> getTypes(Class<T> targetClass){\r\n    return types.values().stream().filter(targetClass::isInstance).map(targetClass::cast).collect(Collectors.toList());\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.redshift.RedshiftSchema.generateDropStatementsForViews",
	"Comment": "generates the statements for dropping the views in this schema.",
	"Method": "List<String> generateDropStatementsForViews(){\r\n    List<String> viewNames = // Search for all views\r\n    jdbcTemplate.queryForStringList(\"SELECT relname FROM pg_catalog.pg_class c JOIN pg_namespace n ON n.oid = c.relnamespace\" + \" LEFT JOIN pg_depend dep ON dep.objid = c.oid AND dep.deptype = 'e'\" + \" WHERE c.relkind = 'v' AND  n.nspname = ? AND dep.objid IS NULL\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (String domainName : viewNames) {\r\n        statements.add(\"DROP VIEW IF EXISTS \" + database.quote(name, domainName) + \" CASCADE\");\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.BadComparable.matches",
	"Comment": "matches if this is a narrowing integral cast between signed types where the expression is asubtract.",
	"Method": "boolean matches(TypeCastTree tree,VisitorState state){\r\n    Type treeType = ASTHelpers.getType(tree.getType());\r\n    if (treeType.getTag() != TypeTag.INT) {\r\n        return false;\r\n    }\r\n    ExpressionTree expression = ASTHelpers.stripParentheses(tree.getExpression());\r\n    if (expression.getKind() != Kind.MINUS) {\r\n        return false;\r\n    }\r\n    Type expressionType = getTypeOfSubtract((BinaryTree) expression);\r\n    TypeTag expressionTypeTag = state.getTypes().unboxedTypeOrType(expressionType).getTag();\r\n    return (expressionTypeTag == TypeTag.LONG);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.argumentselectiondefects.LowInformationNameHeuristic.isAcceptableChange",
	"Comment": "return true if this parameter does not match any of the regular expressions in the list ofoverloaded words.",
	"Method": "boolean isAcceptableChange(Changes changes,Tree node,MethodSymbol symbol,VisitorState state){\r\n    return changes.changedPairs().stream().allMatch(p -> findMatch(p.formal()) == null);\r\n}"
}, {
	"Path": "water.Cleaner.run",
	"Comment": "taking the lock... blocking the kicking thread for the duration.",
	"Method": "void run(){\r\n    boolean diskFull = false;\r\n    while (true) {\r\n        Histo h = Histo.current(false);\r\n        long now = System.currentTimeMillis();\r\n        long dirty = _dirty;\r\n        if (h._cached < DESIRED && (now - dirty < 5000)) {\r\n            block_store_cleaner();\r\n            continue;\r\n        }\r\n        now = System.currentTimeMillis();\r\n        _dirty = Long.MAX_VALUE;\r\n        MemoryManager.set_goals(\"preclean\", false);\r\n        boolean force = (h._cached >= DESIRED || !MemoryManager.CAN_ALLOC);\r\n        if (force && diskFull)\r\n            diskFull = isDiskFull();\r\n        long clean_to_age = h.clean_to(force ? DESIRED : (DESIRED >> 1));\r\n        if (!force)\r\n            clean_to_age = Math.max(clean_to_age, now - 5000);\r\n        if (DESIRED == -1)\r\n            clean_to_age = now;\r\n        String s = h + \" DESIRED=\" + (DESIRED >> 20) + \"M dirtysince=\" + (now - dirty) + \" force=\" + force + \" clean2age=\" + (now - clean_to_age);\r\n        if (MemoryManager.canAlloc())\r\n            Log.debug(s);\r\n        else\r\n            System.err.println(s);\r\n        long cleaned = 0;\r\n        long freed = 0;\r\n        long io_ns = 0;\r\n        Object[] kvs = H2O.STORE.raw_array();\r\n        for (int i = 2; i < kvs.length; i += 2) {\r\n            Object ok = kvs[i], ov = kvs[i + 1];\r\n            if (!(ok instanceof Key))\r\n                continue;\r\n            if (!(ov instanceof Value))\r\n                continue;\r\n            Value val = (Value) ov;\r\n            byte[] m = val.rawMem();\r\n            Object p = val.rawPOJO();\r\n            if (m == null && p == null)\r\n                continue;\r\n            if (val.isLockable())\r\n                continue;\r\n            boolean isChunk = p instanceof Chunk && !((Chunk) p).isVolatile();\r\n            long touched = val._lastAccessedTime;\r\n            if (touched > clean_to_age) {\r\n                if (val.isPersisted() && m != null && p != null && !isChunk) {\r\n                    val.freeMem();\r\n                    freed += val._max;\r\n                }\r\n                dirty_store(touched);\r\n                continue;\r\n            }\r\n            if (!H2O.ARGS.cleaner)\r\n                continue;\r\n            if (isChunk && !val.isPersisted() && !diskFull && ((Key) ok).home()) {\r\n                long now_ns = System.nanoTime();\r\n                try {\r\n                    val.storePersist();\r\n                } catch (FileNotFoundException fnfe) {\r\n                    continue;\r\n                } catch (IOException e) {\r\n                    Log.warn(isDiskFull() ? \"Disk full! Disabling swapping to disk.\" + (force ? \" Memory low! Please free some space in \" + H2O.ICE_ROOT + \"!\" : \"\") : \"Disk swapping failed! \" + e.getMessage());\r\n                    diskFull = true;\r\n                }\r\n                if (m == null)\r\n                    m = val.rawMem();\r\n                if (m != null)\r\n                    cleaned += m.length;\r\n                io_ns += System.nanoTime() - now_ns;\r\n            }\r\n            if (isChunk && force && (val.isPersisted() || !((Key) ok).home())) {\r\n                val.freeMem();\r\n                if (m != null)\r\n                    freed += val._max;\r\n                m = null;\r\n                val.freePOJO();\r\n                if (p != null)\r\n                    freed += val._max;\r\n                p = null;\r\n                if (isChunk)\r\n                    freed -= val._max;\r\n            }\r\n            if (m != null && p != null && !isChunk) {\r\n                val.freeMem();\r\n                freed += val._max;\r\n            }\r\n            force = (h._cached >= DESIRED || !MemoryManager.CAN_ALLOC);\r\n        }\r\n        String s1 = \"Cleaner pass took: \" + PrettyPrint.msecs(System.currentTimeMillis() - now, true) + \", spilled \" + PrettyPrint.bytes(cleaned) + \" in \" + PrettyPrint.usecs(io_ns >> 10);\r\n        h = Histo.current(true);\r\n        MemoryManager.set_goals(\"postclean\", false);\r\n        String s2 = h + \" diski_o=\" + PrettyPrint.bytes(cleaned) + \", freed=\" + (freed >> 20) + \"M, DESIRED=\" + (DESIRED >> 20) + \"M\";\r\n        if (MemoryManager.canAlloc())\r\n            Log.debug(s1, s2);\r\n        else\r\n            System.err.println(s1 + \"\\n\" + s2);\r\n        synchronized (this) {\r\n            _did_sweep = true;\r\n            if (DESIRED == -1)\r\n                DESIRED = 0;\r\n            notifyAll();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.cryptomator.common.Optionals.unwrap",
	"Comment": "returns a function that is equivalent to the input function but immediately gets the value of the returned optional when invoked.",
	"Method": "Function<T, R> unwrap(Function<T, Optional<R>> function){\r\n    return t -> function.apply(t).get();\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.getUpperBound",
	"Comment": "returns the upper bound of a type if it has one, or the type itself if not. correctly handleswildcards and capture variables.",
	"Method": "Type getUpperBound(Type type,Types types){\r\n    if (type.hasTag(TypeTag.WILDCARD)) {\r\n        return types.wildUpperBound(type);\r\n    }\r\n    if (type.hasTag(TypeTag.TYPEVAR) && ((TypeVar) type).isCaptured()) {\r\n        return types.cvarUpperBound(type);\r\n    }\r\n    if (type.getUpperBound() != null) {\r\n        return type.getUpperBound();\r\n    }\r\n    return type;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.AnnotationMatcherUtils.getArgument",
	"Comment": "gets the value for an argument, or null if the argument does not exist.",
	"Method": "ExpressionTree getArgument(AnnotationTree annotationTree,String name){\r\n    for (ExpressionTree argumentTree : annotationTree.getArguments()) {\r\n        if (argumentTree.getKind() != Tree.Kind.ASSIGNMENT) {\r\n            continue;\r\n        }\r\n        AssignmentTree assignmentTree = (AssignmentTree) argumentTree;\r\n        if (!assignmentTree.getVariable().toString().equals(name)) {\r\n            continue;\r\n        }\r\n        ExpressionTree expressionTree = assignmentTree.getExpression();\r\n        return expressionTree;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "jsr166y.Phaser.doArrive",
	"Comment": "main implementation for methods arrive and arriveandderegister.manually tuned to speed up and minimize race windows for thecommon case of just decrementing unarrived field.",
	"Method": "int doArrive(int adjust){\r\n    final Phaser root = this.root;\r\n    for (; ; ) {\r\n        long s = (root == this) ? state : reconcileState();\r\n        int phase = (int) (s >>> PHASE_SHIFT);\r\n        if (phase < 0)\r\n            return phase;\r\n        int counts = (int) s;\r\n        int unarrived = (counts == EMPTY) ? 0 : (counts & UNARRIVED_MASK);\r\n        if (unarrived <= 0)\r\n            throw new IllegalStateException(badArrive(s));\r\n        if (UNSAFE.compareAndSwapLong(this, stateOffset, s, s -= adjust)) {\r\n            if (unarrived == 1) {\r\n                long n = s & PARTIES_MASK;\r\n                int nextUnarrived = (int) n >>> PARTIES_SHIFT;\r\n                if (root == this) {\r\n                    if (onAdvance(phase, nextUnarrived))\r\n                        n |= TERMINATION_BIT;\r\n                    else if (nextUnarrived == 0)\r\n                        n |= EMPTY;\r\n                    else\r\n                        n |= nextUnarrived;\r\n                    int nextPhase = (phase + 1) & MAX_PHASE;\r\n                    n |= (long) nextPhase << PHASE_SHIFT;\r\n                    UNSAFE.compareAndSwapLong(this, stateOffset, s, n);\r\n                    releaseWaiters(phase);\r\n                } else if (nextUnarrived == 0) {\r\n                    phase = parent.doArrive(ONE_DEREGISTER);\r\n                    UNSAFE.compareAndSwapLong(this, stateOffset, s, s | EMPTY);\r\n                } else\r\n                    phase = parent.doArrive(ONE_ARRIVAL);\r\n            }\r\n            return phase;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.getModifiers",
	"Comment": "returns the modifiers tree of the given class, method, or variable declaration.",
	"Method": "ModifiersTree getModifiers(Tree tree){\r\n    if (tree instanceof ClassTree) {\r\n        return ((ClassTree) tree).getModifiers();\r\n    } else if (tree instanceof MethodTree) {\r\n        return ((MethodTree) tree).getModifiers();\r\n    } else if (tree instanceof VariableTree) {\r\n        return ((VariableTree) tree).getModifiers();\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.refaster.PlaceholderUnificationVisitor.chooseSubtrees",
	"Comment": "this method, and its overloads, takean initial statefunctions that, given one state, return a branch choosing a subtreea function that takes pieces of a tree type and recomposes them",
	"Method": "Choice<State<R>> chooseSubtrees(State<?> state,Function<State<?>, Choice<? extends State<? extends T>>> choice1,Function<T, R> finalizer,Choice<State<R>> chooseSubtrees,State<?> state,Function<State<?>, Choice<? extends State<? extends T1>>> choice1,Function<State<?>, Choice<? extends State<? extends T2>>> choice2,BiFunction<T1, T2, R> finalizer,Choice<State<R>> chooseSubtrees,State<?> state,Function<State<?>, Choice<? extends State<? extends T1>>> choice1,Function<State<?>, Choice<? extends State<? extends T2>>> choice2,Function<State<?>, Choice<? extends State<? extends T3>>> choice3,TriFunction<T1, T2, T3, R> finalizer,Choice<State<R>> chooseSubtrees,State<?> state,Function<State<?>, Choice<? extends State<? extends T1>>> choice1,Function<State<?>, Choice<? extends State<? extends T2>>> choice2,Function<State<?>, Choice<? extends State<? extends T3>>> choice3,Function<State<?>, Choice<? extends State<? extends T4>>> choice4,QuadFunction<T1, T2, T3, T4, R> finalizer){\r\n    return choice1.apply(state).thenChoose(s1 -> choice2.apply(s1).thenChoose(s2 -> choice3.apply(s2).thenChoose(s3 -> choice4.apply(s3).transform(s4 -> s4.withResult(finalizer.apply(s1.result(), s2.result(), s3.result(), s4.result()))))));\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.log.TextAreaLogHandler.reset",
	"Comment": "resets all internal state to an initial state and is ready to receive log events.",
	"Method": "void reset(){\r\n    textArea.setText(\"\");\r\n    errorCount = 0;\r\n    hasErrors = false;\r\n}"
}, {
	"Path": "hex.glrm.GLRM.init",
	"Comment": "validate all parameters, and prepare the model for training.",
	"Method": "void init(boolean expensive){\r\n    super.init(expensive);\r\n    _ncolX = _parms._k;\r\n    _ncolA = _train == null ? -1 : _train.numCols();\r\n    _ncolY = _train == null ? -1 : LinearAlgebraUtils.numColsExp(_train, true);\r\n    initLoss();\r\n    if (_parms._gamma_x < 0)\r\n        error(\"_gamma_x\", \"gamma must be a non-negative number\");\r\n    if (_parms._gamma_y < 0)\r\n        error(\"_gamma_y\", \"gamma_y must be a non-negative number\");\r\n    if (_parms._max_iterations < 1 || _parms._max_iterations > 1e6)\r\n        error(\"_max_iterations\", \"max_iterations must be between 1 and 1e6 inclusive\");\r\n    if (_parms._init_step_size <= 0)\r\n        error(\"_init_step_size\", \"init_step_size must be a positive number\");\r\n    if (_parms._min_step_size < 0 || _parms._min_step_size > _parms._init_step_size)\r\n        error(\"_min_step_size\", \"min_step_size must be between 0 and \" + _parms._init_step_size);\r\n    if (_parms._recover_svd && (_parms._impute_original && _parms._transform != DataInfo.TransformType.NONE))\r\n        error(\"_recover_svd\", \"_recover_svd and _impute_original cannot both be true if _train\" + \" is transformed\");\r\n    if (_train == null)\r\n        return;\r\n    if (_ncolA < 2)\r\n        error(\"_train\", \"_train must have more than one column\");\r\n    if (_valid != null && _valid.numRows() != _train.numRows())\r\n        error(\"_valid\", \"_valid must have same number of rows as _train\");\r\n    if (_ncolY > 5000)\r\n        warn(\"_train\", \"_train has \" + _ncolY + \" columns when categoricals are expanded. Algorithm\" + \" may be slow.\");\r\n    if (_parms._k < 1 || _parms._k > _ncolY)\r\n        error(\"_k\", \"_k must be between 1 and \" + _ncolY + \" inclusive\");\r\n    if (_parms._user_y != null) {\r\n        if (_parms._init != GlrmInitialization.User)\r\n            error(\"_init\", \"init must be 'User' if providing user-specified points\");\r\n        Frame user_y = _parms._user_y.get();\r\n        assert user_y != null;\r\n        int user_y_cols = _parms._expand_user_y ? _ncolA : _ncolY;\r\n        if (user_y.numCols() != user_y_cols)\r\n            error(\"_user_y\", \"The user-specified Y must have the same number of columns (\" + user_y_cols + \") \" + \"as the training observations\");\r\n        else if (user_y.numRows() != _parms._k)\r\n            error(\"_user_y\", \"The user-specified Y must have k = \" + _parms._k + \" rows\");\r\n        else {\r\n            int zero_vec = 0;\r\n            Vec[] centersVecs = user_y.vecs();\r\n            for (int c = 0; c < _ncolA; c++) {\r\n                if (centersVecs[c].naCnt() > 0) {\r\n                    error(\"_user_y\", \"The user-specified Y cannot contain any missing values\");\r\n                    break;\r\n                } else if (centersVecs[c].isConst() && centersVecs[c].max() == 0)\r\n                    zero_vec++;\r\n            }\r\n            if (zero_vec == _ncolA)\r\n                error(\"_user_y\", \"The user-specified Y cannot all be zero\");\r\n        }\r\n    }\r\n    if (_parms._user_x != null) {\r\n        if (_parms._init != GlrmInitialization.User)\r\n            error(\"_init\", \"init must be 'User' if providing user-specified points\");\r\n        Frame user_x = _parms._user_x.get();\r\n        assert user_x != null;\r\n        if (user_x.numCols() != _parms._k)\r\n            error(\"_user_x\", \"The user-specified X must have k = \" + _parms._k + \" columns\");\r\n        else if (user_x.numRows() != _train.numRows())\r\n            error(\"_user_x\", \"The user-specified X must have the same number of rows \" + \"(\" + _train.numRows() + \") as the training observations\");\r\n        else {\r\n            int zero_vec = 0;\r\n            Vec[] centersVecs = user_x.vecs();\r\n            for (int c = 0; c < _parms._k; c++) {\r\n                if (centersVecs[c].naCnt() > 0) {\r\n                    error(\"_user_x\", \"The user-specified X cannot contain any missing values\");\r\n                    break;\r\n                } else if (centersVecs[c].isConst() && centersVecs[c].max() == 0)\r\n                    zero_vec++;\r\n            }\r\n            if (zero_vec == _parms._k)\r\n                error(\"_user_x\", \"The user-specified X cannot all be zero\");\r\n        }\r\n    }\r\n    for (int i = 0; i < _ncolA; i++) {\r\n        if (_train.vec(i).isString() || _train.vec(i).isUUID())\r\n            throw H2O.unimpl(\"GLRM cannot handle String or UUID data\");\r\n    }\r\n    if (expensive && error_count() == 0)\r\n        checkMemoryFootPrint();\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.StringUtils.tokenizeToStringCollection",
	"Comment": "splits this string into a collection using this delimiter and this group delimiter.",
	"Method": "List<String> tokenizeToStringCollection(String str,String delimiters,List<String> tokenizeToStringCollection,String str,char delimiterChar,char groupDelimiterChar){\r\n    if (str == null) {\r\n        return null;\r\n    }\r\n    List<String> tokens = new ArrayList(str.length() / 5);\r\n    int start = 0;\r\n    int end = 0;\r\n    boolean inGroup = false;\r\n    for (int i = 0; i < str.length(); i++) {\r\n        char c = str.charAt(i);\r\n        if (c == groupDelimiterChar) {\r\n            inGroup = !inGroup;\r\n            addToken(tokens, str, start, end);\r\n            start = i + 1;\r\n            end = start;\r\n        } else if (!inGroup && c == delimiterChar) {\r\n            addToken(tokens, str, start, end);\r\n            start = i + 1;\r\n            end = start;\r\n        } else if (i == start && c == ' ') {\r\n            start++;\r\n            end++;\r\n        } else if (i >= start && c != ' ') {\r\n            end = i + 1;\r\n        }\r\n    }\r\n    addToken(tokens, str, start, end);\r\n    return tokens;\r\n}"
}, {
	"Path": "hex.Model.exportMojo",
	"Comment": "exports a mojo representation of a model to a given location.",
	"Method": "URI exportMojo(String location,boolean force){\r\n    OutputStream os = null;\r\n    try {\r\n        URI targetUri = FileUtils.getURI(location);\r\n        Persist p = H2O.getPM().getPersistForURI(targetUri);\r\n        os = p.create(targetUri.toString(), force);\r\n        ModelMojoWriter mojo = getMojo();\r\n        mojo.writeTo(os);\r\n        os.close();\r\n        return targetUri;\r\n    } finally {\r\n        FileUtils.closeSilently(os);\r\n    }\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.crawler.CrawlController.getCrawlersLocalData",
	"Comment": "once the crawling session finishes the controller collects the local data of the crawlerthreads and stores themin a list.this function returns the reference to this list.",
	"Method": "List<Object> getCrawlersLocalData(){\r\n    return crawlersLocalData;\r\n}"
}, {
	"Path": "com.google.errorprone.apply.ImportStatements.removeAll",
	"Comment": "removes all imports in a collection to this list of imports. does not remove any imports thatare not in the list.",
	"Method": "boolean removeAll(Collection<String> importsToRemove){\r\n    return importStrings.removeAll(importsToRemove);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.argumentselectiondefects.Parameter.isAssignableTo",
	"Comment": "return true if this parameter is assignable to the target parameter. this will considersubclassing, autoboxing and null.",
	"Method": "boolean isAssignableTo(Parameter target,VisitorState state){\r\n    if (state.getTypes().isSameType(type(), Type.noType) || state.getTypes().isSameType(target.type(), Type.noType)) {\r\n        return false;\r\n    }\r\n    try {\r\n        return state.getTypes().isAssignable(type(), target.type());\r\n    } catch (CompletionFailure e) {\r\n        Check.instance(state.context).completionError((DiagnosticPosition) state.getPath().getLeaf(), e);\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "graphql.execution.instrumentation.Instrumentation.beginFieldListComplete",
	"Comment": "this is called just before the complete field list is started.",
	"Method": "InstrumentationContext<ExecutionResult> beginFieldListComplete(InstrumentationFieldCompleteParameters parameters){\r\n    return new SimpleInstrumentationContext();\r\n}"
}, {
	"Path": "com.google.errorprone.suppliers.Suppliers.identitySupplier",
	"Comment": "supplies what was given. useful for adapting to methods that require a supplier.",
	"Method": "Supplier<T> identitySupplier(T toSupply){\r\n    return new Supplier<T>() {\r\n        @Override\r\n        public T get(VisitorState state) {\r\n            return toSupply;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.suppliers.Suppliers.identitySupplier",
	"Comment": "supplies what was given. useful for adapting to methods that require a supplier.",
	"Method": "Supplier<T> identitySupplier(T toSupply){\r\n    return toSupply;\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setTargetAsString",
	"Comment": "sets the target version up to which flyway should consider migrations.migrations with a higher version number will be ignored.",
	"Method": "void setTargetAsString(String target){\r\n    this.target = MigrationVersion.fromVersion(target);\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaTypeExtensionsChecker.checkInputObjectTypeExtensions",
	"Comment": "input object type extensions have the potential to be invalid if incorrectly defined.the named type must already be defined and must be a input object type.all fields of an input object type extension must have unique names.all fields of an input object type extension must not already be a field of the original input object.any directives provided must not already apply to the original input object type.",
	"Method": "void checkInputObjectTypeExtensions(List<GraphQLError> errors,TypeDefinitionRegistry typeRegistry){\r\n    typeRegistry.inputObjectTypeExtensions().forEach((name, extensions) -> {\r\n        checkTypeExtensionHasCorrespondingType(errors, typeRegistry, name, extensions, InputObjectTypeDefinition.class);\r\n        checkTypeExtensionDirectiveRedefinition(errors, typeRegistry, name, extensions, InputObjectTypeDefinition.class);\r\n        extensions.forEach(extension -> {\r\n            List<InputValueDefinition> inputValueDefinitions = extension.getInputValueDefinitions();\r\n            checkNamedUniqueness(errors, inputValueDefinitions, InputValueDefinition::getName, (namedField, fieldDef) -> new NonUniqueNameError(extension, fieldDef));\r\n            inputValueDefinitions.forEach(fld -> checkNamedUniqueness(errors, fld.getDirectives(), Directive::getName, (directiveName, directive) -> new NonUniqueDirectiveError(extension, fld, directiveName)));\r\n            inputValueDefinitions.forEach(fld -> fld.getDirectives().forEach(directive -> {\r\n                checkDeprecatedDirective(errors, directive, () -> new InvalidDeprecationDirectiveError(extension, fld));\r\n                checkNamedUniqueness(errors, directive.getArguments(), Argument::getName, (argumentName, argument) -> new NonUniqueArgumentError(extension, fld, argumentName));\r\n            }));\r\n            forEachBut(extension, extensions, otherTypeExt -> checkForInputValueRedefinition(errors, otherTypeExt, otherTypeExt.getInputValueDefinitions(), inputValueDefinitions));\r\n            Optional<InputObjectTypeDefinition> baseTypeOpt = typeRegistry.getType(extension.getName(), InputObjectTypeDefinition.class);\r\n            baseTypeOpt.ifPresent(baseTypeDef -> checkForInputValueRedefinition(errors, extension, inputValueDefinitions, baseTypeDef.getInputValueDefinitions()));\r\n        });\r\n    });\r\n}"
}, {
	"Path": "graphql.analysis.MaxQueryComplexityInstrumentation.mkAbortException",
	"Comment": "called to generate your own error message or custom exception class",
	"Method": "AbortExecutionException mkAbortException(int totalComplexity,int maxComplexity){\r\n    return new AbortExecutionException(\"maximum query complexity exceeded \" + totalComplexity + \" > \" + maxComplexity);\r\n}"
}, {
	"Path": "graphql.schema.idl.TypeDefinitionRegistry.getImplementationsOf",
	"Comment": "returns the list of object types that implement the given interface type",
	"Method": "List<ObjectTypeDefinition> getImplementationsOf(InterfaceTypeDefinition targetInterface){\r\n    List<ObjectTypeDefinition> objectTypeDefinitions = getTypes(ObjectTypeDefinition.class);\r\n    return objectTypeDefinitions.stream().filter(objectTypeDefinition -> {\r\n        List<Type> implementsList = objectTypeDefinition.getImplements();\r\n        for (Type iFace : implementsList) {\r\n            Optional<InterfaceTypeDefinition> interfaceTypeDef = getType(iFace, InterfaceTypeDefinition.class);\r\n            if (interfaceTypeDef.isPresent()) {\r\n                boolean equals = interfaceTypeDef.get().getName().equals(targetInterface.getName());\r\n                if (equals) {\r\n                    return true;\r\n                }\r\n            }\r\n        }\r\n        return false;\r\n    }).collect(Collectors.toList());\r\n}"
}, {
	"Path": "water.fvec.Vec.makeRand",
	"Comment": "make a new vector initialized to random numbers with the given seed",
	"Method": "Vec makeRand(long seed){\r\n    Vec randVec = makeZero();\r\n    new MRTask() {\r\n        @Override\r\n        public void map(Chunk c) {\r\n            Random rng = new RandomUtils.PCGRNG(c._start, 1);\r\n            for (int i = 0; i < c._len; ++i) {\r\n                rng.setSeed(seed + c._start + i);\r\n                c.set(i, rng.nextFloat());\r\n            }\r\n        }\r\n    }.doAll(randVec);\r\n    return randVec;\r\n}"
}, {
	"Path": "water.fvec.Vec.makeRand",
	"Comment": "make a new vector initialized to random numbers with the given seed",
	"Method": "Vec makeRand(long seed){\r\n    Random rng = new RandomUtils.PCGRNG(c._start, 1);\r\n    for (int i = 0; i < c._len; ++i) {\r\n        rng.setSeed(seed + c._start + i);\r\n        c.set(i, rng.nextFloat());\r\n    }\r\n}"
}, {
	"Path": "com.alibaba.excel.util.ObjectUtils.isCompatibleWithThrowsClause",
	"Comment": "check whether the given exception is compatible with the specifiedexception types, as declared in a throws clause.",
	"Method": "boolean isCompatibleWithThrowsClause(Throwable ex,Class<?> declaredExceptions){\r\n    if (!isCheckedException(ex)) {\r\n        return true;\r\n    }\r\n    if (declaredExceptions != null) {\r\n        for (Class<?> declaredException : declaredExceptions) {\r\n            if (declaredException.isInstance(ex)) {\r\n                return true;\r\n            }\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.isVariable",
	"Comment": "matches an ast node that represents a local variable or parameter.",
	"Method": "Matcher<ExpressionTree> isVariable(){\r\n    return new Matcher<ExpressionTree>() {\r\n        @Override\r\n        public boolean matches(ExpressionTree expressionTree, VisitorState state) {\r\n            Symbol symbol = ASTHelpers.getSymbol(expressionTree);\r\n            if (symbol == null) {\r\n                return false;\r\n            }\r\n            return symbol.getKind() == ElementKind.LOCAL_VARIABLE || symbol.getKind() == ElementKind.PARAMETER;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.isVariable",
	"Comment": "matches an ast node that represents a local variable or parameter.",
	"Method": "Matcher<ExpressionTree> isVariable(){\r\n    Symbol symbol = ASTHelpers.getSymbol(expressionTree);\r\n    if (symbol == null) {\r\n        return false;\r\n    }\r\n    return symbol.getKind() == ElementKind.LOCAL_VARIABLE || symbol.getKind() == ElementKind.PARAMETER;\r\n}"
}, {
	"Path": "eu.siacs.conversations.crypto.sasl.Tokenizer.hasNext",
	"Comment": "returns true if there is at least one more element, false otherwise.",
	"Method": "boolean hasNext(){\r\n    return parts.size() != index + 1;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.FutureReturnValueIgnored.matchMemberReference",
	"Comment": "detect member references that implement an interface that return object, but resolve to amethod that returns future.",
	"Method": "Description matchMemberReference(MemberReferenceTree tree,VisitorState state){\r\n    Description description = super.matchMemberReference(tree, state);\r\n    if (Description.NO_MATCH == description) {\r\n        if (allOf((t, s) -> t.getMode() == ReferenceMode.INVOKE, FutureReturnValueIgnored::isObjectReturningMethodReferenceExpression, not((t, s) -> isWhitelistedInterfaceType(((JCMemberReference) t).type, s)), not((t, s) -> isThrowingFunctionalInterface(s, ((JCMemberReference) t).type)), specializedMatcher()).matches(tree, state)) {\r\n            return describeMatch(tree);\r\n        }\r\n    }\r\n    return description;\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setBatch",
	"Comment": "whether to batch sql statements when executing them. batching can save up to 99 percent of network roundtrips bysending up to 100 statements at once over the network to the database, instead of sending each statementindividually. this is particularly useful for very large sql migrations composed of multiple mb or even gb ofreference data, as this can dramatically reduce the network overhead. this is supported for insert, update,delete, merge and upsert statements. all other statements are automatically executed without batching.flyway pro and flyway enterprise only",
	"Method": "void setBatch(boolean batch){\r\n    throw new org.flywaydb.core.internal.license.FlywayProUpgradeRequiredException(\"batch\");\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.StringUtils.replaceAll",
	"Comment": "replaces all occurrances of this originaltoken in this string with this replacementtoken.",
	"Method": "String replaceAll(String str,String originalToken,String replacementToken){\r\n    return str.replaceAll(Pattern.quote(originalToken), Matcher.quoteReplacement(replacementToken));\r\n}"
}, {
	"Path": "graphql.schema.GraphQLObjectType.transform",
	"Comment": "this helps you transform the current graphqlobjecttype into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLObjectType transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newObject(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "jsr166y.ForkJoinTask.helpExpungeStaleExceptions",
	"Comment": "if lock is available, poll stale refs and remove them.called from forkjoinpool when pools become quiescent.",
	"Method": "void helpExpungeStaleExceptions(){\r\n    final ReentrantLock lock = exceptionTableLock;\r\n    if (lock.tryLock()) {\r\n        try {\r\n            expungeStaleExceptions();\r\n        } finally {\r\n            lock.unlock();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.fixes.SuggestedFixes.compilesWithFix",
	"Comment": "returns true if the current compilation would succeed with the given fix applied. note thatcalling this method is very expensive as it requires rerunning the entire compile, so it shouldbe used with restraint.",
	"Method": "boolean compilesWithFix(Fix fix,VisitorState state){\r\n    if (fix.isEmpty()) {\r\n        return true;\r\n    }\r\n    JCCompilationUnit compilationUnit = (JCCompilationUnit) state.getPath().getCompilationUnit();\r\n    JavaFileObject modifiedFile = compilationUnit.getSourceFile();\r\n    BasicJavacTask javacTask = (BasicJavacTask) state.context.get(JavacTask.class);\r\n    if (javacTask == null) {\r\n        throw new IllegalArgumentException(\"No JavacTask in context.\");\r\n    }\r\n    Arguments arguments = Arguments.instance(javacTask.getContext());\r\n    List<JavaFileObject> fileObjects = new ArrayList(arguments.getFileObjects());\r\n    for (int i = 0; i < fileObjects.size(); i++) {\r\n        final JavaFileObject oldFile = fileObjects.get(i);\r\n        if (modifiedFile.toUri().equals(oldFile.toUri())) {\r\n            DescriptionBasedDiff diff = DescriptionBasedDiff.create(compilationUnit, ImportOrganizer.STATIC_FIRST_ORGANIZER);\r\n            diff.handleFix(fix);\r\n            SourceFile fixSource;\r\n            try {\r\n                fixSource = new SourceFile(modifiedFile.getName(), modifiedFile.getCharContent(false));\r\n            } catch (IOException e) {\r\n                return false;\r\n            }\r\n            diff.applyDifferences(fixSource);\r\n            fileObjects.set(i, new SimpleJavaFileObject(sourceURI(modifiedFile.toUri()), Kind.SOURCE) {\r\n                @Override\r\n                public CharSequence getCharContent(boolean ignoreEncodingErrors) throws IOException {\r\n                    return fixSource.getAsSequence();\r\n                }\r\n            });\r\n            break;\r\n        }\r\n    }\r\n    DiagnosticCollector<JavaFileObject> diagnosticListener = new DiagnosticCollector();\r\n    Context context = new Context();\r\n    Options options = Options.instance(context);\r\n    Options originalOptions = Options.instance(javacTask.getContext());\r\n    for (String key : originalOptions.keySet()) {\r\n        String value = originalOptions.get(key);\r\n        if (key.equals(\"-Xplugin:\") && value.startsWith(\"ErrorProne\")) {\r\n            continue;\r\n        }\r\n        options.put(key, value);\r\n    }\r\n    JavacTask newTask = JavacTool.create().getTask(CharStreams.nullWriter(), state.context.get(JavaFileManager.class), diagnosticListener, ImmutableList.of(), arguments.getClassNames(), fileObjects, context);\r\n    try {\r\n        newTask.analyze();\r\n    } catch (IOException e) {\r\n        throw new UncheckedIOException(e);\r\n    }\r\n    return countErrors(diagnosticListener) == 0;\r\n}"
}, {
	"Path": "com.google.errorprone.fixes.SuggestedFixes.compilesWithFix",
	"Comment": "returns true if the current compilation would succeed with the given fix applied. note thatcalling this method is very expensive as it requires rerunning the entire compile, so it shouldbe used with restraint.",
	"Method": "boolean compilesWithFix(Fix fix,VisitorState state){\r\n    return fixSource.getAsSequence();\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.JUnit4TestNotRun.calledElsewhere",
	"Comment": "whether the given method is called elsewhere in the enclosing class.",
	"Method": "boolean calledElsewhere(MethodTree methodTree,VisitorState state){\r\n    MethodSymbol methodSymbol = getSymbol(methodTree);\r\n    if (methodSymbol == null) {\r\n        return false;\r\n    }\r\n    return state.findEnclosing(ClassTree.class).accept(new TreeScanner<Boolean, Void>() {\r\n        @Override\r\n        public Boolean visitMethodInvocation(MethodInvocationTree callTree, Void unused) {\r\n            if (methodSymbol.equals(getSymbol(callTree.getMethodSelect()))) {\r\n                return true;\r\n            }\r\n            return super.visitMethodInvocation(callTree, unused);\r\n        }\r\n        @Override\r\n        public Boolean reduce(Boolean r1, Boolean r2) {\r\n            r1 = (r1 == null) ? false : r1;\r\n            r2 = (r2 == null) ? false : r2;\r\n            return r1 || r2;\r\n        }\r\n    }, null);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.JUnit4TestNotRun.calledElsewhere",
	"Comment": "whether the given method is called elsewhere in the enclosing class.",
	"Method": "boolean calledElsewhere(MethodTree methodTree,VisitorState state){\r\n    if (methodSymbol.equals(getSymbol(callTree.getMethodSelect()))) {\r\n        return true;\r\n    }\r\n    return super.visitMethodInvocation(callTree, unused);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.JUnit4TestNotRun.calledElsewhere",
	"Comment": "whether the given method is called elsewhere in the enclosing class.",
	"Method": "boolean calledElsewhere(MethodTree methodTree,VisitorState state){\r\n    r1 = (r1 == null) ? false : r1;\r\n    r2 = (r2 == null) ? false : r2;\r\n    return r1 || r2;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.exp.impl.DataWriterFactory.getDataWriter",
	"Comment": "factory method to retrieve one of the datawriter implementations includingthe option to add a map of configuration objects. the map will be passed to the datawriter,which can use its contents.",
	"Method": "DataWriter getDataWriter(File file,DataWriterType type,DataWriter getDataWriter,File file,DataWriterType type,Map<String, Object> configuration){\r\n    FileOutputStream outputStream = new FileOutputStream(file);\r\n    switch(type) {\r\n        case PLAIN:\r\n            return new PlainDataWriter(outputStream);\r\n        case CSV:\r\n            return new CSVDataWriter(outputStream);\r\n        case CSV_TS:\r\n            return new CSVTSDataWriter(outputStream);\r\n        case SIMPLE:\r\n            return new SimpleGcWriter(outputStream);\r\n        case SUMMARY:\r\n            return new SummaryDataWriter(outputStream, configuration);\r\n        case PNG:\r\n            return new PNGDataWriter(outputStream);\r\n        default:\r\n            throw new IOException(LocalisationHelper.getString(\"datawriterfactory_instantiation_failed\") + \" \" + file);\r\n    }\r\n}"
}, {
	"Path": "com.ramotion.foldingcell.FoldingCell.prepareViewsForAnimation",
	"Comment": "create and prepare list of foldingcellviews with different bitmap parts for fold animation",
	"Method": "ArrayList<FoldingCellView> prepareViewsForAnimation(ArrayList<Integer> viewHeights,Bitmap titleViewBitmap,Bitmap contentViewBitmap){\r\n    if (viewHeights == null || viewHeights.isEmpty())\r\n        throw new IllegalStateException(\"ViewHeights array must be not null and not empty\");\r\n    ArrayList<FoldingCellView> partsList = new ArrayList();\r\n    int partWidth = titleViewBitmap.getWidth();\r\n    int yOffset = 0;\r\n    for (int i = 0; i < viewHeights.size(); i++) {\r\n        int partHeight = viewHeights.get(i);\r\n        Bitmap partBitmap = Bitmap.createBitmap(partWidth, partHeight, Bitmap.Config.ARGB_8888);\r\n        Canvas canvas = new Canvas(partBitmap);\r\n        Rect srcRect = new Rect(0, yOffset, partWidth, yOffset + partHeight);\r\n        Rect destRect = new Rect(0, 0, partWidth, partHeight);\r\n        canvas.drawBitmap(contentViewBitmap, srcRect, destRect, null);\r\n        ImageView backView = createImageViewFromBitmap(partBitmap);\r\n        ImageView frontView = null;\r\n        if (i < viewHeights.size() - 1) {\r\n            frontView = (i == 0) ? createImageViewFromBitmap(titleViewBitmap) : createBackSideView(viewHeights.get(i + 1));\r\n        }\r\n        partsList.add(new FoldingCellView(frontView, backView, getContext()));\r\n        yOffset = yOffset + partHeight;\r\n    }\r\n    return partsList;\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.getQueuedSubmissionCount",
	"Comment": "returns an estimate of the number of tasks submitted to thispool that have not yet begun executing.this method may taketime proportional to the number of submissions.",
	"Method": "int getQueuedSubmissionCount(){\r\n    int count = 0;\r\n    WorkQueue[] ws;\r\n    WorkQueue w;\r\n    if ((ws = workQueues) != null) {\r\n        for (int i = 0; i < ws.length; i += 2) {\r\n            if ((w = ws[i]) != null)\r\n                count += w.queueSize();\r\n        }\r\n    }\r\n    return count;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.AbstractToString.isToString",
	"Comment": "classifies expressions that are converted to strings by their enclosing expression.",
	"Method": "ToStringKind isToString(Tree parent,ExpressionTree tree,VisitorState state){\r\n    if (isStringConcat(parent, state)) {\r\n        return ToStringKind.IMPLICIT;\r\n    }\r\n    if (parent instanceof ExpressionTree) {\r\n        ExpressionTree parentExpression = (ExpressionTree) parent;\r\n        if (PRINT_STRING.matches(parentExpression, state)) {\r\n            return ToStringKind.IMPLICIT;\r\n        }\r\n        if (VALUE_OF.matches(parentExpression, state)) {\r\n            return ToStringKind.EXPLICIT;\r\n        }\r\n    }\r\n    return ToStringKind.NONE;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.EnclosingTest.usedInSubTreeOfLoopCondition",
	"Comment": "tests that a node is enclosed by a node many levels up the tree.",
	"Method": "void usedInSubTreeOfLoopCondition(){\r\n    writeFile(\"A.java\", \"public class A {\", \"  A() {\", \"    boolean foo = true;\", \"    for (int i = 0; !!!!!!!!!foo; i++) {}\", \"  }\", \"}\");\r\n    assertCompiles(fooIsUsedUnderLoopCondition(true));\r\n    assertCompiles(fooIsChildOfLoopCondition(false));\r\n    assertCompiles(fooIsUsedUnderLoopStatement(false));\r\n    assertCompiles(fooIsUsedUnderLoopStatementAccordingToBlockOrCase(false));\r\n}"
}, {
	"Path": "hex.svd.SVD.setSVDModel",
	"Comment": "this method may make changes to the dinfo parameters if svd is called by glrm as a init method.",
	"Method": "void setSVDModel(SVDModel model,DataInfo dinfo){\r\n    if (_callFromGLRM) {\r\n        dinfo._normSub = Arrays.copyOf(_glrmModel._output._normSub, _glrmModel._output._normSub.length);\r\n        dinfo._normMul = Arrays.copyOf(_glrmModel._output._normMul, _glrmModel._output._normMul.length);\r\n        dinfo._permutation = Arrays.copyOf(_glrmModel._output._permutation, _glrmModel._output._permutation.length);\r\n        dinfo._numMeans = Arrays.copyOf(dinfo._normSub, dinfo._normSub.length);\r\n        dinfo._nums = _glrmModel._output._nnums;\r\n        dinfo._cats = _glrmModel._output._ncats;\r\n        dinfo._catOffsets = Arrays.copyOf(_glrmModel._output._catOffsets, _glrmModel._output._catOffsets.length);\r\n        model._output._names_expanded = Arrays.copyOf(_glrmModel._output._names_expanded, _glrmModel._output._names_expanded.length);\r\n    } else\r\n        model._output._names_expanded = dinfo.coefNames();\r\n    model._output._normSub = dinfo._normSub == null ? new double[dinfo._nums] : dinfo._normSub;\r\n    if (dinfo._normMul == null) {\r\n        model._output._normMul = new double[dinfo._nums];\r\n        Arrays.fill(model._output._normMul, 1.0);\r\n    } else\r\n        model._output._normMul = dinfo._normMul;\r\n    model._output._permutation = dinfo._permutation;\r\n    model._output._nnums = dinfo._nums;\r\n    model._output._ncats = dinfo._cats;\r\n    model._output._catOffsets = dinfo._catOffsets;\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlus.assignClickListenerRecursively",
	"Comment": "loop among the views in the hierarchy and assign listener to them",
	"Method": "void assignClickListenerRecursively(View parent){\r\n    if (parent == null) {\r\n        return;\r\n    }\r\n    if (parent instanceof ViewGroup) {\r\n        ViewGroup viewGroup = (ViewGroup) parent;\r\n        int childCount = viewGroup.getChildCount();\r\n        for (int i = childCount - 1; i >= 0; i--) {\r\n            View child = viewGroup.getChildAt(i);\r\n            assignClickListenerRecursively(child);\r\n        }\r\n    }\r\n    setClickListener(parent);\r\n}"
}, {
	"Path": "com.google.errorprone.apply.ImportStatements.addAll",
	"Comment": "add all imports in a collection to this list of imports. does not add any imports that arealready in the list.",
	"Method": "boolean addAll(Collection<String> importsToAdd){\r\n    return importStrings.addAll(importsToAdd);\r\n}"
}, {
	"Path": "graphql.schema.idl.TypeDefinitionRegistry.isPossibleType",
	"Comment": "returns true of the abstract type is in implemented by the object type",
	"Method": "boolean isPossibleType(Type abstractType,Type possibleObjectType){\r\n    if (!isInterfaceOrUnion(abstractType)) {\r\n        return false;\r\n    }\r\n    if (!isObjectType(possibleObjectType)) {\r\n        return false;\r\n    }\r\n    ObjectTypeDefinition targetObjectTypeDef = getType(possibleObjectType, ObjectTypeDefinition.class).get();\r\n    TypeDefinition abstractTypeDef = getType(abstractType).get();\r\n    if (abstractTypeDef instanceof UnionTypeDefinition) {\r\n        List<Type> memberTypes = ((UnionTypeDefinition) abstractTypeDef).getMemberTypes();\r\n        for (Type memberType : memberTypes) {\r\n            Optional<ObjectTypeDefinition> checkType = getType(memberType, ObjectTypeDefinition.class);\r\n            if (checkType.isPresent()) {\r\n                if (checkType.get().getName().equals(targetObjectTypeDef.getName())) {\r\n                    return true;\r\n                }\r\n            }\r\n        }\r\n        return false;\r\n    } else {\r\n        InterfaceTypeDefinition iFace = (InterfaceTypeDefinition) abstractTypeDef;\r\n        List<ObjectTypeDefinition> objectTypeDefinitions = getImplementationsOf(iFace);\r\n        return objectTypeDefinitions.stream().anyMatch(od -> od.getName().equals(targetObjectTypeDef.getName()));\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.commandline.Main.dumpConfiguration",
	"Comment": "dumps the configuration to the console when debug output is activated.",
	"Method": "void dumpConfiguration(Properties properties){\r\n    LOG.debug(\"Using configuration:\");\r\n    for (Map.Entry<Object, Object> entry : properties.entrySet()) {\r\n        String value = entry.getValue().toString();\r\n        value = ConfigUtils.PASSWORD.equals(entry.getKey()) ? StringUtils.trimOrPad(\"\", value.length(), '*') : value;\r\n        LOG.debug(entry.getKey() + \" -> \" + value);\r\n    }\r\n}"
}, {
	"Path": "feign.template.UriUtils.encode",
	"Comment": "uri encode the value, using the default charset. already encoded values are skipped.",
	"Method": "String encode(String value,String encode,String value,Charset charset){\r\n    return encodeReserved(value, \"\", charset);\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.isPrimitiveOrBoxedPrimitiveType",
	"Comment": "matches an ast node if its type is a primitive type, or a boxed version of a primitive type.",
	"Method": "Matcher<T> isPrimitiveOrBoxedPrimitiveType(){\r\n    return new Matcher<T>() {\r\n        @Override\r\n        public boolean matches(Tree t, VisitorState state) {\r\n            Type type = getType(t);\r\n            return type != null && state.getTypes().unboxedTypeOrType(type).isPrimitive();\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.isPrimitiveOrBoxedPrimitiveType",
	"Comment": "matches an ast node if its type is a primitive type, or a boxed version of a primitive type.",
	"Method": "Matcher<T> isPrimitiveOrBoxedPrimitiveType(){\r\n    Type type = getType(t);\r\n    return type != null && state.getTypes().unboxedTypeOrType(type).isPrimitive();\r\n}"
}, {
	"Path": "jsr166y.ForkJoinTask.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    try {\r\n        return sun.misc.Unsafe.getUnsafe();\r\n    } catch (SecurityException se) {\r\n        try {\r\n            return java.security.AccessController.doPrivileged(new java.security.PrivilegedExceptionAction<sun.misc.Unsafe>() {\r\n                public sun.misc.Unsafe run() throws Exception {\r\n                    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n                    f.setAccessible(true);\r\n                    return (sun.misc.Unsafe) f.get(null);\r\n                }\r\n            });\r\n        } catch (java.security.PrivilegedActionException e) {\r\n            throw new RuntimeException(\"Could not initialize intrinsics\", e.getCause());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "jsr166y.ForkJoinTask.getUnsafe",
	"Comment": "returns a sun.misc.unsafe.suitable for use in a 3rd party package.replace with a simple call to unsafe.getunsafe when integratinginto a jdk.",
	"Method": "sun.misc.Unsafe getUnsafe(){\r\n    java.lang.reflect.Field f = sun.misc.Unsafe.class.getDeclaredField(\"theUnsafe\");\r\n    f.setAccessible(true);\r\n    return (sun.misc.Unsafe) f.get(null);\r\n}"
}, {
	"Path": "jsr166y.Phaser.badRegister",
	"Comment": "returns message string for bounds exceptions on registration.",
	"Method": "String badRegister(long s){\r\n    return \"Attempt to register more than \" + MAX_PARTIES + \" parties for \" + stateToString(s);\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.skipDefaultResolvers",
	"Comment": "whether flyway should skip the default resolvers. if true, only custom resolvers are used.",
	"Method": "FluentConfiguration skipDefaultResolvers(boolean skipDefaultResolvers){\r\n    config.setSkipDefaultResolvers(skipDefaultResolvers);\r\n    return this;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.TestDataReaderSun1_8_0G1.fullGcWithDetailedSizes",
	"Comment": "in java 8, suddenly the full gc events in g1 got detailed information about the generationsizes again. test, that they are parsed correctly.",
	"Method": "void fullGcWithDetailedSizes(){\r\n    TestLogHandler handler = new TestLogHandler();\r\n    handler.setLevel(Level.WARNING);\r\n    GCResource gcResource = new GcResourceFile(\"byteArray\");\r\n    gcResource.getLogger().addHandler(handler);\r\n    ByteArrayInputStream in = new ByteArrayInputStream((\"2014-07-24T13:49:45.090+0400: 92457.841: [Full GC (Allocation Failure)  5811M->3097M(12G), 8.9862292 secs]\" + \"\\n  [Eden: 4096.0K(532.0M)->0.0B(612.0M) Survivors: 80.0M->0.0B Heap: 5811.9M(12.0G)->3097.8M(12.0G)], [Metaspace: 95902K->95450K(1140736K)]\" + \"\\n [Times: user=12.34 sys=0.22, real=8.99 secs]\").getBytes());\r\n    DataReader reader = new DataReaderSun1_6_0G1(gcResource, in, GcLogType.SUN1_8);\r\n    GCModel model = reader.read();\r\n    GCEvent event = (GCEvent) model.get(0);\r\n    assertThat(\"footprint\", event.getTotal(), is(12 * 1024 * 1024));\r\n    assertThat(\"yound before\", event.getYoung().getPreUsed(), is(4096 + 80 * 1024));\r\n    assertThat(\"tenured\", event.getTenured().getTotal(), is(12 * 1024 * 1024 - 612 * 1024));\r\n    assertThat(\"metaspace\", event.getPerm().getTotal(), is(1140736));\r\n    assertThat(\"perm\", model.getPermAllocatedSizes().getN(), is(1));\r\n    assertThat(\"warning count\", handler.getCount(), is(0));\r\n}"
}, {
	"Path": "graphql.schema.idl.WiringFactory.providesTypeResolver",
	"Comment": "this is called to ask if this factory can provide a type resolver for the union",
	"Method": "boolean providesTypeResolver(InterfaceWiringEnvironment environment,boolean providesTypeResolver,UnionWiringEnvironment environment){\r\n    return false;\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaTypeChecker.checkNamedUniqueness",
	"Comment": "a simple function that takes a list of things, asks for their names and checks that thenames are unique within that list.if not it calls the error handler function",
	"Method": "void checkNamedUniqueness(List<GraphQLError> errors,List<T> listOfNamedThings,Function<T, String> namer,BiFunction<String, T, E> errorFunction){\r\n    Set<String> names = new LinkedHashSet();\r\n    listOfNamedThings.forEach(thing -> {\r\n        String name = namer.apply(thing);\r\n        if (names.contains(name)) {\r\n            errors.add(errorFunction.apply(name, thing));\r\n        } else {\r\n            names.add(name);\r\n        }\r\n    });\r\n}"
}, {
	"Path": "hex.FrameTask.chunkInit",
	"Comment": "override this to initialize at the beginning of chunk processing.",
	"Method": "boolean chunkInit(){\r\n    return true;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.apidiff.ApiDiff.isMemberUnsupported",
	"Comment": "returns true if the member with the given declaring class is unsupported.",
	"Method": "boolean isMemberUnsupported(String className,ClassMemberKey memberKey){\r\n    return unsupportedMembersByClass().containsEntry(className, memberKey) || unsupportedMembersByClass().containsEntry(className, ClassMemberKey.create(memberKey.identifier(), \"\"));\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.deregisterWorker",
	"Comment": "final callback from terminating worker, as well as upon failureto construct or start a worker in addworker.removes record ofworker from array, and adjusts counts. if pool is shuttingdown, tries to complete termination.",
	"Method": "void deregisterWorker(ForkJoinWorkerThread wt,Throwable ex){\r\n    Mutex lock = this.lock;\r\n    WorkQueue w = null;\r\n    if (wt != null && (w = wt.workQueue) != null) {\r\n        w.runState = -1;\r\n        stealCount.getAndAdd(w.totalSteals + w.nsteals);\r\n        int idx = w.poolIndex;\r\n        lock.lock();\r\n        try {\r\n            WorkQueue[] ws = workQueues;\r\n            if (ws != null && idx >= 0 && idx < ws.length && ws[idx] == w)\r\n                ws[idx] = null;\r\n        } finally {\r\n            lock.unlock();\r\n        }\r\n    }\r\n    long c;\r\n    do {\r\n    } while (!U.compareAndSwapLong(this, CTL, c = ctl, (((c - AC_UNIT) & AC_MASK) | ((c - TC_UNIT) & TC_MASK) | (c & ~(AC_MASK | TC_MASK)))));\r\n    if (!tryTerminate(false, false) && w != null) {\r\n        w.cancelAll();\r\n        if (w.array != null)\r\n            signalWork();\r\n        if (ex == null)\r\n            ForkJoinTask.helpExpungeStaleExceptions();\r\n    }\r\n    if (ex != null)\r\n        U.throwException(ex);\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlusBuilder.setAdapter",
	"Comment": "set the adapter that will be used when listholder or gridholder are passed",
	"Method": "DialogPlusBuilder setAdapter(BaseAdapter adapter){\r\n    this.adapter = adapter;\r\n    return this;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.BugChecker.buildDescription",
	"Comment": "returns a description builder, which allows you to customize the diagnostic with a custommessage or multiple fixes.",
	"Method": "Description.Builder buildDescription(Tree node,Description.Builder buildDescription,DiagnosticPosition position,Description.Builder buildDescription,JCTree tree){\r\n    return buildDescriptionFromChecker((DiagnosticPosition) tree, this);\r\n}"
}, {
	"Path": "jsr166y.LinkedTransferQueue.succ",
	"Comment": "returns the successor of p, or the head node if p.next has beenlinked to self, which will only be true if traversing with astale pointer that is now off the list.",
	"Method": "Node succ(Node p){\r\n    Node next = p.next;\r\n    return (p == next) ? head : next;\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.crawler.WebCrawler.onPageBiggerThanMaxSize",
	"Comment": "this function is called if the content of a url is bigger than allowed size.",
	"Method": "void onPageBiggerThanMaxSize(String urlStr,long pageSize){\r\n    logger.warn(\"Skipping a URL: {} which was bigger ( {} ) than max allowed size\", urlStr, pageSize);\r\n}"
}, {
	"Path": "com.google.errorprone.ErrorProneAnalyzer.shouldExcludeSourceFile",
	"Comment": "returns true if the given source file should be excluded from analysis.",
	"Method": "boolean shouldExcludeSourceFile(CompilationUnitTree tree){\r\n    Pattern excludedPattern = errorProneOptions.getExcludedPattern();\r\n    return excludedPattern != null && excludedPattern.matcher(ASTHelpers.getFileName(tree)).matches();\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.sameVariable",
	"Comment": "matches if this expressiontree refers to the same variable as the one passed into the matcher.",
	"Method": "Matcher<ExpressionTree> sameVariable(ExpressionTree expr){\r\n    return new Matcher<ExpressionTree>() {\r\n        @Override\r\n        public boolean matches(ExpressionTree tree, VisitorState state) {\r\n            return ASTHelpers.sameVariable(tree, expr);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.sameVariable",
	"Comment": "matches if this expressiontree refers to the same variable as the one passed into the matcher.",
	"Method": "Matcher<ExpressionTree> sameVariable(ExpressionTree expr){\r\n    return ASTHelpers.sameVariable(tree, expr);\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.tryPollForAndExec",
	"Comment": "if task is at base of some steal queue, steals and executes it.",
	"Method": "void tryPollForAndExec(WorkQueue joiner,ForkJoinTask<?> task){\r\n    WorkQueue[] ws;\r\n    if ((ws = workQueues) != null) {\r\n        for (int j = 1; j < ws.length && task.status >= 0; j += 2) {\r\n            WorkQueue q = ws[j];\r\n            if (q != null && q.pollFor(task)) {\r\n                joiner.runSubtask(task);\r\n                break;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.commandline.Main.promptForCredentialsIfMissing",
	"Comment": "if no user or password has been provided, prompt for it. if you want to avoid the prompt,pass in an empty user or password.",
	"Method": "void promptForCredentialsIfMissing(Properties properties){\r\n    Console console = System.console();\r\n    if (console == null) {\r\n        return;\r\n    }\r\n    if (!properties.containsKey(ConfigUtils.URL)) {\r\n        return;\r\n    }\r\n    if (!properties.containsKey(ConfigUtils.USER)) {\r\n        properties.put(ConfigUtils.USER, console.readLine(\"Database user: \"));\r\n    }\r\n    if (!properties.containsKey(ConfigUtils.PASSWORD)) {\r\n        char[] password = console.readPassword(\"Database password: \");\r\n        properties.put(ConfigUtils.PASSWORD, password == null ? \"\" : String.valueOf(password));\r\n    }\r\n}"
}, {
	"Path": "graphql.schema.GraphQLDirective.transform",
	"Comment": "this helps you transform the current graphqldirective into another one by starting a builder with allthe current values and allows you to transform it how you want.",
	"Method": "GraphQLDirective transform(Consumer<Builder> builderConsumer){\r\n    Builder builder = newDirective(this);\r\n    builderConsumer.accept(builder);\r\n    return builder.build();\r\n}"
}, {
	"Path": "jsr166y.Phaser.getRoot",
	"Comment": "returns the root ancestor of this phaser, which is the same asthis phaser if it has no parent.",
	"Method": "Phaser getRoot(){\r\n    return root;\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.awaitTermination",
	"Comment": "blocks until all tasks have completed execution after a shutdownrequest, or the timeout occurs, or the current thread isinterrupted, whichever happens first.",
	"Method": "boolean awaitTermination(long timeout,TimeUnit unit){\r\n    long nanos = unit.toNanos(timeout);\r\n    final Mutex lock = this.lock;\r\n    lock.lock();\r\n    try {\r\n        for (; ; ) {\r\n            if (isTerminated())\r\n                return true;\r\n            if (nanos <= 0)\r\n                return false;\r\n            nanos = termination.awaitNanos(nanos);\r\n        }\r\n    } finally {\r\n        lock.unlock();\r\n    }\r\n}"
}, {
	"Path": "water.parser.ZipUtil.getFirstUnzippedBytes",
	"Comment": "this method will attempt to read the few bytes off a file which will in turn be usedto guess what kind of parsers we should use to parse the file.",
	"Method": "byte[] getFirstUnzippedBytes(ByteVec bv){\r\n    try {\r\n        return getFirstUnzippedBytesChecked(bv);\r\n    } catch (Exception e) {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.util.OSXAdapter.setApplicationEventHandled",
	"Comment": "this method checks for a boolean result from the proxy method and sets the event accordingly",
	"Method": "void setApplicationEventHandled(Object event,boolean handled){\r\n    if (event != null) {\r\n        try {\r\n            Method setHandledMethod = event.getClass().getDeclaredMethod(\"setHandled\", new Class[] { boolean.class });\r\n            setHandledMethod.invoke(event, new Object[] { Boolean.valueOf(handled) });\r\n        } catch (Exception ex) {\r\n            LoggerHelper.logException(LOGGER, Level.SEVERE, \"OSXAdapter was unable to handle an ApplicationEvent: \" + event, ex);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.names.LevenshteinEditDistance.getWorstCaseEditDistance",
	"Comment": "calculate the worst case distance between two strings with the given lengths",
	"Method": "int getWorstCaseEditDistance(int sourceLength,int targetLength){\r\n    return Math.max(sourceLength, targetLength);\r\n}"
}, {
	"Path": "com.google.errorprone.JavacErrorDescriptionListener.shouldSkipImportTreeFix",
	"Comment": "be fixed if they were specified via suggestedfix.replace, for example.",
	"Method": "boolean shouldSkipImportTreeFix(DiagnosticPosition position,Fix f){\r\n    if (position.getTree() != null && position.getTree().getKind() != Kind.IMPORT) {\r\n        return false;\r\n    }\r\n    return !f.getImportsToAdd().isEmpty() || !f.getImportsToRemove().isEmpty();\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.methodHasParameters",
	"Comment": "matches an ast node that represents a method declaration, based on the list ofvariablematchers. applies the variablematcher at index n to the parameter at index n andreturns true iff they all match. returns false if the number of variablematchers provided doesnot match the number of parameters.if you pass no variablematchers, this will match methods with no parameters.",
	"Method": "Matcher<MethodTree> methodHasParameters(Matcher<VariableTree> variableMatcher,Matcher<MethodTree> methodHasParameters,List<Matcher<VariableTree>> variableMatcher,MultiMatcher<MethodTree, VariableTree> methodHasParameters,MatchType matchType,Matcher<VariableTree> parameterMatcher){\r\n    return new MethodHasParameters(matchType, parameterMatcher);\r\n}"
}, {
	"Path": "feign.hystrix.HystrixInvocationHandler.toSetters",
	"Comment": "process all methods in the target so that appropriate setters are created.",
	"Method": "Map<Method, Setter> toSetters(SetterFactory setterFactory,Target<?> target,Set<Method> methods){\r\n    Map<Method, Setter> result = new LinkedHashMap<Method, Setter>();\r\n    for (Method method : methods) {\r\n        method.setAccessible(true);\r\n        result.put(method, setterFactory.create(target, method));\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "hex.Model.toJavaPredict",
	"Comment": "wrapper around the main predict call, including the signature and return value",
	"Method": "SBPrintStream toJavaPredict(SBPrintStream ccsb,CodeGeneratorPipeline fileCtx,boolean verboseCode){\r\n    ccsb.nl();\r\n    ccsb.ip(\"// Pass in data in a double[], pre-aligned to the Model's requirements.\").nl();\r\n    ccsb.ip(\"// Jam predictions into the preds[] array; preds[0] is reserved for the\").nl();\r\n    ccsb.ip(\"// main prediction (class for classifiers or value for regression),\").nl();\r\n    ccsb.ip(\"// and remaining columns hold a probability distribution for classifiers.\").nl();\r\n    ccsb.ip(\"public final double[] score0( double[] data, double[] preds ) {\").nl();\r\n    CodeGeneratorPipeline classCtx = new CodeGeneratorPipeline();\r\n    toJavaPredictBody(ccsb.ii(1), classCtx, fileCtx, verboseCode);\r\n    ccsb.ip(\"return preds;\").nl();\r\n    ccsb.di(1).ip(\"}\").nl();\r\n    classCtx.generate(ccsb.ii(1));\r\n    ccsb.di(1);\r\n    return ccsb;\r\n}"
}, {
	"Path": "hex.deepwater.DeepWaterModelInfo.size",
	"Comment": "momenta are not counted here, but they are needed for model building",
	"Method": "long size(){\r\n    long res = 0;\r\n    if (_network != null)\r\n        res += _network.length;\r\n    if (_modelparams != null)\r\n        res += _modelparams.length;\r\n    return res;\r\n}"
}, {
	"Path": "graphql.analysis.MaxQueryDepthInstrumentation.mkAbortException",
	"Comment": "called to generate your own error message or custom exception class",
	"Method": "AbortExecutionException mkAbortException(int depth,int maxDepth){\r\n    return new AbortExecutionException(\"maximum query depth exceeded \" + depth + \" > \" + maxDepth);\r\n}"
}, {
	"Path": "com.google.errorprone.ErrorProneAnalyzer.finishedCompilation",
	"Comment": "returns true if all declarations inside the given compilation unit have been visited.",
	"Method": "boolean finishedCompilation(CompilationUnitTree tree){\r\n    OUTER: for (Tree decl : tree.getTypeDecls()) {\r\n        switch(decl.getKind()) {\r\n            case EMPTY_STATEMENT:\r\n                continue OUTER;\r\n            case IMPORT:\r\n                continue OUTER;\r\n            default:\r\n                break;\r\n        }\r\n        if (!seen.contains(decl)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "water.parser.ParserService.getAllProviders",
	"Comment": "returns all parser providers sorted based on priority if required.",
	"Method": "List<ParserProvider> getAllProviders(List<ParserProvider> getAllProviders,boolean sort){\r\n    List<ParserProvider> providers = new ArrayList();\r\n    for (ParserProvider pp : loader) {\r\n        providers.add(pp);\r\n    }\r\n    if (sort) {\r\n        Collections.sort(providers, PARSER_PROVIDER_COMPARATOR);\r\n    }\r\n    return providers;\r\n}"
}, {
	"Path": "ai.h2o.automl.AutoMLTest.test_automl_basic_behaviour_on_timeout",
	"Comment": "this test uses a slightly random timeout to ensure it will interrupt the training at various steps",
	"Method": "void test_automl_basic_behaviour_on_timeout(){\r\n    AutoML aml = null;\r\n    Frame fr = null;\r\n    try {\r\n        AutoMLBuildSpec autoMLBuildSpec = new AutoMLBuildSpec();\r\n        fr = parse_test_file(\"./smalldata/logreg/prostate_train.csv\");\r\n        autoMLBuildSpec.input_spec.training_frame = fr._key;\r\n        autoMLBuildSpec.input_spec.response_column = \"CAPSULE\";\r\n        autoMLBuildSpec.build_control.stopping_criteria.set_max_runtime_secs(new Random().nextInt(30));\r\n        autoMLBuildSpec.build_control.keep_cross_validation_models = false;\r\n        autoMLBuildSpec.build_control.keep_cross_validation_predictions = false;\r\n        aml = AutoML.startAutoML(autoMLBuildSpec);\r\n        aml.get();\r\n    } finally {\r\n        if (aml != null)\r\n            aml.deleteWithChildren();\r\n        if (fr != null)\r\n            fr.delete();\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.dataflow.nullnesspropagation.inference.InferredNullability.getExprNullness",
	"Comment": "get inferred nullness qualifier for an expression, if possible.",
	"Method": "Optional<Nullness> getExprNullness(ExpressionTree exprTree){\r\n    InferenceVariable iv = TypeArgInferenceVar.create(ImmutableList.of(), exprTree);\r\n    return constraintGraph.nodes().contains(iv) ? getNullness(iv) : Optional.empty();\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.postgresql.PostgreSQLSchema.generateDropStatementsForRoutines",
	"Comment": "generates the statements for dropping the routines in this schema.",
	"Method": "List<String> generateDropStatementsForRoutines(){\r\n    String isAggregate = database.getVersion().isAtLeast(\"11\") ? \"pg_proc.prokind = 'a'\" : \"pg_proc.proisagg\";\r\n    List<Map<String, String>> rows = // Search for all functions\r\n    jdbcTemplate.queryForList(\"SELECT proname, oidvectortypes(proargtypes) AS args, \" + isAggregate + \" as agg \" + \"FROM pg_proc INNER JOIN pg_namespace ns ON (pg_proc.pronamespace = ns.oid) \" + \"LEFT JOIN pg_depend dep ON dep.objid = pg_proc.oid AND dep.deptype = 'e' \" + \"WHERE ns.nspname = ? AND dep.objid IS NULL\", name);\r\n    List<String> statements = new ArrayList();\r\n    for (Map<String, String> row : rows) {\r\n        String type = isTrue(row.get(\"agg\")) ? \"AGGREGATE\" : \"FUNCTION\";\r\n        statements.add(\"DROP \" + type + \" IF EXISTS \" + database.quote(name, row.get(\"proname\")) + \"(\" + row.get(\"args\") + \") CASCADE\");\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaDirectiveWiring.onArgument",
	"Comment": "this is called when an argument is encountered, which gives the schema directive a chance to modify the shape and behaviourof that dslelement",
	"Method": "GraphQLArgument onArgument(SchemaDirectiveWiringEnvironment<GraphQLArgument> environment){\r\n    return environment.getElement();\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.SelfAssignment.stripNullCheck",
	"Comment": "if the given expression is a call to a method checking the nullity of its first parameter, andotherwise returns that parameter.",
	"Method": "ExpressionTree stripNullCheck(ExpressionTree expression,VisitorState state){\r\n    if (expression != null && expression.getKind() == METHOD_INVOCATION) {\r\n        MethodInvocationTree methodInvocation = (MethodInvocationTree) expression;\r\n        if (NON_NULL_MATCHER.matches(methodInvocation, state)) {\r\n            return methodInvocation.getArguments().get(0);\r\n        }\r\n    }\r\n    return expression;\r\n}"
}, {
	"Path": "hex.pca.PCATest.testPUBDEV3500NoLeakage",
	"Comment": "quick test to make sure changes made to pca for rank deficient matrices do not cause leakage.",
	"Method": "void testPUBDEV3500NoLeakage(){\r\n    Scope.enter();\r\n    Frame train = null;\r\n    try {\r\n        train = parse_test_file(Key.make(\"prostate_cat.hex\"), \"smalldata/prostate/prostate_cat.csv\");\r\n        Scope.track(train);\r\n        pcaParameters._train = train._key;\r\n        pcaParameters._k = 3;\r\n        pcaParameters._transform = DataInfo.TransformType.NONE;\r\n        pcaParameters._pca_method = PCAModel.PCAParameters.Method.Randomized;\r\n        pcaParameters._impute_missing = true;\r\n        pcaParameters._seed = 12345;\r\n        pcaParameters._use_all_factor_levels = true;\r\n        PCAModel pca = null;\r\n        pca = new PCA(pcaParameters).trainModel().get();\r\n        Scope.track_generic(pca);\r\n        Assert.assertTrue(pca._parms._k == pca._output._std_deviation.length);\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "hex.grid.Grid.getTrainingFrame",
	"Comment": "returns the data frame used to train all these models.all models are trained on the samedata frame, but might be validated on multiple different frames.",
	"Method": "Frame getTrainingFrame(){\r\n    return _params.train();\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.StringUtils.replace",
	"Comment": "replace all occurences of a substring within a string withanother string.",
	"Method": "String replace(String inString,String oldPattern,String newPattern){\r\n    if (!hasLength(inString) || !hasLength(oldPattern) || newPattern == null) {\r\n        return inString;\r\n    }\r\n    StringBuilder sb = new StringBuilder();\r\n    int pos = 0;\r\n    int index = inString.indexOf(oldPattern);\r\n    int patLen = oldPattern.length();\r\n    while (index >= 0) {\r\n        sb.append(inString, pos, index);\r\n        sb.append(newPattern);\r\n        pos = index + patLen;\r\n        index = inString.indexOf(oldPattern, pos);\r\n    }\r\n    sb.append(inString.substring(pos));\r\n    return sb.toString();\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.jdbc.JdbcTemplate.queryForStringList",
	"Comment": "executes this query with these parameters against this connection.",
	"Method": "List<String> queryForStringList(String query,String params){\r\n    PreparedStatement statement = null;\r\n    ResultSet resultSet = null;\r\n    List<String> result;\r\n    try {\r\n        statement = prepareStatement(query, params);\r\n        resultSet = statement.executeQuery();\r\n        result = new ArrayList();\r\n        while (resultSet.next()) {\r\n            result.add(resultSet.getString(1));\r\n        }\r\n    } finally {\r\n        JdbcUtils.closeResultSet(resultSet);\r\n        JdbcUtils.closeStatement(statement);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "water.MRTask.reduce3",
	"Comment": "block for rpcs to complete, then reduce global results into self results",
	"Method": "void reduce3(RPC<T> rpc){\r\n    if (rpc == null)\r\n        return;\r\n    T mrt = rpc.get();\r\n    if (_profile != null)\r\n        _profile.gather(mrt._profile, rpc.size_rez());\r\n    if (mrt._nhi != -1L) {\r\n        if (_res == null)\r\n            _res = mrt;\r\n        else\r\n            _res.reduce4(mrt);\r\n    }\r\n}"
}, {
	"Path": "water.nbhm.ConcurrentAutoTable.set",
	"Comment": "atomically set the sum of the striped counters to specified value. rather more expensive than a simple store, in order to remain atomic.",
	"Method": "void set(long x){\r\n    CAT newcat = new CAT(null, 4, x);\r\n    while (!CAS_cat(_cat, newcat)) ;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.DataReaderIBMi5OS1_4_2.read",
	"Comment": "reads the gc data lines and translates them to gcevents whichare collected in the gcmodel.",
	"Method": "GCModel read(){\r\n    if (getLogger().isLoggable(Level.INFO))\r\n        getLogger().info(\"Reading IBM i5/OS 1.4.2 format...\");\r\n    try {\r\n        final GCModel model = new GCModel();\r\n        model.setFormat(GCModel.Format.IBM_VERBOSE_GC);\r\n        int state = 0;\r\n        String line = null;\r\n        GCEvent event = null;\r\n        int freed = 0;\r\n        int previousCycle = 0;\r\n        int currentCycle = 0;\r\n        long basetime = 0;\r\n        cycleStartGCFormat = new SimpleDateFormat(\"dd/MM/yy HH:mm:ss\");\r\n        while ((line = in.readLine()) != null && shouldContinue()) {\r\n            final String trimmedLine = line.trim();\r\n            if (!\"\".equals(trimmedLine) && !trimmedLine.startsWith(\"GC\")) {\r\n                if (getLogger().isLoggable(Level.INFO))\r\n                    getLogger().info(\"Malformed line (\" + in.getLineNumber() + \"): \" + line);\r\n                state = 0;\r\n            }\r\n            switch(state) {\r\n                case 0:\r\n                    if (line.indexOf(\"GC:\") != -1) {\r\n                        event = new GCEvent();\r\n                        event.setType(AbstractGCEvent.Type.GC);\r\n                        event.setPreUsed(parseInitialHeap(line));\r\n                        event.setPostUsed(event.getPreUsed());\r\n                        event.setTotal(event.getPreUsed());\r\n                        model.add(event);\r\n                        event = null;\r\n                        break;\r\n                    } else if (line.indexOf(\"collection starting\") != -1) {\r\n                        event = new GCEvent();\r\n                        event.setType(AbstractGCEvent.Type.GC);\r\n                        final long time = parseGCCycleStart(line);\r\n                        if (basetime == 0)\r\n                            basetime = time;\r\n                        event.setTimestamp((time - basetime) / 1000.0d);\r\n                        state++;\r\n                        break;\r\n                    }\r\n                    break;\r\n                case 1:\r\n                    if (line.indexOf(\"current heap(KB) \") != -1) {\r\n                        event.setTotal(parseTotalAfterGC(line));\r\n                        break;\r\n                    } else if (line.indexOf(\"collect (milliseconds) \") != -1) {\r\n                        event.setPause(parsePause(line));\r\n                        break;\r\n                    } else if (line.indexOf(\"collected(KB) \") != -1) {\r\n                        freed = parseFreed(line);\r\n                        break;\r\n                    } else if (line.indexOf(\"current cycle allocation(KB) \") != -1) {\r\n                        previousCycle = parsePreviousCycle(line);\r\n                        currentCycle = parseCurrentCycle(line);\r\n                        event.setPreUsed((event.getTotal() - previousCycle - currentCycle) + freed);\r\n                        event.setPostUsed((event.getTotal() - previousCycle - currentCycle));\r\n                        break;\r\n                    } else if (line.indexOf(\"collection ending\") != -1) {\r\n                        model.add(event);\r\n                        event = null;\r\n                        state = 0;\r\n                        freed = 0;\r\n                        previousCycle = 0;\r\n                        currentCycle = 0;\r\n                        break;\r\n                    }\r\n                    break;\r\n                default:\r\n            }\r\n        }\r\n        return model;\r\n    } finally {\r\n        if (getLogger().isLoggable(Level.INFO))\r\n            getLogger().info(\"Done reading.\");\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setInstalledBy",
	"Comment": "the username that will be recorded in the schema history table as having applied the migration.",
	"Method": "void setInstalledBy(String installedBy){\r\n    if (\"\".equals(installedBy)) {\r\n        installedBy = null;\r\n    }\r\n    this.installedBy = installedBy;\r\n}"
}, {
	"Path": "jsr166y.Phaser.internalAwaitAdvance",
	"Comment": "possibly blocks and waits for phase to advance unless aborted.call only on root phaser.",
	"Method": "int internalAwaitAdvance(int phase,QNode node){\r\n    releaseWaiters(phase - 1);\r\n    boolean queued = false;\r\n    int lastUnarrived = 0;\r\n    int spins = SPINS_PER_ARRIVAL;\r\n    long s;\r\n    int p;\r\n    while ((p = (int) ((s = state) >>> PHASE_SHIFT)) == phase) {\r\n        if (node == null) {\r\n            int unarrived = (int) s & UNARRIVED_MASK;\r\n            if (unarrived != lastUnarrived && (lastUnarrived = unarrived) < NCPU)\r\n                spins += SPINS_PER_ARRIVAL;\r\n            boolean interrupted = Thread.interrupted();\r\n            if (interrupted || --spins < 0) {\r\n                node = new QNode(this, phase, false, false, 0L);\r\n                node.wasInterrupted = interrupted;\r\n            }\r\n        } else if (node.isReleasable())\r\n            break;\r\n        else if (!queued) {\r\n            AtomicReference<QNode> head = (phase & 1) == 0 ? evenQ : oddQ;\r\n            QNode q = node.next = head.get();\r\n            if ((q == null || q.phase == phase) && (int) (state >>> PHASE_SHIFT) == phase)\r\n                queued = head.compareAndSet(q, node);\r\n        } else {\r\n            try {\r\n                ForkJoinPool.managedBlock(node);\r\n            } catch (InterruptedException ie) {\r\n                node.wasInterrupted = true;\r\n            }\r\n        }\r\n    }\r\n    if (node != null) {\r\n        if (node.thread != null)\r\n            node.thread = null;\r\n        if (node.wasInterrupted && !node.interruptible)\r\n            Thread.currentThread().interrupt();\r\n        if (p == phase && (p = (int) (state >>> PHASE_SHIFT)) == phase)\r\n            return abortWait(phase);\r\n    }\r\n    releaseWaiters(phase);\r\n    return p;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.inject.dagger.Util.hasAnyParameter",
	"Comment": "matches an annotation that has an argument for at least one of the given parameters.",
	"Method": "Matcher<AnnotationTree> hasAnyParameter(String parameters){\r\n    return anyOf(transform(asList(parameters), new Function<String, Matcher<AnnotationTree>>() {\r\n        @Override\r\n        public Matcher<AnnotationTree> apply(String parameter) {\r\n            return hasArgumentWithValue(parameter, Matchers.<ExpressionTree>anything());\r\n        }\r\n    }));\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.inject.dagger.Util.hasAnyParameter",
	"Comment": "matches an annotation that has an argument for at least one of the given parameters.",
	"Method": "Matcher<AnnotationTree> hasAnyParameter(String parameters){\r\n    return hasArgumentWithValue(parameter, Matchers.<ExpressionTree>anything());\r\n}"
}, {
	"Path": "hex.deeplearning.DeepLearningModelInfo.initializeFromPretrainedModel",
	"Comment": "fill weights and biases from a pretrained autoencoder model",
	"Method": "void initializeFromPretrainedModel(DeepLearningModelInfo autoencoder){\r\n    assert (autoencoder.parameters._autoencoder);\r\n    randomizeWeights();\r\n    for (int w = 0; w < dense_row_weights.length - 1; ++w) {\r\n        if (get_weights(w).rows() != autoencoder.get_weights(w).rows())\r\n            throw new IllegalArgumentException(\"Mismatch between weights in pretrained model and this model: rows in layer \" + w + \": \" + autoencoder.get_weights(w).rows() + \" vs \" + get_weights(w).rows() + \". Enable ignored_const_cols for both models and/or check categorical levels for consistency.\");\r\n        if (get_weights(w).cols() != autoencoder.get_weights(w).cols())\r\n            throw new IllegalArgumentException(\"Mismatch between weights in pretrained model and this model: cols in layer \" + w + \": \" + autoencoder.get_weights(w).cols() + \" vs \" + get_weights(w).cols() + \". Enable ignored_const_cols for both models and/or check categorical levels for consistency.\");\r\n        for (int i = 0; i < get_weights(w).rows(); i++) {\r\n            for (int j = 0; j < get_weights(w).cols(); j++) {\r\n                get_weights(w).set(i, j, autoencoder.get_weights(w).get(i, j));\r\n            }\r\n        }\r\n    }\r\n    for (int i = 0; i < get_params()._hidden.length; ++i) {\r\n        for (int j = 0; j < biases[i].raw().length; ++j) {\r\n            biases[i].set(j, autoencoder.biases[i].get(j));\r\n        }\r\n    }\r\n    Arrays.fill(biases[biases.length - 1].raw(), 0f);\r\n}"
}, {
	"Path": "water.fvec.Chunk.reportBrokenCategorical",
	"Comment": "used by the parser to help report various internal bugs.not intended for public use.",
	"Method": "void reportBrokenCategorical(int i,int j,long l,int[] cmap,int levels){\r\n    StringBuilder sb = new StringBuilder(\"Categorical renumber task, column # \" + i + \": Found OOB index \" + l + \" (expected 0 - \" + cmap.length + \", global domain has \" + levels + \" levels) pulled from \" + getClass().getSimpleName() + \"\\n\");\r\n    int k = 0;\r\n    for (; k < Math.min(5, _len); ++k) sb.append(\"at8_abs[\" + (k + _start) + \"] = \" + atd(k) + \", _chk2 = \" + (_chk2 != null ? _chk2.atd(k) : \"\") + \"\\n\");\r\n    k = Math.max(k, j - 2);\r\n    sb.append(\"...\\n\");\r\n    for (; k < Math.min(_len, j + 2); ++k) sb.append(\"at8_abs[\" + (k + _start) + \"] = \" + atd(k) + \", _chk2 = \" + (_chk2 != null ? _chk2.atd(k) : \"\") + \"\\n\");\r\n    sb.append(\"...\\n\");\r\n    k = Math.max(k, _len - 5);\r\n    for (; k < _len; ++k) sb.append(\"at8_abs[\" + (k + _start) + \"] = \" + atd(k) + \", _chk2 = \" + (_chk2 != null ? _chk2.atd(k) : \"\") + \"\\n\");\r\n    throw new RuntimeException(sb.toString());\r\n}"
}, {
	"Path": "org.flywaydb.core.api.Location.isParentOf",
	"Comment": "checks whether this location is a parent of this other location.",
	"Method": "boolean isParentOf(Location other){\r\n    if (isClassPath() && other.isClassPath()) {\r\n        return (other.getDescriptor() + \"/\").startsWith(getDescriptor() + \"/\");\r\n    }\r\n    if (isFileSystem() && other.isFileSystem()) {\r\n        return (other.getPath() + File.separator).startsWith(getDescriptor() + File.separator);\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaGenerator.buildOutputType",
	"Comment": "this is the main recursive spot that builds out the various forms of output types",
	"Method": "T buildOutputType(BuildContext buildCtx,Type rawType){\r\n    TypeDefinition typeDefinition = buildCtx.getTypeDefinition(rawType);\r\n    TypeInfo typeInfo = TypeInfo.typeInfo(rawType);\r\n    GraphQLOutputType outputType = buildCtx.hasOutputType(typeDefinition);\r\n    if (outputType != null) {\r\n        return typeInfo.decorate(outputType);\r\n    }\r\n    if (buildCtx.stackContains(typeInfo)) {\r\n        return typeInfo.decorate(typeRef(typeInfo.getName()));\r\n    }\r\n    buildCtx.push(typeInfo);\r\n    if (typeDefinition instanceof ObjectTypeDefinition) {\r\n        outputType = buildObjectType(buildCtx, (ObjectTypeDefinition) typeDefinition);\r\n    } else if (typeDefinition instanceof InterfaceTypeDefinition) {\r\n        outputType = buildInterfaceType(buildCtx, (InterfaceTypeDefinition) typeDefinition);\r\n    } else if (typeDefinition instanceof UnionTypeDefinition) {\r\n        outputType = buildUnionType(buildCtx, (UnionTypeDefinition) typeDefinition);\r\n    } else if (typeDefinition instanceof EnumTypeDefinition) {\r\n        outputType = buildEnumType(buildCtx, (EnumTypeDefinition) typeDefinition);\r\n    } else if (typeDefinition instanceof ScalarTypeDefinition) {\r\n        outputType = buildScalar(buildCtx, (ScalarTypeDefinition) typeDefinition);\r\n    } else {\r\n        throw new NotAnOutputTypeError(rawType, typeDefinition);\r\n    }\r\n    buildCtx.putOutputType(outputType);\r\n    buildCtx.pop();\r\n    return (T) typeInfo.decorate(outputType);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.jdbc.JdbcTemplate.prepareStatement",
	"Comment": "creates a new prepared statement for this sql with these params.",
	"Method": "PreparedStatement prepareStatement(String sql,Object[] params){\r\n    PreparedStatement statement = connection.prepareStatement(sql);\r\n    for (int i = 0; i < params.length; i++) {\r\n        if (params[i] == null) {\r\n            statement.setNull(i + 1, nullType);\r\n        } else if (params[i] instanceof Integer) {\r\n            statement.setInt(i + 1, (Integer) params[i]);\r\n        } else if (params[i] instanceof Boolean) {\r\n            statement.setBoolean(i + 1, (Boolean) params[i]);\r\n        } else {\r\n            statement.setString(i + 1, params[i].toString());\r\n        }\r\n    }\r\n    return statement;\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.model.GCModel.getCmsInitiatingOccupancyFraction",
	"Comment": "return statistical data about fraction of tenured heap when concurrent collection cyclesare started.",
	"Method": "DoubleData getCmsInitiatingOccupancyFraction(){\r\n    return initiatingOccupancyFraction;\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlus.findViewById",
	"Comment": "checks the given resource id and return the corresponding view if it exists.",
	"Method": "View findViewById(int resourceId){\r\n    return contentContainer.findViewById(resourceId);\r\n}"
}, {
	"Path": "com.ramotion.foldingcell.FoldingCell.startCollapseHeightAnimation",
	"Comment": "prepare and start height collapse animation for foldingcelllayout",
	"Method": "void startCollapseHeightAnimation(ArrayList<Integer> viewHeights,int partAnimationDuration){\r\n    if (viewHeights == null || viewHeights.isEmpty())\r\n        throw new IllegalArgumentException(\"ViewHeights array must have at least 2 elements\");\r\n    ArrayList<Animation> heightAnimations = new ArrayList();\r\n    int fromHeight = viewHeights.get(0);\r\n    for (int i = 1; i < viewHeights.size(); i++) {\r\n        int toHeight = fromHeight + viewHeights.get(i);\r\n        heightAnimations.add(new HeightAnimation(this, toHeight, fromHeight, partAnimationDuration).withInterpolator(new DecelerateInterpolator()));\r\n        fromHeight = toHeight;\r\n    }\r\n    Collections.reverse(heightAnimations);\r\n    createAnimationChain(heightAnimations, this);\r\n    this.startAnimation(heightAnimations.get(0));\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.nestingKind",
	"Comment": "matches an class based on whether it is nested in another class or method.",
	"Method": "Matcher<ClassTree> nestingKind(NestingKind kind){\r\n    return new Matcher<ClassTree>() {\r\n        @Override\r\n        public boolean matches(ClassTree classTree, VisitorState state) {\r\n            ClassSymbol sym = ASTHelpers.getSymbol(classTree);\r\n            return sym.getNestingKind() == kind;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.nestingKind",
	"Comment": "matches an class based on whether it is nested in another class or method.",
	"Method": "Matcher<ClassTree> nestingKind(NestingKind kind){\r\n    ClassSymbol sym = ASTHelpers.getSymbol(classTree);\r\n    return sym.getNestingKind() == kind;\r\n}"
}, {
	"Path": "com.google.errorprone.apply.ImportStatementsTest.noRemainingStaticImports",
	"Comment": "tests that a list of imports with no static imports is handled correctly.",
	"Method": "void noRemainingStaticImports(){\r\n    ImportStatements imports = createImportStatements(basePackage, baseImportList);\r\n    boolean removed = imports.removeAll(Arrays.asList(\"import static com.google.common.base.Preconditions.checkNotNull\", \"import static com.google.ads.pebl.AdGroupCriterionPredicate.PAUSED\"));\r\n    assertTrue(removed);\r\n    assertEquals(\"import com.google.common.collect.ImmutableList;\\n\" + \"import com.google.common.collect.ImmutableMap;\\n\" + \"import com.sun.source.tree.CompilationUnitTree;\\n\" + \"import com.sun.source.tree.ImportTree;\\n\" + \"import com.sun.tools.javac.tree.JCTree;\\n\" + \"import com.sun.tools.javac.tree.JCTree.JCExpression;\\n\" + \"import java.io.File;\\n\" + \"import java.io.IOException;\\n\" + \"import java.util.Iterator;\\n\" + \"import javax.tools.JavaCompiler;\\n\" + \"import javax.tools.JavaFileObject;\\n\" + \"import javax.tools.StandardJavaFileManager;\\n\" + \"import javax.tools.ToolProvider;\\n\" + \"import org.joda.time.DateTime;\\n\" + \"import org.joda.time.DateTimeZone;\\n\" + \"import org.joda.time.Interval;\", imports.toString());\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.argumentselectiondefects.CreatesDuplicateCallHeuristic.isAcceptableChange",
	"Comment": "returns true if there are no other calls to this method which already have an actual parameterin the position we are moving this one too.",
	"Method": "boolean isAcceptableChange(Changes changes,Tree node,MethodSymbol symbol,VisitorState state){\r\n    return findArgumentsForOtherInstances(symbol, node, state).stream().allMatch(arguments -> !anyArgumentsMatch(changes.changedPairs(), arguments));\r\n}"
}, {
	"Path": "org.flywaydb.core.Flyway.undo",
	"Comment": "undoes the most recently applied versioned migration. if target is specified, flyway will attempt to undoversioned migrations in the order they were applied until it hits one with a version below the target. if thereis no versioned migration to undo, calling undo has no effect.flyway pro and flyway enterprise only",
	"Method": "int undo(){\r\n    throw new org.flywaydb.core.internal.license.FlywayProUpgradeRequiredException(\"undo\");\r\n}"
}, {
	"Path": "org.flywaydb.gradle.task.AbstractFlywayTask.determineConfigurationFileEncoding",
	"Comment": "determines the encoding to use for loading the configuration files.",
	"Method": "String determineConfigurationFileEncoding(Map<String, String> envVars){\r\n    if (envVars.containsKey(ConfigUtils.CONFIG_FILE_ENCODING)) {\r\n        return envVars.get(ConfigUtils.CONFIG_FILE_ENCODING);\r\n    }\r\n    if (System.getProperties().containsKey(ConfigUtils.CONFIG_FILE_ENCODING)) {\r\n        return System.getProperties().getProperty(ConfigUtils.CONFIG_FILE_ENCODING);\r\n    }\r\n    if (configFileEncoding != null) {\r\n        return configFileEncoding;\r\n    }\r\n    if (extension.configFileEncoding != null) {\r\n        return extension.configFileEncoding;\r\n    }\r\n    return \"UTF-8\";\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.crawler.WebCrawler.onUnhandledException",
	"Comment": "this function is called when a unhandled exception was encountered during fetching",
	"Method": "void onUnhandledException(WebURL webUrl,Throwable e){\r\n    String urlStr = (webUrl == null ? \"NULL\" : webUrl.getURL());\r\n    logger.warn(\"Unhandled exception while fetching {}: {}\", urlStr, e.getMessage());\r\n    logger.info(\"Stacktrace: \", e);\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.view.util.OSXAdapter.setAboutHandler",
	"Comment": "they will be called when the about menu item is selected from the application menu",
	"Method": "void setAboutHandler(Object target,Method aboutHandler){\r\n    boolean enableAboutMenu = (target != null && aboutHandler != null);\r\n    if (enableAboutMenu) {\r\n        setHandler(new OSXAdapter(\"handleAbout\", target, aboutHandler));\r\n    }\r\n    try {\r\n        Method enableAboutMethod = macOSXApplication.getClass().getDeclaredMethod(\"setEnabledAboutMenu\", new Class[] { boolean.class });\r\n        enableAboutMethod.invoke(macOSXApplication, new Object[] { Boolean.valueOf(enableAboutMenu) });\r\n    } catch (Exception ex) {\r\n        LoggerHelper.logException(LOGGER, Level.SEVERE, \"OSXAdapter could not access the About Menu\", ex);\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.info.MigrationInfoServiceImpl.failed",
	"Comment": "retrieves the full set of infos about the migrations that failed.",
	"Method": "MigrationInfo[] failed(){\r\n    List<MigrationInfo> failedMigrations = new ArrayList();\r\n    for (MigrationInfo migrationInfo : migrationInfos) {\r\n        if (migrationInfo.getState().isFailed()) {\r\n            failedMigrations.add(migrationInfo);\r\n        }\r\n    }\r\n    return failedMigrations.toArray(new MigrationInfo[0]);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.sqlscript.SqlScript.extractStatements",
	"Comment": "parses the textual data provided by this reader into a list of statements.",
	"Method": "List<SqlStatement> extractStatements(LineReader reader){\r\n    Line line;\r\n    List<SqlStatement> statements = new ArrayList();\r\n    Delimiter nonStandardDelimiter = null;\r\n    SqlStatementBuilder sqlStatementBuilder = sqlStatementBuilderFactory.createSqlStatementBuilder();\r\n    while ((line = reader.readLine()) != null) {\r\n        line = new PlaceholderReplacingLine(line, sqlStatementBuilderFactory.getPlaceholderReplacer());\r\n        String lineStr = line.getLine();\r\n        if (sqlStatementBuilder.isEmpty() && !StringUtils.hasText(lineStr)) {\r\n            continue;\r\n        }\r\n        if (!sqlStatementBuilder.hasNonCommentPart()) {\r\n            Delimiter newDelimiter = sqlStatementBuilder.extractNewDelimiterFromLine(lineStr);\r\n            if (newDelimiter != null) {\r\n                nonStandardDelimiter = newDelimiter;\r\n                continue;\r\n            }\r\n            if (nonStandardDelimiter != null) {\r\n                sqlStatementBuilder.setDelimiter(nonStandardDelimiter);\r\n            }\r\n        }\r\n        try {\r\n            sqlStatementBuilder.addLine(line);\r\n        } catch (Exception e) {\r\n            throw new FlywayException(\"Flyway parsing bug (\" + e.getMessage() + \") at line \" + line.getLineNumber() + \": \" + lineStr, e);\r\n        }\r\n        if (sqlStatementBuilder.canDiscard()) {\r\n            sqlStatementBuilder = sqlStatementBuilderFactory.createSqlStatementBuilder();\r\n        } else if (sqlStatementBuilder.isTerminated()) {\r\n            addStatement(statements, sqlStatementBuilder);\r\n            sqlStatementBuilder = sqlStatementBuilderFactory.createSqlStatementBuilder();\r\n        }\r\n    }\r\n    if (!sqlStatementBuilder.isEmpty() && sqlStatementBuilder.hasNonCommentPart()) {\r\n        addStatement(statements, sqlStatementBuilder);\r\n    }\r\n    return statements;\r\n}"
}, {
	"Path": "hex.glm.GLMModel.scoreMetrics",
	"Comment": "score an already adapted frame.returns a metricbuilder that can be used to make a model metrics.",
	"Method": "ModelMetrics.MetricBuilder scoreMetrics(Frame adaptFrm){\r\n    GLMScore gs = makeScoringTask(adaptFrm, false, null);\r\n    assert gs._dinfo._valid : \"_valid flag should be set on data info when doing scoring\";\r\n    return gs.doAll(gs._dinfo._adaptedFrame)._mb;\r\n}"
}, {
	"Path": "hex.ModelMetricsRegression.make",
	"Comment": "build a regression modelmetrics object from predicted and actual targets",
	"Method": "ModelMetricsRegression make(Vec predicted,Vec actual,DistributionFamily family){\r\n    if (predicted == null || actual == null)\r\n        throw new IllegalArgumentException(\"Missing actual or predicted targets for regression metrics!\");\r\n    if (!predicted.isNumeric())\r\n        throw new IllegalArgumentException(\"Predicted values must be numeric for regression metrics.\");\r\n    if (!actual.isNumeric())\r\n        throw new IllegalArgumentException(\"Actual values must be numeric for regression metrics.\");\r\n    if (family == DistributionFamily.quantile || family == DistributionFamily.tweedie || family == DistributionFamily.huber)\r\n        throw new IllegalArgumentException(\"Unsupported distribution family, requires additional parameters which cannot be specified right now.\");\r\n    Frame predsActual = new Frame(predicted);\r\n    predsActual.add(\"actual\", actual);\r\n    MetricBuilderRegression mb = new RegressionMetrics(family).doAll(predsActual)._mb;\r\n    ModelMetricsRegression mm = (ModelMetricsRegression) mb.makeModelMetrics(null, predsActual, null, null);\r\n    mm._description = \"Computed on user-given predictions and targets, distribution: \" + (family == null ? DistributionFamily.gaussian.toString() : family.toString()) + \".\";\r\n    return mm;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.CompileTimeConstantExpressionMatcher.hasCompileTimeConstantAnnotation",
	"Comment": "public since this is also used by compiletimeconstantchecker.",
	"Method": "boolean hasCompileTimeConstantAnnotation(VisitorState state,Symbol symbol){\r\n    return hasAttribute(symbol, COMPILE_TIME_CONSTANT_ANNOTATION, state);\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.hasMethod",
	"Comment": "matches a class in which at least one method matches the given methodmatcher.",
	"Method": "Matcher<ClassTree> hasMethod(Matcher<MethodTree> methodMatcher){\r\n    return new Matcher<ClassTree>() {\r\n        @Override\r\n        public boolean matches(ClassTree t, VisitorState state) {\r\n            for (Tree member : t.getMembers()) {\r\n                if (member instanceof MethodTree) {\r\n                    if (methodMatcher.matches((MethodTree) member, state)) {\r\n                        return true;\r\n                    }\r\n                }\r\n            }\r\n            return false;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.hasMethod",
	"Comment": "matches a class in which at least one method matches the given methodmatcher.",
	"Method": "Matcher<ClassTree> hasMethod(Matcher<MethodTree> methodMatcher){\r\n    for (Tree member : t.getMembers()) {\r\n        if (member instanceof MethodTree) {\r\n            if (methodMatcher.matches((MethodTree) member, state)) {\r\n                return true;\r\n            }\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.oracle.OracleDatabase.isLocatorAvailable",
	"Comment": "checks whether oracle locator component is available or not.",
	"Method": "boolean isLocatorAvailable(){\r\n    return isDataDictViewAccessible(\"MDSYS\", \"ALL_SDO_GEOM_METADATA\");\r\n}"
}, {
	"Path": "hex.glrm.GLRM.findtAChunkIndices",
	"Comment": "recall again, tasks are passed chunks containing chunks of xvec.need to find the corresponding\t\tchunks in ta that contains the same row number of x vecs.the correct chunks will be stored as an array.",
	"Method": "ArrayList<Integer> findtAChunkIndices(Frame tAVecs,int xStart,int xEnd,Archetypes yt){\r\n    ArrayList<Integer> tAcidx = new ArrayList<Integer>();\r\n    int tANChunks = tAVecs.anyVec().nChunks();\r\n    if (tANChunks == 1) {\r\n        tAcidx.add(0);\r\n        return tAcidx;\r\n    }\r\n    int startTAcidx = 0;\r\n    int numCats = yt._catOffsets.length - 1;\r\n    int numCatColumns = yt._catOffsets[numCats];\r\n    xStart = findOriginalColIndex(xStart, numCats, numCatColumns, yt);\r\n    xEnd = findOriginalColIndex(xEnd, numCats, numCatColumns, yt);\r\n    findGoodCidx(tAVecs, tAcidx, false, xStart, tANChunks, startTAcidx);\r\n    startTAcidx = tAcidx.get(0);\r\n    if (startTAcidx < (tANChunks - 1)) {\r\n        findGoodCidx(tAVecs, tAcidx, true, xEnd, tANChunks, startTAcidx);\r\n    }\r\n    return tAcidx;\r\n}"
}, {
	"Path": "feign.RequestTemplate.queries",
	"Comment": "return an immutable map of all query parameters and their values.",
	"Method": "RequestTemplate queries(Map<String, Collection<String>> queries,Map<String, Collection<String>> queries){\r\n    Map<String, Collection<String>> queryMap = new LinkedHashMap();\r\n    this.queries.forEach((key, queryTemplate) -> {\r\n        List<String> values = new ArrayList(queryTemplate.getValues());\r\n        queryMap.put(key, Collections.unmodifiableList(values));\r\n    });\r\n    return Collections.unmodifiableMap(queryMap);\r\n}"
}, {
	"Path": "graphql.execution.ExecutionStrategy.toIterable",
	"Comment": "converts an object that is known to should be an iterable into one",
	"Method": "Iterable<Object> toIterable(Object result,Iterable<Object> toIterable,ExecutionContext context,ExecutionStrategyParameters parameters,Object result){\r\n    if (result.getClass().isArray() || result instanceof Iterable) {\r\n        return toIterable(result);\r\n    }\r\n    handleTypeMismatchProblem(context, parameters, result);\r\n    return null;\r\n}"
}, {
	"Path": "hex.deeplearning.DeepLearningTest.testCheckpointOverwriteWithBestModel2",
	"Comment": "check that the restarted model honors the previous model as a best model so far",
	"Method": "void testCheckpointOverwriteWithBestModel2(){\r\n    Frame tfr = null;\r\n    DeepLearningModel dl = null;\r\n    DeepLearningModel dl2 = null;\r\n    Frame train = null, valid = null;\r\n    try {\r\n        tfr = parse_test_file(\"./smalldata/iris/iris.csv\");\r\n        FrameSplitter fs = new FrameSplitter(tfr, new double[] { 0.8 }, new Key[] { Key.make(\"train\"), Key.make(\"valid\") }, null);\r\n        fs.compute2();\r\n        train = fs.getResult()[0];\r\n        valid = fs.getResult()[1];\r\n        DeepLearningParameters parms = new DeepLearningParameters();\r\n        parms._train = train._key;\r\n        parms._valid = valid._key;\r\n        parms._epochs = 10;\r\n        parms._response_column = \"C5\";\r\n        parms._reproducible = true;\r\n        parms._hidden = new int[] { 50, 50 };\r\n        parms._seed = 0xdecaf;\r\n        parms._train_samples_per_iteration = 0;\r\n        parms._score_duty_cycle = 1;\r\n        parms._score_interval = 0;\r\n        parms._stopping_rounds = 0;\r\n        parms._overwrite_with_best_model = true;\r\n        dl = new DeepLearning(parms).trainModel().get();\r\n        double ll1 = ((ModelMetricsMultinomial) dl._output._validation_metrics).logloss();\r\n        DeepLearningParameters parms2 = (DeepLearningParameters) parms.clone();\r\n        parms2._epochs = 20;\r\n        parms2._checkpoint = dl._key;\r\n        dl2 = new DeepLearning(parms2).trainModel().get();\r\n        double ll2 = ((ModelMetricsMultinomial) dl2._output._validation_metrics).logloss();\r\n        Assert.assertTrue(ll2 <= ll1);\r\n    } finally {\r\n        if (tfr != null)\r\n            tfr.delete();\r\n        if (dl != null)\r\n            dl.delete();\r\n        if (dl2 != null)\r\n            dl2.delete();\r\n        if (train != null)\r\n            train.delete();\r\n        if (valid != null)\r\n            valid.delete();\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.base.Database.quote",
	"Comment": "quote these identifiers for use in sql queries. multiple identifiers will be quoted and separated by a dot.",
	"Method": "String quote(String identifiers){\r\n    StringBuilder result = new StringBuilder();\r\n    boolean first = true;\r\n    for (String identifier : identifiers) {\r\n        if (!first) {\r\n            result.append(\".\");\r\n        }\r\n        first = false;\r\n        result.append(doQuote(identifier));\r\n    }\r\n    return result.toString();\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.TestDataReaderJRockit1_5_0.testGenConMemstats",
	"Comment": "this log file sample contains much more information about concurrent eventsthan is currently parsed. still the parser must be able to extract the informationit can parse.",
	"Method": "void testGenConMemstats(){\r\n    DataReader reader = getDataReader1_6(new GcResourceFile(\"SampleJRockit1_5_20_memstats2.txt\"));\r\n    GCModel model = reader.read();\r\n    assertEquals(\"count\", 11, model.size());\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.JUnit3FloatingPointComparisonWithoutDelta.isDouble",
	"Comment": "determines if the type is a double, including reference types.",
	"Method": "boolean isDouble(VisitorState state,Type type){\r\n    Type trueType = unboxedTypeOrType(state, type);\r\n    return trueType.getKind() == TypeKind.DOUBLE;\r\n}"
}, {
	"Path": "water.ClientDisconnectCheckThread.handleClientDisconnect",
	"Comment": "this method checks whether the client is disconnected from this node due to some problem such as client or networkis unreachable.",
	"Method": "void handleClientDisconnect(H2ONode node){\r\n    if (node != H2O.SELF) {\r\n        Log.warn(\"Client \" + node + \" disconnected!\");\r\n        if (H2O.isFlatfileEnabled()) {\r\n            H2O.removeNodeFromFlatfile(node);\r\n        }\r\n        H2O.removeClient(node);\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.base.Database.createSqlScriptExecutor",
	"Comment": "creates a new sqlscriptexecutor for this specific database.",
	"Method": "SqlScriptExecutor createSqlScriptExecutor(JdbcTemplate jdbcTemplate){\r\n    return new DefaultSqlScriptExecutor(jdbcTemplate);\r\n}"
}, {
	"Path": "jsr166y.ForkJoinPool.toString",
	"Comment": "returns a string identifying this pool, as well as its state,including indications of run state, parallelism level, andworker and task counts.",
	"Method": "String toString(){\r\n    long qt = 0L, qs = 0L;\r\n    int rc = 0;\r\n    long st = stealCount.get();\r\n    long c = ctl;\r\n    WorkQueue[] ws;\r\n    WorkQueue w;\r\n    if ((ws = workQueues) != null) {\r\n        for (int i = 0; i < ws.length; ++i) {\r\n            if ((w = ws[i]) != null) {\r\n                int size = w.queueSize();\r\n                if ((i & 1) == 0)\r\n                    qs += size;\r\n                else {\r\n                    qt += size;\r\n                    st += w.totalSteals;\r\n                    if (w.isApparentlyUnblocked())\r\n                        ++rc;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    int pc = parallelism;\r\n    int tc = pc + (short) (c >>> TC_SHIFT);\r\n    int ac = pc + (int) (c >> AC_SHIFT);\r\n    if (ac < 0)\r\n        ac = 0;\r\n    String level;\r\n    if ((c & STOP_BIT) != 0)\r\n        level = (tc == 0) ? \"Terminated\" : \"Terminating\";\r\n    else\r\n        level = runState < 0 ? \"Shutting down\" : \"Running\";\r\n    return super.toString() + \"[\" + level + \", parallelism = \" + pc + \", size = \" + tc + \", active = \" + ac + \", running = \" + rc + \", steals = \" + st + \", tasks = \" + qt + \", submissions = \" + qs + \"]\";\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.util.LoggerHelper.getCallerStackTraceElement",
	"Comment": "finds the first stacktraceelement outside this loggerhelper.",
	"Method": "StackTraceElement getCallerStackTraceElement(){\r\n    Throwable throwable = new Throwable();\r\n    String logClassName = LoggerHelper.class.getName();\r\n    for (StackTraceElement stackTraceElement : throwable.getStackTrace()) {\r\n        String cname = stackTraceElement.getClassName();\r\n        if (!cname.equals(logClassName)) {\r\n            return stackTraceElement;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.alibaba.excel.util.ObjectUtils.containsConstant",
	"Comment": "check whether the given array of enum constants contains a constant with the given name.",
	"Method": "boolean containsConstant(Enum<?>[] enumValues,String constant,boolean containsConstant,Enum<?>[] enumValues,String constant,boolean caseSensitive){\r\n    for (Enum<?> candidate : enumValues) {\r\n        if (caseSensitive ? candidate.toString().equals(constant) : candidate.toString().equalsIgnoreCase(constant)) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.crawler.CrawlConfig.setCrawlStorageFolder",
	"Comment": "the folder which will be used by crawler for storing the intermediatecrawl data. the content of this folder should not be modified manually.",
	"Method": "void setCrawlStorageFolder(String crawlStorageFolder){\r\n    this.crawlStorageFolder = crawlStorageFolder;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.FieldCanBeFinalTest.controlFlow",
	"Comment": "we currently handle this by ignoring control flow and looking for at least one initialization",
	"Method": "void controlFlow(){\r\n    compilationHelper.addSourceLines(\"Test.java\", \"class Test {\", \"  // BUG: Diagnostic contains: private final int x\", \"  private int x;\", \"  Test(boolean flag, int x, int y) {\", \"    if (flag) {\", \"      this.x = x;\", \"    } else {\", \"      this.x = y;\", \"    }\", \"  }\", \"}\").doTest();\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.configuration",
	"Comment": "configures flyway with these properties. this overwrites any existing configuration. property names aredocumented in the flyway maven plugin.to use a custom classloader, it must be passed to the flyway constructor prior to calling this method.",
	"Method": "FluentConfiguration configuration(Configuration configuration,FluentConfiguration configuration,Properties properties,FluentConfiguration configuration,Map<String, String> props){\r\n    config.configure(props);\r\n    return this;\r\n}"
}, {
	"Path": "com.google.errorprone.BugPatternFileGeneratorTest.regressionTest_frontmatter_pygments",
	"Comment": "in the same jekyll environment you use for prod, and verify it looks good.",
	"Method": "void regressionTest_frontmatter_pygments(){\r\n    BugPatternFileGenerator generator = new BugPatternFileGenerator(wikiDir, exampleDirBase, explanationDirBase, true, true, null, input -> input.severity);\r\n    generator.processLine(BUGPATTERN_LINE);\r\n    String expected = CharStreams.toString(new InputStreamReader(getClass().getResourceAsStream(\"testdata/DeadException_frontmatter_pygments.md\"), UTF_8));\r\n    String actual = CharStreams.toString(Files.newBufferedReader(wikiDir.resolve(\"DeadException.md\"), UTF_8));\r\n    assertThat(actual.trim()).isEqualTo(expected.trim());\r\n}"
}, {
	"Path": "com.orhanobut.dialogplus.DialogPlus.initCancelable",
	"Comment": "it is called to set whether the dialog is cancellable by pressing back button ortouching the black overlay",
	"Method": "void initCancelable(){\r\n    if (!isCancelable) {\r\n        return;\r\n    }\r\n    View view = rootView.findViewById(R.id.dialogplus_outmost_container);\r\n    view.setOnTouchListener(onCancelableTouchListener);\r\n}"
}, {
	"Path": "com.google.errorprone.names.NeedlemanWunschEditDistance.scriptCost",
	"Comment": "return the cost of a script consisting of a contiguous sequence of insertions or a contiguoussequence of deletions.",
	"Method": "int scriptCost(int openGapCost,int continueGapCost,int scriptLength){\r\n    return (scriptLength == 0) ? 0 : openGapCost + scriptLength * continueGapCost;\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.sqlserver.SQLServerDatabase.escapeIdentifier",
	"Comment": "escapes this identifier, so it can be safely used in sql queries.",
	"Method": "String escapeIdentifier(String identifier){\r\n    return StringUtils.replaceAll(identifier, \"]\", \"]]\");\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.staticFieldAccess",
	"Comment": "matches an ast node which is an expression yielding the indicated static field access.",
	"Method": "Matcher<ExpressionTree> staticFieldAccess(){\r\n    return allOf(isStatic(), isSymbol(VarSymbol.class));\r\n}"
}, {
	"Path": "feign.RequestTemplate.header",
	"Comment": "specify a header, with the specified values. values can be literals or template expressions.",
	"Method": "RequestTemplate header(String name,String values,RequestTemplate header,String name,Iterable<String> values){\r\n    if (name == null || name.isEmpty()) {\r\n        throw new IllegalArgumentException(\"name is required.\");\r\n    }\r\n    if (values == null) {\r\n        values = Collections.emptyList();\r\n    }\r\n    return appendHeader(name, values);\r\n}"
}, {
	"Path": "water.nbhm.NonBlockingHashMap.print2",
	"Comment": "print only the live values, broken down by the table they are in",
	"Method": "void print2(Object[] kvs){\r\n    for (int i = 0; i < len(kvs); i++) {\r\n        Object key = key(kvs, i);\r\n        Object val = val(kvs, i);\r\n        Object U = Prime.unbox(val);\r\n        if (key != null && key != TOMBSTONE && val != null && U != TOMBSTONE) {\r\n            String p = (val == U) ? \"\" : \"prime_\";\r\n            System.out.println(\"\" + i + \" (\" + key + \",\" + p + val + \")\");\r\n        }\r\n    }\r\n    Object[] newkvs = chm(kvs)._newkvs;\r\n    if (newkvs != null) {\r\n        System.out.println(\"----\");\r\n        print2(newkvs);\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.inject.guice.AssistedParameters.partitionParametersByType",
	"Comment": "determine which parameters are conflicting with each other.",
	"Method": "Multimap<Type, VariableTree> partitionParametersByType(List<VariableTree> parameters,VisitorState state){\r\n    Types types = state.getTypes();\r\n    Multimap<Type, VariableTree> multimap = LinkedListMultimap.create();\r\n    variables: for (VariableTree node : parameters) {\r\n        Type type = types.unboxedTypeOrType(ASTHelpers.getType(node));\r\n        for (Type existingType : multimap.keySet()) {\r\n            if (types.isSameType(existingType, type)) {\r\n                multimap.put(existingType, node);\r\n                continue variables;\r\n            }\r\n        }\r\n        multimap.put(type, node);\r\n    }\r\n    return multimap;\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.FluentConfiguration.installedBy",
	"Comment": "the username that will be recorded in the schema history table as having applied the migration.",
	"Method": "FluentConfiguration installedBy(String installedBy){\r\n    config.setInstalledBy(installedBy);\r\n    return this;\r\n}"
}, {
	"Path": "hex.kmeans.KMeans.makeTrainingMetrics",
	"Comment": "this helper creates a modelmetricsclustering from a trained model",
	"Method": "ModelMetricsClustering makeTrainingMetrics(KMeansModel model){\r\n    ModelMetricsClustering mm = new ModelMetricsClustering(model, train(), CustomMetric.EMPTY);\r\n    mm._size = model._output._size;\r\n    mm._withinss = model._output._withinss;\r\n    mm._betweenss = model._output._betweenss;\r\n    mm._totss = model._output._totss;\r\n    mm._tot_withinss = model._output._tot_withinss;\r\n    model.addMetrics(mm);\r\n    return mm;\r\n}"
}, {
	"Path": "hex.ModelMetrics.deepCloneWithDifferentModelAndFrame",
	"Comment": "utility used by code which creates metrics on a different frame and model thanthe ones that we want the metrics object to be accessible for.an example isstackedensemblemodel, which computes the metrics with a metalearner model.",
	"Method": "ModelMetrics deepCloneWithDifferentModelAndFrame(Model model,Frame frame){\r\n    ModelMetrics m = this.clone();\r\n    m._key = buildKey(model, frame);\r\n    m.setModelAndFrameFields(model, frame);\r\n    return m;\r\n}"
}, {
	"Path": "water.fvec.Chunk.getSparseDoubles",
	"Comment": "sparse bulk interface, stream through the compressed values and extract them into dense double array.",
	"Method": "int getSparseDoubles(double[] vals,int[] ids,int getSparseDoubles,double[] vals,int[] ids,double NA){\r\n    return processRows(new ChunkVisitor.SparseDoubleAryVisitor(vals, ids, isSparseNA(), NA), 0, _len).sparseLen();\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.scanner.classpath.ClassPathScanner.createUrlResolver",
	"Comment": "creates an appropriate url resolver scanner for this url protocol.",
	"Method": "UrlResolver createUrlResolver(String protocol){\r\n    if (new FeatureDetector(classLoader).isJBossVFSv2Available() && protocol.startsWith(\"vfs\")) {\r\n        return new JBossVFSv2UrlResolver();\r\n    }\r\n    return new DefaultUrlResolver();\r\n}"
}, {
	"Path": "edu.uci.ics.crawler4j.fetcher.PageFetcher.newHttpUriRequest",
	"Comment": "creates a new httpurirequest for the given url. the default is to create a httpget withoutany further configuration. subclasses may override this method and provide their own logic.",
	"Method": "HttpUriRequest newHttpUriRequest(String url){\r\n    return new HttpGet(url);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.util.FileCopyUtils.copy",
	"Comment": "copy the contents of the given inputstream to the given outputstream.closes both streams when done.",
	"Method": "void copy(Reader in,Writer out,int copy,InputStream in,OutputStream out){\r\n    try {\r\n        int byteCount = 0;\r\n        byte[] buffer = new byte[4096];\r\n        int bytesRead;\r\n        while ((bytesRead = in.read(buffer)) != -1) {\r\n            out.write(buffer, 0, bytesRead);\r\n            byteCount += bytesRead;\r\n        }\r\n        out.flush();\r\n        return byteCount;\r\n    } finally {\r\n        IOUtils.close(in);\r\n        IOUtils.close(out);\r\n    }\r\n}"
}, {
	"Path": "jsr166y.ForkJoinTask.setCompletion",
	"Comment": "marks completion and wakes up threads waiting to join thistask.",
	"Method": "int setCompletion(int completion){\r\n    for (int s; ; ) {\r\n        if ((s = status) < 0)\r\n            return s;\r\n        if (U.compareAndSwapInt(this, STATUS, s, s | completion)) {\r\n            if ((s >>> 16) != 0)\r\n                synchronized (this) {\r\n                    notifyAll();\r\n                }\r\n            return completion;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setBaselineVersionAsString",
	"Comment": "sets the version to tag an existing schema with when executing baseline.",
	"Method": "void setBaselineVersionAsString(String baselineVersion){\r\n    this.baselineVersion = MigrationVersion.fromVersion(baselineVersion);\r\n}"
}, {
	"Path": "com.alibaba.excel.util.CollectionUtils.findValueOfType",
	"Comment": "find a single value of the given type in the given collection.",
	"Method": "T findValueOfType(Collection<?> collection,Class<T> type,Object findValueOfType,Collection<?> collection,Class<?>[] types){\r\n    if (isEmpty(collection) || ObjectUtils.isEmpty(types)) {\r\n        return null;\r\n    }\r\n    for (Class<?> type : types) {\r\n        Object value = findValueOfType(collection, type);\r\n        if (value != null) {\r\n            return value;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "com.google.errorprone.matchers.Matchers.isDescendantOfMethod",
	"Comment": "matches an instance method that is a descendant of the instance method specified by the classname and method name.",
	"Method": "Matcher<ExpressionTree> isDescendantOfMethod(String fullClassName,String methodName){\r\n    return new DescendantOf(fullClassName, methodName);\r\n}"
}, {
	"Path": "hex.deeplearning.DeepLearningModelInfo.size",
	"Comment": "momenta are not counted here, but they are needed for model building",
	"Method": "long size(){\r\n    long siz = 0;\r\n    for (Storage.DenseRowMatrix w : dense_row_weights) if (w != null)\r\n        siz += w.size();\r\n    for (Storage.Vector b : biases) siz += b.size();\r\n    return siz;\r\n}"
}, {
	"Path": "hex.grid.GridSearch.gridKeyName",
	"Comment": "defines a key for a new grid object holding results of grid search.",
	"Method": "Key<Grid> gridKeyName(String modelName,Frame fr){\r\n    if (fr == null || fr._key == null) {\r\n        throw new IllegalArgumentException(\"The frame being grid-searched over must have a Key\");\r\n    }\r\n    return Key.make(\"Grid_\" + modelName + \"_\" + fr._key.toString() + H2O.calcNextUniqueModelId(\"\"));\r\n}"
}, {
	"Path": "hex.pdp.PartialDependenceTest.prostateRegressionWeighted",
	"Comment": "this test will test the pdp for regression outputs without weights and with constant weights.the pdp generatedhere should be the same.in addition, i generated pdp for one numeric column and one enum column.",
	"Method": "void prostateRegressionWeighted(){\r\n    Scope.enter();\r\n    Frame fr = null;\r\n    GBMModel model = null;\r\n    PartialDependence partialDependence = null;\r\n    PartialDependence partialDependenceW = null;\r\n    try {\r\n        fr = parse_test_file(\"smalldata/prostate/prostate.csv\");\r\n        for (String s : new String[] { \"RACE\", \"GLEASON\", \"DPROS\", \"DCAPS\", \"CAPSULE\" }) {\r\n            Vec v = fr.remove(s);\r\n            fr.add(s, v.toCategoricalVec());\r\n            v.remove();\r\n        }\r\n        Scope.track(fr);\r\n        Vec orig = fr.anyVec();\r\n        Vec[] weights = new Vec[1];\r\n        weights[0] = orig.makeCon(2.0);\r\n        fr.add(new String[] { \"weights\" }, weights);\r\n        Scope.track(orig);\r\n        Scope.track(weights[0]);\r\n        DKV.put(fr);\r\n        GBMModel.GBMParameters parms = new GBMModel.GBMParameters();\r\n        parms._train = fr._key;\r\n        parms._ignored_columns = new String[] { \"ID\" };\r\n        parms._response_column = \"AGE\";\r\n        model = new GBM(parms).trainModel().get();\r\n        Scope.track_generic(model);\r\n        partialDependence = new PartialDependence(Key.<PartialDependence>make());\r\n        partialDependence._nbins = 10;\r\n        partialDependence._model_id = (Key) model._key;\r\n        partialDependence._frame_id = fr._key;\r\n        partialDependence._cols = new String[] { \"AGE\", \"RACE\" };\r\n        partialDependence.execImpl().get();\r\n        Scope.track_generic(partialDependence);\r\n        partialDependenceW = new PartialDependence(Key.<PartialDependence>make());\r\n        partialDependenceW._nbins = 10;\r\n        partialDependenceW._model_id = (Key) model._key;\r\n        partialDependenceW._frame_id = fr._key;\r\n        partialDependenceW._weight_column_index = fr.numCols() - 1;\r\n        partialDependenceW._cols = new String[] { \"AGE\", \"RACE\" };\r\n        partialDependenceW.execImpl().get();\r\n        Scope.track_generic(partialDependenceW);\r\n        assert equalTwoDimTables(partialDependence._partial_dependence_data[0], partialDependenceW._partial_dependence_data[0], 1e-10) : \"pdp with constant weight and without weight generated different answers for column AGE.\";\r\n        assert equalTwoDimTables(partialDependence._partial_dependence_data[1], partialDependenceW._partial_dependence_data[1], 1e-10) : \"pdp with constant weight and without weight generated different answers for column RACE.\";\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "hex.DataInfo.mapNames",
	"Comment": "return permutation matrix mapping input names to adaptedframe colnames",
	"Method": "int[] mapNames(String[] names){\r\n    assert names.length == _adaptedFrame._names.length : \"Names must be the same length!\";\r\n    int[] idx = new int[names.length];\r\n    Arrays.fill(idx, -1);\r\n    for (int i = 0; i < _adaptedFrame._names.length; i++) {\r\n        for (int j = 0; j < names.length; j++) {\r\n            if (names[j].equals(_adaptedFrame.name(i))) {\r\n                idx[i] = j;\r\n                break;\r\n            }\r\n        }\r\n    }\r\n    return idx;\r\n}"
}, {
	"Path": "ai.h2o.automl.targetencoding.TargetEncodingLeaveOneOutStrategyTest.comparisonBetweenNAsAndNonEmptyStringForLOOStrategyTest",
	"Comment": "test that na and empty strings create same encoding. imputed average is slightly different for some reason",
	"Method": "void comparisonBetweenNAsAndNonEmptyStringForLOOStrategyTest(){\r\n    String teColumnName = \"ColA\";\r\n    String targetColumnName = \"ColB\";\r\n    fr = new TestFrameBuilder().withName(\"testFrame\").withColNames(teColumnName, targetColumnName).withVecTypes(Vec.T_CAT, Vec.T_CAT).withDataForCol(0, ar(\"a\", \"b\", null, null, null)).withDataForCol(1, ar(\"2\", \"6\", \"6\", \"2\", \"6\")).build();\r\n    Frame fr2 = new TestFrameBuilder().withName(\"testFrame2\").withColNames(teColumnName, targetColumnName).withVecTypes(Vec.T_CAT, Vec.T_CAT).withDataForCol(0, ar(\"a\", \"b\", \"na\", \"na\", \"na\")).withDataForCol(1, ar(\"2\", \"6\", \"6\", \"2\", \"6\")).build();\r\n    String[] teColumns = { teColumnName };\r\n    TargetEncoder tec = new TargetEncoder(teColumns);\r\n    Map<String, Frame> targetEncodingMap = tec.prepareEncodingMap(fr, targetColumnName, null);\r\n    Frame resultWithEncoding = tec.applyTargetEncoding(fr, targetColumnName, targetEncodingMap, TargetEncoder.DataLeakageHandlingStrategy.LeaveOneOut, false, 0.0, true, 1234, true);\r\n    Map<String, Frame> targetEncodingMap2 = tec.prepareEncodingMap(fr2, targetColumnName, null);\r\n    Frame resultWithEncoding2 = tec.applyTargetEncoding(fr2, targetColumnName, targetEncodingMap2, TargetEncoder.DataLeakageHandlingStrategy.LeaveOneOut, false, 0.0, true, 1234, true);\r\n    Frame sortedResult = resultWithEncoding.sort(new int[] { 2 }, new int[] { 2 });\r\n    Frame sortedResult2 = resultWithEncoding2.sort(new int[] { 2 }, new int[] { 2 });\r\n    assertVecEquals(sortedResult.vec(\"ColA_te\"), sortedResult2.vec(\"ColA_te\"), 1e-5);\r\n    encodingMapCleanUp(targetEncodingMap);\r\n    encodingMapCleanUp(targetEncodingMap2);\r\n    fr2.delete();\r\n    sortedResult.delete();\r\n    sortedResult2.delete();\r\n    resultWithEncoding.delete();\r\n    resultWithEncoding2.delete();\r\n}"
}, {
	"Path": "com.google.errorprone.names.LevenshteinEditDistance.isEmptyOrWhitespace",
	"Comment": "determines if a string is empty or consists only of whitespace",
	"Method": "boolean isEmptyOrWhitespace(String source){\r\n    return source == null || source.matches(\"\\\\s*\");\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.scanner.classpath.ClassPathScanner.toClassName",
	"Comment": "converts this resource name to a fully qualified class name.",
	"Method": "String toClassName(String resourceName){\r\n    String nameWithDots = resourceName.replace(\"/\", \".\");\r\n    return nameWithDots.substring(0, (nameWithDots.length() - \".class\".length()));\r\n}"
}, {
	"Path": "com.google.errorprone.util.ASTHelpers.findEnclosingNode",
	"Comment": "given a treepath, walks up the tree until it finds a node of the given type. returns null if nosuch node is found.",
	"Method": "T findEnclosingNode(TreePath path,Class<T> klass){\r\n    path = findPathFromEnclosingNodeToTopLevel(path, klass);\r\n    return (path == null) ? null : klass.cast(path.getLeaf());\r\n}"
}, {
	"Path": "hex.ScoringInfo.createScoringHistoryTable",
	"Comment": "create a twodimtable to display the scoring history from an array of scoringinfo.",
	"Method": "TwoDimTable createScoringHistoryTable(ScoringInfo[] scoringInfos,boolean hasValidation,boolean hasCrossValidation,ModelCategory modelCategory,boolean isAutoencoder){\r\n    boolean hasEpochs = (scoringInfos instanceof HasEpochs[]);\r\n    boolean hasSamples = (scoringInfos instanceof HasSamples[]);\r\n    boolean hasIterations = (scoringInfos instanceof HasIterations[]);\r\n    boolean isClassifier = (modelCategory == ModelCategory.Binomial || modelCategory == ModelCategory.Multinomial || modelCategory == ModelCategory.Ordinal);\r\n    List<String> colHeaders = new ArrayList();\r\n    List<String> colTypes = new ArrayList();\r\n    List<String> colFormat = new ArrayList();\r\n    colHeaders.add(\"Timestamp\");\r\n    colTypes.add(\"string\");\r\n    colFormat.add(\"%s\");\r\n    colHeaders.add(\"Duration\");\r\n    colTypes.add(\"string\");\r\n    colFormat.add(\"%s\");\r\n    if (hasSamples) {\r\n        colHeaders.add(\"Training Speed\");\r\n        colTypes.add(\"string\");\r\n        colFormat.add(\"%s\");\r\n    }\r\n    if (hasEpochs) {\r\n        colHeaders.add(\"Epochs\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n    }\r\n    if (hasIterations) {\r\n        colHeaders.add(\"Iterations\");\r\n        colTypes.add(\"int\");\r\n        colFormat.add(\"%d\");\r\n    }\r\n    if (hasSamples) {\r\n        colHeaders.add(\"Samples\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%f\");\r\n    }\r\n    colHeaders.add(\"Training RMSE\");\r\n    colTypes.add(\"double\");\r\n    colFormat.add(\"%.5f\");\r\n    if (modelCategory == ModelCategory.Regression) {\r\n        colHeaders.add(\"Training Deviance\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n        colHeaders.add(\"Training MAE\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n        colHeaders.add(\"Training r2\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n    }\r\n    if (isClassifier) {\r\n        colHeaders.add(\"Training LogLoss\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n        colHeaders.add(\"Training r2\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n    }\r\n    if (modelCategory == ModelCategory.Binomial) {\r\n        colHeaders.add(\"Training AUC\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n        colHeaders.add(\"Training pr_auc\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n        colHeaders.add(\"Training Lift\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n    }\r\n    if (isClassifier) {\r\n        colHeaders.add(\"Training Classification Error\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n    }\r\n    if (modelCategory == ModelCategory.AutoEncoder) {\r\n        colHeaders.add(\"Training MSE\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n    }\r\n    if (hasValidation) {\r\n        colHeaders.add(\"Validation RMSE\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n        if (modelCategory == ModelCategory.Regression) {\r\n            colHeaders.add(\"Validation Deviance\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n            colHeaders.add(\"Validation MAE\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n            colHeaders.add(\"Validation r2\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n        }\r\n        if (isClassifier) {\r\n            colHeaders.add(\"Validation LogLoss\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n            colHeaders.add(\"Validation r2\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n        }\r\n        if (modelCategory == ModelCategory.Binomial) {\r\n            colHeaders.add(\"Validation AUC\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n            colHeaders.add(\"Validation pr_auc\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n            colHeaders.add(\"Validation Lift\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n        }\r\n        if (isClassifier) {\r\n            colHeaders.add(\"Validation Classification Error\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n        }\r\n        if (modelCategory == ModelCategory.AutoEncoder) {\r\n            colHeaders.add(\"Validation MSE\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n        }\r\n    }\r\n    if (hasCrossValidation) {\r\n        colHeaders.add(\"Cross-Validation RMSE\");\r\n        colTypes.add(\"double\");\r\n        colFormat.add(\"%.5f\");\r\n        if (modelCategory == ModelCategory.Regression) {\r\n            colHeaders.add(\"Cross-Validation Deviance\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n            colHeaders.add(\"Cross-Validation MAE\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n            colHeaders.add(\"Cross-Validation r2\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n        }\r\n        if (isClassifier) {\r\n            colHeaders.add(\"Cross-Validation LogLoss\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n            colHeaders.add(\"Cross-Validation r2\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n        }\r\n        if (modelCategory == ModelCategory.Binomial) {\r\n            colHeaders.add(\"Cross-Validation AUC\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n            colHeaders.add(\"Cross-Validation pr_auc\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n            colHeaders.add(\"Cross-Validation Lift\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n        }\r\n        if (isClassifier) {\r\n            colHeaders.add(\"Cross-Validation Classification Error\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n        }\r\n        if (modelCategory == ModelCategory.AutoEncoder) {\r\n            colHeaders.add(\"Cross-Validation MSE\");\r\n            colTypes.add(\"double\");\r\n            colFormat.add(\"%.5f\");\r\n        }\r\n    }\r\n    final int rows = scoringInfos == null ? 0 : scoringInfos.length;\r\n    String[] s = new String[0];\r\n    TwoDimTable table = new TwoDimTable(\"Scoring History\", null, new String[rows], colHeaders.toArray(s), colTypes.toArray(s), colFormat.toArray(s), \"\");\r\n    int row = 0;\r\n    if (null == scoringInfos)\r\n        return table;\r\n    for (ScoringInfo si : scoringInfos) {\r\n        int col = 0;\r\n        assert (row < table.getRowDim());\r\n        assert (col < table.getColDim());\r\n        DateTimeFormatter fmt = DateTimeFormat.forPattern(\"yyyy-MM-dd HH:mm:ss\");\r\n        table.set(row, col++, fmt.print(si.time_stamp_ms));\r\n        table.set(row, col++, PrettyPrint.msecs(si.total_training_time_ms, true));\r\n        if (hasSamples) {\r\n            float speed = (float) (((HasSamples) si).training_samples() / ((1. + si.total_training_time_ms - si.total_scoring_time_ms - si.total_setup_time_ms) / 1e3));\r\n            assert (speed >= 0) : \"Speed should not be negative! \" + speed + \" = (float)(\" + ((HasSamples) si).training_samples() + \"/((\" + si.total_training_time_ms + \"-\" + si.total_scoring_time_ms + \"-\" + si.total_setup_time_ms + \")/1e3)\";\r\n            table.set(row, col++, si.total_training_time_ms == 0 ? null : (speed > 10 ? String.format(\"%d\", (int) speed) : String.format(\"%g\", speed)) + \" obs/sec\");\r\n        }\r\n        if (hasEpochs)\r\n            table.set(row, col++, ((HasEpochs) si).epoch_counter());\r\n        if (hasIterations)\r\n            table.set(row, col++, ((HasIterations) si).iterations());\r\n        if (hasSamples)\r\n            table.set(row, col++, ((HasSamples) si).training_samples());\r\n        table.set(row, col++, si.scored_train != null ? si.scored_train._rmse : Double.NaN);\r\n        if (modelCategory == ModelCategory.Regression) {\r\n            table.set(row, col++, si.scored_train != null ? si.scored_train._mean_residual_deviance : Double.NaN);\r\n            table.set(row, col++, si.scored_train != null ? si.scored_train._mae : Double.NaN);\r\n            table.set(row, col++, si.scored_train != null ? si.scored_train._r2 : Double.NaN);\r\n        }\r\n        if (isClassifier) {\r\n            table.set(row, col++, si.scored_train != null ? si.scored_train._logloss : Double.NaN);\r\n            table.set(row, col++, si.scored_train != null ? si.scored_train._r2 : Double.NaN);\r\n        }\r\n        if (modelCategory == ModelCategory.Binomial) {\r\n            table.set(row, col++, si.training_AUC != null ? si.training_AUC._auc : Double.NaN);\r\n            table.set(row, col++, si.training_AUC != null ? si.training_AUC.pr_auc() : Double.NaN);\r\n            table.set(row, col++, si.scored_train != null ? si.scored_train._lift : Double.NaN);\r\n        }\r\n        if (isClassifier) {\r\n            table.set(row, col++, si.scored_train != null ? si.scored_train._classError : Double.NaN);\r\n        }\r\n        if (isAutoencoder) {\r\n            table.set(row, col++, si.scored_train != null ? si.scored_train._mse : Double.NaN);\r\n        }\r\n        if (hasValidation) {\r\n            table.set(row, col++, si.scored_valid != null ? si.scored_valid._rmse : Double.NaN);\r\n            if (modelCategory == ModelCategory.Regression) {\r\n                table.set(row, col++, si.scored_valid != null ? si.scored_valid._mean_residual_deviance : Double.NaN);\r\n                table.set(row, col++, si.scored_valid != null ? si.scored_valid._mae : Double.NaN);\r\n                table.set(row, col++, si.scored_valid != null ? si.scored_valid._r2 : Double.NaN);\r\n            }\r\n            if (isClassifier) {\r\n                table.set(row, col++, si.scored_valid != null ? si.scored_valid._logloss : Double.NaN);\r\n                table.set(row, col++, si.scored_valid != null ? si.scored_valid._r2 : Double.NaN);\r\n            }\r\n            if (modelCategory == ModelCategory.Binomial) {\r\n                table.set(row, col++, si.scored_valid != null ? si.scored_valid._AUC : Double.NaN);\r\n                table.set(row, col++, si.scored_valid != null ? si.scored_valid._pr_auc : Double.NaN);\r\n                table.set(row, col++, si.scored_valid != null ? si.scored_valid._lift : Double.NaN);\r\n            }\r\n            if (isClassifier) {\r\n                table.set(row, col++, si.scored_valid != null ? si.scored_valid._classError : Double.NaN);\r\n            }\r\n            if (isAutoencoder) {\r\n                table.set(row, col++, si.scored_valid != null ? si.scored_valid._mse : Double.NaN);\r\n            }\r\n        }\r\n        if (hasCrossValidation) {\r\n            table.set(row, col++, si.scored_xval != null ? si.scored_xval._rmse : Double.NaN);\r\n            if (modelCategory == ModelCategory.Regression) {\r\n                table.set(row, col++, si.scored_xval != null ? si.scored_xval._mean_residual_deviance : Double.NaN);\r\n                table.set(row, col++, si.scored_xval != null ? si.scored_xval._mae : Double.NaN);\r\n                table.set(row, col++, si.scored_xval != null ? si.scored_xval._r2 : Double.NaN);\r\n            }\r\n            if (isClassifier) {\r\n                table.set(row, col++, si.scored_xval != null ? si.scored_xval._logloss : Double.NaN);\r\n                table.set(row, col++, si.scored_xval != null ? si.scored_xval._r2 : Double.NaN);\r\n            }\r\n            if (modelCategory == ModelCategory.Binomial) {\r\n                table.set(row, col++, si.scored_xval != null ? si.scored_xval._AUC : Double.NaN);\r\n                table.set(row, col++, si.scored_xval != null ? si.scored_xval._pr_auc : Double.NaN);\r\n                table.set(row, col++, si.scored_xval != null ? si.scored_xval._lift : Double.NaN);\r\n            }\r\n            if (isClassifier) {\r\n                table.set(row, col, si.scored_xval != null ? si.scored_xval._classError : Double.NaN);\r\n            }\r\n            if (isAutoencoder) {\r\n                table.set(row, col++, si.scored_xval != null ? si.scored_xval._mse : Double.NaN);\r\n            }\r\n        }\r\n        row++;\r\n    }\r\n    return table;\r\n}"
}, {
	"Path": "graphql.schema.idl.SchemaDirectiveWiring.onField",
	"Comment": "this is called when a field is encountered, which gives the schema directive a chance to modify the shape and behaviourof that dslelement",
	"Method": "GraphQLFieldDefinition onField(SchemaDirectiveWiringEnvironment<GraphQLFieldDefinition> environment){\r\n    return environment.getElement();\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.util.BuildInfoReader.getVersion",
	"Comment": "read version from properties file in classpath if it can be found.",
	"Method": "String getVersion(){\r\n    return readPropertyValue(BUILD_VERSION);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.ModifyingCollectionWithItself.matchMethodInvocation",
	"Comment": "matches calls to addall, containsall, removeall, and retainall on itself",
	"Method": "Description matchMethodInvocation(MethodInvocationTree t,VisitorState state){\r\n    if (IS_COLLECTION_MODIFIED_WITH_ITSELF.matches(t, state)) {\r\n        return describe(t, state);\r\n    }\r\n    return Description.NO_MATCH;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.argumentselectiondefects.NamedParameterComment.containsSyntheticParameterName",
	"Comment": "returns true if the method has synthetic parameter names, indicating the real names are notavailable.",
	"Method": "boolean containsSyntheticParameterName(MethodSymbol sym){\r\n    return sym.getParameters().stream().anyMatch(p -> SYNTHETIC_PARAMETER_NAME.matcher(p.getSimpleName()).matches());\r\n}"
}, {
	"Path": "com.alibaba.excel.util.CollectionUtils.toArray",
	"Comment": "marshal the elements from the given enumeration into an array of the given type.enumeration elements must be assignable to the type of the given array. the arrayreturned will be a different instance than the array given.",
	"Method": "A[] toArray(Enumeration<E> enumeration,A[] array){\r\n    ArrayList<A> elements = new ArrayList<A>();\r\n    while (enumeration.hasMoreElements()) {\r\n        elements.add(enumeration.nextElement());\r\n    }\r\n    return elements.toArray(array);\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.UnnecessaryDefaultInEnumSwitch.trivialDefault",
	"Comment": "returns true if the default is empty, or contains only a break statement.",
	"Method": "boolean trivialDefault(List<? extends StatementTree> defaultStatements){\r\n    if (defaultStatements.isEmpty()) {\r\n        return true;\r\n    }\r\n    return (defaultStatements.size() == 1 && getOnlyElement(defaultStatements).getKind() == Tree.Kind.BREAK);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.oracle.OracleDatabase.isFlashbackDataArchiveAvailable",
	"Comment": "checks whether flashback data archive option is available or not.",
	"Method": "boolean isFlashbackDataArchiveAvailable(){\r\n    return getAvailableOptions().contains(\"Flashback Data Archive\");\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.AbstractDataReaderSun.getMemoryInKiloByte",
	"Comment": "returns the amount of memory in kilobyte. depending on memunit, input isconverted to kilobyte.",
	"Method": "int getMemoryInKiloByte(double memoryValue,char memUnit,String line){\r\n    return getDataReaderTools().getMemoryInKiloByte(memoryValue, memUnit, line);\r\n}"
}, {
	"Path": "water.ExternalFrameWriterClient.createChunks",
	"Comment": "create chunks on the h2o backend. this method creates chunk in en empty frame.",
	"Method": "void createChunks(String frameKey,byte[] expectedTypes,int chunkId,int totalNumRows,int[] maxVecSizes){\r\n    ab.put1(ExternalFrameHandler.INIT_BYTE);\r\n    ab.put1(ExternalFrameHandler.CREATE_FRAME);\r\n    ab.putStr(frameKey);\r\n    this.expectedTypes = expectedTypes;\r\n    ab.putA1(expectedTypes);\r\n    ab.putA4(maxVecSizes);\r\n    ab.putInt(totalNumRows);\r\n    ab.putInt(chunkId);\r\n    writeToChannel(ab, channel);\r\n}"
}, {
	"Path": "eu.siacs.conversations.utils.Patterns.digitsAndPlusOnly",
	"Comment": "convenience method to return only the digits and plus signsin the matching string.",
	"Method": "String digitsAndPlusOnly(Matcher matcher){\r\n    StringBuilder buffer = new StringBuilder();\r\n    String matchingRegion = matcher.group();\r\n    for (int i = 0, size = matchingRegion.length(); i < size; i++) {\r\n        char character = matchingRegion.charAt(i);\r\n        if (character == '+' || Character.isDigit(character)) {\r\n            buffer.append(character);\r\n        }\r\n    }\r\n    return buffer.toString();\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setBaselineDescription",
	"Comment": "sets the description to tag an existing schema with when executing baseline.",
	"Method": "void setBaselineDescription(String baselineDescription){\r\n    this.baselineDescription = baselineDescription;\r\n}"
}, {
	"Path": "graphql.introspection.IntrospectionResultToSchema.createSchemaDefinition",
	"Comment": "returns a idl document that reprsesents the schema as defined by the introspection result map",
	"Method": "Document createSchemaDefinition(ExecutionResult introspectionResult,Document createSchemaDefinition,Map<String, Object> introspectionResult){\r\n    assertTrue(introspectionResult.get(\"__schema\") != null, \"__schema expected\");\r\n    Map<String, Object> schema = (Map<String, Object>) introspectionResult.get(\"__schema\");\r\n    Map<String, Object> queryType = (Map<String, Object>) schema.get(\"queryType\");\r\n    assertNotNull(queryType, \"queryType expected\");\r\n    TypeName query = TypeName.newTypeName().name((String) queryType.get(\"name\")).build();\r\n    boolean nonDefaultQueryName = !\"Query\".equals(query.getName());\r\n    SchemaDefinition.Builder schemaDefinition = SchemaDefinition.newSchemaDefinition();\r\n    schemaDefinition.operationTypeDefinition(OperationTypeDefinition.newOperationTypeDefinition().name(\"query\").type(query).build());\r\n    Map<String, Object> mutationType = (Map<String, Object>) schema.get(\"mutationType\");\r\n    boolean nonDefaultMutationName = false;\r\n    if (mutationType != null) {\r\n        TypeName mutation = TypeName.newTypeName().name((String) mutationType.get(\"name\")).build();\r\n        nonDefaultMutationName = !\"Mutation\".equals(mutation.getName());\r\n        schemaDefinition.operationTypeDefinition(OperationTypeDefinition.newOperationTypeDefinition().name(\"mutation\").type(mutation).build());\r\n    }\r\n    Map<String, Object> subscriptionType = (Map<String, Object>) schema.get(\"subscriptionType\");\r\n    boolean nonDefaultSubscriptionName = false;\r\n    if (subscriptionType != null) {\r\n        TypeName subscription = TypeName.newTypeName().name(((String) subscriptionType.get(\"name\"))).build();\r\n        nonDefaultSubscriptionName = !\"Subscription\".equals(subscription.getName());\r\n        schemaDefinition.operationTypeDefinition(OperationTypeDefinition.newOperationTypeDefinition().name(\"subscription\").type(subscription).build());\r\n    }\r\n    Document.Builder document = Document.newDocument();\r\n    if (nonDefaultQueryName || nonDefaultMutationName || nonDefaultSubscriptionName) {\r\n        document.definition(schemaDefinition.build());\r\n    }\r\n    List<Map<String, Object>> types = (List<Map<String, Object>>) schema.get(\"types\");\r\n    for (Map<String, Object> type : types) {\r\n        TypeDefinition typeDefinition = createTypeDefinition(type);\r\n        if (typeDefinition == null)\r\n            continue;\r\n        document.definition(typeDefinition);\r\n    }\r\n    return document.build();\r\n}"
}, {
	"Path": "hex.Distribution.initFDenom",
	"Comment": "contribution to denominator for initial value computation",
	"Method": "double initFDenom(double w,double o,double y){\r\n    switch(distribution) {\r\n        case AUTO:\r\n        case gaussian:\r\n        case bernoulli:\r\n        case quasibinomial:\r\n        case multinomial:\r\n        case gamma:\r\n            return w;\r\n        case poisson:\r\n            return w * linkInv(o);\r\n        case tweedie:\r\n            return w * exp(o * (2 - tweediePower));\r\n        case modified_huber:\r\n            return y == 1 ? 0 : w;\r\n        default:\r\n            throw H2O.unimpl();\r\n    }\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setCleanDisabled",
	"Comment": "whether to disable clean.this is especially useful for production environments where running clean can be quite a career limiting move.",
	"Method": "void setCleanDisabled(boolean cleanDisabled){\r\n    this.cleanDisabled = cleanDisabled;\r\n}"
}, {
	"Path": "graphql.execution.ExecutionStrategyParameters.getField",
	"Comment": "this returns the current field in its query representations.global fragments mean thata single named field can have multiple representations and different field subselectionshence the use of a list of field",
	"Method": "List<Field> getField(){\r\n    return currentField;\r\n}"
}, {
	"Path": "com.google.errorprone.bugpatterns.PrivateSecurityContractProtoAccess.createFieldMatcher",
	"Comment": "matches instance methods with privatedonotaccessorelse in their names.",
	"Method": "Matcher<MethodInvocationTree> createFieldMatcher(String className){\r\n    String builderName = className + \".Builder\";\r\n    return anyOf(instanceMethod().onExactClass(className).withNameMatching(PRIVATE_DO_NOT_ACCESS_OR_ELSE), instanceMethod().onExactClass(builderName).withNameMatching(PRIVATE_DO_NOT_ACCESS_OR_ELSE));\r\n}"
}, {
	"Path": "org.flywaydb.core.Flyway.doValidate",
	"Comment": "performs the actual validation. all set up must have taken place beforehand.",
	"Method": "void doValidate(Database database,MigrationResolver migrationResolver,SchemaHistory schemaHistory,Schema[] schemas,CallbackExecutor callbackExecutor,boolean ignorePending){\r\n    String validationError = new DbValidate(database, schemaHistory, schemas[0], migrationResolver, configuration, ignorePending, callbackExecutor).validate();\r\n    if (validationError != null) {\r\n        if (configuration.isCleanOnValidationError()) {\r\n            doClean(database, schemaHistory, schemas, callbackExecutor);\r\n        } else {\r\n            throw new FlywayException(\"Validate failed: \" + validationError);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "water.Futures.blockForPending",
	"Comment": "block until all pending futures have completed or canceled.",
	"Method": "void blockForPending(){\r\n    while (true) {\r\n        Future f;\r\n        synchronized (this) {\r\n            if (_pending_cnt == 0)\r\n                break;\r\n            f = _pending[--_pending_cnt];\r\n        }\r\n        waitAndCheckForException(f);\r\n    }\r\n    if (_ex != null)\r\n        throw new RuntimeException(_ex);\r\n}"
}, {
	"Path": "org.flywaydb.core.internal.database.db2.DB2Schema.generateDropStatementsForSequences",
	"Comment": "generates drop statements for the sequences in this schema.",
	"Method": "List<String> generateDropStatementsForSequences(){\r\n    String dropSeqGenQuery = \"select SEQNAME from SYSCAT.SEQUENCES where SEQSCHEMA = '\" + name + \"' and SEQTYPE='S'\";\r\n    return buildDropStatements(\"DROP SEQUENCE\", dropSeqGenQuery);\r\n}"
}, {
	"Path": "hex.pca.PCATest.testIrisScoreWarning",
	"Comment": "this test will make sure that when the test dataset contains columns that are different fromthe training dataset, a warning should be generated to warn the user.",
	"Method": "void testIrisScoreWarning(){\r\n    PCAModel model = null;\r\n    Frame fr = null, fr2 = null;\r\n    Frame tr = null, te = null;\r\n    Scope.enter();\r\n    try {\r\n        fr = parse_test_file(\"smalldata/iris/iris_wheader.csv\");\r\n        tr = parse_test_file(\"smalldata/iris/iris_wheader_bad_cnames.csv\");\r\n        Scope.track(fr);\r\n        Scope.track(tr);\r\n        PCAModel.PCAParameters parms = new PCAModel.PCAParameters();\r\n        parms._train = fr._key;\r\n        parms._k = 4;\r\n        parms._max_iterations = 1000;\r\n        parms._pca_method = PCAParameters.Method.GramSVD;\r\n        model = new PCA(parms).trainModel().get();\r\n        Scope.track_generic(model);\r\n        fr2 = model.score(tr);\r\n        Scope.track(fr2);\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.apply.ImportStatementsTest.startAndEndPositionsShouldComeFromImportStatements",
	"Comment": "test start and end position calculations. the start position should be the start offset of thefirst import statement, and the end position should be the end position of the last importstatement.",
	"Method": "void startAndEndPositionsShouldComeFromImportStatements(){\r\n    ImportStatements imports = createImportStatements(basePackage, baseImportList);\r\n    assertEquals(82, imports.getStartPos());\r\n    assertEquals(806, imports.getEndPos());\r\n}"
}, {
	"Path": "graphql.Assert.assertValidName",
	"Comment": "validates that the lexical token name matches the current spec.currently non null, non empty,",
	"Method": "String assertValidName(String name){\r\n    if (name != null && !name.isEmpty() && name.matches(\"[_A-Za-z][_0-9A-Za-z]*\")) {\r\n        return name;\r\n    }\r\n    throw new AssertException(String.format(invalidNameErrorMessage, name));\r\n}"
}, {
	"Path": "com.tagtraum.perf.gcviewer.imp.DataReaderSun1_6_0G1.isPrintTenuringDistribution",
	"Comment": "returns true, if line ends with one of the detailed event types.",
	"Method": "boolean isPrintTenuringDistribution(String line){\r\n    return (line.indexOf(\"GC pause\") >= 0 && line.endsWith(\")\")) || (line.indexOf(Type.FULL_GC.getName()) >= 0 && line.endsWith(\")\"));\r\n}"
}, {
	"Path": "water.parser.ZipUtil.isZipDirectory",
	"Comment": "this method check if the input argument is a zip directory containing files.",
	"Method": "boolean isZipDirectory(Key key,boolean isZipDirectory,ByteVec bv){\r\n    byte[] bits = bv.getFirstBytes();\r\n    ZipUtil.Compression compressionMethod = guessCompressionMethod(bits);\r\n    try {\r\n        if (compressionMethod == Compression.ZIP) {\r\n            ByteArrayInputStream bais = new ByteArrayInputStream(bits);\r\n            ZipInputStream zis = new ZipInputStream(bais);\r\n            ZipEntry ze = zis.getNextEntry();\r\n            boolean isDir = ze.isDirectory();\r\n            zis.close();\r\n            return isDir;\r\n        }\r\n    } catch (IOException e) {\r\n        e.printStackTrace();\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.flywaydb.core.api.configuration.ClassicConfiguration.setSkipDefaultCallbacks",
	"Comment": "whether flyway should skip the default callbacks. if true, only custom callbacks are used.",
	"Method": "void setSkipDefaultCallbacks(boolean skipDefaultCallbacks){\r\n    this.skipDefaultCallbacks = skipDefaultCallbacks;\r\n}"
}, {
	"Path": "com.google.errorprone.apply.ImportStatementsTest.shouldRemoveImportAndSort",
	"Comment": "test that removing an import works and the resulting output is correctly sorted.",
	"Method": "void shouldRemoveImportAndSort(){\r\n    ImportStatements imports = createImportStatements(basePackage, baseImportList);\r\n    boolean removed = imports.remove(\"import com.sun.tools.javac.tree.JCTree\");\r\n    assertTrue(removed);\r\n    assertEquals(\"import static com.google.ads.pebl.AdGroupCriterionPredicate.PAUSED;\\n\" + \"import static com.google.common.base.Preconditions.checkNotNull;\\n\" + \"\\n\" + \"import com.google.common.collect.ImmutableList;\\n\" + \"import com.google.common.collect.ImmutableMap;\\n\" + \"import com.sun.source.tree.CompilationUnitTree;\\n\" + \"import com.sun.source.tree.ImportTree;\\n\" + \"import com.sun.tools.javac.tree.JCTree.JCExpression;\\n\" + \"import java.io.File;\\n\" + \"import java.io.IOException;\\n\" + \"import java.util.Iterator;\\n\" + \"import javax.tools.JavaCompiler;\\n\" + \"import javax.tools.JavaFileObject;\\n\" + \"import javax.tools.StandardJavaFileManager;\\n\" + \"import javax.tools.ToolProvider;\\n\" + \"import org.joda.time.DateTime;\\n\" + \"import org.joda.time.DateTimeZone;\\n\" + \"import org.joda.time.Interval;\", imports.toString());\r\n}"
}, {
	"Path": "water.H2O.startLocalNode",
	"Comment": "initializes the local node and the local cloud with itself as the only member.",
	"Method": "void startLocalNode(){\r\n    NetworkInit.initializeNetworkSockets();\r\n    if (!ARGS.client && H2O.isFlatfileEnabled() && !H2O.isNodeInFlatfile(SELF)) {\r\n        Log.warn(\"Flatfile configuration does not include self: \" + SELF + \", but contains \" + H2O.getFlatfile());\r\n        H2O.addNodeToFlatfile(SELF);\r\n    }\r\n    Log.info(\"H2O cloud name: '\" + ARGS.name + \"' on \" + SELF + (H2O.isFlatfileEnabled() ? (\", discovery address \" + CLOUD_MULTICAST_GROUP + \":\" + CLOUD_MULTICAST_PORT) : \", static configuration based on -flatfile \" + ARGS.flatfile));\r\n    if (!H2O.ARGS.disable_web) {\r\n        Log.info(\"If you have trouble connecting, try SSH tunneling from your local machine (e.g., via port 55555):\\n\" + \"  1. Open a terminal and run 'ssh -L 55555:localhost:\" + API_PORT + \" \" + System.getProperty(\"user.name\") + \"@\" + SELF_ADDRESS.getHostAddress() + \"'\\n\" + \"  2. Point your browser to \" + NetworkInit.h2oHttpView.getScheme() + \"://localhost:55555\");\r\n    }\r\n    SELF._heartbeat._jar_md5 = JarHash.JARHASH;\r\n    SELF._heartbeat._client = ARGS.client;\r\n    SELF._heartbeat._cloud_name_hash = ARGS.name.hashCode();\r\n    if (ARGS.client) {\r\n        reportClient(H2O.SELF);\r\n    }\r\n}"
}, {
	"Path": "com.google.errorprone.names.NeedlemanWunschEditDistance.getNormalizedEditDistance",
	"Comment": "returns a normalized edit distance between 0 and 1. this is useful if you are comparing oraggregating distances of different pairs of strings",
	"Method": "double getNormalizedEditDistance(String source,String target,boolean caseSensitive,int changeCost,int openGapCost,int continueGapCost){\r\n    if (source.isEmpty() && target.isEmpty()) {\r\n        return 0.0;\r\n    }\r\n    return (double) getEditDistance(source, target, caseSensitive, changeCost, openGapCost, continueGapCost) / (double) getWorstCaseEditDistance(source.length(), target.length(), changeCost, openGapCost, continueGapCost);\r\n}"
}, {
	"Path": "org.flywaydb.gradle.task.AbstractFlywayTask.toFile",
	"Comment": "converts this filename into a file, adjusting relative paths if necessary to make them relative to the pom.",
	"Method": "File toFile(String fileName){\r\n    File file = new File(fileName);\r\n    if (file.isAbsolute()) {\r\n        return file;\r\n    }\r\n    return new File(getProject().getProjectDir(), fileName);\r\n}"
}, {
	"Path": "hex.tree.drf.DRFCheckpointTest.testCheckpointReconstruction4Regression",
	"Comment": "test if reconstructed initial frame match the last iterationof drf model builder.this test verify regression model.",
	"Method": "void testCheckpointReconstruction4Regression(){\r\n    testCheckPointReconstruction(\"smalldata/logreg/prostate.csv\", 8, false, 4, 3);\r\n}"
}, {
	"Path": "jsr166y.ConcurrentLinkedDeque.toArrayList",
	"Comment": "creates an array list and fills it with elements of this list.used by toarray.",
	"Method": "ArrayList<E> toArrayList(){\r\n    ArrayList<E> list = new ArrayList<E>();\r\n    for (Node<E> p = first(); p != null; p = succ(p)) {\r\n        E item = p.item;\r\n        if (item != null)\r\n            list.add(item);\r\n    }\r\n    return list;\r\n}"
}]