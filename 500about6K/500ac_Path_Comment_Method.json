[{
	"Path": "hex.tree.xgboost.XGBoostUtils.sumChunksLength",
	"Comment": "counts a total sum of chunks inside a vector. only chunks present in chunkids are considered.",
	"Method": "long sumChunksLength(int[] chunkIds,Vec vec,Vec weightsVector,int[] chunkLengths){\r\n    for (int i = 0; i < chunkIds.length; i++) {\r\n        final int chunk = chunkIds[i];\r\n        chunkLengths[i] = vec.chunkLen(chunk);\r\n        if (weightsVector == null)\r\n            continue;\r\n        Chunk weightVecChunk = weightsVector.chunkForChunkIdx(chunk);\r\n        if (weightVecChunk.atd(0) == 0)\r\n            chunkLengths[i]--;\r\n        int nzIndex = 0;\r\n        do {\r\n            nzIndex = weightVecChunk.nextNZ(nzIndex, true);\r\n            if (nzIndex < 0 || nzIndex >= weightVecChunk._len)\r\n                break;\r\n            if (weightVecChunk.atd(nzIndex) == 0)\r\n                chunkLengths[i]--;\r\n        } while (true);\r\n    }\r\n    long totalChunkLength = 0;\r\n    for (int cl : chunkLengths) {\r\n        totalChunkLength += cl;\r\n    }\r\n    return totalChunkLength;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.SessionFactoryHelper.getElementType",
	"Comment": "given a collection type, determine the type representing elements\twithin instances of that collection.",
	"Method": "Type getElementType(CollectionType collectionType){\r\n    return collectionType.getElementType(sfi);\r\n}"
}, {
	"Path": "org.hibernate.stat.internal.DeprecatedNaturalIdCacheStatisticsImpl.getExecutionAvgTime",
	"Comment": "average time in ms taken by the excution of this query onto the db",
	"Method": "long getExecutionAvgTime(){\r\n    this.writeLock.lock();\r\n    try {\r\n        long avgExecutionTime = 0;\r\n        if (this.executionCount.get() > 0) {\r\n            avgExecutionTime = this.totalExecutionTime.get() / this.executionCount.get();\r\n        }\r\n        return avgExecutionTime;\r\n    } finally {\r\n        this.writeLock.unlock();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.Node.getRenderText",
	"Comment": "retrieve the text to be used for rendering this particular node.",
	"Method": "String getRenderText(SessionFactoryImplementor sessionFactory){\r\n    return getText();\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.eq",
	"Comment": "creates a criterion which checks that the value of a given literal as being equal to the value in\tthe subquery result.the implication is that the subquery returns a single result..",
	"Method": "Criterion eq(Object value,DetachedCriteria dc){\r\n    return new SimpleSubqueryExpression(value, \"=\", null, dc);\r\n}"
}, {
	"Path": "org.hibernate.jmx.internal.JmxServiceImpl.findServer",
	"Comment": "locate the mbean server to use based on user input from startup.",
	"Method": "MBeanServer findServer(){\r\n    if (usePlatformServer) {\r\n        return ManagementFactory.getPlatformMBeanServer();\r\n    }\r\n    ArrayList<MBeanServer> mbeanServers = MBeanServerFactory.findMBeanServer(agentId);\r\n    if (defaultDomain == null) {\r\n        return mbeanServers.get(0);\r\n    }\r\n    for (MBeanServer mbeanServer : mbeanServers) {\r\n        if (defaultDomain.equals(mbeanServer.getDefaultDomain())) {\r\n            return mbeanServer;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "org.hibernate.criterion.ProjectionList.add",
	"Comment": "adds a projection to this list of projections after wrapping it with an alias",
	"Method": "ProjectionList add(Projection projection,ProjectionList add,Projection projection,String alias){\r\n    return add(Projections.alias(projection, alias));\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.SessionFactoryHelper.getAssociatedEntityName",
	"Comment": "given a collection type, determine the entity name of the elements\tcontained within instance of that collection.",
	"Method": "String getAssociatedEntityName(CollectionType collectionType){\r\n    return collectionType.getAssociatedEntityName(sfi);\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.exec.internal.BatchingLoadQueryDetailsFactory.makeCollectionLoadQueryDetails",
	"Comment": "constructs a basiccollectionloadquerydetails object from the given inputs.",
	"Method": "LoadQueryDetails makeCollectionLoadQueryDetails(CollectionPersister collectionPersister,LoadPlan loadPlan,QueryBuildingParameters buildingParameters){\r\n    final CollectionReturn rootReturn = RootHelper.INSTANCE.extractRootReturn(loadPlan, CollectionReturn.class);\r\n    final AliasResolutionContextImpl aliasResolutionContext = new AliasResolutionContextImpl(collectionPersister.getFactory());\r\n    return collectionPersister.isOneToMany() ? new OneToManyLoadQueryDetails(loadPlan, aliasResolutionContext, rootReturn, buildingParameters, collectionPersister.getFactory()) : new BasicCollectionLoadQueryDetails(loadPlan, aliasResolutionContext, rootReturn, buildingParameters, collectionPersister.getFactory());\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.doQueryAndInitializeNonLazyCollections",
	"Comment": "execute an sql query and attempt to instantiate instances of the class mapped by the given\tpersister from each row of the resultset. if an object is supplied, will attempt to\tinitialize that object. if a collection is supplied, attempt to initialize that collection.",
	"Method": "List doQueryAndInitializeNonLazyCollections(SharedSessionContractImplementor session,QueryParameters queryParameters,boolean returnProxies,List doQueryAndInitializeNonLazyCollections,SharedSessionContractImplementor session,QueryParameters queryParameters,boolean returnProxies,ResultTransformer forcedResultTransformer){\r\n    final PersistenceContext persistenceContext = session.getPersistenceContext();\r\n    boolean defaultReadOnlyOrig = persistenceContext.isDefaultReadOnly();\r\n    if (queryParameters.isReadOnlyInitialized()) {\r\n        persistenceContext.setDefaultReadOnly(queryParameters.isReadOnly());\r\n    } else {\r\n        queryParameters.setReadOnly(persistenceContext.isDefaultReadOnly());\r\n    }\r\n    persistenceContext.beforeLoad();\r\n    List result;\r\n    try {\r\n        try {\r\n            result = doQuery(session, queryParameters, returnProxies, forcedResultTransformer);\r\n        } finally {\r\n            persistenceContext.afterLoad();\r\n        }\r\n        persistenceContext.initializeNonLazyCollections();\r\n    } finally {\r\n        persistenceContext.setDefaultReadOnly(defaultReadOnlyOrig);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.internal.util.collections.IdentityMap.instantiateSequenced",
	"Comment": "return a new instance of this class, with iteration\torder defined as the order in which entries were added",
	"Method": "IdentityMap<K, V> instantiateSequenced(int size){\r\n    return new IdentityMap<K, V>(new LinkedHashMap<IdentityKey<K>, V>(size));\r\n}"
}, {
	"Path": "org.hibernate.context.internal.ManagedSessionContext.hasBind",
	"Comment": "check to see if there is already a session associated with the current\tthread for the given session factory.",
	"Method": "boolean hasBind(SessionFactory factory){\r\n    return existingSession(factory) != null;\r\n}"
}, {
	"Path": "org.hibernate.cfg.Configuration.addDirectory",
	"Comment": "read all mapping documents from a directory tree.\tassumes that any file named .hbm.xml is a mapping document.",
	"Method": "Configuration addDirectory(File dir){\r\n    metadataSources.addDirectory(dir);\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.graph.internal.parse.GraphParser.parseInto",
	"Comment": "parse the passed graph textual representation into the passed graph.",
	"Method": "void parseInto(GraphImplementor<?> targetGraph,CharSequence graphString,SessionFactoryImplementor sessionFactory){\r\n    final GraphParser instance = new GraphParser(graphString, sessionFactory);\r\n    instance.graphStack.push(targetGraph);\r\n    try {\r\n        instance.graph();\r\n    } catch (RecognitionException | TokenStreamException e) {\r\n        throw new InvalidGraphException(\"Error parsing graph string\");\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.isJdbcLogWarningsEnabledByDefault",
	"Comment": "does the fetching jdbc statement warning for logging is enabled by default",
	"Method": "boolean isJdbcLogWarningsEnabledByDefault(){\r\n    return true;\r\n}"
}, {
	"Path": "org.hibernate.event.internal.AbstractLockUpgradeEventListener.upgradeLock",
	"Comment": "performs a pessimistic lock upgrade on a given entity, if needed.",
	"Method": "void upgradeLock(Object object,EntityEntry entry,LockOptions lockOptions,EventSource source){\r\n    LockMode requestedLockMode = lockOptions.getLockMode();\r\n    if (requestedLockMode.greaterThan(entry.getLockMode())) {\r\n        if (entry.getStatus() != Status.MANAGED) {\r\n            throw new ObjectDeletedException(\"attempted to lock a deleted instance\", entry.getId(), entry.getPersister().getEntityName());\r\n        }\r\n        final EntityPersister persister = entry.getPersister();\r\n        if (log.isTraceEnabled()) {\r\n            log.tracev(\"Locking {0} in mode: {1}\", MessageHelper.infoString(persister, entry.getId(), source.getFactory()), requestedLockMode);\r\n        }\r\n        final boolean cachingEnabled = persister.canWriteToCache();\r\n        SoftLock lock = null;\r\n        Object ck = null;\r\n        try {\r\n            if (cachingEnabled) {\r\n                EntityDataAccess cache = persister.getCacheAccessStrategy();\r\n                ck = cache.generateCacheKey(entry.getId(), persister, source.getFactory(), source.getTenantIdentifier());\r\n                lock = cache.lockItem(source, ck, entry.getVersion());\r\n            }\r\n            if (persister.isVersioned() && requestedLockMode == LockMode.FORCE) {\r\n                Object nextVersion = persister.forceVersionIncrement(entry.getId(), entry.getVersion(), source);\r\n                entry.forceLocked(object, nextVersion);\r\n            } else {\r\n                persister.lock(entry.getId(), entry.getVersion(), object, lockOptions, source);\r\n            }\r\n            entry.setLockMode(requestedLockMode);\r\n        } finally {\r\n            if (cachingEnabled) {\r\n                persister.getCacheAccessStrategy().unlockItem(source, ck, lock);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.persister.entity.AbstractEntityPersister.getSQLIdentityInsertString",
	"Comment": "the query that inserts a row, letting the database generate an id",
	"Method": "String getSQLIdentityInsertString(){\r\n    return sqlIdentityInsertString;\r\n}"
}, {
	"Path": "org.hibernate.event.internal.DefaultLoadEventListener.lockAndLoad",
	"Comment": "if the class to be loaded has been configured with a cache, then lock\tgiven id in that cache and then perform the load.",
	"Method": "Object lockAndLoad(LoadEvent event,EntityPersister persister,EntityKey keyToLoad,LoadEventListener.LoadType options,SessionImplementor source){\r\n    SoftLock lock = null;\r\n    final Object ck;\r\n    final EntityDataAccess cache = persister.getCacheAccessStrategy();\r\n    if (persister.canWriteToCache()) {\r\n        ck = cache.generateCacheKey(event.getEntityId(), persister, source.getFactory(), source.getTenantIdentifier());\r\n        lock = persister.getCacheAccessStrategy().lockItem(source, ck, null);\r\n    } else {\r\n        ck = null;\r\n    }\r\n    Object entity;\r\n    try {\r\n        entity = load(event, persister, keyToLoad, options);\r\n    } finally {\r\n        if (persister.canWriteToCache()) {\r\n            cache.unlockItem(source, ck, lock);\r\n        }\r\n    }\r\n    return event.getSession().getPersistenceContext().proxyFor(persister, keyToLoad, entity);\r\n}"
}, {
	"Path": "org.hibernate.userguide.proxy.tuplizer.EntityNameInterceptor.getEntityName",
	"Comment": "the callback from hibernate to determine the entity name given\ta presumed entity instance.",
	"Method": "String getEntityName(Object object){\r\n    String entityName = ProxyHelper.extractEntityName(object);\r\n    if (entityName == null) {\r\n        entityName = super.getEntityName(object);\r\n    }\r\n    return entityName;\r\n}"
}, {
	"Path": "org.hibernate.id.enhanced.TableGenerator.getValueColumnName",
	"Comment": "the name of the column in which we store our persistent generator value.",
	"Method": "String getValueColumnName(){\r\n    return valueColumnName;\r\n}"
}, {
	"Path": "org.hibernate.bytecode.internal.javassist.FastClass.invoke",
	"Comment": "access to invoke a method on the class that this fast class handles by its index",
	"Method": "Object invoke(String name,Class[] parameterTypes,Object obj,Object[] args,Object invoke,int index,Object obj,Object[] args){\r\n    final Method[] methods = this.type.getMethods();\r\n    try {\r\n        return methods[index].invoke(obj, args);\r\n    } catch (ArrayIndexOutOfBoundsException e) {\r\n        throw new IllegalArgumentException(\"Cannot find matching method/constructor\");\r\n    } catch (IllegalAccessException e) {\r\n        throw new InvocationTargetException(e);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.propertyEq",
	"Comment": "creates a criterion which checks that the value of a given property as being equal to the set of values in\tthe subquery result.the implication is that the subquery returns a single result..",
	"Method": "Criterion propertyEq(String propertyName,DetachedCriteria dc){\r\n    return new PropertySubqueryExpression(propertyName, \"=\", null, dc);\r\n}"
}, {
	"Path": "org.hibernate.internal.util.SerializationHelper.serialize",
	"Comment": "serializes an object to the specified stream.\tthe stream will be closed once the object is written.\tthis avoids the need for a finally clause, and maybe also exception\thandling, in the application code.\tthe stream passed in is not buffered internally within this method.\tthis is the responsibility of your application if desired.",
	"Method": "void serialize(Serializable obj,OutputStream outputStream,byte[] serialize,Serializable obj){\r\n    ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(512);\r\n    serialize(obj, byteArrayOutputStream);\r\n    return byteArrayOutputStream.toByteArray();\r\n}"
}, {
	"Path": "hex.genmodel.easy.exception.PredictUnknownCategoricalLevelException.getColumnName",
	"Comment": "get the column name for which the unknown level was given as input.",
	"Method": "String getColumnName(){\r\n    return columnName;\r\n}"
}, {
	"Path": "org.hibernate.tuple.PropertyFactory.buildVersionProperty",
	"Comment": "generates a versionproperty representation for an entity mapping given its\tversion mapping property.",
	"Method": "VersionProperty buildVersionProperty(EntityPersister persister,SessionFactoryImplementor sessionFactory,int attributeNumber,Property property,boolean lazyAvailable){\r\n    String mappedUnsavedValue = ((KeyValue) property.getValue()).getNullValue();\r\n    VersionValue unsavedValue = UnsavedValueFactory.getUnsavedVersionValue(mappedUnsavedValue, getGetter(property), (VersionType) property.getType(), getConstructor(property.getPersistentClass()));\r\n    boolean lazy = lazyAvailable && property.isLazy();\r\n    return new VersionProperty(persister, sessionFactory, attributeNumber, property.getName(), property.getValue().getType(), new BaselineAttributeInformation.Builder().setLazy(lazy).setInsertable(property.isInsertable()).setUpdateable(property.isUpdateable()).setValueGenerationStrategy(property.getValueGenerationStrategy()).setNullable(property.isOptional()).setDirtyCheckable(property.isUpdateable() && !lazy).setVersionable(property.isOptimisticLocked()).setCascadeStyle(property.getCascadeStyle()).createInformation(), unsavedValue);\r\n}"
}, {
	"Path": "org.hibernate.id.enhanced.SequenceStyleConfigUnitTest.testDefaultedSequenceBackedConfiguration",
	"Comment": "test all params defaulted with a dialect supporting sequences",
	"Method": "void testDefaultedSequenceBackedConfiguration(){\r\n    StandardServiceRegistry serviceRegistry = new StandardServiceRegistryBuilder().applySetting(AvailableSettings.DIALECT, SequenceDialect.class.getName()).build();\r\n    try {\r\n        Properties props = buildGeneratorPropertiesBase(serviceRegistry);\r\n        SequenceStyleGenerator generator = new SequenceStyleGenerator();\r\n        generator.configure(StandardBasicTypes.LONG, props, serviceRegistry);\r\n        generator.registerExportables(new Database(new MetadataBuilderImpl.MetadataBuildingOptionsImpl(serviceRegistry)));\r\n        assertClassAssignability(SequenceStructure.class, generator.getDatabaseStructure().getClass());\r\n        assertClassAssignability(NoopOptimizer.class, generator.getOptimizer().getClass());\r\n        assertEquals(SequenceStyleGenerator.DEF_SEQUENCE_NAME, generator.getDatabaseStructure().getName());\r\n    } finally {\r\n        StandardServiceRegistryBuilder.destroy(serviceRegistry);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.supportsUnionAll",
	"Comment": "does this dialect support union all, which is generally a faster\tvariant of union?",
	"Method": "boolean supportsUnionAll(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.id.enhanced.SequenceStyleConfigUnitTest.testDefaultOptimizerBasedOnIncrementBackedByTable",
	"Comment": "test default optimizer selection for table backed generators\tbased on the configured increment size.here we always prefer\tpooled.",
	"Method": "void testDefaultOptimizerBasedOnIncrementBackedByTable(){\r\n    StandardServiceRegistry serviceRegistry = new StandardServiceRegistryBuilder().applySetting(AvailableSettings.DIALECT, TableDialect.class.getName()).build();\r\n    try {\r\n        Properties props = buildGeneratorPropertiesBase(serviceRegistry);\r\n        props.setProperty(SequenceStyleGenerator.INCREMENT_PARAM, \"10\");\r\n        SequenceStyleGenerator generator = new SequenceStyleGenerator();\r\n        generator.configure(StandardBasicTypes.LONG, props, serviceRegistry);\r\n        generator.registerExportables(new Database(new MetadataBuilderImpl.MetadataBuildingOptionsImpl(serviceRegistry)));\r\n        assertClassAssignability(TableStructure.class, generator.getDatabaseStructure().getClass());\r\n        assertClassAssignability(PooledOptimizer.class, generator.getOptimizer().getClass());\r\n        assertEquals(SequenceStyleGenerator.DEF_SEQUENCE_NAME, generator.getDatabaseStructure().getName());\r\n    } finally {\r\n        StandardServiceRegistryBuilder.destroy(serviceRegistry);\r\n    }\r\n}"
}, {
	"Path": "water.hadoop.h2odriver.parseArgs",
	"Comment": "parse remaining arguments after the toolrunner args have already been removed.",
	"Method": "String[] parseArgs(String[] args){\r\n    int i = 0;\r\n    boolean driverArgs = true;\r\n    while (driverArgs) {\r\n        if (i >= args.length) {\r\n            break;\r\n        }\r\n        String s = args[i];\r\n        if (s.equals(\"-h\") || s.equals(\"help\") || s.equals(\"-help\") || s.equals(\"--help\")) {\r\n            usage();\r\n        } else if (s.equals(\"-n\") || s.equals(\"-nodes\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            numNodes = Integer.parseInt(args[i]);\r\n        } else if (s.equals(\"-o\") || s.equals(\"-output\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            outputPath = args[i];\r\n        } else if (s.equals(\"-jobname\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            jobtrackerName = args[i];\r\n        } else if (s.equals(\"-mapperXmx\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            mapperXmx = args[i];\r\n        } else if (s.equals(\"-extramempercent\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            extraMemPercent = Integer.parseInt(args[i]);\r\n        } else if (s.equals(\"-mapperPermSize\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            mapperPermSize = args[i];\r\n        } else if (s.equals(\"-driverif\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            driverCallbackIp = args[i];\r\n        } else if (s.equals(\"-driverport\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            driverCallbackPort = Integer.parseInt(args[i]);\r\n        } else if (s.equals(\"-driverportrange\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            driverCallbackPortRange = PortRange.parse(args[i]);\r\n        } else if (s.equals(\"-network\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            network = args[i];\r\n        } else if (s.equals(\"-timeout\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            cloudFormationTimeoutSeconds = Integer.parseInt(args[i]);\r\n        } else if (s.equals(\"-disown\")) {\r\n            disown = true;\r\n        } else if (s.equals(\"-notify\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            clusterReadyFileName = args[i];\r\n        } else if (s.equals(\"-nthreads\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            nthreads = Integer.parseInt(args[i]);\r\n        } else if (s.equals(\"-context_path\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            contextPath = args[i];\r\n        } else if (s.equals(\"-baseport\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            basePort = Integer.parseInt(args[i]);\r\n            if ((basePort < 0) || (basePort > 65535)) {\r\n                error(\"Base port must be between 1 and 65535\");\r\n            }\r\n        } else if (s.equals(\"-port_offset\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            portOffset = Integer.parseInt(args[i]);\r\n            if ((portOffset <= 0) || (portOffset > 65534)) {\r\n                error(\"Port offset must be between 1 and 65534\");\r\n            }\r\n        } else if (s.equals(\"-beta\")) {\r\n            beta = true;\r\n        } else if (s.equals(\"-random_udp_drop\")) {\r\n            enableRandomUdpDrop = true;\r\n        } else if (s.equals(\"-ea\")) {\r\n            enableExceptions = true;\r\n        } else if (s.equals(\"-verbose:gc\") && !JAVA_VERSION.useUnifiedLogging()) {\r\n            if (!JAVA_VERSION.useUnifiedLogging()) {\r\n                enableVerboseGC = true;\r\n            } else {\r\n                error(\"Parameter -verbose:gc is unusable, running on JVM with deprecated GC debugging flags.\");\r\n            }\r\n        } else if (s.equals(\"-Xlog:gc=info\")) {\r\n            if (JAVA_VERSION.useUnifiedLogging()) {\r\n                enableVerboseGC = true;\r\n            } else {\r\n                error(\"Parameter -verbose:gc is unusable, running on JVM without unified JVM logging.\");\r\n            }\r\n        } else if (s.equals(\"-verbose:class\")) {\r\n            enableVerboseClass = true;\r\n        } else if (s.equals(\"-XX:+PrintCompilation\")) {\r\n            enablePrintCompilation = true;\r\n        } else if (s.equals(\"-exclude\")) {\r\n            enableExcludeMethods = true;\r\n        } else if (s.equals(\"-Dlog4j.defaultInitOverride=true\")) {\r\n            enableLog4jDefaultInitOverride = true;\r\n        } else if (s.equals(\"-debug\")) {\r\n            enableDebug = true;\r\n        } else if (s.equals(\"-suspend\")) {\r\n            enableSuspend = true;\r\n        } else if (s.equals(\"-debugport\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            debugPort = Integer.parseInt(args[i]);\r\n            if ((debugPort < 0) || (debugPort > 65535)) {\r\n                error(\"Debug port must be between 1 and 65535\");\r\n            }\r\n        } else if (s.equals(\"-XX:+PrintGCDetails\")) {\r\n            if (!JAVA_VERSION.useUnifiedLogging()) {\r\n                enablePrintGCDetails = true;\r\n            } else {\r\n                error(\"Parameter -XX:+PrintGCDetails is unusable, running on JVM with deprecated GC debugging flags.\");\r\n            }\r\n        } else if (s.equals(\"-XX:+PrintGCTimeStamps\")) {\r\n            if (!JAVA_VERSION.useUnifiedLogging()) {\r\n                enablePrintGCDetails = true;\r\n            } else {\r\n                error(\"Parameter -XX:+PrintGCTimeStamps is unusable, running on JVM with deprecated GC debugging flags.\");\r\n            }\r\n        } else if (s.equals(\"-gc\")) {\r\n            enableVerboseGC = true;\r\n            enablePrintGCDetails = true;\r\n            enablePrintGCTimeStamps = true;\r\n        } else if (s.equals(\"-nogc\")) {\r\n            enableVerboseGC = false;\r\n            enablePrintGCDetails = false;\r\n            enablePrintGCTimeStamps = false;\r\n        } else if (s.equals(\"-flow_dir\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            flowDir = args[i];\r\n        } else if (s.equals(\"-J\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            extraArguments.add(args[i]);\r\n        } else if (s.equals(\"-JJ\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            extraJvmArguments.add(args[i]);\r\n        } else if (s.equals(\"-jks\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            jksFileName = args[i];\r\n        } else if (s.equals(\"-jks_pass\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            jksPass = args[i];\r\n        } else if (s.equals(\"-internal_secure_connections\")) {\r\n            internal_secure_connections = true;\r\n        } else if (s.equals(\"-internal_security_conf\") || s.equals(\"-internal_security\")) {\r\n            if (s.equals(\"-internal_security\")) {\r\n                System.out.println(\"The '-internal_security' configuration is deprecated. \" + \"Please use '-internal_security_conf' instead.\");\r\n            }\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            securityConf = args[i];\r\n        } else if (s.equals(\"-hash_login\")) {\r\n            hashLogin = true;\r\n        } else if (s.equals(\"-ldap_login\")) {\r\n            ldapLogin = true;\r\n        } else if (s.equals(\"-kerberos_login\")) {\r\n            kerberosLogin = true;\r\n        } else if (s.equals(\"-pam_login\")) {\r\n            pamLogin = true;\r\n        } else if (s.equals(\"-login_conf\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            loginConfFileName = args[i];\r\n        } else if (s.equals(\"-form_auth\")) {\r\n            formAuth = true;\r\n        } else if (s.equals(\"-session_timeout\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            sessionTimeout = args[i];\r\n        } else if (s.equals(\"-user_name\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            userName = args[i];\r\n        } else if (s.equals(\"-client\")) {\r\n            client = true;\r\n            driverArgs = false;\r\n        } else if (s.equals(\"-proxy\")) {\r\n            proxy = true;\r\n            driverArgs = false;\r\n        } else if (s.equals(\"-run_as_user\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            runAsUser = args[i];\r\n        } else if (s.equals(\"-principal\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            principal = args[i];\r\n        } else if (s.equals(\"-keytab\")) {\r\n            i++;\r\n            if (i >= args.length) {\r\n                usage();\r\n            }\r\n            keytabPath = args[i];\r\n        } else if (s.equals(\"-report_hostname\")) {\r\n            reportHostname = true;\r\n        } else if (s.equals(\"-driver_debug\")) {\r\n            driverDebug = true;\r\n        } else {\r\n            error(\"Unrecognized option \" + s);\r\n        }\r\n        i++;\r\n    }\r\n    String[] otherArgs = new String[Math.max(args.length - i, 0)];\r\n    for (int j = 0; j < otherArgs.length; j++) otherArgs[j] = args[i++];\r\n    return otherArgs;\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.propertiesIn",
	"Comment": "creates a criterion which checks that the value of multiple given properties as being in to the set of\tvalues in the subquery result.this form is implicitly using tuple comparisons",
	"Method": "Criterion propertiesIn(String[] propertyNames,DetachedCriteria dc){\r\n    return new PropertiesSubqueryExpression(propertyNames, \"in\", dc);\r\n}"
}, {
	"Path": "org.hibernate.mapping.Column.getAlias",
	"Comment": "generate a column alias that is unique across multiple tables",
	"Method": "String getAlias(Dialect dialect,String getAlias,Dialect dialect,Table table){\r\n    return safeInterning(getAlias(dialect) + table.getUniqueInteger() + '_');\r\n}"
}, {
	"Path": "water.parser.orc.OrcParser.writeLongcolumn",
	"Comment": "this method writes a column of h2o frame for orc file column type of boolean, bigint, int, smallint,tinyint and date.",
	"Method": "void writeLongcolumn(LongColumnVector vec,int colId,int rowNumber,ParseWriter dout){\r\n    long[] oneColumn = vec.vector;\r\n    byte t = _setup.getColumnTypes()[colId];\r\n    switch(t) {\r\n        case Vec.T_CAT:\r\n            if (_toStringMaps.get(colId) == null)\r\n                _toStringMaps.put(colId, new HashMap<Number, byte[]>());\r\n            HashMap<Number, byte[]> map = _toStringMaps.get(colId);\r\n            BufferedString bs = new BufferedString();\r\n            if (vec.isRepeating) {\r\n                bs.set(StringUtils.toBytes(oneColumn[0]));\r\n                for (int i = 0; i < rowNumber; ++i) dout.addStrCol(colId, bs);\r\n            } else if (vec.noNulls) {\r\n                for (int i = 0; i < rowNumber; i++) {\r\n                    long l = oneColumn[i];\r\n                    if (map.get(l) == null)\r\n                        map.put(l, StringUtils.toBytes(l));\r\n                    dout.addStrCol(colId, bs.set(map.get(l)));\r\n                }\r\n            } else {\r\n                for (int i = 0; i < rowNumber; i++) {\r\n                    boolean[] isNull = vec.isNull;\r\n                    if (isNull[i])\r\n                        dout.addInvalidCol(colId);\r\n                    else {\r\n                        long l = oneColumn[i];\r\n                        if (map.get(l) == null)\r\n                            map.put(l, StringUtils.toBytes(l));\r\n                        dout.addStrCol(colId, bs.set(map.get(l)));\r\n                    }\r\n                }\r\n            }\r\n            break;\r\n        default:\r\n            if (vec.isRepeating) {\r\n                for (int i = 0; i < rowNumber; ++i) dout.addNumCol(colId, oneColumn[0], 0);\r\n            } else if (vec.noNulls) {\r\n                for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) {\r\n                    check_Min_Value(oneColumn[rowIndex], colId, rowNumber, dout);\r\n                    dout.addNumCol(colId, oneColumn[rowIndex], 0);\r\n                }\r\n            } else {\r\n                for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) {\r\n                    boolean[] isNull = vec.isNull;\r\n                    if (isNull[rowIndex])\r\n                        dout.addInvalidCol(colId);\r\n                    else {\r\n                        check_Min_Value(oneColumn[rowIndex], colId, rowNumber, dout);\r\n                        dout.addNumCol(colId, oneColumn[rowIndex], 0);\r\n                    }\r\n                }\r\n            }\r\n            break;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.collection.internal.AbstractPersistentCollection.initialize",
	"Comment": "initialize the collection, if possible, wrapping any exceptions\tin a runtime exception",
	"Method": "void initialize(boolean writing){\r\n    if (initialized) {\r\n        return;\r\n    }\r\n    withTemporarySessionIfNeeded(new LazyInitializationWork<Object>() {\r\n        @Override\r\n        public Object doWork() {\r\n            session.initializeCollection(AbstractPersistentCollection.this, writing);\r\n            return null;\r\n        }\r\n    });\r\n}"
}, {
	"Path": "org.hibernate.collection.internal.AbstractPersistentCollection.initialize",
	"Comment": "initialize the collection, if possible, wrapping any exceptions\tin a runtime exception",
	"Method": "void initialize(boolean writing){\r\n    session.initializeCollection(AbstractPersistentCollection.this, writing);\r\n    return null;\r\n}"
}, {
	"Path": "org.hibernate.type.descriptor.java.DataHelper.determineLengthForBufferSizing",
	"Comment": "determine a buffer size for reading the underlying character stream.",
	"Method": "long determineLengthForBufferSizing(Clob value){\r\n    try {\r\n        return value.length();\r\n    } catch (SQLFeatureNotSupportedException e) {\r\n        return BUFFER_SIZE;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.bindParameterValues",
	"Comment": "bind all parameter values into the prepared statement in preparation\tfor execution.",
	"Method": "int bindParameterValues(PreparedStatement statement,QueryParameters queryParameters,int startIndex,SharedSessionContractImplementor session){\r\n    int span = 0;\r\n    span += bindPositionalParameters(statement, queryParameters, startIndex, session);\r\n    span += bindNamedParameters(statement, queryParameters.getNamedParameters(), startIndex + span, session);\r\n    return span;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getDefaultProperties",
	"Comment": "retrieve a set of default hibernate properties for this database.",
	"Method": "Properties getDefaultProperties(){\r\n    return properties;\r\n}"
}, {
	"Path": "water.util.StringUtils.join",
	"Comment": "join the array with the given delimiter, and return it as a string.",
	"Method": "String join(String delimiter,String[] arr,String join,String delimiter,Iterable<String> strings){\r\n    StringBuilder sb = new StringBuilder();\r\n    for (String item : strings) {\r\n        if (sb.length() > 0)\r\n            sb.append(delimiter);\r\n        sb.append(item);\r\n    }\r\n    return sb.toString();\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.Nullability.buildPropertyPath",
	"Comment": "return a well formed property path. basically, it will return parent.child",
	"Method": "String buildPropertyPath(String parent,String child){\r\n    return parent + '.' + child;\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.ExecutableList.getQuerySpaces",
	"Comment": "lazily constructs the queryspaces affected by the actions in the list.",
	"Method": "Set<Serializable> getQuerySpaces(){\r\n    if (querySpaces == null) {\r\n        for (E e : executables) {\r\n            Serializable[] propertySpaces = e.getPropertySpaces();\r\n            if (propertySpaces != null && propertySpaces.length > 0) {\r\n                if (querySpaces == null) {\r\n                    querySpaces = new HashSet<Serializable>();\r\n                }\r\n                Collections.addAll(querySpaces, propertySpaces);\r\n            }\r\n        }\r\n        if (querySpaces == null) {\r\n            return Collections.emptySet();\r\n        }\r\n    }\r\n    return querySpaces;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getColumnComment",
	"Comment": "get the comment into a form supported for column definition.",
	"Method": "String getColumnComment(String comment){\r\n    return \"\";\r\n}"
}, {
	"Path": "org.hibernate.mapping.PersistentClass.isPropertyDefinedInSuperHierarchy",
	"Comment": "check to see if a property with the given name exists in the super hierarchy\tof this persistentclass.does not check this persistentclass, just up the\thierarchy",
	"Method": "boolean isPropertyDefinedInSuperHierarchy(String name){\r\n    return getSuperclass() != null && getSuperclass().isPropertyDefinedInHierarchy(name);\r\n}"
}, {
	"Path": "water.fvec.TestFrameBuilder.getMapping",
	"Comment": "utility method to get mapping from domain member to its level",
	"Method": "HashMap<String, Integer> getMapping(String[] array){\r\n    HashMap<String, Integer> mapping = new HashMap();\r\n    int level = 0;\r\n    for (String item : array) {\r\n        if ((item != null) && (!mapping.containsKey(item))) {\r\n            mapping.put(item, level);\r\n            level++;\r\n        }\r\n    }\r\n    return mapping;\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.exec.internal.AbstractLoadPlanBasedLoader.bindParameterValues",
	"Comment": "bind all parameter values into the prepared statement in preparation\tfor execution.",
	"Method": "int bindParameterValues(PreparedStatement statement,QueryParameters queryParameters,int startIndex,SharedSessionContractImplementor session){\r\n    int span = 0;\r\n    span += bindPositionalParameters(statement, queryParameters, startIndex, session);\r\n    span += bindNamedParameters(statement, queryParameters.getNamedParameters(), startIndex + span, session);\r\n    return span;\r\n}"
}, {
	"Path": "water.fvec.TestFrameBuilder.withColNames",
	"Comment": "sets the names for the columns. default names are created if this method is not called.",
	"Method": "TestFrameBuilder withColNames(String colNames){\r\n    this.colNames = colNames;\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.bytecode.internal.bytebuddy.ByteBuddyState.getProxyDefinitionHelpers",
	"Comment": "returns the proxy definition helpers to reuse when defining proxies.\tthese elements are shared as they are immutable.",
	"Method": "ProxyDefinitionHelpers getProxyDefinitionHelpers(){\r\n    return proxyDefinitionHelpers;\r\n}"
}, {
	"Path": "org.hibernate.mapping.PersistentClass.getReferenceablePropertyIterator",
	"Comment": "build an iterator of properties which may be referenced in association mappings.\tincludes properties defined in superclasses of the mapping inheritance.\tincludes all properties defined as part of a join.",
	"Method": "Iterator getReferenceablePropertyIterator(){\r\n    return getPropertyClosureIterator();\r\n}"
}, {
	"Path": "hex.genmodel.GenModel.getNames",
	"Comment": "the names of all columns used, including response and offset columns.",
	"Method": "String[] getNames(){\r\n    return _names;\r\n}"
}, {
	"Path": "org.hibernate.criterion.DetachedCriteria.createCriteria",
	"Comment": "creates a nested detachedcriteria representing the association path, specifying the type of join to use and\tan additional join restriction.",
	"Method": "DetachedCriteria createCriteria(String associationPath,String alias,DetachedCriteria createCriteria,String associationPath,DetachedCriteria createCriteria,String associationPath,JoinType joinType,DetachedCriteria createCriteria,String associationPath,String alias,JoinType joinType,DetachedCriteria createCriteria,String associationPath,String alias,JoinType joinType,Criterion withClause,DetachedCriteria createCriteria,String associationPath,int joinType,DetachedCriteria createCriteria,String associationPath,String alias,int joinType,DetachedCriteria createCriteria,String associationPath,String alias,int joinType,Criterion withClause){\r\n    return createCriteria(associationPath, alias, JoinType.parse(joinType), withClause);\r\n}"
}, {
	"Path": "water.rapids.RapidsTest.testAstNumListIndex",
	"Comment": "this test will generate a random sorted array and test only the index method of astnumlist.java. it will checkand make sure every index of the array is returned correctly by the index method.",
	"Method": "void testAstNumListIndex(){\r\n    Random rand = new Random();\r\n    int numElement = 2000;\r\n    int[] array2H2O = new int[numElement];\r\n    int arrayVal = rand.nextInt(Integer.SIZE - 1);\r\n    for (int val = 0; val < numElement; val++) {\r\n        int randValue = rand.nextInt(100);\r\n        arrayVal += randValue;\r\n        if (randValue == 0)\r\n            arrayVal++;\r\n        array2H2O[val] = Math.abs(arrayVal);\r\n    }\r\n    AstNumList h2oArray = new AstNumList(array2H2O);\r\n    h2oArray._isSort = true;\r\n    for (int index = 0; index < numElement; index++) {\r\n        int val = array2H2O[index];\r\n        int h2oIndex = (int) h2oArray.index(val);\r\n        assertEquals(index, h2oIndex);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.JoinWalker.isJoinedFetchEnabled",
	"Comment": "override on subclasses to enable or suppress joining\tof certain association types",
	"Method": "boolean isJoinedFetchEnabled(AssociationType type,FetchMode config,CascadeStyle cascadeStyle){\r\n    return type.isEntityType() && isJoinedFetchEnabledInMapping(config, type);\r\n}"
}, {
	"Path": "hex.genmodel.GenModel.getDomainValues",
	"Comment": "returns domain values for all columns, including the response column.",
	"Method": "String[] getDomainValues(String name,String[] getDomainValues,int i,String[][] getDomainValues){\r\n    return _domains;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Teradata14Dialect.getTypeName",
	"Comment": "get the name of the database type associated with the given\tjava.sql.types typecode.",
	"Method": "String getTypeName(int code,int length,int precision,int scale){\r\n    float f = precision > 0 ? (float) scale / (float) precision : 0;\r\n    int p = (precision > 38 ? 38 : precision);\r\n    int s = (precision > 38 ? (int) (38.0 * f) : (scale > 38 ? 38 : scale));\r\n    return super.getTypeName(code, length, p, s);\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.SessionFactoryHelper.requireQueryableCollection",
	"Comment": "locate the collection persister by the collection role, requiring that\tsuch a persister exist.",
	"Method": "QueryableCollection requireQueryableCollection(String role){\r\n    try {\r\n        QueryableCollection queryableCollection = (QueryableCollection) sfi.getMetamodel().collectionPersister(role);\r\n        if (queryableCollection != null) {\r\n            collectionPropertyMappingByRole.put(role, new CollectionPropertyMapping(queryableCollection));\r\n        }\r\n        return queryableCollection;\r\n    } catch (ClassCastException cce) {\r\n        throw new QueryException(\"collection role is not queryable: \" + role);\r\n    } catch (Exception e) {\r\n        throw new QueryException(\"collection role not found: \" + role);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.event.internal.DefaultLoadEventListener.loadFromDatasource",
	"Comment": "performs the process of loading an entity from the configured\tunderlying datasource.",
	"Method": "Object loadFromDatasource(LoadEvent event,EntityPersister persister){\r\n    Object entity = persister.load(event.getEntityId(), event.getInstanceToLoad(), event.getLockOptions(), event.getSession());\r\n    if (event.isAssociationFetch() && event.getSession().getFactory().getStatistics().isStatisticsEnabled()) {\r\n        event.getSession().getFactory().getStatistics().fetchEntity(event.getEntityClassName());\r\n    }\r\n    return entity;\r\n}"
}, {
	"Path": "water.parser.ParseTimeTest.testTimeParse1",
	"Comment": "parse click & query times from a subset of kaggle bestbuy data",
	"Method": "void testTimeParse1(){\r\n    Frame fr = parse_test_file(\"smalldata/junit/test_time.csv\");\r\n    Frame fr2 = fr.subframe(new String[] { \"click_time\", \"query_time\" });\r\n    double[][] exp = new double[][] { d(1314920692533L, 1314920639752L), d(1315225537042L, 1315225501187L), d(1314190618091L, 1314190513012L), d(1319527094722L, 1319527011759L), d(1319527191697L, 1319527011759L), d(1315410887956L, 1315410804353L), d(1316948822603L, 1316948726996L), d(1316781620871L, 1316781614845L), d(1314625052903L, 1314624803249L), d(1319583358683L, 1319583285926L), d(1315745324139L, 1315745178466L), d(1318958493919L, 1318958486057L), d(1315133720427L, 1315133710874L), d(1319819189203L, 1319819180358L), d(1318206926858L, 1318206870708L), d(1316816048965L, 1316816017043L), d(1315656293645L, 1315656270805L), d(1319370275074L, 1319370207011L), d(1319370324416L, 1319370207011L) };\r\n    ParserTest.testParsed(fr2, exp, exp.length);\r\n    fr.delete();\r\n}"
}, {
	"Path": "org.hibernate.QueryException.getQueryString",
	"Comment": "retrieve the query being evaluated when the exception occurred.may be null, but generally should not.",
	"Method": "String getQueryString(){\r\n    return queryString;\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.propertyIn",
	"Comment": "creates a criterion which checks that the value of a given property is in the set of values in the\tsubquery result.",
	"Method": "Criterion propertyIn(String propertyName,DetachedCriteria dc){\r\n    return new PropertySubqueryExpression(propertyName, \"in\", null, dc);\r\n}"
}, {
	"Path": "org.hibernate.type.EntityType.isSame",
	"Comment": "two entities are considered the same when their instances are the same.",
	"Method": "boolean isSame(Object x,Object y){\r\n    return x == y;\r\n}"
}, {
	"Path": "org.hibernate.internal.util.collections.BoundedConcurrentHashMap.putAll",
	"Comment": "copies all of the mappings from the specified map to this one.\tthese mappings replace any mappings that this map had for any of the\tkeys currently in the specified map.",
	"Method": "void putAll(Map<? extends K, ? extends V> m){\r\n    for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {\r\n        put(e.getKey(), e.getValue());\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.StatefulPersistenceContext.deserialize",
	"Comment": "used by the owning session to explicitly control deserialization of the persistence context.",
	"Method": "StatefulPersistenceContext deserialize(ObjectInputStream ois,SessionImplementor session){\r\n    final boolean tracing = LOG.isTraceEnabled();\r\n    if (tracing) {\r\n        LOG.trace(\"Deserializing persistence-context\");\r\n    }\r\n    final StatefulPersistenceContext rtn = new StatefulPersistenceContext(session);\r\n    SessionFactoryImplementor sfi = session.getFactory();\r\n    try {\r\n        rtn.defaultReadOnly = ois.readBoolean();\r\n        rtn.hasNonReadOnlyEntities = ois.readBoolean();\r\n        int count = ois.readInt();\r\n        if (tracing) {\r\n            LOG.trace(\"Starting deserialization of [\" + count + \"] entitiesByKey entries\");\r\n        }\r\n        rtn.entitiesByKey = new HashMap(count < INIT_COLL_SIZE ? INIT_COLL_SIZE : count);\r\n        for (int i = 0; i < count; i++) {\r\n            rtn.entitiesByKey.put(EntityKey.deserialize(ois, sfi), ois.readObject());\r\n        }\r\n        count = ois.readInt();\r\n        if (tracing) {\r\n            LOG.trace(\"Starting deserialization of [\" + count + \"] entitiesByUniqueKey entries\");\r\n        }\r\n        rtn.entitiesByUniqueKey = new HashMap(count < INIT_COLL_SIZE ? INIT_COLL_SIZE : count);\r\n        for (int i = 0; i < count; i++) {\r\n            rtn.entitiesByUniqueKey.put(EntityUniqueKey.deserialize(ois, session), ois.readObject());\r\n        }\r\n        count = ois.readInt();\r\n        if (tracing) {\r\n            LOG.trace(\"Starting deserialization of [\" + count + \"] proxiesByKey entries\");\r\n        }\r\n        rtn.proxiesByKey = new ConcurrentReferenceHashMap(count < INIT_COLL_SIZE ? INIT_COLL_SIZE : count, .75f, 1, ConcurrentReferenceHashMap.ReferenceType.STRONG, ConcurrentReferenceHashMap.ReferenceType.WEAK, null);\r\n        for (int i = 0; i < count; i++) {\r\n            final EntityKey ek = EntityKey.deserialize(ois, sfi);\r\n            final Object proxy = ois.readObject();\r\n            if (proxy instanceof HibernateProxy) {\r\n                ((HibernateProxy) proxy).getHibernateLazyInitializer().setSession(session);\r\n                rtn.proxiesByKey.put(ek, proxy);\r\n            } else {\r\n                if (tracing) {\r\n                    LOG.trace(\"Encountered pruned proxy\");\r\n                }\r\n            }\r\n        }\r\n        count = ois.readInt();\r\n        if (tracing) {\r\n            LOG.trace(\"Starting deserialization of [\" + count + \"] entitySnapshotsByKey entries\");\r\n        }\r\n        rtn.entitySnapshotsByKey = new HashMap(count < INIT_COLL_SIZE ? INIT_COLL_SIZE : count);\r\n        for (int i = 0; i < count; i++) {\r\n            rtn.entitySnapshotsByKey.put(EntityKey.deserialize(ois, sfi), ois.readObject());\r\n        }\r\n        rtn.entityEntryContext = EntityEntryContext.deserialize(ois, rtn);\r\n        count = ois.readInt();\r\n        if (tracing) {\r\n            LOG.trace(\"Starting deserialization of [\" + count + \"] collectionsByKey entries\");\r\n        }\r\n        rtn.collectionsByKey = new HashMap(count < INIT_COLL_SIZE ? INIT_COLL_SIZE : count);\r\n        for (int i = 0; i < count; i++) {\r\n            rtn.collectionsByKey.put(CollectionKey.deserialize(ois, session), (PersistentCollection) ois.readObject());\r\n        }\r\n        count = ois.readInt();\r\n        if (tracing) {\r\n            LOG.trace(\"Starting deserialization of [\" + count + \"] collectionEntries entries\");\r\n        }\r\n        rtn.collectionEntries = IdentityMap.instantiateSequenced(count < INIT_COLL_SIZE ? INIT_COLL_SIZE : count);\r\n        for (int i = 0; i < count; i++) {\r\n            final PersistentCollection pc = (PersistentCollection) ois.readObject();\r\n            final CollectionEntry ce = CollectionEntry.deserialize(ois, session);\r\n            pc.setCurrentSession(session);\r\n            rtn.collectionEntries.put(pc, ce);\r\n        }\r\n        count = ois.readInt();\r\n        if (tracing) {\r\n            LOG.trace(\"Starting deserialization of [\" + count + \"] arrayHolders entries\");\r\n        }\r\n        rtn.arrayHolders = new IdentityHashMap(count < INIT_COLL_SIZE ? INIT_COLL_SIZE : count);\r\n        for (int i = 0; i < count; i++) {\r\n            rtn.arrayHolders.put(ois.readObject(), (PersistentCollection) ois.readObject());\r\n        }\r\n        count = ois.readInt();\r\n        if (tracing) {\r\n            LOG.trace(\"Starting deserialization of [\" + count + \"] nullifiableEntityKey entries\");\r\n        }\r\n        rtn.nullifiableEntityKeys = new HashSet();\r\n        for (int i = 0; i < count; i++) {\r\n            rtn.nullifiableEntityKeys.add(EntityKey.deserialize(ois, sfi));\r\n        }\r\n    } catch (HibernateException he) {\r\n        throw new InvalidObjectException(he.getMessage());\r\n    }\r\n    return rtn;\r\n}"
}, {
	"Path": "org.hibernate.event.spi.AbstractCollectionEvent.getAffectedOwnerIdOrNull",
	"Comment": "get the id for the collection owner entity that is affected by this event.",
	"Method": "Serializable getAffectedOwnerIdOrNull(){\r\n    return affectedOwnerId;\r\n}"
}, {
	"Path": "org.hibernate.dialect.HSQLDialect.supportsIfExistsAfterTableName",
	"Comment": "we put the if exists before the tablename to be able to add cascade after.",
	"Method": "boolean supportsIfExistsAfterTableName(){\r\n    return false;\r\n}"
}, {
	"Path": "water.RPC.isReleasable",
	"Comment": "return true if blocking is unnecessary, which is true if the task isdone.",
	"Method": "boolean isReleasable(){\r\n    return isDone();\r\n}"
}, {
	"Path": "org.hibernate.stat.internal.QueryStatisticsImpl.getExecutionMaxTime",
	"Comment": "max time in ms taken by the execution of this query onto the db",
	"Method": "long getExecutionMaxTime(){\r\n    return executionMaxTime.get();\r\n}"
}, {
	"Path": "org.hibernate.Transaction.markRollbackOnly",
	"Comment": "make a best effort to mark the underlying transaction for rollback only.",
	"Method": "void markRollbackOnly(){\r\n    setRollbackOnly();\r\n}"
}, {
	"Path": "org.hibernate.criterion.DetachedCriteria.forClass",
	"Comment": "static builder to create a detachedcriteria for the given entity, by its class.",
	"Method": "DetachedCriteria forClass(Class clazz,DetachedCriteria forClass,Class clazz,String alias){\r\n    return new DetachedCriteria(clazz.getName(), alias);\r\n}"
}, {
	"Path": "org.hibernate.event.internal.AbstractFlushingEventListener.flushEntities",
	"Comment": "1. detect any dirty entities\t2. schedule any entity updates\t3. search out any reachable collections",
	"Method": "int flushEntities(FlushEvent event,PersistenceContext persistenceContext){\r\n    LOG.trace(\"Flushing entities and processing referenced collections\");\r\n    final EventSource source = event.getSession();\r\n    final Iterable<FlushEntityEventListener> flushListeners = source.getFactory().getServiceRegistry().getService(EventListenerRegistry.class).getEventListenerGroup(EventType.FLUSH_ENTITY).listeners();\r\n    final Map.Entry<Object, EntityEntry>[] entityEntries = persistenceContext.reentrantSafeEntityEntries();\r\n    final int count = entityEntries.length;\r\n    for (Map.Entry<Object, EntityEntry> me : entityEntries) {\r\n        EntityEntry entry = me.getValue();\r\n        Status status = entry.getStatus();\r\n        if (status != Status.LOADING && status != Status.GONE) {\r\n            final FlushEntityEvent entityEvent = new FlushEntityEvent(source, me.getKey(), entry);\r\n            for (FlushEntityEventListener listener : flushListeners) {\r\n                listener.onFlushEntity(entityEvent);\r\n            }\r\n        }\r\n    }\r\n    source.getActionQueue().sortActions();\r\n    return count;\r\n}"
}, {
	"Path": "water.TimeLine.printMyTimeLine",
	"Comment": "only for debugging.prints local timeline to stdout.to be used in case of an error when global timeline can not be relied upon as we might not be able to talk to other nodes.",
	"Method": "void printMyTimeLine(){\r\n    long[] s = TimeLine.snapshot();\r\n    System.err.println(\"===================================<TIMELINE>==============================================\");\r\n    for (int i = 0; i < TimeLine.length(); ++i) {\r\n        long lo = TimeLine.l0(s, i), hi = TimeLine.l8(s, i);\r\n        int port = (int) ((lo >> 8) & 0xFFFF);\r\n        String op = TimeLine.send_recv(s, i) == 0 ? \"SEND\" : \"RECV\";\r\n        if (!TimeLine.isEmpty(s, i) && (lo & 0xFF) == UDP.udp.exec.ordinal())\r\n            System.err.println(TimeLine.ms(s, i) + \": \" + op + \" \" + (((TimeLine.ns(s, i) & 4) != 0) ? \"TCP\" : \"UDP\") + TimeLine.inet(s, i) + \":\" + port + \" | \" + UDP.printx16(lo, hi));\r\n    }\r\n    System.err.println(\"===========================================================================================\");\r\n}"
}, {
	"Path": "org.hibernate.internal.util.jndi.JndiHelper.extractJndiProperties",
	"Comment": "given a hodgepodge of properties, extract out the ones relevant for jndi interaction.",
	"Method": "Properties extractJndiProperties(Map configurationValues){\r\n    return JndiServiceImpl.extractJndiProperties(configurationValues);\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.advance",
	"Comment": "advance the cursor to the first required row of the resultset",
	"Method": "void advance(ResultSet rs,RowSelection selection){\r\n    final int firstRow = LimitHelper.getFirstRow(selection);\r\n    if (firstRow != 0) {\r\n        if (getFactory().getSessionFactoryOptions().isScrollableResultSetsEnabled()) {\r\n            rs.absolute(firstRow);\r\n        } else {\r\n            for (int m = 0; m < firstRow; m++) {\r\n                rs.next();\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.persister.entity.AbstractEntityPersister.getTableUpdateNeeded",
	"Comment": "decide which tables need to be updated.\tthe return here is an array of boolean values with each index corresponding\tto a given table in the scope of this persister.",
	"Method": "boolean[] getTableUpdateNeeded(int[] dirtyProperties,boolean hasDirtyCollection){\r\n    if (dirtyProperties == null) {\r\n        return getTableHasColumns();\r\n    } else {\r\n        boolean[] updateability = getPropertyUpdateability();\r\n        int[] propertyTableNumbers = getPropertyTableNumbers();\r\n        boolean[] tableUpdateNeeded = new boolean[getTableSpan()];\r\n        for (int property : dirtyProperties) {\r\n            int table = propertyTableNumbers[property];\r\n            tableUpdateNeeded[table] = tableUpdateNeeded[table] || (getPropertyColumnSpan(property) > 0 && updateability[property]);\r\n        }\r\n        if (isVersioned()) {\r\n            tableUpdateNeeded[0] = tableUpdateNeeded[0] || Versioning.isVersionIncrementRequired(dirtyProperties, hasDirtyCollection, getPropertyVersionability());\r\n        }\r\n        return tableUpdateNeeded;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.hql.QueryLoader.bindParameterValues",
	"Comment": "we specifically override this method here, because in general we know much more\tabout the parameters and their appropriate bind positions here then we do in\tour super because we track them explicitly here through the parameterspecification\tinterface.",
	"Method": "int bindParameterValues(PreparedStatement statement,QueryParameters queryParameters,int startIndex,SharedSessionContractImplementor session){\r\n    int position = startIndex;\r\n    List<ParameterSpecification> parameterSpecs = queryTranslator.getCollectedParameterSpecifications();\r\n    for (ParameterSpecification spec : parameterSpecs) {\r\n        position += spec.bind(statement, queryParameters, session, position);\r\n    }\r\n    return position - startIndex;\r\n}"
}, {
	"Path": "org.hibernate.boot.model.naming.ImplicitNamingStrategyJpaCompliantImpl.toIdentifier",
	"Comment": "easy hook to build an identifier using the keyword safe identifierhelper.",
	"Method": "Identifier toIdentifier(String stringForm,MetadataBuildingContext buildingContext){\r\n    return buildingContext.getMetadataCollector().getDatabase().getJdbcEnvironment().getIdentifierHelper().toIdentifier(stringForm);\r\n}"
}, {
	"Path": "org.hibernate.bytecode.spi.ByteCodeHelper.readByteCode",
	"Comment": "reads class byte array info from the given input stream.\tthe stream is closed within this method!",
	"Method": "byte[] readByteCode(InputStream inputStream,byte[] readByteCode,File file,byte[] readByteCode,ZipInputStream zip){\r\n    final ByteArrayOutputStream bout = new ByteArrayOutputStream();\r\n    final InputStream in = new BufferedInputStream(zip);\r\n    int b;\r\n    while ((b = in.read()) != -1) {\r\n        bout.write(b);\r\n    }\r\n    return bout.toByteArray();\r\n}"
}, {
	"Path": "org.hibernate.mapping.MappedSuperclass.isPropertyDefinedInHierarchy",
	"Comment": "check to see if a property with the given name exists in this mappedsuperclass\tor in any of its super hierarchy.",
	"Method": "boolean isPropertyDefinedInHierarchy(String name){\r\n    if (hasProperty(name)) {\r\n        return true;\r\n    }\r\n    if (getSuperMappedSuperclass() != null && getSuperMappedSuperclass().isPropertyDefinedInHierarchy(name)) {\r\n        return true;\r\n    }\r\n    if (getSuperPersistentClass() != null && getSuperPersistentClass().isPropertyDefinedInHierarchy(name)) {\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.cfg.Configuration.mergeProperties",
	"Comment": "adds the incoming properties to the internal properties structure, as long as the internal structure does not\talready contain an entry for the given key.",
	"Method": "Configuration mergeProperties(Properties properties){\r\n    for (Map.Entry entry : properties.entrySet()) {\r\n        if (this.properties.containsKey(entry.getKey())) {\r\n            continue;\r\n        }\r\n        this.properties.setProperty((String) entry.getKey(), (String) entry.getValue());\r\n    }\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.engine.transaction.internal.jta.JtaStatusHelper.isActive",
	"Comment": "does the given status code indicate an active transaction?",
	"Method": "boolean isActive(int status,boolean isActive,UserTransaction userTransaction,boolean isActive,TransactionManager transactionManager){\r\n    return isActive(getStatus(transactionManager));\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.HQLQueryPlan.getSqlStrings",
	"Comment": "this method should only be called for debugging purposes as it regenerates a new array every time.",
	"Method": "String[] getSqlStrings(){\r\n    List<String> sqlStrings = new ArrayList();\r\n    for (int i = 0; i < translators.length; i++) {\r\n        sqlStrings.addAll(translators[i].collectSqlStrings());\r\n    }\r\n    return ArrayHelper.toStringArray(sqlStrings);\r\n}"
}, {
	"Path": "org.hibernate.cfg.DefaultNamingStrategy.collectionTableName",
	"Comment": "return the unqualified property name, not the best strategy but a backward compatible one",
	"Method": "String collectionTableName(String ownerEntity,String ownerEntityTable,String associatedEntity,String associatedEntityTable,String propertyName){\r\n    return StringHelper.unqualify(propertyName);\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.getInstanceClass",
	"Comment": "determine the concrete class of an instance in the resultset",
	"Method": "String getInstanceClass(ResultSet rs,int i,Loadable persister,Serializable id,SharedSessionContractImplementor session){\r\n    if (persister.hasSubclasses()) {\r\n        final Object discriminatorValue = persister.getDiscriminatorType().nullSafeGet(rs, getEntityAliases()[i].getSuffixedDiscriminatorAlias(), session, null);\r\n        final String result = persister.getSubclassForDiscriminatorValue(discriminatorValue);\r\n        if (result == null) {\r\n            throw new WrongClassException(\"Discriminator: \" + discriminatorValue, id, persister.getEntityName());\r\n        }\r\n        return result;\r\n    } else {\r\n        return persister.getEntityName();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.BatchFetchQueue.getSubselect",
	"Comment": "retrieve the fetch descriptor associated with the given entity key.",
	"Method": "SubselectFetch getSubselect(EntityKey key){\r\n    return subselectsByEntityKey.get(key);\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.JoinSequence.setRoot",
	"Comment": "set the root of this joinsequence.in sql terms, this would be the driving table.",
	"Method": "JoinSequence setRoot(Joinable joinable,String alias){\r\n    this.rootAlias = alias;\r\n    this.rootJoinable = joinable;\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.JDBCException.getSQL",
	"Comment": "get the actual sql statement being executed when the exception occurred.",
	"Method": "String getSQL(){\r\n    return sql;\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.HQLQueryPlan.performList",
	"Comment": "coordinates the efforts to perform a list across all the included query translators.",
	"Method": "List performList(QueryParameters queryParameters,SharedSessionContractImplementor session){\r\n    if (traceEnabled) {\r\n        LOG.tracev(\"Find: {0}\", getSourceQuery());\r\n        queryParameters.traceParameters(session.getFactory());\r\n    }\r\n    final RowSelection rowSelection = queryParameters.getRowSelection();\r\n    final boolean hasLimit = rowSelection != null && rowSelection.definesLimits();\r\n    final boolean needsLimit = hasLimit && translators.length > 1;\r\n    final QueryParameters queryParametersToUse;\r\n    if (needsLimit) {\r\n        LOG.needsLimit();\r\n        final RowSelection selection = new RowSelection();\r\n        selection.setFetchSize(queryParameters.getRowSelection().getFetchSize());\r\n        selection.setTimeout(queryParameters.getRowSelection().getTimeout());\r\n        queryParametersToUse = queryParameters.createCopyUsing(selection);\r\n    } else {\r\n        queryParametersToUse = queryParameters;\r\n    }\r\n    if (translators.length == 1) {\r\n        return translators[0].list(session, queryParametersToUse);\r\n    }\r\n    final int guessedResultSize = guessResultSize(rowSelection);\r\n    final List combinedResults = new ArrayList(guessedResultSize);\r\n    final IdentitySet distinction;\r\n    if (needsLimit) {\r\n        distinction = new IdentitySet(guessedResultSize);\r\n    } else {\r\n        distinction = null;\r\n    }\r\n    int includedCount = -1;\r\n    translator_loop: for (QueryTranslator translator : translators) {\r\n        final List tmp = translator.list(session, queryParametersToUse);\r\n        if (needsLimit) {\r\n            final int first = queryParameters.getRowSelection().getFirstRow() == null ? 0 : queryParameters.getRowSelection().getFirstRow();\r\n            final int max = queryParameters.getRowSelection().getMaxRows() == null ? -1 : queryParameters.getRowSelection().getMaxRows();\r\n            for (final Object result : tmp) {\r\n                if (!distinction.add(result)) {\r\n                    continue;\r\n                }\r\n                includedCount++;\r\n                if (includedCount < first) {\r\n                    continue;\r\n                }\r\n                combinedResults.add(result);\r\n                if (max >= 0 && includedCount > max) {\r\n                    break translator_loop;\r\n                }\r\n            }\r\n        } else {\r\n            combinedResults.addAll(tmp);\r\n        }\r\n    }\r\n    return combinedResults;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.openQuote",
	"Comment": "the character specific to this dialect used to begin a quoted identifier.",
	"Method": "char openQuote(){\r\n    return '\"';\r\n}"
}, {
	"Path": "org.hibernate.internal.util.collections.ConcurrentReferenceHashMap.putAll",
	"Comment": "copies all of the mappings from the specified map to this one.\tthese mappings replace any mappings that this map had for any of the\tkeys currently in the specified map.",
	"Method": "void putAll(Map<? extends K, ? extends V> m){\r\n    for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {\r\n        put(e.getKey(), e.getValue());\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.pagination.AbstractLimitHandler.bindLimitParametersInReverseOrder",
	"Comment": "ansi sql defines the limit clause to be in the form limit offset, limit.\tdoes this dialect require us to bind the parameters in reverse order?",
	"Method": "boolean bindLimitParametersInReverseOrder(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.HqlToken.setPossibleID",
	"Comment": "set to true if this token can be interpreted as an identifier,\tfalse if not.",
	"Method": "void setPossibleID(boolean possibleID){\r\n    this.possibleID = possibleID;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.SessionFactoryHelper.requireSQLFunction",
	"Comment": "locate a registered sql function by name, requiring that such a registered function exist.",
	"Method": "SQLFunction requireSQLFunction(String functionName){\r\n    SQLFunction f = findSQLFunction(functionName);\r\n    if (f == null) {\r\n        throw new QueryException(\"Unable to find SQL function: \" + functionName);\r\n    }\r\n    return f;\r\n}"
}, {
	"Path": "water.util.FileUtils.keyToFileName",
	"Comment": "transform given key to a string which can be used as a file name.",
	"Method": "String keyToFileName(Key k){\r\n    return k.toString().replaceAll(\"[^a-zA-Z0-9_\\\\-\\\\.]\", \"_\");\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.areResultSetRowsTransformedImmediately",
	"Comment": "are rows transformed immediately after being read from the resultset?",
	"Method": "boolean areResultSetRowsTransformedImmediately(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.persister.entity.AbstractEntityPersister.getEntityName",
	"Comment": "temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~",
	"Method": "String getEntityName(){\r\n    return entityMetamodel.getName();\r\n}"
}, {
	"Path": "org.hibernate.criterion.Property.isNotEmpty",
	"Comment": "creates a restriction to check that a collection is not empty",
	"Method": "Criterion isNotEmpty(){\r\n    return Restrictions.isNotEmpty(getPropertyName());\r\n}"
}, {
	"Path": "org.hibernate.type.EntityType.getIdentifierType",
	"Comment": "convenience method to locate the identifier type of the associated entity.",
	"Method": "Type getIdentifierType(Mapping factory,Type getIdentifierType,SharedSessionContractImplementor session){\r\n    final Type type = associatedIdentifierType;\r\n    if (type == null) {\r\n        associatedIdentifierType = getIdentifierType(session.getFactory());\r\n        return associatedIdentifierType;\r\n    } else {\r\n        return type;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.SessionFactoryHelper.findFunctionReturnType",
	"Comment": "find the function return type given the function name and the first argument expression node.",
	"Method": "Type findFunctionReturnType(String functionName,AST first,Type findFunctionReturnType,String functionName,SQLFunction sqlFunction,AST firstArgument){\r\n    Type argumentType = null;\r\n    if (firstArgument != null) {\r\n        if (\"cast\".equals(functionName)) {\r\n            argumentType = sfi.getTypeResolver().heuristicType(firstArgument.getNextSibling().getText());\r\n        } else if (SqlNode.class.isInstance(firstArgument)) {\r\n            argumentType = ((SqlNode) firstArgument).getDataType();\r\n        }\r\n    }\r\n    return sqlFunction.getReturnType(argumentType, sfi);\r\n}"
}, {
	"Path": "org.hibernate.UnresolvableObjectException.throwIfNull",
	"Comment": "factory method for building and throwing an unresolvableobjectexception if the entity is null.",
	"Method": "void throwIfNull(Object entity,Serializable identifier,String entityName){\r\n    if (entity == null) {\r\n        throw new UnresolvableObjectException(identifier, entityName);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.event.internal.MergeContext.isOperatedOn",
	"Comment": "returns true if the listener is performing the merge operation on the specified merge entity.",
	"Method": "boolean isOperatedOn(Object mergeEntity){\r\n    if (mergeEntity == null) {\r\n        throw new NullPointerException(\"null merge entities are not supported by \" + getClass().getName());\r\n    }\r\n    final Boolean isOperatedOn = mergeEntityToOperatedOnFlagMap.get(mergeEntity);\r\n    return isOperatedOn == null ? false : isOperatedOn;\r\n}"
}, {
	"Path": "water.util.ArrayUtils.sqrtArr",
	"Comment": "return the sqrt of each element of the array.will overwrite the original array in this case",
	"Method": "double[] sqrtArr(double[] x){\r\n    assert (x != null);\r\n    int len = x.length;\r\n    for (int index = 0; index < len; index++) {\r\n        assert (x[index] >= 0.0);\r\n        x[index] = sqrt(x[index]);\r\n    }\r\n    return x;\r\n}"
}, {
	"Path": "org.hibernate.type.TypeHelper.findDirty",
	"Comment": "determine if any of the given field values are dirty, returning an array containing\tindices of the dirty fields.\tif it is determined that no fields are dirty, null is returned.",
	"Method": "int[] findDirty(NonIdentifierAttribute[] properties,Object[] currentState,Object[] previousState,boolean[][] includeColumns,boolean anyUninitializedProperties,SharedSessionContractImplementor session,int[] findDirty,NonIdentifierAttribute[] properties,Object[] currentState,Object[] previousState,boolean[][] includeColumns,SharedSessionContractImplementor session){\r\n    int[] results = null;\r\n    int count = 0;\r\n    int span = properties.length;\r\n    for (int i = 0; i < span; i++) {\r\n        final boolean dirty = currentState[i] != LazyPropertyInitializer.UNFETCHED_PROPERTY && (previousState[i] == LazyPropertyInitializer.UNFETCHED_PROPERTY || (properties[i].isDirtyCheckable() && properties[i].getType().isDirty(previousState[i], currentState[i], includeColumns[i], session)));\r\n        if (dirty) {\r\n            if (results == null) {\r\n                results = new int[span];\r\n            }\r\n            results[count++] = i;\r\n        }\r\n    }\r\n    if (count == 0) {\r\n        return null;\r\n    } else {\r\n        int[] trimmed = new int[count];\r\n        System.arraycopy(results, 0, trimmed, 0, count);\r\n        return trimmed;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.internal.util.config.ConfigurationHelper.toStringArray",
	"Comment": "convert a string to an array of strings.the assumption is that\tthe individual array elements are delimited in the source stringform\tparam by the delim param.",
	"Method": "String[] toStringArray(String propertyName,String delim,Properties properties,String[] toStringArray,String stringForm,String delim){\r\n    if (stringForm != null) {\r\n        return StringHelper.split(delim, stringForm);\r\n    } else {\r\n        return ArrayHelper.EMPTY_STRING_ARRAY;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.QueryPlanCache.getHQLQueryPlan",
	"Comment": "get the query plan for the given hql query, creating it and caching it if not already cached",
	"Method": "HQLQueryPlan getHQLQueryPlan(String queryString,boolean shallow,Map<String, Filter> enabledFilters){\r\n    final HQLQueryPlanKey key = new HQLQueryPlanKey(queryString, shallow, enabledFilters);\r\n    HQLQueryPlan value = (HQLQueryPlan) queryPlanCache.get(key);\r\n    boolean stats = factory.getStatistics().isStatisticsEnabled();\r\n    if (value == null) {\r\n        final long startTime = (stats) ? System.nanoTime() : 0L;\r\n        LOG.tracev(\"Unable to locate HQL query plan in cache; generating ({0})\", queryString);\r\n        value = new HQLQueryPlan(queryString, shallow, enabledFilters, factory);\r\n        if (stats) {\r\n            final long endTime = System.nanoTime();\r\n            final long microseconds = TimeUnit.MICROSECONDS.convert(endTime - startTime, TimeUnit.NANOSECONDS);\r\n            factory.getStatistics().queryCompiled(queryString, microseconds);\r\n        }\r\n        queryPlanCache.putIfAbsent(key, value);\r\n    } else {\r\n        LOG.tracev(\"Located HQL query plan in cache ({0})\", queryString);\r\n        if (stats) {\r\n            factory.getStatistics().queryPlanCacheHit(queryString);\r\n        }\r\n    }\r\n    return value;\r\n}"
}, {
	"Path": "org.hibernate.criterion.Property.between",
	"Comment": "creates a between restriction for this property between the given min and max",
	"Method": "Criterion between(Object min,Object max){\r\n    return Restrictions.between(getPropertyName(), min, max);\r\n}"
}, {
	"Path": "org.hibernate.internal.util.config.ConfigurationHelper.extractPropertyValue",
	"Comment": "extract a property value by name from the given properties object.\tboth null and empty string are viewed as the same, and return null.",
	"Method": "String extractPropertyValue(String propertyName,Properties properties,String extractPropertyValue,String propertyName,Map properties){\r\n    String value = (String) properties.get(propertyName);\r\n    if (value == null) {\r\n        return null;\r\n    }\r\n    value = value.trim();\r\n    if (StringHelper.isEmpty(value)) {\r\n        return null;\r\n    }\r\n    return value;\r\n}"
}, {
	"Path": "water.RPC.get",
	"Comment": "throws a dexception if the remote throws, wrapping the original exception.",
	"Method": "V get(V get,long timeout,TimeUnit unit){\r\n    if (_done)\r\n        return _dt;\r\n    throw H2O.fail();\r\n}"
}, {
	"Path": "org.hibernate.boot.jaxb.internal.stax.LocalSchemaLocator.resolveLocalSchemaUrl",
	"Comment": "given the resource name of a schema, locate its url reference via classloader lookup.",
	"Method": "URL resolveLocalSchemaUrl(String schemaResourceName){\r\n    URL url = LocalSchemaLocator.class.getClassLoader().getResource(schemaResourceName);\r\n    if (url == null) {\r\n        throw new XmlInfrastructureException(\"Unable to locate schema [\" + schemaResourceName + \"] via classpath\");\r\n    }\r\n    return url;\r\n}"
}, {
	"Path": "org.hibernate.mapping.Table.getColumn",
	"Comment": "return the column which is identified by column provided as argument.",
	"Method": "Column getColumn(Column column,Column getColumn,Identifier name,Column getColumn,int n){\r\n    Iterator iter = columns.values().iterator();\r\n    for (int i = 0; i < n - 1; i++) {\r\n        iter.next();\r\n    }\r\n    return (Column) iter.next();\r\n}"
}, {
	"Path": "hex.genmodel.easy.EasyPredictModelWrapper.predictMultinomial",
	"Comment": "make a prediction on a new data point using a multinomial model.",
	"Method": "MultinomialModelPrediction predictMultinomial(RowData data,MultinomialModelPrediction predictMultinomial,RowData data,double offset){\r\n    double[] preds = preamble(ModelCategory.Multinomial, data, offset);\r\n    MultinomialModelPrediction p = new MultinomialModelPrediction();\r\n    if (enableLeafAssignment) {\r\n        SharedTreeMojoModel.LeafNodeAssignments assignments = leafNodeAssignmentExtended(data);\r\n        p.leafNodeAssignments = assignments._paths;\r\n        p.leafNodeAssignmentIds = assignments._nodeIds;\r\n    }\r\n    p.classProbabilities = new double[m.getNumResponseClasses()];\r\n    p.labelIndex = (int) preds[0];\r\n    String[] domainValues = m.getDomainValues(m.getResponseIdx());\r\n    p.label = domainValues[p.labelIndex];\r\n    System.arraycopy(preds, 1, p.classProbabilities, 0, p.classProbabilities.length);\r\n    return p;\r\n}"
}, {
	"Path": "water.hadoop.h2omapper.printArgs",
	"Comment": "under unusual debugging circumstances, it can be helpful to print out the command line arguments in this format.",
	"Method": "void printArgs(String[] arr){\r\n    Log.info(\"\");\r\n    Log.info(\"----- printArgs -----\");\r\n    for (int i = 0; i < arr.length; i++) {\r\n        String s = arr[i];\r\n        Log.info(i);\r\n        if (s == null) {\r\n            Log.info(\"null\");\r\n        } else {\r\n            Log.info(s);\r\n        }\r\n    }\r\n    Log.info(\"----------\");\r\n}"
}, {
	"Path": "org.hibernate.cfg.Environment.useStreamsForBinary",
	"Comment": "should we use streams to bind binary types to jdbc in parameters?",
	"Method": "boolean useStreamsForBinary(){\r\n    return ENABLE_BINARY_STREAMS;\r\n}"
}, {
	"Path": "org.hibernate.loader.GeneratedCollectionAliases.getSuffix",
	"Comment": "returns the suffix used to unique the column aliases for this particular alias set.",
	"Method": "String getSuffix(){\r\n    return suffix;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.HqlSqlWalker.getNamedParameterLocations",
	"Comment": "returns the locations of all occurrences of the named parameter.",
	"Method": "int[] getNamedParameterLocations(String name){\r\n    Object o = namedParameters.get(name);\r\n    if (o == null) {\r\n        throw new QueryException(QueryTranslator.ERROR_NAMED_PARAMETER_DOES_NOT_APPEAR + name, queryTranslatorImpl.getQueryString());\r\n    }\r\n    if (o instanceof Integer) {\r\n        return new int[] { (Integer) o };\r\n    } else {\r\n        return ArrayHelper.toIntArray((ArrayList) o);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.FromElement.isImplied",
	"Comment": "returns true if this fromelement was implied by a path, or false if this from element is explicitly declared in\tthe from clause.",
	"Method": "boolean isImplied(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.boot.registry.StandardServiceRegistryBuilder.destroy",
	"Comment": "destroy a service registry.applications should only destroy registries they have explicitly created.",
	"Method": "void destroy(ServiceRegistry serviceRegistry){\r\n    if (serviceRegistry == null) {\r\n        return;\r\n    }\r\n    ((StandardServiceRegistryImpl) serviceRegistry).destroy();\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.StatefulPersistenceContext.getLoadedCollectionOwnerIdOrNull",
	"Comment": "get the id for the entity that owned this persistent collection when it was loaded",
	"Method": "Serializable getLoadedCollectionOwnerIdOrNull(PersistentCollection collection,Serializable getLoadedCollectionOwnerIdOrNull,CollectionEntry ce){\r\n    if (ce == null || ce.getLoadedKey() == null || ce.getLoadedPersister() == null) {\r\n        return null;\r\n    }\r\n    return ce.getLoadedPersister().getCollectionType().getIdOfOwnerOrNull(ce.getLoadedKey(), session);\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.spi.SqlExceptionHelper.getSqlExceptionConverter",
	"Comment": "access the current exception converter being used internally.",
	"Method": "SQLExceptionConverter getSqlExceptionConverter(){\r\n    return sqlExceptionConverter;\r\n}"
}, {
	"Path": "hex.ConfusionMatrixTest.testDifferentLengthVectors",
	"Comment": "negative test testing expected exception if two vectorsof different lengths are provided.",
	"Method": "void testDifferentLengthVectors(){\r\n    simpleCMTest(\"smalldata/junit/cm/v1.csv\", \"smalldata/junit/cm/v3.csv\", ar(\"A\", \"B\", \"C\"), ar(\"A\", \"B\", \"C\"), ar(\"A\", \"B\", \"C\"), ard(ard(1, 1, 0), ard(0, 1, 1), ard(0, 0, 1)), debug);\r\n}"
}, {
	"Path": "org.hibernate.cfg.PropertyHolder.getOverriddenForeignKey",
	"Comment": "return null if hte foreign key is not overridden, or the foreign key if true",
	"Method": "ForeignKey getOverriddenForeignKey(String propertyName){\r\n    return null;\r\n}"
}, {
	"Path": "org.hibernate.internal.util.ReflectHelper.reflectedPropertyClass",
	"Comment": "attempt to resolve the specified property type through reflection.",
	"Method": "Class reflectedPropertyClass(String className,String name,ClassLoaderService classLoaderService,Class reflectedPropertyClass,Class clazz,String name){\r\n    return getter(clazz, name).getReturnType();\r\n}"
}, {
	"Path": "org.hibernate.persister.collection.AbstractCollectionPersister.getElementClass",
	"Comment": "return the element class of an array, or null otherwise.needed by arrays",
	"Method": "Class getElementClass(){\r\n    return elementClass;\r\n}"
}, {
	"Path": "org.hibernate.persister.entity.AbstractEntityPersister.dehydrate",
	"Comment": "marshall the fields of a persistent instance to a prepared statement",
	"Method": "int dehydrate(Serializable id,Object[] fields,boolean[] includeProperty,boolean[][] includeColumns,int j,PreparedStatement st,SharedSessionContractImplementor session,boolean isUpdate,int dehydrate,Serializable id,Object[] fields,Object rowId,boolean[] includeProperty,boolean[][] includeColumns,int j,PreparedStatement ps,SharedSessionContractImplementor session,int index,boolean isUpdate){\r\n    if (LOG.isTraceEnabled()) {\r\n        LOG.tracev(\"Dehydrating entity: {0}\", MessageHelper.infoString(this, id, getFactory()));\r\n    }\r\n    for (int i = 0; i < entityMetamodel.getPropertySpan(); i++) {\r\n        if (includeProperty[i] && isPropertyOfTable(i, j) && !lobProperties.contains(i)) {\r\n            getPropertyTypes()[i].nullSafeSet(ps, fields[i], index, includeColumns[i], session);\r\n            index += ArrayHelper.countTrue(includeColumns[i]);\r\n        }\r\n    }\r\n    if (!isUpdate) {\r\n        index += dehydrateId(id, rowId, ps, session, index);\r\n    }\r\n    for (int i : lobProperties) {\r\n        if (includeProperty[i] && isPropertyOfTable(i, j)) {\r\n            getPropertyTypes()[i].nullSafeSet(ps, fields[i], index, includeColumns[i], session);\r\n            index += ArrayHelper.countTrue(includeColumns[i]);\r\n        }\r\n    }\r\n    if (isUpdate) {\r\n        index += dehydrateId(id, rowId, ps, session, index);\r\n    }\r\n    return index;\r\n}"
}, {
	"Path": "org.hibernate.Query.setHibernateFirstResult",
	"Comment": "set the position of the first query result to be retrieved. a negative value will\tresult in pagination starting from position 0.",
	"Method": "Query setHibernateFirstResult(int firstRow){\r\n    if (firstRow < 0) {\r\n        getQueryOptions().setFirstRow(0);\r\n    } else {\r\n        getQueryOptions().setFirstRow(firstRow);\r\n    }\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.ASTUtil.insertSibling",
	"Comment": "inserts a node into a child subtree as a particularly positioned\tsibling taking care to properly reorganize the tree to account for this\tnew addition.",
	"Method": "AST insertSibling(AST node,AST prevSibling){\r\n    node.setNextSibling(prevSibling.getNextSibling());\r\n    prevSibling.setNextSibling(node);\r\n    return node;\r\n}"
}, {
	"Path": "hex.createframe.OriginalCreateFrameRecipeTest.missingValuesTest",
	"Comment": "test that the produced number of missing values is the same as requested.",
	"Method": "void missingValuesTest(){\r\n    CreateFrameOriginalIV4 s = new CreateFrameOriginalIV4().fillFromImpl();\r\n    s.rows = 25000;\r\n    s.cols = 4;\r\n    s.categorical_fraction = 0;\r\n    s.integer_fraction = 0;\r\n    s.binary_fraction = 0;\r\n    s.string_fraction = 0;\r\n    s.time_fraction = 0;\r\n    s.missing_fraction = 0.1;\r\n    s.has_response = true;\r\n    s.response_factors = 1;\r\n    Frame frame = s.createAndFillImpl().exec().get();\r\n    assertNotNull(frame);\r\n    assertEquals(s.cols + 1, frame.numCols());\r\n    assertEquals(s.rows, frame.numRows());\r\n    long missingCount = 0;\r\n    for (int i = 0; i < s.cols + 1; i++) {\r\n        missingCount += frame.vec(i).naCnt();\r\n    }\r\n    double N = s.rows * (s.cols + 1);\r\n    double p = s.missing_fraction;\r\n    double ttest = Math.abs(missingCount - N * p) / Math.sqrt(N * p * (1 - p));\r\n    assertTrue(\"Count of NAs is more than 4.417 sigmas away from the expected value: t = \" + ttest, ttest < 4.417);\r\n    frame.delete();\r\n}"
}, {
	"Path": "water.util.TwoDimTable.setTableHeader",
	"Comment": "need to change table header when we are calling glrm from pca.",
	"Method": "void setTableHeader(String newHeader){\r\n    if (!StringUtils.isNullOrEmpty(newHeader)) {\r\n        this.tableHeader = newHeader;\r\n    }\r\n}"
}, {
	"Path": "water.parser.orc.OrcParser.writeStringcolumn",
	"Comment": "this method writes a column of h2o frame for orc file column types of string, varchar, char andbinary at some point.",
	"Method": "void writeStringcolumn(BytesColumnVector col,int cIdx,int rowNumber,ParseWriter dout){\r\n    BufferedString bs = new BufferedString();\r\n    if (col.isRepeating) {\r\n        assert col.length[0] >= 0 : getClass().getSimpleName() + \".writeStringcolumn/1: col.length[0]=\" + col.length[0] + \", col.start[0]=\" + col.start[0];\r\n        dout.addStrCol(cIdx, bs.set(col.vector[0], col.start[0], col.length[0]));\r\n        for (int rowIndex = 1; rowIndex < rowNumber; ++rowIndex) dout.addStrCol(cIdx, bs);\r\n    } else if (col.noNulls) {\r\n        for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) {\r\n            int l = col.length[rowIndex];\r\n            assert l >= 0 : getClass().getSimpleName() + \".writeStringcolumn/2: col.col.length[rowIndex]=\" + l + \", rowIndex=\" + rowIndex;\r\n            dout.addStrCol(cIdx, bs.set(col.vector[rowIndex], col.start[rowIndex], l));\r\n        }\r\n    } else {\r\n        boolean[] isNull = col.isNull;\r\n        for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) {\r\n            if (isNull[rowIndex])\r\n                dout.addInvalidCol(cIdx);\r\n            else {\r\n                int l = col.length[rowIndex];\r\n                assert l >= 0 : getClass().getSimpleName() + \".writeStringcolumn/3: col.col.length[rowIndex]=\" + l + \", rowIndex=\" + rowIndex;\r\n                dout.addStrCol(cIdx, bs.set(col.vector[rowIndex], col.start[rowIndex], col.length[rowIndex]));\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.jpa.internal.util.XmlHelper.getChildrenByTagName",
	"Comment": "returns an iterator over the children of the given element with\tthe given tag name.",
	"Method": "Iterator getChildrenByTagName(Element element,String tagName){\r\n    if (element == null) {\r\n        return null;\r\n    }\r\n    NodeList children = element.getChildNodes();\r\n    ArrayList goodChildren = new ArrayList();\r\n    for (int i = 0; i < children.getLength(); i++) {\r\n        Node currentChild = children.item(i);\r\n        if (currentChild.getNodeType() == Node.ELEMENT_NODE && ((Element) currentChild).getTagName().equals(tagName)) {\r\n            goodChildren.add(currentChild);\r\n        }\r\n    }\r\n    return goodChildren.iterator();\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.supportsParametersInInsertSelect",
	"Comment": "does this dialect support parameters within the select clause of\tinsert ... select ... statements?",
	"Method": "boolean supportsParametersInInsertSelect(){\r\n    return true;\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.readCollectionElements",
	"Comment": "read any collection elements contained in a single row of the result set",
	"Method": "void readCollectionElements(Object[] row,ResultSet resultSet,SharedSessionContractImplementor session){\r\n    final CollectionPersister[] collectionPersisters = getCollectionPersisters();\r\n    if (collectionPersisters != null) {\r\n        final CollectionAliases[] descriptors = getCollectionAliases();\r\n        final int[] collectionOwners = getCollectionOwners();\r\n        for (int i = 0; i < collectionPersisters.length; i++) {\r\n            final boolean hasCollectionOwners = collectionOwners != null && collectionOwners[i] > -1;\r\n            final Object owner = // if null, owner will be retrieved from session\r\n            hasCollectionOwners ? row[collectionOwners[i]] : null;\r\n            final CollectionPersister collectionPersister = collectionPersisters[i];\r\n            final Serializable key;\r\n            if (owner == null) {\r\n                key = null;\r\n            } else {\r\n                key = collectionPersister.getCollectionType().getKeyOfOwner(owner, session);\r\n            }\r\n            readCollectionElement(owner, key, collectionPersister, descriptors[i], resultSet, session);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.stat.Statistics.getQueryPlanCacheHitCount",
	"Comment": "get the global number of query plans successfully retrieved from cache",
	"Method": "long getQueryPlanCacheHitCount(){\r\n    return 0;\r\n}"
}, {
	"Path": "org.hibernate.test.agroal.util.PreparedStatementSpyConnectionProvider.clear",
	"Comment": "clears the recorded preparedstatements and reset the associated mocks.",
	"Method": "void clear(){\r\n    acquiredConnections.clear();\r\n    releasedConnections.clear();\r\n    preparedStatementMap.keySet().forEach(Mockito::reset);\r\n    preparedStatementMap.clear();\r\n}"
}, {
	"Path": "org.hibernate.LockOptions.getAliasLockCount",
	"Comment": "get the number of aliases that have specific lock modes defined.",
	"Method": "int getAliasLockCount(){\r\n    if (aliasSpecificLockModes == null) {\r\n        return 0;\r\n    }\r\n    return aliasSpecificLockModes.size();\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.SelectExpressionList.getTotalParameterCount",
	"Comment": "the total number of parameter projections of this expression.",
	"Method": "int getTotalParameterCount(){\r\n    return parameterPositions.size();\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.BatchFetchQueue.clear",
	"Comment": "clears all entries from this fetch queue.\tcalled after flushing or clearing the session.",
	"Method": "void clear(){\r\n    batchLoadableEntityKeys.clear();\r\n    batchLoadableCollections.clear();\r\n    subselectsByEntityKey.clear();\r\n}"
}, {
	"Path": "org.hibernate.internal.SessionFactoryImpl.writeObject",
	"Comment": "custom serialization hook defined by java spec.used when the factory is directly serialized",
	"Method": "void writeObject(ObjectOutputStream out){\r\n    LOG.debugf(\"Serializing: %s\", getUuid());\r\n    out.defaultWriteObject();\r\n    LOG.trace(\"Serialized\");\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.JoinHelper.getLHSColumnNames",
	"Comment": "get the columns of the owning entity which are to be used in the join",
	"Method": "String[] getLHSColumnNames(AssociationType type,int property,OuterJoinLoadable lhsPersister,Mapping mapping,String[] getLHSColumnNames,AssociationType type,int property,int begin,OuterJoinLoadable lhsPersister,Mapping mapping){\r\n    if (type.useLHSPrimaryKey()) {\r\n        return lhsPersister.getIdentifierColumnNames();\r\n    } else {\r\n        final String propertyName = type.getLHSPropertyName();\r\n        if (propertyName == null) {\r\n            return ArrayHelper.slice(property < 0 ? lhsPersister.getIdentifierColumnNames() : lhsPersister.getSubclassPropertyColumnNames(property), begin, type.getColumnSpan(mapping));\r\n        } else {\r\n            return lhsPersister.getPropertyColumnNames(propertyName);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.SerializableBlobProxy.generateProxy",
	"Comment": "generates a serializableblob proxy wrapping the provided blob object.",
	"Method": "Blob generateProxy(Blob blob){\r\n    return (Blob) Proxy.newProxyInstance(getProxyClassLoader(), PROXY_INTERFACES, new SerializableBlobProxy(blob));\r\n}"
}, {
	"Path": "org.hibernate.event.internal.MergeContext.keySet",
	"Comment": "returns an unmodifiable set view of the merge entities contained in this mergecontext",
	"Method": "Set keySet(){\r\n    return Collections.unmodifiableSet(mergeToManagedEntityXref.keySet());\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.bindNamedParameters",
	"Comment": "bind named parameters to the jdbc prepared statement.\tthis is a generic implementation, the problem being that in the\tgeneral case we do not know enough information about the named\tparameters to perform this in a complete manner here.thus this\tis generally overridden on subclasses allowing named parameters to\tapply the specific behavior.the most usual limitation here is that\twe need to assume the type span is always one...",
	"Method": "int bindNamedParameters(PreparedStatement statement,Map<String, TypedValue> namedParams,int startIndex,SharedSessionContractImplementor session){\r\n    int result = 0;\r\n    if (CollectionHelper.isEmpty(namedParams)) {\r\n        return result;\r\n    }\r\n    for (String name : namedParams.keySet()) {\r\n        TypedValue typedValue = namedParams.get(name);\r\n        int columnSpan = typedValue.getType().getColumnSpan(getFactory());\r\n        int[] locs = getNamedParameterLocs(name);\r\n        for (int loc : locs) {\r\n            if (DEBUG_ENABLED) {\r\n                LOG.debugf(\"bindNamedParameters() %s -> %s [%s]\", typedValue.getValue(), name, loc + startIndex);\r\n            }\r\n            int start = loc * columnSpan + startIndex;\r\n            typedValue.getType().nullSafeSet(statement, typedValue.getValue(), start, session);\r\n        }\r\n        result += locs.length;\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getSchemaNameResolver",
	"Comment": "get the strategy for determining the schema name of a connection",
	"Method": "SchemaNameResolver getSchemaNameResolver(){\r\n    return DefaultSchemaNameResolver.INSTANCE;\r\n}"
}, {
	"Path": "org.hibernate.tool.hbm2ddl.SchemaExport.setOutputFile",
	"Comment": "for generating a export script file, this is the file which will be written.",
	"Method": "SchemaExport setOutputFile(String filename){\r\n    outputFile = filename;\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.engine.loading.internal.LoadContexts.hasRegisteredLoadingCollectionEntries",
	"Comment": "do we currently have any registered internal entries corresponding to loading\tcollections?",
	"Method": "boolean hasRegisteredLoadingCollectionEntries(){\r\n    return (xrefLoadingCollectionEntries != null && !xrefLoadingCollectionEntries.isEmpty());\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.ExecutableList.writeExternal",
	"Comment": "write this list out to the given stream as part of serialization",
	"Method": "void writeExternal(ObjectOutput oos){\r\n    oos.writeBoolean(sorted);\r\n    oos.writeInt(executables.size());\r\n    for (E e : executables) {\r\n        oos.writeObject(e);\r\n    }\r\n    if (querySpaces == null) {\r\n        oos.writeInt(-1);\r\n    } else {\r\n        oos.writeInt(querySpaces.size());\r\n        for (Serializable querySpace : querySpaces) {\r\n            oos.writeUTF(querySpace.toString());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.supportsUniqueConstraintInCreateAlterTable",
	"Comment": "does this dialect support adding unique constraints via create and alter table ?",
	"Method": "boolean supportsUniqueConstraintInCreateAlterTable(){\r\n    return true;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getSelectGUIDString",
	"Comment": "get the command used to select a guid from the underlying database.\toptional operation.",
	"Method": "String getSelectGUIDString(){\r\n    throw new UnsupportedOperationException(getClass().getName() + \" does not support GUIDs\");\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.SerializableClobProxy.getProxyClassLoader",
	"Comment": "determines the appropriate class loader to which the generated proxy\tshould be scoped.",
	"Method": "ClassLoader getProxyClassLoader(){\r\n    return WrappedClob.class.getClassLoader();\r\n}"
}, {
	"Path": "org.hibernate.persister.entity.AbstractEntityPersister.isReadRequired",
	"Comment": "whether the given value generation strategy requires to read the value from the database or not.",
	"Method": "boolean isReadRequired(ValueGeneration valueGeneration,GenerationTiming matchTiming){\r\n    return valueGeneration != null && valueGeneration.getValueGenerator() == null && timingsMatch(valueGeneration.getGenerationTiming(), matchTiming);\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.exists",
	"Comment": "creates a criterion which checks for the existence of rows in the subquery result",
	"Method": "Criterion exists(DetachedCriteria dc){\r\n    return new ExistsSubqueryExpression(\"exists\", dc);\r\n}"
}, {
	"Path": "ml.dmlc.xgboost4j.java.XGBoostModelInfo.size",
	"Comment": "momenta are not counted here, but they are needed for model building",
	"Method": "long size(){\r\n    long res = 0;\r\n    if (_boosterBytes != null)\r\n        res += _boosterBytes.length;\r\n    return res;\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.NonNullableTransientDependencies.resolveNonNullableTransientEntity",
	"Comment": "clean up any tracked references for the given entity, throwing an exception if there were any paths.",
	"Method": "void resolveNonNullableTransientEntity(Object entity){\r\n    if (propertyPathsByTransientEntity != null && propertyPathsByTransientEntity.remove(entity) == null) {\r\n        throw new IllegalStateException(\"Attempt to resolve a non-nullable, transient entity that is not a dependency.\");\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.SessionFactoryImplementor.getSQLExceptionHelper",
	"Comment": "retrieves the sqlexceptionhelper in effect for this sessionfactory.",
	"Method": "SqlExceptionHelper getSQLExceptionHelper(){\r\n    return getServiceRegistry().getService(JdbcServices.class).getSqlExceptionHelper();\r\n}"
}, {
	"Path": "org.hibernate.persister.entity.AbstractEntityPersister.initSubclassPropertyAliasesMap",
	"Comment": "must be called by subclasses, at the end of their constructors",
	"Method": "void initSubclassPropertyAliasesMap(PersistentClass model){\r\n    internalInitSubclassPropertyAliasesMap(null, model.getSubclassPropertyClosureIterator());\r\n    if (!entityMetamodel.hasNonIdentifierPropertyNamedId()) {\r\n        subclassPropertyAliases.put(ENTITY_ID, getIdentifierAliases());\r\n        subclassPropertyColumnNames.put(ENTITY_ID, getIdentifierColumnNames());\r\n    }\r\n    if (hasIdentifierProperty()) {\r\n        subclassPropertyAliases.put(getIdentifierPropertyName(), getIdentifierAliases());\r\n        subclassPropertyColumnNames.put(getIdentifierPropertyName(), getIdentifierColumnNames());\r\n    }\r\n    if (getIdentifierType().isComponentType()) {\r\n        CompositeType componentId = (CompositeType) getIdentifierType();\r\n        String[] idPropertyNames = componentId.getPropertyNames();\r\n        String[] idAliases = getIdentifierAliases();\r\n        String[] idColumnNames = getIdentifierColumnNames();\r\n        for (int i = 0; i < idPropertyNames.length; i++) {\r\n            if (entityMetamodel.hasNonIdentifierPropertyNamedId()) {\r\n                subclassPropertyAliases.put(ENTITY_ID + \".\" + idPropertyNames[i], new String[] { idAliases[i] });\r\n                subclassPropertyColumnNames.put(ENTITY_ID + \".\" + getIdentifierPropertyName() + \".\" + idPropertyNames[i], new String[] { idColumnNames[i] });\r\n            }\r\n            if (hasIdentifierProperty()) {\r\n                subclassPropertyAliases.put(getIdentifierPropertyName() + \".\" + idPropertyNames[i], new String[] { idAliases[i] });\r\n                subclassPropertyColumnNames.put(getIdentifierPropertyName() + \".\" + idPropertyNames[i], new String[] { idColumnNames[i] });\r\n            } else {\r\n                subclassPropertyAliases.put(idPropertyNames[i], new String[] { idAliases[i] });\r\n                subclassPropertyColumnNames.put(idPropertyNames[i], new String[] { idColumnNames[i] });\r\n            }\r\n        }\r\n    }\r\n    if (entityMetamodel.isPolymorphic()) {\r\n        subclassPropertyAliases.put(ENTITY_CLASS, new String[] { getDiscriminatorAlias() });\r\n        subclassPropertyColumnNames.put(ENTITY_CLASS, new String[] { getDiscriminatorColumnName() });\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.type.spi.TypeConfiguration.getServiceRegistry",
	"Comment": "obtain the serviceregistry scoped to the typeconfiguration.",
	"Method": "ServiceRegistry getServiceRegistry(ServiceRegistry getServiceRegistry){\r\n    return scope.getServiceRegistry();\r\n}"
}, {
	"Path": "org.hibernate.criterion.DetachedCriteria.createAlias",
	"Comment": "creates an association path alias within this detachedcriteria specifying the type of join.the alias\tcan then be used in further alias creations or restrictions, etc.",
	"Method": "DetachedCriteria createAlias(String associationPath,String alias,DetachedCriteria createAlias,String associationPath,String alias,JoinType joinType,DetachedCriteria createAlias,String associationPath,String alias,JoinType joinType,Criterion withClause,DetachedCriteria createAlias,String associationPath,String alias,int joinType,DetachedCriteria createAlias,String associationPath,String alias,int joinType,Criterion withClause){\r\n    return createAlias(associationPath, alias, JoinType.parse(joinType), withClause);\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.getEntityEagerPropertyFetches",
	"Comment": "an array indicating whether the entities have eager property fetching\tenabled.",
	"Method": "boolean[] getEntityEagerPropertyFetches(){\r\n    return null;\r\n}"
}, {
	"Path": "org.hibernate.pretty.MessageHelper.infoString",
	"Comment": "generate an info message string relating to a given property value\tfor an entity.",
	"Method": "String infoString(String entityName,Serializable id,String infoString,EntityPersister persister,Object id,SessionFactoryImplementor factory,String infoString,EntityPersister persister,Object id,Type identifierType,SessionFactoryImplementor factory,String infoString,EntityPersister persister,Serializable[] ids,SessionFactoryImplementor factory,String infoString,EntityPersister persister,String infoString,String entityName,String propertyName,Object key){\r\n    StringBuilder s = new StringBuilder().append('[').append(entityName).append('.').append(propertyName).append('#');\r\n    if (key == null) {\r\n        s.append(\"<null>\");\r\n    } else {\r\n        s.append(key);\r\n    }\r\n    s.append(']');\r\n    return s.toString();\r\n}"
}, {
	"Path": "water.TypeMap.onIce",
	"Comment": "during first icing, get a globally unique class id for a classname",
	"Method": "int onIce(Iced ice,int onIce,Freezable ice,int onIce,String className){\r\n    Integer I = MAP.get(className);\r\n    if (I != null)\r\n        return I;\r\n    assert H2O.CLOUD.size() > 0 : \"No cloud when getting type id for \" + className;\r\n    Paxos.lockCloud(className);\r\n    int id = H2O.CLOUD.leader() == H2O.SELF ? -1 : FetchId.fetchId(className);\r\n    return install(className, id);\r\n}"
}, {
	"Path": "org.hibernate.cache.spi.FilterKey.createFilterKeys",
	"Comment": "constructs a number of filterkey instances, given the currently enabled filters",
	"Method": "Set<FilterKey> createFilterKeys(Map<String, Filter> enabledFilters){\r\n    if (enabledFilters.size() == 0) {\r\n        return null;\r\n    }\r\n    final Set<FilterKey> result = new HashSet<FilterKey>();\r\n    for (Filter filter : enabledFilters.values()) {\r\n        final FilterKey key = new FilterKey(filter.getName(), ((FilterImpl) filter).getParameters(), filter.getFilterDefinition().getParameterTypes());\r\n        result.add(key);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.internal.util.collections.CollectionHelper.determineProperSizing",
	"Comment": "determine the proper initial size for a new collection in order for it to hold the given a number of elements.\tspecifically we want to account for load size and load factor to prevent immediate resizing.",
	"Method": "int determineProperSizing(Map original,int determineProperSizing,Set original,int determineProperSizing,int numberOfElements){\r\n    int actual = ((int) (numberOfElements / LOAD_FACTOR)) + 1;\r\n    return Math.max(actual, MINIMUM_INITIAL_CAPACITY);\r\n}"
}, {
	"Path": "org.hibernate.engine.transaction.internal.jta.JtaStatusHelper.isRollback",
	"Comment": "does the given status code indicate a rolled back transaction?",
	"Method": "boolean isRollback(int status,boolean isRollback,UserTransaction userTransaction,boolean isRollback,TransactionManager transactionManager){\r\n    return isRollback(getStatus(transactionManager));\r\n}"
}, {
	"Path": "hex.tree.xgboost.XGBoostUtils.getDataRows",
	"Comment": "fixme this and the other method should subtract rows where response is 0",
	"Method": "int getDataRows(Chunk[] chunks,Frame f,int[] chunksIds,int cols){\r\n    double totalRows = 0;\r\n    if (null != chunks) {\r\n        for (Chunk ch : chunks) {\r\n            totalRows += ch.len();\r\n        }\r\n    } else {\r\n        for (int chunkId : chunksIds) {\r\n            totalRows += f.anyVec().chunkLen(chunkId);\r\n        }\r\n    }\r\n    return (int) Math.ceil(totalRows * cols / ARRAY_MAX);\r\n}"
}, {
	"Path": "water.fvec.TestFrameBuilder.withVecTypes",
	"Comment": "sets the vector types. vector types are initialized to empty array if this method is not called.",
	"Method": "TestFrameBuilder withVecTypes(byte vecTypes){\r\n    this.vecTypes = vecTypes;\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.cfg.Configuration.configure",
	"Comment": "use the mappings and properties specified in an application resource named hibernate.cfg.xml.",
	"Method": "Configuration configure(Configuration configure,String resource,Configuration configure,URL url,Configuration configure,File configFile,Configuration configure,org.w3c.dom.Document document){\r\n    return this;\r\n}"
}, {
	"Path": "water.util.FrameUtils.generateNumKeys",
	"Comment": "generate given numbers of keys by suffixing key by given numbered suffix.",
	"Method": "Key[] generateNumKeys(Key mk,int num,Key[] generateNumKeys,Key mk,int num,String delim){\r\n    Key[] ks = new Key[num];\r\n    String n = mk != null ? mk.toString() : \"noname\";\r\n    String suffix = \"\";\r\n    if (n.endsWith(\".hex\")) {\r\n        n = n.substring(0, n.length() - 4);\r\n        suffix = \".hex\";\r\n    }\r\n    for (int i = 0; i < num; i++) ks[i] = Key.make(n + delim + i + suffix);\r\n    return ks;\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.CascadingActions.getAllElementsIterator",
	"Comment": "given a collection, get an iterator of all its children, loading them\tfrom the database if necessary.",
	"Method": "Iterator getAllElementsIterator(EventSource session,CollectionType collectionType,Object collection){\r\n    return collectionType.getElementsIterator(collection, session);\r\n}"
}, {
	"Path": "org.hibernate.cfg.beanvalidation.TypeSafeActivator.validateSuppliedFactory",
	"Comment": "used to validate a supplied validatorfactory instance as being castable to validatorfactory.",
	"Method": "void validateSuppliedFactory(Object object){\r\n    if (!ValidatorFactory.class.isInstance(object)) {\r\n        throw new IntegrationException(\"Given object was not an instance of \" + ValidatorFactory.class.getName() + \"[\" + object.getClass().getName() + \"]\");\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getForUpdateNowaitString",
	"Comment": "retrieves the for update nowait syntax specific to this dialect.",
	"Method": "String getForUpdateNowaitString(String getForUpdateNowaitString,String aliases){\r\n    return getForUpdateString(aliases);\r\n}"
}, {
	"Path": "water.rapids.ast.prims.string.algorithms.H2OJaroWinklerComparator.similarity",
	"Comment": "returns normalized score, with 0.0 meaning no similarity at all,and 1.0 meaning full equality.",
	"Method": "double similarity(String s1,String s2){\r\n    if (s1.equals(s2))\r\n        return 1.0;\r\n    if (s1.length() > s2.length()) {\r\n        String tmp = s2;\r\n        s2 = s1;\r\n        s1 = tmp;\r\n    }\r\n    List<Boolean> isCommonCharInS2 = new ArrayList<Boolean>();\r\n    for (int i = 0; i < s2.length(); i++) {\r\n        isCommonCharInS2.add(false);\r\n    }\r\n    int maxdist = (int) Math.floor(s2.length() / 2);\r\n    int c = 0;\r\n    int t = 0;\r\n    int prevpos = -1;\r\n    for (int ix = 0; ix < s1.length(); ix++) {\r\n        char ch = s1.charAt(ix);\r\n        for (int ix2 = Math.max(0, ix - maxdist); ix2 < Math.min(s2.length(), ix + maxdist); ix2++) {\r\n            if (ch == s2.charAt(ix2) && !isCommonCharInS2.get(ix2)) {\r\n                c++;\r\n                isCommonCharInS2.set(ix2, true);\r\n                if (prevpos != -1 && ix2 < prevpos)\r\n                    t++;\r\n                prevpos = ix2;\r\n                break;\r\n            }\r\n        }\r\n    }\r\n    if (c == 0)\r\n        return 0.0;\r\n    double score = ((c / (double) s1.length()) + (c / (double) s2.length()) + ((c - t) / (double) c)) / 3.0;\r\n    int p = 0;\r\n    int last = Math.min(4, s1.length());\r\n    for (; p < last && s1.charAt(p) == s2.charAt(p); p++) ;\r\n    score = score + ((p * (1 - score)) / 10);\r\n    return score;\r\n}"
}, {
	"Path": "org.hibernate.jpa.internal.util.XmlHelper.getUniqueChild",
	"Comment": "gets the child of the specified element having the specified unique\tname.if there are more than one children elements with the same name\tand exception is thrown.",
	"Method": "Element getUniqueChild(Element element,String tagName){\r\n    final Iterator goodChildren = getChildrenByTagName(element, tagName);\r\n    if (goodChildren != null && goodChildren.hasNext()) {\r\n        final Element child = (Element) goodChildren.next();\r\n        if (goodChildren.hasNext()) {\r\n            throw new Exception(\"expected only one \" + tagName + \" tag\");\r\n        }\r\n        return child;\r\n    } else {\r\n        throw new Exception(\"expected one \" + tagName + \" tag\");\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.metamodel.internal.AttributeFactory.determineAttributeMetadata",
	"Comment": "here is most of the nuts and bolts of this factory, where we interpret the known jpa metadata\tagainst the known hibernate metadata and build a descriptor for the attribute.",
	"Method": "AttributeMetadata<X, Y> determineAttributeMetadata(AttributeContext<X> attributeContext,MemberResolver memberResolver){\r\n    LOG.trace(\"Starting attribute metadata determination [\" + attributeContext.getPropertyMapping().getName() + \"]\");\r\n    final Member member = memberResolver.resolveMember(attributeContext);\r\n    LOG.trace(\"    Determined member [\" + member + \"]\");\r\n    final Value value = attributeContext.getPropertyMapping().getValue();\r\n    final org.hibernate.type.Type type = value.getType();\r\n    LOG.trace(\"    Determined type [name=\" + type.getName() + \", class=\" + type.getClass().getName() + \"]\");\r\n    if (type.isAnyType()) {\r\n        if (context.isIgnoreUnsupported()) {\r\n            return null;\r\n        } else {\r\n            throw new UnsupportedOperationException(\"ANY not supported\");\r\n        }\r\n    } else if (type.isAssociationType()) {\r\n        if (type.isEntityType()) {\r\n            return new SingularAttributeMetadataImpl<X, Y>(attributeContext.getPropertyMapping(), attributeContext.getOwnerType(), member, determineSingularAssociationAttributeType(member));\r\n        }\r\n        if (value instanceof Collection) {\r\n            final Collection collValue = (Collection) value;\r\n            final Value elementValue = collValue.getElement();\r\n            final org.hibernate.type.Type elementType = elementValue.getType();\r\n            final Attribute.PersistentAttributeType elementPersistentAttributeType;\r\n            final Attribute.PersistentAttributeType persistentAttributeType;\r\n            if (elementType.isAnyType()) {\r\n                if (context.isIgnoreUnsupported()) {\r\n                    return null;\r\n                } else {\r\n                    throw new UnsupportedOperationException(\"collection of any not supported yet\");\r\n                }\r\n            }\r\n            final boolean isManyToMany = isManyToMany(member);\r\n            if (elementValue instanceof Component) {\r\n                elementPersistentAttributeType = Attribute.PersistentAttributeType.EMBEDDED;\r\n                persistentAttributeType = Attribute.PersistentAttributeType.ELEMENT_COLLECTION;\r\n            } else if (elementType.isAssociationType()) {\r\n                elementPersistentAttributeType = isManyToMany ? Attribute.PersistentAttributeType.MANY_TO_MANY : Attribute.PersistentAttributeType.ONE_TO_MANY;\r\n                persistentAttributeType = elementPersistentAttributeType;\r\n            } else {\r\n                elementPersistentAttributeType = Attribute.PersistentAttributeType.BASIC;\r\n                persistentAttributeType = Attribute.PersistentAttributeType.ELEMENT_COLLECTION;\r\n            }\r\n            final Attribute.PersistentAttributeType keyPersistentAttributeType;\r\n            if (value instanceof Map) {\r\n                final Value keyValue = ((Map) value).getIndex();\r\n                final org.hibernate.type.Type keyType = keyValue.getType();\r\n                if (keyType.isAnyType()) {\r\n                    if (context.isIgnoreUnsupported()) {\r\n                        return null;\r\n                    } else {\r\n                        throw new UnsupportedOperationException(\"collection of any not supported yet\");\r\n                    }\r\n                }\r\n                if (keyValue instanceof Component) {\r\n                    keyPersistentAttributeType = Attribute.PersistentAttributeType.EMBEDDED;\r\n                } else if (keyType.isAssociationType()) {\r\n                    keyPersistentAttributeType = Attribute.PersistentAttributeType.MANY_TO_ONE;\r\n                } else {\r\n                    keyPersistentAttributeType = Attribute.PersistentAttributeType.BASIC;\r\n                }\r\n            } else {\r\n                keyPersistentAttributeType = null;\r\n            }\r\n            return new PluralAttributeMetadataImpl(attributeContext.getPropertyMapping(), attributeContext.getOwnerType(), member, persistentAttributeType, elementPersistentAttributeType, keyPersistentAttributeType);\r\n        } else if (value instanceof OneToMany) {\r\n            throw new IllegalArgumentException(\"HUH???\");\r\n        }\r\n    } else if (attributeContext.getPropertyMapping().isComposite()) {\r\n        return new SingularAttributeMetadataImpl<X, Y>(attributeContext.getPropertyMapping(), attributeContext.getOwnerType(), member, Attribute.PersistentAttributeType.EMBEDDED);\r\n    } else {\r\n        return new SingularAttributeMetadataImpl<X, Y>(attributeContext.getPropertyMapping(), attributeContext.getOwnerType(), member, Attribute.PersistentAttributeType.BASIC);\r\n    }\r\n    throw new UnsupportedOperationException(\"oops, we are missing something: \" + attributeContext.getPropertyMapping());\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.executeQueryStatement",
	"Comment": "process query string by applying filters, limit clause, locks and comments if necessary.\tfinally execute sql statement and advance to the first row.",
	"Method": "SqlStatementWrapper executeQueryStatement(QueryParameters queryParameters,boolean scroll,List<AfterLoadAction> afterLoadActions,SharedSessionContractImplementor session,SqlStatementWrapper executeQueryStatement,String sqlStatement,QueryParameters queryParameters,boolean scroll,List<AfterLoadAction> afterLoadActions,SharedSessionContractImplementor session){\r\n    queryParameters.processFilters(sqlStatement, session);\r\n    final LimitHandler limitHandler = getLimitHandler(queryParameters.getRowSelection());\r\n    String sql = limitHandler.processSql(queryParameters.getFilteredSQL(), queryParameters.getRowSelection());\r\n    sql = preprocessSQL(sql, queryParameters, getFactory(), afterLoadActions);\r\n    final PreparedStatement st = prepareQueryStatement(sql, queryParameters, limitHandler, scroll, session);\r\n    final ResultSet rs;\r\n    if (queryParameters.isCallable() && isTypeOf(st, CallableStatement.class)) {\r\n        final CallableStatement cs = st.unwrap(CallableStatement.class);\r\n        rs = getResultSet(cs, queryParameters.getRowSelection(), limitHandler, queryParameters.hasAutoDiscoverScalarTypes(), session);\r\n    } else {\r\n        rs = getResultSet(st, queryParameters.getRowSelection(), limitHandler, queryParameters.hasAutoDiscoverScalarTypes(), session);\r\n    }\r\n    return new SqlStatementWrapper(st, rs);\r\n}"
}, {
	"Path": "org.hibernate.query.internal.ParameterMetadataImpl.getOrdinalParameterDescriptor",
	"Comment": "get the descriptor for an ordinal parameter given its position",
	"Method": "OrdinalParameterDescriptor getOrdinalParameterDescriptor(int position){\r\n    final OrdinalParameterDescriptor descriptor = ordinalDescriptorMap.get(position);\r\n    if (descriptor == null) {\r\n        throw new IllegalArgumentException(String.format(Locale.ROOT, \"Could not locate ordinal parameter [%s], expecting one of [%s]\", position, StringHelper.join(\", \", ordinalDescriptorMap.keySet().iterator())));\r\n    }\r\n    return descriptor;\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.processDistinctKeyword",
	"Comment": "remove distinct keyword from sql statement if the query should not pass it through.",
	"Method": "String processDistinctKeyword(String sql,QueryParameters parameters){\r\n    if (!parameters.isPassDistinctThrough()) {\r\n        if (sql.startsWith(SELECT_DISTINCT)) {\r\n            return SELECT + sql.substring(SELECT_DISTINCT.length());\r\n        }\r\n    }\r\n    return sql;\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.QueryPlanCache.cleanup",
	"Comment": "clean up the caches when the sessionfactory is closed.\tnote that depending on the cache strategy implementation chosen, clearing the cache might not reclaim all the\tmemory.\ttypically, when using lirs, clearing the cache only invalidates the entries but the outdated entries are kept in\tmemory until they are replaced by others. it is not considered a memory leak as the cache is bounded.",
	"Method": "void cleanup(){\r\n    LOG.trace(\"Cleaning QueryPlan Cache\");\r\n    queryPlanCache.clear();\r\n    parameterMetadataCache.clear();\r\n}"
}, {
	"Path": "org.hibernate.internal.SessionFactoryImpl.serialize",
	"Comment": "custom serialization hook used during session serialization.",
	"Method": "void serialize(ObjectOutputStream oos){\r\n    oos.writeUTF(getUuid());\r\n    oos.writeBoolean(name != null);\r\n    if (name != null) {\r\n        oos.writeUTF(name);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.jpa.test.lock.QueryLockingTest.testEntityLockModeStateAfterQueryLocking",
	"Comment": "lock some entities via a query and check the resulting lock mode type via entitymanager",
	"Method": "void testEntityLockModeStateAfterQueryLocking(){\r\n    EntityManager em = getOrCreateEntityManager();\r\n    em.getTransaction().begin();\r\n    em.persist(new LocalEntity(1, \"test\"));\r\n    em.getTransaction().commit();\r\n    em.getTransaction().begin();\r\n    Query query = em.createQuery(\"select l from LocalEntity l\");\r\n    assertEquals(LockModeType.NONE, query.getLockMode());\r\n    query.setLockMode(LockModeType.PESSIMISTIC_READ);\r\n    assertEquals(LockModeType.PESSIMISTIC_READ, query.getLockMode());\r\n    List<LocalEntity> results = query.getResultList();\r\n    for (LocalEntity e : results) {\r\n        assertEquals(LockModeType.PESSIMISTIC_READ, em.getLockMode(e));\r\n    }\r\n    em.getTransaction().commit();\r\n    em.close();\r\n    em = getOrCreateEntityManager();\r\n    em.getTransaction().begin();\r\n    em.createQuery(\"delete from LocalEntity\").executeUpdate();\r\n    em.getTransaction().commit();\r\n    em.close();\r\n}"
}, {
	"Path": "org.hibernate.tool.schema.internal.AbstractSchemaMigrator.checkForExistingForeignKey",
	"Comment": "check if the foreignkey already exists. first check based on definition and if that is not matched check if a key\twith the exact same name exists. keys with the same name are presumed to be functional equal.",
	"Method": "boolean checkForExistingForeignKey(ForeignKey foreignKey,TableInformation tableInformation){\r\n    if (foreignKey.getName() == null || tableInformation == null) {\r\n        return false;\r\n    }\r\n    final String referencingColumn = foreignKey.getColumn(0).getName();\r\n    final String referencedTable = foreignKey.getReferencedTable().getName();\r\n    Predicate<ColumnReferenceMapping> mappingPredicate = m -> {\r\n        String existingReferencingColumn = m.getReferencingColumnMetadata().getColumnIdentifier().getText();\r\n        String existingReferencedTable = m.getReferencedColumnMetadata().getContainingTableInformation().getName().getTableName().getCanonicalName();\r\n        return referencingColumn.equals(existingReferencingColumn) && referencedTable.equals(existingReferencedTable);\r\n    };\r\n    Stream<ForeignKeyInformation> keyStream = StreamSupport.stream(tableInformation.getForeignKeys().spliterator(), false);\r\n    Stream<ColumnReferenceMapping> mappingStream = keyStream.flatMap(k -> StreamSupport.stream(k.getColumnReferenceMappings().spliterator(), false));\r\n    boolean found = mappingStream.anyMatch(mappingPredicate);\r\n    if (found) {\r\n        return true;\r\n    }\r\n    return tableInformation.getForeignKey(Identifier.toIdentifier(foreignKey.getName())) != null;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.bindLimitParametersInReverseOrder",
	"Comment": "ansi sql defines the limit clause to be in the form limit offset, limit.\tdoes this dialect require us to bind the parameters in reverse order?",
	"Method": "boolean bindLimitParametersInReverseOrder(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.cfg.Ejb3Column.getTable",
	"Comment": "find appropriate table of the column.\tit can come from a secondary table or from the main table of the persistent class",
	"Method": "Table getTable(){\r\n    if (table != null) {\r\n        return table;\r\n    }\r\n    if (isSecondary()) {\r\n        return getJoin().getTable();\r\n    } else {\r\n        return propertyHolder.getTable();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.pagination.AbstractLimitHandler.bindLimitParametersFirst",
	"Comment": "does the limit clause come at the start of the\tselect statement, rather than at the end?",
	"Method": "boolean bindLimitParametersFirst(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.boot.archive.internal.ArchiveHelper.getJarURLFromURLEntry",
	"Comment": "get the jar url of the jar containing the given entry\tmethod used in a non managed environment",
	"Method": "URL getJarURLFromURLEntry(URL url,String entry){\r\n    URL jarUrl;\r\n    String file = url.getFile();\r\n    if (!entry.startsWith(\"/\")) {\r\n        entry = \"/\" + entry;\r\n    }\r\n    file = file.substring(0, file.length() - entry.length());\r\n    if (file.endsWith(\"!\")) {\r\n        file = file.substring(0, file.length() - 1);\r\n    }\r\n    try {\r\n        final String protocol = url.getProtocol();\r\n        if (\"jar\".equals(protocol) || \"wsjar\".equals(protocol)) {\r\n            jarUrl = new URL(file);\r\n            if (\"file\".equals(jarUrl.getProtocol())) {\r\n                if (file.indexOf(' ') != -1) {\r\n                    jarUrl = new File(jarUrl.getFile()).toURI().toURL();\r\n                }\r\n            }\r\n        } else if (\"zip\".equals(protocol) || \"code-source\".equals(url.getProtocol()) || \"file\".equals(protocol)) {\r\n            if (file.indexOf(' ') != -1) {\r\n                jarUrl = new File(file).toURI().toURL();\r\n            } else {\r\n                jarUrl = new File(file).toURL();\r\n            }\r\n        } else {\r\n            try {\r\n                jarUrl = new URL(protocol, url.getHost(), url.getPort(), file);\r\n            } catch (final MalformedURLException e) {\r\n                jarUrl = url;\r\n            }\r\n        }\r\n    } catch (MalformedURLException e) {\r\n        throw new IllegalArgumentException(\"Unable to determine JAR Url from \" + url + \". Cause: \" + e.getMessage());\r\n    }\r\n    log.trace(\"JAR URL from URL Entry: \" + url + \" >> \" + jarUrl);\r\n    return jarUrl;\r\n}"
}, {
	"Path": "water.Value.className",
	"Comment": "class name of the embedded pojo, without needing an actual pojo.",
	"Method": "String className(){\r\n    return TypeMap.className(_type);\r\n}"
}, {
	"Path": "water.util.Log.getLogFileNameSuffix",
	"Comment": "get suffix of the log file name specific to particular log level",
	"Method": "String getLogFileNameSuffix(String level){\r\n    switch(level) {\r\n        case \"trace\":\r\n            return \"-1-trace.log\";\r\n        case \"debug\":\r\n            return \"-2-debug.log\";\r\n        case \"info\":\r\n            return \"-3-info.log\";\r\n        case \"warn\":\r\n            return \"-4-warn.log\";\r\n        case \"error\":\r\n            return \"-5-error.log\";\r\n        case \"fatal\":\r\n            return \"-6-fatal.log\";\r\n        case \"httpd\":\r\n            return \"-httpd.log\";\r\n        default:\r\n            throw new RuntimeException(\"Unknown level \" + level);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.internal.util.StringHelper.unquote",
	"Comment": "return the unquoted version of name stripping the start and end quote characters.",
	"Method": "String unquote(String name,String unquote,String name,Dialect dialect,String[] unquote,String[] names,Dialect dialect){\r\n    if (names == null) {\r\n        return null;\r\n    }\r\n    String[] unquoted = new String[names.length];\r\n    for (int i = 0; i < names.length; i++) {\r\n        unquoted[i] = unquote(names[i], dialect);\r\n    }\r\n    return unquoted;\r\n}"
}, {
	"Path": "org.hibernate.boot.registry.StandardServiceRegistryBuilder.configure",
	"Comment": "read setting information from an xml file using the named resource location.",
	"Method": "StandardServiceRegistryBuilder configure(StandardServiceRegistryBuilder configure,String resourceName,StandardServiceRegistryBuilder configure,File configurationFile,StandardServiceRegistryBuilder configure,URL url,StandardServiceRegistryBuilder configure,LoadedConfig loadedConfig){\r\n    aggregatedCfgXml.merge(loadedConfig);\r\n    settings.putAll(loadedConfig.getConfigurationValues());\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.cfg.Environment.getProperties",
	"Comment": "return system properties, extended by any properties specified\tin hibernate.properties.",
	"Method": "Properties getProperties(){\r\n    Properties copy = new Properties();\r\n    copy.putAll(GLOBAL_PROPERTIES);\r\n    return copy;\r\n}"
}, {
	"Path": "org.hibernate.proxy.pojo.javassist.SerializableProxy.readResolve",
	"Comment": "deserialization hook.this method is called by jdk deserialization.we use this hook\tto replace the serial form with a live form.",
	"Method": "Object readResolve(){\r\n    HibernateProxy proxy = JavassistProxyFactory.deserializeProxy(this);\r\n    afterDeserialization((JavassistLazyInitializer) proxy.getHibernateLazyInitializer());\r\n    return proxy;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Oracle8iDialect.useFollowOnLocking",
	"Comment": "for oracle, the for update clause cannot be applied when using order by, distinct or views.",
	"Method": "boolean useFollowOnLocking(QueryParameters parameters){\r\n    if (parameters != null) {\r\n        String lowerCaseSQL = parameters.getFilteredSQL().toLowerCase();\r\n        return DISTINCT_KEYWORD_PATTERN.matcher(lowerCaseSQL).find() || GROUP_BY_KEYWORD_PATTERN.matcher(lowerCaseSQL).find() || UNION_KEYWORD_PATTERN.matcher(lowerCaseSQL).find() || (parameters.hasRowSelection() && (ORDER_BY_KEYWORD_PATTERN.matcher(lowerCaseSQL).find() || parameters.getRowSelection().getFirstRow() != null));\r\n    } else {\r\n        return true;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.JoinWalker.selectString",
	"Comment": "generate a select list of columns containing all properties of the entity classes",
	"Method": "String selectString(List associations){\r\n    if (associations.size() == 0) {\r\n        return \"\";\r\n    } else {\r\n        StringBuilder buf = new StringBuilder(associations.size() * 100);\r\n        int entityAliasCount = 0;\r\n        int collectionAliasCount = 0;\r\n        for (int i = 0; i < associations.size(); i++) {\r\n            OuterJoinableAssociation join = (OuterJoinableAssociation) associations.get(i);\r\n            OuterJoinableAssociation next = (i == associations.size() - 1) ? null : (OuterJoinableAssociation) associations.get(i + 1);\r\n            final Joinable joinable = join.getJoinable();\r\n            final String entitySuffix = (suffixes == null || entityAliasCount >= suffixes.length) ? null : suffixes[entityAliasCount];\r\n            final String collectionSuffix = (collectionSuffixes == null || collectionAliasCount >= collectionSuffixes.length) ? null : collectionSuffixes[collectionAliasCount];\r\n            final String selectFragment = joinable.selectFragment(next == null ? null : next.getJoinable(), next == null ? null : next.getRHSAlias(), join.getRHSAlias(), entitySuffix, collectionSuffix, join.getJoinType() == JoinType.LEFT_OUTER_JOIN);\r\n            if (selectFragment.trim().length() > 0) {\r\n                buf.append(\", \").append(selectFragment);\r\n            }\r\n            if (joinable.consumesEntityAlias()) {\r\n                entityAliasCount++;\r\n            }\r\n            if (joinable.consumesCollectionAlias() && join.getJoinType() == JoinType.LEFT_OUTER_JOIN && !join.hasRestriction()) {\r\n                collectionAliasCount++;\r\n            }\r\n        }\r\n        return buf.toString();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.supportsExistsInSelect",
	"Comment": "does the dialect support an exists statement in the select clause?",
	"Method": "boolean supportsExistsInSelect(){\r\n    return true;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.InsertStatement.validate",
	"Comment": "performs detailed semantic validation on this insert statement tree.",
	"Method": "void validate(){\r\n    getIntoClause().validateTypes(getSelectClause());\r\n}"
}, {
	"Path": "org.hibernate.internal.util.collections.ConcurrentReferenceHashMap.put",
	"Comment": "maps the specified key to the specified value in this table.\tneither the key nor the value can be null.\t the value can be retrieved by calling the get method\twith a key that is equal to the original key.",
	"Method": "V put(K key,int hash,V value,boolean onlyIfAbsent,V put,K key,V value){\r\n    if (key == null || value == null) {\r\n        return null;\r\n    }\r\n    int hash = hashOf(key);\r\n    return segmentFor(hash).put(key, hash, value, false);\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.FromClause.getProjectionList",
	"Comment": "returns the list of from elements that will be part of the result set.",
	"Method": "List getProjectionList(){\r\n    return ASTUtil.collectChildren(this, projectionListPredicate);\r\n}"
}, {
	"Path": "water.rapids.ast.prims.mungers.AstFillNATest.testBackwardMethodRowAll",
	"Comment": "purpose here is to carry out short tests to make sure the code works and the single thread code works.",
	"Method": "void testBackwardMethodRowAll(){\r\n    Scope.enter();\r\n    try {\r\n        Session sess = new Session();\r\n        Frame frAllNA = Scope.track(new TestFrameBuilder().withName(\"$fr\", sess).withVecTypes(Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM).withDataForCol(0, ard(Double.NaN)).withDataForCol(1, ard(Double.NaN)).withDataForCol(2, ard(Double.NaN)).withDataForCol(3, ard(Double.NaN)).withDataForCol(4, ard(Double.NaN)).withDataForCol(5, ard(Double.NaN)).withDataForCol(6, ard(Double.NaN)).build());\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 0\r\n        sess, // h2o.fillna with maxlen 0\r\n        frAllNA, // h2o.fillna with maxlen 0\r\n        frAllNA, // h2o.fillna with maxlen 0\r\n        0, \"(h2o.fillna $fr 'backward' 1 0)\", true);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 100\r\n        sess, // h2o.fillna with maxlen 100\r\n        frAllNA, // h2o.fillna with maxlen 100\r\n        frAllNA, // h2o.fillna with maxlen 100\r\n        100, \"(h2o.fillna $fr 'backward' 1 100)\", true);\r\n        Frame fr1NA = Scope.track(new TestFrameBuilder().withName(\"$fr2\", sess).withVecTypes(Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM).withDataForCol(0, ard(Double.NaN)).withDataForCol(1, ard(Double.NaN)).withDataForCol(2, ard(Double.NaN)).withDataForCol(3, ard(Double.NaN)).withDataForCol(4, ard(Double.NaN)).withDataForCol(5, ard(Double.NaN)).withDataForCol(6, ard(1.234)).build());\r\n        Frame fr1NA1na = Scope.track(new TestFrameBuilder().withName(\"$fr1NA1na\", sess).withVecTypes(Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM).withDataForCol(0, ard(Double.NaN)).withDataForCol(1, ard(Double.NaN)).withDataForCol(2, ard(Double.NaN)).withDataForCol(3, ard(Double.NaN)).withDataForCol(4, ard(Double.NaN)).withDataForCol(5, ard(1.234)).withDataForCol(6, ard(1.234)).build());\r\n        Frame fr1NA3na = Scope.track(new TestFrameBuilder().withName(\"$fr1NA3na\", sess).withVecTypes(Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM).withDataForCol(0, ard(Double.NaN)).withDataForCol(1, ard(Double.NaN)).withDataForCol(2, ard(Double.NaN)).withDataForCol(3, ard(1.234)).withDataForCol(4, ard(1.234)).withDataForCol(5, ard(1.234)).withDataForCol(6, ard(1.234)).build());\r\n        Frame fr1NA100na = Scope.track(new TestFrameBuilder().withName(\"$fr1NA100na\", sess).withVecTypes(Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM).withDataForCol(0, ard(1.234)).withDataForCol(1, ard(1.234)).withDataForCol(2, ard(1.234)).withDataForCol(3, ard(1.234)).withDataForCol(4, ard(1.234)).withDataForCol(5, ard(1.234)).withDataForCol(6, ard(1.234)).build());\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 0\r\n        sess, // h2o.fillna with maxlen 0\r\n        fr1NA, // h2o.fillna with maxlen 0\r\n        fr1NA, // h2o.fillna with maxlen 0\r\n        0, \"(h2o.fillna $fr2 'backward' 1 0)\", true);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 1\r\n        sess, // h2o.fillna with maxlen 1\r\n        fr1NA, // h2o.fillna with maxlen 1\r\n        fr1NA1na, // h2o.fillna with maxlen 1\r\n        1, \"(h2o.fillna $fr2 'backward' 1 1)\", true);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 3\r\n        sess, // h2o.fillna with maxlen 3\r\n        fr1NA, // h2o.fillna with maxlen 3\r\n        fr1NA3na, // h2o.fillna with maxlen 3\r\n        3, \"(h2o.fillna $fr2 'backward' 1 3)\", true);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 100\r\n        sess, // h2o.fillna with maxlen 100\r\n        fr1NA, // h2o.fillna with maxlen 100\r\n        fr1NA100na, // h2o.fillna with maxlen 100\r\n        100, \"(h2o.fillna $fr2 'backward' 1 100)\", true);\r\n        Frame frMultipleNA = Scope.track(new TestFrameBuilder().withName(\"$frMultipleNA\", sess).withVecTypes(Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM).withDataForCol(0, ard(1)).withDataForCol(1, ard(Double.NaN)).withDataForCol(2, ard(2)).withDataForCol(3, ard(Double.NaN)).withDataForCol(4, ard(Double.NaN)).withDataForCol(5, ard(3)).withDataForCol(6, ard(Double.NaN)).withDataForCol(7, ard(Double.NaN)).withDataForCol(8, ard(Double.NaN)).withDataForCol(9, ard(4)).withDataForCol(10, ard(Double.NaN)).withDataForCol(11, ard(Double.NaN)).withDataForCol(12, ard(Double.NaN)).withDataForCol(13, ard(Double.NaN)).withDataForCol(14, ard(5)).withDataForCol(15, ard(Double.NaN)).withDataForCol(16, ard(Double.NaN)).withDataForCol(17, ard(Double.NaN)).withDataForCol(18, ard(Double.NaN)).withDataForCol(19, ard(Double.NaN)).withDataForCol(20, ard(6)).withDataForCol(21, ard(Double.NaN)).withDataForCol(22, ard(Double.NaN)).withDataForCol(23, ard(Double.NaN)).withDataForCol(24, ard(Double.NaN)).withDataForCol(25, ard(Double.NaN)).withDataForCol(26, ard(Double.NaN)).withDataForCol(27, ard(7)).withDataForCol(28, ard(Double.NaN)).build());\r\n        Frame frMultipleNA1Fill = Scope.track(new TestFrameBuilder().withName(\"$frMultipleNA1Fill\", sess).withVecTypes(Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM).withDataForCol(0, ard(1)).withDataForCol(1, ard(2)).withDataForCol(2, ard(2)).withDataForCol(3, ard(Double.NaN)).withDataForCol(4, ard(3)).withDataForCol(5, ard(3)).withDataForCol(6, ard(Double.NaN)).withDataForCol(7, ard(Double.NaN)).withDataForCol(8, ard(4)).withDataForCol(9, ard(4)).withDataForCol(10, ard(Double.NaN)).withDataForCol(11, ard(Double.NaN)).withDataForCol(12, ard(Double.NaN)).withDataForCol(13, ard(5)).withDataForCol(14, ard(5)).withDataForCol(15, ard(Double.NaN)).withDataForCol(16, ard(Double.NaN)).withDataForCol(17, ard(Double.NaN)).withDataForCol(18, ard(Double.NaN)).withDataForCol(19, ard(6)).withDataForCol(20, ard(6)).withDataForCol(21, ard(Double.NaN)).withDataForCol(22, ard(Double.NaN)).withDataForCol(23, ard(Double.NaN)).withDataForCol(24, ard(Double.NaN)).withDataForCol(25, ard(Double.NaN)).withDataForCol(26, ard(7)).withDataForCol(27, ard(7)).withDataForCol(28, ard(Double.NaN)).build());\r\n        Frame frMultipleNA2Fill = Scope.track(new TestFrameBuilder().withName(\"$frMultipleNA2Fill\", sess).withVecTypes(Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM).withDataForCol(0, ard(1)).withDataForCol(1, ard(2)).withDataForCol(2, ard(2)).withDataForCol(3, ard(3)).withDataForCol(4, ard(3)).withDataForCol(5, ard(3)).withDataForCol(6, ard(Double.NaN)).withDataForCol(7, ard(4)).withDataForCol(8, ard(4)).withDataForCol(9, ard(4)).withDataForCol(10, ard(Double.NaN)).withDataForCol(11, ard(Double.NaN)).withDataForCol(12, ard(5)).withDataForCol(13, ard(5)).withDataForCol(14, ard(5)).withDataForCol(15, ard(Double.NaN)).withDataForCol(16, ard(Double.NaN)).withDataForCol(17, ard(Double.NaN)).withDataForCol(18, ard(6)).withDataForCol(19, ard(6)).withDataForCol(20, ard(6)).withDataForCol(21, ard(Double.NaN)).withDataForCol(22, ard(Double.NaN)).withDataForCol(23, ard(Double.NaN)).withDataForCol(24, ard(Double.NaN)).withDataForCol(25, ard(7)).withDataForCol(26, ard(7)).withDataForCol(27, ard(7)).withDataForCol(28, ard(Double.NaN)).build());\r\n        Frame frMultipleNA3Fill = Scope.track(new TestFrameBuilder().withName(\"$frMultipleNA3Fill\", sess).withVecTypes(Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM).withDataForCol(0, ard(1)).withDataForCol(1, ard(2)).withDataForCol(2, ard(2)).withDataForCol(3, ard(3)).withDataForCol(4, ard(3)).withDataForCol(5, ard(3)).withDataForCol(6, ard(4)).withDataForCol(7, ard(4)).withDataForCol(8, ard(4)).withDataForCol(9, ard(4)).withDataForCol(10, ard(5)).withDataForCol(11, ard(5)).withDataForCol(12, ard(5)).withDataForCol(13, ard(5)).withDataForCol(14, ard(5)).withDataForCol(15, ard(6)).withDataForCol(16, ard(6)).withDataForCol(17, ard(6)).withDataForCol(18, ard(6)).withDataForCol(19, ard(6)).withDataForCol(20, ard(6)).withDataForCol(21, ard(7)).withDataForCol(22, ard(7)).withDataForCol(23, ard(7)).withDataForCol(24, ard(7)).withDataForCol(25, ard(7)).withDataForCol(26, ard(7)).withDataForCol(27, ard(7)).withDataForCol(28, ard(Double.NaN)).build());\r\n        Frame frMultipleNA100Fill = Scope.track(new TestFrameBuilder().withName(\"$frMultipleNA100Fill\", sess).withVecTypes(Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM, Vec.T_NUM).withDataForCol(0, ard(1)).withDataForCol(1, ard(2)).withDataForCol(2, ard(2)).withDataForCol(3, ard(3)).withDataForCol(4, ard(3)).withDataForCol(5, ard(3)).withDataForCol(6, ard(4)).withDataForCol(7, ard(4)).withDataForCol(8, ard(4)).withDataForCol(9, ard(5)).withDataForCol(10, ard(5)).withDataForCol(11, ard(5)).withDataForCol(12, ard(5)).withDataForCol(13, ard(5)).withDataForCol(14, ard(6)).withDataForCol(15, ard(6)).withDataForCol(16, ard(6)).withDataForCol(17, ard(6)).withDataForCol(18, ard(6)).withDataForCol(19, ard(6)).withDataForCol(20, ard(7)).withDataForCol(21, ard(7)).withDataForCol(22, ard(7)).withDataForCol(23, ard(7)).withDataForCol(24, ard(7)).withDataForCol(25, ard(7)).withDataForCol(26, ard(7)).withDataForCol(27, ard(Double.NaN)).build());\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 0\r\n        sess, // h2o.fillna with maxlen 0\r\n        frMultipleNA, // h2o.fillna with maxlen 0\r\n        frMultipleNA, // h2o.fillna with maxlen 0\r\n        0, \"(h2o.fillna $frMultipleNA 'backward' 1 0)\", true);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 1\r\n        sess, // h2o.fillna with maxlen 1\r\n        frMultipleNA, // h2o.fillna with maxlen 1\r\n        frMultipleNA1Fill, // h2o.fillna with maxlen 1\r\n        1, \"(h2o.fillna $frMultipleNA 'backward' 1 1)\", true);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 2\r\n        sess, // h2o.fillna with maxlen 2\r\n        frMultipleNA, // h2o.fillna with maxlen 2\r\n        frMultipleNA2Fill, // h2o.fillna with maxlen 2\r\n        2, \"(h2o.fillna $frMultipleNA 'backward' 1 2)\", true);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 3\r\n        sess, // h2o.fillna with maxlen 3\r\n        frMultipleNA, // h2o.fillna with maxlen 3\r\n        frMultipleNA3Fill, // h2o.fillna with maxlen 3\r\n        3, \"(h2o.fillna $frMultipleNA 'backward' 1 3)\", true);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 100\r\n        sess, // h2o.fillna with maxlen 100\r\n        frMultipleNA, // h2o.fillna with maxlen 100\r\n        frMultipleNA100Fill, // h2o.fillna with maxlen 100\r\n        100, \"(h2o.fillna $frMultipleNA 'backward' 1 100)\", true);\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.resolveResultTransformer",
	"Comment": "determine the actual resulttransformer that will be used to\ttransform query results.",
	"Method": "ResultTransformer resolveResultTransformer(ResultTransformer resultTransformer){\r\n    return resultTransformer;\r\n}"
}, {
	"Path": "org.hibernate.metamodel.model.domain.internal.AbstractIdentifiableType.getDeclaredVersion",
	"Comment": "for used to retrieve the declared version when populating the static metamodel.",
	"Method": "SingularPersistentAttribute<J, Y> getDeclaredVersion(Class<Y> javaType,SingularAttribute<J, ?> getDeclaredVersion){\r\n    checkDeclaredVersion();\r\n    return versionAttribute;\r\n}"
}, {
	"Path": "hex.createframe.SimpleCreateFrameRecipeTest.emptyTest",
	"Comment": "test that the frame with all default arguments can be constructed.",
	"Method": "void emptyTest(){\r\n    Scope.enter();\r\n    try {\r\n        CreateFrameSimpleIV4 s = new CreateFrameSimpleIV4().fillFromImpl();\r\n        SimpleCreateFrameRecipe cf = s.createAndFillImpl();\r\n        Frame frame = cf.exec().get();\r\n        Scope.track(frame);\r\n        Log.info(frame);\r\n        assertNotNull(frame);\r\n        assertEquals(0, frame.numCols());\r\n        assertEquals(0, frame.numRows());\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.supportsOuterJoinForUpdate",
	"Comment": "does this dialect support for update in conjunction with\touter joined rows?",
	"Method": "boolean supportsOuterJoinForUpdate(){\r\n    return true;\r\n}"
}, {
	"Path": "org.hibernate.engine.transaction.internal.jta.JtaStatusHelper.isCommitted",
	"Comment": "does the given status code indicate a committed transaction?",
	"Method": "boolean isCommitted(int status,boolean isCommitted,UserTransaction userTransaction,boolean isCommitted,TransactionManager transactionManager){\r\n    return isCommitted(getStatus(transactionManager));\r\n}"
}, {
	"Path": "water.util.ArrayUtils.gaussianArray",
	"Comment": "generate a n by m array of random numbers drawn from the standard normal distribution",
	"Method": "double[][] gaussianArray(int n,int m,double[][] gaussianArray,int n,int m,long seed){\r\n    if (n <= 0 || m <= 0)\r\n        return null;\r\n    double[][] result = new double[n][m];\r\n    Random random = getRNG(seed);\r\n    for (int i = 0; i < n; i++) {\r\n        for (int j = 0; j < m; j++) result[i][j] = random.nextGaussian();\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.exec.internal.AbstractLoadPlanBasedLoader.bindNamedParameters",
	"Comment": "bind named parameters to the jdbc prepared statement.\tthis is a generic implementation, the problem being that in the\tgeneral case we do not know enough information about the named\tparameters to perform this in a complete manner here.thus this\tis generally overridden on subclasses allowing named parameters to\tapply the specific behavior.the most usual limitation here is that\twe need to assume the type span is always one...",
	"Method": "int bindNamedParameters(PreparedStatement statement,Map namedParams,int startIndex,SharedSessionContractImplementor session){\r\n    if (namedParams != null) {\r\n        final Iterator itr = namedParams.entrySet().iterator();\r\n        final boolean debugEnabled = log.isDebugEnabled();\r\n        int result = 0;\r\n        while (itr.hasNext()) {\r\n            final Map.Entry e = (Map.Entry) itr.next();\r\n            final String name = (String) e.getKey();\r\n            final TypedValue typedval = (TypedValue) e.getValue();\r\n            final int[] locs = getNamedParameterLocs(name);\r\n            for (int loc : locs) {\r\n                if (debugEnabled) {\r\n                    log.debugf(\"bindNamedParameters() %s -> %s [%s]\", typedval.getValue(), name, loc + startIndex);\r\n                }\r\n                typedval.getType().nullSafeSet(statement, typedval.getValue(), loc + startIndex, session);\r\n            }\r\n            result += locs.length;\r\n        }\r\n        return result;\r\n    } else {\r\n        return 0;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.event.internal.DefaultSaveOrUpdateEventListener.saveWithGeneratedOrRequestedId",
	"Comment": "save the transient instance, assigning the right identifier",
	"Method": "Serializable saveWithGeneratedOrRequestedId(SaveOrUpdateEvent event){\r\n    return saveWithGeneratedId(event.getEntity(), event.getEntityName(), null, event.getSession(), true);\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.forceLimitUsage",
	"Comment": "generally, if there is no limit applied to a hibernate query we do not apply any limits\tto the sql query.this option forces that the limit be written to the sql query.",
	"Method": "boolean forceLimitUsage(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.ClobProxy.getProxyClassLoader",
	"Comment": "determines the appropriate class loader to which the generated proxy\tshould be scoped.",
	"Method": "ClassLoader getProxyClassLoader(){\r\n    return ClobImplementer.class.getClassLoader();\r\n}"
}, {
	"Path": "org.hibernate.dialect.pagination.AbstractLimitHandler.forceLimitUsage",
	"Comment": "generally, if there is no limit applied to a hibernate query we do not apply any limits\tto the sql query.this option forces that the limit be written to the sql query.",
	"Method": "boolean forceLimitUsage(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.exec.internal.AbstractLoadPlanBasedLoader.getResultSet",
	"Comment": "execute given preparedstatement, advance to the first result and return sql resultset.",
	"Method": "ResultSet getResultSet(PreparedStatement st,RowSelection selection,LimitHandler limitHandler,boolean autodiscovertypes,SharedSessionContractImplementor session,ResultSet getResultSet){\r\n    try {\r\n        ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract(st);\r\n        rs = wrapResultSetIfEnabled(rs, session);\r\n        if (!limitHandler.supportsLimitOffset() || !LimitHelper.useLimit(limitHandler, selection)) {\r\n            advance(rs, selection);\r\n        }\r\n        if (autodiscovertypes) {\r\n            autoDiscoverTypes(rs);\r\n        }\r\n        return rs;\r\n    } catch (SQLException | HibernateException ex) {\r\n        session.getJdbcCoordinator().getResourceRegistry().release(st);\r\n        session.getJdbcCoordinator().afterStatementExecution();\r\n        throw ex;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.dialect.internal.DialectResolverSet.addResolver",
	"Comment": "add a resolver at the end of the underlying resolver list.the resolver added by this method is at lower\tpriority than any other existing resolvers.",
	"Method": "void addResolver(DialectResolver resolver){\r\n    resolvers.add(resolver);\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.HQLQueryPlan.performIterate",
	"Comment": "coordinates the efforts to perform an iterate across all the included query translators.",
	"Method": "Iterator performIterate(QueryParameters queryParameters,EventSource session){\r\n    if (traceEnabled) {\r\n        LOG.tracev(\"Iterate: {0}\", getSourceQuery());\r\n        queryParameters.traceParameters(session.getFactory());\r\n    }\r\n    if (translators.length == 0) {\r\n        return Collections.emptyIterator();\r\n    }\r\n    final boolean many = translators.length > 1;\r\n    Iterator[] results = null;\r\n    if (many) {\r\n        results = new Iterator[translators.length];\r\n    }\r\n    Iterator result = null;\r\n    for (int i = 0; i < translators.length; i++) {\r\n        result = translators[i].iterate(queryParameters, session);\r\n        if (many) {\r\n            results[i] = result;\r\n        }\r\n    }\r\n    return many ? new JoinedIterator(results) : result;\r\n}"
}, {
	"Path": "org.hibernate.graph.spi.RootGraphImplementor.makeImmutableCopy",
	"Comment": "make an immutable copy of this entity graph, using the given name.",
	"Method": "RootGraphImplementor<J> makeImmutableCopy(String name){\r\n    return makeRootGraph(name, false);\r\n}"
}, {
	"Path": "org.hibernate.event.internal.DefaultResolveNaturalIdEventListener.loadFromDatasource",
	"Comment": "performs the process of loading an entity from the configured\tunderlying datasource.",
	"Method": "Serializable loadFromDatasource(ResolveNaturalIdEvent event){\r\n    final SessionFactoryImplementor factory = event.getSession().getFactory();\r\n    final boolean stats = factory.getStatistics().isStatisticsEnabled();\r\n    long startTime = 0;\r\n    if (stats) {\r\n        startTime = System.nanoTime();\r\n    }\r\n    final Serializable pk = event.getEntityPersister().loadEntityIdByNaturalId(event.getOrderedNaturalIdValues(), event.getLockOptions(), event.getSession());\r\n    if (stats) {\r\n        final long endTime = System.nanoTime();\r\n        final long milliseconds = TimeUnit.MILLISECONDS.convert(endTime - startTime, TimeUnit.NANOSECONDS);\r\n        factory.getStatistics().naturalIdQueryExecuted(event.getEntityPersister().getRootEntityName(), milliseconds);\r\n    }\r\n    if (pk != null) {\r\n        event.getSession().getPersistenceContext().getNaturalIdHelper().cacheNaturalIdCrossReferenceFromLoad(event.getEntityPersister(), pk, event.getOrderedNaturalIdValues());\r\n    }\r\n    return pk;\r\n}"
}, {
	"Path": "org.hibernate.id.enhanced.OptimizerFactory.determineImplicitOptimizerName",
	"Comment": "determine the optimizer to use when there was not one explicitly specified.",
	"Method": "String determineImplicitOptimizerName(int incrementSize,Properties configSettings){\r\n    if (incrementSize <= 1) {\r\n        return StandardOptimizerDescriptor.NONE.getExternalName();\r\n    }\r\n    final String preferredPooledOptimizerStrategy = configSettings.getProperty(AvailableSettings.PREFERRED_POOLED_OPTIMIZER);\r\n    if (StringHelper.isNotEmpty(preferredPooledOptimizerStrategy)) {\r\n        return preferredPooledOptimizerStrategy;\r\n    }\r\n    return ConfigurationHelper.getBoolean(AvailableSettings.PREFER_POOLED_VALUES_LO, configSettings, false) ? StandardOptimizerDescriptor.POOLED_LO.getExternalName() : StandardOptimizerDescriptor.POOLED.getExternalName();\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.QueryPlanCache.getNativeSQLQueryPlan",
	"Comment": "get the query plan for a native sql query, creating it and caching it if not already cached",
	"Method": "NativeSQLQueryPlan getNativeSQLQueryPlan(NativeSQLQuerySpecification spec){\r\n    NativeSQLQueryPlan value = (NativeSQLQueryPlan) queryPlanCache.get(spec);\r\n    if (value == null) {\r\n        LOG.tracev(\"Unable to locate native-sql query plan in cache; generating ({0})\", spec.getQueryString());\r\n        value = nativeQueryInterpreter.createQueryPlan(spec, factory);\r\n        queryPlanCache.putIfAbsent(spec, value);\r\n    } else {\r\n        LOG.tracev(\"Located native-sql query plan in cache ({0})\", spec.getQueryString());\r\n    }\r\n    return value;\r\n}"
}, {
	"Path": "org.hibernate.Hibernate.isPropertyInitialized",
	"Comment": "check if the property is initialized. if the named property does not exist\tor is not persistent, this method always returns true.",
	"Method": "boolean isPropertyInitialized(Object proxy,String propertyName){\r\n    final Object entity;\r\n    if (proxy instanceof HibernateProxy) {\r\n        final LazyInitializer li = ((HibernateProxy) proxy).getHibernateLazyInitializer();\r\n        if (li.isUninitialized()) {\r\n            return false;\r\n        } else {\r\n            entity = li.getImplementation();\r\n        }\r\n    } else {\r\n        entity = proxy;\r\n    }\r\n    if (entity instanceof PersistentAttributeInterceptable) {\r\n        PersistentAttributeInterceptor interceptor = ((PersistentAttributeInterceptable) entity).$$_hibernate_getInterceptor();\r\n        if (interceptor != null && interceptor instanceof LazyAttributeLoadingInterceptor) {\r\n            return ((LazyAttributeLoadingInterceptor) interceptor).isAttributeLoaded(propertyName);\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "hex.genmodel.GenModel.nclasses",
	"Comment": "returns number of output classes for classifiers, 1 for regression models, and 0 for unsupervised models.",
	"Method": "int nclasses(){\r\n    return 0;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.FromElementType.getQueryable",
	"Comment": "returns the hibernate queryable implementation for the hql class.",
	"Method": "Queryable getQueryable(){\r\n    return (persister instanceof Queryable) ? (Queryable) persister : null;\r\n}"
}, {
	"Path": "hex.genmodel.GenModel.KMeans_distances",
	"Comment": "outputs distances from a given point to all cluster centers, returns index of the closest cluster center",
	"Method": "int KMeans_distances(double[][] centers,double[] point,String[][] domains,double[] distances){\r\n    int min = -1;\r\n    double minSqr = Double.MAX_VALUE;\r\n    for (int cluster = 0; cluster < centers.length; cluster++) {\r\n        distances[cluster] = KMeans_distance(centers[cluster], point, domains);\r\n        if (distances[cluster] < minSqr) {\r\n            min = cluster;\r\n            minSqr = distances[cluster];\r\n        }\r\n    }\r\n    return min;\r\n}"
}, {
	"Path": "org.hibernate.bytecode.enhance.spi.interceptor.LazyAttributeDescriptor.getAttributeIndex",
	"Comment": "access to the index of the attribute in terms of its position in the entity persister",
	"Method": "int getAttributeIndex(){\r\n    return attributeIndex;\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.ActionQueue.invalidateSpaces",
	"Comment": "this method is now called once per execution of an executablelist or once for execution of an execution.",
	"Method": "void invalidateSpaces(String spaces){\r\n    if (spaces != null && spaces.length > 0) {\r\n        for (Serializable s : spaces) {\r\n            if (afterTransactionProcesses == null) {\r\n                afterTransactionProcesses = new AfterTransactionCompletionProcessQueue(session);\r\n            }\r\n            afterTransactionProcesses.addSpaceToInvalidate((String) s);\r\n        }\r\n        session.getFactory().getCache().getTimestampsCache().preInvalidate(spaces, session);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.param.PositionalParameterSpecification.bind",
	"Comment": "bind the appropriate value into the given statement at the specified position.",
	"Method": "int bind(PreparedStatement statement,QueryParameters qp,SharedSessionContractImplementor session,int position){\r\n    final TypedValue typedValue = qp.getNamedParameters().get(Integer.toString(label));\r\n    typedValue.getType().nullSafeSet(statement, typedValue.getValue(), position, session);\r\n    return typedValue.getType().getColumnSpan(session.getFactory());\r\n}"
}, {
	"Path": "water.Value.block",
	"Comment": "possibly blocks the current thread.returns true if isreleasable wouldreturn true.used by the fj pool management to spawn threads to preventdeadlock is otherwise all threads would block on waits.",
	"Method": "boolean block(){\r\n    while (!isReleasable()) {\r\n        try {\r\n            wait();\r\n        } catch (InterruptedException ignore) {\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.SerializableClobProxy.generateProxy",
	"Comment": "generates a serializableclobproxy proxy wrapping the provided clob object.",
	"Method": "Clob generateProxy(Clob clob){\r\n    return (Clob) Proxy.newProxyInstance(getProxyClassLoader(), PROXY_INTERFACES, new SerializableClobProxy(clob));\r\n}"
}, {
	"Path": "org.hibernate.cfg.annotations.CollectionBinder.bindManytoManyInverseFk",
	"Comment": "bind the inverse fk of a manytomany\tif we are in a mappedby case, read the columns from the associated\tcollection element\totherwise delegates to the usual algorithm",
	"Method": "void bindManytoManyInverseFk(PersistentClass referencedEntity,Ejb3JoinColumn[] columns,SimpleValue value,boolean unique,MetadataBuildingContext buildingContext){\r\n    final String mappedBy = columns[0].getMappedBy();\r\n    if (StringHelper.isNotEmpty(mappedBy)) {\r\n        final Property property = referencedEntity.getRecursiveProperty(mappedBy);\r\n        Iterator mappedByColumns;\r\n        if (property.getValue() instanceof Collection) {\r\n            mappedByColumns = ((Collection) property.getValue()).getKey().getColumnIterator();\r\n        } else {\r\n            Iterator joinsIt = referencedEntity.getJoinIterator();\r\n            KeyValue key = null;\r\n            while (joinsIt.hasNext()) {\r\n                Join join = (Join) joinsIt.next();\r\n                if (join.containsProperty(property)) {\r\n                    key = join.getKey();\r\n                    break;\r\n                }\r\n            }\r\n            if (key == null)\r\n                key = property.getPersistentClass().getIdentifier();\r\n            mappedByColumns = key.getColumnIterator();\r\n        }\r\n        while (mappedByColumns.hasNext()) {\r\n            Column column = (Column) mappedByColumns.next();\r\n            columns[0].linkValueUsingAColumnCopy(column, value);\r\n        }\r\n        String referencedPropertyName = buildingContext.getMetadataCollector().getPropertyReferencedAssociation(\"inverse__\" + referencedEntity.getEntityName(), mappedBy);\r\n        if (referencedPropertyName != null) {\r\n            ((ManyToOne) value).setReferencedPropertyName(referencedPropertyName);\r\n            buildingContext.getMetadataCollector().addUniquePropertyReference(referencedEntity.getEntityName(), referencedPropertyName);\r\n        }\r\n        ((ManyToOne) value).setReferenceToPrimaryKey(referencedPropertyName == null);\r\n        value.createForeignKey();\r\n    } else {\r\n        BinderHelper.createSyntheticPropertyReference(columns, referencedEntity, null, value, true, buildingContext);\r\n        TableBinder.bindFk(referencedEntity, null, columns, value, unique, buildingContext);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cfg.BinderHelper.findPropertyByName",
	"Comment": "retrieve the property by path in a recursive way, including indetifierproperty in the loop\tif propertyname is null or empty, the identifierproperty is returned",
	"Method": "Property findPropertyByName(PersistentClass associatedClass,String propertyName,Property findPropertyByName,Component component,String propertyName){\r\n    Property property = null;\r\n    try {\r\n        if (propertyName == null || propertyName.length() == 0) {\r\n            return null;\r\n        } else {\r\n            StringTokenizer st = new StringTokenizer(propertyName, \".\", false);\r\n            while (st.hasMoreElements()) {\r\n                String element = (String) st.nextElement();\r\n                if (property == null) {\r\n                    property = component.getProperty(element);\r\n                } else {\r\n                    if (!property.isComposite()) {\r\n                        return null;\r\n                    }\r\n                    property = ((Component) property.getValue()).getProperty(element);\r\n                }\r\n            }\r\n        }\r\n    } catch (MappingException e) {\r\n        try {\r\n            if (component.getOwner().getIdentifierMapper() == null) {\r\n                return null;\r\n            }\r\n            StringTokenizer st = new StringTokenizer(propertyName, \".\", false);\r\n            while (st.hasMoreElements()) {\r\n                String element = (String) st.nextElement();\r\n                if (property == null) {\r\n                    property = component.getOwner().getIdentifierMapper().getProperty(element);\r\n                } else {\r\n                    if (!property.isComposite()) {\r\n                        return null;\r\n                    }\r\n                    property = ((Component) property.getValue()).getProperty(element);\r\n                }\r\n            }\r\n        } catch (MappingException ee) {\r\n            return null;\r\n        }\r\n    }\r\n    return property;\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.applyLocks",
	"Comment": "append for update of clause, if necessary. this\tempty superclass implementation merely returns its first\targument.",
	"Method": "String applyLocks(String sql,QueryParameters parameters,Dialect dialect,List<AfterLoadAction> afterLoadActions){\r\n    return sql;\r\n}"
}, {
	"Path": "water.parser.ParserTest2.testSparse2",
	"Comment": "so, the first column was compressed into c2schunk with 0s causing short overflow,",
	"Method": "void testSparse2(){\r\n    String data = \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"35351, 0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"6108,  0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"35351, 0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"6334,  0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\" + \"0,     0,0,0,0,0\\n\";\r\n    double[][] exp = new double[][] { ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(35351, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(6108, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(35351, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(6334, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0), ard(0, 0, 0, 0, 0, 0) };\r\n    Key k = ParserTest.makeByteVec(data);\r\n    ParserTest.testParsed(ParseDataset.parse(Key.make(), k), exp, 33);\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.propertyEqAll",
	"Comment": "creates a criterion which checks that the value of a given property equals all the values in the\tsubquery result.",
	"Method": "Criterion propertyEqAll(String propertyName,DetachedCriteria dc){\r\n    return new PropertySubqueryExpression(propertyName, \"=\", \"all\", dc);\r\n}"
}, {
	"Path": "water.util.Timer.toString",
	"Comment": "return the difference between when the timer was created and the current time as a string along with the time of creation in date format.",
	"Method": "String toString(){\r\n    final long now = System.currentTimeMillis();\r\n    return PrettyPrint.msecs(now - _start, false) + \" (Wall: \" + longFormat.print(now) + \") \";\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.spi.JdbcCoordinator.getConnectionReleaseMode",
	"Comment": "the release mode under which this logical connection is operating.",
	"Method": "ConnectionReleaseMode getConnectionReleaseMode(){\r\n    return getLogicalConnection().getConnectionHandlingMode().getReleaseMode();\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.FromClause.containsClassAlias",
	"Comment": "returns true if the from node contains the class alias name.",
	"Method": "boolean containsClassAlias(String alias){\r\n    boolean isAlias = fromElementByClassAlias.containsKey(alias);\r\n    if (!isAlias && getSessionFactoryHelper().isStrictJPAQLComplianceEnabled()) {\r\n        isAlias = findIntendedAliasedFromElementBasedOnCrazyJPARequirements(alias) != null;\r\n    }\r\n    return isAlias;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getLowercaseFunction",
	"Comment": "the name of the sql function that transforms a string to\tlowercase",
	"Method": "String getLowercaseFunction(){\r\n    return \"lower\";\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.sql.NativeSQLQueryJoinReturn.getOwnerAlias",
	"Comment": "retrieve the alias of the owner of this fetched association.",
	"Method": "String getOwnerAlias(){\r\n    return ownerAlias;\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.exec.internal.RootHelper.extractRootReturn",
	"Comment": "extract the root return of the loadplan, assuming there is just one.",
	"Method": "T extractRootReturn(LoadPlan loadPlan,Class<T> returnType){\r\n    if (loadPlan.getReturns().size() == 0) {\r\n        throw new IllegalStateException(\"LoadPlan contained no root returns\");\r\n    } else if (loadPlan.getReturns().size() > 1) {\r\n        throw new IllegalStateException(\"LoadPlan contained more than one root returns\");\r\n    }\r\n    final Return rootReturn = loadPlan.getReturns().get(0);\r\n    if (!returnType.isInstance(rootReturn)) {\r\n        throw new IllegalStateException(String.format(\"Unexpected LoadPlan root return; expecting %s, but found %s\", returnType.getName(), rootReturn.getClass().getName()));\r\n    }\r\n    return (T) rootReturn;\r\n}"
}, {
	"Path": "hex.genmodel.easy.EasyPredictModelWrapper.predictClustering",
	"Comment": "make a prediction on a new data point using a clustering model.",
	"Method": "ClusteringModelPrediction predictClustering(RowData data){\r\n    ClusteringModelPrediction p = new ClusteringModelPrediction();\r\n    if (useExtendedOutput && (m instanceof IClusteringModel)) {\r\n        IClusteringModel cm = (IClusteringModel) m;\r\n        double[] rawData = nanArray(m.nfeatures());\r\n        rawData = fillRawData(data, rawData);\r\n        final int k = cm.getNumClusters();\r\n        p.distances = new double[k];\r\n        p.cluster = cm.distances(rawData, p.distances);\r\n    } else {\r\n        double[] preds = preamble(ModelCategory.Clustering, data);\r\n        p.cluster = (int) preds[0];\r\n    }\r\n    return p;\r\n}"
}, {
	"Path": "org.hibernate.action.internal.BulkOperationCleanupAction.affectedEntity",
	"Comment": "check to determine whether the table spaces reported by an entity\tpersister match against the defined affected table spaces.",
	"Method": "boolean affectedEntity(Set affectedTableSpaces,Serializable[] checkTableSpaces){\r\n    if (affectedTableSpaces == null || affectedTableSpaces.isEmpty()) {\r\n        return true;\r\n    }\r\n    for (Serializable checkTableSpace : checkTableSpaces) {\r\n        if (affectedTableSpaces.contains(checkTableSpace)) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.internal.util.collections.BoundedConcurrentHashMap.put",
	"Comment": "maps the specified key to the specified value in this table.\tneither the key nor the value can be null.\t the value can be retrieved by calling the get method\twith a key that is equal to the original key.",
	"Method": "V put(K key,int hash,V value,boolean onlyIfAbsent,V put,K key,V value){\r\n    if (value == null) {\r\n        throw new NullPointerException();\r\n    }\r\n    int hash = hash(key.hashCode());\r\n    return segmentFor(hash).put(key, hash, value, false);\r\n}"
}, {
	"Path": "org.hibernate.event.spi.AbstractEvent.getSession",
	"Comment": "returns the session event source for this event.this is the underlyingsession from which this event was generated.",
	"Method": "EventSource getSession(){\r\n    return session;\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl.notifyObserversExplicitExecution",
	"Comment": "convenience method to notify registered observers of an explicit execution of this batch.",
	"Method": "void notifyObserversExplicitExecution(){\r\n    for (BatchObserver observer : observers) {\r\n        observer.batchExplicitlyExecuted();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getLimitString",
	"Comment": "given a limit and an offset, apply the limit clause to the query.",
	"Method": "String getLimitString(String query,int offset,int limit,String getLimitString,String query,boolean hasOffset){\r\n    throw new UnsupportedOperationException(\"Paged queries not supported by \" + getClass().getName());\r\n}"
}, {
	"Path": "org.hibernate.cfg.Ejb3JoinColumn.overrideFromReferencedColumnIfNecessary",
	"Comment": "called to apply column definitions from the referenced fk column to this column.",
	"Method": "void overrideFromReferencedColumnIfNecessary(org.hibernate.mapping.Column column){\r\n    if (getMappingColumn() != null) {\r\n        if (StringHelper.isEmpty(sqlType)) {\r\n            sqlType = column.getSqlType();\r\n            getMappingColumn().setSqlType(sqlType);\r\n        }\r\n        getMappingColumn().setLength(column.getLength());\r\n        getMappingColumn().setPrecision(column.getPrecision());\r\n        getMappingColumn().setScale(column.getScale());\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.internal.util.jndi.JndiHelper.bind",
	"Comment": "bind val to name in ctx, and make sure that all intermediate contexts exist.",
	"Method": "void bind(Context ctx,String name,Object val){\r\n    try {\r\n        ctx.rebind(name, val);\r\n    } catch (Exception e) {\r\n        Name n = ctx.getNameParser(\"\").parse(name);\r\n        while (n.size() > 1) {\r\n            final String ctxName = n.get(0);\r\n            Context subctx = null;\r\n            try {\r\n                subctx = (Context) ctx.lookup(ctxName);\r\n            } catch (NameNotFoundException ignore) {\r\n            }\r\n            if (subctx != null) {\r\n                ctx = subctx;\r\n            } else {\r\n                ctx = ctx.createSubcontext(ctxName);\r\n            }\r\n            n = n.getSuffix(1);\r\n        }\r\n        ctx.rebind(n, val);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.tuple.entity.EntityMetamodel.getPropertyNames",
	"Comment": "temporary ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~",
	"Method": "String[] getPropertyNames(){\r\n    return propertyNames;\r\n}"
}, {
	"Path": "org.hibernate.cfg.ImprovedNamingStrategy.propertyToColumnName",
	"Comment": "return the full property path with underscore seperators, mixed\tcase converted to underscores",
	"Method": "String propertyToColumnName(String propertyName){\r\n    return addUnderscores(StringHelper.unqualify(propertyName));\r\n}"
}, {
	"Path": "org.hibernate.transform.AliasToBeanConstructorResultTransformer.equals",
	"Comment": "2 aliastobeanconstructorresulttransformer are considered equal if they have the same\tdefined constructor.",
	"Method": "boolean equals(Object other){\r\n    return other instanceof AliasToBeanConstructorResultTransformer && constructor.equals(((AliasToBeanConstructorResultTransformer) other).constructor);\r\n}"
}, {
	"Path": "org.hibernate.context.internal.ManagedSessionContext.bind",
	"Comment": "binds the given session to the current context for its session factory.",
	"Method": "Session bind(Session session){\r\n    return sessionMap(true).put(session.getSessionFactory(), session);\r\n}"
}, {
	"Path": "hex.genmodel.algos.tree.SharedTreeNode.printDotNodesAtLevel",
	"Comment": "recursively print nodes at a particular depth level in the tree.useful to group them so they render properly.",
	"Method": "void printDotNodesAtLevel(PrintStream os,int levelToPrint,boolean detail,PrintMojo.PrintTreeOptions treeOptions){\r\n    if (getDepth() == levelToPrint) {\r\n        printDotNode(os, detail, treeOptions);\r\n        return;\r\n    }\r\n    assert (getDepth() < levelToPrint);\r\n    if (leftChild != null) {\r\n        leftChild.printDotNodesAtLevel(os, levelToPrint, detail, treeOptions);\r\n    }\r\n    if (rightChild != null) {\r\n        rightChild.printDotNodesAtLevel(os, levelToPrint, detail, treeOptions);\r\n    }\r\n}"
}, {
	"Path": "water.fvec.TestFrameBuilder.getUniqueValues",
	"Comment": "utility method to get unique values from categorical domain",
	"Method": "String[] getUniqueValues(HashMap<String, Integer> mapping){\r\n    String[] values = new String[mapping.size()];\r\n    for (String key : mapping.keySet()) values[mapping.get(key)] = key;\r\n    return values;\r\n}"
}, {
	"Path": "org.hibernate.metamodel.model.domain.spi.SingularPersistentAttribute.getValueGraphType",
	"Comment": "for a singular attribute, the value type is defined as the\tattribute type",
	"Method": "SimpleTypeDescriptor<?> getValueGraphType(){\r\n    return getType();\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.needsFetchingScroll",
	"Comment": "does the result set to be scrolled contain collection fetches?",
	"Method": "boolean needsFetchingScroll(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.bytecode.enhance.spi.interceptor.LazyAttributesMetadata.from",
	"Comment": "build a lazyfetchgroupmetadata based on the attributes defined for the\tpersistentclass",
	"Method": "LazyAttributesMetadata from(PersistentClass mappedEntity){\r\n    final Map<String, LazyAttributeDescriptor> lazyAttributeDescriptorMap = new LinkedHashMap();\r\n    final Map<String, Set<String>> fetchGroupToAttributesMap = new HashMap();\r\n    int i = -1;\r\n    int x = 0;\r\n    final Iterator itr = mappedEntity.getPropertyClosureIterator();\r\n    while (itr.hasNext()) {\r\n        i++;\r\n        final Property property = (Property) itr.next();\r\n        if (property.isLazy()) {\r\n            final LazyAttributeDescriptor lazyAttributeDescriptor = LazyAttributeDescriptor.from(property, i, x++);\r\n            lazyAttributeDescriptorMap.put(lazyAttributeDescriptor.getName(), lazyAttributeDescriptor);\r\n            final Set<String> attributeSet = fetchGroupToAttributesMap.computeIfAbsent(lazyAttributeDescriptor.getFetchGroupName(), k -> new LinkedHashSet());\r\n            attributeSet.add(lazyAttributeDescriptor.getName());\r\n        }\r\n    }\r\n    if (lazyAttributeDescriptorMap.isEmpty()) {\r\n        return new LazyAttributesMetadata(mappedEntity.getEntityName());\r\n    }\r\n    for (Map.Entry<String, Set<String>> entry : fetchGroupToAttributesMap.entrySet()) {\r\n        entry.setValue(Collections.unmodifiableSet(entry.getValue()));\r\n    }\r\n    return new LazyAttributesMetadata(mappedEntity.getEntityName(), Collections.unmodifiableMap(lazyAttributeDescriptorMap), Collections.unmodifiableMap(fetchGroupToAttributesMap));\r\n}"
}, {
	"Path": "org.hibernate.type.EntityType.getIdentifierOrUniqueKeyPropertyName",
	"Comment": "the name of the property on the associated entity to which our fk\trefers",
	"Method": "String getIdentifierOrUniqueKeyPropertyName(Mapping factory){\r\n    if (isReferenceToPrimaryKey() || uniqueKeyPropertyName == null) {\r\n        return factory.getIdentifierPropertyName(getAssociatedEntityName());\r\n    } else {\r\n        return uniqueKeyPropertyName;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.list",
	"Comment": "return the query results, using the query cache, called\tby subclasses that implement cacheable queries",
	"Method": "List list(SharedSessionContractImplementor session,QueryParameters queryParameters,Set<Serializable> querySpaces,Type[] resultTypes){\r\n    final boolean cacheable = factory.getSessionFactoryOptions().isQueryCacheEnabled() && queryParameters.isCacheable();\r\n    if (cacheable) {\r\n        return listUsingQueryCache(session, queryParameters, querySpaces, resultTypes);\r\n    } else {\r\n        return listIgnoreQueryCache(session, queryParameters);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.proxy.AbstractLazyInitializer.initializeWithoutLoadIfPossible",
	"Comment": "attempt to initialize the proxy without loading anything from the database.\tthis will only have any effect if the proxy is still attached to a session,\tand the entity being proxied has been loaded and added to the persistence context\tof that session since the proxy was created.",
	"Method": "void initializeWithoutLoadIfPossible(){\r\n    if (!initialized && session != null && session.isOpen()) {\r\n        final EntityKey key = session.generateEntityKey(getIdentifier(), session.getFactory().getMetamodel().entityPersister(getEntityName()));\r\n        final Object entity = session.getPersistenceContext().getEntity(key);\r\n        if (entity != null) {\r\n            setImplementation(entity);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.stat.QueryStatistics.getPlanCacheHitCount",
	"Comment": "the number of query plans successfully fetched from the cache.",
	"Method": "long getPlanCacheHitCount(){\r\n    return 0;\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.SerializableNClobProxy.generateProxy",
	"Comment": "generates a serializablenclobproxy proxy wrapping the provided nclob object.",
	"Method": "NClob generateProxy(NClob nclob){\r\n    return (NClob) Proxy.newProxyInstance(getProxyClassLoader(), PROXY_INTERFACES, new SerializableNClobProxy(nclob));\r\n}"
}, {
	"Path": "org.hibernate.cfg.annotations.PropertyBinder.makeProperty",
	"Comment": "used when the value is provided and the binding is done elsewhere",
	"Method": "Property makeProperty(){\r\n    validateMake();\r\n    LOG.debugf(\"Building property %s\", name);\r\n    Property prop = new Property();\r\n    prop.setName(name);\r\n    prop.setValue(value);\r\n    prop.setLazy(lazy);\r\n    prop.setLazyGroup(lazyGroup);\r\n    prop.setCascade(cascade);\r\n    prop.setPropertyAccessorName(accessType.getType());\r\n    if (property != null) {\r\n        prop.setValueGenerationStrategy(determineValueGenerationStrategy(property));\r\n        if (property.isAnnotationPresent(AttributeAccessor.class)) {\r\n            final AttributeAccessor accessor = property.getAnnotation(AttributeAccessor.class);\r\n            prop.setPropertyAccessorName(accessor.value());\r\n        }\r\n    }\r\n    NaturalId naturalId = property != null ? property.getAnnotation(NaturalId.class) : null;\r\n    if (naturalId != null) {\r\n        if (!entityBinder.isRootEntity()) {\r\n            throw new AnnotationException(\"@NaturalId only valid on root entity (or its @MappedSuperclasses)\");\r\n        }\r\n        if (!naturalId.mutable()) {\r\n            updatable = false;\r\n        }\r\n        prop.setNaturalIdentifier(true);\r\n    }\r\n    Lob lob = property != null ? property.getAnnotation(Lob.class) : null;\r\n    prop.setLob(lob != null);\r\n    prop.setInsertable(insertable);\r\n    prop.setUpdateable(updatable);\r\n    if (Collection.class.isInstance(value)) {\r\n        prop.setOptimisticLocked(((Collection) value).isOptimisticLocked());\r\n    } else {\r\n        final OptimisticLock lockAnn = property != null ? property.getAnnotation(OptimisticLock.class) : null;\r\n        if (lockAnn != null) {\r\n            if (lockAnn.excluded() && (property.isAnnotationPresent(javax.persistence.Version.class) || property.isAnnotationPresent(Id.class) || property.isAnnotationPresent(EmbeddedId.class))) {\r\n                throw new AnnotationException(\"@OptimisticLock.exclude=true incompatible with @Id, @EmbeddedId and @Version: \" + StringHelper.qualify(holder.getPath(), name));\r\n            }\r\n        }\r\n        final boolean isOwnedValue = !isToOneValue(value) || insertable;\r\n        final boolean includeInOptimisticLockChecks = (lockAnn != null) ? !lockAnn.excluded() : isOwnedValue;\r\n        prop.setOptimisticLocked(includeInOptimisticLockChecks);\r\n    }\r\n    LOG.tracev(\"Cascading {0} with {1}\", name, cascade);\r\n    this.mappingProperty = prop;\r\n    return prop;\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.dialect.internal.DialectResolverSet.addResolverAtFirst",
	"Comment": "add a resolver at the beginning of the underlying resolver list.the resolver added by this method is at higher\tpriority than any other existing resolvers.",
	"Method": "void addResolverAtFirst(DialectResolver resolver){\r\n    resolvers.add(0, resolver);\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.JoinSequence.getFromPart",
	"Comment": "retrieve a joinsequence that represents just the from clause parts",
	"Method": "JoinSequence getFromPart(){\r\n    final JoinSequence fromPart = new JoinSequence(factory);\r\n    fromPart.joins.addAll(this.joins);\r\n    fromPart.useThetaStyle = this.useThetaStyle;\r\n    fromPart.rootAlias = this.rootAlias;\r\n    fromPart.rootJoinable = this.rootJoinable;\r\n    fromPart.selector = this.selector;\r\n    fromPart.next = this.next == null ? null : this.next.getFromPart();\r\n    fromPart.isFromPart = true;\r\n    return fromPart;\r\n}"
}, {
	"Path": "water.rapids.RapidsTest.testMergeWithStrings",
	"Comment": "however, due to test timing, i choose one test to run randomly each time.",
	"Method": "void testMergeWithStrings(){\r\n    String[] f1Names = new String[] { \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f1_small_NAs.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f1_small_NAs.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f2_small_NAs.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f1_small.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f1_small.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f2_small.csv\" };\r\n    String[] f2Names = new String[] { \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f2_small_NAs.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f2_small_NAs.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f1_small_NAs.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f2_small.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f2_small.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/PUBDEV_5266_f1_small.csv\" };\r\n    String[] ansNames = new String[] { \"smalldata/jira/PUBDEV_5266_merge_strings/mergedf1_f2_small_NAs.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/mergedf1_f2_x_T_small_NAs.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/mergedf2_f1_x_T_small_NAs.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/mergedf1_f2_small.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/mergedf1_f2_x_T_small.csv\", \"smalldata/jira/PUBDEV_5266_merge_strings/mergedf2_f1_x_T_small.csv\" };\r\n    String[] rapidStrings = new String[] { \"(merge %s %s 0 0 [0] [0] \\\"radix\\\")\", \"(merge %s %s 1 0 [0] [0] \\\"radix\\\")\", \"(merge %s %s 1 0 [0] [0] \\\"radix\\\")\", \"(merge %s %s 0 0 [0] [0] \\\"radix\\\")\", \"(merge %s %s 1 0 [0] [0] \\\"radix\\\")\", \"(merge %s %s 1 0 [0] [0] \\\"radix\\\")\" };\r\n    int[][] stringColIndices = new int[][] { { 1, 2, 4, 5, 6, 10 }, { 1, 2, 4, 5, 6, 10 }, { 1, 2, 3, 7, 8, 9 }, { 1, 2, 4, 5, 6, 10 }, { 1, 2, 4, 5, 6, 10 }, { 1, 2, 3, 7, 8, 9 } };\r\n    Random newRand = new Random();\r\n    int index = newRand.nextInt(rapidStrings.length);\r\n    testMergeStringOneSetting(f1Names[index], f2Names[index], ansNames[index], rapidStrings[index], stringColIndices[index]);\r\n}"
}, {
	"Path": "org.hibernate.event.internal.MergeContext.get",
	"Comment": "returns the managed entity associated with the specified merge entity.",
	"Method": "Object get(Object mergeEntity){\r\n    if (mergeEntity == null) {\r\n        throw new NullPointerException(\"null entities are not supported by \" + getClass().getName());\r\n    }\r\n    return mergeToManagedEntityXref.get(mergeEntity);\r\n}"
}, {
	"Path": "org.hibernate.type.EntityType.getName",
	"Comment": "for entity types, the name correlates to the associated entity name.",
	"Method": "String getName(){\r\n    return associatedEntityName;\r\n}"
}, {
	"Path": "water.parser.orc.OrcParser.writeTimecolumn",
	"Comment": "this method writes one column of h2o frame for column type timestamp.this is just a long thatrecords the number of seconds since jan 1, 2015.",
	"Method": "void writeTimecolumn(LongColumnVector col,String columnType,int cIdx,int rowNumber,ParseWriter dout){\r\n    boolean timestamp = columnType.equals(\"timestamp\");\r\n    long[] oneColumn = col.vector;\r\n    if (col.isRepeating) {\r\n        long val = timestamp ? oneColumn[0] / 1000000 : correctTimeStamp(oneColumn[0]);\r\n        for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) dout.addNumCol(cIdx, val, 0);\r\n    } else if (col.noNulls) {\r\n        for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) dout.addNumCol(cIdx, timestamp ? oneColumn[rowIndex] / 1000000 : correctTimeStamp(oneColumn[rowIndex]), 0);\r\n    } else {\r\n        boolean[] isNull = col.isNull;\r\n        for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) {\r\n            if (isNull[rowIndex])\r\n                dout.addInvalidCol(cIdx);\r\n            else\r\n                dout.addNumCol(cIdx, timestamp ? oneColumn[rowIndex] / 1000000 : correctTimeStamp(oneColumn[rowIndex]), 0);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.batch.internal.AbstractBatchImpl.notifyObserversImplicitExecution",
	"Comment": "convenience method to notify registered observers of an implicit execution of this batch.",
	"Method": "void notifyObserversImplicitExecution(){\r\n    for (BatchObserver observer : observers) {\r\n        observer.batchImplicitlyExecuted();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.SessionFactoryHelper.hasPhysicalDiscriminatorColumn",
	"Comment": "does the given persister define a physical discriminator column\tfor the purpose of inheritance discrimination?",
	"Method": "boolean hasPhysicalDiscriminatorColumn(Queryable persister){\r\n    if (persister.getDiscriminatorType() != null) {\r\n        String discrimColumnName = persister.getDiscriminatorColumnName();\r\n        if (discrimColumnName != null && !\"clazz_\".equals(discrimColumnName)) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.scroll",
	"Comment": "return the query results, as an instance of scrollableresults",
	"Method": "ScrollableResultsImplementor scroll(QueryParameters queryParameters,Type[] returnTypes,HolderInstantiator holderInstantiator,SharedSessionContractImplementor session){\r\n    checkScrollability();\r\n    final boolean stats = getQueryIdentifier() != null && getFactory().getStatistics().isStatisticsEnabled();\r\n    long startTime = 0;\r\n    if (stats) {\r\n        startTime = System.nanoTime();\r\n    }\r\n    try {\r\n        final SqlStatementWrapper wrapper = executeQueryStatement(queryParameters, true, new ArrayList<AfterLoadAction>(), session);\r\n        final ResultSet rs = wrapper.getResultSet();\r\n        final PreparedStatement st = (PreparedStatement) wrapper.getStatement();\r\n        if (stats) {\r\n            final long endTime = System.nanoTime();\r\n            final long milliseconds = TimeUnit.MILLISECONDS.convert(endTime - startTime, TimeUnit.NANOSECONDS);\r\n            getFactory().getStatistics().queryExecuted(getQueryIdentifier(), 0, milliseconds);\r\n        }\r\n        if (needsFetchingScroll()) {\r\n            return new FetchingScrollableResultsImpl(rs, st, session, this, queryParameters, returnTypes, holderInstantiator);\r\n        } else {\r\n            return new ScrollableResultsImpl(rs, st, session, this, queryParameters, returnTypes, holderInstantiator);\r\n        }\r\n    } catch (SQLException sqle) {\r\n        throw factory.getJdbcServices().getSqlExceptionHelper().convert(sqle, \"could not execute query using scroll\", getSQLString());\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.tool.hbm2ddl.SchemaExportTask.setConfig",
	"Comment": "set a .cfg.xml file, which will be\tloaded as a resource, from the classpath",
	"Method": "void setConfig(File configurationFile){\r\n    this.configurationFile = configurationFile;\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.HQLQueryPlan.performExecuteUpdate",
	"Comment": "coordinates the efforts to perform an execution across all the included query translators.",
	"Method": "int performExecuteUpdate(QueryParameters queryParameters,SharedSessionContractImplementor session){\r\n    if (traceEnabled) {\r\n        LOG.tracev(\"Execute update: {0}\", getSourceQuery());\r\n        queryParameters.traceParameters(session.getFactory());\r\n    }\r\n    if (translators.length != 1) {\r\n        LOG.splitQueries(getSourceQuery(), translators.length);\r\n    }\r\n    int result = 0;\r\n    for (QueryTranslator translator : translators) {\r\n        result += translator.executeUpdate(queryParameters, session);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.persister.entity.AbstractEntityPersister.generateIdentityInsertString",
	"Comment": "used to generate an insery statement against the root table in the\tcase of identifier generation strategies where the insert statement\texecutions actually generates the identifier value.",
	"Method": "String generateIdentityInsertString(boolean[] includeProperty){\r\n    Insert insert = identityDelegate.prepareIdentifierGeneratingInsert();\r\n    insert.setTableName(getTableName(0));\r\n    for (int i = 0; i < entityMetamodel.getPropertySpan(); i++) {\r\n        if (isPropertyOfTable(i, 0) && !lobProperties.contains(i)) {\r\n            final InDatabaseValueGenerationStrategy generationStrategy = entityMetamodel.getInDatabaseValueGenerationStrategies()[i];\r\n            if (includeProperty[i]) {\r\n                insert.addColumns(getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i]);\r\n            } else if (generationStrategy != null && generationStrategy.getGenerationTiming().includesInsert() && generationStrategy.referenceColumnsInSql()) {\r\n                final String[] values;\r\n                if (generationStrategy.getReferencedColumnValues() == null) {\r\n                    values = propertyColumnWriters[i];\r\n                } else {\r\n                    values = new String[propertyColumnWriters[i].length];\r\n                    for (int j = 0; j < values.length; j++) {\r\n                        values[j] = (generationStrategy.getReferencedColumnValues()[j] != null) ? generationStrategy.getReferencedColumnValues()[j] : propertyColumnWriters[i][j];\r\n                    }\r\n                }\r\n                insert.addColumns(getPropertyColumnNames(i), propertyColumnInsertable[i], values);\r\n            }\r\n        }\r\n    }\r\n    for (int i : lobProperties) {\r\n        if (includeProperty[i] && isPropertyOfTable(i, 0)) {\r\n            insert.addColumns(getPropertyColumnNames(i), propertyColumnInsertable[i], propertyColumnWriters[i]);\r\n        }\r\n    }\r\n    addDiscriminatorToInsert(insert);\r\n    if (getFactory().getSessionFactoryOptions().isCommentsEnabled()) {\r\n        insert.setComment(\"insert \" + getEntityName());\r\n    }\r\n    return insert.toStatementString();\r\n}"
}, {
	"Path": "org.hibernate.cfg.Configuration.addAnnotatedClass",
	"Comment": "read metadata from the annotations associated with this class.",
	"Method": "Configuration addAnnotatedClass(Class annotatedClass){\r\n    metadataSources.addAnnotatedClass(annotatedClass);\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.loader.JoinWalker.walkComponentTree",
	"Comment": "for a component, add to a list of associations to be fetched by outerjoin",
	"Method": "void walkComponentTree(CompositeType componentType,int propertyNumber,int begin,OuterJoinLoadable persister,String alias,PropertyPath path,int currentDepth){\r\n    Type[] types = componentType.getSubtypes();\r\n    String[] propertyNames = componentType.getPropertyNames();\r\n    for (int i = 0; i < types.length; i++) {\r\n        if (types[i].isAssociationType()) {\r\n            AssociationType associationType = (AssociationType) types[i];\r\n            String[] aliasedLhsColumns = JoinHelper.getAliasedLHSColumnNames(associationType, alias, propertyNumber, begin, persister, getFactory());\r\n            String[] lhsColumns = JoinHelper.getLHSColumnNames(associationType, propertyNumber, begin, persister, getFactory());\r\n            String lhsTable = JoinHelper.getLHSTableName(associationType, propertyNumber, persister);\r\n            final PropertyPath subPath = path.append(propertyNames[i]);\r\n            final boolean[] propertyNullability = componentType.getPropertyNullability();\r\n            final JoinType joinType = getJoinType(persister, subPath, propertyNumber, associationType, componentType.getFetchMode(i), componentType.getCascadeStyle(i), lhsTable, lhsColumns, propertyNullability == null || propertyNullability[i], currentDepth);\r\n            addAssociationToJoinTreeIfNecessary(associationType, aliasedLhsColumns, alias, subPath, currentDepth, joinType);\r\n        } else if (types[i].isComponentType()) {\r\n            final PropertyPath subPath = path.append(propertyNames[i]);\r\n            walkComponentTree((CompositeType) types[i], propertyNumber, begin, persister, alias, subPath, currentDepth);\r\n        }\r\n        begin += types[i].getColumnSpan(getFactory());\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.type.descriptor.spi.JdbcRecommendedSqlTypeMappingContext.isNationalized",
	"Comment": "was nationalized character datatype requested for the given java type?",
	"Method": "boolean isNationalized(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.ASTUtil.makeSiblingOfParent",
	"Comment": "makes the child node a sibling of the parent, reconnecting all siblings.",
	"Method": "void makeSiblingOfParent(AST parent,AST child){\r\n    AST prev = findPreviousSibling(parent, child);\r\n    if (prev != null) {\r\n        prev.setNextSibling(child.getNextSibling());\r\n    } else {\r\n        parent.setFirstChild(child.getNextSibling());\r\n    }\r\n    child.setNextSibling(parent.getNextSibling());\r\n    parent.setNextSibling(child);\r\n}"
}, {
	"Path": "org.hibernate.context.internal.ThreadLocalSessionContext.bind",
	"Comment": "associates the given session with the current thread of execution.",
	"Method": "void bind(org.hibernate.Session session){\r\n    final SessionFactory factory = session.getSessionFactory();\r\n    doBind(session, factory);\r\n}"
}, {
	"Path": "hex.tree.xgboost.XGBoostUtils.enlargeTables",
	"Comment": "assumes both matrices are getting filled at the same rate and will require the same amount of space",
	"Method": "void enlargeTables(float[][] data,int[][] rowIndex,int cols,int currentRow,int currentCol){\r\n    while (data[currentRow].length < currentCol + cols) {\r\n        if (data[currentRow].length == ARRAY_MAX) {\r\n            currentCol = 0;\r\n            cols -= (data[currentRow].length - currentCol);\r\n            currentRow++;\r\n            data[currentRow] = malloc4f(ALLOCATED_ARRAY_LEN);\r\n            rowIndex[currentRow] = malloc4(ALLOCATED_ARRAY_LEN);\r\n        } else {\r\n            int newLen = (int) Math.min((long) data[currentRow].length << 1L, (long) ARRAY_MAX);\r\n            data[currentRow] = Arrays.copyOf(data[currentRow], newLen);\r\n            rowIndex[currentRow] = Arrays.copyOf(rowIndex[currentRow], newLen);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "water.parser.orc.OrcParser.writeDecimalcolumn",
	"Comment": "this method writes a column to h2o frame for column type decimal.it is just written as someinteger without using the scale field.need to make sure this is what the customer wants.",
	"Method": "void writeDecimalcolumn(DecimalColumnVector col,int cIdx,int rowNumber,ParseWriter dout){\r\n    HiveDecimalWritable[] oneColumn = col.vector;\r\n    if (col.isRepeating) {\r\n        HiveDecimal hd = oneColumn[0].getHiveDecimal();\r\n        for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) dout.addNumCol(cIdx, hd.unscaledValue().longValue(), -hd.scale());\r\n    } else if (col.noNulls) {\r\n        for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) {\r\n            HiveDecimal hd = oneColumn[rowIndex].getHiveDecimal();\r\n            dout.addNumCol(cIdx, hd.unscaledValue().longValue(), -hd.scale());\r\n        }\r\n    } else {\r\n        boolean[] isNull = col.isNull;\r\n        for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) {\r\n            if (isNull[rowIndex])\r\n                dout.addInvalidCol(cIdx);\r\n            else {\r\n                HiveDecimal hd = oneColumn[rowIndex].getHiveDecimal();\r\n                dout.addNumCol(cIdx, hd.unscaledValue().longValue(), -hd.scale());\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cfg.Ejb3Column.extractDataFromPropertyData",
	"Comment": "must only be called after all setters are defined and before bind",
	"Method": "void extractDataFromPropertyData(PropertyData inferredData){\r\n    if (inferredData != null) {\r\n        XProperty property = inferredData.getProperty();\r\n        if (property != null) {\r\n            processExpression(property.getAnnotation(ColumnTransformer.class));\r\n            ColumnTransformers annotations = property.getAnnotation(ColumnTransformers.class);\r\n            if (annotations != null) {\r\n                for (ColumnTransformer annotation : annotations.value()) {\r\n                    processExpression(annotation);\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.event.internal.MergeContext.values",
	"Comment": "returns an unmodifiable set view of managed entities contained in this mergecontext.",
	"Method": "Collection values(){\r\n    return Collections.unmodifiableSet(managedToMergeEntityXref.keySet());\r\n}"
}, {
	"Path": "org.hibernate.cfg.Ejb3JoinColumn.getManyToManyOwnerSideEntityName",
	"Comment": "todo hacky solution to get the information at property ref resolution",
	"Method": "String getManyToManyOwnerSideEntityName(){\r\n    return manyToManyOwnerSideEntityName;\r\n}"
}, {
	"Path": "org.hibernate.internal.SessionFactoryImpl.readObject",
	"Comment": "custom serialization hook defined by java spec.used when the factory is directly deserialized",
	"Method": "void readObject(ObjectInputStream in){\r\n    LOG.trace(\"Deserializing\");\r\n    in.defaultReadObject();\r\n    LOG.debugf(\"Deserialized: %s\", getUuid());\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.build.internal.spaces.AbstractQuerySpace.getQuerySpaces",
	"Comment": "provides subclasses access to the spaces to which this space belongs.",
	"Method": "QuerySpaces getQuerySpaces(){\r\n    return querySpaces;\r\n}"
}, {
	"Path": "org.hibernate.context.internal.ThreadLocalSessionContext.unbind",
	"Comment": "disassociates a previously bound session from the current thread of execution.",
	"Method": "Session unbind(SessionFactory factory){\r\n    return doUnbind(factory, true);\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.preprocessSQL",
	"Comment": "modify the sql, adding lock hints and comments, if necessary",
	"Method": "String preprocessSQL(String sql,QueryParameters parameters,SessionFactoryImplementor sessionFactory,List<AfterLoadAction> afterLoadActions){\r\n    Dialect dialect = sessionFactory.getServiceRegistry().getService(JdbcServices.class).getDialect();\r\n    sql = applyLocks(sql, parameters, dialect, afterLoadActions);\r\n    sql = dialect.addSqlHintOrComment(sql, parameters, sessionFactory.getSessionFactoryOptions().isCommentsEnabled());\r\n    return processDistinctKeyword(sql, parameters);\r\n}"
}, {
	"Path": "water.TypeMap.install",
	"Comment": "smaller type ids, and these will work fine in either old or new arrays.",
	"Method": "int install(String className,int id){\r\n    assert !_check_no_locking : \"Locking cloud to assign typeid to \" + className;\r\n    if (id == -1) {\r\n        assert H2O.CLOUD.leader() == H2O.SELF;\r\n        Integer i = MAP.get(className);\r\n        if (i != null)\r\n            return i;\r\n        id = IDS++;\r\n    }\r\n    MAP.put(className, id);\r\n    if (id >= CLAZZES.length)\r\n        CLAZZES = Arrays.copyOf(CLAZZES, Math.max(CLAZZES.length << 1, id + 1));\r\n    if (id >= GOLD.length)\r\n        GOLD = Arrays.copyOf(GOLD, Math.max(CLAZZES.length << 1, id + 1));\r\n    CLAZZES[id] = className;\r\n    return id;\r\n}"
}, {
	"Path": "org.hibernate.id.enhanced.SequenceStyleConfigUnitTest.testForceTableUse",
	"Comment": "test forcing of table as backing structure with dialect supporting sequences",
	"Method": "void testForceTableUse(){\r\n    StandardServiceRegistry serviceRegistry = new StandardServiceRegistryBuilder().applySetting(AvailableSettings.DIALECT, SequenceDialect.class.getName()).build();\r\n    try {\r\n        Properties props = buildGeneratorPropertiesBase(serviceRegistry);\r\n        props.setProperty(SequenceStyleGenerator.FORCE_TBL_PARAM, \"true\");\r\n        SequenceStyleGenerator generator = new SequenceStyleGenerator();\r\n        generator.configure(StandardBasicTypes.LONG, props, serviceRegistry);\r\n        generator.registerExportables(new Database(new MetadataBuilderImpl.MetadataBuildingOptionsImpl(serviceRegistry)));\r\n        assertClassAssignability(TableStructure.class, generator.getDatabaseStructure().getClass());\r\n        assertClassAssignability(NoopOptimizer.class, generator.getOptimizer().getClass());\r\n        assertEquals(SequenceStyleGenerator.DEF_SEQUENCE_NAME, generator.getDatabaseStructure().getName());\r\n    } finally {\r\n        StandardServiceRegistryBuilder.destroy(serviceRegistry);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cache.spi.support.AbstractReadWriteAccess.get",
	"Comment": "returns null if the item is not readable.locked items are not readable, nor are items created\tafterquery the start of this transaction.",
	"Method": "Object get(SharedSessionContractImplementor session,Object key){\r\n    log.debugf(\"Getting cached data from region [`%s` (%s)] by key [%s]\", getRegion().getName(), getAccessType(), key);\r\n    try {\r\n        readLock.lock();\r\n        Lockable item = (Lockable) getStorageAccess().getFromCache(key, session);\r\n        if (item == null) {\r\n            log.debugf(\"Cache miss : region = `%s`, key = `%s`\", getRegion().getName(), key);\r\n            return null;\r\n        }\r\n        boolean readable = item.isReadable(session.getTransactionStartTimestamp());\r\n        if (readable) {\r\n            log.debugf(\"Cache hit : region = `%s`, key = `%s`\", getRegion().getName(), key);\r\n            return item.getValue();\r\n        } else {\r\n            log.debugf(\"Cache hit, but item is unreadable/invalid : region = `%s`, key = `%s`\", getRegion().getName(), key);\r\n            return null;\r\n        }\r\n    } finally {\r\n        readLock.unlock();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.event.spi.AbstractCollectionEvent.getAffectedOwnerEntityName",
	"Comment": "get the entity name for the collection owner entity that is affected by this event.",
	"Method": "String getAffectedOwnerEntityName(CollectionPersister collectionPersister,Object affectedOwner,EventSource source,String getAffectedOwnerEntityName){\r\n    return affectedOwnerEntityName;\r\n}"
}, {
	"Path": "org.hibernate.boot.MetadataSources.addAnnotatedClass",
	"Comment": "read metadata from the annotations attached to the given class.",
	"Method": "MetadataSources addAnnotatedClass(Class annotatedClass){\r\n    annotatedClasses.add(annotatedClass);\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.type.CollectionType.getElementsIterator",
	"Comment": "get an iterator over the element set of the collection in pojo mode",
	"Method": "Iterator getElementsIterator(Object collection,SharedSessionContractImplementor session,Iterator getElementsIterator,Object collection){\r\n    return ((Collection) collection).iterator();\r\n}"
}, {
	"Path": "hex.genmodel.easy.EasyPredictModelWrapper.sortByDescendingClassProbability",
	"Comment": "a helper function to return an array of binomial class probabilities for a prediction in sorted order.the returned array has the most probable class in position 0.",
	"Method": "SortedClassProbability[] sortByDescendingClassProbability(String[] domainValues,double[] classProbabilities,SortedClassProbability[] sortByDescendingClassProbability,BinomialModelPrediction p){\r\n    String[] domainValues = m.getDomainValues(m.getResponseIdx());\r\n    double[] classProbabilities = p.classProbabilities;\r\n    return sortByDescendingClassProbability(domainValues, classProbabilities);\r\n}"
}, {
	"Path": "org.hibernate.persister.walking.spi.MetamodelGraphWalker.isDuplicateAssociationKey",
	"Comment": "has an association with the specified key been visited already?",
	"Method": "boolean isDuplicateAssociationKey(AssociationKey associationKey){\r\n    return visitedAssociationKeys.contains(associationKey) || strategy.isDuplicateAssociationKey(associationKey);\r\n}"
}, {
	"Path": "water.util.MRUtils.sampleFrameStratified",
	"Comment": "currently hardcoded to do up to 10 tries to get a row from each class, which can be impossible for certain wrong sampling ratios",
	"Method": "Frame sampleFrameStratified(Frame fr,Vec label,Vec weights,float[] sampling_ratios,long maxrows,long seed,boolean allowOversampling,boolean verbose,Frame sampleFrameStratified,Frame fr,Vec label,Vec weights,float[] sampling_ratios,long seed,boolean debug,Frame sampleFrameStratified,Frame fr,Vec label,Vec weights,float[] sampling_ratios,long seed,boolean debug,int count){\r\n    if (fr == null)\r\n        return null;\r\n    assert (label.isCategorical());\r\n    assert (sampling_ratios != null && sampling_ratios.length == label.domain().length);\r\n    final int labelidx = fr.find(label);\r\n    assert (labelidx >= 0);\r\n    final int weightsidx = fr.find(weights);\r\n    final boolean poisson = false;\r\n    Frame r = new MRTask() {\r\n        @Override\r\n        public void map(Chunk[] cs, NewChunk[] ncs) {\r\n            final Random rng = getRNG(seed);\r\n            for (int r = 0; r < cs[0]._len; r++) {\r\n                if (cs[labelidx].isNA(r))\r\n                    continue;\r\n                rng.setSeed(cs[0].start() + r + seed);\r\n                final int label = (int) cs[labelidx].at8(r);\r\n                assert (sampling_ratios.length > label && label >= 0);\r\n                int sampling_reps;\r\n                if (poisson) {\r\n                    throw H2O.unimpl();\r\n                } else {\r\n                    final float remainder = sampling_ratios[label] - (int) sampling_ratios[label];\r\n                    sampling_reps = (int) sampling_ratios[label] + (rng.nextFloat() < remainder ? 1 : 0);\r\n                }\r\n                for (int i = 0; i < ncs.length; i++) {\r\n                    if (cs[i] instanceof CStrChunk) {\r\n                        for (int j = 0; j < sampling_reps; ++j) {\r\n                            ncs[i].addStr(cs[i], cs[0].start() + r);\r\n                        }\r\n                    } else {\r\n                        for (int j = 0; j < sampling_reps; ++j) {\r\n                            ncs[i].addNum(cs[i].atd(r));\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }.doAll(fr.types(), fr).outputFrame(fr.names(), fr.domains());\r\n    Vec lab = r.vecs()[labelidx];\r\n    Vec wei = weightsidx != -1 ? r.vecs()[weightsidx] : null;\r\n    double[] dist = wei != null ? new ClassDist(lab).doAll(lab, wei).dist() : new ClassDist(lab).doAll(lab).dist();\r\n    if (dist == null)\r\n        return fr;\r\n    if (debug) {\r\n        double sumdist = ArrayUtils.sum(dist);\r\n        Log.info(\"After stratified sampling: \" + sumdist + \" rows.\");\r\n        for (int i = 0; i < dist.length; ++i) {\r\n            Log.info(\"Class \" + r.vecs()[labelidx].factor(i) + \": count: \" + dist[i] + \" sampling ratio: \" + sampling_ratios[i] + \" actual relative frequency: \" + (float) dist[i] / sumdist * dist.length);\r\n        }\r\n    }\r\n    if (ArrayUtils.minValue(dist) == 0 && count < 10) {\r\n        Log.info(\"Re-doing stratified sampling because not all classes were represented (unlucky draw).\");\r\n        r.remove();\r\n        return sampleFrameStratified(fr, label, weights, sampling_ratios, seed + 1, debug, ++count);\r\n    }\r\n    Frame shuffled = shuffleFramePerChunk(r, seed + 0x580FF13);\r\n    r.remove();\r\n    return shuffled;\r\n}"
}, {
	"Path": "water.util.MRUtils.sampleFrameStratified",
	"Comment": "currently hardcoded to do up to 10 tries to get a row from each class, which can be impossible for certain wrong sampling ratios",
	"Method": "Frame sampleFrameStratified(Frame fr,Vec label,Vec weights,float[] sampling_ratios,long maxrows,long seed,boolean allowOversampling,boolean verbose,Frame sampleFrameStratified,Frame fr,Vec label,Vec weights,float[] sampling_ratios,long seed,boolean debug,Frame sampleFrameStratified,Frame fr,Vec label,Vec weights,float[] sampling_ratios,long seed,boolean debug,int count){\r\n    final Random rng = getRNG(seed);\r\n    for (int r = 0; r < cs[0]._len; r++) {\r\n        if (cs[labelidx].isNA(r))\r\n            continue;\r\n        rng.setSeed(cs[0].start() + r + seed);\r\n        final int label = (int) cs[labelidx].at8(r);\r\n        assert (sampling_ratios.length > label && label >= 0);\r\n        int sampling_reps;\r\n        if (poisson) {\r\n            throw H2O.unimpl();\r\n        } else {\r\n            final float remainder = sampling_ratios[label] - (int) sampling_ratios[label];\r\n            sampling_reps = (int) sampling_ratios[label] + (rng.nextFloat() < remainder ? 1 : 0);\r\n        }\r\n        for (int i = 0; i < ncs.length; i++) {\r\n            if (cs[i] instanceof CStrChunk) {\r\n                for (int j = 0; j < sampling_reps; ++j) {\r\n                    ncs[i].addStr(cs[i], cs[0].start() + r);\r\n                }\r\n            } else {\r\n                for (int j = 0; j < sampling_reps; ++j) {\r\n                    ncs[i].addNum(cs[i].atd(r));\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getForUpdateSkipLockedString",
	"Comment": "retrieves the for update skip locked syntax specific to this dialect.",
	"Method": "String getForUpdateSkipLockedString(String getForUpdateSkipLockedString,String aliases){\r\n    return getForUpdateString(aliases);\r\n}"
}, {
	"Path": "org.hibernate.event.spi.AbstractCollectionEvent.getAffectedOwnerOrNull",
	"Comment": "get the collection owner entity that is affected by this event.",
	"Method": "Object getAffectedOwnerOrNull(){\r\n    return affectedOwner;\r\n}"
}, {
	"Path": "org.hibernate.cfg.OneToOneSecondPass.doSecondPass",
	"Comment": "todo refactor this code, there is a lot of duplication in this method",
	"Method": "void doSecondPass(Map persistentClasses){\r\n    org.hibernate.mapping.OneToOne value = new org.hibernate.mapping.OneToOne(buildingContext, propertyHolder.getTable(), propertyHolder.getPersistentClass());\r\n    final String propertyName = inferredData.getPropertyName();\r\n    value.setPropertyName(propertyName);\r\n    String referencedEntityName = ToOneBinder.getReferenceEntityName(inferredData, targetEntity, buildingContext);\r\n    value.setReferencedEntityName(referencedEntityName);\r\n    AnnotationBinder.defineFetchingStrategy(value, inferredData.getProperty());\r\n    value.setCascadeDeleteEnabled(cascadeOnDelete);\r\n    value.setConstrained(!optional);\r\n    final ForeignKeyDirection foreignKeyDirection = !BinderHelper.isEmptyAnnotationValue(mappedBy) ? ForeignKeyDirection.TO_PARENT : ForeignKeyDirection.FROM_PARENT;\r\n    value.setForeignKeyType(foreignKeyDirection);\r\n    AnnotationBinder.bindForeignKeyNameAndDefinition(value, inferredData.getProperty(), inferredData.getProperty().getAnnotation(javax.persistence.ForeignKey.class), inferredData.getProperty().getAnnotation(JoinColumn.class), inferredData.getProperty().getAnnotation(JoinColumns.class));\r\n    PropertyBinder binder = new PropertyBinder();\r\n    binder.setName(propertyName);\r\n    binder.setValue(value);\r\n    binder.setCascade(cascadeStrategy);\r\n    binder.setAccessType(inferredData.getDefaultAccess());\r\n    final LazyGroup lazyGroupAnnotation = inferredData.getProperty().getAnnotation(LazyGroup.class);\r\n    if (lazyGroupAnnotation != null) {\r\n        binder.setLazyGroup(lazyGroupAnnotation.value());\r\n    }\r\n    Property prop = binder.makeProperty();\r\n    prop.setOptional(optional);\r\n    if (BinderHelper.isEmptyAnnotationValue(mappedBy)) {\r\n        boolean rightOrder = true;\r\n        if (rightOrder) {\r\n            String path = StringHelper.qualify(propertyHolder.getPath(), propertyName);\r\n            final ToOneFkSecondPass secondPass = new // cannot have nullabe and unique on certain DBs\r\n            ToOneFkSecondPass(// cannot have nullabe and unique on certain DBs\r\n            value, joinColumns, !optional, propertyHolder.getEntityOwnerClassName(), path, buildingContext);\r\n            secondPass.doSecondPass(persistentClasses);\r\n            propertyHolder.addProperty(prop, inferredData.getDeclaringClass());\r\n        } else {\r\n        }\r\n    } else {\r\n        PersistentClass otherSide = (PersistentClass) persistentClasses.get(value.getReferencedEntityName());\r\n        Property otherSideProperty;\r\n        try {\r\n            if (otherSide == null) {\r\n                throw new MappingException(\"Unable to find entity: \" + value.getReferencedEntityName());\r\n            }\r\n            otherSideProperty = BinderHelper.findPropertyByName(otherSide, mappedBy);\r\n        } catch (MappingException e) {\r\n            throw new AnnotationException(\"Unknown mappedBy in: \" + StringHelper.qualify(ownerEntity, ownerProperty) + \", referenced property unknown: \" + StringHelper.qualify(value.getReferencedEntityName(), mappedBy));\r\n        }\r\n        if (otherSideProperty == null) {\r\n            throw new AnnotationException(\"Unknown mappedBy in: \" + StringHelper.qualify(ownerEntity, ownerProperty) + \", referenced property unknown: \" + StringHelper.qualify(value.getReferencedEntityName(), mappedBy));\r\n        }\r\n        if (otherSideProperty.getValue() instanceof OneToOne) {\r\n            propertyHolder.addProperty(prop, inferredData.getDeclaringClass());\r\n        } else if (otherSideProperty.getValue() instanceof ManyToOne) {\r\n            Iterator it = otherSide.getJoinIterator();\r\n            Join otherSideJoin = null;\r\n            while (it.hasNext()) {\r\n                Join otherSideJoinValue = (Join) it.next();\r\n                if (otherSideJoinValue.containsProperty(otherSideProperty)) {\r\n                    otherSideJoin = otherSideJoinValue;\r\n                    break;\r\n                }\r\n            }\r\n            if (otherSideJoin != null) {\r\n                Join mappedByJoin = buildJoinFromMappedBySide((PersistentClass) persistentClasses.get(ownerEntity), otherSideProperty, otherSideJoin);\r\n                ManyToOne manyToOne = new ManyToOne(buildingContext, mappedByJoin.getTable());\r\n                manyToOne.setIgnoreNotFound(ignoreNotFound);\r\n                manyToOne.setCascadeDeleteEnabled(value.isCascadeDeleteEnabled());\r\n                manyToOne.setFetchMode(value.getFetchMode());\r\n                manyToOne.setLazy(value.isLazy());\r\n                manyToOne.setReferencedEntityName(value.getReferencedEntityName());\r\n                manyToOne.setUnwrapProxy(value.isUnwrapProxy());\r\n                prop.setValue(manyToOne);\r\n                Iterator otherSideJoinKeyColumns = otherSideJoin.getKey().getColumnIterator();\r\n                while (otherSideJoinKeyColumns.hasNext()) {\r\n                    Column column = (Column) otherSideJoinKeyColumns.next();\r\n                    Column copy = new Column();\r\n                    copy.setLength(column.getLength());\r\n                    copy.setScale(column.getScale());\r\n                    copy.setValue(manyToOne);\r\n                    copy.setName(column.getQuotedName());\r\n                    copy.setNullable(column.isNullable());\r\n                    copy.setPrecision(column.getPrecision());\r\n                    copy.setUnique(column.isUnique());\r\n                    copy.setSqlType(column.getSqlType());\r\n                    copy.setCheckConstraint(column.getCheckConstraint());\r\n                    copy.setComment(column.getComment());\r\n                    copy.setDefaultValue(column.getDefaultValue());\r\n                    manyToOne.addColumn(copy);\r\n                }\r\n                mappedByJoin.addProperty(prop);\r\n            } else {\r\n                propertyHolder.addProperty(prop, inferredData.getDeclaringClass());\r\n            }\r\n            value.setReferencedPropertyName(mappedBy);\r\n            boolean referencesDerivedId = false;\r\n            try {\r\n                referencesDerivedId = otherSide.getIdentifier() instanceof Component && ((Component) otherSide.getIdentifier()).getProperty(mappedBy) != null;\r\n            } catch (MappingException e) {\r\n            }\r\n            boolean referenceToPrimaryKey = referencesDerivedId || mappedBy == null;\r\n            value.setReferenceToPrimaryKey(referenceToPrimaryKey);\r\n            if (referencesDerivedId) {\r\n                ((ManyToOne) otherSideProperty.getValue()).setReferenceToPrimaryKey(false);\r\n            }\r\n            String propertyRef = value.getReferencedPropertyName();\r\n            if (propertyRef != null) {\r\n                buildingContext.getMetadataCollector().addUniquePropertyReference(value.getReferencedEntityName(), propertyRef);\r\n            }\r\n        } else {\r\n            throw new AnnotationException(\"Referenced property not a (One|Many)ToOne: \" + StringHelper.qualify(otherSide.getEntityName(), mappedBy) + \" in mappedBy of \" + StringHelper.qualify(ownerEntity, ownerProperty));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.jndi.internal.JndiServiceImpl.extractJndiProperties",
	"Comment": "given a hodgepodge of properties, extract out the ones relevant for jndi interaction.",
	"Method": "Properties extractJndiProperties(Map configurationValues){\r\n    final Properties jndiProperties = new Properties();\r\n    for (Map.Entry entry : (Set<Map.Entry>) configurationValues.entrySet()) {\r\n        if (!String.class.isInstance(entry.getKey())) {\r\n            continue;\r\n        }\r\n        final String propertyName = (String) entry.getKey();\r\n        final Object propertyValue = entry.getValue();\r\n        if (propertyName.startsWith(Environment.JNDI_PREFIX)) {\r\n            if (Environment.JNDI_CLASS.equals(propertyName)) {\r\n                if (propertyValue != null) {\r\n                    jndiProperties.put(Context.INITIAL_CONTEXT_FACTORY, propertyValue);\r\n                }\r\n            } else if (Environment.JNDI_URL.equals(propertyName)) {\r\n                if (propertyValue != null) {\r\n                    jndiProperties.put(Context.PROVIDER_URL, propertyValue);\r\n                }\r\n            } else {\r\n                final String passThruPropertyname = propertyName.substring(Environment.JNDI_PREFIX.length() + 1);\r\n                jndiProperties.put(passThruPropertyname, propertyValue);\r\n            }\r\n        }\r\n    }\r\n    return jndiProperties;\r\n}"
}, {
	"Path": "hex.genmodel.AbstractMojoWriter.writeDomains",
	"Comment": "create files containing domain definitions for each categorical column.",
	"Method": "void writeDomains(){\r\n    int domIndex = 0;\r\n    for (String[] domain : model.scoringDomains()) {\r\n        if (domain == null)\r\n            continue;\r\n        startWritingTextFile(String.format(\"domains/dd.txt\", domIndex++));\r\n        for (String category : domain) {\r\n            writeln(category.replaceAll(\"\\n\", \"\\\\n\"));\r\n        }\r\n        finishWritingTextFile();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.internal.util.collections.BoundedConcurrentHashMap.segmentFor",
	"Comment": "returns the segment that should be used for key with given hash",
	"Method": "Segment<K, V> segmentFor(int hash){\r\n    return segments[hash >>> segmentShift & segmentMask];\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.HQLQueryPlan.getTranslators",
	"Comment": "access to the underlying translators associated with this query",
	"Method": "QueryTranslator[] getTranslators(){\r\n    final QueryTranslator[] copy = new QueryTranslator[translators.length];\r\n    System.arraycopy(translators, 0, copy, 0, copy.length);\r\n    return copy;\r\n}"
}, {
	"Path": "org.hibernate.mapping.PersistentClass.hasProperty",
	"Comment": "check to see if this persistentclass defines a property with the given name.",
	"Method": "boolean hasProperty(String name){\r\n    final Property identifierProperty = getIdentifierProperty();\r\n    if (identifierProperty != null && identifierProperty.getName().equals(name)) {\r\n        return true;\r\n    }\r\n    final Iterator itr = getPropertyClosureIterator();\r\n    while (itr.hasNext()) {\r\n        final Property property = (Property) itr.next();\r\n        if (property.getName().equals(name)) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "water.util.PojoUtils.fillFromMap",
	"Comment": "fill the fields of an object from the corresponding fields in a map.",
	"Method": "Object fillFromMap(Object o,Map<String, Object> setFields){\r\n    for (String key : setFields.keySet()) {\r\n        Object value = setFields.get(key);\r\n        if (value instanceof Map) {\r\n            try {\r\n                Field f = PojoUtils.getFieldEvenInherited(o, key);\r\n                f.setAccessible(true);\r\n                if (null == f.get(o))\r\n                    f.set(o, f.getType().newInstance());\r\n                fillFromMap(f.get(o), (Map<String, Object>) value);\r\n            } catch (NoSuchFieldException e) {\r\n                throw new IllegalArgumentException(\"Field not found: '\" + key + \"' on object \" + o);\r\n            } catch (IllegalAccessException e) {\r\n                throw new IllegalArgumentException(\"Cannot get value of the field: '\" + key + \"' on object \" + o);\r\n            } catch (InstantiationException e) {\r\n                try {\r\n                    throw new IllegalArgumentException(\"Cannot create new child object of type: \" + PojoUtils.getFieldEvenInherited(o, key).getClass().getCanonicalName() + \" for field: '\" + key + \"' on object \" + o);\r\n                } catch (NoSuchFieldException ee) {\r\n                    throw new IllegalArgumentException(\"Cannot create new child object of type for field: '\" + key + \"' on object \" + o);\r\n                }\r\n            }\r\n        } else {\r\n            try {\r\n                Field f = PojoUtils.getFieldEvenInherited(o, key);\r\n                f.setAccessible(true);\r\n                if (f.getType().isAssignableFrom(FrameV3.ColSpecifierV3.class)) {\r\n                    setField(o, key, new FrameV3.ColSpecifierV3((String) value));\r\n                } else if (KeyV3.class.isAssignableFrom(f.getType())) {\r\n                    setField(o, key, KeyV3.make((Class<? extends KeyV3>) f.getType(), Key.make((String) value)));\r\n                } else {\r\n                    setField(o, key, value);\r\n                }\r\n            } catch (NoSuchFieldException e) {\r\n                throw new IllegalArgumentException(\"Field not found: '\" + key + \"' on object \" + o);\r\n            }\r\n        }\r\n    }\r\n    return o;\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.NonNullableTransientDependencies.toLoggableString",
	"Comment": "build a loggable representation of the paths tracked here at the moment.",
	"Method": "String toLoggableString(SharedSessionContractImplementor session){\r\n    final StringBuilder sb = new StringBuilder(getClass().getSimpleName()).append('[');\r\n    if (propertyPathsByTransientEntity != null) {\r\n        for (Map.Entry<Object, Set<String>> entry : propertyPathsByTransientEntity.entrySet()) {\r\n            sb.append(\"transientEntityName=\").append(session.bestGuessEntityName(entry.getKey()));\r\n            sb.append(\" requiredBy=\").append(entry.getValue());\r\n        }\r\n    }\r\n    sb.append(']');\r\n    return sb.toString();\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.SerializableBlobProxy.getProxyClassLoader",
	"Comment": "determines the appropriate class loader to which the generated proxy\tshould be scoped.",
	"Method": "ClassLoader getProxyClassLoader(){\r\n    return WrappedBlob.class.getClassLoader();\r\n}"
}, {
	"Path": "org.hibernate.SharedSessionBuilder.transactionContext",
	"Comment": "signifies that the transaction context from the original session should be used to create the new session.",
	"Method": "T transactionContext(){\r\n    return connection();\r\n}"
}, {
	"Path": "water.persist.PersistS3.getObjectForKey",
	"Comment": "gets the s3 object associated with the key that can read length bytes from offset",
	"Method": "S3Object getObjectForKey(Key k,long offset,long length){\r\n    String[] bk = decodeKey(k);\r\n    GetObjectRequest r = new GetObjectRequest(bk[0], bk[1]);\r\n    r.setRange(offset, offset + length - 1);\r\n    return getClient().getObject(r);\r\n}"
}, {
	"Path": "water.util.FrameUtils.shrinkDomainsToObservedSubset",
	"Comment": "reduce the domains of all categorical columns to the actually observed subset",
	"Method": "void shrinkDomainsToObservedSubset(Frame frameToModifyInPlace){\r\n    for (Vec v : frameToModifyInPlace.vecs()) {\r\n        if (v.isCategorical()) {\r\n            long[] uniques = (v.min() >= 0 && v.max() < Integer.MAX_VALUE - 4) ? new VecUtils.CollectDomainFast((int) v.max()).doAll(v).domain() : new VecUtils.CollectIntegerDomain().doAll(v).domain();\r\n            String[] newDomain = new String[uniques.length];\r\n            final int[] fromTo = new int[(int) ArrayUtils.maxValue(uniques) + 1];\r\n            for (int i = 0; i < newDomain.length; ++i) {\r\n                newDomain[i] = v.domain()[(int) uniques[i]];\r\n                fromTo[(int) uniques[i]] = i;\r\n            }\r\n            new MRTask() {\r\n                @Override\r\n                public void map(Chunk c) {\r\n                    for (int i = 0; i < c._len; ++i) {\r\n                        if (c.isNA(i))\r\n                            continue;\r\n                        else\r\n                            c.set(i, fromTo[(int) c.at8(i)]);\r\n                    }\r\n                }\r\n            }.doAll(v);\r\n            v.setDomain(newDomain);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "water.util.FrameUtils.shrinkDomainsToObservedSubset",
	"Comment": "reduce the domains of all categorical columns to the actually observed subset",
	"Method": "void shrinkDomainsToObservedSubset(Frame frameToModifyInPlace){\r\n    for (int i = 0; i < c._len; ++i) {\r\n        if (c.isNA(i))\r\n            continue;\r\n        else\r\n            c.set(i, fromTo[(int) c.at8(i)]);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.ASTUtil.getConstantName",
	"Comment": "get the name of a constant defined on the given class which has the given value.\tnote, if multiple constants have this value, the first will be returned which is known to be different\ton different jvm implementations.",
	"Method": "String getConstantName(Class owner,int value){\r\n    return getTokenTypeName(owner, value);\r\n}"
}, {
	"Path": "org.hibernate.loader.JoinWalker.walkCompositeElementTree",
	"Comment": "for a composite element, add to a list of associations to be fetched by outerjoin",
	"Method": "void walkCompositeElementTree(CompositeType compositeType,String[] cols,QueryableCollection persister,String alias,PropertyPath path,int currentDepth){\r\n    Type[] types = compositeType.getSubtypes();\r\n    String[] propertyNames = compositeType.getPropertyNames();\r\n    int begin = 0;\r\n    for (int i = 0; i < types.length; i++) {\r\n        int length = types[i].getColumnSpan(getFactory());\r\n        String[] lhsColumns = ArrayHelper.slice(cols, begin, length);\r\n        if (types[i].isAssociationType()) {\r\n            AssociationType associationType = (AssociationType) types[i];\r\n            String[] aliasedLhsColumns = StringHelper.qualify(alias, lhsColumns);\r\n            final PropertyPath subPath = path.append(propertyNames[i]);\r\n            final boolean[] propertyNullability = compositeType.getPropertyNullability();\r\n            final JoinType joinType = getJoinType(associationType, compositeType.getFetchMode(i), subPath, persister.getTableName(), lhsColumns, propertyNullability == null || propertyNullability[i], currentDepth, compositeType.getCascadeStyle(i));\r\n            addAssociationToJoinTreeIfNecessary(associationType, aliasedLhsColumns, alias, subPath, currentDepth, joinType);\r\n        } else if (types[i].isComponentType()) {\r\n            final PropertyPath subPath = path.append(propertyNames[i]);\r\n            walkCompositeElementTree((CompositeType) types[i], lhsColumns, persister, alias, subPath, currentDepth);\r\n        }\r\n        begin += length;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.persister.collection.AbstractCollectionPersister.selectFragment",
	"Comment": "generate a list of collection index, key and element columns",
	"Method": "String selectFragment(String alias,String columnSuffix){\r\n    SelectFragment frag = generateSelectFragment(alias, columnSuffix);\r\n    appendElementColumns(frag, alias);\r\n    appendIndexColumns(frag, alias);\r\n    appendIdentifierColumns(frag, alias);\r\n    return // strip leading ','\r\n    frag.toFragmentString().substring(2);\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.dropConstraints",
	"Comment": "do we need to drop constraints before dropping tables in this dialect?",
	"Method": "boolean dropConstraints(){\r\n    return true;\r\n}"
}, {
	"Path": "org.hibernate.mapping.Property.isSynthetic",
	"Comment": "does this property represent a synthetic property?a synthetic property is one we create during\tmetamodel binding to represent a collection of columns but which does not represent a property\tphysically available on the entity.",
	"Method": "boolean isSynthetic(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.criterion.Example.setPropertySelector",
	"Comment": "set the property selector to use.\tthe property selector operates separate from excluding a property.",
	"Method": "Example setPropertySelector(PropertySelector selector){\r\n    this.selector = selector;\r\n    return this;\r\n}"
}, {
	"Path": "water.util.MathUtils.equalsWithinOneSmallUlp",
	"Comment": "compare two numbers to see if they are within one ulp of the smaller decade.order of the arguments does not matter.",
	"Method": "boolean equalsWithinOneSmallUlp(float a,float b,boolean equalsWithinOneSmallUlp,double a,double b){\r\n    if (Double.isNaN(a) && Double.isNaN(b))\r\n        return true;\r\n    double ulp_a = Math.ulp(a);\r\n    double ulp_b = Math.ulp(b);\r\n    double small_ulp = Math.min(ulp_a, ulp_b);\r\n    double absdiff_a_b = Math.abs(a - b);\r\n    return absdiff_a_b <= small_ulp;\r\n}"
}, {
	"Path": "org.hibernate.cfg.Configuration.addJar",
	"Comment": "read all mappings from a jar file\tassumes that any file named .hbm.xml is a mapping document.",
	"Method": "Configuration addJar(File jar){\r\n    metadataSources.addJar(jar);\r\n    return this;\r\n}"
}, {
	"Path": "water.parser.orc.OrcParser.writeDoublecolumn",
	"Comment": "this method writes a column of h2o frame for orc file column type of float or double.",
	"Method": "void writeDoublecolumn(DoubleColumnVector vec,int colId,int rowNumber,ParseWriter dout){\r\n    double[] oneColumn = vec.vector;\r\n    byte t = _setup.getColumnTypes()[colId];\r\n    switch(t) {\r\n        case Vec.T_CAT:\r\n            if (_toStringMaps.get(colId) == null)\r\n                _toStringMaps.put(colId, new HashMap<Number, byte[]>());\r\n            HashMap<Number, byte[]> map = _toStringMaps.get(colId);\r\n            BufferedString bs = new BufferedString();\r\n            if (vec.isRepeating) {\r\n                bs.set(StringUtils.toBytes(oneColumn[0]));\r\n                for (int i = 0; i < rowNumber; ++i) dout.addStrCol(colId, bs);\r\n            } else if (vec.noNulls) {\r\n                for (int i = 0; i < rowNumber; i++) {\r\n                    double d = oneColumn[i];\r\n                    if (map.get(d) == null)\r\n                        map.put(d, StringUtils.toBytes(d));\r\n                    dout.addStrCol(colId, bs.set(map.get(d)));\r\n                }\r\n            } else {\r\n                for (int i = 0; i < rowNumber; i++) {\r\n                    boolean[] isNull = vec.isNull;\r\n                    if (isNull[i])\r\n                        dout.addInvalidCol(colId);\r\n                    else {\r\n                        double d = oneColumn[i];\r\n                        if (map.get(d) == null)\r\n                            map.put(d, StringUtils.toBytes(d));\r\n                        dout.addStrCol(colId, bs.set(map.get(d)));\r\n                    }\r\n                }\r\n            }\r\n            break;\r\n        default:\r\n            if (vec.isRepeating) {\r\n                for (int i = 0; i < rowNumber; ++i) dout.addNumCol(colId, oneColumn[0]);\r\n            } else if (vec.noNulls) {\r\n                for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) dout.addNumCol(colId, oneColumn[rowIndex]);\r\n            } else {\r\n                boolean[] isNull = vec.isNull;\r\n                for (int rowIndex = 0; rowIndex < rowNumber; rowIndex++) {\r\n                    if (isNull[rowIndex])\r\n                        dout.addInvalidCol(colId);\r\n                    else\r\n                        dout.addNumCol(colId, oneColumn[rowIndex]);\r\n                }\r\n            }\r\n            break;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.BatchFetchQueue.getEntityBatch",
	"Comment": "get a batch of unloaded identifiers for this class, using a slightly\tcomplex algorithm that tries to grab keys registered immediately after\tthe given key.",
	"Method": "Serializable[] getEntityBatch(EntityPersister persister,Serializable id,int batchSize,EntityMode entityMode){\r\n    Serializable[] ids = new Serializable[batchSize];\r\n    ids[0] = id;\r\n    int i = 1;\r\n    int end = -1;\r\n    boolean checkForEnd = false;\r\n    LinkedHashSet<EntityKey> set = batchLoadableEntityKeys.get(persister.getEntityName());\r\n    if (set != null) {\r\n        for (EntityKey key : set) {\r\n            if (checkForEnd && i == end) {\r\n                return ids;\r\n            }\r\n            if (persister.getIdentifierType().isEqual(id, key.getIdentifier())) {\r\n                end = i;\r\n            } else {\r\n                if (!isCached(key, persister)) {\r\n                    ids[i++] = key.getIdentifier();\r\n                }\r\n            }\r\n            if (i == batchSize) {\r\n                i = 1;\r\n                if (end != -1) {\r\n                    checkForEnd = true;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return ids;\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.propertiesEq",
	"Comment": "creates a criterion which checks that the value of multiple given properties as being equal to the set of\tvalues in the subquery result.the implication is that the subquery returns a single result.this form is\thowever implicitly using tuple comparisons",
	"Method": "Criterion propertiesEq(String[] propertyNames,DetachedCriteria dc){\r\n    return new PropertiesSubqueryExpression(propertyNames, \"=\", dc);\r\n}"
}, {
	"Path": "org.hibernate.engine.transaction.internal.jta.JtaStatusHelper.isMarkedForRollback",
	"Comment": "does the given status code indicate the transaction has been marked for rollback?",
	"Method": "boolean isMarkedForRollback(int status){\r\n    return status == Status.STATUS_MARKED_ROLLBACK;\r\n}"
}, {
	"Path": "hex.genmodel.easy.exception.PredictUnknownCategoricalLevelException.getUnknownLevel",
	"Comment": "get the unknown level which was not seen during model training.",
	"Method": "String getUnknownLevel(){\r\n    return unknownLevel;\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.NaturalIdXrefDelegate.validateNaturalId",
	"Comment": "invariant validate of the natural id.checks include\tthat the entity defines a natural id\tthe number of natural id values matches the expected number",
	"Method": "void validateNaturalId(EntityPersister persister,Object[] naturalIdValues){\r\n    if (!persister.hasNaturalIdentifier()) {\r\n        throw new IllegalArgumentException(\"Entity did not define a natrual-id\");\r\n    }\r\n    if (persister.getNaturalIdentifierProperties().length != naturalIdValues.length) {\r\n        throw new IllegalArgumentException(\"Mismatch between expected number of natural-id values and found.\");\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.event.internal.ProxyVisitor.isOwnerUnchanged",
	"Comment": "has the owner of the collection changed since the collection\twas snapshotted and detached?",
	"Method": "boolean isOwnerUnchanged(PersistentCollection snapshot,CollectionPersister persister,Serializable id){\r\n    return isCollectionSnapshotValid(snapshot) && persister.getRole().equals(snapshot.getRole()) && id.equals(snapshot.getKey());\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.ActionQueue.areInsertionsOrDeletionsQueued",
	"Comment": "check whether any insertion or deletion actions are currently queued.",
	"Method": "boolean areInsertionsOrDeletionsQueued(){\r\n    return (insertions != null && !insertions.isEmpty()) || hasUnresolvedEntityInsertActions() || (deletions != null && !deletions.isEmpty()) || (orphanRemovals != null && !orphanRemovals.isEmpty());\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.HqlParser.handleIdentifierError",
	"Comment": "overrides the base behavior to retry keywords as identifiers.",
	"Method": "AST handleIdentifierError(Token token,RecognitionException ex){\r\n    if (token instanceof HqlToken) {\r\n        HqlToken hqlToken = (HqlToken) token;\r\n        if (hqlToken.isPossibleID() && (ex instanceof MismatchedTokenException)) {\r\n            MismatchedTokenException mte = (MismatchedTokenException) ex;\r\n            if (mte.expecting == HqlTokenTypes.IDENT) {\r\n                reportWarning(\"Keyword  '\" + token.getText() + \"' is being interpreted as an identifier due to: \" + mte.getMessage());\r\n                ASTPair currentAST = new ASTPair();\r\n                token.setType(HqlTokenTypes.WEIRD_IDENT);\r\n                astFactory.addASTChild(currentAST, astFactory.create(token));\r\n                consume();\r\n                return currentAST.root;\r\n            }\r\n        }\r\n    }\r\n    return super.handleIdentifierError(token, ex);\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.ResultVariableRefNode.setSelectExpression",
	"Comment": "set the select expression that defines the result variable.",
	"Method": "void setSelectExpression(SelectExpression selectExpression){\r\n    if (selectExpression == null || selectExpression.getAlias() == null) {\r\n        throw new SemanticException(\"A ResultVariableRefNode must refer to a non-null alias.\");\r\n    }\r\n    this.selectExpression = selectExpression;\r\n}"
}, {
	"Path": "org.hibernate.Query.setTimestamp",
	"Comment": "bind the value and the time of a given date object to a named query parameter.",
	"Method": "Query<R> setTimestamp(int position,Date val,Query<R> setTimestamp,String name,Date value){\r\n    setParameter(name, value, TimestampType.INSTANCE);\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.internal.SessionImpl.instantiate",
	"Comment": "give the interceptor an opportunity to override the default instantiation",
	"Method": "Object instantiate(String entityName,Serializable id,Object instantiate,EntityPersister persister,Serializable id){\r\n    checkOpenOrWaitingForAutoClose();\r\n    checkTransactionSynchStatus();\r\n    Object result = getInterceptor().instantiate(persister.getEntityName(), persister.getEntityMetamodel().getEntityMode(), id);\r\n    if (result == null) {\r\n        result = persister.instantiate(id, this);\r\n    }\r\n    delayedAfterCompletion();\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.metadata.ClassMetadata.instantiate",
	"Comment": "create a class instance initialized with the given identifier",
	"Method": "Object instantiate(Serializable id,SessionImplementor session,Object instantiate,Serializable id,SharedSessionContractImplementor session){\r\n    return instantiate(id, (SharedSessionContractImplementor) session);\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.ASTUtil.generateTokenNameCache",
	"Comment": "method to generate a map of token type names, keyed by their token type values.",
	"Method": "String[] generateTokenNameCache(Class tokenTypeInterface){\r\n    final Field[] fields = tokenTypeInterface.getFields();\r\n    final String[] names = new String[fields.length + 2];\r\n    for (final Field field : fields) {\r\n        if (Modifier.isStatic(field.getModifiers())) {\r\n            int idx = 0;\r\n            try {\r\n                idx = field.getInt(null);\r\n            } catch (IllegalAccessException e) {\r\n                throw new HibernateError(\"Initialization error\", e);\r\n            }\r\n            String fieldName = field.getName();\r\n            names[idx] = fieldName;\r\n        }\r\n    }\r\n    return names;\r\n}"
}, {
	"Path": "org.hibernate.id.enhanced.OptimizerFactory.isPooledOptimizer",
	"Comment": "does the given optimizer name represent a pooled strategy?",
	"Method": "boolean isPooledOptimizer(String optimizerName){\r\n    final StandardOptimizerDescriptor standardDescriptor = StandardOptimizerDescriptor.fromExternalName(optimizerName);\r\n    return standardDescriptor != null && standardDescriptor.isPooled();\r\n}"
}, {
	"Path": "org.hibernate.cfg.beanvalidation.BeanValidationIntegrator.validateMissingBeanValidationApi",
	"Comment": "used to validate the case when the bean validation api is not available.",
	"Method": "void validateMissingBeanValidationApi(Set<ValidationMode> modes){\r\n    if (modes.contains(ValidationMode.CALLBACK)) {\r\n        throw new IntegrationException(\"Bean Validation API was not available, but 'callback' validation was requested\");\r\n    }\r\n    if (modes.contains(ValidationMode.DDL)) {\r\n        throw new IntegrationException(\"Bean Validation API was not available, but 'ddl' validation was requested\");\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.supportsLockTimeouts",
	"Comment": "informational metadata about whether this dialect is known to support\tspecifying timeouts for requested lock acquisitions.",
	"Method": "boolean supportsLockTimeouts(){\r\n    return true;\r\n}"
}, {
	"Path": "water.rapids.SortTest.testSortOneColumn",
	"Comment": "test sorting of integers and floats of small magnitude, 2^30 and no nans or infs",
	"Method": "void testSortOneColumn(String fileWithPath,int colIndex,boolean addNas,boolean addInfs){\r\n    Scope.enter();\r\n    Frame fr = null, sortedInt = null, sortedFloat = null;\r\n    try {\r\n        fr = parse_test_file(fileWithPath);\r\n        if (addNas) {\r\n            Random _rand = new Random();\r\n            int randRange = Math.min(10, (int) fr.numRows());\r\n            int numNAs = _rand.nextInt(randRange) + 1;\r\n            for (int index = 0; index < numNAs; index++) {\r\n                fr.vec(colIndex).setNA(_rand.nextInt((int) fr.numRows()));\r\n            }\r\n        }\r\n        if (addInfs && fr.vec(colIndex).isNumeric() && !fr.vec(colIndex).isInt()) {\r\n            Random _rand = new Random();\r\n            int infRange = Math.min(10, (int) fr.numRows());\r\n            int numInfs = _rand.nextInt(infRange) + 1;\r\n            for (int index = 0; index < numInfs; index++) {\r\n                fr.vec(colIndex).set(_rand.nextInt((int) fr.numRows()), Double.POSITIVE_INFINITY);\r\n                fr.vec(colIndex).set(_rand.nextInt((int) fr.numRows()), Double.NEGATIVE_INFINITY);\r\n            }\r\n        }\r\n        Scope.track(fr);\r\n        sortedInt = fr.sort(new int[] { colIndex });\r\n        Scope.track(sortedInt);\r\n        testSort(sortedInt, fr, colIndex);\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.custom.FetchReturn.getOwner",
	"Comment": "retrieves the return descriptor for the owner of this fetch.",
	"Method": "NonScalarReturn getOwner(){\r\n    return owner;\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.loadSingleRow",
	"Comment": "loads a single row from the result set.this is the processing used from the\tscrollableresults where no collection fetches were encountered.",
	"Method": "Object loadSingleRow(ResultSet resultSet,SharedSessionContractImplementor session,QueryParameters queryParameters,boolean returnProxies){\r\n    final int entitySpan = getEntityPersisters().length;\r\n    final List hydratedObjects = entitySpan == 0 ? null : new ArrayList(entitySpan);\r\n    final Object result;\r\n    try {\r\n        result = getRowFromResultSet(resultSet, session, queryParameters, getLockModes(queryParameters.getLockOptions()), null, hydratedObjects, new EntityKey[entitySpan], returnProxies);\r\n    } catch (SQLException sqle) {\r\n        throw factory.getJdbcServices().getSqlExceptionHelper().convert(sqle, \"could not read next row of results\", getSQLString());\r\n    }\r\n    initializeEntitiesAndCollections(hydratedObjects, resultSet, session, queryParameters.isReadOnly(session));\r\n    session.getPersistenceContext().initializeNonLazyCollections();\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.persister.entity.AbstractEntityPersister.getPropertiesToUpdate",
	"Comment": "transform the array of property indexes to an array of booleans,\ttrue when the property is dirty",
	"Method": "boolean[] getPropertiesToUpdate(int[] dirtyProperties,boolean hasDirtyCollection){\r\n    final boolean[] propsToUpdate = new boolean[entityMetamodel.getPropertySpan()];\r\n    final boolean[] updateability = getPropertyUpdateability();\r\n    for (int j = 0; j < dirtyProperties.length; j++) {\r\n        int property = dirtyProperties[j];\r\n        if (updateability[property]) {\r\n            propsToUpdate[property] = true;\r\n        }\r\n    }\r\n    if (isVersioned() && updateability[getVersionProperty()]) {\r\n        propsToUpdate[getVersionProperty()] = Versioning.isVersionIncrementRequired(dirtyProperties, hasDirtyCollection, getPropertyVersionability());\r\n    }\r\n    return propsToUpdate;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.applyLocksToSql",
	"Comment": "modifies the given sql by applying the appropriate updates for the specified\tlock modes and key columns.\tthe behavior here is that of an ansi sql select for update.this\tmethod is really intended to allow dialects which do not support\tselect for update to achieve this in their own fashion.",
	"Method": "String applyLocksToSql(String sql,LockOptions aliasedLockOptions,Map<String, String[]> keyColumnNames){\r\n    return sql + new ForUpdateFragment(this, aliasedLockOptions, keyColumnNames).toFragmentString();\r\n}"
}, {
	"Path": "water.persist.PersistS3.decodeKey",
	"Comment": "decodes the given h2o key to the s3 bucket and key name. returns the array of two strings,first one is the bucket name and second one is the key name.",
	"Method": "String[] decodeKey(Key k){\r\n    return decodeKeyImpl(k);\r\n}"
}, {
	"Path": "water.util.Timer.time",
	"Comment": "return the difference between when the timer was created and the current time.",
	"Method": "long time(){\r\n    return System.currentTimeMillis() - _start;\r\n}"
}, {
	"Path": "org.hibernate.dialect.HSQLDialect.getCreateSequenceString",
	"Comment": "hsql will start with 0, by default.in order for hibernate to know that this not transient,\tmanually start with 1.",
	"Method": "String getCreateSequenceString(String sequenceName,String getCreateSequenceString,String sequenceName,int initialValue,int incrementSize){\r\n    if (supportsPooledSequences()) {\r\n        return \"create sequence \" + sequenceName + \" start with \" + initialValue + \" increment by \" + incrementSize;\r\n    }\r\n    throw new MappingException(getClass().getName() + \" does not support pooled sequences\");\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.SessionFactoryImplementor.getSQLExceptionConverter",
	"Comment": "retrieves the sqlexceptionconverter in effect for this sessionfactory.",
	"Method": "SQLExceptionConverter getSQLExceptionConverter(){\r\n    return getServiceRegistry().getService(JdbcServices.class).getSqlExceptionHelper().getSqlExceptionConverter();\r\n}"
}, {
	"Path": "org.hibernate.loader.criteria.CriteriaQueryTranslator.getColumnsUsingProjection",
	"Comment": "get the names of the columns constrained\tby this criterion.",
	"Method": "String[] getColumnsUsingProjection(Criteria subcriteria,String propertyName){\r\n    final Projection projection = rootCriteria.getProjection();\r\n    String[] projectionColumns = null;\r\n    if (projection != null) {\r\n        projectionColumns = (projection instanceof EnhancedProjection ? ((EnhancedProjection) projection).getColumnAliases(propertyName, 0, rootCriteria, this) : projection.getColumnAliases(propertyName, 0));\r\n    }\r\n    if (projectionColumns == null) {\r\n        try {\r\n            return getColumns(propertyName, subcriteria);\r\n        } catch (HibernateException he) {\r\n            if (outerQueryTranslator != null) {\r\n                return outerQueryTranslator.getColumnsUsingProjection(subcriteria, propertyName);\r\n            } else {\r\n                throw he;\r\n            }\r\n        }\r\n    } else {\r\n        return projectionColumns;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.event.internal.DefaultFlushEntityEventListener.getNextVersion",
	"Comment": "convenience method to retrieve an entities next version value",
	"Method": "Object getNextVersion(FlushEntityEvent event){\r\n    EntityEntry entry = event.getEntityEntry();\r\n    EntityPersister persister = entry.getPersister();\r\n    if (persister.isVersioned()) {\r\n        Object[] values = event.getPropertyValues();\r\n        if (entry.isBeingReplicated()) {\r\n            return Versioning.getVersion(values, persister);\r\n        } else {\r\n            int[] dirtyProperties = event.getDirtyProperties();\r\n            final boolean isVersionIncrementRequired = isVersionIncrementRequired(event, entry, persister, dirtyProperties);\r\n            final Object nextVersion = // use the current version\r\n            isVersionIncrementRequired ? Versioning.increment(entry.getVersion(), persister.getVersionType(), event.getSession()) : entry.getVersion();\r\n            Versioning.setVersion(values, nextVersion, persister);\r\n            return nextVersion;\r\n        }\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.QueryTranslatorImpl.scroll",
	"Comment": "return the query results, as an instance of scrollableresults",
	"Method": "ScrollableResultsImplementor scroll(QueryParameters queryParameters,SharedSessionContractImplementor session){\r\n    errorIfDML();\r\n    return queryLoader.scroll(queryParameters, session);\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.CollectionEntry.resetStoredSnapshot",
	"Comment": "reset the stored snapshot for both the persistent collection and this collection entry. \tused during the merge of detached collections.",
	"Method": "void resetStoredSnapshot(PersistentCollection collection,Serializable storedSnapshot){\r\n    LOG.debugf(\"Reset storedSnapshot to %s for %s\", storedSnapshot, this);\r\n    if (fromMerge) {\r\n        return;\r\n    }\r\n    snapshot = storedSnapshot;\r\n    collection.setSnapshot(loadedKey, role, snapshot);\r\n    fromMerge = true;\r\n}"
}, {
	"Path": "org.hibernate.tuple.PropertyFactory.buildIdentifierAttribute",
	"Comment": "generates the attribute representation of the identifier for a given entity mapping.",
	"Method": "IdentifierProperty buildIdentifierAttribute(PersistentClass mappedEntity,IdentifierGenerator generator){\r\n    String mappedUnsavedValue = mappedEntity.getIdentifier().getNullValue();\r\n    Type type = mappedEntity.getIdentifier().getType();\r\n    Property property = mappedEntity.getIdentifierProperty();\r\n    IdentifierValue unsavedValue = UnsavedValueFactory.getUnsavedIdentifierValue(mappedUnsavedValue, getGetter(property), type, getConstructor(mappedEntity));\r\n    if (property == null) {\r\n        return new IdentifierProperty(type, mappedEntity.hasEmbeddedIdentifier(), mappedEntity.hasIdentifierMapper(), unsavedValue, generator);\r\n    } else {\r\n        return new IdentifierProperty(property.getName(), type, mappedEntity.hasEmbeddedIdentifier(), unsavedValue, generator);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.exec.internal.AbstractLoadPlanBasedLoader.advance",
	"Comment": "advance the cursor to the first required row of the resultset",
	"Method": "void advance(ResultSet rs,RowSelection selection){\r\n    final int firstRow = LimitHelper.getFirstRow(selection);\r\n    if (firstRow != 0) {\r\n        if (getFactory().getSettings().isScrollableResultSetsEnabled()) {\r\n            rs.absolute(firstRow);\r\n        } else {\r\n            for (int m = 0; m < firstRow; m++) {\r\n                rs.next();\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.ColumnHelper.generateScalarColumns",
	"Comment": "generates the scalar column ast nodes for a given array of sql columns",
	"Method": "void generateScalarColumns(HqlSqlWalkerNode node,String[] sqlColumns,int i){\r\n    if (sqlColumns.length == 1) {\r\n        generateSingleScalarColumn(node, i);\r\n    } else {\r\n        ASTFactory factory = node.getASTFactory();\r\n        AST n = node;\r\n        n.setText(sqlColumns[0]);\r\n        for (int j = 0; j < sqlColumns.length; j++) {\r\n            if (j > 0) {\r\n                n = ASTUtil.createSibling(factory, SqlTokenTypes.SQL_TOKEN, sqlColumns[j], n);\r\n            }\r\n            n = ASTUtil.createSibling(factory, SqlTokenTypes.SELECT_COLUMNS, \" as \" + NameGenerator.scalarName(i, j), n);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.tool.hbm2ddl.SchemaUpdate.getExceptions",
	"Comment": "returns a list of all exceptions which occurred during the export.",
	"Method": "List getExceptions(){\r\n    return exceptions;\r\n}"
}, {
	"Path": "water.fvec.NewVectorTest.testCompression",
	"Comment": "test that various collections of parsed numbers compress as expected.",
	"Method": "void testCompression(){\r\n    testImpl(new long[] { 120, 12, 120 }, new int[] { 0, 1, 0 }, C0LChunk.class, false);\r\n    testImpl(new long[] { 122, 3, 44 }, new int[] { 0, 0, 0 }, C1NChunk.class, false);\r\n    testImpl(new long[] { 1, 0, 1 }, new int[] { 0, 0, 0 }, CBSChunk.class, false);\r\n    testImpl(new long[] { 122, -3, 44 }, new int[] { -1, 0, -1 }, C1SChunk.class, true);\r\n    testImpl(new long[] { 1000, 200, 30 }, new int[] { 0, 1, 2 }, C1SChunk.class, false);\r\n    testImpl(new long[] { 1000, 200, 32767, -32767, 32 }, new int[] { 0, 1, 0, 0, 3 }, C2Chunk.class, false);\r\n    testImpl(new long[] { 50100, 50101, 50123, 49999 }, new int[] { 0, 0, 0, 0 }, C1SChunk.class, false);\r\n    testImpl(new long[] { 51000, 50101, 50123, 49999 }, new int[] { 0, 0, 0, 0 }, C2SChunk.class, false);\r\n    testImpl(new long[] { 501000, 501001, 50123, 49999 }, new int[] { -1, -1, 0, 0 }, C2SChunk.class, true);\r\n    testImpl(new long[] { 123456, 2345678, 34567890 }, new int[] { 0, 0, 0 }, C4Chunk.class, false);\r\n    testImpl(new long[] { 1234, 2345, 314 }, new int[] { -1, -5, -2 }, C4SChunk.class, true);\r\n    testImpl(new long[] { 1234, 2345678, 31415 }, new int[] { 40, 10, -40 }, C8DChunk.class, true);\r\n    testImpl(new long[] { -581504, -477862, 342349 }, new int[] { -5, -18, -5 }, C8DChunk.class, true);\r\n}"
}, {
	"Path": "org.hibernate.boot.model.naming.NamingHelper.generateHashedConstraintName",
	"Comment": "if a constraint is not explicitly named, this is called to generate\ta unique hash using the table and column names.",
	"Method": "String generateHashedConstraintName(String prefix,Identifier tableName,Identifier columnNames,String generateHashedConstraintName,String prefix,Identifier tableName,List<Identifier> columnNames){\r\n    Identifier[] columnNamesArray = new Identifier[columnNames.size()];\r\n    for (int i = 0; i < columnNames.size(); i++) {\r\n        columnNamesArray[i] = columnNames.get(i);\r\n    }\r\n    return generateHashedConstraintName(prefix, tableName, columnNamesArray);\r\n}"
}, {
	"Path": "org.hibernate.event.internal.AbstractSaveEventListener.isVersionIncrementDisabled",
	"Comment": "after the save, will te version number be incremented\tif the instance is modified?",
	"Method": "boolean isVersionIncrementDisabled(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.SerializableNClobProxy.getProxyClassLoader",
	"Comment": "determines the appropriate class loader to which the generated proxy\tshould be scoped.",
	"Method": "ClassLoader getProxyClassLoader(){\r\n    return SerializableClobProxy.getProxyClassLoader();\r\n}"
}, {
	"Path": "water.jdbc.SQLManagerTest.testConnectionPoolSizeZeroProcessors",
	"Comment": "tests if there is at least one connection in the pool instantiated for each node, even if number of availableprocessors is a number lower than 1.",
	"Method": "void testConnectionPoolSizeZeroProcessors(){\r\n    int maxConnectionsPerNode = SQLManager.ConnectionPoolProvider.getMaxConnectionsPerNode(1, (short) -1, 10);\r\n    Assert.assertEquals(1, maxConnectionsPerNode);\r\n}"
}, {
	"Path": "org.hibernate.boot.jaxb.Origin.getName",
	"Comment": "the name of the document origin.interpretation is relative to the type, but might be the\tresource name or file url.",
	"Method": "String getName(){\r\n    return name;\r\n}"
}, {
	"Path": "water.util.JCodeGen.toClassWithArray",
	"Comment": "generates a new class with one static member called values whichis filled by values of given array.the generator can generate more classes to avoid limit of class constantpool holding all generated literals.",
	"Method": "JCodeSB toClassWithArray(JCodeSB sb,String modifiers,String className,String[] values,String comment,JCodeSB toClassWithArray,JCodeSB sb,String modifiers,String className,String[] values,JCodeSB toClassWithArray,JCodeSB sb,String modifiers,String className,double[] values,String comment,JCodeSB toClassWithArray,JCodeSB sb,String modifiers,String className,double[] values,JCodeSB toClassWithArray,JCodeSB sb,String modifiers,String className,float[] values,String comment,JCodeSB toClassWithArray,JCodeSB sb,String modifiers,String className,float[] values,JCodeSB toClassWithArray,JCodeSB sb,String modifiers,String className,int[] values,String comment,JCodeSB toClassWithArray,JCodeSB sb,String modifiers,String className,int[] values,JCodeSB toClassWithArray,JCodeSB sb,String modifiers,String className,double[][] values,String comment,JCodeSB toClassWithArray,JCodeSB sb,String modifiers,String className,double[][] values,JCodeSB toClassWithArray,JCodeSB sb,String modifiers,String className,double[][][] values,String comment){\r\n    if (comment != null) {\r\n        sb.p(\"// \").p(comment).nl();\r\n    }\r\n    sb.ip(modifiers != null ? modifiers + \" \" : \"\").p(\"class \").p(className).p(\" implements java.io.Serializable {\").nl().ii(1);\r\n    sb.ip(\"public static final double[][][] VALUES = \");\r\n    if (values == null)\r\n        sb.p(\"null;\").nl();\r\n    else {\r\n        sb.p(\"new double[\").p(values.length).p(\"][][];\").nl();\r\n        int s = 0;\r\n        int remain = values.length;\r\n        int its = 0;\r\n        SB sb4fillers = new SB().ci(sb);\r\n        sb.ip(\"static {\").ii(1).nl();\r\n        while (remain > 0) {\r\n            String subClzName = className + \"_\" + its++;\r\n            int len = Math.min(MAX_STRINGS_IN_CONST_POOL, remain);\r\n            toClassWithArrayFill(sb4fillers, subClzName, values, s, len);\r\n            sb.ip(subClzName).p(\".fill(VALUES);\").nl();\r\n            s += len;\r\n            remain -= len;\r\n        }\r\n        sb.di(1).ip(\"}\").nl();\r\n        sb.p(sb4fillers);\r\n    }\r\n    return sb.di(1).p(\"}\").nl();\r\n}"
}, {
	"Path": "org.hibernate.criterion.Projections.sqlGroupProjection",
	"Comment": "a grouping sql projection, specifying both select clause and group by clause fragments",
	"Method": "Projection sqlGroupProjection(String sql,String groupBy,String[] columnAliases,Type[] types){\r\n    return new SQLProjection(sql, groupBy, columnAliases, types);\r\n}"
}, {
	"Path": "water.rapids.ast.prims.mungers.AstGetrowTest.TestGetrow",
	"Comment": "test that in normal case the result has the correct type and value.",
	"Method": "void TestGetrow(){\r\n    Frame f = null;\r\n    try {\r\n        f = ArrayUtils.frame(ar(\"A\", \"B\", \"C\", \"D\", \"E\"), ard(1.0, -3, 12, 1000000, Double.NaN));\r\n        Val v = Rapids.exec(\"(getrow \" + f._key + \")\");\r\n        assertTrue(v instanceof ValRow);\r\n        double[] row = v.getRow();\r\n        assertEquals(row.length, 5);\r\n        assertArrayEquals(ard(1.0, -3, 12, 1000000, Double.NaN), row, 1e-8);\r\n    } finally {\r\n        if (f != null)\r\n            f.delete();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.criterion.DetachedCriteria.getExecutableCriteria",
	"Comment": "get an executable instance of criteria to actually run the query.",
	"Method": "Criteria getExecutableCriteria(Session session){\r\n    impl.setSession((SessionImplementor) session);\r\n    return impl;\r\n}"
}, {
	"Path": "org.hibernate.persister.collection.OneToManyPersister.generateDeleteString",
	"Comment": "generate the sql update that updates all the foreign keys to null",
	"Method": "String generateDeleteString(){\r\n    final Update update = new Update(getDialect()).setTableName(qualifiedTableName).addColumns(keyColumnNames, \"null\").addPrimaryKeyColumns(keyColumnNames);\r\n    if (hasIndex && !indexContainsFormula) {\r\n        for (int i = 0; i < indexColumnNames.length; i++) {\r\n            if (indexColumnIsSettable[i]) {\r\n                update.addColumn(indexColumnNames[i], \"null\");\r\n            }\r\n        }\r\n    }\r\n    if (hasWhere) {\r\n        update.setWhere(sqlWhereString);\r\n    }\r\n    if (getFactory().getSessionFactoryOptions().isCommentsEnabled()) {\r\n        update.setComment(\"delete one-to-many \" + getRole());\r\n    }\r\n    return update.toStatementString();\r\n}"
}, {
	"Path": "water.util.MathUtils.compareUnsigned",
	"Comment": "comparision of 128bit unsigned values represented by 2 longs",
	"Method": "int compareUnsigned(long a,long b,int compareUnsigned,long hiA,long loA,long hiB,long loB){\r\n    int resHi = compareUnsigned(hiA, hiB);\r\n    int resLo = compareUnsigned(loA, loB);\r\n    return resHi != 0 ? resHi : resLo;\r\n}"
}, {
	"Path": "water.rapids.ast.prims.reducers.AstSumAxis.rowwiseSum",
	"Comment": "compute frame sum for each row. this returns a frame consisting of a single vec of sums in each row.",
	"Method": "ValFrame rowwiseSum(Frame fr,boolean na_rm){\r\n    String[] newnames = { \"sum\" };\r\n    Key<Frame> newkey = Key.make();\r\n    int n_numeric = 0, n_time = 0;\r\n    for (Vec vec : fr.vecs()) {\r\n        if (vec.isNumeric())\r\n            n_numeric++;\r\n        if (vec.isTime())\r\n            n_time++;\r\n    }\r\n    byte resType = n_numeric > 0 ? Vec.T_NUM : Vec.T_TIME;\r\n    Frame compFrame = new Frame();\r\n    for (int i = 0; i < fr.numCols(); i++) {\r\n        Vec vec = fr.vec(i);\r\n        if (n_numeric > 0 ? vec.isNumeric() : vec.isTime())\r\n            compFrame.add(fr.name(i), vec);\r\n    }\r\n    Vec anyvec = compFrame.anyVec();\r\n    if (anyvec == null) {\r\n        Frame res = new Frame(newkey);\r\n        anyvec = fr.anyVec();\r\n        if (anyvec != null) {\r\n            res.add(\"sum\", anyvec.makeCon(Double.NaN));\r\n        }\r\n        return new ValFrame(res);\r\n    }\r\n    if (!na_rm && n_numeric < fr.numCols() && n_time < fr.numCols()) {\r\n        Frame res = new Frame(newkey, newnames, new Vec[] { anyvec.makeCon(Double.NaN) });\r\n        return new ValFrame(res);\r\n    }\r\n    final int numCols = compFrame.numCols();\r\n    Frame res = new MRTask() {\r\n        @Override\r\n        public void map(Chunk[] cs, NewChunk nc) {\r\n            for (int i = 0; i < cs[0]._len; i++) {\r\n                double d = 0;\r\n                int numNaColumns = 0;\r\n                for (int j = 0; j < numCols; j++) {\r\n                    double val = cs[j].atd(i);\r\n                    if (Double.isNaN(val))\r\n                        numNaColumns++;\r\n                    else\r\n                        d += val;\r\n                }\r\n                if (na_rm ? numNaColumns < numCols : numNaColumns == 0)\r\n                    nc.addNum(d);\r\n                else\r\n                    nc.addNum(Double.NaN);\r\n            }\r\n        }\r\n    }.doAll(1, resType, compFrame).outputFrame(newkey, newnames, null);\r\n    return new ValFrame(res);\r\n}"
}, {
	"Path": "water.rapids.ast.prims.reducers.AstSumAxis.rowwiseSum",
	"Comment": "compute frame sum for each row. this returns a frame consisting of a single vec of sums in each row.",
	"Method": "ValFrame rowwiseSum(Frame fr,boolean na_rm){\r\n    for (int i = 0; i < cs[0]._len; i++) {\r\n        double d = 0;\r\n        int numNaColumns = 0;\r\n        for (int j = 0; j < numCols; j++) {\r\n            double val = cs[j].atd(i);\r\n            if (Double.isNaN(val))\r\n                numNaColumns++;\r\n            else\r\n                d += val;\r\n        }\r\n        if (na_rm ? numNaColumns < numCols : numNaColumns == 0)\r\n            nc.addNum(d);\r\n        else\r\n            nc.addNum(Double.NaN);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cfg.beanvalidation.BeanValidationIntegrator.validateFactory",
	"Comment": "used to validate the type of an explicitly passed validatorfactory instance",
	"Method": "void validateFactory(Object object){\r\n    try {\r\n        final Class activatorClass = BeanValidationIntegrator.class.getClassLoader().loadClass(ACTIVATOR_CLASS_NAME);\r\n        try {\r\n            final Method validateMethod = activatorClass.getMethod(VALIDATE_SUPPLIED_FACTORY_METHOD_NAME, Object.class);\r\n            try {\r\n                validateMethod.invoke(null, object);\r\n            } catch (InvocationTargetException e) {\r\n                if (e.getTargetException() instanceof HibernateException) {\r\n                    throw (HibernateException) e.getTargetException();\r\n                }\r\n                throw new HibernateException(\"Unable to check validity of passed ValidatorFactory\", e);\r\n            } catch (IllegalAccessException e) {\r\n                throw new HibernateException(\"Unable to check validity of passed ValidatorFactory\", e);\r\n            }\r\n        } catch (HibernateException e) {\r\n            throw e;\r\n        } catch (Exception e) {\r\n            throw new HibernateException(\"Could not locate method needed for ValidatorFactory validation\", e);\r\n        }\r\n    } catch (HibernateException e) {\r\n        throw e;\r\n    } catch (Exception e) {\r\n        throw new HibernateException(\"Could not locate TypeSafeActivator class\", e);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.internal.util.LockModeConverter.convertToLockMode",
	"Comment": "convert from jpa defined lockmodetype to hibernate specific lockmode.",
	"Method": "LockMode convertToLockMode(LockModeType lockMode){\r\n    switch(lockMode) {\r\n        case READ:\r\n        case OPTIMISTIC:\r\n            {\r\n                return LockMode.OPTIMISTIC;\r\n            }\r\n        case OPTIMISTIC_FORCE_INCREMENT:\r\n        case WRITE:\r\n            {\r\n                return LockMode.OPTIMISTIC_FORCE_INCREMENT;\r\n            }\r\n        case PESSIMISTIC_READ:\r\n            {\r\n                return LockMode.PESSIMISTIC_READ;\r\n            }\r\n        case PESSIMISTIC_WRITE:\r\n            {\r\n                return LockMode.PESSIMISTIC_WRITE;\r\n            }\r\n        case PESSIMISTIC_FORCE_INCREMENT:\r\n            {\r\n                return LockMode.PESSIMISTIC_FORCE_INCREMENT;\r\n            }\r\n        case NONE:\r\n            {\r\n                return LockMode.NONE;\r\n            }\r\n        default:\r\n            {\r\n                throw new AssertionFailure(\"Unknown LockModeType: \" + lockMode);\r\n            }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.getQueryIdentifier",
	"Comment": "identifies the query for statistics reporting, if null,\tno statistics will be reported",
	"Method": "String getQueryIdentifier(){\r\n    return null;\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.StatefulPersistenceContext.serialize",
	"Comment": "used by the owning session to explicitly control serialization of the\tpersistence context.",
	"Method": "void serialize(ObjectOutputStream oos){\r\n    final boolean tracing = LOG.isTraceEnabled();\r\n    if (tracing) {\r\n        LOG.trace(\"Serializing persistence-context\");\r\n    }\r\n    oos.writeBoolean(defaultReadOnly);\r\n    oos.writeBoolean(hasNonReadOnlyEntities);\r\n    oos.writeInt(entitiesByKey.size());\r\n    if (tracing) {\r\n        LOG.trace(\"Starting serialization of [\" + entitiesByKey.size() + \"] entitiesByKey entries\");\r\n    }\r\n    for (Map.Entry<EntityKey, Object> entry : entitiesByKey.entrySet()) {\r\n        entry.getKey().serialize(oos);\r\n        oos.writeObject(entry.getValue());\r\n    }\r\n    oos.writeInt(entitiesByUniqueKey.size());\r\n    if (tracing) {\r\n        LOG.trace(\"Starting serialization of [\" + entitiesByUniqueKey.size() + \"] entitiesByUniqueKey entries\");\r\n    }\r\n    for (Map.Entry<EntityUniqueKey, Object> entry : entitiesByUniqueKey.entrySet()) {\r\n        entry.getKey().serialize(oos);\r\n        oos.writeObject(entry.getValue());\r\n    }\r\n    oos.writeInt(proxiesByKey.size());\r\n    if (tracing) {\r\n        LOG.trace(\"Starting serialization of [\" + proxiesByKey.size() + \"] proxiesByKey entries\");\r\n    }\r\n    for (Map.Entry<EntityKey, Object> entry : proxiesByKey.entrySet()) {\r\n        entry.getKey().serialize(oos);\r\n        oos.writeObject(entry.getValue());\r\n    }\r\n    oos.writeInt(entitySnapshotsByKey.size());\r\n    if (tracing) {\r\n        LOG.trace(\"Starting serialization of [\" + entitySnapshotsByKey.size() + \"] entitySnapshotsByKey entries\");\r\n    }\r\n    for (Map.Entry<EntityKey, Object> entry : entitySnapshotsByKey.entrySet()) {\r\n        entry.getKey().serialize(oos);\r\n        oos.writeObject(entry.getValue());\r\n    }\r\n    entityEntryContext.serialize(oos);\r\n    oos.writeInt(collectionsByKey.size());\r\n    if (tracing) {\r\n        LOG.trace(\"Starting serialization of [\" + collectionsByKey.size() + \"] collectionsByKey entries\");\r\n    }\r\n    for (Map.Entry<CollectionKey, PersistentCollection> entry : collectionsByKey.entrySet()) {\r\n        entry.getKey().serialize(oos);\r\n        oos.writeObject(entry.getValue());\r\n    }\r\n    oos.writeInt(collectionEntries.size());\r\n    if (tracing) {\r\n        LOG.trace(\"Starting serialization of [\" + collectionEntries.size() + \"] collectionEntries entries\");\r\n    }\r\n    for (Map.Entry<PersistentCollection, CollectionEntry> entry : collectionEntries.entrySet()) {\r\n        oos.writeObject(entry.getKey());\r\n        entry.getValue().serialize(oos);\r\n    }\r\n    oos.writeInt(arrayHolders.size());\r\n    if (tracing) {\r\n        LOG.trace(\"Starting serialization of [\" + arrayHolders.size() + \"] arrayHolders entries\");\r\n    }\r\n    for (Map.Entry<Object, PersistentCollection> entry : arrayHolders.entrySet()) {\r\n        oos.writeObject(entry.getKey());\r\n        oos.writeObject(entry.getValue());\r\n    }\r\n    oos.writeInt(nullifiableEntityKeys.size());\r\n    if (tracing) {\r\n        LOG.trace(\"Starting serialization of [\" + nullifiableEntityKeys.size() + \"] nullifiableEntityKey entries\");\r\n    }\r\n    for (EntityKey entry : nullifiableEntityKeys) {\r\n        entry.serialize(oos);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cfg.AbstractPropertyHolder.getExactOverriddenColumn",
	"Comment": "get column overriding, property first, then parent, then holder\tfind the overridden rules from the exact property name.",
	"Method": "Column[] getExactOverriddenColumn(String propertyName){\r\n    Column[] override = null;\r\n    if (parent != null) {\r\n        override = parent.getExactOverriddenColumn(propertyName);\r\n    }\r\n    if (override == null && currentPropertyColumnOverride != null) {\r\n        override = currentPropertyColumnOverride.get(propertyName);\r\n    }\r\n    if (override == null && holderColumnOverride != null) {\r\n        override = holderColumnOverride.get(propertyName);\r\n    }\r\n    return override;\r\n}"
}, {
	"Path": "water.rapids.ast.prims.reducers.AstTopNTest.checkTopBottomN",
	"Comment": "helper function to compare test frame result with correct answer",
	"Method": "void checkTopBottomN(Frame answerF,Frame grabF,double tolerance,int grabTopN){\r\n    Scope.enter();\r\n    try {\r\n        double nfrac = (grabTopN < 0) ? 1.0 * grabF.numRows() / answerF.numRows() : (1 - 1.0 * grabF.numRows() / answerF.numRows());\r\n        SplitFrame sf = new SplitFrame(answerF, new double[] { nfrac, 1 - nfrac }, new Key[] { Key.make(\"topN.hex\"), Key.make(\"bottomN.hex\") });\r\n        sf.exec().get();\r\n        Key[] ksplits = sf._destination_frames;\r\n        Frame topN = (Frame) ((grabTopN < 0) ? DKV.get(ksplits[0]).get() : DKV.get(ksplits[1]).get());\r\n        double[] bottomN = FrameUtils.asDoubles(grabF.vec(0));\r\n        Arrays.sort(bottomN);\r\n        Frame sortedF = new water.util.ArrayUtils().frame(bottomN);\r\n        Scope.track(sortedF);\r\n        Frame sortedFT = DMatrix.transpose(sortedF);\r\n        Scope.track(sortedFT);\r\n        assertTrue(isIdenticalUpToRelTolerance(topN, sortedFT, tolerance));\r\n        Scope.track(topN);\r\n        Scope.track_generic(ksplits[0].get());\r\n        Scope.track_generic(ksplits[1].get());\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.event.internal.AbstractSaveEventListener.getEntityState",
	"Comment": "determine whether the entity is persistent, detached, or transient",
	"Method": "EntityState getEntityState(Object entity,String entityName,EntityEntry entry,SessionImplementor source){\r\n    final boolean traceEnabled = LOG.isTraceEnabled();\r\n    if (entry != null) {\r\n        if (entry.getStatus() != Status.DELETED) {\r\n            if (traceEnabled) {\r\n                LOG.tracev(\"Persistent instance of: {0}\", getLoggableName(entityName, entity));\r\n            }\r\n            return EntityState.PERSISTENT;\r\n        }\r\n        if (traceEnabled) {\r\n            LOG.tracev(\"Deleted instance of: {0}\", getLoggableName(entityName, entity));\r\n        }\r\n        return EntityState.DELETED;\r\n    }\r\n    if (ForeignKeys.isTransient(entityName, entity, getAssumedUnsaved(), source)) {\r\n        if (traceEnabled) {\r\n            LOG.tracev(\"Transient instance of: {0}\", getLoggableName(entityName, entity));\r\n        }\r\n        return EntityState.TRANSIENT;\r\n    }\r\n    if (traceEnabled) {\r\n        LOG.tracev(\"Detached instance of: {0}\", getLoggableName(entityName, entity));\r\n    }\r\n    return EntityState.DETACHED;\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.eqAll",
	"Comment": "creates a criterion which checks that the value of a literal equals all the values in the\tsubquery result.",
	"Method": "Criterion eqAll(Object value,DetachedCriteria dc){\r\n    return new SimpleSubqueryExpression(value, \"=\", \"all\", dc);\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.NClobProxy.getProxyClassLoader",
	"Comment": "determines the appropriate class loader to which the generated proxy\tshould be scoped.",
	"Method": "ClassLoader getProxyClassLoader(){\r\n    return NClobImplementer.class.getClassLoader();\r\n}"
}, {
	"Path": "org.hibernate.pretty.MessageHelper.collectionInfoString",
	"Comment": "generate an info message string relating to a particular managed\tcollection.",
	"Method": "String collectionInfoString(CollectionPersister persister,PersistentCollection collection,Serializable collectionKey,SharedSessionContractImplementor session,String collectionInfoString,CollectionPersister persister,Serializable[] ids,SessionFactoryImplementor factory,String collectionInfoString,CollectionPersister persister,Serializable id,SessionFactoryImplementor factory,String collectionInfoString,String role,Serializable id){\r\n    StringBuilder s = new StringBuilder();\r\n    s.append('[');\r\n    if (role == null) {\r\n        s.append(\"<unreferenced>\");\r\n    } else {\r\n        s.append(role);\r\n        s.append('#');\r\n        if (id == null) {\r\n            s.append(\"<null>\");\r\n        } else {\r\n            s.append(id);\r\n        }\r\n    }\r\n    s.append(']');\r\n    return s.toString();\r\n}"
}, {
	"Path": "water.rapids.vals.ValRow.slice",
	"Comment": "creates a new valrow by selecting elements at the specified indices.",
	"Method": "ValRow slice(int[] cols){\r\n    double[] ds = new double[cols.length];\r\n    String[] ns = new String[cols.length];\r\n    for (int i = 0; i < cols.length; ++i) {\r\n        ds[i] = _ds[cols[i]];\r\n        ns[i] = _names[cols[i]];\r\n    }\r\n    return new ValRow(ds, ns);\r\n}"
}, {
	"Path": "hex.tree.xgboost.rabit.communication.XGBoostAutoBuffer.putStr",
	"Comment": "used to communicate with external frameworks, for example xgboost",
	"Method": "XGBoostAutoBuffer putStr(String s){\r\n    ab.put4(s.length());\r\n    byte[] a = StringUtils.bytesOf(s);\r\n    ab.putA1(a, a.length);\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.loader.custom.FetchReturn.getOwnerProperty",
	"Comment": "the name of the property on the owner which represents this association.",
	"Method": "String getOwnerProperty(){\r\n    return ownerProperty;\r\n}"
}, {
	"Path": "org.hibernate.bytecode.internal.javassist.BulkAccessorException.getIndex",
	"Comment": "returns the index of the property that causes this exception.",
	"Method": "int getIndex(){\r\n    return this.index;\r\n}"
}, {
	"Path": "org.hibernate.mapping.ForeignKey.isReferenceToPrimaryKey",
	"Comment": "does this foreignkey reference the primary key of the reference table",
	"Method": "boolean isReferenceToPrimaryKey(){\r\n    return referencedColumns.isEmpty();\r\n}"
}, {
	"Path": "org.hibernate.SharedSessionBuilder.flushBeforeCompletion",
	"Comment": "signifies that the flushbeforecompletion flag from the original session should be used to create the new session.",
	"Method": "T flushBeforeCompletion(T flushBeforeCompletion,boolean flushBeforeCompletion){\r\n    if (flushBeforeCompletion) {\r\n        flushMode(FlushMode.ALWAYS);\r\n    } else {\r\n        flushMode(FlushMode.MANUAL);\r\n    }\r\n    return (T) this;\r\n}"
}, {
	"Path": "hex.createframe.OriginalCreateFrameRecipeTest.testReproducibility",
	"Comment": "this test attempts to create the same dataset twice starting from the same seed, and then checks thatthe result came out exactly the same both times.we also verify that the test frame has multiple chunks, since most of the breakages will happen because ofnondeterministic chunk execution.",
	"Method": "void testReproducibility(){\r\n    CreateFrameOriginalIV4 s = new CreateFrameOriginalIV4().fillFromImpl();\r\n    s.rows = 5000;\r\n    s.cols = 20;\r\n    s.time_fraction = 0.1;\r\n    s.categorical_fraction = 0.2;\r\n    s.integer_fraction = 0.2;\r\n    s.binary_fraction = 0.2;\r\n    s.string_fraction = 0.1;\r\n    s.missing_fraction = 0.05;\r\n    s.has_response = false;\r\n    s.seed = (long) (Math.random() * 100000000000L);\r\n    Log.info(\"Using seed \" + s.seed);\r\n    Frame frame1 = s.createAndFillImpl().exec().get();\r\n    assertNotNull(frame1);\r\n    Log.info(frame1.toString());\r\n    assertTrue(\"Please adjust test parameters to have more than 1 chunk in the frame\", frame1.vec(0).nChunks() > 1);\r\n    Frame frame2 = s.createAndFillImpl().exec().get();\r\n    assertNotNull(frame2);\r\n    assertTrue(isBitIdentical(frame1, frame2));\r\n    frame1.delete();\r\n    frame2.delete();\r\n}"
}, {
	"Path": "water.persist.PersistS3.encodeKey",
	"Comment": "creates the key for given s3 bucket and key. returns the h2o key, or null if the key cannot becreated.",
	"Method": "Key encodeKey(String bucket,String key){\r\n    Key res = encodeKeyImpl(bucket, key);\r\n    return res;\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.ActionQueue.deserialize",
	"Comment": "used by the owning session to explicitly control deserialization of the action queue.",
	"Method": "ActionQueue deserialize(ObjectInputStream ois,SessionImplementor session){\r\n    final boolean traceEnabled = LOG.isTraceEnabled();\r\n    if (traceEnabled) {\r\n        LOG.trace(\"Deserializing action-queue\");\r\n    }\r\n    ActionQueue rtn = new ActionQueue(session);\r\n    rtn.unresolvedInsertions = UnresolvedEntityInsertActions.deserialize(ois, session);\r\n    for (ListProvider provider : EXECUTABLE_LISTS_MAP.values()) {\r\n        ExecutableList<?> l = provider.get(rtn);\r\n        boolean notNull = ois.readBoolean();\r\n        if (notNull) {\r\n            if (l == null) {\r\n                l = provider.init(rtn);\r\n            }\r\n            l.readExternal(ois);\r\n            if (traceEnabled) {\r\n                LOG.tracev(\"Deserialized [{0}] entries\", l.size());\r\n            }\r\n            l.afterDeserialize(session);\r\n        }\r\n    }\r\n    return rtn;\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.exec.process.internal.EntityReferenceInitializerImpl.readIdentifierHydratedState",
	"Comment": "read the identifier state for the entity reference for the currently processing row in the resultset",
	"Method": "Object readIdentifierHydratedState(ResultSet resultSet,ResultSetProcessingContext context){\r\n    try {\r\n        return entityReference.getEntityPersister().getIdentifierType().hydrate(resultSet, entityReferenceAliases.getColumnAliases().getSuffixedKeyAliases(), context.getSession(), null);\r\n    } catch (Exception e) {\r\n        throw new HibernateException(\"Encountered problem trying to hydrate identifier for entity [\" + entityReference.getEntityPersister() + \"]\", e);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.checkVersion",
	"Comment": "check the version of the object in the resultset against\tthe object version in the session cache, throwing an exception\tif the version numbers are different",
	"Method": "void checkVersion(int i,Loadable persister,Serializable id,Object entity,ResultSet rs,SharedSessionContractImplementor session){\r\n    Object version = session.getPersistenceContext().getEntry(entity).getVersion();\r\n    if (version != null) {\r\n        final VersionType versionType = persister.getVersionType();\r\n        final Object currentVersion = versionType.nullSafeGet(rs, getEntityAliases()[i].getSuffixedVersionAliases(), session, null);\r\n        if (!versionType.isEqual(version, currentVersion)) {\r\n            if (session.getFactory().getStatistics().isStatisticsEnabled()) {\r\n                session.getFactory().getStatistics().optimisticFailure(persister.getEntityName());\r\n            }\r\n            throw new StaleObjectStateException(persister.getEntityName(), id);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.Nullability.checkComponentNullability",
	"Comment": "check component nullability. returns property path that break\tnullability or null if none",
	"Method": "String checkComponentNullability(Object value,CompositeType compositeType){\r\n    if (compositeType.isAnyType()) {\r\n        return null;\r\n    }\r\n    final boolean[] nullability = compositeType.getPropertyNullability();\r\n    if (nullability != null) {\r\n        final Object[] subValues = compositeType.getPropertyValues(value, session);\r\n        final Type[] propertyTypes = compositeType.getSubtypes();\r\n        for (int i = 0; i < subValues.length; i++) {\r\n            final Object subValue = subValues[i];\r\n            if (!nullability[i] && subValue == null) {\r\n                return compositeType.getPropertyNames()[i];\r\n            } else if (subValue != null) {\r\n                final String breakProperties = checkSubElementsNullability(propertyTypes[i], subValue);\r\n                if (breakProperties != null) {\r\n                    return buildPropertyPath(compositeType.getPropertyNames()[i], breakProperties);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "hex.genmodel.GenModel.getModelCategories",
	"Comment": "override this for models that may produce results in different categories.",
	"Method": "EnumSet<ModelCategory> getModelCategories(){\r\n    return EnumSet.of(getModelCategory());\r\n}"
}, {
	"Path": "org.hibernate.boot.internal.InFlightMetadataCollectorImpl.buildMetadataInstance",
	"Comment": "builds the complete and immutable metadata instance from the collected info.",
	"Method": "MetadataImpl buildMetadataInstance(MetadataBuildingContext buildingContext){\r\n    processSecondPasses(buildingContext);\r\n    processExportableProducers();\r\n    try {\r\n        return new MetadataImpl(uuid, options, identifierGeneratorFactory, entityBindingMap, mappedSuperClasses, collectionBindingMap, typeDefinitionMap, filterDefinitionMap, fetchProfileMap, imports, idGeneratorDefinitionMap, namedQueryMap, namedNativeQueryMap, namedProcedureCallMap, sqlResultSetMappingMap, namedEntityGraphMap, sqlFunctionMap, getDatabase(), bootstrapContext);\r\n    } finally {\r\n        getBootstrapContext().release();\r\n    }\r\n}"
}, {
	"Path": "water.Value.makeNull",
	"Comment": "thus stall future puts overriding the deletion until the delete completes.",
	"Method": "Value makeNull(Key key){\r\n    assert key.home();\r\n    return new Value(key, 0, null, (short) 0, TCP);\r\n}"
}, {
	"Path": "water.util.ArrayUtils.maxIndex",
	"Comment": "returns the index of the largest value in the array.in case of a tie, an the index is selected randomly.",
	"Method": "int maxIndex(int[] from,Random rand,int maxIndex,float[] from,Random rand,int maxIndex,double[] from,Random rand,int maxIndex,int[] from,int maxIndex,long[] from,int maxIndex,long[] from,int off,int maxIndex,float[] from,int maxIndex,double[] from){\r\n    int result = 0;\r\n    for (int i = 1; i < from.length; ++i) if (from[i] > from[result])\r\n        result = i;\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.stat.QueryStatistics.getPlanCompilationTotalMicroseconds",
	"Comment": "the overall time spent to compile the plan for this particular query.",
	"Method": "long getPlanCompilationTotalMicroseconds(){\r\n    return 0;\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.HQLQueryPlan.performScroll",
	"Comment": "coordinates the efforts to perform a scroll across all the included query translators.",
	"Method": "ScrollableResultsImplementor performScroll(QueryParameters queryParameters,SharedSessionContractImplementor session){\r\n    if (traceEnabled) {\r\n        LOG.tracev(\"Iterate: {0}\", getSourceQuery());\r\n        queryParameters.traceParameters(session.getFactory());\r\n    }\r\n    if (translators.length != 1) {\r\n        throw new QueryException(\"implicit polymorphism not supported for scroll() queries\");\r\n    }\r\n    if (queryParameters.getRowSelection().definesLimits() && translators[0].containsCollectionFetches()) {\r\n        throw new QueryException(\"firstResult/maxResults not supported in conjunction with scroll() of a query containing collection fetches\");\r\n    }\r\n    return translators[0].scroll(queryParameters, session);\r\n}"
}, {
	"Path": "org.hibernate.tool.hbm2ddl.SchemaExport.getExceptions",
	"Comment": "returns a list of all exceptions which occurred during the export.",
	"Method": "List getExceptions(){\r\n    return exceptions;\r\n}"
}, {
	"Path": "org.hibernate.Query.setHibernateMaxResults",
	"Comment": "set the maximum number of query results to be retrieved. a value less than\tor equal to 0 is considered uninitialized, resulting in no limit on the number\tof results.",
	"Method": "Query setHibernateMaxResults(int maxResults){\r\n    if (maxResults <= 0) {\r\n        getQueryOptions().setMaxRows(null);\r\n    } else {\r\n        getQueryOptions().setMaxRows(maxResults);\r\n    }\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.dialect.HSQLDialect.dropConstraints",
	"Comment": "do not drop constraints explicitly, just do this by cascading instead.",
	"Method": "boolean dropConstraints(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.engine.loading.internal.LoadContexts.hasLoadingCollectionEntries",
	"Comment": "do we currently have any internal entries corresponding to loading\tcollections?",
	"Method": "boolean hasLoadingCollectionEntries(){\r\n    return (collectionLoadContexts != null && !collectionLoadContexts.isEmpty());\r\n}"
}, {
	"Path": "org.hibernate.bytecode.enhance.spi.interceptor.LazyAttributeDescriptor.getLazyIndex",
	"Comment": "access to the index of the attribute in terms of its position withing the lazy attributes of the persister",
	"Method": "int getLazyIndex(){\r\n    return lazyIndex;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getReadLockString",
	"Comment": "get the string to append to select statements to acquire read locks\tfor this dialect given the aliases of the columns to be read locked.\tlocation of the of the returned string is treated\tthe same as getforupdatestring.",
	"Method": "String getReadLockString(int timeout,String getReadLockString,String aliases,int timeout){\r\n    return getReadLockString(timeout);\r\n}"
}, {
	"Path": "org.hibernate.cfg.AnnotationBinder.bindClass",
	"Comment": "bind a class having jsr175 annotations. subclasses have to be bound after its parent class.",
	"Method": "void bindClass(XClass clazzToProcess,Map<XClass, InheritanceState> inheritanceStatePerClass,MetadataBuildingContext context){\r\n    if (clazzToProcess.isAnnotationPresent(Entity.class) && clazzToProcess.isAnnotationPresent(MappedSuperclass.class)) {\r\n        throw new AnnotationException(\"An entity cannot be annotated with both @Entity and @MappedSuperclass: \" + clazzToProcess.getName());\r\n    }\r\n    if (clazzToProcess.isAnnotationPresent(Inheritance.class) && clazzToProcess.isAnnotationPresent(MappedSuperclass.class)) {\r\n        throw new AnnotationException(\"An entity cannot be annotated with both @Inheritance and @MappedSuperclass: \" + clazzToProcess.getName());\r\n    }\r\n    InheritanceState inheritanceState = inheritanceStatePerClass.get(clazzToProcess);\r\n    AnnotatedClassType classType = context.getMetadataCollector().getClassType(clazzToProcess);\r\n    if (AnnotatedClassType.EMBEDDABLE_SUPERCLASS.equals(classType)) {\r\n        bindQueries(clazzToProcess, context);\r\n        bindTypeDefs(clazzToProcess, context);\r\n        bindFilterDefs(clazzToProcess, context);\r\n    }\r\n    if (!isEntityClassType(clazzToProcess, classType)) {\r\n        return;\r\n    }\r\n    if (LOG.isDebugEnabled()) {\r\n        LOG.debugf(\"Binding entity from annotated class: %s\", clazzToProcess.getName());\r\n    }\r\n    PersistentClass superEntity = getSuperEntity(clazzToProcess, inheritanceStatePerClass, context, inheritanceState);\r\n    if (superEntity != null && (clazzToProcess.getAnnotation(AttributeOverride.class) != null || clazzToProcess.getAnnotation(AttributeOverrides.class) != null)) {\r\n        throw new AnnotationException(\"An entity annotated with @Inheritance cannot use @AttributeOverride or @AttributeOverrides: \" + clazzToProcess.getName());\r\n    }\r\n    PersistentClass persistentClass = makePersistentClass(inheritanceState, superEntity, context);\r\n    Entity entityAnn = clazzToProcess.getAnnotation(Entity.class);\r\n    org.hibernate.annotations.Entity hibEntityAnn = clazzToProcess.getAnnotation(org.hibernate.annotations.Entity.class);\r\n    EntityBinder entityBinder = new EntityBinder(entityAnn, hibEntityAnn, clazzToProcess, persistentClass, context);\r\n    entityBinder.setInheritanceState(inheritanceState);\r\n    bindQueries(clazzToProcess, context);\r\n    bindFilterDefs(clazzToProcess, context);\r\n    bindTypeDefs(clazzToProcess, context);\r\n    bindFetchProfiles(clazzToProcess, context);\r\n    BinderHelper.bindAnyMetaDefs(clazzToProcess, context);\r\n    String schema = \"\";\r\n    String table = \"\";\r\n    String catalog = \"\";\r\n    List<UniqueConstraintHolder> uniqueConstraints = new ArrayList();\r\n    javax.persistence.Table tabAnn = null;\r\n    if (clazzToProcess.isAnnotationPresent(javax.persistence.Table.class)) {\r\n        tabAnn = clazzToProcess.getAnnotation(javax.persistence.Table.class);\r\n        table = tabAnn.name();\r\n        schema = tabAnn.schema();\r\n        catalog = tabAnn.catalog();\r\n        uniqueConstraints = TableBinder.buildUniqueConstraintHolders(tabAnn.uniqueConstraints());\r\n    }\r\n    Ejb3JoinColumn[] inheritanceJoinedColumns = makeInheritanceJoinColumns(clazzToProcess, context, inheritanceState, superEntity);\r\n    final Ejb3DiscriminatorColumn discriminatorColumn;\r\n    if (InheritanceType.SINGLE_TABLE.equals(inheritanceState.getType())) {\r\n        discriminatorColumn = processSingleTableDiscriminatorProperties(clazzToProcess, context, inheritanceState, entityBinder);\r\n    } else if (InheritanceType.JOINED.equals(inheritanceState.getType())) {\r\n        discriminatorColumn = processJoinedDiscriminatorProperties(clazzToProcess, context, inheritanceState, entityBinder);\r\n    } else {\r\n        discriminatorColumn = null;\r\n    }\r\n    entityBinder.setProxy(clazzToProcess.getAnnotation(Proxy.class));\r\n    entityBinder.setBatchSize(clazzToProcess.getAnnotation(BatchSize.class));\r\n    entityBinder.setWhere(clazzToProcess.getAnnotation(Where.class));\r\n    applyCacheSettings(entityBinder, clazzToProcess, context);\r\n    bindFilters(clazzToProcess, entityBinder, context);\r\n    entityBinder.bindEntity();\r\n    if (inheritanceState.hasTable()) {\r\n        Check checkAnn = clazzToProcess.getAnnotation(Check.class);\r\n        String constraints = checkAnn == null ? null : checkAnn.constraints();\r\n        EntityTableXref denormalizedTableXref = inheritanceState.hasDenormalizedTable() ? context.getMetadataCollector().getEntityTableXref(superEntity.getEntityName()) : null;\r\n        entityBinder.bindTable(schema, catalog, table, uniqueConstraints, constraints, denormalizedTableXref);\r\n    } else {\r\n        if (clazzToProcess.isAnnotationPresent(Table.class)) {\r\n            LOG.invalidTableAnnotation(clazzToProcess.getName());\r\n        }\r\n        if (inheritanceState.getType() == InheritanceType.SINGLE_TABLE) {\r\n            entityBinder.bindTableForDiscriminatedSubclass(context.getMetadataCollector().getEntityTableXref(superEntity.getEntityName()));\r\n        }\r\n    }\r\n    PropertyHolder propertyHolder = PropertyHolderBuilder.buildPropertyHolder(clazzToProcess, persistentClass, entityBinder, context, inheritanceStatePerClass);\r\n    javax.persistence.SecondaryTable secTabAnn = clazzToProcess.getAnnotation(javax.persistence.SecondaryTable.class);\r\n    javax.persistence.SecondaryTables secTabsAnn = clazzToProcess.getAnnotation(javax.persistence.SecondaryTables.class);\r\n    entityBinder.firstLevelSecondaryTablesBinding(secTabAnn, secTabsAnn);\r\n    OnDelete onDeleteAnn = clazzToProcess.getAnnotation(OnDelete.class);\r\n    boolean onDeleteAppropriate = false;\r\n    final boolean isInheritanceRoot = !inheritanceState.hasParents();\r\n    final boolean hasSubclasses = inheritanceState.hasSiblings();\r\n    if (InheritanceType.JOINED.equals(inheritanceState.getType())) {\r\n        if (inheritanceState.hasParents()) {\r\n            onDeleteAppropriate = true;\r\n            final JoinedSubclass jsc = (JoinedSubclass) persistentClass;\r\n            SimpleValue key = new DependantValue(context, jsc.getTable(), jsc.getIdentifier());\r\n            jsc.setKey(key);\r\n            ForeignKey fk = clazzToProcess.getAnnotation(ForeignKey.class);\r\n            if (fk != null && !BinderHelper.isEmptyAnnotationValue(fk.name())) {\r\n                key.setForeignKeyName(fk.name());\r\n            } else {\r\n                final PrimaryKeyJoinColumn pkJoinColumn = clazzToProcess.getAnnotation(PrimaryKeyJoinColumn.class);\r\n                final PrimaryKeyJoinColumns pkJoinColumns = clazzToProcess.getAnnotation(PrimaryKeyJoinColumns.class);\r\n                if (pkJoinColumns != null && pkJoinColumns.foreignKey().value() == ConstraintMode.NO_CONSTRAINT) {\r\n                    key.setForeignKeyName(\"none\");\r\n                } else if (pkJoinColumns != null && !StringHelper.isEmpty(pkJoinColumns.foreignKey().name())) {\r\n                    key.setForeignKeyName(pkJoinColumns.foreignKey().name());\r\n                } else if (pkJoinColumn != null && pkJoinColumn.foreignKey().value() == ConstraintMode.NO_CONSTRAINT) {\r\n                    key.setForeignKeyName(\"none\");\r\n                } else if (pkJoinColumn != null && !StringHelper.isEmpty(pkJoinColumn.foreignKey().name())) {\r\n                    key.setForeignKeyName(pkJoinColumn.foreignKey().name());\r\n                }\r\n            }\r\n            if (onDeleteAnn != null) {\r\n                key.setCascadeDeleteEnabled(OnDeleteAction.CASCADE.equals(onDeleteAnn.action()));\r\n            } else {\r\n                key.setCascadeDeleteEnabled(false);\r\n            }\r\n            context.getMetadataCollector().addSecondPass(new JoinedSubclassFkSecondPass(jsc, inheritanceJoinedColumns, key, context));\r\n            context.getMetadataCollector().addSecondPass(new CreateKeySecondPass(jsc));\r\n        }\r\n        if (isInheritanceRoot) {\r\n            if (discriminatorColumn != null) {\r\n                if (hasSubclasses || !discriminatorColumn.isImplicit()) {\r\n                    bindDiscriminatorColumnToRootPersistentClass((RootClass) persistentClass, discriminatorColumn, entityBinder.getSecondaryTables(), propertyHolder, context);\r\n                    entityBinder.bindDiscriminatorValue();\r\n                }\r\n            }\r\n        }\r\n    } else if (InheritanceType.SINGLE_TABLE.equals(inheritanceState.getType())) {\r\n        if (isInheritanceRoot) {\r\n            if (hasSubclasses || !discriminatorColumn.isImplicit()) {\r\n                bindDiscriminatorColumnToRootPersistentClass((RootClass) persistentClass, discriminatorColumn, entityBinder.getSecondaryTables(), propertyHolder, context);\r\n                entityBinder.bindDiscriminatorValue();\r\n            }\r\n        }\r\n    }\r\n    if (onDeleteAnn != null && !onDeleteAppropriate) {\r\n        LOG.invalidOnDeleteAnnotation(propertyHolder.getEntityName());\r\n    }\r\n    HashMap<String, IdentifierGeneratorDefinition> classGenerators = buildGenerators(clazzToProcess, context);\r\n    final InheritanceState.ElementsToProcess elementsToProcess = inheritanceState.getElementsToProcess();\r\n    inheritanceState.postProcess(persistentClass, entityBinder);\r\n    final boolean subclassAndSingleTableStrategy = inheritanceState.getType() == InheritanceType.SINGLE_TABLE && inheritanceState.hasParents();\r\n    Set<String> idPropertiesIfIdClass = new HashSet();\r\n    boolean isIdClass = mapAsIdClass(inheritanceStatePerClass, inheritanceState, persistentClass, entityBinder, propertyHolder, elementsToProcess, idPropertiesIfIdClass, context);\r\n    if (!isIdClass) {\r\n        entityBinder.setWrapIdsInEmbeddedComponents(elementsToProcess.getIdPropertyCount() > 1);\r\n    }\r\n    processIdPropertiesIfNotAlready(inheritanceStatePerClass, context, persistentClass, entityBinder, propertyHolder, classGenerators, elementsToProcess, subclassAndSingleTableStrategy, idPropertiesIfIdClass);\r\n    if (!inheritanceState.hasParents()) {\r\n        final RootClass rootClass = (RootClass) persistentClass;\r\n        context.getMetadataCollector().addSecondPass(new CreateKeySecondPass(rootClass));\r\n    } else {\r\n        superEntity.addSubclass((Subclass) persistentClass);\r\n    }\r\n    context.getMetadataCollector().addEntityBinding(persistentClass);\r\n    context.getMetadataCollector().addSecondPass(new SecondaryTableSecondPass(entityBinder, propertyHolder, clazzToProcess));\r\n    entityBinder.processComplementaryTableDefinitions(clazzToProcess.getAnnotation(org.hibernate.annotations.Table.class));\r\n    entityBinder.processComplementaryTableDefinitions(clazzToProcess.getAnnotation(org.hibernate.annotations.Tables.class));\r\n    entityBinder.processComplementaryTableDefinitions(tabAnn);\r\n}"
}, {
	"Path": "water.rapids.ast.prims.mungers.AstFillNATest.genFillNARow",
	"Comment": "this method will perform fillna operation in single thread and will be used to verify correct implementationof the multithread one.",
	"Method": "Frame genFillNARow(Frame fr,int maxlen){\r\n    Frame newFrame = fr.deepCopy(Key.make().toString());\r\n    long nrow = fr.numRows();\r\n    int lastColInd = fr.numCols() - 1;\r\n    int naColStart = -1;\r\n    int lastNonNaCol = Integer.MAX_VALUE;\r\n    int cindex = lastColInd - 1;\r\n    double fillVal = Double.NaN;\r\n    int naBlockLen = 0;\r\n    if (maxlen == 0)\r\n        return newFrame;\r\n    Vec[] allVecs = new Vec[newFrame.numCols()];\r\n    Vec.Writer[] allWriters = new Vec.Writer[newFrame.numCols()];\r\n    for (int cind = 0; cind < allVecs.length; cind++) {\r\n        allVecs[cind] = newFrame.vec(cind);\r\n        Scope.track(allVecs[cind]);\r\n        allWriters[cind] = allVecs[cind].open();\r\n    }\r\n    for (long rindex = 0; rindex < nrow; rindex++) {\r\n        if (!fr.vec(lastColInd).isNA(rindex)) {\r\n            lastNonNaCol = lastColInd;\r\n            fillVal = fr.vec(lastColInd).at(rindex);\r\n        }\r\n        while (cindex >= 0) {\r\n            if (fr.vec(cindex).isNA(rindex)) {\r\n                naColStart = cindex;\r\n                naBlockLen++;\r\n                cindex--;\r\n                while ((cindex >= 0) && fr.vec(cindex).isNA(rindex)) {\r\n                    cindex--;\r\n                    naBlockLen++;\r\n                }\r\n                int cend = naColStart - naBlockLen;\r\n                for (int cind = naColStart; cind > cend; cind--) {\r\n                    int colIndDiff = lastNonNaCol - cind;\r\n                    if (colIndDiff <= maxlen) {\r\n                        allWriters[cind].set(rindex, fillVal);\r\n                    } else {\r\n                        break;\r\n                    }\r\n                }\r\n            } else {\r\n                lastNonNaCol = cindex;\r\n                fillVal = fr.vec(cindex).at(rindex);\r\n                naBlockLen = 0;\r\n                cindex--;\r\n            }\r\n        }\r\n    }\r\n    for (int cind = 0; cind < allVecs.length; cind++) {\r\n        allWriters[cind].close();\r\n    }\r\n    return newFrame;\r\n}"
}, {
	"Path": "org.hibernate.internal.SessionImpl.tryNaturalIdLoadAccess",
	"Comment": "checks to see if the criteriaimpl is a naturalid lookup that can be done via\tnaturalidloadaccess",
	"Method": "NaturalIdLoadAccess tryNaturalIdLoadAccess(CriteriaImpl criteria){\r\n    if (!criteria.isLookupByNaturalKey()) {\r\n        return null;\r\n    }\r\n    final String entityName = criteria.getEntityOrClassName();\r\n    final EntityPersister entityPersister = getFactory().getMetamodel().entityPersister(entityName);\r\n    if (!entityPersister.hasNaturalIdentifier()) {\r\n        return null;\r\n    }\r\n    final CriterionEntry criterionEntry = criteria.iterateExpressionEntries().next();\r\n    final NaturalIdentifier naturalIdentifier = (NaturalIdentifier) criterionEntry.getCriterion();\r\n    final Map<String, Object> naturalIdValues = naturalIdentifier.getNaturalIdValues();\r\n    final int[] naturalIdentifierProperties = entityPersister.getNaturalIdentifierProperties();\r\n    if (naturalIdentifierProperties.length != naturalIdValues.size()) {\r\n        return null;\r\n    }\r\n    final String[] propertyNames = entityPersister.getPropertyNames();\r\n    final NaturalIdLoadAccess naturalIdLoader = this.byNaturalId(entityName);\r\n    for (int naturalIdentifierProperty : naturalIdentifierProperties) {\r\n        final String naturalIdProperty = propertyNames[naturalIdentifierProperty];\r\n        final Object naturalIdValue = naturalIdValues.get(naturalIdProperty);\r\n        if (naturalIdValue == null) {\r\n            return null;\r\n        }\r\n        naturalIdLoader.using(naturalIdProperty, naturalIdValue);\r\n    }\r\n    log.warn(\"Session.byNaturalId(\" + entityName + \") should be used for naturalId queries instead of Restrictions.naturalId() from a Criteria\");\r\n    return naturalIdLoader;\r\n}"
}, {
	"Path": "org.hibernate.criterion.DetachedCriteria.forEntityName",
	"Comment": "static builder to create a detachedcriteria for the given entity.",
	"Method": "DetachedCriteria forEntityName(String entityName,DetachedCriteria forEntityName,String entityName,String alias){\r\n    return new DetachedCriteria(entityName, alias);\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.supportsCircularCascadeDeleteConstraints",
	"Comment": "does this dialect support definition of cascade delete constraints\twhich can cause circular chains?",
	"Method": "boolean supportsCircularCascadeDeleteConstraints(){\r\n    return true;\r\n}"
}, {
	"Path": "org.hibernate.loader.JoinWalker.mergeOuterJoins",
	"Comment": "generate a sequence of left outer join clauses for the given associations.",
	"Method": "JoinFragment mergeOuterJoins(List associations){\r\n    JoinFragment outerjoin = getDialect().createOuterJoinFragment();\r\n    Iterator iter = associations.iterator();\r\n    OuterJoinableAssociation last = null;\r\n    while (iter.hasNext()) {\r\n        final OuterJoinableAssociation oj = (OuterJoinableAssociation) iter.next();\r\n        if (last != null && last.isManyToManyWith(oj)) {\r\n            oj.addManyToManyJoin(outerjoin, (QueryableCollection) last.getJoinable());\r\n        } else {\r\n            oj.addJoins(outerjoin);\r\n        }\r\n        last = oj;\r\n    }\r\n    last = null;\r\n    return outerjoin;\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.Versioning.getVersion",
	"Comment": "extract the optimistic locking value out of the entity state snapshot.",
	"Method": "Object getVersion(Object[] fields,EntityPersister persister){\r\n    if (!persister.isVersioned()) {\r\n        return null;\r\n    }\r\n    return fields[persister.getVersionProperty()];\r\n}"
}, {
	"Path": "org.hibernate.jpa.internal.util.PersistenceUtilHelper.getMethod",
	"Comment": "returns the method with the specified name or null if it does not exist.",
	"Method": "Method getMethod(Class<?> clazz,String attributeName){\r\n    try {\r\n        char[] string = attributeName.toCharArray();\r\n        string[0] = Character.toUpperCase(string[0]);\r\n        String casedAttributeName = new String(string);\r\n        try {\r\n            return clazz.getDeclaredMethod(\"get\" + casedAttributeName);\r\n        } catch (NoSuchMethodException e) {\r\n            return clazz.getDeclaredMethod(\"is\" + casedAttributeName);\r\n        }\r\n    } catch (NoSuchMethodException e) {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.action.internal.EntityIncrementVersionProcess.doBeforeTransactionCompletion",
	"Comment": "perform whatever processing is encapsulated here before completion of the transaction.",
	"Method": "void doBeforeTransactionCompletion(SessionImplementor session){\r\n    final EntityPersister persister = entry.getPersister();\r\n    final Object nextVersion = persister.forceVersionIncrement(entry.getId(), entry.getVersion(), session);\r\n    entry.forceLocked(object, nextVersion);\r\n}"
}, {
	"Path": "org.hibernate.cfg.ImprovedNamingStrategy.logicalCollectionTableName",
	"Comment": "returns either the table name if explicit or\tif there is an associated table, the concatenation of owner entity table and associated table\totherwise the concatenation of owner entity table and the unqualified property name",
	"Method": "String logicalCollectionTableName(String tableName,String ownerEntityTable,String associatedEntityTable,String propertyName){\r\n    if (tableName != null) {\r\n        return tableName;\r\n    } else {\r\n        return new StringBuffer(ownerEntityTable).append(\"_\").append(associatedEntityTable != null ? associatedEntityTable : StringHelper.unqualify(propertyName)).toString();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.OuterJoinableAssociation.getPosition",
	"Comment": "get the position of the join with the given alias in the\tlist of joins",
	"Method": "int getPosition(String lhsAlias,List associations){\r\n    int result = 0;\r\n    for (Object association : associations) {\r\n        final OuterJoinableAssociation oj = (OuterJoinableAssociation) association;\r\n        if (oj.getJoinable().consumesEntityAlias()) {\r\n            if (oj.rhsAlias.equals(lhsAlias)) {\r\n                return result;\r\n            }\r\n            result++;\r\n        }\r\n    }\r\n    return -1;\r\n}"
}, {
	"Path": "org.hibernate.Cache.evictCollection",
	"Comment": "evicts the cache data for the given identified collection instance.",
	"Method": "void evictCollection(String role,Serializable ownerIdentifier){\r\n    evictCollectionData(role, ownerIdentifier);\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.exec.internal.AbstractLoadQueryDetails.generate",
	"Comment": "main entry point for properly handling the from clause and and joins and restrictions",
	"Method": "void generate(){\r\n    final SelectStatementBuilder select = new SelectStatementBuilder(queryProcessor.getSessionFactory().getDialect());\r\n    applyRootReturnTableFragments(select);\r\n    if (shouldApplyRootReturnFilterBeforeKeyRestriction()) {\r\n        applyRootReturnFilterRestrictions(select);\r\n        applyKeyRestriction(select, getRootTableAlias(), keyColumnNames, getQueryBuildingParameters().getBatchSize());\r\n    } else {\r\n        applyKeyRestriction(select, getRootTableAlias(), keyColumnNames, getQueryBuildingParameters().getBatchSize());\r\n        applyRootReturnFilterRestrictions(select);\r\n    }\r\n    applyRootReturnWhereJoinRestrictions(select);\r\n    applyRootReturnOrderByFragments(select);\r\n    applyRootReturnSelectFragments(select);\r\n    queryProcessor.processQuerySpaceJoins(getRootQuerySpace(), select);\r\n    FetchStats fetchStats = null;\r\n    if (FetchSource.class.isInstance(rootReturn)) {\r\n        fetchStats = queryProcessor.processFetches((FetchSource) rootReturn, select, getReaderCollector());\r\n    } else if (CollectionReturn.class.isInstance(rootReturn)) {\r\n        final CollectionReturn collectionReturn = (CollectionReturn) rootReturn;\r\n        if (collectionReturn.getElementGraph() != null) {\r\n            fetchStats = queryProcessor.processFetches(collectionReturn.getElementGraph(), select, getReaderCollector());\r\n        }\r\n    }\r\n    if (fetchStats != null && fetchStats.getJoinedBagAttributeFetches().size() > 1) {\r\n        final List<String> bagRoles = new ArrayList();\r\n        for (CollectionAttributeFetch bagFetch : fetchStats.getJoinedBagAttributeFetches()) {\r\n            bagRoles.add(bagFetch.getCollectionPersister().getRole());\r\n        }\r\n        throw new MultipleBagFetchException(bagRoles);\r\n    }\r\n    LoadPlanTreePrinter.INSTANCE.logTree(loadPlan, queryProcessor.getAliasResolutionContext());\r\n    this.sqlStatement = select.toStatementString();\r\n    this.resultSetProcessor = new ResultSetProcessorImpl(loadPlan, queryProcessor.getAliasResolutionContext(), getReaderCollector().buildRowReader(), shouldUseOptionalEntityInstance(), isSubselectLoadingEnabled(fetchStats));\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.cursor.internal.StandardRefCursorSupport.injectJdbcServices",
	"Comment": "hook for service registry to be able to inject jdbcservices",
	"Method": "void injectJdbcServices(JdbcServices jdbcServices){\r\n    this.jdbcServices = jdbcServices;\r\n}"
}, {
	"Path": "water.parser.avro.AvroParser.write2frame",
	"Comment": "the main method transforming avro record into a row in h2o frame.",
	"Method": "void write2frame(GenericRecord gr,String[] columnNames,Schema.Field[] inSchema,byte[] columnTypes,ParseWriter dout){\r\n    assert inSchema.length == columnTypes.length : \"AVRO field flatenized schema has to match to parser setup\";\r\n    BufferedString bs = new BufferedString();\r\n    for (int cIdx = 0; cIdx < columnNames.length; cIdx++) {\r\n        int inputFieldIdx = inSchema[cIdx].pos();\r\n        Schema.Type inputType = toPrimitiveType(inSchema[cIdx].schema());\r\n        byte targetType = columnTypes[cIdx];\r\n        Object value = gr.get(inputFieldIdx);\r\n        if (value == null) {\r\n            dout.addInvalidCol(cIdx);\r\n        } else {\r\n            switch(inputType) {\r\n                case BOOLEAN:\r\n                    dout.addNumCol(cIdx, ((Boolean) value) ? 1 : 0);\r\n                    break;\r\n                case INT:\r\n                    dout.addNumCol(cIdx, ((Integer) value), 0);\r\n                    break;\r\n                case LONG:\r\n                    dout.addNumCol(cIdx, ((Long) value), 0);\r\n                    break;\r\n                case FLOAT:\r\n                    dout.addNumCol(cIdx, (Float) value);\r\n                    break;\r\n                case DOUBLE:\r\n                    dout.addNumCol(cIdx, (Double) value);\r\n                    break;\r\n                case ENUM:\r\n                    GenericData.EnumSymbol es = (GenericData.EnumSymbol) value;\r\n                    dout.addNumCol(cIdx, es.getSchema().getEnumOrdinal(es.toString()));\r\n                    break;\r\n                case BYTES:\r\n                    dout.addStrCol(cIdx, bs.set(((ByteBuffer) value).array()));\r\n                    break;\r\n                case STRING:\r\n                    dout.addStrCol(cIdx, bs.set(((Utf8) value).getBytes()));\r\n                    break;\r\n                case NULL:\r\n                    dout.addInvalidCol(cIdx);\r\n                    break;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "water.rapids.ast.prims.mungers.AstNaOmitTest.TestNaOmit",
	"Comment": "test written by nidhi to test that naomit actaully remove the rows with nas in them.",
	"Method": "void TestNaOmit(){\r\n    Frame f = null;\r\n    Frame fNew = null;\r\n    try {\r\n        f = ArrayUtils.frame(ar(\"A\", \"B\"), ard(1.0, Double.NaN), ard(2.0, 23.3), ard(3.0, 3.3), ard(Double.NaN, 3.3));\r\n        String x = String.format(\"(na.omit %s)\", f._key);\r\n        Val res = Rapids.exec(x);\r\n        fNew = res.getFrame();\r\n        assertEquals(f.numRows() - fNew.numRows(), 2);\r\n    } finally {\r\n        if (f != null)\r\n            f.delete();\r\n        if (fNew != null)\r\n            fNew.delete();\r\n    }\r\n}"
}, {
	"Path": "water.parser.avro.AvroUtil.isSupportedSchema",
	"Comment": "return true if the given schema can be transformedinto h2o type.",
	"Method": "boolean isSupportedSchema(Schema s){\r\n    Schema.Type typ = s.getType();\r\n    switch(typ) {\r\n        case BOOLEAN:\r\n        case INT:\r\n        case LONG:\r\n        case FLOAT:\r\n        case DOUBLE:\r\n        case ENUM:\r\n        case STRING:\r\n        case NULL:\r\n        case BYTES:\r\n            return true;\r\n        case UNION:\r\n            List<Schema> unionSchemas = s.getTypes();\r\n            if (unionSchemas.size() == 1) {\r\n                return isSupportedSchema(unionSchemas.get(0));\r\n            } else if (unionSchemas.size() == 2) {\r\n                Schema s1 = unionSchemas.get(0);\r\n                Schema s2 = unionSchemas.get(1);\r\n                return s1.getType().equals(Schema.Type.NULL) && isSupportedSchema(s2) || s2.getType().equals(Schema.Type.NULL) && isSupportedSchema(s1);\r\n            }\r\n        default:\r\n            return false;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cfg.ClassPropertyHolder.getJoinsPerRealTableName",
	"Comment": "needed for proper compliance with naming strategy, the property table\tcan be overriden if the properties are part of secondary tables",
	"Method": "Map<String, Join> getJoinsPerRealTableName(){\r\n    if (joinsPerRealTableName == null) {\r\n        joinsPerRealTableName = new HashMap<String, Join>(joins.size());\r\n        for (Join join : joins.values()) {\r\n            joinsPerRealTableName.put(join.getTable().getName(), join);\r\n        }\r\n    }\r\n    return joinsPerRealTableName;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getQuerySequencesString",
	"Comment": "get the select command used retrieve the names of all sequences.",
	"Method": "String getQuerySequencesString(){\r\n    return null;\r\n}"
}, {
	"Path": "org.hibernate.persister.entity.AbstractEntityPersister.load",
	"Comment": "load an instance using either the forupdateloader or the outer joining loader,\tdepending upon the value of the lock parameter",
	"Method": "Object load(Serializable id,Object optionalObject,LockMode lockMode,SharedSessionContractImplementor session,Object load,Serializable id,Object optionalObject,LockOptions lockOptions,SharedSessionContractImplementor session){\r\n    if (LOG.isTraceEnabled()) {\r\n        LOG.tracev(\"Fetching entity: {0}\", MessageHelper.infoString(this, id, getFactory()));\r\n    }\r\n    final UniqueEntityLoader loader = getAppropriateLoader(lockOptions, session);\r\n    return loader.load(id, optionalObject, session, lockOptions);\r\n}"
}, {
	"Path": "org.hibernate.collection.internal.AbstractPersistentCollection.getSession",
	"Comment": "get the session currently associated with this collection.",
	"Method": "SharedSessionContractImplementor getSession(){\r\n    return session;\r\n}"
}, {
	"Path": "ml.dmlc.xgboost4j.java.XGBoostSetupTask.findFrameNodes",
	"Comment": "finds what nodes actually do carry some of data of a given frame",
	"Method": "FrameNodes findFrameNodes(Frame fr){\r\n    boolean[] nodesHoldingFrame = new boolean[H2O.CLOUD.size()];\r\n    Vec vec = fr.anyVec();\r\n    for (int chunkNr = 0; chunkNr < vec.nChunks(); chunkNr++) {\r\n        int home = vec.chunkKey(chunkNr).home_node().index();\r\n        if (!nodesHoldingFrame[home])\r\n            nodesHoldingFrame[home] = true;\r\n    }\r\n    return new FrameNodes(fr, nodesHoldingFrame);\r\n}"
}, {
	"Path": "org.hibernate.stat.internal.QueryStatisticsImpl.getExecutionAvgTimeAsDouble",
	"Comment": "average time in ms as double taken by the execution of this query onto the db",
	"Method": "double getExecutionAvgTimeAsDouble(){\r\n    writeLock.lock();\r\n    try {\r\n        double avgExecutionTime = 0;\r\n        final long ec = executionCount.sum();\r\n        if (ec > 0) {\r\n            avgExecutionTime = totalExecutionTime.get() / (double) ec;\r\n        }\r\n        return avgExecutionTime;\r\n    } finally {\r\n        writeLock.unlock();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.query.criteria.internal.expression.BinaryArithmeticOperation.determineReturnType",
	"Comment": "helper for determining the appropriate operation return type based on one of the operands as a literal.",
	"Method": "Class<? extends Number> determineReturnType(Class<? extends Number> defaultType,Expression<? extends Number> expression,Class<? extends Number> determineReturnType,Class<? extends Number> defaultType,Number numberLiteral){\r\n    return numberLiteral == null ? defaultType : numberLiteral.getClass();\r\n}"
}, {
	"Path": "org.hibernate.jpa.test.callbacks.hbmxml.MappingClassMoreThanOnceTest.testBootstrapWithClassMappedMOreThanOnce",
	"Comment": "tests that an entity manager can be created when a class is mapped more than once.",
	"Method": "void testBootstrapWithClassMappedMOreThanOnce(){\r\n    Map settings = new HashMap();\r\n    settings.put(AvailableSettings.HBXML_FILES, \"org/hibernate/jpa/test/callbacks/hbmxml/ClassMappedMoreThanOnce.hbm.xml\");\r\n    final EntityManagerFactoryBuilder builder = Bootstrap.getEntityManagerFactoryBuilder(new BaseEntityManagerFunctionalTestCase.TestingPersistenceUnitDescriptorImpl(getClass().getSimpleName()), settings);\r\n    HibernateEntityManagerFactory emf = null;\r\n    try {\r\n        emf = builder.build().unwrap(HibernateEntityManagerFactory.class);\r\n    } finally {\r\n        if (emf != null) {\r\n            try {\r\n                emf.close();\r\n            } catch (Exception ignore) {\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.JoinHelper.getRHSColumnNames",
	"Comment": "get the columns of the associated table which are to be used in the join",
	"Method": "String[] getRHSColumnNames(AssociationType type,SessionFactoryImplementor factory){\r\n    final String uniqueKeyPropertyName = type.getRHSUniqueKeyPropertyName();\r\n    final Joinable joinable = type.getAssociatedJoinable(factory);\r\n    if (uniqueKeyPropertyName == null) {\r\n        return joinable.getKeyColumnNames();\r\n    } else {\r\n        return ((OuterJoinLoadable) joinable).getPropertyColumnNames(uniqueKeyPropertyName);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.JoinSequence.setSelector",
	"Comment": "set the selector to use to determine how subclass joins should be applied.",
	"Method": "JoinSequence setSelector(Selector selector){\r\n    this.selector = selector;\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.internal.util.StringHelper.generateAlias",
	"Comment": "generate a nice alias for the given class name or collection role name and unique integer. subclasses of\tloader do not have to use aliases of this form.",
	"Method": "String generateAlias(String description,String generateAlias,String description,int unique){\r\n    return generateAliasRoot(description) + Integer.toString(unique) + '_';\r\n}"
}, {
	"Path": "org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.getEnhancementContext",
	"Comment": "builds the context to be used in runtime bytecode enhancement",
	"Method": "EnhancementContext getEnhancementContext(boolean dirtyTrackingEnabled,boolean lazyInitializationEnabled,boolean associationManagementEnabled){\r\n    return new DefaultEnhancementContext() {\r\n        @Override\r\n        public boolean isEntityClass(UnloadedClass classDescriptor) {\r\n            return managedResources.getAnnotatedClassNames().contains(classDescriptor.getName()) && super.isEntityClass(classDescriptor);\r\n        }\r\n        @Override\r\n        public boolean isCompositeClass(UnloadedClass classDescriptor) {\r\n            return managedResources.getAnnotatedClassNames().contains(classDescriptor.getName()) && super.isCompositeClass(classDescriptor);\r\n        }\r\n        @Override\r\n        public boolean doBiDirectionalAssociationManagement(UnloadedField field) {\r\n            return associationManagementEnabled;\r\n        }\r\n        @Override\r\n        public boolean doDirtyCheckingInline(UnloadedClass classDescriptor) {\r\n            return dirtyTrackingEnabled;\r\n        }\r\n        @Override\r\n        public boolean hasLazyLoadableAttributes(UnloadedClass classDescriptor) {\r\n            return lazyInitializationEnabled;\r\n        }\r\n        @Override\r\n        public boolean isLazyLoadable(UnloadedField field) {\r\n            return lazyInitializationEnabled;\r\n        }\r\n        @Override\r\n        public boolean doExtendedEnhancement(UnloadedClass classDescriptor) {\r\n            return false;\r\n        }\r\n    };\r\n}"
}, {
	"Path": "org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.getEnhancementContext",
	"Comment": "builds the context to be used in runtime bytecode enhancement",
	"Method": "EnhancementContext getEnhancementContext(boolean dirtyTrackingEnabled,boolean lazyInitializationEnabled,boolean associationManagementEnabled){\r\n    return managedResources.getAnnotatedClassNames().contains(classDescriptor.getName()) && super.isEntityClass(classDescriptor);\r\n}"
}, {
	"Path": "org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.getEnhancementContext",
	"Comment": "builds the context to be used in runtime bytecode enhancement",
	"Method": "EnhancementContext getEnhancementContext(boolean dirtyTrackingEnabled,boolean lazyInitializationEnabled,boolean associationManagementEnabled){\r\n    return managedResources.getAnnotatedClassNames().contains(classDescriptor.getName()) && super.isCompositeClass(classDescriptor);\r\n}"
}, {
	"Path": "org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.getEnhancementContext",
	"Comment": "builds the context to be used in runtime bytecode enhancement",
	"Method": "EnhancementContext getEnhancementContext(boolean dirtyTrackingEnabled,boolean lazyInitializationEnabled,boolean associationManagementEnabled){\r\n    return associationManagementEnabled;\r\n}"
}, {
	"Path": "org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.getEnhancementContext",
	"Comment": "builds the context to be used in runtime bytecode enhancement",
	"Method": "EnhancementContext getEnhancementContext(boolean dirtyTrackingEnabled,boolean lazyInitializationEnabled,boolean associationManagementEnabled){\r\n    return dirtyTrackingEnabled;\r\n}"
}, {
	"Path": "org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.getEnhancementContext",
	"Comment": "builds the context to be used in runtime bytecode enhancement",
	"Method": "EnhancementContext getEnhancementContext(boolean dirtyTrackingEnabled,boolean lazyInitializationEnabled,boolean associationManagementEnabled){\r\n    return lazyInitializationEnabled;\r\n}"
}, {
	"Path": "org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.getEnhancementContext",
	"Comment": "builds the context to be used in runtime bytecode enhancement",
	"Method": "EnhancementContext getEnhancementContext(boolean dirtyTrackingEnabled,boolean lazyInitializationEnabled,boolean associationManagementEnabled){\r\n    return lazyInitializationEnabled;\r\n}"
}, {
	"Path": "org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.getEnhancementContext",
	"Comment": "builds the context to be used in runtime bytecode enhancement",
	"Method": "EnhancementContext getEnhancementContext(boolean dirtyTrackingEnabled,boolean lazyInitializationEnabled,boolean associationManagementEnabled){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.collection.internal.AbstractPersistentCollection.performQueuedOperations",
	"Comment": "after reading all existing elements from the database,\tadd the queued elements to the underlying collection.",
	"Method": "void performQueuedOperations(){\r\n    for (DelayedOperation operation : operationQueue) {\r\n        operation.operate();\r\n    }\r\n    clearOperationQueue();\r\n}"
}, {
	"Path": "water.Value.completeRemotePut",
	"Comment": "the put for this value has completed.wakeup any blocked later puts.",
	"Method": "void completeRemotePut(){\r\n    assert !_key.home();\r\n    if (RW_CAS(1, -1, \"remote_complete\"))\r\n        return;\r\n    synchronized (this) {\r\n        boolean res = RW_CAS(2, -1, \"remote_do_notify\");\r\n        assert res;\r\n        notifyAll();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.boot.registry.BootstrapServiceRegistryBuilder.destroy",
	"Comment": "destroy a service registry.applications should only destroy registries they have explicitly created.",
	"Method": "void destroy(ServiceRegistry serviceRegistry){\r\n    if (serviceRegistry == null) {\r\n        return;\r\n    }\r\n    ((BootstrapServiceRegistryImpl) serviceRegistry).destroy();\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getCaseInsensitiveLike",
	"Comment": "the name of the sql function that can do case insensitive like comparison.",
	"Method": "String getCaseInsensitiveLike(){\r\n    return \"like\";\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.SessionFactoryHelper.getCollectionPropertyMapping",
	"Comment": "retrieve a propertymapping describing the given collection role.",
	"Method": "PropertyMapping getCollectionPropertyMapping(String role){\r\n    return collectionPropertyMappingByRole.get(role);\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.ResultSetWrapperProxy.findColumn",
	"Comment": "locate the column index corresponding to the given column name via the cache.",
	"Method": "Integer findColumn(String columnName){\r\n    return columnNameCache.getIndexForColumnName(columnName, rs);\r\n}"
}, {
	"Path": "org.hibernate.event.internal.AbstractFlushingEventListener.prepareCollectionFlushes",
	"Comment": "initialize the flags of the collectionentry, including the\tdirty check.",
	"Method": "void prepareCollectionFlushes(PersistenceContext persistenceContext){\r\n    LOG.debug(\"Dirty checking collections\");\r\n    for (Map.Entry<PersistentCollection, CollectionEntry> entry : IdentityMap.concurrentEntries((Map<PersistentCollection, CollectionEntry>) persistenceContext.getCollectionEntries())) {\r\n        entry.getValue().preFlush(entry.getKey());\r\n    }\r\n}"
}, {
	"Path": "water.parser.orc.OrcParser.deriveParseSetup",
	"Comment": "this function will derive information like column names, types and number fromthe inspector.",
	"Method": "OrcParseSetup deriveParseSetup(Reader orcFileReader,StructObjectInspector insp){\r\n    List<StructField> allColumns = (List<StructField>) insp.getAllStructFieldRefs();\r\n    List<StripeInformation> allStripes = orcFileReader.getStripes();\r\n    ArrayList<String> allColNames = new ArrayList();\r\n    boolean[] toInclude = new boolean[allColumns.size() + 1];\r\n    int supportedFieldCnt = 0;\r\n    int colIdx = 0;\r\n    for (StructField oneField : allColumns) {\r\n        allColNames.add(oneField.getFieldName());\r\n        String columnType = oneField.getFieldObjectInspector().getTypeName();\r\n        if (columnType.toLowerCase().contains(\"decimal\")) {\r\n            columnType = \"decimal\";\r\n        }\r\n        if (isSupportedSchema(columnType)) {\r\n            toInclude[colIdx + 1] = true;\r\n            supportedFieldCnt++;\r\n        }\r\n        int cnt = countStructFields(oneField.getFieldObjectInspector(), allColNames);\r\n        if (cnt > 1)\r\n            toInclude = Arrays.copyOf(toInclude, toInclude.length + cnt - 1);\r\n        colIdx += cnt;\r\n    }\r\n    String[] allNames = allColNames.toArray(new String[allColNames.size()]);\r\n    String[] names = new String[supportedFieldCnt];\r\n    byte[] types = new byte[supportedFieldCnt];\r\n    String[][] domains = new String[supportedFieldCnt][];\r\n    String[] dataPreview = new String[supportedFieldCnt];\r\n    String[] dataTypes = new String[supportedFieldCnt];\r\n    ParseWriter.ParseErr[] errs = new ParseWriter.ParseErr[0];\r\n    int columnIndex = 0;\r\n    for (StructField oneField : allColumns) {\r\n        String columnType = oneField.getFieldObjectInspector().getTypeName();\r\n        if (columnType.toLowerCase().contains(\"decimal\"))\r\n            columnType = \"decimal\";\r\n        if (isSupportedSchema(columnType)) {\r\n            names[columnIndex] = oneField.getFieldName();\r\n            types[columnIndex] = schemaToColumnType(columnType);\r\n            dataTypes[columnIndex] = columnType;\r\n            columnIndex++;\r\n        } else {\r\n            errs = ArrayUtils.append(errs, new ParseWriter.ParseErr(\"Orc Parser: Skipping field: \" + oneField.getFieldName() + \" because of unsupported type: \" + columnType, -1, -1L, -2L));\r\n        }\r\n    }\r\n    long[] stripeSizes = new long[allStripes.size()];\r\n    long fileSize = 0L;\r\n    long maxStripeSize = 0L;\r\n    for (int index = 0; index < allStripes.size(); index++) {\r\n        long stripeSize = allStripes.get(index).getDataLength();\r\n        if (stripeSize > maxStripeSize)\r\n            maxStripeSize = stripeSize;\r\n        fileSize = fileSize + stripeSize;\r\n        stripeSizes[index] = fileSize;\r\n    }\r\n    OrcParseSetup ps = new OrcParseSetup(supportedFieldCnt, names, types, domains, null, new String[][] { dataPreview }, orcFileReader, dataTypes, toInclude, allNames, errs);\r\n    return ps;\r\n}"
}, {
	"Path": "org.hibernate.dialect.function.StandardAnsiSqlAggregationFunctions.primeFunctionMap",
	"Comment": "push the functions defined on standardansisqlaggregationfunctions into the given map",
	"Method": "void primeFunctionMap(Map<String, SQLFunction> functionMap){\r\n    functionMap.put(AvgFunction.INSTANCE.getName(), AvgFunction.INSTANCE);\r\n    functionMap.put(CountFunction.INSTANCE.getName(), CountFunction.INSTANCE);\r\n    functionMap.put(MaxFunction.INSTANCE.getName(), MaxFunction.INSTANCE);\r\n    functionMap.put(MinFunction.INSTANCE.getName(), MinFunction.INSTANCE);\r\n    functionMap.put(SumFunction.INSTANCE.getName(), SumFunction.INSTANCE);\r\n}"
}, {
	"Path": "org.hibernate.boot.spi.AbstractDelegatingMetadataBuilderImplementor.getDelegate",
	"Comment": "kept for compatibility reason but should be removed as soon as possible.",
	"Method": "MetadataBuilderImplementor getDelegate(){\r\n    return delegate;\r\n}"
}, {
	"Path": "org.hibernate.internal.util.collections.ConcurrentReferenceHashMap.segmentFor",
	"Comment": "returns the segment that should be used for key with given hash",
	"Method": "Segment<K, V> segmentFor(int hash){\r\n    return segments[(hash >>> segmentShift) & segmentMask];\r\n}"
}, {
	"Path": "hex.genmodel.utils.StringEscapeUtils.escapeNewlines",
	"Comment": "escapes new line characters of a given string.it also escapes the forward slash characters.",
	"Method": "String escapeNewlines(String str){\r\n    final int len = str.length();\r\n    StringWriter out = new StringWriter(len * 2);\r\n    for (int i = 0; i < len; i++) {\r\n        char c = str.charAt(i);\r\n        switch(c) {\r\n            case '\\\\':\r\n                out.write('\\\\');\r\n                out.write('\\\\');\r\n                break;\r\n            case '\\n':\r\n                out.write('\\\\');\r\n                out.write('n');\r\n                break;\r\n            default:\r\n                out.write(c);\r\n        }\r\n    }\r\n    return out.toString();\r\n}"
}, {
	"Path": "org.hibernate.id.enhanced.SequenceStyleGenerator.determineAdjustedIncrementSize",
	"Comment": "in certain cases we need to adjust the increment size based on the\tselected optimizer.this is the hook to achieve that.",
	"Method": "int determineAdjustedIncrementSize(String optimizationStrategy,int incrementSize){\r\n    final int resolvedIncrementSize;\r\n    if (Math.abs(incrementSize) > 1 && StandardOptimizerDescriptor.NONE.getExternalName().equals(optimizationStrategy)) {\r\n        if (incrementSize < -1) {\r\n            resolvedIncrementSize = -1;\r\n            LOG.honoringOptimizerSetting(StandardOptimizerDescriptor.NONE.getExternalName(), INCREMENT_PARAM, incrementSize, \"negative\", resolvedIncrementSize);\r\n        } else {\r\n            resolvedIncrementSize = 1;\r\n            LOG.honoringOptimizerSetting(StandardOptimizerDescriptor.NONE.getExternalName(), INCREMENT_PARAM, incrementSize, \"positive\", resolvedIncrementSize);\r\n        }\r\n    } else {\r\n        resolvedIncrementSize = incrementSize;\r\n    }\r\n    return resolvedIncrementSize;\r\n}"
}, {
	"Path": "org.hibernate.cfg.ImprovedNamingStrategy.classToTableName",
	"Comment": "return the unqualified class name, mixed case converted to\tunderscores",
	"Method": "String classToTableName(String className){\r\n    return addUnderscores(StringHelper.unqualify(className));\r\n}"
}, {
	"Path": "org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorImpl.joinJtaTransaction",
	"Comment": "join to the jta transaction.note that the underlying meaning of joining in jta environments is to register the\tregisteredsynchronization with the jta system",
	"Method": "void joinJtaTransaction(){\r\n    if (synchronizationRegistered) {\r\n        return;\r\n    }\r\n    jtaPlatform.registerSynchronization(new RegisteredSynchronization(getSynchronizationCallbackCoordinator()));\r\n    getSynchronizationCallbackCoordinator().synchronizationRegistered();\r\n    synchronizationRegistered = true;\r\n    log.debug(\"Hibernate RegisteredSynchronization successfully registered with JTA platform\");\r\n    getTransactionCoordinatorOwner().startTransactionBoundary();\r\n}"
}, {
	"Path": "water.util.OSUtils.getTotalPhysicalMemory",
	"Comment": "safe call to obtain size of total physical memory. it is platform dependent and returns size of machine physical memory in bytes",
	"Method": "long getTotalPhysicalMemory(){\r\n    long memory = -1;\r\n    try {\r\n        MBeanServer mBeanServer = ManagementFactory.getPlatformMBeanServer();\r\n        Object attribute = mBeanServer.getAttribute(new ObjectName(\"java.lang\", \"type\", \"OperatingSystem\"), \"TotalPhysicalMemorySize\");\r\n        return (Long) attribute;\r\n    } catch (Throwable e) {\r\n        e.printStackTrace();\r\n    }\r\n    return memory;\r\n}"
}, {
	"Path": "org.hibernate.internal.AbstractScrollableResults.getFinal",
	"Comment": "check that the requested type is compatible with the result type, and\treturn the column value.this version makes sure the the classes\tare identical.",
	"Method": "Object getFinal(int col,Type returnType){\r\n    if (closed) {\r\n        throw new IllegalStateException(\"ScrollableResults is closed\");\r\n    }\r\n    if (holderInstantiator != null) {\r\n        throw new HibernateException(\"query specifies a holder class\");\r\n    }\r\n    if (returnType.getReturnedClass() == types[col].getReturnedClass()) {\r\n        return get(col);\r\n    } else {\r\n        return throwInvalidColumnTypeException(col, types[col], returnType);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.criterion.SubqueryExpression.createAndSetInnerQuery",
	"Comment": "creates the inner query used to extract some useful information about types, since it is needed in both methods.",
	"Method": "void createAndSetInnerQuery(CriteriaQuery criteriaQuery,SessionFactoryImplementor factory){\r\n    if (innerQuery == null) {\r\n        String alias;\r\n        if (this.criteriaImpl.getAlias() == null) {\r\n            alias = criteriaQuery.generateSQLAlias();\r\n        } else {\r\n            alias = this.criteriaImpl.getAlias() + \"_\";\r\n        }\r\n        innerQuery = new CriteriaQueryTranslator(factory, criteriaImpl, criteriaImpl.getEntityOrClassName(), alias, criteriaQuery);\r\n        params = innerQuery.getQueryParameters();\r\n        types = innerQuery.getProjectedTypes();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.type.CollectionType.replaceElements",
	"Comment": "replace the elements of a collection with the elements of another collection.",
	"Method": "Object replaceElements(Object original,Object target,Object owner,Map copyCache,SharedSessionContractImplementor session){\r\n    java.util.Collection result = (java.util.Collection) target;\r\n    result.clear();\r\n    Type elemType = getElementType(session.getFactory());\r\n    Iterator iter = ((java.util.Collection) original).iterator();\r\n    while (iter.hasNext()) {\r\n        result.add(elemType.replace(iter.next(), null, session, owner, copyCache));\r\n    }\r\n    if (original instanceof PersistentCollection) {\r\n        if (result instanceof PersistentCollection) {\r\n            final PersistentCollection originalPersistentCollection = (PersistentCollection) original;\r\n            final PersistentCollection resultPersistentCollection = (PersistentCollection) result;\r\n            preserveSnapshot(originalPersistentCollection, resultPersistentCollection, elemType, owner, copyCache, session);\r\n            if (!originalPersistentCollection.isDirty()) {\r\n                resultPersistentCollection.clearDirty();\r\n            }\r\n        }\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.type.descriptor.java.DataHelper.subStream",
	"Comment": "extract a portion of the bytes from the given stream., wrapping them in a new stream.",
	"Method": "Object subStream(Reader characterStream,long start,int length,InputStream subStream,InputStream inputStream,long start,int length){\r\n    return new BinaryStreamImpl(extractBytes(inputStream, start, length));\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.exec.internal.BatchingLoadQueryDetailsFactory.makeEntityLoadQueryDetails",
	"Comment": "returns a entityloadquerydetails object based on an existing one and additional elements specific to this one.",
	"Method": "EntityLoadQueryDetails makeEntityLoadQueryDetails(LoadPlan loadPlan,String[] keyColumnNames,QueryBuildingParameters buildingParameters,SessionFactoryImplementor factory,EntityLoadQueryDetails makeEntityLoadQueryDetails,EntityLoadQueryDetails entityLoadQueryDetailsTemplate,QueryBuildingParameters buildingParameters){\r\n    return new EntityLoadQueryDetails(entityLoadQueryDetailsTemplate, buildingParameters);\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.BlobProxy.generateProxy",
	"Comment": "generates a blobimpl proxy using a given number of bytes from an inputstream.",
	"Method": "Blob generateProxy(byte[] bytes,Blob generateProxy,InputStream stream,long length){\r\n    return new BlobProxy(stream, length);\r\n}"
}, {
	"Path": "org.hibernate.boot.model.naming.ImplicitNamingStrategyJpaCompliantImpl.transformAttributePath",
	"Comment": "for jpa standards we typically need the unqualified name.however, a more usable\timpl tends to use the whole path.this method provides an easy hook for subclasses\tto accomplish that",
	"Method": "String transformAttributePath(AttributePath attributePath){\r\n    return attributePath.getProperty();\r\n}"
}, {
	"Path": "org.hibernate.boot.MetadataSources.addDirectory",
	"Comment": "read all mapping documents from a directory tree.\tassumes that any file named .hbm.xml is a mapping document.",
	"Method": "MetadataSources addDirectory(File dir){\r\n    File[] files = dir.listFiles();\r\n    if (files != null && files.length > 0) {\r\n        for (File file : files) {\r\n            if (file.isDirectory()) {\r\n                addDirectory(file);\r\n            } else if (file.getName().endsWith(\".hbm.xml\")) {\r\n                addFile(file);\r\n            }\r\n        }\r\n    }\r\n    return this;\r\n}"
}, {
	"Path": "water.rapids.ast.prims.reducers.AstMean.rowwiseMean",
	"Comment": "compute frame means by rows, and return a frame consisting of a single vec of means in each row.",
	"Method": "ValFrame rowwiseMean(Frame fr,boolean na_rm){\r\n    String[] newnames = { \"mean\" };\r\n    Key<Frame> newkey = Key.make();\r\n    int n_numeric = 0, n_time = 0;\r\n    for (Vec vec : fr.vecs()) {\r\n        if (vec.isNumeric())\r\n            n_numeric++;\r\n        if (vec.isTime())\r\n            n_time++;\r\n    }\r\n    byte resType = n_numeric > 0 ? Vec.T_NUM : Vec.T_TIME;\r\n    Frame compFrame = new Frame();\r\n    for (int i = 0; i < fr.numCols(); i++) {\r\n        Vec vec = fr.vec(i);\r\n        if (n_numeric > 0 ? vec.isNumeric() : vec.isTime())\r\n            compFrame.add(fr.name(i), vec);\r\n    }\r\n    Vec anyvec = compFrame.anyVec();\r\n    if (anyvec == null) {\r\n        Frame res = new Frame(newkey);\r\n        anyvec = fr.anyVec();\r\n        if (anyvec != null) {\r\n            res.add(\"mean\", anyvec.makeCon(Double.NaN));\r\n        }\r\n        return new ValFrame(res);\r\n    }\r\n    if (!na_rm && n_numeric < fr.numCols() && n_time < fr.numCols()) {\r\n        Frame res = new Frame(newkey, newnames, new Vec[] { anyvec.makeCon(Double.NaN) });\r\n        return new ValFrame(res);\r\n    }\r\n    final int numCols = compFrame.numCols();\r\n    Frame res = new MRTask() {\r\n        @Override\r\n        public void map(Chunk[] cs, NewChunk nc) {\r\n            for (int i = 0; i < cs[0]._len; i++) {\r\n                double d = 0;\r\n                int numNaColumns = 0;\r\n                for (int j = 0; j < numCols; j++) {\r\n                    double val = cs[j].atd(i);\r\n                    if (Double.isNaN(val))\r\n                        numNaColumns++;\r\n                    else\r\n                        d += val;\r\n                }\r\n                if (na_rm ? numNaColumns < numCols : numNaColumns == 0)\r\n                    nc.addNum(d / (numCols - numNaColumns));\r\n                else\r\n                    nc.addNum(Double.NaN);\r\n            }\r\n        }\r\n    }.doAll(1, resType, compFrame).outputFrame(newkey, newnames, null);\r\n    return new ValFrame(res);\r\n}"
}, {
	"Path": "water.rapids.ast.prims.reducers.AstMean.rowwiseMean",
	"Comment": "compute frame means by rows, and return a frame consisting of a single vec of means in each row.",
	"Method": "ValFrame rowwiseMean(Frame fr,boolean na_rm){\r\n    for (int i = 0; i < cs[0]._len; i++) {\r\n        double d = 0;\r\n        int numNaColumns = 0;\r\n        for (int j = 0; j < numCols; j++) {\r\n            double val = cs[j].atd(i);\r\n            if (Double.isNaN(val))\r\n                numNaColumns++;\r\n            else\r\n                d += val;\r\n        }\r\n        if (na_rm ? numNaColumns < numCols : numNaColumns == 0)\r\n            nc.addNum(d / (numCols - numNaColumns));\r\n        else\r\n            nc.addNum(Double.NaN);\r\n    }\r\n}"
}, {
	"Path": "water.rapids.ast.prims.mungers.AstFillNATest.testBackwardMethodColAll",
	"Comment": "purpose here is to carry out short tests to make sure the code works and the single thread code works.",
	"Method": "void testBackwardMethodColAll(){\r\n    Scope.enter();\r\n    try {\r\n        Session sess = new Session();\r\n        Frame frAllNA = Scope.track(new TestFrameBuilder().withName(\"$fr\", sess).withColNames(\"C1\").withVecTypes(Vec.T_NUM).withDataForCol(0, ard(Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN)).build());\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 0\r\n        sess, // h2o.fillna with maxlen 0\r\n        frAllNA, // h2o.fillna with maxlen 0\r\n        frAllNA, // h2o.fillna with maxlen 0\r\n        0, \"(h2o.fillna $fr 'backward' 0 0)\", false);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 100\r\n        sess, // h2o.fillna with maxlen 100\r\n        frAllNA, // h2o.fillna with maxlen 100\r\n        frAllNA, // h2o.fillna with maxlen 100\r\n        100, \"(h2o.fillna $fr 'backward' 0 100)\", false);\r\n        Frame fr1NA = Scope.track(new TestFrameBuilder().withName(\"$fr2\", sess).withColNames(\"C1\").withVecTypes(Vec.T_NUM).withDataForCol(0, ard(Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, 1.234)).build());\r\n        Frame fr1NA1Ans = Scope.track(new TestFrameBuilder().withName(\"$fr1NA1Ans\", sess).withColNames(\"C1\").withVecTypes(Vec.T_NUM).withDataForCol(0, ard(Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, 1.234, 1.234)).build());\r\n        Frame fr1NA3Ans = Scope.track(new TestFrameBuilder().withName(\"$fr1NA3Ans\", sess).withColNames(\"C1\").withVecTypes(Vec.T_NUM).withDataForCol(0, ard(Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, 1.234, 1.234, 1.234, 1.234)).build());\r\n        Frame fr1NA100Ans = Scope.track(new TestFrameBuilder().withName(\"$fr1NA100Ans\", sess).withColNames(\"C1\").withVecTypes(Vec.T_NUM).withDataForCol(0, ard(1.234, 1.234, 1.234, 1.234, 1.234, 1.234, 1.234, 1.234, 1.234, 1.234)).build());\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 0\r\n        sess, // h2o.fillna with maxlen 0\r\n        fr1NA, // h2o.fillna with maxlen 0\r\n        fr1NA, // h2o.fillna with maxlen 0\r\n        0, \"(h2o.fillna $fr 'backward' 0 0)\", false);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 1\r\n        sess, // h2o.fillna with maxlen 1\r\n        fr1NA, // h2o.fillna with maxlen 1\r\n        fr1NA1Ans, // h2o.fillna with maxlen 1\r\n        1, \"(h2o.fillna $fr 'backward' 0 1)\", false);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 3\r\n        sess, // h2o.fillna with maxlen 3\r\n        fr1NA, // h2o.fillna with maxlen 3\r\n        fr1NA3Ans, // h2o.fillna with maxlen 3\r\n        3, \"(h2o.fillna $fr 'backward' 0 3)\", false);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 100\r\n        sess, // h2o.fillna with maxlen 100\r\n        fr1NA, // h2o.fillna with maxlen 100\r\n        fr1NA100Ans, // h2o.fillna with maxlen 100\r\n        100, \"(h2o.fillna $fr 'backward' 0 100)\", false);\r\n        Frame frMultipleNA = Scope.track(new TestFrameBuilder().withName(\"$frMultipleNA\", sess).withColNames(\"C1\").withVecTypes(Vec.T_NUM).withDataForCol(0, ard(1, Double.NaN, 2, Double.NaN, Double.NaN, 3, Double.NaN, Double.NaN, 4, Double.NaN, Double.NaN, Double.NaN, Double.NaN, 5, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, 6, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, 7, Double.NaN)).build());\r\n        Frame frMultipleNA1Fill = Scope.track(new TestFrameBuilder().withName(\"$frMultipleNA1Fill\", sess).withColNames(\"C1\").withVecTypes(Vec.T_NUM).withDataForCol(0, ard(1, 2, 2, Double.NaN, 3, 3, Double.NaN, 4, 4, Double.NaN, Double.NaN, Double.NaN, 5, 5, Double.NaN, Double.NaN, Double.NaN, Double.NaN, 6, 6, Double.NaN, Double.NaN, Double.NaN, Double.NaN, Double.NaN, 7, 7, Double.NaN)).build());\r\n        Frame frMultipleNA2Fill = Scope.track(new TestFrameBuilder().withName(\"$frMultipleNA2Fill\", sess).withColNames(\"C1\").withVecTypes(Vec.T_NUM).withDataForCol(0, ard(1, 2, 2, 3, 3, 3, 4, 4, 4, Double.NaN, Double.NaN, 5, 5, 5, Double.NaN, Double.NaN, Double.NaN, 6, 6, 6, Double.NaN, Double.NaN, Double.NaN, Double.NaN, 7, 7, 7, Double.NaN)).build());\r\n        Frame frMultipleNA3Fill = Scope.track(new TestFrameBuilder().withName(\"$frMultipleNA3Fill\", sess).withColNames(\"C1\").withVecTypes(Vec.T_NUM).withDataForCol(0, ard(1, 2, 2, 3, 3, 3, 4, 4, 4, Double.NaN, 5, 5, 5, 5, Double.NaN, Double.NaN, 6, 6, 6, 6, Double.NaN, Double.NaN, Double.NaN, 7, 7, 7, 7, Double.NaN)).build());\r\n        Frame frMultipleNA100Fill = Scope.track(new TestFrameBuilder().withName(\"$frMultipleNA100Fill\", sess).withColNames(\"C1\").withVecTypes(Vec.T_NUM).withDataForCol(0, ard(1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, Double.NaN)).build());\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 0\r\n        sess, // h2o.fillna with maxlen 0\r\n        frMultipleNA, // h2o.fillna with maxlen 0\r\n        frMultipleNA, // h2o.fillna with maxlen 0\r\n        0, \"(h2o.fillna $frMultipleNA 'backward' 0 0)\", false);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 1\r\n        sess, // h2o.fillna with maxlen 1\r\n        frMultipleNA, // h2o.fillna with maxlen 1\r\n        frMultipleNA1Fill, // h2o.fillna with maxlen 1\r\n        1, \"(h2o.fillna $frMultipleNA 'backward' 0 1)\", false);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 2\r\n        sess, // h2o.fillna with maxlen 2\r\n        frMultipleNA, // h2o.fillna with maxlen 2\r\n        frMultipleNA2Fill, // h2o.fillna with maxlen 2\r\n        2, \"(h2o.fillna $frMultipleNA 'backward' 0 2)\", false);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 3\r\n        sess, // h2o.fillna with maxlen 3\r\n        frMultipleNA, // h2o.fillna with maxlen 3\r\n        frMultipleNA3Fill, // h2o.fillna with maxlen 3\r\n        3, \"(h2o.fillna $frMultipleNA 'backward' 0 3)\", false);\r\n        assertNFillNACorrect(// h2o.fillna with maxlen 100\r\n        sess, // h2o.fillna with maxlen 100\r\n        frMultipleNA, // h2o.fillna with maxlen 100\r\n        frMultipleNA100Fill, // h2o.fillna with maxlen 100\r\n        100, \"(h2o.fillna $frMultipleNA 'backward' 0 100)\", false);\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.cast",
	"Comment": "return an expression casting the value to the specified type",
	"Method": "String cast(String value,int jdbcTypeCode,int length,int precision,int scale,String cast,String value,int jdbcTypeCode,int length,String cast,String value,int jdbcTypeCode,int precision,int scale){\r\n    return cast(value, jdbcTypeCode, Column.DEFAULT_LENGTH, precision, scale);\r\n}"
}, {
	"Path": "org.hibernate.type.spi.TypeConfiguration.getSessionFactory",
	"Comment": "obtain the sessionfactory currently scoping the typeconfiguration.",
	"Method": "SessionFactoryImplementor getSessionFactory(SessionFactoryImplementor getSessionFactory){\r\n    return scope.getSessionFactory();\r\n}"
}, {
	"Path": "org.hibernate.cfg.ImprovedNamingStrategy.logicalCollectionColumnName",
	"Comment": "return the column name if explicit or the concatenation of the property name and the referenced column",
	"Method": "String logicalCollectionColumnName(String columnName,String propertyName,String referencedColumn){\r\n    return StringHelper.isNotEmpty(columnName) ? columnName : StringHelper.unqualify(propertyName) + \"_\" + referencedColumn;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getDialect",
	"Comment": "get an instance of the dialect specified by the given properties or by\tthe current system properties.",
	"Method": "Dialect getDialect(Dialect getDialect,Properties props){\r\n    final String dialectName = props.getProperty(Environment.DIALECT);\r\n    if (dialectName == null) {\r\n        return getDialect();\r\n    }\r\n    return instantiateDialect(dialectName);\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.BinaryLogicOperatorNode.initialize",
	"Comment": "performs the operator node initialization by seeking out any parameter\tnodes and setting their expected type, if possible.",
	"Method": "void initialize(){\r\n    final Node lhs = getLeftHandOperand();\r\n    if (lhs == null) {\r\n        throw new SemanticException(\"left-hand operand of a binary operator was null\");\r\n    }\r\n    final Node rhs = getRightHandOperand();\r\n    if (rhs == null) {\r\n        throw new SemanticException(\"right-hand operand of a binary operator was null\");\r\n    }\r\n    Type lhsType = extractDataType(lhs);\r\n    Type rhsType = extractDataType(rhs);\r\n    if (lhsType == null) {\r\n        lhsType = rhsType;\r\n    }\r\n    if (rhsType == null) {\r\n        rhsType = lhsType;\r\n    }\r\n    if (ExpectedTypeAwareNode.class.isAssignableFrom(lhs.getClass())) {\r\n        ((ExpectedTypeAwareNode) lhs).setExpectedType(rhsType);\r\n    }\r\n    if (ExpectedTypeAwareNode.class.isAssignableFrom(rhs.getClass())) {\r\n        ((ExpectedTypeAwareNode) rhs).setExpectedType(lhsType);\r\n    }\r\n    mutateRowValueConstructorSyntaxesIfNecessary(lhsType, rhsType);\r\n}"
}, {
	"Path": "org.hibernate.type.EntityType.toLoggableString",
	"Comment": "generate a loggable representation of an instance of the value mapped by this type.",
	"Method": "String toLoggableString(Object value,SessionFactoryImplementor factory){\r\n    if (value == null) {\r\n        return \"null\";\r\n    }\r\n    final EntityPersister persister = getAssociatedEntityPersister(factory);\r\n    if (!persister.getEntityTuplizer().isInstance(value)) {\r\n        if (persister.getIdentifierType().getReturnedClass().isInstance(value)) {\r\n            return associatedEntityName + \"#\" + value;\r\n        }\r\n    }\r\n    final StringBuilder result = new StringBuilder().append(associatedEntityName);\r\n    if (persister.hasIdentifierProperty()) {\r\n        final Serializable id;\r\n        if (value instanceof HibernateProxy) {\r\n            HibernateProxy proxy = (HibernateProxy) value;\r\n            id = proxy.getHibernateLazyInitializer().getIdentifier();\r\n        } else {\r\n            id = persister.getIdentifier(value);\r\n        }\r\n        result.append('#').append(persister.getIdentifierType().toLoggableString(id, factory));\r\n    }\r\n    return result.toString();\r\n}"
}, {
	"Path": "org.hibernate.persister.walking.spi.MetamodelGraphWalker.addAssociationKey",
	"Comment": "add association key to indicate the association is being visited.",
	"Method": "void addAssociationKey(AssociationKey associationKey){\r\n    if (!visitedAssociationKeys.add(associationKey)) {\r\n        throw new WalkingException(String.format(\"Association has already been visited: %s\", associationKey));\r\n    }\r\n    strategy.associationKeyRegistered(associationKey);\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.ActionQueue.serialize",
	"Comment": "used by the owning session to explicitly control serialization of the action queue",
	"Method": "void serialize(ObjectOutputStream oos){\r\n    LOG.trace(\"Serializing action-queue\");\r\n    if (unresolvedInsertions == null) {\r\n        unresolvedInsertions = new UnresolvedEntityInsertActions();\r\n    }\r\n    unresolvedInsertions.serialize(oos);\r\n    for (ListProvider p : EXECUTABLE_LISTS_MAP.values()) {\r\n        ExecutableList<?> l = p.get(this);\r\n        if (l == null) {\r\n            oos.writeBoolean(false);\r\n        } else {\r\n            oos.writeBoolean(true);\r\n            l.writeExternal(oos);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.boot.registry.BootstrapServiceRegistryBuilder.applyStrategySelector",
	"Comment": "applies a named strategy implementation to the bootstrap registry.",
	"Method": "BootstrapServiceRegistryBuilder applyStrategySelector(Class<T> strategy,String name,Class<? extends T> implementation){\r\n    this.strategySelectorBuilder.addExplicitStrategyRegistration(strategy, implementation, name);\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.id.enhanced.TableGenerator.getSegmentColumnName",
	"Comment": "the name of the column in which we store the segment to which each row\tbelongs.the value here acts as pk.",
	"Method": "String getSegmentColumnName(){\r\n    return segmentColumnName;\r\n}"
}, {
	"Path": "org.hibernate.bytecode.enhance.spi.interceptor.LazyAttributeDescriptor.getFetchGroupName",
	"Comment": "access to the name of the fetch group to which the attribute belongs",
	"Method": "String getFetchGroupName(){\r\n    return fetchGroupName;\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.TwoPhaseLoad.getOverridingEager",
	"Comment": "check if eager of the association is overriden by anything.",
	"Method": "Boolean getOverridingEager(SharedSessionContractImplementor session,String entityName,String associationName,Type type){\r\n    if (type.isAssociationType() || type.isCollectionType()) {\r\n        Boolean overridingEager = isEagerFetchProfile(session, entityName + \".\" + associationName);\r\n        if (LOG.isDebugEnabled()) {\r\n            if (overridingEager != null) {\r\n                LOG.debugf(\"Overriding eager fetching using active fetch profile. EntityName: %s, associationName: %s, eager fetching: %s\", entityName, associationName, overridingEager);\r\n            }\r\n        }\r\n        return overridingEager;\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.toBooleanValueString",
	"Comment": "the sql literal value to which this database maps boolean values.",
	"Method": "String toBooleanValueString(boolean bool){\r\n    return bool ? \"1\" : \"0\";\r\n}"
}, {
	"Path": "org.hibernate.criterion.DetachedCriteria.getCriteriaImpl",
	"Comment": "retrieve the criteriaimpl used internally to hold the detachedcriteria state",
	"Method": "CriteriaImpl getCriteriaImpl(){\r\n    return impl;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.ASTUtil.findTypeInChildren",
	"Comment": "finds the first node of the specified type in the chain of children.",
	"Method": "AST findTypeInChildren(AST parent,int type){\r\n    AST n = parent.getFirstChild();\r\n    while (n != null && n.getType() != type) {\r\n        n = n.getNextSibling();\r\n    }\r\n    return n;\r\n}"
}, {
	"Path": "water.fvec.TestFrameBuilder.withName",
	"Comment": "sets the name for the frame. default name is created if this method is not called.",
	"Method": "TestFrameBuilder withName(String frameName,TestFrameBuilder withName,String frameName,Session session){\r\n    return withName(new Env(session).expand(frameName));\r\n}"
}, {
	"Path": "org.hibernate.dialect.pagination.SQLServer2005LimitHandler.locateQueryInCTEStatement",
	"Comment": "steps through the sql buffer from the specified offset and performs a series of pattern matches.\tthe method locates where the cte select clause begins and returns that offset from the sql buffer.",
	"Method": "int locateQueryInCTEStatement(StringBuilder sql,int offset){\r\n    while (true) {\r\n        Matcher matcher = WITH_EXPRESSION_NAME.matcher(sql.substring(offset));\r\n        if (matcher.find() && matcher.groupCount() > 0) {\r\n            offset += matcher.end();\r\n            matcher = WITH_COLUMN_NAMES_START.matcher(sql.substring(offset));\r\n            if (matcher.find() && matcher.groupCount() > 0) {\r\n                offset += matcher.end();\r\n                matcher = WITH_COLUMN_NAMES_END.matcher(sql.substring(offset));\r\n                if (matcher.find() && matcher.groupCount() > 0) {\r\n                    offset += matcher.end();\r\n                    offset += advanceOverCTEInnerQuery(sql, offset);\r\n                    matcher = WITH_COMMA.matcher(sql.substring(offset));\r\n                    if (matcher.find() && matcher.groupCount() > 0) {\r\n                        offset += matcher.end();\r\n                    } else {\r\n                        return offset;\r\n                    }\r\n                } else {\r\n                    throw new IllegalArgumentException(String.format(Locale.ROOT, \"Failed to parse CTE expression columns at offset %d, SQL [%s]\", offset, sql.toString()));\r\n                }\r\n            } else {\r\n                matcher = WITH_AS.matcher(sql.substring(offset));\r\n                if (matcher.find() && matcher.groupCount() > 0) {\r\n                    offset += matcher.end();\r\n                    offset += advanceOverCTEInnerQuery(sql, offset);\r\n                    matcher = WITH_COMMA.matcher(sql.substring(offset));\r\n                    if (matcher.find() && matcher.groupCount() > 0) {\r\n                        offset += matcher.end();\r\n                    } else {\r\n                        return offset;\r\n                    }\r\n                } else {\r\n                    throw new IllegalArgumentException(String.format(Locale.ROOT, \"Failed to locate AS keyword in CTE query at offset %d, SQL [%s]\", offset, sql.toString()));\r\n                }\r\n            }\r\n        } else {\r\n            throw new IllegalArgumentException(String.format(Locale.ROOT, \"Failed to locate CTE expression name at offset %d, SQL [%s]\", offset, sql.toString()));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.defaultScrollMode",
	"Comment": "certain dialects support a subset of scrollmodes.provide a default to be used by criteria and query.",
	"Method": "ScrollMode defaultScrollMode(){\r\n    return ScrollMode.SCROLL_INSENSITIVE;\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.Versioning.isVersionIncrementRequired",
	"Comment": "do we need to increment the version number, given the dirty properties?",
	"Method": "boolean isVersionIncrementRequired(int[] dirtyProperties,boolean hasDirtyCollections,boolean[] propertyVersionability){\r\n    if (hasDirtyCollections) {\r\n        return true;\r\n    }\r\n    for (int dirtyProperty : dirtyProperties) {\r\n        if (propertyVersionability[dirtyProperty]) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.persister.entity.AbstractEntityPersister.createLoaders",
	"Comment": "relational based persisters should be content with this implementation",
	"Method": "void createLoaders(){\r\n    noneLockLoader = createEntityLoader(LockMode.NONE);\r\n    readLockLoader = createEntityLoader(LockMode.READ);\r\n    if (!factory.getSessionFactoryOptions().isDelayBatchFetchLoaderCreationsEnabled()) {\r\n        for (LockMode lockMode : EnumSet.complementOf(EnumSet.of(LockMode.NONE, LockMode.READ, LockMode.WRITE))) {\r\n            loaders.put(lockMode, createEntityLoader(lockMode));\r\n        }\r\n    }\r\n    loaders.put(\"merge\", new CascadeEntityLoader(this, CascadingActions.MERGE, getFactory()));\r\n    loaders.put(\"refresh\", new CascadeEntityLoader(this, CascadingActions.REFRESH, getFactory()));\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.FromClause.containsTableAlias",
	"Comment": "returns true if the from node contains the table alias name.",
	"Method": "boolean containsTableAlias(String alias){\r\n    return fromElementByTableAlias.keySet().contains(alias);\r\n}"
}, {
	"Path": "org.hibernate.stat.internal.QueryStatisticsImpl.getExecutionAvgTime",
	"Comment": "average time in ms taken by the execution of this query onto the db",
	"Method": "long getExecutionAvgTime(){\r\n    return (long) getExecutionAvgTimeAsDouble();\r\n}"
}, {
	"Path": "org.hibernate.id.enhanced.SequenceStyleConfigUnitTest.testDefaultedTableBackedConfiguration",
	"Comment": "test all params defaulted with a dialect which does not support sequences",
	"Method": "void testDefaultedTableBackedConfiguration(){\r\n    StandardServiceRegistry serviceRegistry = new StandardServiceRegistryBuilder().applySetting(AvailableSettings.DIALECT, TableDialect.class.getName()).build();\r\n    try {\r\n        Properties props = buildGeneratorPropertiesBase(serviceRegistry);\r\n        SequenceStyleGenerator generator = new SequenceStyleGenerator();\r\n        generator.configure(StandardBasicTypes.LONG, props, serviceRegistry);\r\n        generator.registerExportables(new Database(new MetadataBuilderImpl.MetadataBuildingOptionsImpl(serviceRegistry)));\r\n        assertClassAssignability(TableStructure.class, generator.getDatabaseStructure().getClass());\r\n        assertClassAssignability(NoopOptimizer.class, generator.getOptimizer().getClass());\r\n        assertEquals(SequenceStyleGenerator.DEF_SEQUENCE_NAME, generator.getDatabaseStructure().getName());\r\n    } finally {\r\n        StandardServiceRegistryBuilder.destroy(serviceRegistry);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.internal.CriteriaImpl.getAlias",
	"Comment": "criteria impl ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~",
	"Method": "String getAlias(String getAlias){\r\n    return rootAlias;\r\n}"
}, {
	"Path": "org.hibernate.loader.custom.ColumnCollectionAliases.getSuffix",
	"Comment": "returns the suffix used to unique the column aliases for this particular alias set.",
	"Method": "String getSuffix(){\r\n    return \"\";\r\n}"
}, {
	"Path": "water.util.ReflectionUtils.findActualClassParameter",
	"Comment": "reflection helper which returns the actual class for a type parameter, even if itself is parameterized.",
	"Method": "Class<T> findActualClassParameter(Class clz,int parm){\r\n    Class parm_class = null;\r\n    if (clz.getGenericSuperclass() instanceof ParameterizedType) {\r\n        Type[] handler_type_parms = ((ParameterizedType) (clz.getGenericSuperclass())).getActualTypeArguments();\r\n        if (handler_type_parms[parm] instanceof Class) {\r\n            parm_class = (Class) handler_type_parms[parm];\r\n        } else if (handler_type_parms[parm] instanceof TypeVariable) {\r\n            TypeVariable v = (TypeVariable) (handler_type_parms[parm]);\r\n            Type t = v.getBounds()[0];\r\n            if (t instanceof Class)\r\n                parm_class = (Class) t;\r\n            else if (t instanceof ParameterizedType)\r\n                parm_class = (Class) ((ParameterizedType) t).getRawType();\r\n        } else if (handler_type_parms[parm] instanceof ParameterizedType) {\r\n            parm_class = (Class) ((ParameterizedType) (handler_type_parms[parm])).getRawType();\r\n        } else {\r\n            String msg = \"Iced parameter for handler: \" + clz + \" uses a type parameterization scheme that we don't yet handle: \" + handler_type_parms[parm];\r\n            Log.warn(msg);\r\n            throw H2O.fail(msg);\r\n        }\r\n    } else {\r\n        parm_class = Iced.class;\r\n    }\r\n    return (Class<T>) parm_class;\r\n}"
}, {
	"Path": "org.hibernate.id.enhanced.TableGenerator.getInitialValue",
	"Comment": "the initial value to use when we find no previous state in the\tgenerator table corresponding to our sequence.",
	"Method": "int getInitialValue(){\r\n    return initialValue;\r\n}"
}, {
	"Path": "hex.genmodel.easy.EasyPredictModelWrapper.predictAutoEncoder",
	"Comment": "make a prediction on a new data point using an autoencoder model.",
	"Method": "AutoEncoderModelPrediction predictAutoEncoder(RowData data){\r\n    validateModelCategory(ModelCategory.AutoEncoder);\r\n    int size = m.getPredsSize(ModelCategory.AutoEncoder);\r\n    double[] output = new double[size];\r\n    double[] rawData = nanArray(m.nfeatures());\r\n    rawData = fillRawData(data, rawData);\r\n    output = m.score0(rawData, output);\r\n    AutoEncoderModelPrediction p = new AutoEncoderModelPrediction();\r\n    p.original = expandRawData(rawData, output.length);\r\n    p.reconstructed = output;\r\n    p.reconstructedRowData = reconstructedToRowData(output);\r\n    return p;\r\n}"
}, {
	"Path": "org.hibernate.criterion.Restrictions.naturalId",
	"Comment": "consider using any of the natural id based loading stuff from session instead, especially in cases\twhere the restriction is the full set of natural id values.",
	"Method": "NaturalIdentifier naturalId(){\r\n    return new NaturalIdentifier();\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.QuerySyntaxException.convert",
	"Comment": "converts the given antlr recognitionexception into a querysyntaxexception.the recognitionexception\tdoes not become the cause because antlr exceptions are not serializable.",
	"Method": "QuerySyntaxException convert(RecognitionException e,QuerySyntaxException convert,RecognitionException e,String hql){\r\n    String positionInfo = e.getLine() > 0 && e.getColumn() > 0 ? \" near line \" + e.getLine() + \", column \" + e.getColumn() : \"\";\r\n    return new QuerySyntaxException(e.getMessage() + positionInfo, hql);\r\n}"
}, {
	"Path": "org.hibernate.tool.hbm2ddl.SchemaExportTask.setDelimiter",
	"Comment": "set the end of statement delimiter for the generated script",
	"Method": "void setDelimiter(String delimiter){\r\n    this.delimiter = delimiter;\r\n}"
}, {
	"Path": "org.hibernate.jpa.test.callbacks.CallbacksTest.listenerAnnotation",
	"Comment": "not a test since the spec did not make the proper change on listeners",
	"Method": "void listenerAnnotation(){\r\n    EntityManager em = getOrCreateEntityManager();\r\n    Translation tl = new Translation();\r\n    em.getTransaction().begin();\r\n    tl.setInto(\"France\");\r\n    em.persist(tl);\r\n    tl = new Translation();\r\n    tl.setInto(\"Bimboland\");\r\n    try {\r\n        em.persist(tl);\r\n        em.flush();\r\n        fail(\"Annotations annotated by a listener not used\");\r\n    } catch (IllegalArgumentException e) {\r\n    } finally {\r\n        em.getTransaction().rollback();\r\n        em.close();\r\n    }\r\n}"
}, {
	"Path": "hex.tree.xgboost.rabit.communication.XGBoostAutoBuffer.getStr",
	"Comment": "used to communicate with external frameworks, for example xgboost",
	"Method": "String getStr(){\r\n    int len = ab.get4();\r\n    return len == -1 ? null : new String(ab.getA1(len), UTF_8);\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.BatchFetchQueue.addBatchLoadableCollection",
	"Comment": "if a collectionentry represents a batch loadable collection, add\tit to the queue.",
	"Method": "void addBatchLoadableCollection(PersistentCollection collection,CollectionEntry ce){\r\n    final CollectionPersister persister = ce.getLoadedPersister();\r\n    LinkedHashMap<CollectionEntry, PersistentCollection> map = batchLoadableCollections.get(persister.getRole());\r\n    if (map == null) {\r\n        map = new LinkedHashMap(16);\r\n        batchLoadableCollections.put(persister.getRole(), map);\r\n    }\r\n    map.put(ce, collection);\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.StreamUtils.copy",
	"Comment": "copy the reader to the writer using a buffer of the specified size",
	"Method": "long copy(InputStream inputStream,OutputStream outputStream,long copy,InputStream inputStream,OutputStream outputStream,int bufferSize,long copy,Reader reader,Writer writer,long copy,Reader reader,Writer writer,int bufferSize){\r\n    final char[] buffer = new char[bufferSize];\r\n    long count = 0;\r\n    int n;\r\n    while (-1 != (n = reader.read(buffer))) {\r\n        writer.write(buffer, 0, n);\r\n        count += n;\r\n    }\r\n    return count;\r\n}"
}, {
	"Path": "org.hibernate.criterion.Property.in",
	"Comment": "creates an in restriction for this property based on the given list of literals",
	"Method": "Criterion in(Collection values,Criterion in,Object values,Criterion in,DetachedCriteria subselect){\r\n    return Subqueries.propertyIn(getPropertyName(), subselect);\r\n}"
}, {
	"Path": "org.hibernate.internal.util.config.ConfigurationHelper.resolvePlaceHolders",
	"Comment": "handles interpolation processing for all entries in a properties object.",
	"Method": "void resolvePlaceHolders(Map<?, ?> configurationValues){\r\n    Iterator itr = configurationValues.entrySet().iterator();\r\n    while (itr.hasNext()) {\r\n        final Map.Entry entry = (Map.Entry) itr.next();\r\n        final Object value = entry.getValue();\r\n        if (value != null && String.class.isInstance(value)) {\r\n            final String resolved = resolvePlaceHolder((String) value);\r\n            if (!value.equals(resolved)) {\r\n                if (resolved == null) {\r\n                    itr.remove();\r\n                } else {\r\n                    entry.setValue(resolved);\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.transform.AliasToBeanConstructorResultTransformer.transformTuple",
	"Comment": "wrap the incoming tuples in a call to our configured constructor.",
	"Method": "Object transformTuple(Object[] tuple,String[] aliases){\r\n    try {\r\n        return constructor.newInstance(tuple);\r\n    } catch (Exception e) {\r\n        throw new QueryException(\"could not instantiate class [\" + constructor.getDeclaringClass().getName() + \"] from tuple\", e);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.SelectExpressionList.getParameterPositions",
	"Comment": "the position of parameters within the list of select expressions of this clause",
	"Method": "List<Integer> getParameterPositions(){\r\n    return parameterPositions;\r\n}"
}, {
	"Path": "org.hibernate.stat.internal.NaturalIdStatisticsImpl.getExecutionAvgTime",
	"Comment": "average time in ms taken by the excution of this query onto the db",
	"Method": "long getExecutionAvgTime(){\r\n    this.writeLock.lock();\r\n    try {\r\n        long avgExecutionTime = 0;\r\n        if (this.executionCount.get() > 0) {\r\n            avgExecutionTime = this.totalExecutionTime.get() / this.executionCount.get();\r\n        }\r\n        return avgExecutionTime;\r\n    } finally {\r\n        this.writeLock.unlock();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.stat.internal.QueryStatisticsImpl.getExecutionTotalTime",
	"Comment": "total time in ms taken by the execution of this query onto the db",
	"Method": "long getExecutionTotalTime(){\r\n    return totalExecutionTime.get();\r\n}"
}, {
	"Path": "water.rapids.ast.prims.operators.AstBinOp.alignCategoricals",
	"Comment": "produces a mapping array with indexes of the smaller pointing to the larger domain.",
	"Method": "int[] alignCategoricals(String[] longerDomain,String[] shorterDomain){\r\n    String[] sortedLongerDomain = Arrays.copyOf(longerDomain, longerDomain.length);\r\n    Arrays.sort(sortedLongerDomain);\r\n    int[] transformedIndices = MemoryManager.malloc4(shorterDomain.length);\r\n    for (int i = 0; i < shorterDomain.length; i++) {\r\n        transformedIndices[i] = Arrays.binarySearch(sortedLongerDomain, shorterDomain[i]);\r\n    }\r\n    return transformedIndices;\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert",
	"Comment": "convert an sqlexception using the current converter, doing some logging first.",
	"Method": "JDBCException convert(SQLException sqlException,String message,JDBCException convert,SQLException sqlException,String message,String sql){\r\n    logExceptions(sqlException, message + \" [\" + sql + \"]\");\r\n    return sqlExceptionConverter.convert(sqlException, message, sql);\r\n}"
}, {
	"Path": "water.util.FileUtils.close",
	"Comment": "closes given files, logging exceptions thrown during the process of closing.",
	"Method": "void close(Closeable closeable){\r\n    for (Closeable c : closeable) try {\r\n        if (c != null)\r\n            c.close();\r\n    } catch (IOException ex) {\r\n        Log.err(ex);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cfg.Ejb3JoinColumn.setPersistentClass",
	"Comment": "override persistent class on onetomany cases for late settings\tmust only be used on second level pass binding",
	"Method": "void setPersistentClass(PersistentClass persistentClass,Map<String, Join> joins,Map<XClass, InheritanceState> inheritanceStatePerClass){\r\n    this.propertyHolder = PropertyHolderBuilder.buildPropertyHolder(persistentClass, joins, getBuildingContext(), inheritanceStatePerClass);\r\n}"
}, {
	"Path": "org.hibernate.type.descriptor.java.DataHelper.getSuggestedBufferSize",
	"Comment": "make sure we allocate a buffer sized not bigger than 2048,\tnot higher than what is actually needed, and at least one.",
	"Method": "int getSuggestedBufferSize(int lengthHint){\r\n    return Math.max(1, Math.min(lengthHint, BUFFER_SIZE));\r\n}"
}, {
	"Path": "org.hibernate.action.internal.UnresolvedEntityInsertActions.isEmpty",
	"Comment": "returns true if there are no unresolved entity insert actions.",
	"Method": "boolean isEmpty(){\r\n    return dependenciesByAction.isEmpty();\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.ParamLocationRecognizer.parseLocations",
	"Comment": "convenience method for creating a param location recognizer and\tinitiating the parse.",
	"Method": "ParamLocationRecognizer parseLocations(String query,SessionFactoryImplementor sessionFactory){\r\n    final ParamLocationRecognizer recognizer = new ParamLocationRecognizer(sessionFactory.getSessionFactoryOptions().jdbcStyleParamsZeroBased() ? 0 : 1);\r\n    ParameterParser.parse(query, recognizer);\r\n    return recognizer;\r\n}"
}, {
	"Path": "hex.genmodel.algos.glrm.GlrmMojoModel.applyBestAlpha",
	"Comment": "this method will try a bunch of arbitray alpha values and pick the best to return which get the best objimprovement.",
	"Method": "double applyBestAlpha(double[] u,double[] x,double[] grad,double[] a,double oldObj,Random random){\r\n    double[] bestX = new double[x.length];\r\n    double lowestObj = Double.MAX_VALUE;\r\n    if (oldObj == 0) {\r\n        return 0;\r\n    }\r\n    double alphaScale = oldObj > 10 ? (1.0 / oldObj) : 1.0;\r\n    for (int index = 0; index < _numAlphaFactors; index++) {\r\n        double alpha = _allAlphas[index] * alphaScale;\r\n        for (int k = 0; k < _ncolX; k++) {\r\n            u[k] = x[k] - alpha * grad[k];\r\n        }\r\n        double[] xnew = _regx.rproxgrad(u, alpha * _gammax, random);\r\n        double newobj = objective(xnew, a);\r\n        if (lowestObj > newobj) {\r\n            System.arraycopy(xnew, 0, bestX, 0, xnew.length);\r\n            lowestObj = newobj;\r\n        }\r\n        if (newobj == 0)\r\n            break;\r\n    }\r\n    if (lowestObj < oldObj)\r\n        System.arraycopy(bestX, 0, x, 0, x.length);\r\n    return lowestObj;\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.EntityEntryContext.hasEntityEntry",
	"Comment": "does this entity exist in this context, associated with an entityentry?",
	"Method": "boolean hasEntityEntry(Object entity){\r\n    return getEntityEntry(entity) != null;\r\n}"
}, {
	"Path": "org.hibernate.internal.util.config.ConfigurationHelper.toMap",
	"Comment": "constructs a map from a property value.\tthe exact behavior here is largely dependant upon what is passed in as\tthe delimiter.",
	"Method": "Map toMap(String propertyName,String delim,Properties properties,Map toMap,String propertyName,String delim,Map properties){\r\n    Map map = new HashMap();\r\n    String value = extractPropertyValue(propertyName, properties);\r\n    if (value != null) {\r\n        StringTokenizer tokens = new StringTokenizer(value, delim);\r\n        while (tokens.hasMoreTokens()) {\r\n            map.put(tokens.nextToken(), tokens.hasMoreElements() ? tokens.nextToken() : \"\");\r\n        }\r\n    }\r\n    return map;\r\n}"
}, {
	"Path": "org.hibernate.loader.JoinWalker.countCollectionPersisters",
	"Comment": "count the number of instances of joinable which are actually\talso instances of persistentcollection which are being fetched\tby outer join",
	"Method": "int countCollectionPersisters(List associations){\r\n    int result = 0;\r\n    for (Object association : associations) {\r\n        final OuterJoinableAssociation oj = (OuterJoinableAssociation) association;\r\n        if (oj.getJoinType() == JoinType.LEFT_OUTER_JOIN && oj.getJoinable().isCollection() && !oj.hasRestriction()) {\r\n            result++;\r\n        }\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.jpa.boot.spi.ProviderChecker.hibernateProviderNamesContain",
	"Comment": "is the requested provider name one of the recognized hibernate provider names?",
	"Method": "boolean hibernateProviderNamesContain(String requestedProviderName){\r\n    log.tracef(\"Checking requested PersistenceProvider name [%s] against Hibernate provider names\", requestedProviderName);\r\n    final String deprecatedPersistenceProvider = \"org.hibernate.ejb.HibernatePersistence\";\r\n    if (deprecatedPersistenceProvider.equals(requestedProviderName)) {\r\n        HEMLogging.messageLogger(ProviderChecker.class).deprecatedPersistenceProvider(deprecatedPersistenceProvider, HibernatePersistenceProvider.class.getName());\r\n        return true;\r\n    }\r\n    return HibernatePersistenceProvider.class.getName().equals(requestedProviderName);\r\n}"
}, {
	"Path": "org.hibernate.boot.registry.BootstrapServiceRegistryBuilder.applyStrategySelectors",
	"Comment": "applies one or more strategy selectors announced as available by the passed announcer.",
	"Method": "BootstrapServiceRegistryBuilder applyStrategySelectors(StrategyRegistrationProvider strategyRegistrationProvider){\r\n    for (StrategyRegistration strategyRegistration : strategyRegistrationProvider.getStrategyRegistrations()) {\r\n        this.strategySelectorBuilder.addExplicitStrategyRegistration(strategyRegistration);\r\n    }\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.internal.util.collections.CollectionHelper.mapOfSize",
	"Comment": "build a properly sized map, especially handling load size and load factor to prevent immediate resizing.\tespecially helpful for copy map contents.",
	"Method": "Map<K, V> mapOfSize(int size){\r\n    return new HashMap(determineProperSizing(size), LOAD_FACTOR);\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.readCollectionElement",
	"Comment": "read one collection element from the current row of the jdbc result set",
	"Method": "void readCollectionElement(Object optionalOwner,Serializable optionalKey,CollectionPersister persister,CollectionAliases descriptor,ResultSet rs,SharedSessionContractImplementor session){\r\n    final PersistenceContext persistenceContext = session.getPersistenceContext();\r\n    final Serializable collectionRowKey = (Serializable) persister.readKey(rs, descriptor.getSuffixedKeyAliases(), session);\r\n    if (collectionRowKey != null) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debugf(\"Found row of collection: %s\", MessageHelper.collectionInfoString(persister, collectionRowKey, getFactory()));\r\n        }\r\n        Object owner = optionalOwner;\r\n        if (owner == null) {\r\n            owner = persistenceContext.getCollectionOwner(collectionRowKey, persister);\r\n            if (owner == null) {\r\n            }\r\n        }\r\n        PersistentCollection rowCollection = persistenceContext.getLoadContexts().getCollectionLoadContext(rs).getLoadingCollection(persister, collectionRowKey);\r\n        if (rowCollection != null) {\r\n            rowCollection.readFrom(rs, persister, descriptor, owner);\r\n        }\r\n    } else if (optionalKey != null) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debugf(\"Result set contains (possibly empty) collection: %s\", MessageHelper.collectionInfoString(persister, optionalKey, getFactory()));\r\n        }\r\n        // handle empty collection\r\n        persistenceContext.getLoadContexts().getCollectionLoadContext(rs).getLoadingCollection(persister, optionalKey);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.EntityEntryContext.removeEntityEntry",
	"Comment": "remove an entity from the context, returning the entityentry which was associated with it",
	"Method": "EntityEntry removeEntityEntry(Object entity){\r\n    final ManagedEntity managedEntity = getAssociatedManagedEntity(entity);\r\n    if (managedEntity == null) {\r\n        return null;\r\n    }\r\n    dirty = true;\r\n    if (ImmutableManagedEntityHolder.class.isInstance(managedEntity)) {\r\n        assert entity == ((ImmutableManagedEntityHolder) managedEntity).managedEntity;\r\n        immutableManagedEntityXref.remove((ManagedEntity) entity);\r\n    } else if (!ManagedEntity.class.isInstance(entity)) {\r\n        nonEnhancedEntityXref.remove(entity);\r\n    }\r\n    final ManagedEntity previous = managedEntity.$$_hibernate_getPreviousManagedEntity();\r\n    final ManagedEntity next = managedEntity.$$_hibernate_getNextManagedEntity();\r\n    managedEntity.$$_hibernate_setPreviousManagedEntity(null);\r\n    managedEntity.$$_hibernate_setNextManagedEntity(null);\r\n    count--;\r\n    if (count == 0) {\r\n        head = null;\r\n        tail = null;\r\n        assert previous == null;\r\n        assert next == null;\r\n    } else {\r\n        if (previous == null) {\r\n            assert managedEntity == head;\r\n            head = next;\r\n        } else {\r\n            previous.$$_hibernate_setNextManagedEntity(next);\r\n        }\r\n        if (next == null) {\r\n            assert managedEntity == tail;\r\n            tail = previous;\r\n        } else {\r\n            next.$$_hibernate_setPreviousManagedEntity(previous);\r\n        }\r\n    }\r\n    final EntityEntry theEntityEntry = managedEntity.$$_hibernate_getEntityEntry();\r\n    managedEntity.$$_hibernate_setEntityEntry(null);\r\n    return theEntityEntry;\r\n}"
}, {
	"Path": "org.hibernate.persister.collection.AbstractCollectionPersister.getInitializer",
	"Comment": "intended for internal use only. in fact really only currently used from\ttest suite for assertion purposes.",
	"Method": "CollectionInitializer getInitializer(){\r\n    return initializer;\r\n}"
}, {
	"Path": "org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitCollection",
	"Comment": "entry point into walking the model graph of a collection according to its defined metamodel.",
	"Method": "void visitCollection(AssociationVisitationStrategy strategy,CollectionPersister persister){\r\n    strategy.start();\r\n    try {\r\n        new MetamodelGraphWalker(strategy, persister.getFactory()).visitCollectionDefinition(persister);\r\n    } finally {\r\n        strategy.finish();\r\n    }\r\n}"
}, {
	"Path": "hex.createframe.OriginalCreateFrameRecipeTest.testAllColumnTypes",
	"Comment": "test that columns of all types can be created, and that there is the correct number of eachin the resulting frame.",
	"Method": "void testAllColumnTypes(){\r\n    CreateFrameOriginalIV4 s = new CreateFrameOriginalIV4().fillFromImpl();\r\n    s.rows = 100;\r\n    s.cols = 100;\r\n    s.categorical_fraction = 0.10000000000001;\r\n    s.integer_fraction = 0.099999999999998;\r\n    s.binary_fraction = 0.10000000000003;\r\n    s.time_fraction = 0.1200045762024587;\r\n    s.string_fraction = 0.16000204587202;\r\n    s.binary_ones_fraction = 0.1;\r\n    s.factors = 5;\r\n    s.response_factors = 5;\r\n    s.positive_response = false;\r\n    s.has_response = true;\r\n    s.seed = 1234567;\r\n    Frame frame = s.createAndFillImpl().exec().get();\r\n    assertNotNull(frame);\r\n    assertEquals(\"response\", frame.name(0));\r\n    assertEquals(s.cols + 1, frame.numCols());\r\n    assertEquals(s.rows, frame.numRows());\r\n    assertEquals(Math.round(s.cols * s.categorical_fraction) + 1, countVecsOfType(frame, \"enum\"));\r\n    assertEquals(Math.round(s.cols * s.time_fraction), countVecsOfType(frame, \"time\"));\r\n    assertEquals(Math.round(s.cols * s.string_fraction), countVecsOfType(frame, \"str\"));\r\n    assertEquals(Math.round(s.cols * s.integer_fraction), countVecsOfType(frame, \"int\"));\r\n    assertEquals(Math.round(s.cols * s.binary_fraction), countVecsOfType(frame, \"bool\"));\r\n    Log.info(frame.toString());\r\n    frame.delete();\r\n}"
}, {
	"Path": "org.hibernate.internal.util.ConfigHelper.findAsResource",
	"Comment": "try to locate a local url representing the incoming path.\tthis method only attempts to locate this url as a\tjava system resource.",
	"Method": "URL findAsResource(String path){\r\n    URL url = null;\r\n    ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\r\n    if (contextClassLoader != null) {\r\n        url = contextClassLoader.getResource(path);\r\n    }\r\n    if (url != null) {\r\n        return url;\r\n    }\r\n    url = ConfigHelper.class.getClassLoader().getResource(path);\r\n    if (url != null) {\r\n        return url;\r\n    }\r\n    url = ClassLoader.getSystemClassLoader().getResource(path);\r\n    return url;\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.FilterDefinition.getParameterType",
	"Comment": "retrieve the type of the named parameter defined for this filter.",
	"Method": "Type getParameterType(String parameterName){\r\n    return parameterTypes.get(parameterName);\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.ASTUtil.createSibling",
	"Comment": "creates a single node ast as a sibling of the passed prevsibling,\ttaking care to reorganize the tree correctly to account for this\tnewly created node.",
	"Method": "AST createSibling(ASTFactory astFactory,int type,String text,AST prevSibling){\r\n    AST node = astFactory.create(type, text);\r\n    return insertSibling(node, prevSibling);\r\n}"
}, {
	"Path": "water.fvec.TestFrameBuilderTest.testWrongVecNameSize",
	"Comment": "this test throws exception because size of specified vectors and size of specified names differ",
	"Method": "void testWrongVecNameSize(){\r\n    Frame fr = new TestFrameBuilder().withVecTypes(Vec.T_CAT, Vec.T_NUM, Vec.T_TIME, Vec.T_STR).withColNames(\"A\", \"B\").build();\r\n    fr.remove();\r\n}"
}, {
	"Path": "org.hibernate.loader.hql.QueryLoader.getNamedParameterLocs",
	"Comment": "returns the locations of all occurrences of the named parameter.",
	"Method": "int[] getNamedParameterLocs(String name){\r\n    ParameterInformation info = queryTranslator.getParameterTranslations().getNamedParameterInformation(name);\r\n    if (info == null) {\r\n        try {\r\n            info = queryTranslator.getParameterTranslations().getPositionalParameterInformation(Integer.parseInt(name));\r\n        } catch (Exception ignore) {\r\n        }\r\n    }\r\n    if (info == null) {\r\n        throw new QueryException(\"Unrecognized parameter label : \" + name);\r\n    }\r\n    return info.getSourceLocations();\r\n}"
}, {
	"Path": "org.hibernate.query.Query.setTimestamp",
	"Comment": "bind the value and the time of a given date object to a named query parameter.",
	"Method": "Query<R> setTimestamp(int position,Date val,Query<R> setTimestamp,String name,Date value){\r\n    setParameter(name, value, TimestampType.INSTANCE);\r\n    return this;\r\n}"
}, {
	"Path": "org.hibernate.internal.FilterImpl.getParameter",
	"Comment": "get the value of the named parameter for the current filter.",
	"Method": "Object getParameter(String name){\r\n    return parameters.get(name);\r\n}"
}, {
	"Path": "water.Value.isReleasable",
	"Comment": "return true if blocking is unnecessary. alas, used in two places and the blocking api forces them to share here.",
	"Method": "boolean isReleasable(){\r\n    int r = _rwlock.get();\r\n    if (_key.home()) {\r\n        return r <= 0;\r\n    } else {\r\n        assert r == 2 || r == -1;\r\n        return r == -1;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.closeQuote",
	"Comment": "the character specific to this dialect used to close a quoted identifier.",
	"Method": "char closeQuote(){\r\n    return '\"';\r\n}"
}, {
	"Path": "org.hibernate.bytecode.enhance.internal.javassist.AttributeTypeDescriptor.resolve",
	"Comment": "factory method to get the attributetypedescriptor for a particular field type",
	"Method": "AttributeTypeDescriptor resolve(CtClass managedCtClass,CtField persistentField){\r\n    boolean inherited = !managedCtClass.equals(persistentField.getDeclaringClass());\r\n    boolean visible = persistentField.visibleFrom(managedCtClass);\r\n    String readerName = EnhancerConstants.PERSISTENT_FIELD_READER_PREFIX + persistentField.getName();\r\n    String writerName = EnhancerConstants.PERSISTENT_FIELD_WRITER_PREFIX + persistentField.getName();\r\n    InheritanceMetadata inheritanceMetadata = new InheritanceMetadata(inherited, visible, readerName, writerName);\r\n    if (CtClass.booleanType.equals(persistentField.getType())) {\r\n        return new PrimitiveAttributeTypeDescriptor(inheritanceMetadata, Boolean.TYPE);\r\n    } else if (CtClass.byteType.equals(persistentField.getType())) {\r\n        return new PrimitiveAttributeTypeDescriptor(inheritanceMetadata, Byte.TYPE);\r\n    } else if (CtClass.charType.equals(persistentField.getType())) {\r\n        return new PrimitiveAttributeTypeDescriptor(inheritanceMetadata, Character.TYPE);\r\n    } else if (CtClass.shortType.equals(persistentField.getType())) {\r\n        return new PrimitiveAttributeTypeDescriptor(inheritanceMetadata, Short.TYPE);\r\n    } else if (CtClass.intType.equals(persistentField.getType())) {\r\n        return new PrimitiveAttributeTypeDescriptor(inheritanceMetadata, Integer.TYPE);\r\n    } else if (CtClass.longType.equals(persistentField.getType())) {\r\n        return new PrimitiveAttributeTypeDescriptor(inheritanceMetadata, Long.TYPE);\r\n    } else if (CtClass.doubleType.equals(persistentField.getType())) {\r\n        return new PrimitiveAttributeTypeDescriptor(inheritanceMetadata, Double.TYPE);\r\n    } else if (CtClass.floatType.equals(persistentField.getType())) {\r\n        return new PrimitiveAttributeTypeDescriptor(inheritanceMetadata, Float.TYPE);\r\n    } else {\r\n        return new ObjectAttributeTypeDescriptor(inheritanceMetadata, persistentField.getType());\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cfg.AbstractPropertyHolder.getExactOverriddenJoinTable",
	"Comment": "get column overriding, property first, then parent, then holder",
	"Method": "JoinTable getExactOverriddenJoinTable(String propertyName){\r\n    JoinTable override = null;\r\n    if (parent != null) {\r\n        override = parent.getExactOverriddenJoinTable(propertyName);\r\n    }\r\n    if (override == null && currentPropertyJoinTableOverride != null) {\r\n        override = currentPropertyJoinTableOverride.get(propertyName);\r\n    }\r\n    if (override == null && holderJoinTableOverride != null) {\r\n        override = holderJoinTableOverride.get(propertyName);\r\n    }\r\n    return override;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.SessionFactoryHelper.getCollectionElementColumns",
	"Comment": "retrieves the column names corresponding to the collection elements for the given\tcollection role.",
	"Method": "String[] getCollectionElementColumns(String role,String roleAlias){\r\n    return getCollectionPropertyMapping(role).toColumns(roleAlias, CollectionPropertyNames.COLLECTION_ELEMENTS);\r\n}"
}, {
	"Path": "org.hibernate.loader.criteria.CriteriaJoinWalker.getWhereFragment",
	"Comment": "use the discriminator, to narrow the select to instances\tof the queried subclass, also applying any filters.",
	"Method": "String getWhereFragment(){\r\n    return super.getWhereFragment() + ((Queryable) getPersister()).filterFragment(getAlias(), getLoadQueryInfluencers().getEnabledFilters());\r\n}"
}, {
	"Path": "org.hibernate.event.spi.PostActionEventListener.requiresPostCommitHandling",
	"Comment": "does this listener require that after transaction hooks be registered?",
	"Method": "boolean requiresPostCommitHandling(EntityPersister persister){\r\n    return requiresPostCommitHanding(persister);\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.ASTUtil.findPreviousSibling",
	"Comment": "find the previous sibling in the parent for the given child.",
	"Method": "AST findPreviousSibling(AST parent,AST child){\r\n    AST prev = null;\r\n    AST n = parent.getFirstChild();\r\n    while (n != null) {\r\n        if (n == child) {\r\n            return prev;\r\n        }\r\n        prev = n;\r\n        n = n.getNextSibling();\r\n    }\r\n    throw new IllegalArgumentException(\"Child not found in parent!\");\r\n}"
}, {
	"Path": "org.hibernate.event.internal.AbstractVisitor.processValue",
	"Comment": "visit a property value. dispatch to the\tcorrect handler for the property type.",
	"Method": "void processValue(int i,Object[] values,Type[] types,Object processValue,Object value,Type type){\r\n    if (type.isCollectionType()) {\r\n        return processCollection(value, (CollectionType) type);\r\n    } else if (type.isEntityType()) {\r\n        return processEntity(value, (EntityType) type);\r\n    } else if (type.isComponentType()) {\r\n        return processComponent(value, (CompositeType) type);\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.internal.SessionFactoryImpl.deserialize",
	"Comment": "custom deserialization hook used during session deserialization.",
	"Method": "SessionFactoryImpl deserialize(ObjectInputStream ois){\r\n    LOG.trace(\"Deserializing SessionFactory from Session\");\r\n    final String uuid = ois.readUTF();\r\n    boolean isNamed = ois.readBoolean();\r\n    final String name = isNamed ? ois.readUTF() : null;\r\n    return (SessionFactoryImpl) locateSessionFactoryOnDeserialization(uuid, name);\r\n}"
}, {
	"Path": "org.hibernate.query.criteria.internal.path.AbstractPathImpl.locateAttribute",
	"Comment": "get the attribute by name from the underlying model.this allows subclasses to\tdefine exactly how the attribute is derived.",
	"Method": "Attribute locateAttribute(String attributeName){\r\n    final Attribute attribute = locateAttributeInternal(attributeName);\r\n    if (attribute == null) {\r\n        throw unknownAttribute(attributeName);\r\n    }\r\n    return attribute;\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.EntityEntryContext.addEntityEntry",
	"Comment": "adds the entity and entry to this context, associating them together",
	"Method": "void addEntityEntry(Object entity,EntityEntry entityEntry){\r\n    dirty = true;\r\n    assert AbstractEntityEntry.class.isInstance(entityEntry);\r\n    if (entityEntry.getPersister().isMutable()) {\r\n        assert AbstractEntityEntry.class.cast(entityEntry).getPersistenceContext() == persistenceContext;\r\n    }\r\n    ManagedEntity managedEntity = getAssociatedManagedEntity(entity);\r\n    final boolean alreadyAssociated = managedEntity != null;\r\n    if (!alreadyAssociated) {\r\n        if (ManagedEntity.class.isInstance(entity)) {\r\n            if (entityEntry.getPersister().isMutable()) {\r\n                managedEntity = (ManagedEntity) entity;\r\n                checkNotAssociatedWithOtherPersistenceContextIfMutable(managedEntity);\r\n            } else {\r\n                managedEntity = new ImmutableManagedEntityHolder((ManagedEntity) entity);\r\n                if (immutableManagedEntityXref == null) {\r\n                    immutableManagedEntityXref = new IdentityHashMap<ManagedEntity, ImmutableManagedEntityHolder>();\r\n                }\r\n                immutableManagedEntityXref.put((ManagedEntity) entity, (ImmutableManagedEntityHolder) managedEntity);\r\n            }\r\n        } else {\r\n            if (nonEnhancedEntityXref == null) {\r\n                nonEnhancedEntityXref = new IdentityHashMap<Object, ManagedEntity>();\r\n            }\r\n            managedEntity = new ManagedEntityImpl(entity);\r\n            nonEnhancedEntityXref.put(entity, managedEntity);\r\n        }\r\n    }\r\n    managedEntity.$$_hibernate_setEntityEntry(entityEntry);\r\n    if (alreadyAssociated) {\r\n        return;\r\n    }\r\n    if (tail == null) {\r\n        assert head == null;\r\n        managedEntity.$$_hibernate_setPreviousManagedEntity(null);\r\n        managedEntity.$$_hibernate_setNextManagedEntity(null);\r\n        head = managedEntity;\r\n        tail = head;\r\n        count = 1;\r\n    } else {\r\n        tail.$$_hibernate_setNextManagedEntity(managedEntity);\r\n        managedEntity.$$_hibernate_setPreviousManagedEntity(tail);\r\n        managedEntity.$$_hibernate_setNextManagedEntity(null);\r\n        tail = managedEntity;\r\n        count++;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.bindLimitParametersFirst",
	"Comment": "does the limit clause come at the start of the\tselect statement, rather than at the end?",
	"Method": "boolean bindLimitParametersFirst(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.mapping.MappedSuperclass.hasProperty",
	"Comment": "check to see if this mappedsuperclass defines a property with the given name.",
	"Method": "boolean hasProperty(String name){\r\n    final Iterator itr = getDeclaredPropertyIterator();\r\n    while (itr.hasNext()) {\r\n        final Property property = (Property) itr.next();\r\n        if (property.getName().equals(name)) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "hex.genmodel.MojoModel.load",
	"Comment": "advanced way of constructing mojo models by supplying a custom mojoreader.",
	"Method": "MojoModel load(String file,MojoModel load,MojoReaderBackend mojoReader){\r\n    return ModelMojoReader.readFrom(mojoReader);\r\n}"
}, {
	"Path": "org.hibernate.dialect.TeradataDialect.getTypeName",
	"Comment": "get the name of the database type associated with the given\tjava.sql.types typecode.",
	"Method": "String getTypeName(int code,int length,int precision,int scale){\r\n    float f = precision > 0 ? (float) scale / (float) precision : 0;\r\n    int p = (precision > 18 ? 18 : precision);\r\n    int s = (precision > 18 ? (int) (18.0 * f) : (scale > 18 ? 18 : scale));\r\n    return super.getTypeName(code, length, p, s);\r\n}"
}, {
	"Path": "org.hibernate.persister.collection.OneToManyPersister.generateInsertRowString",
	"Comment": "generate the sql update that updates a foreign key to a value",
	"Method": "String generateInsertRowString(){\r\n    final Update update = new Update(getDialect()).setTableName(qualifiedTableName).addColumns(keyColumnNames);\r\n    if (hasIndex && !indexContainsFormula) {\r\n        for (int i = 0; i < indexColumnNames.length; i++) {\r\n            if (indexColumnIsSettable[i]) {\r\n                update.addColumn(indexColumnNames[i]);\r\n            }\r\n        }\r\n    }\r\n    if (getFactory().getSessionFactoryOptions().isCommentsEnabled()) {\r\n        update.setComment(\"create one-to-many row \" + getRole());\r\n    }\r\n    return update.addPrimaryKeyColumns(elementColumnNames, elementColumnWriters).toStatementString();\r\n}"
}, {
	"Path": "org.hibernate.type.spi.TypeConfiguration.getMetadataBuildingContext",
	"Comment": "obtain the metadatabuildingcontext currently scoping the\ttypeconfiguration.",
	"Method": "MetadataBuildingContext getMetadataBuildingContext(MetadataBuildingContext getMetadataBuildingContext){\r\n    return scope.getMetadataBuildingContext();\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getQueryHintString",
	"Comment": "apply a hint to the query.the entire query is provided, allowing the dialect full control over the placement\tand syntax of the hint.by default, ignore the hint and simply return the query.",
	"Method": "String getQueryHintString(String query,List<String> hintList,String getQueryHintString,String query,String hints){\r\n    return query;\r\n}"
}, {
	"Path": "org.hibernate.transform.Transformers.aliasToBean",
	"Comment": "creates a resulttransformer that will inject aliased values into \tinstances of class via property methods or fields.",
	"Method": "ResultTransformer aliasToBean(Class target){\r\n    return new AliasToBeanResultTransformer(target);\r\n}"
}, {
	"Path": "water.AAA_PreCloudLock.testBasicStatusPages",
	"Comment": "should be able to load basic status pages without locking the cloud.",
	"Method": "void testBasicStatusPages(){\r\n    try {\r\n        TypeMap._check_no_locking = true;\r\n        assertFalse(testRan);\r\n        assertFalse(Paxos._cloudLocked);\r\n        stall();\r\n        assertFalse(Paxos._cloudLocked);\r\n        serve(\"/\", null);\r\n        serve(\"/3/Cloud\", null);\r\n        serve(\"/junk\", null);\r\n        serve(\"/HTTP404\", null);\r\n        Properties parms = new Properties();\r\n        parms.setProperty(\"src\", \"./smalldata/iris\");\r\n        serve(\"/3/Typeahead/files\", parms);\r\n        water.util.Log.info(\"Testing that logging will not lock a cloud\");\r\n        serve(\"/3/ModelBuilders\", null);\r\n        serve(\"/3/About\", null);\r\n        serve(\"/3/NodePersistentStorage/categories/environment/names/clips/exists\", null);\r\n        assertFalse(\"Check of pre-cloud classes failed.  You likely made a Key before any outside action triggers cloud-lock.  \", Paxos._cloudLocked);\r\n    } finally {\r\n        TypeMap._check_no_locking = false;\r\n        testRan = true;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cfg.DefaultNamingStrategy.logicalCollectionTableName",
	"Comment": "returns either the table name if explicit or\tif there is an associated table, the concatenation of owner entity table and associated table\totherwise the concatenation of owner entity table and the unqualified property name",
	"Method": "String logicalCollectionTableName(String tableName,String ownerEntityTable,String associatedEntityTable,String propertyName){\r\n    if (tableName != null) {\r\n        return tableName;\r\n    } else {\r\n        return new StringBuffer(ownerEntityTable).append(\"_\").append(associatedEntityTable != null ? associatedEntityTable : StringHelper.unqualify(propertyName)).toString();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.SessionFactoryHelper.createJoinSequence",
	"Comment": "generate a join sequence representing the given association type.",
	"Method": "JoinSequence createJoinSequence(JoinSequence createJoinSequence,boolean implicit,AssociationType associationType,String tableAlias,JoinType joinType,String[] columns,JoinSequence createJoinSequence,boolean implicit,AssociationType associationType,String tableAlias,JoinType joinType,String[][] columns){\r\n    JoinSequence joinSequence = createJoinSequence();\r\n    joinSequence.setUseThetaStyle(implicit);\r\n    joinSequence.addJoin(associationType, tableAlias, joinType, columns);\r\n    return joinSequence;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.supportsCascadeDelete",
	"Comment": "does this dialect support cascaded delete on foreign key definitions?",
	"Method": "boolean supportsCascadeDelete(){\r\n    return true;\r\n}"
}, {
	"Path": "org.hibernate.Hibernate.isInitialized",
	"Comment": "check if the proxy or persistent collection is initialized.",
	"Method": "boolean isInitialized(Object proxy){\r\n    if (proxy instanceof HibernateProxy) {\r\n        return !((HibernateProxy) proxy).getHibernateLazyInitializer().isUninitialized();\r\n    } else if (proxy instanceof PersistentCollection) {\r\n        return ((PersistentCollection) proxy).wasInitialized();\r\n    } else {\r\n        return true;\r\n    }\r\n}"
}, {
	"Path": "water.rapids.Rapids.parse",
	"Comment": "parse a rapids expression string into an abstract syntax tree object.",
	"Method": "AstRoot parse(String rapids){\r\n    Rapids r = new Rapids(rapids);\r\n    AstRoot res = r.parseNext();\r\n    if (r.skipWS() != ' ')\r\n        throw new IllegalASTException(\"Syntax error: illegal Rapids expression `\" + rapids + \"`\");\r\n    return res;\r\n}"
}, {
	"Path": "water.rapids.ast.prims.operators.AstBinOp.categoricalOK",
	"Comment": "does it make sense to run this operation on a categorical variable ?",
	"Method": "boolean categoricalOK(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.collection.internal.PersistentBag.occurrences",
	"Comment": "count how many times the given object occurs in the elements",
	"Method": "int occurrences(Object o){\r\n    read();\r\n    final Iterator itr = bag.iterator();\r\n    int result = 0;\r\n    while (itr.hasNext()) {\r\n        if (o.equals(itr.next())) {\r\n            result++;\r\n        }\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.internal.FilterImpl.validate",
	"Comment": "perform validation of the filter state.this is used to verify the\tstate of the filter after its enablement and before its use.",
	"Method": "void validate(){\r\n    for (final String parameterName : definition.getParameterNames()) {\r\n        if (parameters.get(parameterName) == null) {\r\n            throw new HibernateException(\"Filter [\" + getName() + \"] parameter [\" + parameterName + \"] value not set\");\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cfg.annotations.PropertyBinder.getValueGenerationFromAnnotations",
	"Comment": "returns the value generation strategy for the given property, if any.",
	"Method": "ValueGeneration getValueGenerationFromAnnotations(XProperty property){\r\n    AnnotationValueGeneration<?> valueGeneration = null;\r\n    for (Annotation annotation : property.getAnnotations()) {\r\n        AnnotationValueGeneration<?> candidate = getValueGenerationFromAnnotation(property, annotation);\r\n        if (candidate != null) {\r\n            if (valueGeneration != null) {\r\n                throw new AnnotationException(\"Only one generator annotation is allowed:\" + StringHelper.qualify(holder.getPath(), name));\r\n            } else {\r\n                valueGeneration = candidate;\r\n            }\r\n        }\r\n    }\r\n    return valueGeneration;\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.propertyNe",
	"Comment": "creates a criterion which checks that the value of a given property is not equal to the value in the\tsubquery result.the assumption is that the subquery returns a single result.",
	"Method": "Criterion propertyNe(String propertyName,DetachedCriteria dc){\r\n    return new PropertySubqueryExpression(propertyName, \"<>\", null, dc);\r\n}"
}, {
	"Path": "water.util.TwoDimTable.toString",
	"Comment": "print table to string, using 2 spaces for padding between columns",
	"Method": "String toString(String toString,int pad,String toString,int pad,boolean full){\r\n    if (pad < 0)\r\n        throw new IllegalArgumentException(\"pad must be a non-negative integer\");\r\n    final int rowDim = getRowDim();\r\n    final int colDim = getColDim();\r\n    final int actualRowDim = full ? rowDim : Math.min(PRINTOUT_ROW_LIMIT + 1, rowDim);\r\n    final String[][] cellStrings = new String[actualRowDim + 1][colDim + 1];\r\n    for (String[] row : cellStrings) Arrays.fill(row, \"\");\r\n    cellStrings[0][0] = colHeaderForRowHeaders != null ? colHeaderForRowHeaders : \"\";\r\n    int row = 0;\r\n    for (int r = 0; r < rowDim; ++r) {\r\n        if (!full && skip(r))\r\n            continue;\r\n        cellStrings[row + 1][0] = rowHeaders[r];\r\n        row++;\r\n    }\r\n    for (int c = 0; c < colDim; ++c) cellStrings[0][c + 1] = colHeaders[c];\r\n    for (int c = 0; c < colDim; ++c) {\r\n        final String formatString = colFormats[c];\r\n        row = 0;\r\n        for (int r = 0; r < rowDim; ++r) {\r\n            if (!full && skip(r))\r\n                continue;\r\n            Object o = get(r, c);\r\n            if ((o == null) || o instanceof Double && isEmpty((double) o)) {\r\n                cellStrings[row + 1][c + 1] = \"\";\r\n                row++;\r\n                continue;\r\n            } else if (o instanceof Double && Double.isNaN((double) o)) {\r\n                cellStrings[row + 1][c + 1] = \"NaN\";\r\n                row++;\r\n                continue;\r\n            }\r\n            try {\r\n                if (o instanceof Double)\r\n                    cellStrings[row + 1][c + 1] = String.format(formatString, (Double) o);\r\n                else if (o instanceof Float)\r\n                    cellStrings[row + 1][c + 1] = String.format(formatString, (Float) o);\r\n                else if (o instanceof Integer)\r\n                    cellStrings[row + 1][c + 1] = String.format(formatString, (Integer) o);\r\n                else if (o instanceof Long)\r\n                    cellStrings[row + 1][c + 1] = String.format(formatString, (Long) o);\r\n                else if (o instanceof String)\r\n                    cellStrings[row + 1][c + 1] = (String) o;\r\n                else\r\n                    cellStrings[row + 1][c + 1] = String.format(formatString, cellValues[r][c]);\r\n            } catch (Throwable t) {\r\n                cellStrings[row + 1][c + 1] = o.toString();\r\n            }\r\n            row++;\r\n        }\r\n    }\r\n    final int[] colLen = new int[colDim + 1];\r\n    for (int c = 0; c <= colDim; ++c) {\r\n        for (int r = 0; r <= actualRowDim; ++r) {\r\n            colLen[c] = Math.max(colLen[c], cellStrings[r][c].length());\r\n        }\r\n    }\r\n    final StringBuilder sb = new StringBuilder();\r\n    if (tableHeader.length() > 0) {\r\n        sb.append(tableHeader);\r\n    }\r\n    if (tableDescription.length() > 0) {\r\n        sb.append(\" (\").append(tableDescription).append(\")\");\r\n    }\r\n    sb.append(\":\\n\");\r\n    for (int r = 0; r <= actualRowDim; ++r) {\r\n        int len = colLen[0];\r\n        if (actualRowDim != rowDim && r - 1 == PRINTOUT_ROW_LIMIT / 2) {\r\n            assert (!full);\r\n            sb.append(\"---\");\r\n        } else {\r\n            if (len > 0)\r\n                sb.append(String.format(\"%\" + colLen[0] + \"s\", cellStrings[r][0]));\r\n            for (int c = 1; c <= colDim; ++c) {\r\n                len = colLen[c];\r\n                if (len > 0)\r\n                    sb.append(String.format(\"%\" + (len + pad) + \"s\", cellStrings[r][c].equals(\"null\") ? \"\" : cellStrings[r][c]));\r\n            }\r\n        }\r\n        sb.append(\"\\n\");\r\n    }\r\n    return sb.toString();\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getTableComment",
	"Comment": "get the comment into a form supported for table definition.",
	"Method": "String getTableComment(String comment){\r\n    return \"\";\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.FromClause.findJoinByPath",
	"Comment": "look for an existing implicit or explicit join by the\tgiven path.",
	"Method": "FromElement findJoinByPath(String path){\r\n    FromElement elem = findJoinByPathLocal(path);\r\n    if (elem == null && parentFromClause != null) {\r\n        elem = parentFromClause.findJoinByPath(path);\r\n    }\r\n    return elem;\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.notIn",
	"Comment": "creates a criterion which checks that the value of a literal is not in the values in the\tsubquery result.",
	"Method": "Criterion notIn(Object value,DetachedCriteria dc){\r\n    return new SimpleSubqueryExpression(value, \"not in\", null, dc);\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.NaturalIdXrefDelegate.locatePersisterForKey",
	"Comment": "it is only valid to define natural ids at the root of an entity hierarchy.this method makes sure we are \tusing the root persister.",
	"Method": "EntityPersister locatePersisterForKey(EntityPersister persister){\r\n    return persistenceContext.getSession().getFactory().getEntityPersister(persister.getRootEntityName());\r\n}"
}, {
	"Path": "org.hibernate.boot.model.source.internal.hbm.HBMManyToOneAnnotationMissingPrimaryKeyTest.hhh11502",
	"Comment": "test to trigger the nullpointerexception in the modelbinder.",
	"Method": "void hhh11502(){\r\n    Assert.assertTrue(true);\r\n}"
}, {
	"Path": "org.hibernate.internal.util.LockModeConverter.convertToLockModeType",
	"Comment": "convert from the hibernate specific lockmode to the jpa defined lockmodetype.",
	"Method": "LockModeType convertToLockModeType(LockMode lockMode){\r\n    if (lockMode == LockMode.NONE) {\r\n        return LockModeType.NONE;\r\n    } else if (lockMode == LockMode.OPTIMISTIC || lockMode == LockMode.READ) {\r\n        return LockModeType.OPTIMISTIC;\r\n    } else if (lockMode == LockMode.OPTIMISTIC_FORCE_INCREMENT || lockMode == LockMode.WRITE) {\r\n        return LockModeType.OPTIMISTIC_FORCE_INCREMENT;\r\n    } else if (lockMode == LockMode.PESSIMISTIC_READ) {\r\n        return LockModeType.PESSIMISTIC_READ;\r\n    } else if (lockMode == LockMode.PESSIMISTIC_WRITE || lockMode == LockMode.UPGRADE || lockMode == LockMode.UPGRADE_NOWAIT || lockMode == LockMode.UPGRADE_SKIPLOCKED) {\r\n        return LockModeType.PESSIMISTIC_WRITE;\r\n    } else if (lockMode == LockMode.PESSIMISTIC_FORCE_INCREMENT || lockMode == LockMode.FORCE) {\r\n        return LockModeType.PESSIMISTIC_FORCE_INCREMENT;\r\n    }\r\n    throw new AssertionFailure(\"unhandled lock mode \" + lockMode);\r\n}"
}, {
	"Path": "org.hibernate.dialect.pagination.AbstractLimitHandler.bindLimitParameters",
	"Comment": "default implementation of binding parameter values needed by the limit clause.",
	"Method": "int bindLimitParameters(RowSelection selection,PreparedStatement statement,int index){\r\n    if (!supportsVariableLimit() || !LimitHelper.hasMaxRows(selection)) {\r\n        return 0;\r\n    }\r\n    final int firstRow = convertToFirstRowValue(LimitHelper.getFirstRow(selection));\r\n    final int lastRow = getMaxOrLimit(selection);\r\n    final boolean hasFirstRow = supportsLimitOffset() && (firstRow > 0 || forceLimitUsage());\r\n    final boolean reverse = bindLimitParametersInReverseOrder();\r\n    if (hasFirstRow) {\r\n        statement.setInt(index + (reverse ? 1 : 0), firstRow);\r\n    }\r\n    statement.setInt(index + (reverse || !hasFirstRow ? 0 : 1), lastRow);\r\n    return hasFirstRow ? 2 : 1;\r\n}"
}, {
	"Path": "water.util.FrameUtilsTest.testIDColumnOperationEncoder",
	"Comment": "this test is used to test some utilities that i have written to make sure they function as planned.",
	"Method": "void testIDColumnOperationEncoder(){\r\n    Scope.enter();\r\n    Random _rand = new Random();\r\n    int numRows = 1000;\r\n    int rowsToTest = _rand.nextInt(numRows);\r\n    try {\r\n        FrameTestUtil.Create1IDColumn tempO = new FrameTestUtil.Create1IDColumn(numRows);\r\n        Frame f = tempO.doAll(tempO.returnFrame()).returnFrame();\r\n        Scope.track(f);\r\n        ArrayList<Integer> badRows = new FrameTestUtil.CountAllRowsPresented(0, f).doAll(f).findMissingRows();\r\n        assertEquals(\"All rows should be present but not!\", badRows.size(), 0);\r\n        long countAppear = new FrameTestUtil.CountIntValueRows(rowsToTest, 0, 0, f).doAll(f).getNumberAppear();\r\n        assertEquals(\"All values should appear only once.\", countAppear, 1);\r\n        f.remove(rowsToTest);\r\n        countAppear = new FrameTestUtil.CountIntValueRows(2000, 0, 0, f).doAll(f).getNumberAppear();\r\n        assertEquals(\"Value of interest should not been found....\", countAppear, 0);\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.query.spi.QueryPlanCache.getFilterQueryPlan",
	"Comment": "get the query plan for the given collection hql filter fragment, creating it and caching it if not already cached",
	"Method": "FilterQueryPlan getFilterQueryPlan(String filterString,String collectionRole,boolean shallow,Map<String, Filter> enabledFilters){\r\n    final FilterQueryPlanKey key = new FilterQueryPlanKey(filterString, collectionRole, shallow, enabledFilters);\r\n    FilterQueryPlan value = (FilterQueryPlan) queryPlanCache.get(key);\r\n    if (value == null) {\r\n        LOG.tracev(\"Unable to locate collection-filter query plan in cache; generating ({0} : {1} )\", collectionRole, filterString);\r\n        value = new FilterQueryPlan(filterString, collectionRole, shallow, enabledFilters, factory);\r\n        queryPlanCache.putIfAbsent(key, value);\r\n    } else {\r\n        LOG.tracev(\"Located collection-filter query plan in cache ({0} : {1})\", collectionRole, filterString);\r\n    }\r\n    return value;\r\n}"
}, {
	"Path": "org.hibernate.internal.SessionImpl.immediateLoad",
	"Comment": "load the data for the object with the specified id into a newly created object.\tthis is only called when lazily initializing a proxy.\tdo not return a proxy.",
	"Method": "Object immediateLoad(String entityName,Serializable id){\r\n    if (log.isDebugEnabled()) {\r\n        EntityPersister persister = getFactory().getMetamodel().entityPersister(entityName);\r\n        log.debugf(\"Initializing proxy: %s\", MessageHelper.infoString(persister, id, getFactory()));\r\n    }\r\n    LoadEvent event = loadEvent;\r\n    loadEvent = null;\r\n    event = recycleEventInstance(event, id, entityName);\r\n    fireLoad(event, LoadEventListener.IMMEDIATE_LOAD);\r\n    Object result = event.getResult();\r\n    if (loadEvent == null) {\r\n        event.setEntityClassName(null);\r\n        event.setEntityId(null);\r\n        event.setInstanceToLoad(null);\r\n        event.setResult(null);\r\n        loadEvent = event;\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.hibernate.cfg.DefaultNamingStrategy.logicalCollectionColumnName",
	"Comment": "return the column name if explicit or the concatenation of the property name and the referenced column",
	"Method": "String logicalCollectionColumnName(String columnName,String propertyName,String referencedColumn){\r\n    return StringHelper.isNotEmpty(columnName) ? columnName : propertyName + \"_\" + referencedColumn;\r\n}"
}, {
	"Path": "org.hibernate.persister.walking.spi.MetamodelGraphWalker.visitEntity",
	"Comment": "entry point into walking the model graph of an entity according to its defined metamodel.",
	"Method": "void visitEntity(AssociationVisitationStrategy strategy,EntityPersister persister){\r\n    strategy.start();\r\n    try {\r\n        new MetamodelGraphWalker(strategy, persister.getFactory()).visitEntityDefinition(persister);\r\n    } finally {\r\n        strategy.finish();\r\n    }\r\n}"
}, {
	"Path": "water.parser.orc.OrcUtil.isSupportedSchema",
	"Comment": "return true if the given schema can be transformedinto h2o type.",
	"Method": "boolean isSupportedSchema(String s){\r\n    switch(s.toLowerCase()) {\r\n        case \"boolean\":\r\n        case \"bigint\":\r\n        case \"char\":\r\n        case \"date\":\r\n        case \"decimal\":\r\n        case \"double\":\r\n        case \"float\":\r\n        case \"int\":\r\n        case \"smallint\":\r\n        case \"string\":\r\n        case \"timestamp\":\r\n        case \"tinyint\":\r\n        case \"varchar\":\r\n        case \"enum\":\r\n            return true;\r\n        default:\r\n            return false;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.BatchFetchQueue.getCollectionBatch",
	"Comment": "get a batch of uninitialized collection keys for a given role",
	"Method": "Serializable[] getCollectionBatch(CollectionPersister collectionPersister,Serializable id,int batchSize){\r\n    Serializable[] keys = new Serializable[batchSize];\r\n    keys[0] = id;\r\n    int i = 1;\r\n    int end = -1;\r\n    boolean checkForEnd = false;\r\n    final LinkedHashMap<CollectionEntry, PersistentCollection> map = batchLoadableCollections.get(collectionPersister.getRole());\r\n    if (map != null) {\r\n        for (Entry<CollectionEntry, PersistentCollection> me : map.entrySet()) {\r\n            final CollectionEntry ce = me.getKey();\r\n            final PersistentCollection collection = me.getValue();\r\n            if (ce.getLoadedKey() == null) {\r\n                continue;\r\n            }\r\n            if (collection.wasInitialized()) {\r\n                LOG.warn(\"Encountered initialized collection in BatchFetchQueue, this should not happen.\");\r\n                continue;\r\n            }\r\n            if (checkForEnd && i == end) {\r\n                return keys;\r\n            }\r\n            final boolean isEqual = collectionPersister.getKeyType().isEqual(id, ce.getLoadedKey(), collectionPersister.getFactory());\r\n            if (isEqual) {\r\n                end = i;\r\n            } else if (!isCached(ce.getLoadedKey(), collectionPersister)) {\r\n                keys[i++] = ce.getLoadedKey();\r\n            }\r\n            if (i == batchSize) {\r\n                i = 1;\r\n                if (end != -1) {\r\n                    checkForEnd = true;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return keys;\r\n}"
}, {
	"Path": "water.parser.orc.OrcParser.parseChunk",
	"Comment": "this method calculates the number of stripes that will be read for each chunk.sinceonly single threading is supported in reading each stripe, we will never split one stripeover different chunks.",
	"Method": "ParseWriter parseChunk(int chunkId,ParseReader din,ParseWriter dout){\r\n    _cidx = chunkId;\r\n    List<StripeInformation> stripesInfo = ((OrcParseSetup) this._setup).getStripes();\r\n    if (stripesInfo.size() == 0) {\r\n        dout.addError(new ParseWriter.ParseErr(\"Orc Parser: Empty file.\", chunkId, 0L, -2L));\r\n        return dout;\r\n    }\r\n    OrcParseSetup setup = (OrcParseSetup) this._setup;\r\n    StripeInformation thisStripe = stripesInfo.get(chunkId);\r\n    String[] orcTypes = setup.getColumnTypesString();\r\n    boolean[] toInclude = setup.getToInclude();\r\n    try {\r\n        RecordReader perStripe = orcFileReader.rows(thisStripe.getOffset(), thisStripe.getDataLength(), setup.getToInclude(), null, setup.getColumnNames());\r\n        VectorizedRowBatch batch = null;\r\n        long rows = 0;\r\n        long rowCount = thisStripe.getNumberOfRows();\r\n        while (rows != rowCount) {\r\n            batch = perStripe.nextBatch(batch);\r\n            long currentBatchRow = batch.count();\r\n            int nrows = (int) currentBatchRow;\r\n            if (currentBatchRow != nrows)\r\n                throw new IllegalArgumentException(\"got batch with too many records, does not fit in int\");\r\n            ColumnVector[] dataVectors = batch.cols;\r\n            int colIndex = 0;\r\n            for (int col = 0; col < batch.numCols; ++col) {\r\n                if (toInclude[col + 1]) {\r\n                    if (_setup.getColumnTypes()[colIndex] != Vec.T_BAD)\r\n                        write1column(dataVectors[col], orcTypes[colIndex], colIndex, nrows, dout);\r\n                    else\r\n                        dout.addNAs(col, nrows);\r\n                    colIndex++;\r\n                }\r\n            }\r\n            rows += currentBatchRow;\r\n        }\r\n        byte[] col_types = _setup.getColumnTypes();\r\n        for (int i = 0; i < col_types.length; ++i) {\r\n            if (col_types[i] == Vec.T_BAD)\r\n                dout.addNAs(i, (int) rowCount);\r\n        }\r\n        perStripe.close();\r\n    } catch (IOException ioe) {\r\n        throw new RuntimeException(ioe);\r\n    }\r\n    return dout;\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.tree.SelectExpressionList.collectSelectExpressions",
	"Comment": "returns an array of selectexpressions gathered from the children of the given parent ast node.",
	"Method": "SelectExpression[] collectSelectExpressions(){\r\n    AST firstChild = getFirstSelectExpression();\r\n    ArrayList<SelectExpression> list = new ArrayList<SelectExpression>();\r\n    int p = 0;\r\n    for (AST n = firstChild; n != null; n = n.getNextSibling()) {\r\n        if (n instanceof SelectExpression) {\r\n            list.add((SelectExpression) n);\r\n        } else if (n instanceof ParameterNode) {\r\n            parameterPositions.add(p);\r\n        } else {\r\n            throw new IllegalStateException(\"Unexpected AST: \" + n.getClass().getName() + \" \" + TokenPrinters.SQL_TOKEN_PRINTER.showAsString(n, \"\"));\r\n        }\r\n        p++;\r\n    }\r\n    return list.toArray(new SelectExpression[list.size()]);\r\n}"
}, {
	"Path": "org.hibernate.criterion.Property.group",
	"Comment": "creates a projection for this property as a group expression",
	"Method": "PropertyProjection group(){\r\n    return Projections.groupProperty(getPropertyName());\r\n}"
}, {
	"Path": "org.hibernate.collection.internal.AbstractPersistentCollection.getOrphans",
	"Comment": "given a collection of entity instances that used to\tbelong to the collection, and a collection of instances\tthat currently belong, return a collection of orphans",
	"Method": "Collection getOrphans(Serializable snapshot,String entityName,Collection getOrphans,Collection oldElements,Collection currentElements,String entityName,SharedSessionContractImplementor session){\r\n    if (currentElements.size() == 0) {\r\n        return oldElements;\r\n    }\r\n    if (oldElements.size() == 0) {\r\n        return oldElements;\r\n    }\r\n    final EntityPersister entityPersister = session.getFactory().getEntityPersister(entityName);\r\n    final Type idType = entityPersister.getIdentifierType();\r\n    final boolean useIdDirect = mayUseIdDirect(idType);\r\n    final Collection res = new ArrayList();\r\n    final java.util.Set currentIds = new HashSet();\r\n    final java.util.Set currentSaving = new IdentitySet();\r\n    for (Object current : currentElements) {\r\n        if (current != null && ForeignKeys.isNotTransient(entityName, current, null, session)) {\r\n            final EntityEntry ee = session.getPersistenceContext().getEntry(current);\r\n            if (ee != null && ee.getStatus() == Status.SAVING) {\r\n                currentSaving.add(current);\r\n            } else {\r\n                final Serializable currentId = ForeignKeys.getEntityIdentifierIfNotUnsaved(entityName, current, session);\r\n                currentIds.add(useIdDirect ? currentId : new TypedValue(idType, currentId));\r\n            }\r\n        }\r\n    }\r\n    for (Object old : oldElements) {\r\n        if (!currentSaving.contains(old)) {\r\n            final Serializable oldId = ForeignKeys.getEntityIdentifierIfNotUnsaved(entityName, old, session);\r\n            if (!currentIds.contains(useIdDirect ? oldId : new TypedValue(idType, oldId))) {\r\n                res.add(old);\r\n            }\r\n        }\r\n    }\r\n    return res;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.supportsBindAsCallableArgument",
	"Comment": "does this dialect support using a jdbc bind parameter as an argument\tto a function or procedure call?",
	"Method": "boolean supportsBindAsCallableArgument(){\r\n    return true;\r\n}"
}, {
	"Path": "water.fvec.FVecTest.test50pct",
	"Comment": "the rollups only compute approximate quantiles, not exact.",
	"Method": "void test50pct(){\r\n    Vec vec = null;\r\n    try {\r\n        double[] d = new double[] { 0.812834256224, 1.56386606237, 3.12702210880, 3.68417563302, 5.51277746586 };\r\n        vec = Vec.makeVec(d, Vec.newKey());\r\n        double[] pct = vec.pctiles();\r\n        double eps = (vec.max() - vec.min()) / 1e-3;\r\n        Assert.assertEquals(pct[0], d[0], eps);\r\n        Assert.assertEquals(pct[1], d[0], eps);\r\n        Assert.assertEquals(pct[2], d[0], eps);\r\n        Assert.assertEquals(pct[3], d[1], eps);\r\n        Assert.assertEquals(pct[4], d[2], eps);\r\n        Assert.assertEquals(pct[5], d[2], eps);\r\n        Assert.assertEquals(pct[6], d[3], eps);\r\n        Assert.assertEquals(pct[7], d[4], eps);\r\n        Assert.assertEquals(pct[8], d[4], eps);\r\n        vec.remove();\r\n        d = new double[] { 490, 492, 494, 496, 498 };\r\n        vec = Vec.makeVec(d, Vec.newKey());\r\n        pct = vec.pctiles();\r\n        eps = (vec.max() - vec.min()) / 1e-3;\r\n        System.out.println(java.util.Arrays.toString(pct));\r\n        Assert.assertEquals(pct[0], d[0], eps);\r\n    } finally {\r\n        if (vec != null)\r\n            vec.remove();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getCurrentTimestampSelectString",
	"Comment": "retrieve the command used to retrieve the current timestamp from the\tdatabase.",
	"Method": "String getCurrentTimestampSelectString(){\r\n    throw new UnsupportedOperationException(\"Database not known to define a current timestamp function\");\r\n}"
}, {
	"Path": "org.hibernate.param.NamedParameterSpecification.bind",
	"Comment": "bind the appropriate value into the given statement at the specified position.",
	"Method": "int bind(PreparedStatement statement,QueryParameters qp,SharedSessionContractImplementor session,int position){\r\n    TypedValue typedValue = qp.getNamedParameters().get(name);\r\n    typedValue.getType().nullSafeSet(statement, typedValue.getValue(), position, session);\r\n    return typedValue.getType().getColumnSpan(session.getFactory());\r\n}"
}, {
	"Path": "water.util.FrameUtilsTest.testCalculateWeightMeanSTD",
	"Comment": "for a column of a dataset using another column as the weight column.note that the weighted",
	"Method": "void testCalculateWeightMeanSTD(){\r\n    Scope.enter();\r\n    try {\r\n        Frame trainData = parse_test_file(\"smalldata/prostate/prostate.csv\");\r\n        Scope.track(trainData);\r\n        Vec orig = trainData.remove(trainData.numCols() - 1);\r\n        Vec[] weights = new Vec[2];\r\n        weights[0] = orig.makeCon(2.0);\r\n        weights[1] = orig.makeCon(1.0);\r\n        for (int rindex = 0; rindex < orig.length(); rindex++) {\r\n            weights[1].set(rindex, rindex + 1);\r\n        }\r\n        Scope.track(orig);\r\n        Scope.track(weights[0]);\r\n        Scope.track(weights[1]);\r\n        Frame test = new Frame(new String[] { \"weight0\", \"weight1\" }, weights);\r\n        test._key = Key.make();\r\n        Scope.track(test);\r\n        FrameUtils.CalculateWeightMeanSTD calMeansSTDW1 = new FrameUtils.CalculateWeightMeanSTD();\r\n        calMeansSTDW1.doAll(trainData.vec(0), test.vec(0));\r\n        assert Math.abs(trainData.vec(0).mean() - calMeansSTDW1.getWeightedMean()) < 1e-10 : \"Error, weighted mean \" + calMeansSTDW1.getWeightedMean() + \" and expected mean \" + trainData.vec(0).mean() + \" should equal but not.\";\r\n        assert Math.abs(trainData.vec(0).sigma() - calMeansSTDW1.getWeightedSigma()) < 1e-10 : \"Error, weighted sigma \" + calMeansSTDW1.getWeightedSigma() + \" and expected sigma \" + trainData.vec(0).sigma() + \" should equal but not.\";\r\n        FrameUtils.CalculateWeightMeanSTD calMeansSTDW2 = new FrameUtils.CalculateWeightMeanSTD();\r\n        calMeansSTDW2.doAll(trainData.vec(0), test.vec(1));\r\n        double[] meanSigma = calWeightedMeanSigma(trainData, test, 0, 1);\r\n        assert Math.abs(meanSigma[0] - calMeansSTDW2.getWeightedMean()) < 1e-10 : \"Error, weighted mean \" + calMeansSTDW1.getWeightedMean() + \" and expected mean \" + meanSigma[0] + \" should equal but not.\";\r\n        assert Math.abs(meanSigma[1] - calMeansSTDW2.getWeightedSigma()) < 1e-10 : \"Error, weighted sigma \" + calMeansSTDW1.getWeightedSigma() + \" and expected sigma \" + meanSigma[1] + \" should equal but not.\";\r\n    } finally {\r\n        Scope.exit();\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.mapping.ForeignKey.getReferencedColumns",
	"Comment": "returns the referenced columns if the foreignkey does not refer to the primary key",
	"Method": "List getReferencedColumns(){\r\n    return referencedColumns;\r\n}"
}, {
	"Path": "org.hibernate.engine.internal.Versioning.setVersion",
	"Comment": "inject the optimistic locking value into the entity state snapshot.",
	"Method": "void setVersion(Object[] fields,Object version,EntityPersister persister){\r\n    if (!persister.isVersioned()) {\r\n        return;\r\n    }\r\n    fields[persister.getVersionProperty()] = version;\r\n}"
}, {
	"Path": "org.hibernate.engine.jdbc.dialect.internal.DialectFactoryImpl.determineDialect",
	"Comment": "determine the appropriate dialect to use given the connection.",
	"Method": "Dialect determineDialect(DialectResolutionInfoSource resolutionInfoSource){\r\n    if (resolutionInfoSource == null) {\r\n        throw new HibernateException(\"Access to DialectResolutionInfo cannot be null when 'hibernate.dialect' not set\");\r\n    }\r\n    final DialectResolutionInfo info = resolutionInfoSource.getDialectResolutionInfo();\r\n    final Dialect dialect = dialectResolver.resolveDialect(info);\r\n    if (dialect == null) {\r\n        throw new HibernateException(\"Unable to determine Dialect to use [name=\" + info.getDatabaseName() + \", majorVersion=\" + info.getDatabaseMajorVersion() + \"]; user must register resolver or explicitly set 'hibernate.dialect'\");\r\n    }\r\n    return dialect;\r\n}"
}, {
	"Path": "org.hibernate.event.internal.DefaultSaveOrUpdateEventListener.cascadeOnUpdate",
	"Comment": "handles the calls needed to perform cascades as part of an update request\tfor the given entity.",
	"Method": "void cascadeOnUpdate(SaveOrUpdateEvent event,EntityPersister persister,Object entity){\r\n    final EventSource source = event.getSession();\r\n    source.getPersistenceContext().incrementCascadeLevel();\r\n    try {\r\n        Cascade.cascade(CascadingActions.SAVE_UPDATE, CascadePoint.AFTER_UPDATE, source, persister, entity);\r\n    } finally {\r\n        source.getPersistenceContext().decrementCascadeLevel();\r\n    }\r\n}"
}, {
	"Path": "water.Weaver.implClazzName",
	"Comment": "the name conversion from a iced subclass to an icer subclass.",
	"Method": "String implClazzName(String name){\r\n    return name + \"$Icer\";\r\n}"
}, {
	"Path": "hex.genmodel.algos.tree.SharedTreeNode.findInclusiveNa",
	"Comment": "calculate whether the na value for a particular colid can reach this node.",
	"Method": "boolean findInclusiveNa(int colIdToFind){\r\n    if (parent == null) {\r\n        return true;\r\n    } else if (parent.getColId() == colIdToFind) {\r\n        return inclusiveNa;\r\n    }\r\n    return parent.findInclusiveNa(colIdToFind);\r\n}"
}, {
	"Path": "org.hibernate.resource.transaction.backend.jta.internal.JtaTransactionCoordinatorImpl.isSynchronizationRegistered",
	"Comment": "is the registeredsynchronization used by hibernate for unified jta synchronization callbacks registered for this\tcoordinator?",
	"Method": "boolean isSynchronizationRegistered(){\r\n    return synchronizationRegistered;\r\n}"
}, {
	"Path": "hex.genmodel.GenModel.isClassifier",
	"Comment": "returns true if this model represents a classifier, else it is used for regression.",
	"Method": "boolean isClassifier(){\r\n    ModelCategory cat = getModelCategory();\r\n    return cat == ModelCategory.Binomial || cat == ModelCategory.Multinomial || cat == ModelCategory.Ordinal;\r\n}"
}, {
	"Path": "water.KVTest.testRemoteBitSet",
	"Comment": "issue a slew of remote puts, then issue a dfj job on the array of keys.",
	"Method": "void testRemoteBitSet(){\r\n    long start = System.currentTimeMillis();\r\n    Futures fs = new Futures();\r\n    Key[] keys = new Key[32];\r\n    for (int i = 0; i < keys.length; ++i) {\r\n        Key k = keys[i] = Key.make(\"key\" + i);\r\n        byte[] bits = new byte[4];\r\n        bits[0] = (byte) i;\r\n        Value val = new Value(k, bits);\r\n        DKV.put(k, val, fs);\r\n    }\r\n    fs.blockForPending();\r\n    int x = new RemoteBitSet().doAll(keys)._x;\r\n    assertEquals((int) ((1L << keys.length) - 1), x);\r\n    for (Key k : keys) DKV.remove(k, fs);\r\n    fs.blockForPending();\r\n    System.out.println(\"RemoteBitSet \" + (System.currentTimeMillis() - start));\r\n}"
}, {
	"Path": "org.hibernate.boot.MetadataSources.addJar",
	"Comment": "read all mappings from a jar file.\tassumes that any file named .hbm.xml is a mapping document.",
	"Method": "MetadataSources addJar(File jar){\r\n    LOG.debugf(\"Seeking mapping documents in jar file : %s\", jar.getName());\r\n    final Origin origin = new Origin(SourceType.JAR, jar.getAbsolutePath());\r\n    try {\r\n        JarFile jarFile = new JarFile(jar);\r\n        try {\r\n            Enumeration jarEntries = jarFile.entries();\r\n            while (jarEntries.hasMoreElements()) {\r\n                final ZipEntry zipEntry = (ZipEntry) jarEntries.nextElement();\r\n                if (zipEntry.getName().endsWith(\".hbm.xml\")) {\r\n                    LOG.tracef(\"found mapping document : %s\", zipEntry.getName());\r\n                    xmlBindings.add(new JarFileEntryXmlSource(origin, jarFile, zipEntry).doBind(getXmlMappingBinderAccess().getMappingBinder()));\r\n                }\r\n            }\r\n        } finally {\r\n            try {\r\n                jarFile.close();\r\n            } catch (Exception ignore) {\r\n            }\r\n        }\r\n    } catch (IOException e) {\r\n        throw new MappingNotFoundException(e, origin);\r\n    }\r\n    return this;\r\n}"
}, {
	"Path": "ml.dmlc.xgboost4j.java.XGBoostScoreTask.createMetricsBuilder",
	"Comment": "constructs a metricbuilder for this xgboostscoretask based on parameters of response variable",
	"Method": "ModelMetrics.MetricBuilder createMetricsBuilder(int responseClassesNum,String[] responseDomain){\r\n    switch(responseClassesNum) {\r\n        case 1:\r\n            return new ModelMetricsRegression.MetricBuilderRegression();\r\n        case 2:\r\n            return new ModelMetricsBinomial.MetricBuilderBinomial(responseDomain);\r\n        default:\r\n            return new ModelMetricsMultinomial.MetricBuilderMultinomial(responseClassesNum, responseDomain);\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.loader.JoinWalker.isJoinedFetchEnabledInMapping",
	"Comment": "does the mapping, and hibernate default semantics, specify that\tthis association should be fetched by outer joining",
	"Method": "boolean isJoinedFetchEnabledInMapping(FetchMode config,AssociationType type){\r\n    if (!type.isEntityType() && !type.isCollectionType()) {\r\n        return false;\r\n    } else {\r\n        if (config == FetchMode.JOIN) {\r\n            return true;\r\n        }\r\n        if (config == FetchMode.SELECT) {\r\n            return false;\r\n        }\r\n        if (type.isEntityType()) {\r\n            EntityType entityType = (EntityType) type;\r\n            EntityPersister persister = getFactory().getEntityPersister(entityType.getAssociatedEntityName());\r\n            return !persister.hasProxy();\r\n        } else {\r\n            return false;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.cfg.AbstractPropertyHolder.getExactOverriddenJoinColumn",
	"Comment": "get column overriding, property first, then parent, then holder",
	"Method": "JoinColumn[] getExactOverriddenJoinColumn(String propertyName){\r\n    JoinColumn[] override = null;\r\n    if (parent != null) {\r\n        override = parent.getExactOverriddenJoinColumn(propertyName);\r\n    }\r\n    if (override == null && currentPropertyJoinColumnOverride != null) {\r\n        override = currentPropertyJoinColumnOverride.get(propertyName);\r\n    }\r\n    if (override == null && holderJoinColumnOverride != null) {\r\n        override = holderJoinColumnOverride.get(propertyName);\r\n    }\r\n    return override;\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.supportsLimit",
	"Comment": "does this dialect support some form of limiting query results\tvia a sql clause?",
	"Method": "boolean supportsLimit(){\r\n    return false;\r\n}"
}, {
	"Path": "org.hibernate.boot.archive.scan.spi.AbstractScannerImpl.resolveNonRootUrl",
	"Comment": "handlereferences from a persistence.xml file.\tjpa allows forto be specific",
	"Method": "URL resolveNonRootUrl(URL url){\r\n    return null;\r\n}"
}, {
	"Path": "org.hibernate.TransientPropertyValueException.getPropertyOwnerEntityName",
	"Comment": "returns the entity name for entity that owns the association\tproperty.",
	"Method": "String getPropertyOwnerEntityName(){\r\n    return propertyOwnerEntityName;\r\n}"
}, {
	"Path": "org.hibernate.loader.plan.exec.internal.RootHelper.extractRootQuerySpace",
	"Comment": "extract the root queryspace of the loadplan, assuming there is just one.",
	"Method": "T extractRootQuerySpace(QuerySpaces querySpaces,Class<EntityQuerySpace> returnType){\r\n    if (querySpaces.getRootQuerySpaces().size() == 0) {\r\n        throw new IllegalStateException(\"LoadPlan contained no root query-spaces\");\r\n    } else if (querySpaces.getRootQuerySpaces().size() > 1) {\r\n        throw new IllegalStateException(\"LoadPlan contained more than one root query-space\");\r\n    }\r\n    final QuerySpace querySpace = querySpaces.getRootQuerySpaces().get(0);\r\n    if (!returnType.isInstance(querySpace)) {\r\n        throw new IllegalStateException(String.format(\"Unexpected LoadPlan root query-space; expecting %s, but found %s\", returnType.getName(), querySpace.getClass().getName()));\r\n    }\r\n    return (T) querySpace;\r\n}"
}, {
	"Path": "org.hibernate.stat.internal.QueryStatisticsImpl.getExecutionMinTime",
	"Comment": "min time in ms taken by the execution of this query onto the db",
	"Method": "long getExecutionMinTime(){\r\n    return executionMinTime.get();\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getNoColumnsInsertString",
	"Comment": "the fragment used to insert a row without specifying any column values.\tthis is not possible on some databases.",
	"Method": "String getNoColumnsInsertString(){\r\n    return \"values ( )\";\r\n}"
}, {
	"Path": "org.hibernate.engine.spi.ExecutableList.iterator",
	"Comment": "returns an iterator for the list. wraps the list just in case something tries to modify it.",
	"Method": "Iterator<E> iterator(){\r\n    return Collections.unmodifiableList(executables).iterator();\r\n}"
}, {
	"Path": "org.hibernate.stat.internal.NaturalIdStatisticsImpl.getExecutionMinTime",
	"Comment": "min time in ms taken by the execution of this query onto the db",
	"Method": "long getExecutionMinTime(){\r\n    return this.executionMinTime.get();\r\n}"
}, {
	"Path": "water.fvec.TestFrameBuilderTest.testDataDifferentSize",
	"Comment": "this test throws exception because the data has different length",
	"Method": "void testDataDifferentSize(){\r\n    final Frame fr = // 2 elements\r\n    new TestFrameBuilder().withVecTypes(Vec.T_NUM, Vec.T_STR).withDataForCol(0, // 3 elements\r\n    ard(Double.NaN, 1)).withDataForCol(1, ar(\"A\", \"B\", \"C\")).build();\r\n    fr.remove();\r\n}"
}, {
	"Path": "org.hibernate.internal.util.ReflectHelper.implementsInterface",
	"Comment": "determine if the given class implements the given interface.",
	"Method": "boolean implementsInterface(Class clazz,Class intf){\r\n    assert intf.isInterface() : \"Interface to check was not an interface\";\r\n    return intf.isAssignableFrom(clazz);\r\n}"
}, {
	"Path": "org.hibernate.criterion.Subqueries.in",
	"Comment": "creates a criterion which checks that the value of a literal is in the values in the\tsubquery result.",
	"Method": "Criterion in(Object value,DetachedCriteria dc){\r\n    return new SimpleSubqueryExpression(value, \"in\", null, dc);\r\n}"
}, {
	"Path": "org.hibernate.dialect.Dialect.getForUpdateString",
	"Comment": "get the string to append to select statements to acquire locks\tfor this dialect.",
	"Method": "String getForUpdateString(LockOptions lockOptions,String getForUpdateString,LockMode lockMode,int timeout,String getForUpdateString,LockMode lockMode,String getForUpdateString,String getForUpdateString,String aliases,String getForUpdateString,String aliases,LockOptions lockOptions){\r\n    LockMode lockMode = lockOptions.getLockMode();\r\n    final Iterator<Map.Entry<String, LockMode>> itr = lockOptions.getAliasLockIterator();\r\n    while (itr.hasNext()) {\r\n        final Map.Entry<String, LockMode> entry = itr.next();\r\n        final LockMode lm = entry.getValue();\r\n        if (lm.greaterThan(lockMode)) {\r\n            lockMode = lm;\r\n        }\r\n    }\r\n    lockOptions.setLockMode(lockMode);\r\n    return getForUpdateString(lockOptions);\r\n}"
}, {
	"Path": "org.hibernate.hql.internal.ast.util.SessionFactoryHelper.requireClassPersister",
	"Comment": "locate the persister by class or entity name, requiring that such a persister\texist.",
	"Method": "EntityPersister requireClassPersister(String name){\r\n    EntityPersister cp;\r\n    try {\r\n        cp = findEntityPersisterByName(name);\r\n        if (cp == null) {\r\n            throw new QuerySyntaxException(name + \" is not mapped\");\r\n        }\r\n    } catch (MappingException e) {\r\n        throw new DetailedSemanticException(e.getMessage(), e);\r\n    }\r\n    return cp;\r\n}"
}, {
	"Path": "hex.genmodel.easy.EasyPredictModelWrapper.predictRegression",
	"Comment": "make a prediction on a new data point using a regression model.",
	"Method": "RegressionModelPrediction predictRegression(RowData data,RegressionModelPrediction predictRegression,RowData data,double offset){\r\n    double[] preds = preamble(ModelCategory.Regression, data, offset);\r\n    RegressionModelPrediction p = new RegressionModelPrediction();\r\n    if (enableLeafAssignment) {\r\n        SharedTreeMojoModel.LeafNodeAssignments assignments = leafNodeAssignmentExtended(data);\r\n        p.leafNodeAssignments = assignments._paths;\r\n        p.leafNodeAssignmentIds = assignments._nodeIds;\r\n    }\r\n    p.value = preds[0];\r\n    return p;\r\n}"
}, {
	"Path": "org.hibernate.event.internal.DefaultUpdateEventListener.getUpdateId",
	"Comment": "if the user specified an id, assign it to the instance and use that, \totherwise use the id already assigned to the instance",
	"Method": "Serializable getUpdateId(Object entity,EntityPersister persister,Serializable requestedId,SessionImplementor session){\r\n    if (requestedId == null) {\r\n        return super.getUpdateId(entity, persister, requestedId, session);\r\n    } else {\r\n        persister.setIdentifier(entity, requestedId, session);\r\n        return requestedId;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.jpa.boot.internal.PersistenceXmlParser.parse",
	"Comment": "intended only for use by hibernate tests!\tparses a specific persistence.xml file...",
	"Method": "Map<String, ParsedPersistenceXmlDescriptor> parse(URL persistenceXmlUrl,PersistenceUnitTransactionType transactionType,Map<String, ParsedPersistenceXmlDescriptor> parse,URL persistenceXmlUrl,PersistenceUnitTransactionType transactionType,Map integration){\r\n    PersistenceXmlParser parser = new PersistenceXmlParser(ClassLoaderServiceImpl.fromConfigSettings(integration), transactionType);\r\n    parser.doResolve(integration);\r\n    return parser.persistenceUnits;\r\n}"
}, {
	"Path": "org.hibernate.event.internal.AbstractFlushingEventListener.flushEverythingToExecutions",
	"Comment": "coordinates the processing necessary to get things ready for executions\tas db calls by preping the session caches and moving the appropriate\tentities and collections to their respective execution queues.",
	"Method": "void flushEverythingToExecutions(FlushEvent event){\r\n    LOG.trace(\"Flushing session\");\r\n    EventSource session = event.getSession();\r\n    final PersistenceContext persistenceContext = session.getPersistenceContext();\r\n    session.getInterceptor().preFlush(new LazyIterator(persistenceContext.getEntitiesByKey()));\r\n    prepareEntityFlushes(session, persistenceContext);\r\n    prepareCollectionFlushes(persistenceContext);\r\n    persistenceContext.setFlushing(true);\r\n    try {\r\n        int entityCount = flushEntities(event, persistenceContext);\r\n        int collectionCount = flushCollections(session, persistenceContext);\r\n        event.setNumberOfEntitiesProcessed(entityCount);\r\n        event.setNumberOfCollectionsProcessed(collectionCount);\r\n    } finally {\r\n        persistenceContext.setFlushing(false);\r\n    }\r\n    logFlushResults(event);\r\n}"
}, {
	"Path": "hex.genmodel.algos.glrm.GlrmMojoModel.score0",
	"Comment": "this function corresponds to the dimreduction model category",
	"Method": "double[] score0(double[] row,double[] preds,long seedValue,double[] score0,double[] row,double[] preds){\r\n    return score0(row, preds, _seed + _rcnt++);\r\n}"
}, {
	"Path": "hex.genmodel.easy.error.CountingErrorConsumer.getTotalUnknownCategoricalLevelsSeen",
	"Comment": "counts and returns all previously unseen categorical variables across all columns.results may vary when called during prediction phase.",
	"Method": "long getTotalUnknownCategoricalLevelsSeen(){\r\n    long total = 0;\r\n    for (AtomicLong l : unknownCategoricalsPerColumn.values()) {\r\n        total += l.get();\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "org.hibernate.cache.spi.entry.StandardCacheEntryImpl.assemble",
	"Comment": "assemble the previously disassembled state represented by this entry into the given entity instance.\tadditionally manages the preloadevent callbacks.",
	"Method": "Object[] assemble(Object instance,Serializable id,EntityPersister persister,Interceptor interceptor,EventSource session){\r\n    if (!persister.getEntityName().equals(subclass)) {\r\n        throw new AssertionFailure(\"Tried to assemble a different subclass instance\");\r\n    }\r\n    final Object[] state = TypeHelper.assemble(disassembledState, persister.getPropertyTypes(), session, instance);\r\n    final PreLoadEvent preLoadEvent = new PreLoadEvent(session).setEntity(instance).setState(state).setId(id).setPersister(persister);\r\n    final EventListenerGroup<PreLoadEventListener> listenerGroup = session.getFactory().getServiceRegistry().getService(EventListenerRegistry.class).getEventListenerGroup(EventType.PRE_LOAD);\r\n    for (PreLoadEventListener listener : listenerGroup.listeners()) {\r\n        listener.onPreLoad(preLoadEvent);\r\n    }\r\n    persister.setPropertyValues(instance, state);\r\n    return state;\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.getResultSet",
	"Comment": "execute given callablestatement, advance to the first result and return sql resultset.",
	"Method": "ResultSet getResultSet(PreparedStatement st,RowSelection selection,LimitHandler limitHandler,boolean autodiscovertypes,SharedSessionContractImplementor session,ResultSet getResultSet,CallableStatement st,RowSelection selection,LimitHandler limitHandler,boolean autodiscovertypes,SharedSessionContractImplementor session,ResultSet getResultSet){\r\n    try {\r\n        ResultSet rs = session.getJdbcCoordinator().getResultSetReturn().extract(st);\r\n        return processResultSet(rs, selection, limitHandler, autodiscovertypes, session);\r\n    } catch (SQLException | HibernateException e) {\r\n        session.getJdbcCoordinator().getLogicalConnection().getResourceRegistry().release(st);\r\n        session.getJdbcCoordinator().afterStatementExecution();\r\n        throw e;\r\n    }\r\n}"
}, {
	"Path": "org.hibernate.boot.spi.SessionFactoryOptions.getStatelessInterceptorImplementorSupplier",
	"Comment": "get the interceptor to use by default for all sessions opened from this factory.",
	"Method": "Supplier<? extends Interceptor> getStatelessInterceptorImplementorSupplier(){\r\n    return () -> {\r\n        try {\r\n            return getStatelessInterceptorImplementor().newInstance();\r\n        } catch (InstantiationException | IllegalAccessException e) {\r\n            throw new HibernateException(\"Could not supply session-scoped SessionFactory Interceptor\", e);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "org.hibernate.loader.Loader.upgradeLocks",
	"Comment": "does this query return objects that might be already cached\tby the session, whose lock mode may need upgrading",
	"Method": "boolean upgradeLocks(){\r\n    return false;\r\n}"
}, {
	"Path": "water.util.ArrayUtils.multArrArr",
	"Comment": "with no memory allocation for results.we assume the memory is already allocated.",
	"Method": "double[][] multArrArr(double[][] ary1,double[][] ary2,double[][] res,double[][] multArrArr,double[][] ary1,double[][] ary2){\r\n    if (ary1 == null || ary2 == null)\r\n        return null;\r\n    double[][] res = new double[ary1.length][ary2[0].length];\r\n    return multArrArr(ary1, ary2, res);\r\n}"
}]