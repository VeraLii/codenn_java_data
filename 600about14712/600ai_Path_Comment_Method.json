[{
	"Path": "boofcv.alg.tracker.klt.TestKltTracker.detectBadFeature",
	"Comment": "pass in a feature with a small determinant and see if it returns a fault.",
	"Method": "void detectBadFeature(){\r\n    KltTracker<GrayF32, GrayF32> tracker = createDefaultTracker();\r\n    tracker.setImage(image, derivX, derivY);\r\n    KltFeature feature = new KltFeature(2);\r\n    feature.setPosition(20, 20);\r\n    tracker.setImage(image, derivX, derivY);\r\n    assertTrue(tracker.track(feature) != KltTrackFault.SUCCESS);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.SiftScaleSpace.computeOctaveScales",
	"Comment": "computes all the scale images in an octave.this includes dog images.",
	"Method": "void computeOctaveScales(){\r\n    octaveImages[0] = tempImage0;\r\n    for (int i = 1; i < numScales + 3; i++) {\r\n        octaveImages[i].reshape(tempImage0.width, tempImage0.height);\r\n        applyGaussian(octaveImages[i - 1], octaveImages[i], kernelSigmaToK[i - 1]);\r\n    }\r\n    for (int i = 1; i < numScales + 3; i++) {\r\n        differenceOfGaussian[i - 1].reshape(tempImage0.width, tempImage0.height);\r\n        PixelMath.subtract(octaveImages[i], octaveImages[i - 1], differenceOfGaussian[i - 1]);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.TestContourTracer.shiftContourCheck",
	"Comment": "given a pattern that is only a contour, it sees if it has the expected results when the pattern\tis shifted to every possible location in the image",
	"Method": "void shiftContourCheck(GrayU8 pattern,int expectedSize,ConnectRule rule){\r\n    ContourTracer alg = new ContourTracer(rule);\r\n    GrayU8 input = new GrayU8(4, 5);\r\n    GrayS32 label = new GrayS32(input.width, input.height);\r\n    for (int y = 0; y < input.height - pattern.height + 1; y++) {\r\n        for (int x = 0; x < input.width - pattern.width + 1; x++) {\r\n            ImageMiscOps.fill(input, 0);\r\n            GrayU8 sub = input.subimage(x, y, x + pattern.width, y + pattern.height, null);\r\n            sub.setTo(pattern);\r\n            ImageMiscOps.fill(label, 0);\r\n            queue.reset();\r\n            queue.grow();\r\n            alg.setInputs(addBorder(input), label, queue);\r\n            alg.trace(2, x + 1, y + 1, true);\r\n            assertEquals(expectedSize, queue.sizeOfTail());\r\n            for (int yy = 0; yy < input.height; yy++) {\r\n                for (int xx = 0; xx < input.width; xx++) {\r\n                    boolean isOne = false;\r\n                    if (pattern.isInBounds(xx - x, yy - y)) {\r\n                        isOne = pattern.get(xx - x, yy - y) == 1;\r\n                    }\r\n                    if (isOne)\r\n                        assertEquals(2, label.get(xx, yy));\r\n                    else\r\n                        assertEquals(0, label.get(xx, yy));\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.watershed.TestRemoveWatersheds.basic",
	"Comment": "simple case.still will require multiple passes for all the pixels to be assigned.",
	"Method": "void basic(){\r\n    GrayS32 segmented = new GrayS32(5, 7);\r\n    segmented.data = new int[] { -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 1, 0, 0, -1, -1, 2, 2, 2, -1, -1, 0, 0, 0, -1, -1, 0, 0, 0, -1, -1, -1, -1, -1, -1 };\r\n    GrayS32 expected = new GrayS32(5, 7);\r\n    expected.data = new int[] { -1, -1, -1, -1, -1, -1, 0, 0, 0, -1, -1, 0, 0, 0, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1 };\r\n    RemoveWatersheds alg = new RemoveWatersheds();\r\n    alg.remove(segmented);\r\n    BoofTesting.assertEquals(expected, segmented, 0);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.KltTracker.getError",
	"Comment": "average absolute value of the difference between each pixel in the image and the template",
	"Method": "float getError(){\r\n    return error;\r\n}"
}, {
	"Path": "com.bugsnag.android.Bugsnag.getMetaData",
	"Comment": "get the global diagnostic information currently stored in metadata.",
	"Method": "MetaData getMetaData(){\r\n    return getClient().getMetaData();\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonBinaryGrayRefine.refineAll",
	"Comment": "refines all the detected polygons and places them into the provided list. polygons which fail the refinement\tstep are not added.",
	"Method": "void refineAll(){\r\n    List<DetectPolygonFromContour.Info> detections = detector.getFound().toList();\r\n    for (int i = 0; i < detections.size(); i++) {\r\n        refine(detections.get(i));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.TestDetectFiducialSquareGrid.simple",
	"Comment": "generate a fiducial and detect its corners.fully visible.",
	"Method": "void simple(){\r\n    ConfigFiducialBinary configBinary = new ConfigFiducialBinary(1);\r\n    configBinary.gridWidth = 3;\r\n    long[] values = new long[] { 0, 1, 2, 3, 4, 5 };\r\n    BaseDetectFiducialSquare<GrayF32> detector = FactoryFiducial.squareBinary(configBinary, ConfigThreshold.fixed(125), GrayF32.class).getAlgorithm();\r\n    DetectFiducialSquareGrid<GrayF32> alg = new DetectFiducialSquareGrid(3, 2, values, detector);\r\n    RenderSquareBinaryGridFiducial render = new RenderSquareBinaryGridFiducial();\r\n    render.values = values;\r\n    GrayF32 image = render.generate(3, 2);\r\n    assertTrue(alg.detect(image));\r\n    List<DetectFiducialSquareGrid.Detection> detections = alg.detections.toList();\r\n    int[] foundIds = new int[6];\r\n    for (int i = 0; i < detections.size(); i++) {\r\n        DetectFiducialSquareGrid.Detection d = detections.get(i);\r\n        foundIds[d.gridIndex]++;\r\n        Quadrilateral_F64 expected = render.expectedCorners.get(d.gridIndex);\r\n        Quadrilateral_F64 found = d.location;\r\n        for (int j = 0; j < 4; j++) {\r\n            assertTrue(expected.get(j).distance(found.get(j)) < 0.1);\r\n        }\r\n    }\r\n    for (int i = 0; i < foundIds.length; i++) {\r\n        assertEquals(1, foundIds[i]);\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.learning.Confusion.computeAccuracy",
	"Comment": "computes accuracy from the confusion matrix.this is the sum of the fraction correct divide by total number\tof types.the number of each sample for each type is not taken in account.",
	"Method": "double computeAccuracy(){\r\n    double totalCorrect = 0;\r\n    double totalIncorrect = 0;\r\n    for (int i = 0; i < actualCounts.length; i++) {\r\n        for (int j = 0; j < actualCounts.length; j++) {\r\n            if (i == j) {\r\n                totalCorrect += matrix.get(i, j);\r\n            } else {\r\n                totalIncorrect += matrix.get(i, j);\r\n            }\r\n        }\r\n    }\r\n    return totalCorrect / (totalCorrect + totalIncorrect);\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.OrientationHistogramSift.computeAngle",
	"Comment": "compute the angle.the angle for each neighbor bin is found using the weighted sum\tof the derivative.then the peak index is found by 2nd order polygon interpolation.these two bits of\tinformation are combined and used to return the final angle output.",
	"Method": "double computeAngle(int index1){\r\n    int index0 = CircularIndex.addOffset(index1, -1, histogramMag.length);\r\n    int index2 = CircularIndex.addOffset(index1, 1, histogramMag.length);\r\n    double v0 = histogramMag[index0];\r\n    double v1 = histogramMag[index1];\r\n    double v2 = histogramMag[index2];\r\n    double offset = FastHessianFeatureDetector.polyPeak(v0, v1, v2);\r\n    return interpolateAngle(index0, index1, index2, offset);\r\n}"
}, {
	"Path": "boofcv.alg.geo.h.HomographyInducedStereoLinePt.process",
	"Comment": "computes the homography based on a line and point on the plane",
	"Method": "void process(PairLineNorm line,AssociatedPair point){\r\n    GeometryMath_F64.mult(F, point.p1, Fx);\r\n    GeometryMath_F64.cross(Fx, line.getL2(), t0);\r\n    GeometryMath_F64.cross(point.p2, t0, t1);\r\n    GeometryMath_F64.cross(point.p2, e2, t0);\r\n    double top = GeometryMath_F64.dot(t0, t1);\r\n    double bottom = t0.normSq() * (line.l1.x * point.p1.x + line.l1.y * point.p1.y + line.l1.z);\r\n    GeometryMath_F64.outerProd(e2, line.l1, el);\r\n    GeometryMath_F64.multCrossA(line.l2, F, lf);\r\n    CommonOps_DDRM.add(lf, top / bottom, el, H);\r\n    adjust.adjust(H, point);\r\n}"
}, {
	"Path": "boofcv.alg.flow.BroxWarpingSpacial.interpolateFlowScale",
	"Comment": "provides an initial estimate for the flow by interpolating values from the previous layer.",
	"Method": "void interpolateFlowScale(int widthNew,int heightNew){\r\n    GrayF32 enlargedU = warpDeriv2X;\r\n    GrayF32 enlargedV = warpDeriv2Y;\r\n    interpolateFlowScale(flowU, enlargedU);\r\n    interpolateFlowScale(flowV, enlargedV);\r\n    flowU.reshape(widthNew, heightNew);\r\n    flowV.reshape(widthNew, heightNew);\r\n    flowU.setTo(enlargedU);\r\n    flowV.setTo(enlargedV);\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.PnPLepetitEPnP.computeResultFromBest",
	"Comment": "selects the best motion hypothesis based on the actual observations and optionally\toptimizes the solution.",
	"Method": "void computeResultFromBest(Se3_F64 solutionModel){\r\n    double bestScore = Double.MAX_VALUE;\r\n    int bestSolution = -1;\r\n    for (int i = 0; i < numControl; i++) {\r\n        double score = score(solutions.get(i));\r\n        if (score < bestScore) {\r\n            bestScore = score;\r\n            bestSolution = i;\r\n        }\r\n    }\r\n    double[] solution = solutions.get(bestSolution);\r\n    if (numIterations > 0) {\r\n        gaussNewton(solution);\r\n    }\r\n    UtilLepetitEPnP.computeCameraControl(solution, nullPts, solutionPts, numControl);\r\n    motionFit.process(controlWorldPts.toList(), solutionPts.toList());\r\n    solutionModel.set(motionFit.getTransformSrcToDst());\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.AssociateStereo2D.setDestination",
	"Comment": "converts location into rectified coordinates and saved a reference to the description.",
	"Method": "void setDestination(FastQueue<Point2D_F64> location,FastQueue<Desc> descriptions){\r\n    locationRight.reset();\r\n    for (int i = 0; i < location.size; i++) {\r\n        Point2D_F64 orig = location.get(i);\r\n        Point2D_F64 rectified = locationRight.grow();\r\n        rightImageToRect.compute(orig.x, orig.y, rectified);\r\n    }\r\n    this.descriptionsRight = descriptions;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.FeaturePyramid.detectCandidateFeatures",
	"Comment": "use the feature detector to find candidate features in each level.only compute the needed image derivatives.",
	"Method": "void detectCandidateFeatures(T image,double sigma){\r\n    float scaleThreshold = (float) (baseThreshold / Math.pow(sigma, scalePower));\r\n    detector.setThreshold(scaleThreshold);\r\n    computeDerivative.setInput(image);\r\n    D derivX = null, derivY = null;\r\n    D derivXX = null, derivYY = null, derivXY = null;\r\n    if (detector.getRequiresGradient()) {\r\n        derivX = computeDerivative.getDerivative(true);\r\n        derivY = computeDerivative.getDerivative(false);\r\n    }\r\n    if (detector.getRequiresHessian()) {\r\n        derivXX = computeDerivative.getDerivative(true, true);\r\n        derivYY = computeDerivative.getDerivative(false, false);\r\n        derivXY = computeDerivative.getDerivative(true, false);\r\n    }\r\n    detector.process(image, derivX, derivY, derivXX, derivYY, derivXY);\r\n    intensities[spaceIndex].reshape(image.width, image.height);\r\n    intensities[spaceIndex].setTo(detector.getIntensity());\r\n    List<Point2D_I16> m = maximums[spaceIndex];\r\n    m.clear();\r\n    QueueCorner q = detector.getMaximums();\r\n    for (int i = 0; i < q.size; i++) {\r\n        m.add(q.get(i).copy());\r\n    }\r\n    spaceIndex++;\r\n    if (spaceIndex >= 3)\r\n        spaceIndex = 0;\r\n}"
}, {
	"Path": "boofcv.io.TestUtilIO.ensureURL_mangled",
	"Comment": "see if it handles the url after it has been messed up by being passed through file",
	"Method": "void ensureURL_mangled(){\r\n    String input = \"jar:file:/home/person/BoofApplications/demonstrations.jar!/fiducial/image/video/patterns/chicken.png\";\r\n    URL url = UtilIO.ensureURL(new File(input).getPath());\r\n    assertNotNull(url);\r\n    assertEquals(input, url.toString());\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TestEnforceTrifocalGeometry.checkMatrixE",
	"Comment": "construct a tensor from two arbitrary camera matrices.then provide the same inputs\tto the algorithm and see if the matrix is constructed correctly.",
	"Method": "void checkMatrixE(){\r\n    DMatrixRMaj P2 = new DMatrixRMaj(3, 4, true, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12);\r\n    DMatrixRMaj P3 = new DMatrixRMaj(3, 4, true, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120);\r\n    Point3D_F64 e2 = new Point3D_F64(P2.get(0, 3), P2.get(1, 3), P2.get(2, 3));\r\n    Point3D_F64 e3 = new Point3D_F64(P3.get(0, 3), P3.get(1, 3), P3.get(2, 3));\r\n    TrifocalTensor tensor = MultiViewOps.createTrifocal(P2, P3, null);\r\n    EnforceTrifocalGeometry alg = new EnforceTrifocalGeometry();\r\n    alg.constructE(e2, e3);\r\n    DMatrixRMaj X = new DMatrixRMaj(18, 1);\r\n    for (int i = 0; i < 9; i++) {\r\n        X.data[i] = P2.get(i / 3, i % 3);\r\n        X.data[i + 9] = P3.get(i / 3, i % 3);\r\n    }\r\n    DMatrixRMaj vectorT = new DMatrixRMaj(27, 1);\r\n    CommonOps_DDRM.mult(alg.E, X, vectorT);\r\n    TrifocalTensor foundT = new TrifocalTensor();\r\n    foundT.convertFrom(vectorT);\r\n    for (int i = 0; i < 3; i++) {\r\n        assertTrue(MatrixFeatures_DDRM.isIdentical(tensor.getT(i), foundT.getT(i), 1e-8));\r\n    }\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.windows.PokemonTab.addAndInitializeComponents",
	"Comment": "handle component creation and initialization inside pokemontab constructor.",
	"Method": "void addAndInitializeComponents(){\r\n    final JPanel topPanel = new JPanel(new GridBagLayout());\r\n    final JButton refreshPkmn = new JButton(\"Refresh List\"), renameSelected = new JButton(BatchOperation.RENAME.toString()), transferSelected = new JButton(BatchOperation.TRANSFER.toString()), evolveSelected = new JButton(BatchOperation.EVOLVE.toString()), powerUpSelected = new JButton(BatchOperation.POWER_UP.toString()), toggleFavorite = new JButton(BatchOperation.FAVORITE.toString()), setFavoriteYes = new JButton(BatchOperation.SET_FAVORITE_YES.toString()), setFavoriteNo = new JButton(BatchOperation.SET_FAVORITE_NO.toString());\r\n    final IVTransferTextField ivTransfer = new IVTransferTextField(pt::selectLessThanIv);\r\n    final JButton transferIv = new JButton(\"Select Pokemon < IV\");\r\n    final JComboBox<String> pokelang = new JComboBox<String>(LOCALES);\r\n    final JComboBox<String> fontSize = new JComboBox(SIZES);\r\n    final GridBagConstraints gbc = new GridBagConstraints();\r\n    topPanel.add(refreshPkmn, gbc);\r\n    topPanel.add(renameSelected, gbc);\r\n    topPanel.add(transferSelected, gbc);\r\n    topPanel.add(evolveSelected, gbc);\r\n    topPanel.add(powerUpSelected, gbc);\r\n    topPanel.add(toggleFavorite, gbc);\r\n    topPanel.add(setFavoriteYes, gbc);\r\n    topPanel.add(setFavoriteNo, gbc);\r\n    topPanel.add(ivTransfer, gbc);\r\n    topPanel.add(transferIv, gbc);\r\n    gbc.weightx = 1.0;\r\n    gbc.weighty = 1.0;\r\n    gbc.gridwidth = GRID_WIDTH;\r\n    gbc.fill = GridBagConstraints.HORIZONTAL;\r\n    topPanel.add(new SearchBarTextField(pt::filterTable), gbc);\r\n    topPanel.add(pokelang);\r\n    topPanel.add(fontSize);\r\n    add(topPanel, BorderLayout.NORTH);\r\n    final JScrollPane sp = new JScrollPane(pt);\r\n    sp.setHorizontalScrollBarPolicy(JScrollPane.HORIZONTAL_SCROLLBAR_AS_NEEDED);\r\n    add(sp, BorderLayout.CENTER);\r\n    refreshPkmn.addActionListener(l -> new OperationWorker<Object>(this::refreshPkmn).execute());\r\n    renameSelected.addActionListener(l -> new OperationWorker<Object>(this::renameSelected).execute());\r\n    transferSelected.addActionListener(l -> new OperationWorker<Object>(this::transferSelected).execute());\r\n    evolveSelected.addActionListener(l -> new OperationWorker<Object>(this::evolveSelected).execute());\r\n    powerUpSelected.addActionListener(l -> new OperationWorker<Object>(this::powerUpSelected).execute());\r\n    toggleFavorite.addActionListener(l -> new OperationWorker<BatchOperation>(this::toggleFavorite, BatchOperation.FAVORITE).execute());\r\n    setFavoriteYes.addActionListener(l -> new OperationWorker<BatchOperation>(this::toggleFavorite, BatchOperation.SET_FAVORITE_YES).execute());\r\n    setFavoriteNo.addActionListener(l -> new OperationWorker<BatchOperation>(this::toggleFavorite, BatchOperation.SET_FAVORITE_NO).execute());\r\n    transferIv.addActionListener(l -> new OperationWorker<String>(pt::selectLessThanIv, ivTransfer.getText()).execute());\r\n    pokelang.setSelectedItem(config.getString(ConfigKey.LANGUAGE));\r\n    pokelang.addActionListener(e -> new OperationWorker<String>(this::changeLanguage, (String) pokelang.getSelectedItem()).execute());\r\n    fontSize.setSelectedItem(String.valueOf(pt.getFont().getSize()));\r\n    fontSize.addActionListener(e -> new OperationWorker<Object>(() -> {\r\n        final String innerSize = fontSize.getSelectedItem().toString();\r\n        pt.setFont(pt.getFont().deriveFont(Float.parseFloat(innerSize)));\r\n        config.setInt(ConfigKey.FONT_SIZE, Integer.parseInt(innerSize));\r\n    }).execute());\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.GenericFiducialDetectorChecks.checkStability",
	"Comment": "see if the stability estimation is reasonable.first detect targets in the full sized image.then shrink it\tby 15% and see if the instability increases.the instability should always increase for smaller objects with\tthe same orientation since the geometry is worse.",
	"Method": "void checkStability(){\r\n    for (ImageType type : types) {\r\n        ImageBase image = loadImage(type);\r\n        FiducialDetector detector = createDetector(type);\r\n        detector.setLensDistortion(loadDistortion(true), image.width, image.height);\r\n        detector.detect(image);\r\n        assertTrue(detector.totalFound() >= 1);\r\n        long[] foundIds = new long[detector.totalFound()];\r\n        double[] location = new double[detector.totalFound()];\r\n        double[] orientation = new double[detector.totalFound()];\r\n        FiducialStability results = new FiducialStability();\r\n        for (int i = 0; i < detector.totalFound(); i++) {\r\n            detector.computeStability(i, 0.2, results);\r\n            foundIds[i] = detector.getId(i);\r\n            location[i] = results.location;\r\n            orientation[i] = results.orientation;\r\n        }\r\n        ImageBase shrunk = image.createSameShape();\r\n        new FDistort(image, shrunk).affine(0.6, 0, 0, 0.6, 0, 0).apply();\r\n        detector.detect(shrunk);\r\n        assertTrue(detector.totalFound() == foundIds.length);\r\n        for (int i = 0; i < detector.totalFound(); i++) {\r\n            detector.computeStability(i, 0.2, results);\r\n            long id = detector.getId(i);\r\n            boolean matched = false;\r\n            for (int j = 0; j < foundIds.length; j++) {\r\n                if (foundIds[j] == id) {\r\n                    matched = true;\r\n                    assertTrue(location[j] < results.location);\r\n                    assertTrue(orientation[j] < results.orientation);\r\n                    break;\r\n                }\r\n            }\r\n            assertTrue(matched);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Bugsnag.enableExceptionHandler",
	"Comment": "enable automatic reporting of unhandled exceptions.by default, this is automatically enabled in the constructor.",
	"Method": "void enableExceptionHandler(){\r\n    getClient().enableExceptionHandler();\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.setEnableExceptionHandler",
	"Comment": "set whether or not bugsnag should automatically handle uncaught exceptions",
	"Method": "void setEnableExceptionHandler(boolean enableExceptionHandler){\r\n    this.enableExceptionHandler = enableExceptionHandler;\r\n}"
}, {
	"Path": "boofcv.factory.sfm.FactoryVisualOdometry.monoPlaneInfinity",
	"Comment": "monocular plane based visual odometry algorithm which uses both points on the plane and off plane for motion\testimation.",
	"Method": "MonocularPlaneVisualOdometry<T> monoPlaneInfinity(int thresholdAdd,int thresholdRetire,double inlierPixelTol,int ransacIterations,PointTracker<T> tracker,ImageType<T> imageType){\r\n    double ransacTOL = inlierPixelTol * inlierPixelTol;\r\n    ModelManagerSe2_F64 manager = new ModelManagerSe2_F64();\r\n    DistancePlane2DToPixelSq distance = new DistancePlane2DToPixelSq();\r\n    GenerateSe2_PlanePtPixel generator = new GenerateSe2_PlanePtPixel();\r\n    ModelMatcher<Se2_F64, PlanePtPixel> motion = new Ransac(2323, manager, generator, distance, ransacIterations, ransacTOL);\r\n    VisOdomMonoPlaneInfinity<T> alg = new VisOdomMonoPlaneInfinity(thresholdAdd, thresholdRetire, inlierPixelTol, motion, tracker);\r\n    return new MonoPlaneInfinity_to_MonocularPlaneVisualOdometry(alg, distance, generator, imageType);\r\n}"
}, {
	"Path": "boofcv.alg.geo.robust.TestDistanceSe3SymmetricSq.testIntrinsicParameters",
	"Comment": "manually compute the error using a calibration matrix and see if they match",
	"Method": "void testIntrinsicParameters(){\r\n    DMatrixRMaj K = new DMatrixRMaj(3, 3, true, 100, 0.01, 200, 0, 150, 200, 0, 0, 1);\r\n    DMatrixRMaj K2 = new DMatrixRMaj(3, 3, true, 105, 0.021, 180, 0, 155, 210, 0, 0, 1);\r\n    DMatrixRMaj K_inv = new DMatrixRMaj(3, 3);\r\n    DMatrixRMaj K2_inv = new DMatrixRMaj(3, 3);\r\n    CommonOps_DDRM.invert(K, K_inv);\r\n    CommonOps_DDRM.invert(K2, K2_inv);\r\n    Se3_F64 keyToCurr = new Se3_F64();\r\n    keyToCurr.getT().set(0.1, -0.1, 0.01);\r\n    Point3D_F64 X = new Point3D_F64(0.02, -0.05, 3);\r\n    AssociatedPair obs = new AssociatedPair();\r\n    AssociatedPair obsP = new AssociatedPair();\r\n    obs.p1.x = X.x / X.z;\r\n    obs.p1.y = X.y / X.z;\r\n    SePointOps_F64.transform(keyToCurr, X, X);\r\n    obs.p2.x = X.x / X.z;\r\n    obs.p2.y = X.y / X.z;\r\n    GeometryMath_F64.mult(K, obs.p1, obsP.p1);\r\n    GeometryMath_F64.mult(K2, obs.p2, obsP.p2);\r\n    obsP.p1.x += 0.25;\r\n    obsP.p1.y += 0.25;\r\n    obsP.p2.x -= 0.25;\r\n    obsP.p2.y -= 0.25;\r\n    GeometryMath_F64.mult(K_inv, obsP.p1, obsP.p1);\r\n    GeometryMath_F64.mult(K2_inv, obsP.p2, obsP.p2);\r\n    LineParametric3D_F64 rayA = new LineParametric3D_F64();\r\n    LineParametric3D_F64 rayB = new LineParametric3D_F64();\r\n    rayA.slope.set(obsP.p1.x, obsP.p1.y, 1);\r\n    rayB.p.set(-0.1, 0.1, -0.01);\r\n    rayB.slope.set(obsP.p2.x, obsP.p2.y, 1);\r\n    ClosestPoint3D_F64.closestPoint(rayA, rayB, X);\r\n    AssociatedPair ugh = new AssociatedPair();\r\n    ugh.p1.x = X.x / X.z;\r\n    ugh.p1.y = X.y / X.z;\r\n    SePointOps_F64.transform(keyToCurr, X, X);\r\n    ugh.p2.x = X.x / X.z;\r\n    ugh.p2.y = X.y / X.z;\r\n    GeometryMath_F64.mult(K, ugh.p1, ugh.p1);\r\n    GeometryMath_F64.mult(K2, ugh.p2, ugh.p2);\r\n    GeometryMath_F64.mult(K, obsP.p1, obsP.p1);\r\n    GeometryMath_F64.mult(K2, obsP.p2, obsP.p2);\r\n    double dx1 = ugh.p1.x - obsP.p1.x;\r\n    double dy1 = ugh.p1.y - obsP.p1.y;\r\n    double dx2 = ugh.p2.x - obsP.p2.x;\r\n    double dy2 = ugh.p2.y - obsP.p2.y;\r\n    double error = dx1 * dx1 + dy1 * dy1 + dx2 * dx2 + dy2 * dy2;\r\n    GeometryMath_F64.mult(K_inv, obsP.p1, obsP.p1);\r\n    GeometryMath_F64.mult(K2_inv, obsP.p2, obsP.p2);\r\n    DistanceSe3SymmetricSq alg = new DistanceSe3SymmetricSq(triangulate);\r\n    alg.setIntrinsic(0, PerspectiveOps.matrixToPinhole(K, 0, 0, null));\r\n    alg.setIntrinsic(1, PerspectiveOps.matrixToPinhole(K2, 0, 0, null));\r\n    alg.setModel(keyToCurr);\r\n    assertEquals(error, alg.computeDistance(obsP), 1e-8);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareRegularClustersIntoGrids.addLineToGrid",
	"Comment": "add all the nodes into the list which lie along the line defined by a and b.a is assumed to be\tan end point.care is taken to not cycle.",
	"Method": "int addLineToGrid(SquareNode a,SquareNode b,List<SquareNode> list){\r\n    int total = 2;\r\n    while (true) {\r\n        boolean matched = false;\r\n        int side;\r\n        for (side = 0; side < 4; side++) {\r\n            if (b.edges[side] != null && b.edges[side].destination(b) == a) {\r\n                matched = true;\r\n                break;\r\n            }\r\n        }\r\n        if (!matched) {\r\n            throw new RuntimeException(\"BUG!\");\r\n        }\r\n        side = (side + 2) % 4;\r\n        if (b.edges[side] == null)\r\n            break;\r\n        SquareNode c = b.edges[side].destination(b);\r\n        if (c.graph == SEARCHED)\r\n            break;\r\n        total++;\r\n        c.graph = SEARCHED;\r\n        list.add(c);\r\n        a = b;\r\n        b = c;\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "org.boon.datarepo.impl.RepoBuilderDefault.storeKeyInIndexOnly",
	"Comment": "stores only the keys in the index. the data is stored elsewhere.this is not implemented yet.",
	"Method": "RepoBuilder storeKeyInIndexOnly(){\r\n    this.storeKeyInIndexOnly = true;\r\n    return this;\r\n}"
}, {
	"Path": "boofcv.alg.geo.TestDecomposeEssential.multipleCalls",
	"Comment": "checks to see if the same solution is returned when invoked multiple times",
	"Method": "void multipleCalls(){\r\n    DMatrixRMaj R = ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0.1, -0.4, 0.5, null);\r\n    Vector3D_F64 T = new Vector3D_F64(2, 1, -3);\r\n    DMatrixRMaj E = MultiViewOps.createEssential(R, T, null);\r\n    DecomposeEssential alg = new DecomposeEssential();\r\n    alg.decompose(E);\r\n    alg.decompose(E);\r\n    List<Se3_F64> solutions = alg.getSolutions();\r\n    assertEquals(4, solutions.size());\r\n    checkUnique(solutions);\r\n    checkHasOriginal(solutions, R, T);\r\n}"
}, {
	"Path": "boofcv.factory.fiducial.FactoryFiducialCalibration.circleRegularGrid",
	"Comment": "detector for regular grid of circles.all circles must be entirely inside of the image.",
	"Method": "CalibrationDetectorCircleRegularGrid circleRegularGrid(ConfigCircleRegularGrid config){\r\n    config.checkValidity();\r\n    return new CalibrationDetectorCircleRegularGrid(config);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.windows.PokemonTable.filterTable",
	"Comment": "function for filtering the table using the proper rowfilter of java.",
	"Method": "void filterTable(String filterText){\r\n    RowFilter<PokemonTableModel, Integer> rowFilter = null;\r\n    if (filterText != null && !\"\".equals(filterText)) {\r\n        rowFilter = new PokemonRowFilter(filterText);\r\n    }\r\n    trs.setRowFilter(rowFilter);\r\n}"
}, {
	"Path": "boofcv.factory.sfm.FactoryMotion2D.createVideoStitch",
	"Comment": "estimates the image motion then combines images together.typically used for mosaics and stabilization.",
	"Method": "StitchingFromMotion2D<I, IT> createVideoStitch(double maxJumpFraction,ImageMotion2D<I, IT> motion2D,ImageType<I> imageType){\r\n    StitchingTransform<IT> transform;\r\n    if (motion2D.getTransformType() == Affine2D_F64.class) {\r\n        transform = (StitchingTransform) FactoryStitchingTransform.createAffine_F64();\r\n    } else {\r\n        transform = (StitchingTransform) FactoryStitchingTransform.createHomography_F64();\r\n    }\r\n    InterpolatePixel<I> interp;\r\n    if (imageType.getFamily() == ImageType.Family.GRAY || imageType.getFamily() == ImageType.Family.PLANAR) {\r\n        interp = FactoryInterpolation.createPixelS(0, 255, InterpolationType.BILINEAR, BorderType.EXTENDED, imageType.getImageClass());\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unsupported image type\");\r\n    }\r\n    ImageDistort<I, I> distorter = FactoryDistort.distort(false, interp, imageType);\r\n    distorter.setRenderAll(false);\r\n    return new StitchingFromMotion2D(motion2D, distorter, transform, maxJumpFraction);\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.TestCalibrationDetectorCircleRegularGrid.createFisheyePoses",
	"Comment": "reduce the intensity of fisheye distortion by moving the fiducials away from the border",
	"Method": "void createFisheyePoses(){\r\n    Se3_F64 markerToWorld = new Se3_F64();\r\n    ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI, 0, markerToWorld.R);\r\n    markerToWorld.T.set(0, 0, 0.12);\r\n    fisheye_poses.add(markerToWorld.copy());\r\n    markerToWorld.T.set(0.1, 0, 0.18);\r\n    fisheye_poses.add(markerToWorld.copy());\r\n    markerToWorld.T.set(0.25, 0, 0.2);\r\n    fisheye_poses.add(markerToWorld.copy());\r\n    ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI - 0.2, 0, markerToWorld.getR());\r\n    fisheye_poses.add(markerToWorld.copy());\r\n    markerToWorld.T.set(0.3, 0, 0.15);\r\n    ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI - 1, 0, markerToWorld.getR());\r\n    fisheye_poses.add(markerToWorld.copy());\r\n    ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI - 1, 0.15, markerToWorld.getR());\r\n    fisheye_poses.add(markerToWorld.copy());\r\n    ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI - 1, 0.27, markerToWorld.getR());\r\n    fisheye_poses.add(markerToWorld.copy());\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.TestCylinderToEquirectangular_F64.pointingAtZero",
	"Comment": "the latitude and longitude should be zero when sampling the middle of the cylindrical image",
	"Method": "void pointingAtZero(){\r\n    CylinderToEquirectangular_F64 alg = new CylinderToEquirectangular_F64();\r\n    alg.setEquirectangularShape(400, 501);\r\n    alg.configure(200, 301, UtilAngle.radian(100));\r\n    alg.compute(100, 150);\r\n    assertEquals(200, alg.distX, GrlConstants.TEST_F64);\r\n    assertEquals(501 - 250 - 1, alg.distY, GrlConstants.TEST_F64);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.TestStitchingFromMotion2D.checkMaxJump",
	"Comment": "provide an extremely different transformation and see if that causes an exception",
	"Method": "void checkMaxJump(){\r\n    HelperMotion motion = new HelperMotion();\r\n    HelperDistort distort = new HelperDistort();\r\n    StitchingTransform trans = FactoryStitchingTransform.createAffine_F64();\r\n    StitchingFromMotion2D<GrayF32, Affine2D_F64> alg = new StitchingFromMotion2D(motion, distort, trans, 0.3);\r\n    alg.configure(200, 300, null);\r\n    assertTrue(alg.process(image));\r\n    motion.found = motion0;\r\n    assertFalse(alg.process(image));\r\n}"
}, {
	"Path": "org.boofcv.video.QrCodeActivity.processImage",
	"Comment": "this function is invoked in its own thread and can take as long as you want.",
	"Method": "void processImage(ImageBase image){\r\n    long time0 = System.nanoTime();\r\n    detector.process((GrayU8) image);\r\n    long time1 = System.nanoTime();\r\n    timeDetection.update((time1 - time0) * 1e-6);\r\n    synchronized (foundQR) {\r\n        foundQR.reset();\r\n        List<QrCode> found = detector.getDetections();\r\n        for (int i = 0; i < found.size(); i++) {\r\n            QrCode qr = found.get(i);\r\n            foundQR.grow().set(qr.bounds);\r\n            message = qr.message;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.boon.collections.LongList.reduceBy",
	"Comment": "this would be a good opportunity to reintroduce dynamic invoke",
	"Method": "long reduceBy(Object function,long reduceBy,Object function,String name,long reduceBy,Lng.ReduceBy reduceBy){\r\n    return Lng.reduceBy(values, end, reduceBy);\r\n}"
}, {
	"Path": "boofcv.abst.feature.detect.intensity.WrapperHessianBlobIntensity.getIgnoreBorder",
	"Comment": "no ignore border unless the derivative has an ignore border",
	"Method": "int getIgnoreBorder(){\r\n    return 0;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.template.TemplateMatching.setTemplate",
	"Comment": "specifies the template to search for and the maximum number of matches to return.",
	"Method": "void setTemplate(T template,T mask,int maxMatches){\r\n    this.template = template;\r\n    this.mask = mask;\r\n    this.maxMatches = maxMatches;\r\n}"
}, {
	"Path": "boofcv.struct.calib.StereoParameters.getBaseline",
	"Comment": "returns the distance between the optical center of each camera",
	"Method": "double getBaseline(){\r\n    return rightToLeft.getT().norm();\r\n}"
}, {
	"Path": "boofcv.alg.transform.pyramid.TestPyramidFloatScale.checkSigmas",
	"Comment": "well no blur is applied at any level so this should all be zero",
	"Method": "void checkSigmas(){\r\n    InterpolatePixelS<GrayF32> interp = FactoryInterpolation.bilinearPixelS(GrayF32.class, BorderType.EXTENDED);\r\n    PyramidFloatScale<GrayF32> alg = new PyramidFloatScale(interp, new double[] { 3, 5 }, imageType);\r\n    for (int i = 0; i < 2; i++) {\r\n        assertEquals(0, alg.getSigma(0), 1e-8);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.StereoSparse3D.process",
	"Comment": "takes in pixel coordinates from the left camera in the original image coordinate system",
	"Method": "boolean process(double x,double y){\r\n    leftPixelToRect.compute(x, y, pixelRect);\r\n    if (!disparity.process((int) (pixelRect.x + 0.5), (int) (pixelRect.y + 0.5)))\r\n        return false;\r\n    this.w = disparity.getDisparity();\r\n    computeHomo3D(pixelRect.x, pixelRect.y, pointLeft);\r\n    return true;\r\n}"
}, {
	"Path": "org.boon.datarepo.impl.RepoBuilderDefault.usePropertyForAccess",
	"Comment": "turns on property access instead of field access.field is the default.",
	"Method": "RepoBuilder usePropertyForAccess(boolean useProperty){\r\n    this.useField = !useProperty;\r\n    return this;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.Utilities.getRealExceptionMessage",
	"Comment": "abstracts the exception message and makes a more readable exception out of it for edge cases.",
	"Method": "String getRealExceptionMessage(Exception exception){\r\n    String message = exception.getMessage();\r\n    if (exception instanceof InvalidProtocolBufferException || \"Contents of buffer are null\".equals(message)) {\r\n        message = \"Server hasn't responded in time. \" + \"Seems to be busy. \" + \"The action may have been successful though. (\" + message + \")\";\r\n    }\r\n    return message;\r\n}"
}, {
	"Path": "boofcv.alg.geo.impl.ImplRectifyImageOps_F32.adjustCalibrated",
	"Comment": "internal function which applies the rectification adjustment to a calibrated stereo pair",
	"Method": "void adjustCalibrated(FMatrixRMaj rectifyLeft,FMatrixRMaj rectifyRight,FMatrixRMaj rectifyK,RectangleLength2D_F32 bound,float scale){\r\n    float deltaX = -bound.x0 * scale;\r\n    float deltaY = -bound.y0 * scale;\r\n    SimpleMatrix A = new SimpleMatrix(3, 3, true, new float[] { scale, 0, deltaX, 0, scale, deltaY, 0, 0, 1 });\r\n    SimpleMatrix rL = SimpleMatrix.wrap(rectifyLeft);\r\n    SimpleMatrix rR = SimpleMatrix.wrap(rectifyRight);\r\n    SimpleMatrix K = SimpleMatrix.wrap(rectifyK);\r\n    SimpleMatrix K_inv = K.invert();\r\n    rL = K_inv.mult(rL);\r\n    rR = K_inv.mult(rR);\r\n    K = A.mult(K);\r\n    rectifyK.set(K.getFDRM());\r\n    rectifyLeft.set(K.mult(rL).getFDRM());\r\n    rectifyRight.set(K.mult(rR).getFDRM());\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.HysteresisEdgeTracePoints.check",
	"Comment": "checks to see if the given coordinate is above the lower threshold.if it is the point will be\tadded to the current segment or be the start of a new segment.",
	"Method": "boolean check(int x,int y,EdgeSegment parent,boolean match){\r\n    if (intensity.isInBounds(x, y)) {\r\n        int index = intensity.getIndex(x, y);\r\n        if (intensity.data[index] >= lower) {\r\n            intensity.data[index] = MARK_TRAVERSED;\r\n            if (!match) {\r\n                Point2D_I32 p = queuePoints.grow();\r\n                p.set(x, y);\r\n                parent.points.add(p);\r\n            } else {\r\n                startNewSegment(x, y, parent);\r\n            }\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.alg.filter.derivative.CompareDerivativeToConvolution.countImageOutputs",
	"Comment": "counts the number of derivative images it takes in as an output.",
	"Method": "int countImageOutputs(Class<?>[] param){\r\n    int count = 0;\r\n    for (int i = 1; i < param.length; i++) {\r\n        if (ImageGray.class.isAssignableFrom(param[i])) {\r\n            count++;\r\n        }\r\n    }\r\n    return count;\r\n}"
}, {
	"Path": "boofcv.abst.feature.dense.TestDescribeImageDenseSift.checkSampleLocations",
	"Comment": "checks to see if the returned location is actually where it sampled",
	"Method": "void checkSampleLocations(){\r\n    for (Class type : imageTypes) {\r\n        ImageGray image = GeneralizedImageOps.createSingleBand(type, width, height);\r\n        GImageMiscOps.fillUniform(image, rand, 0, 200);\r\n        DescribeImageDense alg = createAlg(type, 8, 9);\r\n        alg.process(image);\r\n        List<Point2D_I32> locations = alg.getLocations();\r\n        for (int i = 0; i < locations.size(); i++) {\r\n            Point2D_I32 p = locations.get(i);\r\n            TupleDesc_F64 expected = describe(p.x, p.y, image, alg);\r\n            TupleDesc_F64 found = (TupleDesc_F64) alg.getDescriptions().get(i);\r\n            for (int j = 0; j < expected.size(); j++) {\r\n                assertEquals(expected.value[j], found.value[j], 1e-8);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.TestGThresholdImageOps.computeOtsu",
	"Comment": "compare otsu against a brute force algorithm for computing variance directly.",
	"Method": "void computeOtsu(){\r\n    for (int i = 0; i < 100; i++) {\r\n        int[] histogram = new int[256];\r\n        int total = 0;\r\n        for (int j = 0; j < histogram.length; j++) {\r\n            total += histogram[j] = rand.nextInt(400);\r\n        }\r\n        int best = bruteForceOtsu(histogram, total);\r\n        int found = GThresholdImageOps.computeOtsu(histogram, histogram.length, total);\r\n        assertEquals(best, found);\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.example.ExampleActivity.crashUnhandled",
	"Comment": "throws an unhandled exception. bugsnag will automatically capture any uncaught exceptionsin your app and send an error report.",
	"Method": "void crashUnhandled(View view){\r\n    throw CrashyClass.crash(\"Fatal Crash\");\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.BaseTestDescribeSurf.features_increasing",
	"Comment": "create an image which has a constant slope.the features aligned along that\tdirection should be large.this also checks that the orientation parameter\tis being used correctly and that absolute value is being done.",
	"Method": "void features_increasing(){\r\n    TestImplSurfDescribeOps.createGradient(0, input);\r\n    GIntegralImageOps.transform(input, ii);\r\n    sparse = TestImplSurfDescribeOps.createGradient(ii, 1);\r\n    alg.setImage(ii);\r\n    BrightFeature feat = alg.createDescription();\r\n    alg.describe(15, 15, 0, 1, feat);\r\n    for (int i = 0; i < 64; i += 4) {\r\n        assertEquals(feat.value[i], feat.value[i + 1], 1e-4);\r\n        assertTrue(feat.value[i] > 0);\r\n        assertEquals(0, feat.value[i + 2], 1e-4);\r\n        assertEquals(0, feat.value[i + 3], 1e-4);\r\n    }\r\n    alg.describe(15, 15, Math.PI / 2.0, 1, feat);\r\n    for (int i = 0; i < 64; i += 4) {\r\n        assertEquals(-feat.value[i + 2], feat.value[i + 3], 1e-4);\r\n        assertTrue(feat.value[i + 2] < 0);\r\n        assertEquals(0, feat.value[i], 1e-4);\r\n        assertEquals(0, feat.value[i + 1], 1e-4);\r\n    }\r\n}"
}, {
	"Path": "org.bytedeco.copiedstuff.Frame.cloneBufferArray",
	"Comment": "this private method takes a buffer array as input and returns a deep copy.it is assumed that all buffers in the input array are of the same subclass.",
	"Method": "Buffer[] cloneBufferArray(Buffer[] srcBuffers){\r\n    Buffer[] clonedBuffers = null;\r\n    int i;\r\n    short dataSize;\r\n    if (srcBuffers != null) {\r\n        clonedBuffers = new Buffer[srcBuffers.length];\r\n        for (i = 0; i < srcBuffers.length; i++) srcBuffers[i].rewind();\r\n        if (srcBuffers[0] instanceof ByteBuffer)\r\n            for (i = 0; i < srcBuffers.length; i++) clonedBuffers[i] = ByteBuffer.allocateDirect(srcBuffers[i].capacity()).put((ByteBuffer) srcBuffers[i]).rewind();\r\n        else if (srcBuffers[0] instanceof ShortBuffer) {\r\n            dataSize = Short.SIZE >> 3;\r\n            for (i = 0; i < srcBuffers.length; i++) clonedBuffers[i] = ByteBuffer.allocateDirect(srcBuffers[i].capacity() * dataSize).order(ByteOrder.nativeOrder()).asShortBuffer().put((ShortBuffer) srcBuffers[i]).rewind();\r\n        } else if (srcBuffers[0] instanceof IntBuffer) {\r\n            dataSize = Integer.SIZE >> 3;\r\n            for (i = 0; i < srcBuffers.length; i++) clonedBuffers[i] = ByteBuffer.allocateDirect(srcBuffers[i].capacity() * dataSize).order(ByteOrder.nativeOrder()).asIntBuffer().put((IntBuffer) srcBuffers[i]).rewind();\r\n        } else if (srcBuffers[0] instanceof LongBuffer) {\r\n            dataSize = Long.SIZE >> 3;\r\n            for (i = 0; i < srcBuffers.length; i++) clonedBuffers[i] = ByteBuffer.allocateDirect(srcBuffers[i].capacity() * dataSize).order(ByteOrder.nativeOrder()).asLongBuffer().put((LongBuffer) srcBuffers[i]).rewind();\r\n        } else if (srcBuffers[0] instanceof FloatBuffer) {\r\n            dataSize = Float.SIZE >> 3;\r\n            for (i = 0; i < srcBuffers.length; i++) clonedBuffers[i] = ByteBuffer.allocateDirect(srcBuffers[i].capacity() * dataSize).order(ByteOrder.nativeOrder()).asFloatBuffer().put((FloatBuffer) srcBuffers[i]).rewind();\r\n        } else if (srcBuffers[0] instanceof DoubleBuffer) {\r\n            dataSize = Double.SIZE >> 3;\r\n            for (i = 0; i < srcBuffers.length; i++) clonedBuffers[i] = ByteBuffer.allocateDirect(srcBuffers[i].capacity() * dataSize).order(ByteOrder.nativeOrder()).asDoubleBuffer().put((DoubleBuffer) srcBuffers[i]).rewind();\r\n        }\r\n        for (i = 0; i < srcBuffers.length; i++) srcBuffers[i].rewind();\r\n    }\r\n    return clonedBuffers;\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.impl.GeneralChecksInterpolationPixelMB.checkPixelValueBoundsHonored",
	"Comment": "interpolates the whole image and sees if the values returned are within the specified bounds",
	"Method": "void checkPixelValueBoundsHonored(){\r\n    T img = createImage(20, 30, numBands);\r\n    GImageMiscOps.fillUniform(img, rand, 0, 100);\r\n    InterpolatePixelMB<T> interp = wrap(img, 0, 100);\r\n    interp.setBorder((ImageBorder) FactoryImageBorder.interleavedValue((ImageInterleaved) img, 0));\r\n    for (int off = 0; off < 5; off++) {\r\n        float frac = off / 5.0f;\r\n        for (int y = 0; y < img.height; y++) {\r\n            for (int x = 0; x < img.width; x++) {\r\n                interp.get(x + frac, y + frac, tmp0);\r\n                for (int i = 0; i < numBands; i++) {\r\n                    assertTrue(tmp0[i] >= 0 && tmp0[i] <= 100);\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.slic.SegmentSlic.computeClusterDistance",
	"Comment": "computes how far away each cluster is from each pixel.expectation step.",
	"Method": "void computeClusterDistance(){\r\n    for (int i = 0; i < pixels.size; i++) {\r\n        pixels.data[i].reset();\r\n    }\r\n    for (int i = 0; i < clusters.size && !stopRequested; i++) {\r\n        Cluster c = clusters.data[i];\r\n        int centerX = (int) (c.x + 0.5f);\r\n        int centerY = (int) (c.y + 0.5f);\r\n        int x0 = centerX - gridInterval;\r\n        int x1 = centerX + gridInterval + 1;\r\n        int y0 = centerY - gridInterval;\r\n        int y1 = centerY + gridInterval + 1;\r\n        if (x0 < 0)\r\n            x0 = 0;\r\n        if (y0 < 0)\r\n            y0 = 0;\r\n        if (x1 > input.width)\r\n            x1 = input.width;\r\n        if (y1 > input.height)\r\n            y1 = input.height;\r\n        for (int y = y0; y < y1; y++) {\r\n            int indexPixel = y * input.width + x0;\r\n            int indexInput = input.startIndex + y * input.stride + x0;\r\n            int dy = y - centerY;\r\n            for (int x = x0; x < x1; x++) {\r\n                int dx = x - centerX;\r\n                float distanceColor = colorDistance(c.color, indexInput++);\r\n                float distanceSpacial = dx * dx + dy * dy;\r\n                pixels.data[indexPixel++].add(c, distanceColor + adjustSpacial * distanceSpacial);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquaresIntoRegularClusters.process",
	"Comment": "processes the unordered set of squares and creates a graph out of them using prior knowledge and geometric\tconstraints.",
	"Method": "List<List<SquareNode>> process(List<Polygon2D_F64> squares){\r\n    recycleData();\r\n    computeNodeInfo(squares);\r\n    connectNodes();\r\n    disconnectSingleConnections();\r\n    findClusters();\r\n    return clusters.toList();\r\n}"
}, {
	"Path": "org.boon.primitive.Int.add",
	"Comment": "adds an int to the array. grows the array by one and adds the int to the end.",
	"Method": "int[] add(int[] array,int v,int[] add,int[] array,int[] array2){\r\n    int[] newArray = new int[array.length + array2.length];\r\n    System.arraycopy(array, 0, newArray, 0, array.length);\r\n    System.arraycopy(array2, 0, newArray, array.length, array2.length);\r\n    return newArray;\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.EquirectangularDistortBase_F32.declareVectors",
	"Comment": "declares storage for precomputed pointing vectors to output image",
	"Method": "void declareVectors(int width,int height){\r\n    this.outWidth = width;\r\n    if (vectors.length < width * height) {\r\n        Point3D_F32[] tmp = new Point3D_F32[width * height];\r\n        System.arraycopy(vectors, 0, tmp, 0, vectors.length);\r\n        for (int i = vectors.length; i < tmp.length; i++) {\r\n            tmp[i] = new Point3D_F32();\r\n        }\r\n        vectors = tmp;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.DetectFiducialSquareBinary.thresholdBinaryNumber",
	"Comment": "sees how many pixels were positive and negative in each square region.then decides if they\tshould be 0 or 1 or unknown",
	"Method": "boolean thresholdBinaryNumber(){\r\n    int lower = (int) (N * (ambiguityThreshold / 2.0));\r\n    int upper = (int) (N * (1 - ambiguityThreshold / 2.0));\r\n    final int totalElements = getTotalGridElements();\r\n    for (int i = 0; i < totalElements; i++) {\r\n        if (counts[i] < lower) {\r\n            classified[i] = 0;\r\n        } else if (counts[i] > upper) {\r\n            classified[i] = 1;\r\n        } else {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.testing.BoofTesting.callStaticMethod",
	"Comment": "looks up the static method then passes in the specified inputs.",
	"Method": "void callStaticMethod(Class<?> classType,String name,Object inputs){\r\n    Class<?>[] params = new Class[inputs.length];\r\n    for (int i = 0; i < inputs.length; i++) {\r\n        params[i] = inputs[i].getClass();\r\n    }\r\n    Method m = findMethod(classType, name, params);\r\n    if (m == null) {\r\n        for (int i = 0; i < inputs.length; i++) {\r\n            if (params[i] == Integer.class) {\r\n                params[i] = int.class;\r\n            } else if (params[i] == Float.class) {\r\n                params[i] = float.class;\r\n            } else if (params[i] == Double.class) {\r\n                params[i] = double.class;\r\n            }\r\n        }\r\n        m = findMethod(classType, name, params);\r\n    }\r\n    if (m == null)\r\n        throw new IllegalArgumentException(\"Method not found\");\r\n    try {\r\n        m.invoke(null, inputs);\r\n    } catch (IllegalAccessException | InvocationTargetException e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.ClusterLabeledImage.connectInner",
	"Comment": "examines pixels inside the image without the need for bounds checking",
	"Method": "void connectInner(GrayS32 input,GrayS32 output){\r\n    int startX = connectRule == ConnectRule.EIGHT ? 1 : 0;\r\n    for (int y = 0; y < input.height - 1; y++) {\r\n        int indexIn = input.startIndex + y * input.stride + startX;\r\n        int indexOut = output.startIndex + y * output.stride + startX;\r\n        for (int x = startX; x < input.width - 1; x++, indexIn++, indexOut++) {\r\n            int inputLabel = input.data[indexIn];\r\n            int outputLabel = output.data[indexOut];\r\n            if (outputLabel == -1) {\r\n                output.data[indexOut] = outputLabel = regionMemberCount.size;\r\n                regionMemberCount.add(1);\r\n                mergeList.add(outputLabel);\r\n            }\r\n            for (int i = 0; i < edgesIn.length; i++) {\r\n                if (inputLabel == input.data[indexIn + edgesIn[i]]) {\r\n                    int outputAdj = output.data[indexOut + edgesOut[i]];\r\n                    if (outputAdj == -1) {\r\n                        regionMemberCount.data[outputLabel]++;\r\n                        output.data[indexOut + edgesOut[i]] = outputLabel;\r\n                    } else if (outputLabel != outputAdj) {\r\n                        markMerge(outputLabel, outputAdj);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.shape.FactoryPointsToPolyline.create",
	"Comment": "generic function for create polyline algorithms based on configuration type",
	"Method": "PointsToPolyline create(ConfigPolyline config){\r\n    if (config instanceof ConfigSplitMergeLineFit) {\r\n        return splitMerge((ConfigSplitMergeLineFit) config);\r\n    } else if (config instanceof ConfigPolylineSplitMerge) {\r\n        return splitMerge((ConfigPolylineSplitMerge) config);\r\n    } else {\r\n        throw new RuntimeException(\"Unknown\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoPlaneInfinity.changeCurrToReference",
	"Comment": "updates the relative position of all points so that the current frame is the reference frame.mathematically\tthis is not needed, but should help keep numbers from getting too large.",
	"Method": "void changeCurrToReference(){\r\n    Se2_F64 keyToCurr = currToKey.invert(null);\r\n    List<PointTrack> all = tracker.getAllTracks(null);\r\n    for (PointTrack t : all) {\r\n        VoTrack p = t.getCookie();\r\n        if (p.onPlane) {\r\n            SePointOps_F64.transform(keyToCurr, p.ground, p.ground);\r\n        } else {\r\n            GeometryMath_F64.rotate(keyToCurr.c, keyToCurr.s, p.ground, p.ground);\r\n        }\r\n    }\r\n    concatMotion();\r\n}"
}, {
	"Path": "boofcv.alg.transform.pyramid.TestPyramidFloatGaussianScale.checkSigmas",
	"Comment": "makes sure the amount of gaussian blur in each level is correctly computed.test against hand computed\tnumbers",
	"Method": "void checkSigmas(){\r\n    InterpolatePixelS<GrayF32> interp = FactoryInterpolation.bilinearPixelS(GrayF32.class, BorderType.EXTENDED);\r\n    double[] scales = new double[] { 1, 1 };\r\n    PyramidFloatGaussianScale<GrayF32> alg = new PyramidFloatGaussianScale(interp, scales, sigmas, imageType);\r\n    assertEquals(1, alg.getSigma(0), 1e-6);\r\n    assertEquals(2.23606797749979, alg.getSigma(1), 0.001);\r\n    scales = new double[] { 2, 3 };\r\n    alg = new PyramidFloatGaussianScale(interp, scales, sigmas, imageType);\r\n    assertEquals(1, alg.getSigma(0), 1e-6);\r\n    assertEquals(4.123105625617661, alg.getSigma(1), 0.001);\r\n}"
}, {
	"Path": "boofcv.alg.distort.mls.ImageDeformPointMLS_F32.interpolateDeformedPoint",
	"Comment": "samples the 4 grid points around v and performs bilinear interpolation",
	"Method": "void interpolateDeformedPoint(float v_x,float v_y,Point2D_F32 deformed){\r\n    int x0 = (int) v_x;\r\n    int y0 = (int) v_y;\r\n    int x1 = x0 + 1;\r\n    int y1 = y0 + 1;\r\n    if (x1 >= gridCols)\r\n        x1 = gridCols - 1;\r\n    if (y1 >= gridRows)\r\n        y1 = gridRows - 1;\r\n    float ax = v_x - x0;\r\n    float ay = v_y - y0;\r\n    float w00 = (1.0f - ax) * (1.0f - ay);\r\n    float w01 = ax * (1.0f - ay);\r\n    float w11 = ax * ay;\r\n    float w10 = (1.0f - ax) * ay;\r\n    Point2D_F32 d00 = getGrid(y0, x0).deformed;\r\n    Point2D_F32 d01 = getGrid(y0, x1).deformed;\r\n    Point2D_F32 d10 = getGrid(y1, x0).deformed;\r\n    Point2D_F32 d11 = getGrid(y1, x1).deformed;\r\n    deformed.set(0, 0);\r\n    deformed.x += w00 * d00.x;\r\n    deformed.x += w01 * d01.x;\r\n    deformed.x += w11 * d11.x;\r\n    deformed.x += w10 * d10.x;\r\n    deformed.y += w00 * d00.y;\r\n    deformed.y += w01 * d01.y;\r\n    deformed.y += w11 * d11.y;\r\n    deformed.y += w10 * d10.y;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.TestSplitMergeLineFitSegment.selectSplitBetween_minimumSideLengthPixel",
	"Comment": "makes sure the selectsplitoffset is obeying the minimumsidelengthpixel parameter",
	"Method": "void selectSplitBetween_minimumSideLengthPixel(){\r\n    SplitMergeLineFitSegment alg = new SplitMergeLineFitSegment(0.001, MIN_SPLIT, 100);\r\n    alg.contour = new ArrayList();\r\n    for (int i = 0; i < 20; i++) {\r\n        alg.contour.add(new Point2D_I32(i, 0));\r\n    }\r\n    alg.contour.get(10).set(10, 10);\r\n    alg.minimumSideLengthPixel = 0;\r\n    assertEquals(10, alg.selectSplitBetween(0, 19));\r\n    int r = 0;\r\n    assertEquals(10, alg.selectSplitBetween(10 - r - 1, 10 + r + 1));\r\n    assertEquals(-1, alg.selectSplitBetween(10 - r, 10 + r + 1));\r\n    assertEquals(-1, alg.selectSplitBetween(10 - r - 1, 10 + r));\r\n    alg.minimumSideLengthPixel = 2;\r\n    r = 1;\r\n    assertEquals(10, alg.selectSplitBetween(10 - r - 1, 10 + r + 1));\r\n    assertEquals(-1, alg.selectSplitBetween(10 - r, 10 + r + 1));\r\n    assertEquals(-1, alg.selectSplitBetween(10 - r - 1, 10 + r));\r\n}"
}, {
	"Path": "org.boon.slumberdb.stores.log.CollectorManager.allocateBuffer",
	"Comment": "this gets called from the http post handleror event bus handler.",
	"Method": "ByteBuffer allocateBuffer(int size){\r\n    if (RECYCLE_BUFFER) {\r\n        ByteBuffer spentBuffer = recycleChannel.poll();\r\n        if (spentBuffer == null) {\r\n            spentBuffer = ByteBuffer.allocateDirect(size);\r\n        }\r\n        spentBuffer.clear();\r\n        return spentBuffer;\r\n    } else {\r\n        return ByteBuffer.allocateDirect(size);\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionThreadTester.testCloseConnectionWithException",
	"Comment": "should close off the connection by returning the connection to pool.",
	"Method": "void testCloseConnectionWithException(){\r\n    this.testClass = new ConnectionTesterThread(mockConnectionPartition, mockExecutor, mockPool, 123, 123, false);\r\n    expect(mockConnection.isClosed()).andReturn(false);\r\n    mockConnection.internalClose();\r\n    expectLastCall().andThrow(new SQLException());\r\n    ConnectionPartition mockPartition = EasyMock.createNiceMock(ConnectionPartition.class);\r\n    BlockingQueue<Object> mockQueue = EasyMock.createNiceMock(BlockingQueue.class);\r\n    expect(mockConnection.getOriginatingPartition()).andReturn(mockPartition);\r\n    expect(mockPartition.getPoolWatchThreadSignalQueue()).andReturn(mockQueue);\r\n    expect(mockQueue.offer(anyObject())).andReturn(true).anyTimes();\r\n    mockPool.postDestroyConnection(mockConnection);\r\n    replay(mockConnection, mockPool, mockQueue, mockPartition);\r\n    this.testClass.closeConnection(mockConnection);\r\n    verify(mockPool, mockConnection, mockQueue);\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.GenericPlanarCalibrationDetectorChecks.dataNotRecycled",
	"Comment": "make sure new instances of calibration points are returned each time",
	"Method": "void dataNotRecycled(){\r\n    for (Object layout : targetConfigs) {\r\n        DetectorFiducialCalibration detector = createDetector(layout);\r\n        GrayF32 original = renderEasy(layout, null);\r\n        assertTrue(detector.process(original));\r\n        CalibrationObservation found0 = detector.getDetectedPoints();\r\n        assertTrue(detector.process(original));\r\n        CalibrationObservation found1 = detector.getDetectedPoints();\r\n        assertEquals(found0.size(), found1.size());\r\n        assertTrue(found0 != found1);\r\n        for (int i = 0; i < found0.size(); i++) {\r\n            PointIndex2D_F64 p0 = found0.get(i);\r\n            for (int j = 0; j < found1.size(); j++) {\r\n                PointIndex2D_F64 p1 = found1.get(j);\r\n                assertFalse(p0 == p1);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.core.image.TestConvertImage.selectTolerance",
	"Comment": "if the two images are both int or float then set a low tolerance, otherwise set the tolerance to one pixel",
	"Method": "double selectTolerance(ImageGray a,ImageGray b,double selectTolerance,ImageInterleaved a,ImageInterleaved b){\r\n    if (a.getDataType().isInteger() == b.getDataType().isInteger())\r\n        return 1e-4;\r\n    else\r\n        return 1;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.TestQrCodePolynomialMath.bitPolyDivide",
	"Comment": "test against an example from the qr code reference manual for format information",
	"Method": "void bitPolyDivide(){\r\n    int message = 0b00101 << 10;\r\n    int divisor = 0b10100110111;\r\n    int found = QrCodePolynomialMath.bitPolyModulus(message, divisor, 15, 5);\r\n    int expected = 0b0011011100;\r\n    assertEquals(expected, found);\r\n}"
}, {
	"Path": "boofcv.alg.geo.h.HomographyInducedStereo2Line.process",
	"Comment": "computes the homography based on two unique lines on the plane",
	"Method": "boolean process(PairLineNorm line0,PairLineNorm line1){\r\n    double a0 = GeometryMath_F64.dot(e2, line0.l2);\r\n    double a1 = GeometryMath_F64.dot(e2, line1.l2);\r\n    GeometryMath_F64.multTran(A, line0.l2, Al0);\r\n    GeometryMath_F64.multTran(A, line1.l2, Al1);\r\n    planeA.set(line0.l1.x, line0.l1.y, line0.l1.z, 0);\r\n    planeB.set(Al0.x, Al0.y, Al0.z, a0);\r\n    if (!Intersection3D_F64.intersect(planeA, planeB, intersect0))\r\n        return false;\r\n    intersect0.slope.normalize();\r\n    planeA.set(line1.l1.x, line1.l1.y, line1.l1.z, 0);\r\n    planeB.set(Al1.x, Al1.y, Al1.z, a1);\r\n    if (!Intersection3D_F64.intersect(planeA, planeB, intersect1))\r\n        return false;\r\n    intersect1.slope.normalize();\r\n    from0to1.x = intersect1.p.x - intersect0.p.x;\r\n    from0to1.y = intersect1.p.y - intersect0.p.y;\r\n    from0to1.z = intersect1.p.z - intersect0.p.z;\r\n    GeometryMath_F64.cross(intersect0.slope, from0to1, pi.n);\r\n    pi.p.set(intersect0.p);\r\n    UtilPlane3D_F64.convert(pi, pi_gen);\r\n    v.set(pi_gen.A / pi_gen.D, pi_gen.B / pi_gen.D, pi_gen.C / pi_gen.D);\r\n    GeometryMath_F64.outerProd(e2, v, av);\r\n    CommonOps_DDRM.subtract(A, av, H);\r\n    adjust.adjust(H, line0);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareGridTools.orderNodeGrid",
	"Comment": "given the grid coordinate, order the corners for the node at that location.takes in handles situations\twhere there are no neighbors.",
	"Method": "void orderNodeGrid(SquareGrid grid,int row,int col){\r\n    SquareNode node = grid.get(row, col);\r\n    if (grid.rows == 1 && grid.columns == 1) {\r\n        for (int i = 0; i < 4; i++) {\r\n            ordered[i] = node.square.get(i);\r\n        }\r\n    } else if (grid.columns == 1) {\r\n        if (row == grid.rows - 1) {\r\n            orderNode(node, grid.get(row - 1, col), false);\r\n            rotateTwiceOrdered();\r\n        } else {\r\n            orderNode(node, grid.get(row + 1, col), false);\r\n        }\r\n    } else {\r\n        if (col == grid.columns - 1) {\r\n            orderNode(node, grid.get(row, col - 1), true);\r\n            rotateTwiceOrdered();\r\n        } else {\r\n            orderNode(node, grid.get(row, col + 1), true);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareCrossClustersIntoGrids.lowerEdgeIndex",
	"Comment": "returns the open corner index which is first.assuming that there are two adjacent corners.",
	"Method": "int lowerEdgeIndex(SquareNode node){\r\n    for (int i = 0; i < node.square.size(); i++) {\r\n        if (isOpenEdge(node, i)) {\r\n            int next = addOffset(i, 1, node.square.size());\r\n            if (isOpenEdge(node, next)) {\r\n                return i;\r\n            }\r\n            if (i == 0) {\r\n                int previous = node.square.size() - 1;\r\n                if (isOpenEdge(node, previous)) {\r\n                    return previous;\r\n                }\r\n            }\r\n            return i;\r\n        }\r\n    }\r\n    throw new RuntimeException(\"BUG!\");\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.SurfDescribeOps.createGradient",
	"Comment": "creates a class for computing the image gradient from an integral image in a sparse fashion.\tall these kernels assume that the kernel is entirely contained inside the image!",
	"Method": "SparseScaleGradient<T, ?> createGradient(boolean useHaar,Class<T> imageType){\r\n    if (useHaar)\r\n        return FactorySparseIntegralFilters.haar(imageType);\r\n    else\r\n        return FactorySparseIntegralFilters.gradient(imageType);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.SnapToEllipseEdge.change",
	"Comment": "computes a numerical value for the difference in parameters between the two ellipses",
	"Method": "double change(EllipseRotated_F64 a,EllipseRotated_F64 b){\r\n    double total = 0;\r\n    total += Math.abs(a.center.x - b.center.x);\r\n    total += Math.abs(a.center.y - b.center.y);\r\n    total += Math.abs(a.a - b.a);\r\n    total += Math.abs(a.b - b.b);\r\n    double weight = Math.min(4, 2.0 * (a.a / a.b - 1.0));\r\n    total += weight * UtilAngle.distHalf(a.phi, b.phi);\r\n    return total;\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.getPersistUserBetweenSessions",
	"Comment": "get whether or not bugsnag should persist user information between application settings",
	"Method": "boolean getPersistUserBetweenSessions(){\r\n    return persistUserBetweenSessions;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.template.TestTemplateMatching.basicTest_NOBORDER",
	"Comment": "basic detection task with an extraction algorithm that has no border",
	"Method": "void basicTest_NOBORDER(){\r\n    expected = new ArrayList();\r\n    expected.add(new Match(10, 11, 15));\r\n    expected.add(new Match(17, 15, 18));\r\n    expected.add(new Match(0, 0, 18));\r\n    DummyIntensity intensity = new DummyIntensity(false, 4, 5);\r\n    TemplateMatching alg = new TemplateMatching(intensity);\r\n    alg.setImage(input);\r\n    alg.setTemplate(template, null, 10);\r\n    alg.process();\r\n    expected.remove(2);\r\n    checkResults(alg.getResults().toList(), expected, 4, 5);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.StatementHandle.setOpenStackTrace",
	"Comment": "sets the stack trace where this statement was first opened.",
	"Method": "void setOpenStackTrace(String openStackTrace){\r\n    this.openStackTrace = openStackTrace;\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.TestGThresholdImageOps.computeOtsu_zeros",
	"Comment": "check to see if it handles zeros and the start and end of the histogram correctly.",
	"Method": "void computeOtsu_zeros(){\r\n    int[] histogram = new int[256];\r\n    int total = 0;\r\n    for (int j = 15; j < histogram.length - 40; j++) {\r\n        total += histogram[j] = rand.nextInt(400);\r\n    }\r\n    int best = bruteForceOtsu(histogram, total);\r\n    int found = GThresholdImageOps.computeOtsu(histogram, histogram.length, total);\r\n    assertEquals(best, found);\r\n}"
}, {
	"Path": "org.boon.core.reflection.AnnotationData.isAllowed",
	"Comment": "determines if this is an annotation we care about.checks to see if the package name is in the set.",
	"Method": "boolean isAllowed(){\r\n    if (allowedAnnotations == null || allowedAnnotations.size() == 0)\r\n        return true;\r\n    return allowedAnnotations.contains(annotationPackageName);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.StatementHandle.getOpenStackTrace",
	"Comment": "returns the stack trace where this statement was first opened.",
	"Method": "String getOpenStackTrace(){\r\n    return this.openStackTrace;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.removeCornerAndSavePolyline",
	"Comment": "remove the corner from the current polyline. if the new polyline has a better score than the currently\tsaved one with the same number of corners save it",
	"Method": "boolean removeCornerAndSavePolyline(Element<Corner> corner,double sideErrorAfterRemoved){\r\n    Element<Corner> p = previous(corner);\r\n    p.object.sideError = sideErrorAfterRemoved;\r\n    list.remove(corner);\r\n    return savePolyline();\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.ConnectLinesGrid.connectToNeighbors",
	"Comment": "connect lines in the target region to lines in neighboring regions.regions are selected such that\tno two regions are compared against each other more than once.",
	"Method": "void connectToNeighbors(int x,int y){\r\n    List<LineSegment2D_F32> lines = grid.get(x, y);\r\n    Iterator<LineSegment2D_F32> iter = lines.iterator();\r\n    while (iter.hasNext()) {\r\n        LineSegment2D_F32 l = iter.next();\r\n        boolean connected = false;\r\n        if (connectTry(l, x + 1, y))\r\n            connected = true;\r\n        if (!connected && connectTry(l, x + 1, y + 1))\r\n            connected = true;\r\n        if (!connected && connectTry(l, x, y + 1))\r\n            connected = true;\r\n        if (!connected && connectTry(l, x - 1, y + 1))\r\n            connected = true;\r\n        if (connected)\r\n            iter.remove();\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.ExceptionHandlerTest.setUp",
	"Comment": "sets the default exception handler to null to avoid any bugsnag handlers createdin previous test",
	"Method": "void setUp(){\r\n    context = InstrumentationRegistry.getContext();\r\n    Thread.setDefaultUncaughtExceptionHandler(null);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomDualTrackPnP.selectCandidateTracks",
	"Comment": "searches for tracks which are active and meet the epipolar constraints",
	"Method": "void selectCandidateTracks(){\r\n    List<PointTrack> activeRight = trackerRight.getActiveTracks(null);\r\n    for (PointTrack t : activeRight) {\r\n        RightTrackInfo info = t.getCookie();\r\n        info.lastActiveList = tick;\r\n    }\r\n    int mutualActive = 0;\r\n    List<PointTrack> activeLeft = trackerLeft.getActiveTracks(null);\r\n    candidates.clear();\r\n    for (PointTrack left : activeLeft) {\r\n        LeftTrackInfo info = left.getCookie();\r\n        RightTrackInfo infoRight = info.right.getCookie();\r\n        if (infoRight.lastActiveList != tick) {\r\n            continue;\r\n        }\r\n        if (stereoCheck.checkPixel(left, info.right)) {\r\n            info.lastConsistent = tick;\r\n            candidates.add(left);\r\n        }\r\n        mutualActive++;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeGenerator.render",
	"Comment": "generates a qr code with the specified message. an exception is thrown if the message is\ttoo long to be encoded.",
	"Method": "void render(QrCode qr){\r\n    initialize(qr);\r\n    render.init();\r\n    positionPattern(0, 0, qr.ppCorner);\r\n    positionPattern((numModules - 7) * moduleWidth, 0, qr.ppRight);\r\n    positionPattern(0, (numModules - 7) * moduleWidth, qr.ppDown);\r\n    timingPattern(7 * moduleWidth, 6 * moduleWidth, moduleWidth, 0);\r\n    timingPattern(6 * moduleWidth, 7 * moduleWidth, 0, moduleWidth);\r\n    formatInformation();\r\n    if (qr.version >= QrCode.VERSION_ENCODED_AT)\r\n        versionInformation();\r\n    int[] alignment = QrCode.VERSION_INFO[qr.version].alignment;\r\n    for (int i = 0; i < alignment.length; i++) {\r\n        int row = alignment[i];\r\n        for (int j = 0; j < alignment.length; j++) {\r\n            if (i == 0 & j == 0)\r\n                continue;\r\n            if (i == alignment.length - 1 & j == 0)\r\n                continue;\r\n            if (i == alignment.length - 1 & j == alignment.length - 1)\r\n                continue;\r\n            int col = alignment[j];\r\n            alignmentPattern(col, numModules - row - 1);\r\n        }\r\n    }\r\n    if (renderData) {\r\n        if (qr.rawbits.length != QrCode.VERSION_INFO[qr.version].codewords)\r\n            throw new RuntimeException(\"Unexpected length of raw data.\");\r\n        bitLocations = new QrCodeCodeWordLocations(qr.version).bits;\r\n        int numBytes = bitLocations.size() / 8;\r\n        if (numBytes != qr.rawbits.length)\r\n            throw new RuntimeException(\"Egads. unexpected length of qrcode raw data\");\r\n        renderData();\r\n    }\r\n    qr.bounds.set(0, 0, 0);\r\n    qr.bounds.set(1, markerWidth, 0);\r\n    qr.bounds.set(2, markerWidth, markerWidth);\r\n    qr.bounds.set(3, 0, markerWidth);\r\n}"
}, {
	"Path": "org.boon.cache.SimpleConcurrentCache.size",
	"Comment": "get the size of the cache. this is not 100% accurate if cache is being concurrenly accessed.",
	"Method": "int size(int size){\r\n    int size = 0;\r\n    for (SimpleCache<K, V> cache : cacheRegions) {\r\n        size += cache.size();\r\n    }\r\n    return size;\r\n}"
}, {
	"Path": "org.boon.sort.Sort.childComparators",
	"Comment": "this creates a list of children comparators based on the child list.",
	"Method": "List<Comparator> childComparators(Map<String, FieldAccess> fields){\r\n    if (this.comparators == null) {\r\n        this.comparators = new ArrayList(this.sorts.size() + 1);\r\n        for (Sort sort : sorts) {\r\n            Comparator comparator = universalComparator(sort.getName(), fields, sort.getType(), sort.childComparators(fields));\r\n            this.comparators.add(comparator);\r\n        }\r\n    }\r\n    return this.comparators;\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.Zhang99CalibrationMatrixFromHomographies.computeParam_ZeroSkew",
	"Comment": "compute the calibration parameters from the b matrix when the skew is assumed to be zero",
	"Method": "void computeParam_ZeroSkew(){\r\n    CommonOps_DDRM.divide(b, CommonOps_DDRM.elementMaxAbs(b));\r\n    double B11 = b.get(0, 0);\r\n    double B22 = b.get(1, 0);\r\n    double B13 = b.get(2, 0);\r\n    double B23 = b.get(3, 0);\r\n    double B33 = b.get(4, 0);\r\n    double temp0 = -B11 * B23;\r\n    double temp1 = B11 * B22;\r\n    double v0 = temp0 / temp1;\r\n    double lambda = B33 - (B13 * B13 + v0 * temp0) / B11;\r\n    double a = Math.sqrt(Math.abs(lambda / B11));\r\n    double b = Math.sqrt(Math.abs(lambda * B11 / temp1));\r\n    double u0 = -B13 / B11;\r\n    K.set(0, 0, a);\r\n    K.set(0, 1, 0);\r\n    K.set(0, 2, u0);\r\n    K.set(1, 1, b);\r\n    K.set(1, 2, v0);\r\n    K.set(2, 2, 1);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.TestReidSolomonCodes.correct_random",
	"Comment": "randomly correct the message and ecc. see if the message is correctly reconstructed.",
	"Method": "void correct_random(){\r\n    GrowQueue_I8 ecc = new GrowQueue_I8();\r\n    int nsyn = 10;\r\n    ReidSolomonCodes alg = new ReidSolomonCodes(8, primitive8);\r\n    alg.generator(nsyn);\r\n    for (int i = 0; i < 20000; i++) {\r\n        GrowQueue_I8 message = randomMessage(100);\r\n        GrowQueue_I8 corrupted = message.copy();\r\n        alg.computeECC(message, ecc);\r\n        int numErrors = rand.nextInt(6);\r\n        for (int j = 0; j < numErrors; j++) {\r\n            int selected = rand.nextInt(message.size);\r\n            corrupted.data[selected] ^= (0x12 + j);\r\n        }\r\n        if (numErrors < 5 && rand.nextInt(5) < 1) {\r\n            numErrors++;\r\n            ecc.data[rand.nextInt(ecc.size)] ^= 0x13;\r\n        }\r\n        alg.correct(corrupted, ecc);\r\n        assertEquals(corrupted.size, message.size);\r\n        for (int j = 0; j < corrupted.size; j++) {\r\n            assertEquals(corrupted.get(j), message.get(j));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldDetection.detectionCascade",
	"Comment": "detects the object inside the image.eliminates candidate regions using a cascade of tests",
	"Method": "void detectionCascade(FastQueue<ImageRectangle> cascadeRegions){\r\n    success = false;\r\n    ambiguous = false;\r\n    best = null;\r\n    candidateDetections.reset();\r\n    localMaximums.reset();\r\n    ambiguousRegions.clear();\r\n    storageMetric.reset();\r\n    storageIndexes.reset();\r\n    storageRect.clear();\r\n    fernRegions.clear();\r\n    fernInfo.reset();\r\n    int totalP = 0;\r\n    int totalN = 0;\r\n    TldRegionFernInfo info = fernInfo.grow();\r\n    for (int i = 0; i < cascadeRegions.size; i++) {\r\n        ImageRectangle region = cascadeRegions.get(i);\r\n        if (!variance.checkVariance(region)) {\r\n            continue;\r\n        }\r\n        info.r = region;\r\n        if (fern.lookupFernPN(info)) {\r\n            totalP += info.sumP;\r\n            totalN += info.sumN;\r\n            info = fernInfo.grow();\r\n        }\r\n    }\r\n    fernInfo.removeTail();\r\n    if (totalP > 0x0fffffff)\r\n        fern.renormalizeP();\r\n    if (totalN > 0x0fffffff)\r\n        fern.renormalizeN();\r\n    selectBestRegionsFern(totalP, totalN);\r\n    computeTemplateConfidence();\r\n    if (candidateDetections.size == 0) {\r\n        return;\r\n    }\r\n    nonmax.process(candidateDetections, localMaximums);\r\n    best = selectBest();\r\n    if (best != null) {\r\n        ambiguous = checkAmbiguous(best);\r\n        success = true;\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCP.isConnectionHandleAlive",
	"Comment": "sends a dummy statement to the server to keep the connection alive",
	"Method": "boolean isConnectionHandleAlive(ConnectionHandle connection){\r\n    Statement stmt = null;\r\n    boolean result = false;\r\n    boolean logicallyClosed = connection.logicallyClosed.get();\r\n    try {\r\n        connection.logicallyClosed.compareAndSet(true, false);\r\n        String testStatement = this.config.getConnectionTestStatement();\r\n        ResultSet rs = null;\r\n        if (testStatement == null) {\r\n            rs = connection.getMetaData().getTables(null, null, KEEPALIVEMETADATA, METADATATABLE);\r\n        } else {\r\n            stmt = connection.createStatement();\r\n            stmt.execute(testStatement);\r\n        }\r\n        if (rs != null) {\r\n            rs.close();\r\n        }\r\n        result = true;\r\n    } catch (SQLException e) {\r\n        result = false;\r\n    } finally {\r\n        connection.logicallyClosed.set(logicallyClosed);\r\n        connection.setConnectionLastResetInMs(System.currentTimeMillis());\r\n        result = closeStatement(stmt, result);\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "boofcv.examples.recognition.ExampleColorHistogramLookup.independentHueSat",
	"Comment": "computes two independent 1d histograms from hue and saturation.less affects by sparsity, but can produce\tworse results since the basic assumption that hue and saturation are decoupled is most of the time false.",
	"Method": "List<double[]> independentHueSat(List<File> images){\r\n    List<double[]> points = new ArrayList();\r\n    TupleDesc_F64 histogramHue = new TupleDesc_F64(30);\r\n    TupleDesc_F64 histogramValue = new TupleDesc_F64(30);\r\n    List<TupleDesc_F64> histogramList = new ArrayList();\r\n    histogramList.add(histogramHue);\r\n    histogramList.add(histogramValue);\r\n    Planar<GrayF32> rgb = new Planar(GrayF32.class, 1, 1, 3);\r\n    Planar<GrayF32> hsv = new Planar(GrayF32.class, 1, 1, 3);\r\n    for (File f : images) {\r\n        BufferedImage buffered = UtilImageIO.loadImage(f.getPath());\r\n        if (buffered == null)\r\n            throw new RuntimeException(\"Can't load image!\");\r\n        rgb.reshape(buffered.getWidth(), buffered.getHeight());\r\n        hsv.reshape(buffered.getWidth(), buffered.getHeight());\r\n        ConvertBufferedImage.convertFrom(buffered, rgb, true);\r\n        ColorHsv.rgbToHsv_F32(rgb, hsv);\r\n        GHistogramFeatureOps.histogram(hsv.getBand(0), 0, 2 * Math.PI, histogramHue);\r\n        GHistogramFeatureOps.histogram(hsv.getBand(1), 0, 1, histogramValue);\r\n        TupleDesc_F64 imageHist = UtilFeature.combine(histogramList, null);\r\n        UtilFeature.normalizeL2(imageHist);\r\n        points.add(imageHist.value);\r\n    }\r\n    return points;\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationLinearRotationSingle.ensureDeterminantOfOne",
	"Comment": "scales all homographies so that their determinants are equal to one",
	"Method": "void ensureDeterminantOfOne(List<Homography2D_F64> homography0toI){\r\n    int N = homography0toI.size();\r\n    for (int i = 0; i < N; i++) {\r\n        Homography2D_F64 H = homography0toI.get(i);\r\n        double d = CommonOps_DDF3.det(H);\r\n        if (d < 0)\r\n            CommonOps_DDF3.divide(H, -Math.pow(-d, 1.0 / 3));\r\n        else\r\n            CommonOps_DDF3.divide(H, Math.pow(d, 1.0 / 3));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.TestMergeSmallRegions.process",
	"Comment": "runs everything to remove the small patches. this test hsa been designed to take multiple\tpasses to complete.",
	"Method": "void process(){\r\n    GrayU8 image = new GrayU8(10, 9);\r\n    image.data = new byte[] { 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 7, 8, 0, 0, 0, 0, 0, 5, 6, 5, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 0, 0, 0, 7, 0, 0, 0, 5, 5, 4, 4, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 9, 6, 7 };\r\n    GrayS32 pixelToRegion = new GrayS32(10, 9);\r\n    pixelToRegion.data = new int[] { 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 4, 5, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 9, 0, 0, 0, 1, 1, 3, 3, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 0, 0, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 6, 6, 7, 8 };\r\n    GrowQueue_I32 memberCount = new GrowQueue_I32();\r\n    memberCount.resize(10);\r\n    for (int i = 0; i < pixelToRegion.data.length; i++) {\r\n        memberCount.data[pixelToRegion.data[i]]++;\r\n    }\r\n    FastQueue<float[]> regionColor = new FastQueue<float[]>(float[].class, true) {\r\n        protected float[] createInstance() {\r\n            return new float[1];\r\n        }\r\n    };\r\n    regionColor.resize(10);\r\n    ComputeRegionMeanColor<GrayU8> mean = new ComputeRegionMeanColor.U8();\r\n    mean.process(image, pixelToRegion, memberCount, regionColor);\r\n    MergeSmallRegions<GrayU8> alg = new MergeSmallRegions(3, ConnectRule.FOUR, mean);\r\n    alg.process(image, pixelToRegion, memberCount, regionColor);\r\n    assertEquals(3, memberCount.size);\r\n    assertEquals(3, regionColor.size);\r\n    GrowQueue_I32 memberExpected = new GrowQueue_I32(3);\r\n    memberExpected.resize(3);\r\n    for (int i = 0; i < pixelToRegion.data.length; i++) {\r\n        memberExpected.data[pixelToRegion.data[i]]++;\r\n    }\r\n    for (int i = 0; i < 3; i++) assertEquals(memberExpected.get(i), memberCount.get(i));\r\n    assertTrue(memberExpected.get(0) > memberExpected.get(1));\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.TestMergeSmallRegions.process",
	"Comment": "runs everything to remove the small patches. this test hsa been designed to take multiple\tpasses to complete.",
	"Method": "void process(){\r\n    return new float[1];\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomQuadPnP.associateL2R",
	"Comment": "associates image features from the left and right camera together while applying epipolar constraints.",
	"Method": "void associateL2R(T left,T right){\r\n    ImageInfo<TD> tmp = featsLeft1;\r\n    featsLeft1 = featsLeft0;\r\n    featsLeft0 = tmp;\r\n    tmp = featsRight1;\r\n    featsRight1 = featsRight0;\r\n    featsRight0 = tmp;\r\n    featsLeft1.reset();\r\n    featsRight1.reset();\r\n    describeImage(left, featsLeft1);\r\n    describeImage(right, featsRight1);\r\n    for (int i = 0; i < detector.getNumberOfSets(); i++) {\r\n        SetMatches matches = setMatches[i];\r\n        matches.swap();\r\n        matches.match2to3.reset();\r\n        FastQueue<Point2D_F64> leftLoc = featsLeft1.location[i];\r\n        FastQueue<Point2D_F64> rightLoc = featsRight1.location[i];\r\n        assocL2R.setSource(leftLoc, featsLeft1.description[i]);\r\n        assocL2R.setDestination(rightLoc, featsRight1.description[i]);\r\n        assocL2R.associate();\r\n        FastQueue<AssociatedIndex> found = assocL2R.getMatches();\r\n        setMatches(matches.match2to3, found, leftLoc.size);\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.ClientNotifyTest.setUp",
	"Comment": "generates a configuration and clears sharedprefs values to begin the test with a clean slate",
	"Method": "void setUp(){\r\n    client = BugsnagTestUtils.generateClient();\r\n    apiClient = new FakeClient();\r\n    client.setErrorReportApiClient(apiClient);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.FitLinesToContour.fitAnchored",
	"Comment": "fits line segments along the contour with the first and last corner fixed at the original corners.the output\twill be a new set of corner indexes.since the corner list is circular, it is assumed that anchor1 comes after\tanchor0.the same index can be specified for an anchor, it will just go around the entire circle",
	"Method": "boolean fitAnchored(int anchor0,int anchor1,GrowQueue_I32 corners,GrowQueue_I32 output){\r\n    this.anchor0 = anchor0;\r\n    this.anchor1 = anchor1;\r\n    int numLines = anchor0 == anchor1 ? corners.size() : CircularIndex.distanceP(anchor0, anchor1, corners.size);\r\n    if (numLines < 2) {\r\n        throw new RuntimeException(\"The one line is anchored and can't be optimized\");\r\n    }\r\n    lines.resize(numLines);\r\n    if (verbose)\r\n        System.out.println(\"ENTER FitLinesToContour\");\r\n    workCorners.setTo(corners);\r\n    for (int iteration = 0; iteration < maxIterations; iteration++) {\r\n        if (!fitLinesUsingCorners(numLines, workCorners)) {\r\n            return false;\r\n        }\r\n        if (!linesIntoCorners(numLines, workCorners)) {\r\n            return false;\r\n        }\r\n        if (!sanityCheckCornerOrder(numLines, workCorners)) {\r\n            return false;\r\n        }\r\n    }\r\n    if (verbose)\r\n        System.out.println(\"EXIT FitLinesToContour. \" + corners.size() + \"  \" + workCorners.size());\r\n    output.setTo(workCorners);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.TestEllipseClustersIntoGrid.checkLargestAngle",
	"Comment": "checks to see if the two nodes farthest apart is correctly found and the angle computed",
	"Method": "void checkLargestAngle(NodeInfo info,NodeInfo left,NodeInfo right){\r\n    assertTrue(info.left == left);\r\n    assertTrue(info.right == right);\r\n    if (left != null) {\r\n        double angle0 = Math.atan2(left.ellipse.center.y - info.ellipse.center.y, left.ellipse.center.x - info.ellipse.center.x);\r\n        double angle1 = Math.atan2(right.ellipse.center.y - info.ellipse.center.y, right.ellipse.center.x - info.ellipse.center.x);\r\n        double expected = UtilAngle.distanceCCW(angle0, angle1);\r\n        assertEquals(expected, info.angleBetween, GrlConstants.TEST_F64);\r\n    }\r\n}"
}, {
	"Path": "org.boon.primitive.Lng.reduceBy",
	"Comment": "a very fast reduce by.if performance is your thing, this seems to be as fast a plain for loop when benchmarking with jmh.",
	"Method": "long reduceBy(long[] array,ReduceBy reduceBy,long reduceBy,long[] array,int start,int length,ReduceBy reduceBy,long reduceBy,long[] array,int length,ReduceBy reduceBy,long reduceBy,long[] array,T object,long reduceBy,long[] array,T object,String methodName,long reduceBy,long[] array,int length,Object object,long reduceBy,long[] array,int length,Object function,String functionName,long reduceBy,long[] array,int start,int length,Object object){\r\n    if (object.getClass().isAnonymousClass()) {\r\n        return reduceByR(array, object);\r\n    }\r\n    try {\r\n        ConstantCallSite callSite = Invoker.invokeReducerLongIntReturnLongMethodHandle(object);\r\n        MethodHandle methodHandle = callSite.dynamicInvoker();\r\n        try {\r\n            long sum = 0;\r\n            for (int index = start; index < length; index++) {\r\n                long v = array[index];\r\n                sum = (long) methodHandle.invokeExact(sum, v);\r\n            }\r\n            return sum;\r\n        } catch (Throwable throwable) {\r\n            return handle(Long.class, throwable, \"Unable to perform reduceBy\");\r\n        }\r\n    } catch (Exception ex) {\r\n        return reduceByR(array, object);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.robust.Se3FromEssentialGenerator.generate",
	"Comment": "computes the camera motion from the set of observations. the motion is from the first\tinto the second camera frame.",
	"Method": "boolean generate(List<AssociatedPair> dataSet,Se3_F64 model){\r\n    if (!computeEssential.process(dataSet, E))\r\n        return false;\r\n    decomposeE.decompose(E);\r\n    selectBest.select(decomposeE.getSolutions(), dataSet, model);\r\n    return true;\r\n}"
}, {
	"Path": "org.boon.json.JsonSlurper.parse",
	"Comment": "parse a json data structure from content at a given url. convenience variant when using groovy named parameters for the connection params.",
	"Method": "Object parse(Reader reader,Object parse,File file,Object parse,File file,String charset,Object parse,URL url,Object parse,URL url,Map params,Object parse,Map params,URL url,Object parse,URL url,String charset,Object parse,URL url,Map params,String charset,Object parse,Map params,URL url,String charset){\r\n    return parseURL(url, params, charset);\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.PnPLepetitEPnP.score",
	"Comment": "score a solution based on distance between control points.closer the camera\tcontrol points are from the world control points the better the score.this is\tsimilar to how optimization score works and not the way recommended in the original\tpaper.",
	"Method": "double score(double betas){\r\n    UtilLepetitEPnP.computeCameraControl(betas, nullPts, solutionPts, numControl);\r\n    int index = 0;\r\n    double score = 0;\r\n    for (int i = 0; i < numControl; i++) {\r\n        Point3D_F64 si = solutionPts.get(i);\r\n        Point3D_F64 wi = controlWorldPts.get(i);\r\n        for (int j = i + 1; j < numControl; j++, index++) {\r\n            double ds = si.distance(solutionPts.get(j));\r\n            double dw = wi.distance(controlWorldPts.get(j));\r\n            score += (ds - dw) * (ds - dw);\r\n        }\r\n    }\r\n    return score;\r\n}"
}, {
	"Path": "boofcv.abst.geo.f.CheckEstimate1ofEpipolar.checkConstraint",
	"Comment": "make sure the ordering of the epipolar constraint is computed correctly",
	"Method": "void checkConstraint(){\r\n    init(50, isPixels);\r\n    boolean workedOnce = false;\r\n    DMatrixRMaj F = new DMatrixRMaj(3, 3);\r\n    for (int i = 0; i < 10; i++) {\r\n        List<AssociatedPair> pairs = randomPairs(alg.getMinimumPoints());\r\n        if (!alg.process(pairs, F)) {\r\n            continue;\r\n        }\r\n        workedOnce = true;\r\n        double n = CommonOps_DDRM.elementMaxAbs(F);\r\n        CommonOps_DDRM.scale(1.0 / n, F);\r\n        for (AssociatedPair p : pairs) {\r\n            double correct = Math.abs(GeometryMath_F64.innerProd(p.p2, F, p.p1));\r\n            double wrong = Math.abs(GeometryMath_F64.innerProd(p.p1, F, p.p2));\r\n            assertTrue(correct < wrong * 0.001);\r\n        }\r\n    }\r\n    assertTrue(workedOnce);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeEncoder.getLengthBits",
	"Comment": "returns the length of the message length variable in bits. dependent on version",
	"Method": "int getLengthBits(int version,int bitsA,int bitsB,int bitsC){\r\n    int lengthBits;\r\n    if (version < 10)\r\n        lengthBits = bitsA;\r\n    else if (version < 27)\r\n        lengthBits = bitsB;\r\n    else\r\n        lengthBits = bitsC;\r\n    return lengthBits;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.chess.TestDetectChessboardSquarePoints.touchImageEdge",
	"Comment": "crash case.the outer grid touches the image edge but not the inner.",
	"Method": "void touchImageEdge(){\r\n    offsetX = -10;\r\n    offsetY = -15;\r\n    int gridWidth = 4;\r\n    int gridHeight = 5;\r\n    GrayU8 binary = createTarget(gridHeight, gridWidth);\r\n    GrayU8 gray = binary.clone();\r\n    PixelMath.multiply(gray, 200, gray);\r\n    PixelMath.minus(255, gray, gray);\r\n    DetectPolygonBinaryGrayRefine<GrayU8> detectorSquare = FactoryShapeDetector.polygon(new ConfigPolygonDetector(4, 4), GrayU8.class);\r\n    DetectChessboardSquarePoints<GrayU8> alg = new DetectChessboardSquarePoints(gridWidth, gridHeight, ConfigLength.fixed(2), detectorSquare);\r\n    assertFalse(alg.process(gray, binary));\r\n}"
}, {
	"Path": "boofcv.factory.feature.orientation.FactoryOrientationAlgs.sift",
	"Comment": "estimates multiple orientations as specified in sift paper.",
	"Method": "OrientationHistogramSift<D> sift(ConfigSiftOrientation config,Class<D> derivType){\r\n    if (config == null)\r\n        config = new ConfigSiftOrientation();\r\n    config.checkValidity();\r\n    return new OrientationHistogramSift(config.histogramSize, config.sigmaEnlarge, derivType);\r\n}"
}, {
	"Path": "boofcv.alg.feature.color.Histogram_F64.isRangeSet",
	"Comment": "returns true if the min and max value for each dimension has been set",
	"Method": "boolean isRangeSet(){\r\n    for (int i = 0; i < getDimensions(); i++) {\r\n        if (valueMin[i] == 0 && valueMax[i] == 0) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setStatementsCacheSize",
	"Comment": "sets statementscachesize setting.\tthe number of statements to cache.",
	"Method": "void setStatementsCacheSize(int statementsCacheSize){\r\n    this.statementsCacheSize = statementsCacheSize;\r\n}"
}, {
	"Path": "boofcv.abst.feature.detect.intensity.WrapperKitRosCornerIntensity.getIgnoreBorder",
	"Comment": "there is no ignore border, unless the derivative that it is computed from has an ignore border.",
	"Method": "int getIgnoreBorder(){\r\n    return 0;\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.TestDescribeDenseHogAlg.computeCellHistogram",
	"Comment": "checks to see if the expected cells are modified in the descriptor",
	"Method": "void computeCellHistogram(){\r\n    DescribeDenseHogAlg<GrayF32> helper = new DescribeDenseHogAlg(10, pixelsPerCell, widthCellsX, widthCellsY, 1, imageType);\r\n    helper.setInput(new GrayF32(imgWidth, imgHeight));\r\n    ImageMiscOps.fill(helper.orientation, 0);\r\n    ImageMiscOps.fill(helper.magnitude, 1);\r\n    int cellX = 1;\r\n    int cellY = 2;\r\n    helper.histogram = new double[10 * widthCellsX * widthCellsY];\r\n    helper.computeCellHistogram(20, 25, cellX, cellY);\r\n    for (int i = -1; i <= 1; i++) {\r\n        for (int j = -1; j <= 1; j++) {\r\n            checkCellModified(helper.histogram, cellX + j, cellY + i, true);\r\n        }\r\n    }\r\n    checkCellModified(helper.histogram, 0, 0, false);\r\n}"
}, {
	"Path": "org.boon.criteria.ObjectFilter.matches",
	"Comment": "does the object match this expression.an expression is a collection of criteria.",
	"Method": "boolean matches(Object obj,Criteria exp,boolean matches,Object obj,Predicate exp,boolean matches,Object obj,List<Criteria> expressions){\r\n    return ObjectFilter.and(expressions.toArray(new Criteria[expressions.size()])).test(obj);\r\n}"
}, {
	"Path": "org.boon.core.value.LazyValueMap.lazyChopIfNeeded",
	"Comment": "if in lazy chop mode, and the object is a lazy value map or a valuelistthen we force a chop operation for each of its items.",
	"Method": "void lazyChopIfNeeded(Object object){\r\n    if (lazyChop) {\r\n        if (object instanceof LazyValueMap) {\r\n            LazyValueMap m = (LazyValueMap) object;\r\n            m.chopMap();\r\n        } else if (object instanceof ValueList) {\r\n            ValueList list = (ValueList) object;\r\n            list.chopList();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.ChecksSelectRectStandardBase.testRightToLeftValidation",
	"Comment": "similar to simpletest but takes in account the effects of right to left validation",
	"Method": "void testRightToLeftValidation(){\r\n    rightToLeftValidation(0);\r\n    rightToLeftValidation(2);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldTracker.createCascadeRegion",
	"Comment": "creates a list containing all the regions which need to be tested",
	"Method": "void createCascadeRegion(int imageWidth,int imageHeight){\r\n    cascadeRegions.reset();\r\n    int rectWidth = (int) (targetRegion.getWidth() + 0.5);\r\n    int rectHeight = (int) (targetRegion.getHeight() + 0.5);\r\n    for (int scaleInt = -config.scaleSpread; scaleInt <= config.scaleSpread; scaleInt++) {\r\n        double scale = Math.pow(1.2, scaleInt);\r\n        int actualWidth = (int) (rectWidth * scale);\r\n        int actualHeight = (int) (rectHeight * scale);\r\n        if (actualWidth < config.detectMinimumSide || actualHeight < config.detectMinimumSide)\r\n            continue;\r\n        if (actualWidth >= imageWidth || actualHeight >= imageHeight)\r\n            continue;\r\n        int stepWidth = (int) (rectWidth * scale * 0.1);\r\n        int stepHeight = (int) (rectHeight * scale * 0.1);\r\n        if (stepWidth < 1)\r\n            stepWidth = 1;\r\n        if (stepHeight < 1)\r\n            stepHeight = 1;\r\n        int maxX = imageWidth - actualWidth;\r\n        int maxY = imageHeight - actualHeight;\r\n        for (int y0 = 1; y0 < maxY; y0 += stepHeight) {\r\n            for (int x0 = 1; x0 < maxX; x0 += stepWidth) {\r\n                ImageRectangle r = cascadeRegions.grow();\r\n                r.x0 = x0;\r\n                r.y0 = y0;\r\n                r.x1 = x0 + actualWidth;\r\n                r.y1 = y0 + actualHeight;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.pyramid.TestImagePyramidBase.saveOriginalReference",
	"Comment": "if told to use the original image then no image should be declared for layer 0",
	"Method": "void saveOriginalReference(){\r\n    Dummy pyramid = new Dummy(GrayU8.class, false);\r\n    pyramid.setScaleFactors(1, 2, 4);\r\n    pyramid.initialize(100, 120);\r\n    assertTrue(pyramid.getLayer(0) != null);\r\n    pyramid = new Dummy(GrayU8.class, true);\r\n    pyramid.setScaleFactors(1, 2, 4);\r\n    pyramid.initialize(100, 120);\r\n    assertTrue(pyramid.getLayer(0) == null);\r\n    pyramid = new Dummy(GrayU8.class, true);\r\n    pyramid.setScaleFactors(2, 4);\r\n    pyramid.initialize(100, 120);\r\n    assertTrue(pyramid.getLayer(0) != null);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestBoneCP.testIsConnectionHandleAlive",
	"Comment": "test method for com.jolbox.bonecp.bonecp isconnectionhandlealive.",
	"Method": "void testIsConnectionHandleAlive(){\r\n    expect(mockConfig.getConnectionTestStatement()).andReturn(null).once();\r\n    mockConnection.logicallyClosed = new AtomicBoolean();\r\n    expect(mockConnection.getMetaData()).andReturn(mockDatabaseMetadata).once();\r\n    expect(mockDatabaseMetadata.getTables((String) anyObject(), (String) anyObject(), (String) anyObject(), (String[]) anyObject())).andReturn(mockResultSet).once();\r\n    mockResultSet.close();\r\n    expectLastCall().once();\r\n    replay(mockConfig, mockConnection, mockDatabaseMetadata, mockResultSet);\r\n    assertTrue(testClass.isConnectionHandleAlive(mockConnection));\r\n    verify(mockConfig, mockConnection, mockResultSet, mockDatabaseMetadata);\r\n}"
}, {
	"Path": "boofcv.alg.feature.color.Histogram_F64.setRange",
	"Comment": "specifies the minimum and maximum values for a specific dimension",
	"Method": "void setRange(int dimension,double min,double max){\r\n    valueMin[dimension] = min;\r\n    valueMax[dimension] = max;\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.BinaryImageOps.labelToBinary",
	"Comment": "only converts the specified blobs over into the binary image",
	"Method": "GrayU8 labelToBinary(GrayS32 labelImage,GrayU8 binaryImage,GrayU8 labelToBinary,GrayS32 labelImage,GrayU8 binaryImage,boolean selectedBlobs,GrayU8 labelToBinary,GrayS32 labelImage,GrayU8 binaryImage,int numLabels,int selected){\r\n    boolean[] selectedBlobs = new boolean[numLabels];\r\n    for (int i = 0; i < selected.length; i++) {\r\n        selectedBlobs[selected[i]] = true;\r\n    }\r\n    return labelToBinary(labelImage, binaryImage, selectedBlobs);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.chess.DetectChessboardSquarePoints.adjustBeforeOptimize",
	"Comment": "the polygon detected from the contour is too small because the binary image was eroded. this expand the size\tof the polygon so that it fits the image edge better",
	"Method": "void adjustBeforeOptimize(Polygon2D_F64 polygon,GrowQueue_B touchesBorder,boolean clockwise){\r\n    int N = polygon.size();\r\n    work.vertexes.resize(N);\r\n    for (int i = 0; i < N; i++) {\r\n        work.get(i).set(0, 0);\r\n    }\r\n    for (int i = N - 1, j = 0; j < N; i = j, j++) {\r\n        int ii, jj, kk, mm;\r\n        if (clockwise) {\r\n            mm = CircularIndex.addOffset(-1, i, N);\r\n            ii = i;\r\n            jj = j;\r\n            kk = CircularIndex.addOffset(1, j, N);\r\n        } else {\r\n            mm = CircularIndex.addOffset(1, j, N);\r\n            ii = j;\r\n            jj = i;\r\n            kk = CircularIndex.addOffset(-1, i, N);\r\n        }\r\n        Point2D_F64 a = polygon.get(ii), b = polygon.get(jj);\r\n        double dx = b.x - a.x;\r\n        double dy = b.y - a.y;\r\n        double l = Math.sqrt(dx * dx + dy * dy);\r\n        if (l == 0) {\r\n            throw new RuntimeException(\"Input polygon has two identical corners. You need to fix that.\");\r\n        }\r\n        dx *= 1.5 / l;\r\n        dy *= 1.5 / l;\r\n        Point2D_F64 _a = work.get(ii);\r\n        Point2D_F64 _b = work.get(jj);\r\n        if (touchesBorder.size > 0 && touchesBorder.get(ii)) {\r\n            if (!touchesBorder.get(mm)) {\r\n                _a.x -= dx;\r\n                _a.y -= dy;\r\n            }\r\n        } else {\r\n            _a.x += -dy;\r\n            _a.y += dx;\r\n        }\r\n        if (touchesBorder.size > 0 && touchesBorder.get(jj)) {\r\n            if (!touchesBorder.get(kk)) {\r\n                _b.x += dx;\r\n                _b.y += dy;\r\n            }\r\n        } else {\r\n            _b.x += -dy;\r\n            _b.y += dx;\r\n        }\r\n    }\r\n    for (int i = 0; i < N; i++) {\r\n        Point2D_F64 a = polygon.get(i);\r\n        Point2D_F64 b = work.get(i);\r\n        a.x += b.x;\r\n        a.y += b.y;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoOverheadMotion2D.process",
	"Comment": "estimates the motion which the camera undergoes relative to the first frame processed.",
	"Method": "boolean process(T image){\r\n    createOverhead.process(image, overhead.image);\r\n    if (!motion2D.process(overhead.image)) {\r\n        return false;\r\n    }\r\n    worldToCurr2D.set(motion2D.getFirstToCurrent());\r\n    worldToCurr2D.T.x *= overhead.cellSize;\r\n    worldToCurr2D.T.y *= overhead.cellSize;\r\n    origToMap.concat(worldToCurr2D, temp);\r\n    temp.concat(mapToOrigin, worldToCurr2D);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.increaseNumberOfSidesByOne",
	"Comment": "increase the number of sides in the polyline. this is done greedily selecting the side which would improve the\tscore by the most of it was split.",
	"Method": "boolean increaseNumberOfSidesByOne(List<Point2D_I32> contour,boolean loops){\r\n    Element<Corner> selected = selectCornerToSplit(loops);\r\n    if (selected == null)\r\n        return false;\r\n    selected.object.sideError = selected.object.splitError0;\r\n    Corner c = corners.grow();\r\n    c.reset();\r\n    c.index = selected.object.splitLocation;\r\n    c.sideError = selected.object.splitError1;\r\n    Element<Corner> cornerE = list.insertAfter(selected, c);\r\n    if (convex && !isSideConvex(contour, selected))\r\n        return false;\r\n    else {\r\n        computePotentialSplitScore(contour, cornerE, list.size() < minSides);\r\n        computePotentialSplitScore(contour, selected, list.size() < minSides);\r\n        savePolyline();\r\n        return true;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.EquirectangularDistortBase_F64.declareVectors",
	"Comment": "declares storage for precomputed pointing vectors to output image",
	"Method": "void declareVectors(int width,int height){\r\n    this.outWidth = width;\r\n    if (vectors.length < width * height) {\r\n        Point3D_F64[] tmp = new Point3D_F64[width * height];\r\n        System.arraycopy(vectors, 0, tmp, 0, vectors.length);\r\n        for (int i = vectors.length; i < tmp.length; i++) {\r\n            tmp[i] = new Point3D_F64();\r\n        }\r\n        vectors = tmp;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.transform.pyramid.GenericPyramidTests.checkModifiesLayersOnUpdate",
	"Comment": "checks to see if every layer in the pyramid has been modified on a call to update",
	"Method": "void checkModifiesLayersOnUpdate(){\r\n    T input = GeneralizedImageOps.createSingleBand(imageType, width, height);\r\n    ImagePyramid<T> pyramid = createPyramid(1, 2, 4);\r\n    GImageMiscOps.fillUniform(input, rand, 0, 100);\r\n    pyramid.process(input);\r\n    for (int i = 0; i < pyramid.getNumLayers(); i++) {\r\n        T image = pyramid.getLayer(i);\r\n        assertTrue(GImageStatistics.sum(image) > 0);\r\n    }\r\n}"
}, {
	"Path": "boofcv.android.camera2.SimpleCamera2Activity.selectCamera",
	"Comment": "by default this will select the backfacing camera. override to change the camera it selects.",
	"Method": "boolean selectCamera(String id,CameraCharacteristics characteristics){\r\n    if (verbose)\r\n        Log.i(TAG, \"selectCamera() default function\");\r\n    Integer facing = characteristics.get(CameraCharacteristics.LENS_FACING);\r\n    return facing == null || facing != CameraCharacteristics.LENS_FACING_FRONT;\r\n}"
}, {
	"Path": "boofcv.alg.misc.GPixelMath.abs",
	"Comment": "sets each pixel in the output image to be the absolute value of the input image.\tboth the input and output image can be the same instance.",
	"Method": "void abs(T input,T output){\r\n    if (input instanceof ImageGray) {\r\n        if (GrayS8.class == input.getClass()) {\r\n            PixelMath.abs((GrayS8) input, (GrayS8) output);\r\n        } else if (GrayS16.class == input.getClass()) {\r\n            PixelMath.abs((GrayS16) input, (GrayS16) output);\r\n        } else if (GrayS32.class == input.getClass()) {\r\n            PixelMath.abs((GrayS32) input, (GrayS32) output);\r\n        } else if (GrayS64.class == input.getClass()) {\r\n            PixelMath.abs((GrayS64) input, (GrayS64) output);\r\n        } else if (GrayF32.class == input.getClass()) {\r\n            PixelMath.abs((GrayF32) input, (GrayF32) output);\r\n        } else if (GrayF64.class == input.getClass()) {\r\n            PixelMath.abs((GrayF64) input, (GrayF64) output);\r\n        }\r\n    } else if (input instanceof ImageInterleaved) {\r\n        if (InterleavedS8.class == input.getClass()) {\r\n            PixelMath.abs((InterleavedS8) input, (InterleavedS8) output);\r\n        } else if (InterleavedS16.class == input.getClass()) {\r\n            PixelMath.abs((InterleavedS16) input, (InterleavedS16) output);\r\n        } else if (InterleavedS32.class == input.getClass()) {\r\n            PixelMath.abs((InterleavedS32) input, (InterleavedS32) output);\r\n        } else if (InterleavedS64.class == input.getClass()) {\r\n            PixelMath.abs((InterleavedS64) input, (InterleavedS64) output);\r\n        } else if (InterleavedF32.class == input.getClass()) {\r\n            PixelMath.abs((InterleavedF32) input, (InterleavedF32) output);\r\n        } else if (InterleavedF64.class == input.getClass()) {\r\n            PixelMath.abs((InterleavedF64) input, (InterleavedF64) output);\r\n        }\r\n    } else {\r\n        Planar in = (Planar) input;\r\n        Planar out = (Planar) output;\r\n        for (int i = 0; i < in.getNumBands(); i++) {\r\n            abs(in.getBand(i), out.getBand(i));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.TestQrCodeAlignmentPatternLocator.localize_OnePixelModules",
	"Comment": "the smallest possible configuration for a qr code.see if it still works",
	"Method": "void localize_OnePixelModules(){\r\n    QrCode qr = new QrCodeEncoder().setVersion(2).addNumeric(\"12340324\").fixate();\r\n    localize(qr, 1);\r\n}"
}, {
	"Path": "org.boon.core.reflection.Reflection.getPropertyFieldAccessMapFieldFirstForSerializer",
	"Comment": "gets a list of fields merges with properties if field is not found.",
	"Method": "Map<String, FieldAccess> getPropertyFieldAccessMapFieldFirstForSerializer(Class<?> clazz){\r\n    Map<String, FieldAccess> combinedFieldsFieldFirst = getCombinedFieldsFieldFirstForSerializer(clazz);\r\n    if (combinedFieldsFieldFirst != null) {\r\n        return combinedFieldsFieldFirst;\r\n    } else {\r\n        Map<String, FieldAccess> fieldsFallbacks = null;\r\n        Map<String, FieldAccess> fieldsPrimary = null;\r\n        fieldsPrimary = Reflection.getAllAccessorFields(clazz, true);\r\n        fieldsFallbacks = Reflection.getPropertyFieldAccessors(clazz);\r\n        fieldsPrimary = removeNonSerializable(fieldsPrimary);\r\n        fieldsFallbacks = removeNonSerializable(fieldsFallbacks);\r\n        combineFieldMaps(fieldsFallbacks, fieldsPrimary);\r\n        combinedFieldsFieldFirst = fieldsPrimary;\r\n        putCombinedFieldsFieldFirstForSerializer(clazz, combinedFieldsFieldFirst);\r\n        return combinedFieldsFieldFirst;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.TestSplitMergeLineFitSegment.set_minimumSideLengthPixel",
	"Comment": "checks to make sure the minimum side length is correctly set",
	"Method": "void set_minimumSideLengthPixel(){\r\n    List<Point2D_I32> contour = new ArrayList();\r\n    for (int i = 0; i < 30; i++) {\r\n        contour.add(new Point2D_I32(i, 0));\r\n    }\r\n    ConfigLength cl = ConfigLength.relative(0.1, 0);\r\n    SplitMergeLineFitSegment alg = new SplitMergeLineFitSegment(0.001, cl, 100);\r\n    alg.process(contour, splits);\r\n    assertEquals(contour.size() / 10, alg.minimumSideLengthPixel);\r\n}"
}, {
	"Path": "com.bugsnag.android.NativeInterface.getDeviceData",
	"Comment": "retrieve device data from the static client instance as a map",
	"Method": "Map<String, Object> getDeviceData(){\r\n    HashMap<String, Object> deviceData = new HashMap();\r\n    DeviceData source = getClient().getDeviceData();\r\n    deviceData.putAll(source.getDeviceMetaData());\r\n    deviceData.putAll(source.getDeviceData());\r\n    return deviceData;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.FeaturePyramid.findLocalScaleSpaceMax",
	"Comment": "searches the pyramid layers up and down to see if the found 2d features are also scale space maximums.",
	"Method": "void findLocalScaleSpaceMax(PyramidFloat<T> ss,int layerID){\r\n    int index0 = spaceIndex;\r\n    int index1 = (spaceIndex + 1) % 3;\r\n    int index2 = (spaceIndex + 2) % 3;\r\n    List<Point2D_I16> candidates = maximums[index1];\r\n    ImageBorder_F32 inten0 = (ImageBorder_F32) FactoryImageBorderAlgs.value(intensities[index0], 0);\r\n    GrayF32 inten1 = intensities[index1];\r\n    ImageBorder_F32 inten2 = (ImageBorder_F32) FactoryImageBorderAlgs.value(intensities[index2], 0);\r\n    float scale0 = (float) ss.scale[layerID - 1];\r\n    float scale1 = (float) ss.scale[layerID];\r\n    float scale2 = (float) ss.scale[layerID + 1];\r\n    float sigma0 = (float) ss.getSigma(layerID - 1);\r\n    float sigma1 = (float) ss.getSigma(layerID);\r\n    float sigma2 = (float) ss.getSigma(layerID + 1);\r\n    float ss0 = (float) (Math.pow(sigma0, scalePower) / scale0);\r\n    float ss1 = (float) (Math.pow(sigma1, scalePower) / scale1);\r\n    float ss2 = (float) (Math.pow(sigma2, scalePower) / scale2);\r\n    for (Point2D_I16 c : candidates) {\r\n        float val = ss1 * inten1.get(c.x, c.y);\r\n        int x0 = (int) (c.x * scale1 / scale0);\r\n        int y0 = (int) (c.y * scale1 / scale0);\r\n        int x2 = (int) (c.x * scale1 / scale2);\r\n        int y2 = (int) (c.y * scale1 / scale2);\r\n        if (checkMax(inten0, val / ss0, x0, y0) && checkMax(inten2, val / ss2, x2, y2)) {\r\n            foundPoints.add(new ScalePoint(c.x * scale1, c.y * scale1, sigma1));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.TestCylinderToEquirectangular_F32.pointingAtZero",
	"Comment": "the latitude and longitude should be zero when sampling the middle of the cylindrical image",
	"Method": "void pointingAtZero(){\r\n    CylinderToEquirectangular_F32 alg = new CylinderToEquirectangular_F32();\r\n    alg.setEquirectangularShape(400, 501);\r\n    alg.configure(200, 301, UtilAngle.radian(100));\r\n    alg.compute(100, 150);\r\n    assertEquals(200, alg.distX, GrlConstants.TEST_F32);\r\n    assertEquals(501 - 250 - 1, alg.distY, GrlConstants.TEST_F32);\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.TestPnPDistanceReprojectionSq.checkBehindCamera",
	"Comment": "a very large error should be returned if the point appears behind the second camera",
	"Method": "void checkBehindCamera(){\r\n    DMatrixRMaj K = new DMatrixRMaj(3, 3, true, 100, 0.01, 200, 0, 150, 200, 0, 0, 1);\r\n    Se3_F64 worldToCamera = new Se3_F64();\r\n    worldToCamera.getT().set(0.1, -0.1, -2.5);\r\n    Point3D_F64 X = new Point3D_F64(0.1, -0.04, 2.3);\r\n    Point2D_F64 observed = PerspectiveOps.renderPixel(worldToCamera, K, X);\r\n    PnPDistanceReprojectionSq alg = new PnPDistanceReprojectionSq();\r\n    alg.setIntrinsic(0, PerspectiveOps.matrixToPinhole(K, 0, 0, null));\r\n    alg.setModel(worldToCamera);\r\n    double found = alg.computeDistance(new Point2D3D(observed, X));\r\n    assertTrue(Double.MAX_VALUE == found);\r\n}"
}, {
	"Path": "boofcv.abst.filter.derivative.TestAnyImageDerivative.changeInputImageSize",
	"Comment": "see if changing the input image size causes an exception to be thrown.",
	"Method": "void changeInputImageSize(){\r\n    Kernel1D_F32 kernelX = (Kernel1D_F32) GradientThree.getKernelX(false);\r\n    AnyImageDerivative<GrayF32, GrayF32> alg = new AnyImageDerivative(kernelX, GrayF32.class, GrayF32.class);\r\n    alg.setInput(original);\r\n    alg.getDerivative(true);\r\n    GrayF32 smaller = new GrayF32(width - 5, height - 5);\r\n    GImageMiscOps.fillUniform(smaller, rand, 0, 40);\r\n    alg.setInput(smaller);\r\n    alg.getDerivative(true);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestBoneCP.testIsConnectionHandleAliveTriggerException",
	"Comment": "test method for com.jolbox.bonecp.bonecp isconnectionhandlealive.",
	"Method": "void testIsConnectionHandleAliveTriggerException(){\r\n    reset(mockConfig, mockConnection, mockDatabaseMetadata, mockResultSet);\r\n    expect(mockConfig.getConnectionTestStatement()).andReturn(null).once();\r\n    expect(mockConnection.getMetaData()).andThrow(new SQLException()).once();\r\n    mockConnection.logicallyClosed = new AtomicBoolean(false);\r\n    replay(mockConfig, mockConnection, mockDatabaseMetadata, mockResultSet);\r\n    assertFalse(testClass.isConnectionHandleAlive(mockConnection));\r\n    verify(mockConfig, mockConnection, mockResultSet, mockDatabaseMetadata);\r\n}"
}, {
	"Path": "boofcv.alg.geo.h.AdjustHomographyMatrix.findScaleH",
	"Comment": "the scale of h is found by computing the second smallest singular value.",
	"Method": "boolean findScaleH(DMatrixRMaj H){\r\n    if (!svd.decompose(H))\r\n        return false;\r\n    Arrays.sort(svd.getSingularValues(), 0, 3);\r\n    double scale = svd.getSingularValues()[1];\r\n    CommonOps_DDRM.divide(H, scale);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.demonstrations.calibration.CalibrateStereoPlanarGuiApp.configure",
	"Comment": "configures the calibration tool. for the calibration images, the image index in both lists must\tcorrespond to images taken at the same time.",
	"Method": "void configure(DetectorFiducialCalibration detector,int numRadial,boolean includeTangential,boolean assumeZeroSkew,List<File> leftImages,List<File> rightImages){\r\n    if (leftImages.size() != rightImages.size())\r\n        throw new IllegalArgumentException(\"Number of left and right images must be the same\");\r\n    this.detector = detector;\r\n    calibrator = new CalibrateStereoPlanar(detector.getLayout());\r\n    calibrator.configure(assumeZeroSkew, numRadial, includeTangential);\r\n    this.leftImages = leftImages;\r\n    this.rightImages = rightImages;\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.CalibrationPlanarGridZhang99.linearEstimate",
	"Comment": "find an initial estimate for calibration parameters using linear techniques.",
	"Method": "boolean linearEstimate(List<CalibrationObservation> observations,Zhang99AllParam param){\r\n    status(\"Estimating Homographies\");\r\n    List<DMatrixRMaj> homographies = new ArrayList();\r\n    List<Se3_F64> motions = new ArrayList();\r\n    for (CalibrationObservation obs : observations) {\r\n        if (!computeHomography.computeHomography(obs))\r\n            return false;\r\n        DMatrixRMaj H = computeHomography.getHomography();\r\n        homographies.add(H);\r\n    }\r\n    status(\"Estimating Calibration Matrix\");\r\n    computeK.process(homographies);\r\n    DMatrixRMaj K = computeK.getCalibrationMatrix();\r\n    decomposeH.setCalibrationMatrix(K);\r\n    for (DMatrixRMaj H : homographies) {\r\n        motions.add(decomposeH.decompose(H));\r\n    }\r\n    status(\"Estimating Radial Distortion\");\r\n    computeRadial.process(K, homographies, observations);\r\n    double[] distort = computeRadial.getParameters();\r\n    convertIntoZhangParam(motions, K, distort, param);\r\n    return true;\r\n}"
}, {
	"Path": "com.bugsnag.android.SessionTrackingPayloadTest.tearDown",
	"Comment": "deletes any files in the session store created during the test",
	"Method": "void tearDown(){\r\n    FileUtils.clearFilesInDir(storageDir);\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.AssociateGreedy.associate",
	"Comment": "associates the two sets objects against each other by minimizing fit score.",
	"Method": "void associate(FastQueue<D> src,FastQueue<D> dst){\r\n    fitQuality.reset();\r\n    pairs.reset();\r\n    workBuffer.reset();\r\n    fitQuality.setMaxSize(src.size);\r\n    workBuffer.setMaxSize(src.size * dst.size);\r\n    for (int i = 0; i < src.size; i++) {\r\n        D a = src.data[i];\r\n        double bestScore = maxFitError;\r\n        int bestIndex = -1;\r\n        for (int j = 0; j < dst.size; j++) {\r\n            D b = dst.data[j];\r\n            double fit = score.score(a, b);\r\n            workBuffer.push(fit);\r\n            if (fit <= bestScore) {\r\n                bestIndex = j;\r\n                bestScore = fit;\r\n            }\r\n        }\r\n        pairs.push(bestIndex);\r\n        fitQuality.push(bestScore);\r\n    }\r\n    if (backwardsValidation) {\r\n        for (int i = 0; i < src.size; i++) {\r\n            int match = pairs.data[i];\r\n            if (match == -1)\r\n                continue;\r\n            double scoreToBeat = workBuffer.data[i * dst.size + match];\r\n            for (int j = 0; j < src.size; j++, match += dst.size) {\r\n                if (workBuffer.data[match] <= scoreToBeat && j != i) {\r\n                    pairs.data[i] = -1;\r\n                    fitQuality.data[i] = Double.MAX_VALUE;\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "io.github.bucket4j.Bandwidth.withInitialTokens",
	"Comment": "by default new created bandwidth has amount tokens that equals its capacity.this method allows to replace initial tokens.",
	"Method": "Bandwidth withInitialTokens(long initialTokens){\r\n    if (initialTokens < 0) {\r\n        throw BucketExceptions.nonPositiveInitialTokens(initialTokens);\r\n    }\r\n    return new Bandwidth(capacity, refillPeriodNanos, refillTokens, initialTokens, refillIntervally);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.HoughTransformLinePolar.parameterize",
	"Comment": "converts the pixel coordinate into a line in parameter space",
	"Method": "void parameterize(int x,int y){\r\n    x -= originX;\r\n    y -= originY;\r\n    int w2 = transform.width / 2;\r\n    for (int i = 0; i < transform.height; i++) {\r\n        double p = x * tableTrig.c[i] + y * tableTrig.s[i];\r\n        int col = (int) Math.floor(p * w2 / r_max) + w2;\r\n        int index = transform.startIndex + i * transform.stride + col;\r\n        transform.data[index]++;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodePolynomialMath.decodeFormatMessage",
	"Comment": "assumes that the format message has no errors in it and decodes its data and saves it into the qr code",
	"Method": "void decodeFormatMessage(int message,QrCode qr){\r\n    int error = message >> 3;\r\n    qr.error = QrCode.ErrorLevel.lookup(error);\r\n    qr.mask = QrCodeMaskPattern.lookupMask(message & 0x07);\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.StereoConsistencyCheck.checkRectified",
	"Comment": "checks to see if the observations from the left and right camera are consistent.observations\tare assumed to be in the rectified image pixel coordinates.",
	"Method": "boolean checkRectified(Point2D_F64 left,Point2D_F64 right){\r\n    if (Math.abs(left.y - right.y) > toleranceY)\r\n        return false;\r\n    return right.x <= left.x + toleranceX;\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.impl.ImplSurfDescribeOps.naiveGradient",
	"Comment": "simple algorithm for computing the gradient of a region.can handle image borders",
	"Method": "void naiveGradient(T ii,double tl_x,double tl_y,double samplePeriod,int regionSize,double kernelSize,boolean useHaar,double[] derivX,double derivY){\r\n    SparseScaleGradient<T, ?> gg = SurfDescribeOps.createGradient(useHaar, (Class<T>) ii.getClass());\r\n    gg.setWidth(kernelSize);\r\n    gg.setImage(ii);\r\n    SparseGradientSafe g = new SparseGradientSafe(gg);\r\n    tl_x += 0.5;\r\n    tl_y += 0.5;\r\n    int i = 0;\r\n    for (int y = 0; y < regionSize; y++) {\r\n        for (int x = 0; x < regionSize; x++, i++) {\r\n            int xx = (int) (tl_x + x * samplePeriod);\r\n            int yy = (int) (tl_y + y * samplePeriod);\r\n            GradientValue deriv = g.compute(xx, yy);\r\n            derivX[i] = deriv.getX();\r\n            derivY[i] = deriv.getY();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.PointTrackerKltPyramid.checkValidSpawn",
	"Comment": "returns true if a new track can be spawned here.intended to be overloaded",
	"Method": "boolean checkValidSpawn(PointTrack p){\r\n    return true;\r\n}"
}, {
	"Path": "com.gazbert.bxbot.core.engine.TradingEngine.runMainControlLoop",
	"Comment": "the main control loop.we loop infinitely unless an unexpected exception occurs.the code fails hard and fast if an unexpected occurs. network exceptionsrecover.",
	"Method": "void runMainControlLoop(){\r\n    LOG.info(() -> \"Starting Trading Engine for \" + botId + \" ...\");\r\n    while (keepAlive) {\r\n        try {\r\n            LOG.info(() -> \"*** Starting next trade cycle... ***\");\r\n            if (isEmergencyStopLimitBreached()) {\r\n                break;\r\n            }\r\n            for (final TradingStrategy tradingStrategy : tradingStrategiesToExecute) {\r\n                LOG.info(() -> \"Executing Trading Strategy ---> \" + tradingStrategy.getClass().getSimpleName());\r\n                tradingStrategy.execute();\r\n            }\r\n            LOG.info(() -> \"*** Sleeping \" + tradeExecutionInterval + \"s til next trade cycle... ***\");\r\n            try {\r\n                Thread.sleep(tradeExecutionInterval * 1000);\r\n            } catch (InterruptedException e) {\r\n                LOG.warn(\"Control Loop thread interrupted when sleeping before next trade cycle\");\r\n                Thread.currentThread().interrupt();\r\n            }\r\n        } catch (ExchangeNetworkException e) {\r\n            final String WARNING_MSG = \"A network error has occurred in Exchange Adapter! \" + \"BX-bot will try again in \" + tradeExecutionInterval + \"s...\";\r\n            LOG.error(WARNING_MSG, e);\r\n            try {\r\n                Thread.sleep(tradeExecutionInterval * 1000);\r\n            } catch (InterruptedException e1) {\r\n                LOG.warn(\"Control Loop thread interrupted when sleeping before next trade cycle\");\r\n                Thread.currentThread().interrupt();\r\n            }\r\n        } catch (TradingApiException e) {\r\n            final String FATAL_ERROR_MSG = \"A FATAL error has occurred in Exchange Adapter!\";\r\n            LOG.fatal(FATAL_ERROR_MSG, e);\r\n            emailAlerter.sendMessage(CRITICAL_EMAIL_ALERT_SUBJECT, buildCriticalEmailAlertMsgContent(FATAL_ERROR_MSG + DETAILS_ERROR_MSG_LABEL + e.getMessage() + CAUSE_ERROR_MSG_LABEL + e.getCause(), e));\r\n            keepAlive = false;\r\n        } catch (StrategyException e) {\r\n            final String FATAL_ERROR_MSG = \"A FATAL error has occurred in Trading Strategy!\";\r\n            LOG.fatal(FATAL_ERROR_MSG, e);\r\n            emailAlerter.sendMessage(CRITICAL_EMAIL_ALERT_SUBJECT, buildCriticalEmailAlertMsgContent(FATAL_ERROR_MSG + DETAILS_ERROR_MSG_LABEL + e.getMessage() + CAUSE_ERROR_MSG_LABEL + e.getCause(), e));\r\n            keepAlive = false;\r\n        } catch (Exception e) {\r\n            final String FATAL_ERROR_MSG = \"An unexpected FATAL error has occurred in Exchange Adapter or Trading Strategy!\";\r\n            LOG.fatal(FATAL_ERROR_MSG, e);\r\n            emailAlerter.sendMessage(CRITICAL_EMAIL_ALERT_SUBJECT, buildCriticalEmailAlertMsgContent(FATAL_ERROR_MSG + DETAILS_ERROR_MSG_LABEL + e.getMessage() + CAUSE_ERROR_MSG_LABEL + e.getCause(), e));\r\n            keepAlive = false;\r\n        }\r\n    }\r\n    LOG.fatal(\"BX-bot \" + botId + \" is shutting down NOW!\");\r\n    synchronized (IS_RUNNING_MONITOR) {\r\n        isRunning = false;\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.CalibrationFiducialDetector.getCenter",
	"Comment": "returns the detection point average location.this will not be the same as the geometric center.",
	"Method": "void getCenter(int which,Point2D_F64 location){\r\n    CalibrationObservation view = detector.getDetectedPoints();\r\n    location.set(0, 0);\r\n    for (int i = 0; i < view.size(); i++) {\r\n        PointIndex2D_F64 p = view.get(i);\r\n        location.x += p.x;\r\n        location.y += p.y;\r\n    }\r\n    location.x /= view.size();\r\n    location.y /= view.size();\r\n}"
}, {
	"Path": "boofcv.android.ConvertBitmap.bitmapToGray",
	"Comment": "converts bitmap image into a single band image of arbitrary type.",
	"Method": "T bitmapToGray(Bitmap input,T output,Class<T> imageType,byte[] storage,GrayU8 bitmapToGray,Bitmap input,GrayU8 output,byte[] storage,GrayF32 bitmapToGray,Bitmap input,GrayF32 output,byte[] storage){\r\n    if (output == null) {\r\n        output = new GrayF32(input.getWidth(), input.getHeight());\r\n    } else {\r\n        output.reshape(input.getWidth(), input.getHeight());\r\n    }\r\n    if (storage == null)\r\n        storage = declareStorage(input, null);\r\n    input.copyPixelsToBuffer(ByteBuffer.wrap(storage));\r\n    ImplConvertBitmap.arrayToGray(storage, input.getConfig(), output);\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.alg.flow.ChecksHornSchunck.process",
	"Comment": "manually construct the input so that it has a known and easily understood output",
	"Method": "void process(){\r\n    HornSchunck<T, D> alg = createAlg();\r\n    T image1 = GeneralizedImageOps.createSingleBand(imageType, width, height);\r\n    T image2 = GeneralizedImageOps.createSingleBand(imageType, width, height);\r\n    ImageFlow output = new ImageFlow(width, height);\r\n    GImageMiscOps.fillRectangle(image1, 100, 10, 0, 20, 30);\r\n    GImageMiscOps.fillRectangle(image2, 100, 11, 0, 20, 30);\r\n    alg.process(image1, image2, output);\r\n    for (int y = 0; y < height - 1; y++) {\r\n        assertTrue(output.get(9, y).x > 0.9);\r\n        assertTrue(Math.abs(output.get(10, y).y) < 0.1);\r\n        assertTrue(output.get(10, y).x > 0.9);\r\n        assertTrue(Math.abs(output.get(11, y).y) < 0.1);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.bow.ClusterVisualWords.process",
	"Comment": "clusters the list of features into the specified number of words",
	"Method": "void process(int numberOfWords){\r\n    computeClusters.process(tuples, numberOfWords);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.LocalWeightedHistogramRotRect.computeHistogramBorder",
	"Comment": "computes the histogram and skips pixels which are outside the image border",
	"Method": "void computeHistogramBorder(T image,RectangleRotate_F32 region){\r\n    for (int i = 0; i < samplePts.size(); i++) {\r\n        Point2D_F32 p = samplePts.get(i);\r\n        squareToImageSample(p.x, p.y, region);\r\n        if (!BoofMiscOps.checkInside(image, imageX, imageY)) {\r\n            sampleHistIndex[i] = -1;\r\n        } else {\r\n            interpolate.get(imageX, imageY, value);\r\n            int indexHistogram = computeHistogramBin(value);\r\n            sampleHistIndex[i] = indexHistogram;\r\n            histogram[indexHistogram] += weights[i];\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.PackedSetsPoint2D_I32.reset",
	"Comment": "discards all previously detected points but does not free its memory. this allows it to be recycled",
	"Method": "void reset(){\r\n    tailBlockSize = 0;\r\n    blocks.reset();\r\n    blocks.grow();\r\n    sets.reset();\r\n}"
}, {
	"Path": "boofcv.deepboof.TestClipAndReduce.massage_distorted",
	"Comment": "fill the center of the image with a single color.if clipped correctly the output should be that color\tentirely.if not only the center",
	"Method": "void massage_distorted(boolean clipped,ImageType type){\r\n    ImageBase input = type.createImage(40, 30);\r\n    GImageMiscOps.fill(input.subimage(5, 0, 35, 30), 255);\r\n    ImageBase output = type.createImage(20, 20);\r\n    ClipAndReduce alg = new ClipAndReduce(clipped, type);\r\n    alg.massage(input, output);\r\n    if (clipped) {\r\n        assertEquals(255, GeneralizedImageOps.get(output, 0, 10, 0), 1e-4);\r\n        assertEquals(255, GeneralizedImageOps.get(output, 10, 10, 0), 1e-4);\r\n        assertEquals(255, GeneralizedImageOps.get(output, 19, 10, 0), 1e-4);\r\n    } else {\r\n        assertEquals(0, GeneralizedImageOps.get(output, 0, 10, 0), 2);\r\n        assertEquals(255, GeneralizedImageOps.get(output, 10, 10, 0), 1e-4);\r\n        assertEquals(0, GeneralizedImageOps.get(output, 19, 10, 0), 2);\r\n    }\r\n}"
}, {
	"Path": "org.boon.criteria.ObjectFilter.criteriaFromList",
	"Comment": "creates criteria from a list. this is used to configure criteria in json.",
	"Method": "Criteria criteriaFromList(List<?> list){\r\n    List<Object> args = new ArrayList(list);\r\n    Object o = atIndex(args, -1);\r\n    if (!(o instanceof List)) {\r\n        atIndex(args, -1, Collections.singletonList(o));\r\n    }\r\n    return (Criteria) Invoker.invokeFromList(ObjectFilter.class, \"createCriteriaFromClass\", args);\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationLinearDualQuadratic.solve",
	"Comment": "solve for camera calibration. a sanity check is performed to ensure that a valid calibration is found.\tall values must be countable numbers and the focal lengths must be positive numbers.",
	"Method": "GeometricResult solve(){\r\n    if (cameras.size < minimumProjectives)\r\n        throw new IllegalArgumentException(\"You need at least \" + minimumProjectives + \" motions\");\r\n    int N = cameras.size;\r\n    DMatrixRMaj L = new DMatrixRMaj(N * eqs, 10);\r\n    constructMatrix(L);\r\n    if (!svd.decompose(L)) {\r\n        return GeometricResult.SOLVE_FAILED;\r\n    }\r\n    extractSolutionForQ(Q);\r\n    double[] sv = svd.getSingularValues();\r\n    Arrays.sort(sv);\r\n    if (singularThreshold * sv[1] <= sv[0]) {\r\n        return GeometricResult.GEOMETRY_POOR;\r\n    }\r\n    if (!MultiViewOps.enforceAbsoluteQuadraticConstraints(Q, true, zeroSkew)) {\r\n        return GeometricResult.SOLVE_FAILED;\r\n    }\r\n    computeSolutions(Q);\r\n    if (solutions.size() != N) {\r\n        return GeometricResult.SOLUTION_NAN;\r\n    } else {\r\n        return GeometricResult.SUCCESS;\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.getErrorApiHeaders",
	"Comment": "supplies the headers which must be used in any request sent to the error reporting api.",
	"Method": "Map<String, String> getErrorApiHeaders(){\r\n    Map<String, String> map = new HashMap();\r\n    map.put(HEADER_API_PAYLOAD_VERSION, \"4.0\");\r\n    map.put(HEADER_API_KEY, apiKey);\r\n    map.put(HEADER_BUGSNAG_SENT_AT, DateUtils.toIso8601(new Date()));\r\n    return map;\r\n}"
}, {
	"Path": "boofcv.abst.geo.bundle.SceneStructureMetric.getUnknownViewCount",
	"Comment": "returns the number of view with parameters that are not fixed",
	"Method": "int getUnknownViewCount(){\r\n    int total = 0;\r\n    for (int i = 0; i < views.length; i++) {\r\n        if (!views[i].known) {\r\n            total++;\r\n        }\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.impl.TestBinaryThinning.thinning",
	"Comment": "run the overall algorithm and compare against a known result",
	"Method": "void thinning(){\r\n    GrayU8 img = new GrayU8(20, 25);\r\n    ImageMiscOps.fill(img.subimage(1, 5, 19, 10), 1);\r\n    BinaryThinning alg = new BinaryThinning();\r\n    alg.apply(img, -1);\r\n    assertEquals(24, ImageStatistics.sum(img));\r\n    for (int i = 2; i < 18; i++) {\r\n        assertEquals(1, img.get(i, 7));\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.fiducial.FactoryFiducialCalibration.circleHexagonalGrid",
	"Comment": "detector for hexagonal grid of circles.all circles must be entirely inside of the image.",
	"Method": "CalibrationDetectorCircleHexagonalGrid circleHexagonalGrid(ConfigCircleHexagonalGrid config){\r\n    config.checkValidity();\r\n    return new CalibrationDetectorCircleHexagonalGrid(config);\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.TestSelfCalibrationLinearDualQuadratic.solveWithTrificalInput",
	"Comment": "create a trifocal tensor, extract camera matrices, and see if it can find the solution",
	"Method": "void solveWithTrificalInput(){\r\n    CameraPinhole intrinsic = new CameraPinhole(500, 500, 0, 0, 0, 0, 0);\r\n    List<CameraPinhole> intrinsics = new ArrayList();\r\n    for (int i = 0; i < 3; i++) {\r\n        intrinsics.add(intrinsic);\r\n    }\r\n    renderGood(intrinsics);\r\n    List<AssociatedTriple> obs = new ArrayList();\r\n    for (int i = 0; i < cloud.size(); i++) {\r\n        Point3D_F64 X = cloud.get(i);\r\n        AssociatedTriple t = new AssociatedTriple();\r\n        t.p1 = PerspectiveOps.renderPixel(listCameraToWorld.get(0), intrinsic, X);\r\n        t.p2 = PerspectiveOps.renderPixel(listCameraToWorld.get(1), intrinsic, X);\r\n        t.p3 = PerspectiveOps.renderPixel(listCameraToWorld.get(2), intrinsic, X);\r\n        obs.add(t);\r\n    }\r\n    Estimate1ofTrifocalTensor estimate = FactoryMultiView.trifocal_1(EnumTrifocal.LINEAR_7, -1);\r\n    TrifocalTensor tensor = new TrifocalTensor();\r\n    assertTrue(estimate.process(obs, tensor));\r\n    DMatrixRMaj P1 = CommonOps_DDRM.identity(3, 4);\r\n    DMatrixRMaj P2 = new DMatrixRMaj(3, 4);\r\n    DMatrixRMaj P3 = new DMatrixRMaj(3, 4);\r\n    MultiViewOps.extractCameraMatrices(tensor, P2, P3);\r\n    SelfCalibrationLinearDualQuadratic alg = new SelfCalibrationLinearDualQuadratic(1.0);\r\n    alg.addCameraMatrix(P1);\r\n    alg.addCameraMatrix(P2);\r\n    alg.addCameraMatrix(P3);\r\n    assertEquals(GeometricResult.SUCCESS, alg.solve());\r\n    List<Intrinsic> found = alg.getSolutions();\r\n    assertEquals(3, found.size());\r\n    for (int i = 0; i < found.size(); i++) {\r\n        Intrinsic f = found.get(i);\r\n        assertEquals(500, f.fx, UtilEjml.TEST_F64_SQ);\r\n        assertEquals(500, f.fy, UtilEjml.TEST_F64_SQ);\r\n        assertEquals(0, f.skew, UtilEjml.TEST_F64_SQ);\r\n    }\r\n}"
}, {
	"Path": "boofcv.misc.TestMovingAverage.basic",
	"Comment": "basic check that makes sure the rate of decay changes the behavior in the expected way",
	"Method": "void basic(){\r\n    MovingAverage a = new MovingAverage(0.95);\r\n    MovingAverage b = new MovingAverage(0.8);\r\n    assertEquals(2.0, a.update(2), GrlConstants.TEST_F64);\r\n    assertEquals(2.0, b.update(2), GrlConstants.TEST_F64);\r\n    a.update(1.5);\r\n    b.update(1.5);\r\n    assertTrue(a.average > b.average);\r\n    assertTrue(a.average > 1.5 && a.average < 2);\r\n    assertTrue(b.average > 1.5 && b.average < 2);\r\n}"
}, {
	"Path": "boofcv.alg.geo.structure.ProjectiveStructureByFactorization.process",
	"Comment": "performs iteration to find camera matrices and feature locations in world frame",
	"Method": "boolean process(){\r\n    int numViews = depths.numRows;\r\n    int numFeatures = depths.numCols;\r\n    P.reshape(3 * numViews, 4);\r\n    X.reshape(4, numFeatures);\r\n    A.reshape(numViews * 3, numFeatures);\r\n    B.reshape(numViews * 3, numFeatures);\r\n    normalizeDepths(depths);\r\n    assignValuesToA(A);\r\n    for (int iter = 0; iter < maxIterations; iter++) {\r\n        if (!svd.decompose(A))\r\n            return false;\r\n        svd.getU(U, false);\r\n        svd.getV(Vt, true);\r\n        double[] sv = svd.getSingularValues();\r\n        SingularOps_DDRM.descendingOrder(U, false, sv, A.numCols, Vt, true);\r\n        CommonOps_DDRM.extract(U, 0, 0, P);\r\n        CommonOps_DDRM.multCols(P, sv);\r\n        CommonOps_DDRM.extract(Vt, 0, 0, X);\r\n        CommonOps_DDRM.mult(P, X, B);\r\n        double delta = SpecializedOps_DDRM.diffNormF(A, B) / (A.numCols * A.numRows);\r\n        DMatrixRMaj tmp = A;\r\n        A = B;\r\n        B = tmp;\r\n        if (delta <= minimumChangeTol)\r\n            break;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.examples.tracking.ExamplePointFeatureTracker.process",
	"Comment": "processes the sequence of images and displays the tracked features in a window",
	"Method": "void process(SimpleImageSequence<T> sequence){\r\n    T frame = sequence.next();\r\n    gui.setPreferredSize(new Dimension(frame.getWidth(), frame.getHeight()));\r\n    ShowImages.showWindow(gui, \"KTL Tracker\", true);\r\n    while (sequence.hasNext()) {\r\n        frame = sequence.next();\r\n        tracker.process(frame);\r\n        if (tracker.getActiveTracks(null).size() < 130)\r\n            tracker.spawnTracks();\r\n        updateGUI(sequence);\r\n        BoofMiscOps.pause(pause);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.UtilLepetitEPnP.constraintMatrix6x6",
	"Comment": "extracts the linear constraint matrix for case 3 from the full 6x10 constraint matrix.",
	"Method": "void constraintMatrix6x6(DMatrixRMaj L_6x10,DMatrixRMaj L_6x6){\r\n    int index = 0;\r\n    for (int i = 0; i < 6; i++) {\r\n        L_6x6.data[index++] = L_6x10.get(i, 0);\r\n        L_6x6.data[index++] = L_6x10.get(i, 1);\r\n        L_6x6.data[index++] = L_6x10.get(i, 2);\r\n        L_6x6.data[index++] = L_6x10.get(i, 4);\r\n        L_6x6.data[index++] = L_6x10.get(i, 5);\r\n        L_6x6.data[index++] = L_6x10.get(i, 7);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareGraph.almostParallel",
	"Comment": "checks to see if the two sides are almost parallel to each other by looking at their acute\tangle.",
	"Method": "boolean almostParallel(SquareNode a,int sideA,SquareNode b,int sideB){\r\n    double selected = acuteAngle(a, sideA, b, sideB);\r\n    if (selected > parallelThreshold)\r\n        return false;\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.UtilLepetitEPnP.constraintMatrix6x3",
	"Comment": "extracts the linear constraint matrix for case 2 from the full 6x10 constraint matrix.",
	"Method": "void constraintMatrix6x3(DMatrixRMaj L_6x10,DMatrixRMaj L_6x3){\r\n    int index = 0;\r\n    for (int i = 0; i < 6; i++) {\r\n        L_6x3.data[index++] = L_6x10.get(i, 0);\r\n        L_6x3.data[index++] = L_6x10.get(i, 1);\r\n        L_6x3.data[index++] = L_6x10.get(i, 4);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.GaliosFieldTableOps.polyEvalContinue",
	"Comment": "continue evaluating a polynomial which has been broken up into multiple arrays.",
	"Method": "int polyEvalContinue(int previousOutput,GrowQueue_I8 part,int x){\r\n    int y = previousOutput;\r\n    for (int i = 0; i < part.size; i++) {\r\n        y = multiply(y, x) ^ (part.data[i] & 0xFF);\r\n    }\r\n    return y;\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.UtilLepetitEPnP.constraintMatrix6x4",
	"Comment": "extracts the linear constraint matrix for case 1 from the full 6x10 constraint matrix.",
	"Method": "void constraintMatrix6x4(DMatrixRMaj L_6x10,DMatrixRMaj L_6x4){\r\n    int index = 0;\r\n    for (int i = 0; i < 6; i++) {\r\n        L_6x4.data[index++] = L_6x10.get(i, 0);\r\n        L_6x4.data[index++] = L_6x10.get(i, 1);\r\n        L_6x4.data[index++] = L_6x10.get(i, 3);\r\n        L_6x4.data[index++] = L_6x10.get(i, 6);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.MergeSmallRegions.selectMerge",
	"Comment": "examine edges for the specified node and select node which it is the best match for it to merge with",
	"Method": "void selectMerge(int pruneId,FastQueue<float[]> regionColor){\r\n    Node n = pruneGraph.get(pruneId);\r\n    float[] targetColor = regionColor.get(n.segment);\r\n    int bestId = -1;\r\n    float bestDistance = Float.MAX_VALUE;\r\n    for (int i = 0; i < n.edges.size; i++) {\r\n        int segment = n.edges.get(i);\r\n        float[] neighborColor = regionColor.get(segment);\r\n        float d = SegmentMeanShiftSearch.distanceSq(targetColor, neighborColor);\r\n        if (d < bestDistance) {\r\n            bestDistance = d;\r\n            bestId = segment;\r\n        }\r\n    }\r\n    if (bestId == -1)\r\n        throw new RuntimeException(\"No neighbors?  Something went really wrong.\");\r\n    markMerge(n.segment, bestId);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.combined.CombinedTrackerScalePoint.updateTracks",
	"Comment": "updates the location and description of tracks using klt.saves a reference\tto the input image for future processing.",
	"Method": "void updateTracks(I input,PyramidDiscrete<I> pyramid,D[] derivX,D[] derivY){\r\n    tracksSpawned.clear();\r\n    this.input = input;\r\n    trackerKlt.setInputs(pyramid, derivX, derivY);\r\n    trackUsingKlt(tracksPureKlt);\r\n    trackUsingKlt(tracksReactivated);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoPlaneInfinity.addNewTracks",
	"Comment": "requests that new tracks are spawned, determines if they are on the plane or not, and computes other required\tdata structures.",
	"Method": "void addNewTracks(){\r\n    tracker.spawnTracks();\r\n    List<PointTrack> spawned = tracker.getNewTracks(null);\r\n    for (PointTrack t : spawned) {\r\n        VoTrack p = t.getCookie();\r\n        if (p == null) {\r\n            t.cookie = p = new VoTrack();\r\n        }\r\n        pixelToNorm.compute(t.x, t.y, n);\r\n        if (planeProjection.normalToPlane(n.x, n.y, p.ground)) {\r\n            p.onPlane = true;\r\n        } else {\r\n            pointing.set(n.x, n.y, 1);\r\n            GeometryMath_F64.mult(cameraToPlane.getR(), pointing, pointing);\r\n            pointing.normalize();\r\n            double normXZ = Math.sqrt(pointing.x * pointing.x + pointing.z * pointing.z);\r\n            p.pointingY = pointing.y / normXZ;\r\n            p.ground.x = pointing.z;\r\n            p.ground.y = -pointing.x;\r\n            p.ground.x /= normXZ;\r\n            p.ground.y /= normXZ;\r\n            p.onPlane = false;\r\n        }\r\n        p.lastInlier = tick;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.RectifyImageOps.transformRectToPixel",
	"Comment": "creates a transform that goes from rectified to original distorted pixel coordinates.\trectification includes removal of lens distortion.used for rendering rectified images.",
	"Method": "Point2Transform2_F64 transformRectToPixel(CameraPinholeRadial param,DMatrixRMaj rectify,Point2Transform2_F32 transformRectToPixel,CameraPinholeRadial param,FMatrixRMaj rectify){\r\n    return ImplRectifyImageOps_F32.transformRectToPixel(param, rectify);\r\n}"
}, {
	"Path": "boofcv.factory.sfm.FactoryVisualOdometry.depthDepthPnP",
	"Comment": "depth sensor based visual odometry algorithm which runs a sparse feature tracker in the visual camera and\testimates the range of tracks once when first detected using the depth sensor.",
	"Method": "DepthVisualOdometry<Vis, Depth> depthDepthPnP(double inlierPixelTol,int thresholdAdd,int thresholdRetire,int ransacIterations,int refineIterations,boolean doublePass,DepthSparse3D<Depth> sparseDepth,PointTrackerTwoPass<Vis> tracker,Class<Vis> visualType,Class<Depth> depthType){\r\n    ImagePixelTo3D pixelTo3D = new DepthSparse3D_to_PixelTo3D(sparseDepth);\r\n    Estimate1ofPnP estimator = FactoryMultiView.pnp_1(EnumPNP.P3P_FINSTERWALDER, -1, 2);\r\n    final DistanceFromModelMultiView<Se3_F64, Point2D3D> distance = new PnPDistanceReprojectionSq();\r\n    ModelManagerSe3_F64 manager = new ModelManagerSe3_F64();\r\n    EstimatorToGenerator<Se3_F64, Point2D3D> generator = new EstimatorToGenerator(estimator);\r\n    double ransacTOL = inlierPixelTol * inlierPixelTol;\r\n    ModelMatcher<Se3_F64, Point2D3D> motion = new Ransac(2323, manager, generator, distance, ransacIterations, ransacTOL);\r\n    RefinePnP refine = null;\r\n    if (refineIterations > 0) {\r\n        refine = FactoryMultiView.pnpRefine(1e-12, refineIterations);\r\n    }\r\n    VisOdomPixelDepthPnP<Vis> alg = new VisOdomPixelDepthPnP(thresholdAdd, thresholdRetire, doublePass, motion, pixelTo3D, refine, tracker, null, null);\r\n    return new VisOdomPixelDepthPnP_to_DepthVisualOdometry(sparseDepth, alg, distance, ImageType.single(visualType), depthType);\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestNarrowToWidePtoP_F32.checkFOVBounds",
	"Comment": "request points at the border and see if it has the expected vertical and horizontal fov",
	"Method": "void checkFOVBounds(){\r\n    NarrowToWidePtoP_F32 alg = createAlg();\r\n    Point2D_F32 foundA = new Point2D_F32();\r\n    Point2D_F32 foundB = new Point2D_F32();\r\n    Point3D_F32 vA = new Point3D_F32();\r\n    Point3D_F32 vB = new Point3D_F32();\r\n    alg.compute(0, 250, foundA);\r\n    alg.compute(500, 250, foundB);\r\n    Point2Transform3_F32 wideToSphere = createModelWide().undistortPtoS_F32();\r\n    wideToSphere.compute(foundA.x, foundA.y, vA);\r\n    wideToSphere.compute(foundB.x, foundB.y, vB);\r\n    float found = UtilVector3D_F32.acute(new Vector3D_F32(vA), new Vector3D_F32(vB));\r\n    float expected = 2.0f * (float) Math.atan(250.0f / 400.0f);\r\n    assertEquals(expected, found, 0.01f);\r\n    alg.compute(250, 0, foundA);\r\n    alg.compute(250, 500, foundB);\r\n    wideToSphere.compute(foundA.x, foundA.y, vA);\r\n    wideToSphere.compute(foundB.x, foundB.y, vB);\r\n    found = UtilVector3D_F32.acute(new Vector3D_F32(vA), new Vector3D_F32(vB));\r\n    expected = 2.0f * (float) Math.atan(250.0f / 400.0f);\r\n    assertEquals(expected, found, 0.001f);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.RefinePolyLineCorner.computeCost",
	"Comment": "computes the distance between the two lines defined by corner points in the contour",
	"Method": "double computeCost(List<Point2D_I32> contour,int c0,int c1,int c2,int offset){\r\n    c1 = CircularIndex.addOffset(c1, offset, contour.size());\r\n    createLine(c0, c1, contour, line0);\r\n    createLine(c1, c2, contour, line1);\r\n    return distanceSum(line0, c0, c1, contour) + distanceSum(line1, c1, c2, contour);\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.impl.GeneralChecksInterpolationPixelMB.compareToSingleBand",
	"Comment": "compares interpolation to two single band images and sees if they produce nearly identical results",
	"Method": "void compareToSingleBand(){\r\n    T origMB = createImage(30, 40, 2);\r\n    GImageMiscOps.fillUniform(origMB, rand, 0, 100);\r\n    ImageDataType dataType = origMB.getImageType().getDataType();\r\n    ImageGray band0 = GeneralizedImageOps.createSingleBand(dataType, origMB.width, origMB.height);\r\n    ImageGray band1 = GeneralizedImageOps.createSingleBand(dataType, origMB.width, origMB.height);\r\n    for (int y = 0; y < origMB.height; y++) {\r\n        for (int x = 0; x < origMB.width; x++) {\r\n            double val0 = GeneralizedImageOps.get(origMB, x, y, 0);\r\n            double val1 = GeneralizedImageOps.get(origMB, x, y, 1);\r\n            GeneralizedImageOps.set(band0, x, y, val0);\r\n            GeneralizedImageOps.set(band1, x, y, val1);\r\n        }\r\n    }\r\n    InterpolatePixelS interpBand0 = wrapSingle(band0, 0, 255);\r\n    InterpolatePixelS interpBand1 = wrapSingle(band1, 0, 255);\r\n    InterpolatePixelMB<T> interpMB = wrap(origMB, 0, 255);\r\n    interpBand0.setBorder(FactoryImageBorder.genericValue(0, band0.getImageType()));\r\n    interpBand1.setBorder(FactoryImageBorder.genericValue(0, band1.getImageType()));\r\n    interpMB.setBorder(FactoryImageBorder.genericValue(0, interpMB.getImageType()));\r\n    interpBand0.setImage(band0);\r\n    interpBand1.setImage(band1);\r\n    interpMB.setImage(origMB);\r\n    float[] values = new float[2];\r\n    for (int y = 0; y < origMB.height - 1; y++) {\r\n        for (int x = 0; x < origMB.width - 1; x++) {\r\n            float val0 = interpBand0.get(x + 0.2f, y + 0.3f);\r\n            float val1 = interpBand1.get(x + 0.2f, y + 0.3f);\r\n            interpMB.get(x + 0.2f, y + 0.3f, values);\r\n            assertEquals(val0, values[0], 1e-4f);\r\n            assertEquals(val1, values[1], 1e-4f);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomPixelDepthPnP.changePoseToReference",
	"Comment": "updates the relative position of all points so that the current frame is the reference frame.mathematically\tthis is not needed, but should help keep numbers from getting too large.",
	"Method": "void changePoseToReference(){\r\n    Se3_F64 keyToCurr = currToKey.invert(null);\r\n    List<PointTrack> all = tracker.getAllTracks(null);\r\n    for (PointTrack t : all) {\r\n        Point2D3DTrack p = t.getCookie();\r\n        SePointOps_F64.transform(keyToCurr, p.location, p.location);\r\n    }\r\n    concatMotion();\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.LocalWeightedHistogramRotRect.computeHistogramBin",
	"Comment": "given the value of a pixel, compute which bin in the histogram it belongs in",
	"Method": "int computeHistogramBin(float value){\r\n    int indexHistogram = 0;\r\n    int binStride = 1;\r\n    for (int bandIndex = 0; bandIndex < value.length; bandIndex++) {\r\n        int bin = (int) (numBins * value[bandIndex] / maxPixelValue);\r\n        indexHistogram += bin * binStride;\r\n        binStride *= numBins;\r\n    }\r\n    return indexHistogram;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.TestAdjustPolygonForThresholdBias.removeDuplicatePoint",
	"Comment": "create a situation where a point will be shifted on top of an existing one. see if that is caught\tand removed. not trivial to reproduce with real data but does happen.",
	"Method": "void removeDuplicatePoint(){\r\n    AdjustPolygonForThresholdBias alg = new AdjustPolygonForThresholdBias();\r\n    Polygon2D_F64 original = new Polygon2D_F64(10, 10, 10, 9, 9, 9, 20, 9, 20, 0, 11, 0);\r\n    original.flip();\r\n    Polygon2D_F64 shape = original.copy();\r\n    alg.process(shape, true);\r\n    assertEquals(original.size() - 1, shape.size());\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.TestDescribePointSift.process",
	"Comment": "tests to see if it blows up and not much more.random image.compute descriptor along border and image\tcenter.",
	"Method": "void process(){\r\n    GrayF32 derivX = new GrayF32(200, 200);\r\n    GrayF32 derivY = new GrayF32(200, 200);\r\n    GImageMiscOps.fillUniform(derivX, rand, -100, 100);\r\n    GImageMiscOps.fillUniform(derivY, rand, -100, 100);\r\n    DescribePointSift<GrayF32> alg = new DescribePointSift(4, 4, 8, 1.5, 0.5, 0.2, GrayF32.class);\r\n    alg.setImageGradient(derivX, derivY);\r\n    List<Point2D_I32> testPoints = new ArrayList();\r\n    testPoints.add(new Point2D_I32(100, 0));\r\n    testPoints.add(new Point2D_I32(100, 199));\r\n    testPoints.add(new Point2D_I32(0, 100));\r\n    testPoints.add(new Point2D_I32(199, 100));\r\n    testPoints.add(new Point2D_I32(100, 100));\r\n    TupleDesc_F64 desc = new TupleDesc_F64(alg.getDescriptorLength());\r\n    for (Point2D_I32 where : testPoints) {\r\n        alg.process(where.x, where.y, 2, 0.5, desc);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.LowLevelMultiViewOps.computeNormalizationLL",
	"Comment": "computes normalization when points are contained in a list of lists",
	"Method": "void computeNormalizationLL(List<List<Point2D_F64>> points,NormalizationPoint2D normalize){\r\n    double meanX = 0;\r\n    double meanY = 0;\r\n    int count = 0;\r\n    for (int i = 0; i < points.size(); i++) {\r\n        List<Point2D_F64> l = points.get(i);\r\n        for (int j = 0; j < l.size(); j++) {\r\n            Point2D_F64 p = l.get(j);\r\n            meanX += p.x;\r\n            meanY += p.y;\r\n        }\r\n        count += l.size();\r\n    }\r\n    meanX /= count;\r\n    meanY /= count;\r\n    double stdX = 0;\r\n    double stdY = 0;\r\n    for (int i = 0; i < points.size(); i++) {\r\n        List<Point2D_F64> l = points.get(i);\r\n        for (int j = 0; j < l.size(); j++) {\r\n            Point2D_F64 p = l.get(j);\r\n            double dx = p.x - meanX;\r\n            double dy = p.y - meanY;\r\n            stdX += dx * dx;\r\n            stdY += dy * dy;\r\n        }\r\n    }\r\n    normalize.meanX = meanX;\r\n    normalize.meanY = meanY;\r\n    normalize.stdX = Math.sqrt(stdX / count);\r\n    normalize.stdY = Math.sqrt(stdY / count);\r\n}"
}, {
	"Path": "boofcv.alg.geo.PerspectiveOps.createIntrinsic",
	"Comment": "creates a set of intrinsic parameters, without distortion, for a camera with the specified characteristics.\tthe focal length is assumed to be the same for x and y.",
	"Method": "CameraPinhole createIntrinsic(int width,int height,double hfov,double vfov,CameraPinholeRadial createIntrinsic,int width,int height,double hfov){\r\n    CameraPinholeRadial intrinsic = new CameraPinholeRadial();\r\n    intrinsic.width = width;\r\n    intrinsic.height = height;\r\n    intrinsic.cx = width / 2;\r\n    intrinsic.cy = height / 2;\r\n    intrinsic.fx = intrinsic.cx / Math.tan(UtilAngle.degreeToRadian(hfov / 2.0));\r\n    intrinsic.fy = intrinsic.fx;\r\n    return intrinsic;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeCodeWordLocations.computeFeatureMask",
	"Comment": "blocks out the location of features in the image. needed for codeworld location extraction",
	"Method": "void computeFeatureMask(int numModules,int[] alignment,boolean hasVersion){\r\n    markSquare(0, 0, 9);\r\n    markRectangle(numModules - 8, 0, 9, 8);\r\n    markRectangle(0, numModules - 8, 8, 9);\r\n    markRectangle(8, 6, 1, numModules - 8 - 8);\r\n    markRectangle(6, 8, numModules - 8 - 8, 1);\r\n    if (hasVersion) {\r\n        markRectangle(numModules - 11, 0, 6, 3);\r\n        markRectangle(0, numModules - 11, 3, 6);\r\n    }\r\n    for (int i = 0; i < alignment.length; i++) {\r\n        int row = alignment[i];\r\n        for (int j = 0; j < alignment.length; j++) {\r\n            if (i == 0 & j == 0)\r\n                continue;\r\n            if (i == alignment.length - 1 & j == 0)\r\n                continue;\r\n            if (i == alignment.length - 1 & j == alignment.length - 1)\r\n                continue;\r\n            int col = alignment[j];\r\n            markSquare(numModules - row - 3, col - 2, 5);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.EstimateSceneCalibrated.medianTriangulationAngle",
	"Comment": "compares the angle that different observations form when their lines intersect. returns\tthe median angle. used to determine if this edge is good for triangulation",
	"Method": "double medianTriangulationAngle(Motion edge){\r\n    GrowQueue_F64 angles = new GrowQueue_F64(edge.associated.size());\r\n    angles.size = edge.associated.size();\r\n    for (int i = 0; i < edge.associated.size(); i++) {\r\n        AssociatedIndex a = edge.associated.get(i);\r\n        Point2D_F64 normA = edge.viewSrc.observationNorm.get(a.src);\r\n        Point2D_F64 normB = edge.viewDst.observationNorm.get(a.dst);\r\n        double acute = triangulationAngle(normA, normB, edge.a_to_b);\r\n        angles.data[i] = acute;\r\n    }\r\n    angles.sort();\r\n    return angles.getFraction(0.5);\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.noborder.TestConvolveImageStandard_IL.checkAll",
	"Comment": "using reflections get a list of all the functions and test each of them",
	"Method": "void checkAll(){\r\n    int numExpected = 29;\r\n    Method[] methods = ConvolveImageStandard_IL.class.getMethods();\r\n    int numFound = 0;\r\n    for (Method m : methods) {\r\n        if (!isTestMethod(m)) {\r\n            continue;\r\n        }\r\n        testMethod(m);\r\n        numFound++;\r\n    }\r\n    if (numExpected != numFound)\r\n        throw new RuntimeException(\"Unexpected number of methods: Found \" + numFound + \"  expected \" + numExpected);\r\n}"
}, {
	"Path": "com.bugsnag.android.ClientTest.setUp",
	"Comment": "generates a configuration and clears sharedprefs values to begin the test with a clean slate",
	"Method": "void setUp(){\r\n    context = InstrumentationRegistry.getContext();\r\n    clearSharedPrefs();\r\n    config = new Configuration(\"api-key\");\r\n}"
}, {
	"Path": "com.bugsnag.android.SessionTracker.trackSessionIfNeeded",
	"Comment": "determines whether or not a session should be tracked. if this is true, the session will bestored and sent to the bugsnag api, otherwise no action will occur in this method.",
	"Method": "void trackSessionIfNeeded(Session session){\r\n    boolean notifyForRelease = configuration.shouldNotifyForReleaseStage(getReleaseStage());\r\n    if (notifyForRelease && (configuration.shouldAutoCaptureSessions() || !session.isAutoCaptured()) && session.isTracked().compareAndSet(false, true)) {\r\n        try {\r\n            final String endpoint = configuration.getSessionEndpoint();\r\n            Async.run(new Runnable() {\r\n                @Override\r\n                public void run() {\r\n                    flushStoredSessions();\r\n                    SessionTrackingPayload payload = new SessionTrackingPayload(session, null, client.appData, client.deviceData);\r\n                    try {\r\n                        configuration.getDelivery().deliver(payload, configuration);\r\n                    } catch (DeliveryFailureException exception) {\r\n                        Logger.warn(\"Storing session payload for future delivery\", exception);\r\n                        sessionStore.write(session);\r\n                    } catch (Exception exception) {\r\n                        Logger.warn(\"Dropping invalid session tracking payload\", exception);\r\n                    }\r\n                }\r\n            });\r\n        } catch (RejectedExecutionException exception) {\r\n            sessionStore.write(session);\r\n        }\r\n        setChanged();\r\n        String startedAt = DateUtils.toIso8601(session.getStartedAt());\r\n        notifyObservers(new NativeInterface.Message(NativeInterface.MessageType.START_SESSION, Arrays.asList(session.getId(), startedAt)));\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.SessionTracker.trackSessionIfNeeded",
	"Comment": "determines whether or not a session should be tracked. if this is true, the session will bestored and sent to the bugsnag api, otherwise no action will occur in this method.",
	"Method": "void trackSessionIfNeeded(Session session){\r\n    flushStoredSessions();\r\n    SessionTrackingPayload payload = new SessionTrackingPayload(session, null, client.appData, client.deviceData);\r\n    try {\r\n        configuration.getDelivery().deliver(payload, configuration);\r\n    } catch (DeliveryFailureException exception) {\r\n        Logger.warn(\"Storing session payload for future delivery\", exception);\r\n        sessionStore.write(session);\r\n    } catch (Exception exception) {\r\n        Logger.warn(\"Dropping invalid session tracking payload\", exception);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquaresIntoClusters.addToCluster",
	"Comment": "finds all neighbors and adds them to the graph.repeated until there are no more nodes to add to the graph",
	"Method": "void addToCluster(SquareNode seed,List<SquareNode> graph){\r\n    open.clear();\r\n    open.add(seed);\r\n    while (!open.isEmpty()) {\r\n        SquareNode n = open.remove(open.size() - 1);\r\n        for (int i = 0; i < n.square.size(); i++) {\r\n            SquareEdge edge = n.edges[i];\r\n            if (edge == null)\r\n                continue;\r\n            SquareNode other;\r\n            if (edge.a == n)\r\n                other = edge.b;\r\n            else if (edge.b == n)\r\n                other = edge.a;\r\n            else\r\n                throw new RuntimeException(\"BUG!\");\r\n            if (other.graph == SquareNode.RESET_GRAPH) {\r\n                other.graph = n.graph;\r\n                graph.add(other);\r\n                open.add(other);\r\n            } else if (other.graph != n.graph) {\r\n                throw new RuntimeException(\"BUG! \" + other.graph + \" \" + n.graph);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.SplitMergeLineFitLoop.mergeSegments",
	"Comment": "merges lines together if the common corner is close to a common line",
	"Method": "boolean mergeSegments(){\r\n    if (splits.size() <= 3)\r\n        return false;\r\n    boolean change = false;\r\n    work.reset();\r\n    for (int i = 0; i < splits.size; i++) {\r\n        int start = splits.data[i];\r\n        int end = splits.data[(i + 2) % splits.size];\r\n        if (selectSplitOffset(start, circularDistance(start, end)) < 0) {\r\n            change = true;\r\n        } else {\r\n            work.add(splits.data[(i + 1) % splits.size]);\r\n        }\r\n    }\r\n    GrowQueue_I32 tmp = work;\r\n    work = splits;\r\n    splits = tmp;\r\n    return change;\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.BasicDisparitySelectRectTests.minDisparity",
	"Comment": "set the minimum disparity to a non zero number and see if it has the expected behavior",
	"Method": "void minDisparity(){\r\n    int minDisparity = 2;\r\n    int maxDisparity = 10;\r\n    int r = 2;\r\n    int range = maxDisparity - minDisparity;\r\n    int y = 3;\r\n    GImageMiscOps.fill(disparity, 0);\r\n    alg.configure(disparity, minDisparity, maxDisparity, r);\r\n    int[] scores = new int[w * range];\r\n    for (int d = 0; d < range; d++) {\r\n        for (int x = 0; x < w - (r * 2 + 1); x++) {\r\n            scores[w * d + x] = Math.abs(d - 5);\r\n        }\r\n    }\r\n    alg.process(y, copyToCorrectType(scores));\r\n    for (int i = 0; i < 2 + minDisparity; i++) assertEquals(0, GeneralizedImageOps.get(disparity, i, y), 1e-8);\r\n    assertEquals(0, GeneralizedImageOps.get(disparity, w - 2, y), 1e-8);\r\n    assertEquals(0, GeneralizedImageOps.get(disparity, w - 1, y), 1e-8);\r\n    for (int i = 0; i < 5; i++) assertEquals(i + 2, minDisparity + GeneralizedImageOps.get(disparity, i + 2 + minDisparity, y), 1e-8);\r\n    for (int i = 5; i < w - 4 - minDisparity; i++) assertEquals(7, minDisparity + GeneralizedImageOps.get(disparity, i + 2 + minDisparity, y), 1e-8);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.CommonFitPolygonChecks.findMatchesOriginal",
	"Comment": "compare found rectangle against rectangles in the original undistorted image",
	"Method": "int findMatchesOriginal(Polygon2D_F64 found,double tol){\r\n    int match = 0;\r\n    for (int i = 0; i < rectangles.size(); i++) {\r\n        Rectangle2D_I32 ri = rectangles.get(i);\r\n        Rectangle2D_F64 r = new Rectangle2D_F64(ri.x0, ri.y0, ri.x1, ri.y1);\r\n        Polygon2D_F64 p = new Polygon2D_F64(4);\r\n        UtilPolygons2D_F64.convert(r, p);\r\n        if (p.isCCW())\r\n            p.flip();\r\n        if (UtilPolygons2D_F64.isEquivalent(found, p, tol))\r\n            match++;\r\n    }\r\n    return match;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.intensity.GenericCornerIntensityTests.testLargerCorner",
	"Comment": "checks to see if an image with a corner has a larger response than a flat image.",
	"Method": "void testLargerCorner(){\r\n    createUniformI8();\r\n    createUniformF32();\r\n    float flatResponse = getResponse();\r\n    createCornerI8();\r\n    createCornerF32();\r\n    float cornerResponse = getResponse();\r\n    assertTrue(cornerResponse > flatResponse);\r\n    float awayResponse = getResponseAway();\r\n    assertTrue(cornerResponse > awayResponse);\r\n}"
}, {
	"Path": "boofcv.alg.geo.structure.ProjectiveStructureByFactorization.setDepths",
	"Comment": "sets depths for a particular value to the values in the passed in array",
	"Method": "void setDepths(int view,double featureDepths){\r\n    if (featureDepths.length < depths.numCols)\r\n        throw new IllegalArgumentException(\"Pixel count must be constant and match \" + pixels.numCols);\r\n    int N = depths.numCols;\r\n    for (int i = 0; i < N; i++) {\r\n        depths.set(view, i, featureDepths[i]);\r\n    }\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.ui.ColorTransitioner.getColor",
	"Comment": "gets the transitioned color based on a percentage between 0 and 1.",
	"Method": "Color getColor(double percentage){\r\n    final double transitionPoint = Utilities.limit(0.0, percentage, 1.0);\r\n    if (colors.size() == 1) {\r\n        return colors.get(0).color;\r\n    }\r\n    ColorPoint lower = colors.get(0);\r\n    ColorPoint higher = colors.get(1);\r\n    for (final ColorPoint colorPoint : colors) {\r\n        if (colorPoint.point > transitionPoint) {\r\n            higher = colorPoint;\r\n            break;\r\n        }\r\n        lower = colorPoint;\r\n    }\r\n    final double spanned = (transitionPoint - lower.point) * (1 / (higher.point - lower.point));\r\n    return new Color((int) Math.round(lower.color.getRed() * (1 - spanned) + higher.color.getRed() * spanned), (int) Math.round(lower.color.getGreen() * (1 - spanned) + higher.color.getGreen() * spanned), (int) Math.round(lower.color.getBlue() * (1 - spanned) + higher.color.getBlue() * spanned), Utilities.limit(0, ConfigNew.getConfig().getInt(ConfigKey.COLOR_ALPHA), ColorHelper.MAX_COLOR));\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.GeneralFeatureDetector.setExcludeMaximum",
	"Comment": "specify points which are excluded when detecting maximums",
	"Method": "void setExcludeMaximum(QueueCorner exclude){\r\n    this.excludeMaximum = exclude;\r\n}"
}, {
	"Path": "boofcv.alg.geo.h.TestHomographyTotalLeastSquares.checkHomography",
	"Comment": "create a set of points perfectly on a plane and provide perfect observations of them",
	"Method": "void checkHomography(int N,HomographyTotalLeastSquares alg){\r\n    createScene(N, true);\r\n    assertTrue(alg.process(pairs, solution));\r\n    assertTrue(NormOps_DDRM.normF(solution) > 0.001);\r\n    for (AssociatedPair p : pairs) {\r\n        Point2D_F64 a = GeometryMath_F64.mult(solution, p.p1, new Point2D_F64());\r\n        double diff = a.distance(p.p2);\r\n        assertEquals(0, diff, 1e-8);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.misc.GImageStatistics.maxAbs",
	"Comment": "returns the absolute value of the element with the largest absolute value, across all bands",
	"Method": "double maxAbs(ImageBase input){\r\n    if (input instanceof ImageGray) {\r\n        if (GrayU8.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((GrayU8) input);\r\n        } else if (GrayS8.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((GrayS8) input);\r\n        } else if (GrayU16.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((GrayU16) input);\r\n        } else if (GrayS16.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((GrayS16) input);\r\n        } else if (GrayS32.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((GrayS32) input);\r\n        } else if (GrayS64.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((GrayS64) input);\r\n        } else if (GrayF32.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((GrayF32) input);\r\n        } else if (GrayF64.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((GrayF64) input);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown Image Type: \" + input.getClass().getSimpleName());\r\n        }\r\n    } else if (input instanceof ImageInterleaved) {\r\n        if (InterleavedU8.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((InterleavedU8) input);\r\n        } else if (InterleavedS8.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((InterleavedS8) input);\r\n        } else if (InterleavedU16.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((InterleavedU16) input);\r\n        } else if (InterleavedS16.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((InterleavedS16) input);\r\n        } else if (InterleavedS32.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((InterleavedS32) input);\r\n        } else if (InterleavedS64.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((InterleavedS64) input);\r\n        } else if (InterleavedF32.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((InterleavedF32) input);\r\n        } else if (InterleavedF64.class == input.getClass()) {\r\n            return ImageStatistics.maxAbs((InterleavedF64) input);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown Image Type: \" + input.getClass().getSimpleName());\r\n        }\r\n    } else {\r\n        throw new IllegalArgumentException(\"Planar image support needs to be added\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.normalized.TestConvolveNormalizedNaive_IL.vertical",
	"Comment": "check it against one specific type to see if the core algorithm is correct",
	"Method": "void vertical(int vertical,int x,int y,int band,Kernel1D_S32 kernel,InterleavedU8 image){\r\n    int total = 0;\r\n    int weight = 0;\r\n    for (int i = 0; i < kernel.width; i++) {\r\n        if (image.isInBounds(x, y + i - kernel.offset)) {\r\n            int w = kernel.get(i);\r\n            int v = image.getBand(x, y + i - kernel.offset, band);\r\n            total += w * v;\r\n            weight += w;\r\n        }\r\n    }\r\n    return (total + weight / 2) / weight;\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.CalibrationFiducialDetector.selectBoundaryCorners",
	"Comment": "selects points which will be the corners in the boundary. finds the convex hull.",
	"Method": "void selectBoundaryCorners(){\r\n    List<Point2D_F64> layout = detector.getLayout();\r\n    Polygon2D_F64 hull = new Polygon2D_F64();\r\n    UtilPolygons2D_F64.convexHull(layout, hull);\r\n    UtilPolygons2D_F64.removeAlmostParallel(hull, 0.02);\r\n    boundaryIndexes = new int[hull.size()];\r\n    for (int i = 0; i < hull.size(); i++) {\r\n        Point2D_F64 h = hull.get(i);\r\n        boolean matched = false;\r\n        for (int j = 0; j < layout.size(); j++) {\r\n            if (h.isIdentical(layout.get(j), 1e-6)) {\r\n                matched = true;\r\n                boundaryIndexes[i] = j;\r\n                break;\r\n            }\r\n        }\r\n        if (!matched)\r\n            throw new RuntimeException(\"Bug!\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.feature.disparity.TestWrapDisparitySadRect.borderSetToInvalid",
	"Comment": "the whole image should be set as invalid since it is not being written over",
	"Method": "void borderSetToInvalid(){\r\n    int range = 4;\r\n    Foo foo = new Foo(1, 1 + range, 2, 2);\r\n    WrapDisparitySadRect<GrayF32, GrayF32> alg = new WrapDisparitySadRect(foo);\r\n    GrayF32 l = new GrayF32(10, 20);\r\n    GrayF32 r = new GrayF32(10, 20);\r\n    alg.process(l, r);\r\n    GrayF32 found = alg.getDisparity();\r\n    for (int y = 0; y < found.height; y++) for (int x = 0; x < found.width; x++) assertTrue(found.get(x, y) > range);\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.TestSegmentMeanShiftSearchGray.simpleTest",
	"Comment": "process a random image and do a basic sanity check on the output",
	"Method": "void simpleTest(){\r\n    GrayF32 image = new GrayF32(20, 25);\r\n    ImageMiscOps.fillUniform(image, rand, 0, 256);\r\n    SegmentMeanShiftSearchGray<GrayF32> alg = new SegmentMeanShiftSearchGray(30, 0.05f, interp, 2, 2, 100, false);\r\n    alg.process(image);\r\n    FastQueue<Point2D_I32> locations = alg.getModeLocation();\r\n    GrowQueue_I32 counts = alg.getRegionMemberCount();\r\n    GrayS32 peaks = alg.getPixelToRegion();\r\n    FastQueue<float[]> values = alg.getModeColor();\r\n    assertTrue(locations.size > 20);\r\n    assertEquals(locations.size, counts.size);\r\n    assertEquals(locations.size, values.size);\r\n    int totalMembers = 0;\r\n    for (int i = 0; i < counts.size; i++) {\r\n        totalMembers += counts.get(i);\r\n    }\r\n    assertEquals(20 * 25, totalMembers);\r\n    for (int y = 0; y < peaks.height; y++) {\r\n        for (int x = 0; x < peaks.width; x++) {\r\n            int peak = peaks.get(x, y);\r\n            assertTrue(counts.get(peak) > 0);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.AssociateStereo2D.setSource",
	"Comment": "converts location into rectified coordinates and saved a reference to the description.",
	"Method": "void setSource(FastQueue<Point2D_F64> location,FastQueue<Desc> descriptions){\r\n    locationLeft.reset();\r\n    for (int i = 0; i < location.size; i++) {\r\n        Point2D_F64 orig = location.get(i);\r\n        Point2D_F64 rectified = locationLeft.grow();\r\n        leftImageToRect.compute(orig.x, orig.y, rectified);\r\n    }\r\n    this.descriptionsLeft = descriptions;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.helpers.Browser.openUrl",
	"Comment": "opens given url in users default browser of his operating system.should work for all operating systems, with fallback.",
	"Method": "boolean openUrl(String url){\r\n    if (Desktop.isDesktopSupported()) {\r\n        Desktop desktop = Desktop.getDesktop();\r\n        try {\r\n            desktop.browse(new URI(url));\r\n            return true;\r\n        } catch (IOException | URISyntaxException | UnsupportedOperationException e) {\r\n            e.printStackTrace();\r\n            return tryCrossPlatformOpenUrl(url);\r\n        }\r\n    } else {\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.impl.ImplOrientationAverageGradientIntegral.computeUnweighted",
	"Comment": "compute the gradient while checking for border conditions",
	"Method": "double computeUnweighted(double tl_x,double tl_y,double samplePeriod,SparseImageGradient<T, G> g){\r\n    tl_x += 0.5;\r\n    tl_y += 0.5;\r\n    double Dx = 0, Dy = 0;\r\n    for (int y = 0; y < sampleWidth; y++) {\r\n        int pixelsY = (int) (tl_y + y * samplePeriod);\r\n        for (int x = 0; x < sampleWidth; x++) {\r\n            int pixelsX = (int) (tl_x + x * samplePeriod);\r\n            GradientValue v = g.compute(pixelsX, pixelsY);\r\n            Dx += v.getX();\r\n            Dy += v.getY();\r\n        }\r\n    }\r\n    return Math.atan2(Dy, Dx);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.TestPairwiseImageMatching.withIslands",
	"Comment": "the graph will not be fully connected in this scenario. there are two independent islands",
	"Method": "void withIslands(){\r\n    MockDetector detector = new MockDetector();\r\n    PairwiseImageMatching alg = create(detector);\r\n    alg.getConfigRansac().maxIterations = 100;\r\n    String cameraName = \"camera\";\r\n    Map<String, Point2Transform2_F64> camerasPixelToNorm = new HashMap();\r\n    camerasPixelToNorm.put(cameraName, new LensDistortionRadialTangential(intrinsic).undistort_F64(true, false));\r\n    alg.addCamera(cameraName, camerasPixelToNorm.get(cameraName), intrinsic);\r\n    for (int i = 0; i < 7; i++) {\r\n        double x = i < 5 ? 0 : 10000 + 0.5 * 5;\r\n        Se3_F64 cameraToWorld = SpecialEuclideanOps_F64.eulerXyz(x - 0.5 * i, 0, 0, 0, 0, 0, null);\r\n        detector.cameraToWorld.set(cameraToWorld);\r\n        alg.addImage(new GrayF32(intrinsic.width, intrinsic.height), cameraName);\r\n    }\r\n    assertTrue(alg.process());\r\n    PairwiseImageGraph graph = alg.getGraph();\r\n    assertEquals(7, graph.nodes.size());\r\n    assertEquals(4 + 3 + 2 + 1 + 1, graph.edges.size());\r\n    for (int i = 0; i < 5; i++) {\r\n        PairwiseImageGraph.View n = graph.nodes.get(i);\r\n        assertEquals(4, n.connections.size());\r\n        assertTrue(n.observationNorm.size <= 400 && n.observationNorm.size >= 300);\r\n    }\r\n    for (int i = 5; i < 7; i++) {\r\n        PairwiseImageGraph.View n = graph.nodes.get(i);\r\n        assertEquals(1, n.connections.size());\r\n        assertTrue(n.observationNorm.size <= 400 && n.observationNorm.size >= 300);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.EnforceTrifocalGeometry.process",
	"Comment": "computes a trifocal tensor which minimizes the algebraic error given the\ttwo epipoles and the linear constraint matrix.the epipoles are from a previously\tcomputed trifocal tensor.",
	"Method": "void process(Point3D_F64 e2,Point3D_F64 e3,DMatrixRMaj A){\r\n    constructE(e2, e3);\r\n    svdU.decompose(E);\r\n    svdU.getU(U, false);\r\n    SingularOps_DDRM.descendingOrder(U, false, svdU.getSingularValues(), svdU.numberOfSingularValues(), null, false);\r\n    int rank = SingularOps_DDRM.rank(svdU, 1e-13);\r\n    Up.reshape(U.numRows, rank);\r\n    CommonOps_DDRM.extract(U, 0, U.numRows, 0, Up.numCols, Up, 0, 0);\r\n    AU.reshape(A.numRows, Up.numCols);\r\n    CommonOps_DDRM.mult(A, Up, AU);\r\n    svdV.decompose(AU);\r\n    xp.reshape(rank, 1);\r\n    SingularOps_DDRM.nullVector(svdV, true, xp);\r\n    CommonOps_DDRM.mult(Up, xp, vectorT);\r\n    if (vectorT.data[0] > 0)\r\n        CommonOps_DDRM.changeSign(vectorT);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.TestEllipseClustersIntoGrid.createRegularGrid",
	"Comment": "creates a regular grid of nodes and sets up the angle and neighbors correctly",
	"Method": "Tuple2<List<Node>, List<EllipseRotated_F64>> createRegularGrid(int rows,int cols){\r\n    List<EllipseRotated_F64> ellipses = new ArrayList();\r\n    for (int row = 0, i = 0; row < rows; row++) {\r\n        for (int col = 0; col < cols; col++, i++) {\r\n            ellipses.add(new EllipseRotated_F64(col, row, 0.1, 0.1, 0));\r\n        }\r\n    }\r\n    return connectEllipses(ellipses, 1.8);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.EstimateSceneCalibrated.convertToOutput",
	"Comment": "converts the internal data structures into the output format for bundle adjustment. camera models are omitted\tsince they are not available",
	"Method": "void convertToOutput(View origin){\r\n    structure = new SceneStructureMetric(false);\r\n    observations = new SceneObservations(viewsAdded.size());\r\n    int idx = 0;\r\n    for (String key : graph.cameras.keySet()) {\r\n        cameraToIndex.put(key, idx++);\r\n    }\r\n    structure.initialize(cameraToIndex.size(), viewsAdded.size(), graph.features3D.size());\r\n    for (String key : graph.cameras.keySet()) {\r\n        int i = cameraToIndex.get(key);\r\n        structure.setCamera(i, true, graph.cameras.get(key).pinhole);\r\n    }\r\n    int[] viewOldToView = new int[graph.nodes.size()];\r\n    Arrays.fill(viewOldToView, -1);\r\n    for (int i = 0; i < viewsAdded.size(); i++) {\r\n        viewOldToView[graph.nodes.indexOf(viewsAdded.get(i))] = i;\r\n    }\r\n    for (int i = 0; i < viewsAdded.size(); i++) {\r\n        View v = viewsAdded.get(i);\r\n        int cameraIndex = cameraToIndex.get(v.camera.camera);\r\n        structure.setView(i, v == origin, v.viewToWorld.invert(null));\r\n        structure.connectViewToCamera(i, cameraIndex);\r\n    }\r\n    for (int indexPoint = 0; indexPoint < graph.features3D.size(); indexPoint++) {\r\n        Feature3D f = graph.features3D.get(indexPoint);\r\n        structure.setPoint(indexPoint, f.worldPt.x, f.worldPt.y, f.worldPt.z);\r\n        if (f.views.size() != f.obsIdx.size)\r\n            throw new RuntimeException(\"BUG!\");\r\n        for (int j = 0; j < f.views.size(); j++) {\r\n            View view = f.views.get(j);\r\n            int viewIndex = viewOldToView[view.index];\r\n            structure.connectPointToView(indexPoint, viewIndex);\r\n            Point2D_F64 pixel = viewsAdded.get(viewIndex).observationPixels.get(f.obsIdx.get(j));\r\n            observations.getView(viewIndex).add(indexPoint, (float) (pixel.x), (float) (pixel.y));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.shouldAutoCaptureSessions",
	"Comment": "get whether or not user sessions are captured automatically.",
	"Method": "boolean shouldAutoCaptureSessions(){\r\n    return autoCaptureSessions;\r\n}"
}, {
	"Path": "boofcv.alg.geo.h.TestHomographyDirectLinearTransform.checkHomography",
	"Comment": "create a set of points perfectly on a plane and provide perfect observations of them",
	"Method": "void checkHomography(int N,boolean isPixels,HomographyDirectLinearTransform alg){\r\n    createScene(N, isPixels);\r\n    assertTrue(alg.process(pairs, solution));\r\n    assertTrue(NormOps_DDRM.normF(solution) > 0.001);\r\n    for (AssociatedPair p : pairs) {\r\n        Point2D_F64 a = GeometryMath_F64.mult(solution, p.p1, new Point2D_F64());\r\n        double diff = a.distance(p.p2);\r\n        assertEquals(0, diff, 1e-8);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.FeatureLaplacePyramid.checkMax",
	"Comment": "see if the best score is better than the local adjusted scores at this scale",
	"Method": "boolean checkMax(T image,double adj,double bestScore,int c_x,int c_y){\r\n    sparseLaplace.setImage(image);\r\n    boolean isMax = true;\r\n    beginLoop: for (int i = c_y - 1; i <= c_y + 1; i++) {\r\n        for (int j = c_x - 1; j <= c_x + 1; j++) {\r\n            double value = adj * sparseLaplace.compute(j, i);\r\n            if (value >= bestScore) {\r\n                isMax = false;\r\n                break beginLoop;\r\n            }\r\n        }\r\n    }\r\n    return isMax;\r\n}"
}, {
	"Path": "com.bugsnag.android.StrictModeHandler.isStrictModeThrowable",
	"Comment": "checks whether a throwable was originally thrown from the strictmode class",
	"Method": "boolean isStrictModeThrowable(Throwable throwable){\r\n    Throwable cause = getRootCause(throwable);\r\n    Class<? extends Throwable> causeClass = cause.getClass();\r\n    String simpleName = causeClass.getName();\r\n    return simpleName.toLowerCase(Locale.US).startsWith(STRICT_MODE_CLZ_NAME);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.TestEllipseClustersIntoGrid.computeNodeInfo",
	"Comment": "this test just checks to see if a node info is created for each node passed in and that\tthe ellipse is assinged to it.the inner functions are tested elsewhere",
	"Method": "void computeNodeInfo(){\r\n    List<Node> nodes = new ArrayList();\r\n    nodes.add(createNode(0, 1, 2, 3));\r\n    nodes.add(createNode(1, 0, 2, 4));\r\n    nodes.add(createNode(2, 0, 1));\r\n    nodes.add(createNode(3, 0));\r\n    nodes.add(createNode(4));\r\n    List<EllipseRotated_F64> ellipses = new ArrayList();\r\n    for (int i = 0; i < nodes.size(); i++) {\r\n        ellipses.add(new EllipseRotated_F64());\r\n    }\r\n    EllipseClustersIntoGrid alg = new HelperAlg();\r\n    alg.computeNodeInfo(ellipses, nodes);\r\n    assertEquals(nodes.size(), alg.listInfo.size);\r\n    for (int i = 0; i < nodes.size(); i++) {\r\n        assertTrue(ellipses.get(i) == alg.listInfo.get(i).ellipse);\r\n    }\r\n}"
}, {
	"Path": "org.boon.slumberdb.stores.log.CollectorManager.determineIfWeShouldExit",
	"Comment": "see if it is time to stopwe have been interrupted. should we ignore it or break out of the loop.",
	"Method": "boolean determineIfWeShouldExit(){\r\n    boolean shouldStop = stop.get();\r\n    if (!shouldStop) {\r\n        Thread.interrupted();\r\n    } else {\r\n        System.out.println(\"Exiting processing loop as requested\");\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.TestSnapToEllipseEdge.simpleNoChange",
	"Comment": "simple test case involving a fully rendered image and known result",
	"Method": "void simpleNoChange(){\r\n    EllipseRotated_F64 target = new EllipseRotated_F64(80, 85, 50, 40, 0);\r\n    EllipseRotated_F64 found = new EllipseRotated_F64();\r\n    List<EllipseRotated_F64> ellipses = new ArrayList();\r\n    ellipses.add(target);\r\n    GrayU8 image = TestBinaryEllipseDetectorPixel.renderEllipses_F64(200, 300, ellipses, 0);\r\n    SnapToEllipseEdge<GrayU8> alg = new SnapToEllipseEdge(30, 1, GrayU8.class);\r\n    alg.setImage(image);\r\n    assertTrue(alg.process(target, found));\r\n    TestBinaryEllipseDetectorPixel.checkEquals(target, found, 1.0, 0.01);\r\n}"
}, {
	"Path": "boofcv.examples.segmentation.ExampleSegmentColor.printClickedColor",
	"Comment": "shows a color image and allows the user to select a pixel, convert it to hsv, print\tthe hsv values, and calls the function below to display similar pixels.",
	"Method": "void printClickedColor(BufferedImage image){\r\n    ImagePanel gui = new ImagePanel(image);\r\n    gui.addMouseListener(new MouseAdapter() {\r\n        @Override\r\n        public void mouseClicked(MouseEvent e) {\r\n            float[] color = new float[3];\r\n            int rgb = image.getRGB(e.getX(), e.getY());\r\n            ColorHsv.rgbToHsv((rgb >> 16) & 0xFF, (rgb >> 8) & 0xFF, rgb & 0xFF, color);\r\n            System.out.println(\"H = \" + color[0] + \" S = \" + color[1] + \" V = \" + color[2]);\r\n            showSelectedColor(\"Selected\", image, color[0], color[1]);\r\n        }\r\n    });\r\n    ShowImages.showWindow(gui, \"Color Selector\");\r\n}"
}, {
	"Path": "boofcv.examples.segmentation.ExampleSegmentColor.printClickedColor",
	"Comment": "shows a color image and allows the user to select a pixel, convert it to hsv, print\tthe hsv values, and calls the function below to display similar pixels.",
	"Method": "void printClickedColor(BufferedImage image){\r\n    float[] color = new float[3];\r\n    int rgb = image.getRGB(e.getX(), e.getY());\r\n    ColorHsv.rgbToHsv((rgb >> 16) & 0xFF, (rgb >> 8) & 0xFF, rgb & 0xFF, color);\r\n    System.out.println(\"H = \" + color[0] + \" S = \" + color[1] + \" V = \" + color[2]);\r\n    showSelectedColor(\"Selected\", image, color[0], color[1]);\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.ImplDisparityScoreSadRectFive_F32.computeFirstRow",
	"Comment": "initializes disparity calculation by finding the scores for the initial block of horizontal\trows.",
	"Method": "void computeFirstRow(GrayF32 left,GrayF32 right){\r\n    float[] firstRow = verticalScore[0];\r\n    activeVerticalScore = 1;\r\n    for (int row = 0; row < regionHeight; row++) {\r\n        float[] scores = horizontalScore[row];\r\n        UtilDisparityScore.computeScoreRow(left, right, row, scores, minDisparity, maxDisparity, regionWidth, elementScore);\r\n    }\r\n    for (int i = 0; i < lengthHorizontal; i++) {\r\n        float sum = 0;\r\n        for (int row = 0; row < regionHeight; row++) {\r\n            sum += horizontalScore[row][i];\r\n        }\r\n        firstRow[i] = sum;\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.PackedSetsPoint2D_I32.sizeOfTail",
	"Comment": "returns the size of the set at the tail. if there is no tail an exception will be thrown.",
	"Method": "int sizeOfTail(){\r\n    return tail.length;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.TestQrCodePositionPatternDetector.considerConnect_negative_rotated",
	"Comment": "the two patterns are rotated 45 degrees relative to each other",
	"Method": "void considerConnect_negative_rotated(){\r\n    QrCodePositionPatternDetector<GrayF32> alg = createAlg();\r\n    SquareNode n0 = squareNode(40, 60, 70);\r\n    SquareNode n1 = squareNode(140, 60, 70);\r\n    Se2_F64 translate = new Se2_F64(-175, -95, 0);\r\n    Se2_F64 rotate = new Se2_F64(0, 0, UtilAngle.radian(45));\r\n    Se2_F64 tmp = translate.concat(rotate, null);\r\n    Se2_F64 combined = tmp.concat(translate.invert(null), null);\r\n    for (int i = 0; i < 4; i++) {\r\n        SePointOps_F64.transform(combined, n1.square.get(i), n1.square.get(i));\r\n    }\r\n    SePointOps_F64.transform(combined, n1.center, n1.center);\r\n    alg.considerConnect(n0, n1);\r\n    assertEquals(0, n0.getNumberOfConnections());\r\n    assertEquals(0, n1.getNumberOfConnections());\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.template.TemplateMatching.setImage",
	"Comment": "specifies the input image which the template is to be found inside.",
	"Method": "void setImage(T image){\r\n    match.setInputImage(image);\r\n    this.imageWidth = image.width;\r\n    this.imageHeight = image.height;\r\n}"
}, {
	"Path": "boofcv.factory.feature.describe.FactoryDescribeRegionPoint.pixelNCC",
	"Comment": "creates a region descriptor based on normalized pixel intensity values alone.this descriptor\tis designed to be light invariance, but is still less stable than more modern ones.",
	"Method": "DescribeRegionPoint<T, NccFeature> pixelNCC(int regionWidth,int regionHeight,Class<T> imageType){\r\n    return new WrapDescribePixelRegionNCC(FactoryDescribePointAlgs.pixelRegionNCC(regionWidth, regionHeight, imageType), imageType);\r\n}"
}, {
	"Path": "boofcv.alg.geo.TestRectifyImageOps.transform_PixelToRect_and_RectToPixel_F32",
	"Comment": "transforms and then performs the inverse transform to distorted rectified pixel",
	"Method": "void transform_PixelToRect_and_RectToPixel_F32(){\r\n    CameraPinholeRadial param = new CameraPinholeRadial().fsetK(300, 320, 0, 150, 130, width, height).fsetRadial(0.1, 1e-4);\r\n    FMatrixRMaj rect = new FMatrixRMaj(3, 3, true, 1.1f, 0, 0, 0, 2, 0, 0.1f, 0, 3);\r\n    Point2Transform2_F32 forward = RectifyImageOps.transformPixelToRect(param, rect);\r\n    Point2Transform2_F32 inverse = RectifyImageOps.transformRectToPixel(param, rect);\r\n    float x = 20, y = 30;\r\n    Point2D_F32 out = new Point2D_F32();\r\n    forward.compute(x, y, out);\r\n    assertTrue(Math.abs(x - out.x) > 1e-4);\r\n    assertTrue(Math.abs(y - out.y) > 1e-4);\r\n    inverse.compute(out.x, out.y, out);\r\n    assertEquals(x, out.x, 1e-4);\r\n    assertEquals(y, out.y, 1e-4);\r\n}"
}, {
	"Path": "boofcv.abst.feature.detdesc.GenericTestsDetectDescribePoint.detectFeatures",
	"Comment": "detects features inside the image and checks to see if it is in compliance of its reported capabilities",
	"Method": "void detectFeatures(){\r\n    DetectDescribePoint<T, D> alg = createDetDesc();\r\n    for (int imageIndex = 0; imageIndex < 10; imageIndex++) {\r\n        int numScaleNotOne = 0;\r\n        int numOrientationNotZero = 0;\r\n        GImageMiscOps.fillUniform(image, rand, 0, 100);\r\n        alg.detect(image);\r\n        int N = alg.getNumberOfFeatures();\r\n        assertTrue(N > 5);\r\n        for (int i = 0; i < N; i++) {\r\n            Point2D_F64 p = alg.getLocation(i);\r\n            double radius = alg.getRadius(i);\r\n            double angle = alg.getOrientation(i);\r\n            D desc = alg.getDescription(i);\r\n            for (int j = 0; j < desc.size(); j++) {\r\n                assertTrue(!Double.isNaN(desc.getDouble(j)) && !Double.isInfinite(desc.getDouble(j)));\r\n            }\r\n            assertTrue(desc != null);\r\n            assertTrue(p.x != 0 && p.y != 0);\r\n            assertTrue(p.x >= 0 && p.y >= 0 && p.x < image.width && p.y < image.height);\r\n            if (radius != 1)\r\n                numScaleNotOne++;\r\n            if (angle != 0)\r\n                numOrientationNotZero++;\r\n        }\r\n        if (hasScale)\r\n            assertTrue(numScaleNotOne > 0);\r\n        else\r\n            assertTrue(numScaleNotOne == 0);\r\n        if (hasOrientation)\r\n            assertTrue(numOrientationNotZero > 0);\r\n        else\r\n            assertTrue(numOrientationNotZero == 0);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.scene.FeatureToWordHistogram_F64.getHistogram",
	"Comment": "histogram of word frequencies.normalized such that the sum is equal to 1.",
	"Method": "double[] getHistogram(){\r\n    if (!processed)\r\n        throw new RuntimeException(\"Must call process first before histogram is valid\");\r\n    return histogram;\r\n}"
}, {
	"Path": "boofcv.examples.stereo.ExampleFundamentalMatrix.simpleFundamental",
	"Comment": "if the set of associated features are known to be correct, then the fundamental matrix can\tbe computed directly with a lot less code.the down side is that this technique is very\tsensitive to noise.",
	"Method": "DMatrixRMaj simpleFundamental(List<AssociatedPair> matches){\r\n    Estimate1ofEpipolar estimateF = FactoryMultiView.fundamental_1(EnumFundamental.LINEAR_8, 0);\r\n    DMatrixRMaj F = new DMatrixRMaj(3, 3);\r\n    if (!estimateF.process(matches, F))\r\n        throw new IllegalArgumentException(\"Failed\");\r\n    return F;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.TestGeneralFeatureDetector.candidatesMissMatch",
	"Comment": "if an extractor requires candidates the intensity image needs to provide them.",
	"Method": "void candidatesMissMatch(){\r\n    HelperIntensity intensity = new HelperIntensity(false, false, false);\r\n    HelperExtractor extractor = new HelperExtractor(true, true);\r\n    assertThrows(IllegalArgumentException.class, () -> new GeneralFeatureDetector(intensity, extractor));\r\n}"
}, {
	"Path": "org.boon.validation.readers.PropertiesFileValidatorMetaDataReader.loadMetaDataPropsFile",
	"Comment": "this method loads the metadata properties file. the properties are cachedin metadatapropscache and will not be reloaded twice.",
	"Method": "Properties loadMetaDataPropsFile(Class<?> clazzWhoseValidationMetaDataWeAreReading){\r\n    String className = clazzWhoseValidationMetaDataWeAreReading.getName();\r\n    className = className.split(\"[$]\")[0];\r\n    String[] sourceParts = className.split(\"[.]\");\r\n    String resourceName = (sourceParts[sourceParts.length - 1]) + \".properties\";\r\n    Properties validationMetaDataProps = metaDataPropsCache.get(resourceName);\r\n    if (validationMetaDataProps == null) {\r\n        validationMetaDataProps = new Properties();\r\n        try {\r\n            validationMetaDataProps.load(this.getClass().getClassLoader().getResourceAsStream(resourceName));\r\n        } catch (IOException ioex) {\r\n        }\r\n        metaDataPropsCache.put(resourceName, validationMetaDataProps);\r\n    }\r\n    assert validationMetaDataProps != null : \"Properties for validation meta-data were loaded\";\r\n    return validationMetaDataProps;\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.DescribeDenseHogFastAlg.getDescriptorsInRegion",
	"Comment": "convenience function which returns a list of all the descriptors computed inside the specified region in the image",
	"Method": "void getDescriptorsInRegion(int pixelX0,int pixelY0,int pixelX1,int pixelY1,List<TupleDesc_F64> output){\r\n    int gridX0 = (int) Math.ceil(pixelX0 / (double) pixelsPerCell);\r\n    int gridY0 = (int) Math.ceil(pixelY0 / (double) pixelsPerCell);\r\n    int gridX1 = pixelX1 / pixelsPerCell - cellsPerBlockX;\r\n    int gridY1 = pixelY1 / pixelsPerCell - cellsPerBlockY;\r\n    for (int y = gridY0; y <= gridY1; y++) {\r\n        int index = y * cellCols + gridX0;\r\n        for (int x = gridX0; x <= gridX1; x++) {\r\n            output.add(descriptions.get(index++));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.NarrowToWidePtoP_F64.setRotationWideToNarrow",
	"Comment": "specifies rotation matrix which determines the pointing direction of the camera",
	"Method": "void setRotationWideToNarrow(DMatrixRMaj R){\r\n    this.rotateWideToNarrow.set(R);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.TestConnectLinesGrid.checkTangentTolerance",
	"Comment": "makes sure the tangent distance tolerance parameter is correctly set and processed",
	"Method": "void checkTangentTolerance(){\r\n    MatrixOfList<LineSegment2D_F32> grid = new MatrixOfList(1, 1);\r\n    grid.get(0, 0).add(new LineSegment2D_F32(0, 0, 2, 0));\r\n    grid.get(0, 0).add(new LineSegment2D_F32(2, 1, 4, 1));\r\n    ConnectLinesGrid app = new ConnectLinesGrid(2, 0.1, 2);\r\n    app.process(grid);\r\n    assertEquals(2, grid.createSingleList().size());\r\n    app = new ConnectLinesGrid(2, 1.1, 2);\r\n    app.process(grid);\r\n    assertEquals(1, grid.createSingleList().size());\r\n}"
}, {
	"Path": "boofcv.alg.distort.radtan.RemoveRadialNtoN_F32.removeRadial",
	"Comment": "static function for removing radial and tangential distortion",
	"Method": "void removeRadial(float x,float y,float[] radial,float t1,float t2,Point2D_F32 out,float tol){\r\n    float origX = x;\r\n    float origY = y;\r\n    float prevSum = 0;\r\n    for (int iter = 0; iter < 500; iter++) {\r\n        float r2 = x * x + y * y;\r\n        float ri2 = r2;\r\n        float sum = 0;\r\n        for (int i = 0; i < radial.length; i++) {\r\n            sum += radial[i] * ri2;\r\n            ri2 *= r2;\r\n        }\r\n        float tx = 2.0f * t1 * x * y + t2 * (r2 + 2.0f * x * x);\r\n        float ty = t1 * (r2 + 2.0f * y * y) + 2.0f * t2 * x * y;\r\n        x = (origX - tx) / (1.0f + sum);\r\n        y = (origY - ty) / (1.0f + sum);\r\n        if ((float) Math.abs(prevSum - sum) <= tol) {\r\n            break;\r\n        } else {\r\n            prevSum = sum;\r\n        }\r\n    }\r\n    out.set(x, y);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.CachedConnectionStrategy.threadWatch",
	"Comment": "keep track of this handle tied to which thread so that if the thread is terminated\twe can reclaim our connection handle. we also",
	"Method": "void threadWatch(ConnectionHandle c){\r\n    this.threadFinalizableRefs.put(c, new FinalizableWeakReference<Thread>(Thread.currentThread(), this.finalizableRefQueue) {\r\n        public void finalizeReferent() {\r\n            try {\r\n                if (!CachedConnectionStrategy.this.pool.poolShuttingDown) {\r\n                    logger.debug(\"Monitored thread is dead, closing off allocated connection.\");\r\n                }\r\n                c.internalClose();\r\n            } catch (SQLException e) {\r\n                e.printStackTrace();\r\n            }\r\n            CachedConnectionStrategy.this.threadFinalizableRefs.remove(c);\r\n        }\r\n    });\r\n}"
}, {
	"Path": "com.jolbox.bonecp.CachedConnectionStrategy.threadWatch",
	"Comment": "keep track of this handle tied to which thread so that if the thread is terminated\twe can reclaim our connection handle. we also",
	"Method": "void threadWatch(ConnectionHandle c){\r\n    try {\r\n        if (!CachedConnectionStrategy.this.pool.poolShuttingDown) {\r\n            logger.debug(\"Monitored thread is dead, closing off allocated connection.\");\r\n        }\r\n        c.internalClose();\r\n    } catch (SQLException e) {\r\n        e.printStackTrace();\r\n    }\r\n    CachedConnectionStrategy.this.threadFinalizableRefs.remove(c);\r\n}"
}, {
	"Path": "boofcv.alg.background.BackgroundGmmCommon.updateWeightAndPrune",
	"Comment": "updates the weight of each gaussian and prunes one which have a negative weight after the update.",
	"Method": "void updateWeightAndPrune(float[] dataRow,int modelIndex,int ng,int bestIndex,float bestWeight){\r\n    int index = modelIndex;\r\n    float weightTotal = 0;\r\n    for (int i = 0; i < ng; ) {\r\n        float weight = dataRow[index];\r\n        weight = weight - learningRate * (weight + decay);\r\n        if (weight <= 0) {\r\n            int indexLast = modelIndex + (ng - 1) * gaussianStride;\r\n            for (int j = 0; j < gaussianStride; j++) {\r\n                dataRow[index + j] = dataRow[indexLast + j];\r\n            }\r\n            if (indexLast == bestIndex)\r\n                bestIndex = index;\r\n            dataRow[indexLast + 1] = 0;\r\n            ng -= 1;\r\n        } else {\r\n            dataRow[index] = weight;\r\n            weightTotal += weight;\r\n            index += gaussianStride;\r\n            i++;\r\n        }\r\n    }\r\n    if (bestIndex != -1) {\r\n        weightTotal -= dataRow[bestIndex];\r\n        weightTotal += bestWeight;\r\n        dataRow[bestIndex] = bestWeight;\r\n    }\r\n    index = modelIndex;\r\n    for (int i = 0; i < ng; i++, index += gaussianStride) {\r\n        dataRow[index] /= weightTotal;\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCP.getTotalCreatedConnections",
	"Comment": "return total number of connections created in all partitions.",
	"Method": "int getTotalCreatedConnections(){\r\n    int total = 0;\r\n    for (int i = 0; i < this.partitionCount && this.partitions[i] != null; i++) {\r\n        total += this.partitions[i].getCreatedConnections();\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "boofcv.examples.features.ExampleDenseImageFeatures.HighLevel",
	"Comment": "for much larger images you might need to shrink the image down or change the cell size to get good results.",
	"Method": "void HighLevel(GrayF32 input){\r\n    System.out.println(\"\\n------------------- Dense High Level\");\r\n    DescribeImageDense<GrayF32, TupleDesc_F64> describer = FactoryDescribeImageDense.hog(new ConfigDenseHoG(), input.getImageType());\r\n    describer.process(input);\r\n    System.out.println(\"Total Features = \" + describer.getLocations().size());\r\n    for (int i = 0; i < 5; i++) {\r\n        Point2D_I32 p = describer.getLocations().get(i);\r\n        TupleDesc_F64 d = describer.getDescriptions().get(i);\r\n        System.out.printf(\"= = = [ %f %f %f %f\\n\", p.x, p.y, d.value[0], d.value[1], d.value[2], d.value[3]);\r\n    }\r\n}"
}, {
	"Path": "boofcv.examples.features.ExampleAssociatePoints.describeImage",
	"Comment": "detects features inside the two images and computes descriptions at those points.",
	"Method": "void describeImage(T input,List<Point2D_F64> points,FastQueue<TD> descs){\r\n    detDesc.detect(input);\r\n    for (int i = 0; i < detDesc.getNumberOfFeatures(); i++) {\r\n        points.add(detDesc.getLocation(i).copy());\r\n        descs.grow().setTo(detDesc.getDescription(i));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.findInitialTriangle",
	"Comment": "select an initial triangle. a good initial triangle is needed. by good it\tshould minimize the error of the contour from each side",
	"Method": "boolean findInitialTriangle(List<Point2D_I32> contour){\r\n    int cornerSeed = findCornerSeed(contour);\r\n    if (convex) {\r\n        if (!isConvexUsingMaxDistantPoints(contour, 0, cornerSeed))\r\n            return false;\r\n    }\r\n    splitter.selectSplitPoint(contour, 0, cornerSeed, resultsA);\r\n    splitter.selectSplitPoint(contour, cornerSeed, 0, resultsB);\r\n    if (splitter.compareScore(resultsA.score, resultsB.score) >= 0) {\r\n        addCorner(resultsA.index);\r\n        addCorner(cornerSeed);\r\n    } else {\r\n        addCorner(cornerSeed);\r\n        addCorner(resultsB.index);\r\n    }\r\n    int index0 = list.getHead().object.index;\r\n    int index1 = list.getHead().next.object.index;\r\n    int index2 = maximumDistance(contour, index0, index1);\r\n    addCorner(index2);\r\n    ensureTriangleOrder(contour);\r\n    return initializeScore(contour, true);\r\n}"
}, {
	"Path": "boofcv.alg.misc.ImageStatistics.variance",
	"Comment": "computes the variance of pixel intensity values inside the image.",
	"Method": "double variance(GrayU8 img,double mean,double variance,GrayS8 img,double mean,double variance,GrayU16 img,double mean,double variance,GrayS16 img,double mean,double variance,GrayS32 img,double mean,double variance,GrayS64 img,double mean,float variance,GrayF32 img,float mean,double variance,GrayF64 img,double mean){\r\n    double variance = 0;\r\n    for (int y = 0; y < img.height; y++) {\r\n        int index = img.getStartIndex() + y * img.getStride();\r\n        int indexEnd = index + img.width;\r\n        for (; index < indexEnd; index++) {\r\n            double d = (img.data[index]) - mean;\r\n            variance += d * d;\r\n        }\r\n    }\r\n    return variance / (img.width * img.height);\r\n}"
}, {
	"Path": "boofcv.alg.transform.wavelet.impl.TestImplWaveletTransformNaive.encodeDecode_F32",
	"Comment": "see if it can handle odd image sizes and output with extra padding",
	"Method": "void encodeDecode_F32(){\r\n    testEncodeDecode_F32(20, 30, 20, 30);\r\n    testEncodeDecode_F32(19, 29, 20, 30);\r\n    testEncodeDecode_F32(19, 29, 22, 32);\r\n    testEncodeDecode_F32(19, 29, 24, 34);\r\n    testEncodeDecode_F32(20, 30, 24, 34);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.getQueryExecuteTimeLimit",
	"Comment": "returns the queryexecutetimelimit setting with the specified granularity.",
	"Method": "long getQueryExecuteTimeLimit(long getQueryExecuteTimeLimit,TimeUnit timeUnit){\r\n    return timeUnit.convert(this.queryExecuteTimeLimitInMs, TimeUnit.MILLISECONDS);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoPlaneInfinity.maximizeCountInSpread",
	"Comment": "finds the value which has the largest number of points above and below it within the specified spread",
	"Method": "double maximizeCountInSpread(double[] data,int size,double maxSpread){\r\n    if (size <= 0)\r\n        return 0;\r\n    Arrays.sort(data, 0, size);\r\n    int length = 0;\r\n    for (; length < size; length++) {\r\n        double s = UtilAngle.dist(data[0], data[length]);\r\n        if (s > maxSpread) {\r\n            break;\r\n        }\r\n    }\r\n    int bestStart = 0;\r\n    int bestLength = length;\r\n    int start;\r\n    for (start = 1; start < size && length < size; start++) {\r\n        length--;\r\n        while (length < size) {\r\n            double s = UtilAngle.dist(data[start], data[(start + length) % size]);\r\n            if (s > maxSpread) {\r\n                break;\r\n            } else {\r\n                length++;\r\n            }\r\n        }\r\n        if (length > bestLength) {\r\n            bestLength = length;\r\n            bestStart = start;\r\n        }\r\n    }\r\n    return data[(bestStart + bestLength / 2) % size];\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeCodeWordLocations.computeBitLocations",
	"Comment": "snakes through and specifies the location of each bit for all the code words in the grid.",
	"Method": "void computeBitLocations(){\r\n    int N = numRows;\r\n    int row = N - 1;\r\n    int col = N - 1;\r\n    int direction = -1;\r\n    while (col > 0) {\r\n        if (col == 6)\r\n            col -= 1;\r\n        if (!get(row, col)) {\r\n            bits.add(new Point2D_I32(col, row));\r\n        }\r\n        if (!get(row, col - 1)) {\r\n            bits.add(new Point2D_I32(col - 1, row));\r\n        }\r\n        row += direction;\r\n        if (row < 0 || row >= N) {\r\n            direction = -direction;\r\n            col -= 2;\r\n            row += direction;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestBoneCP.testGetConnectionOnShutdownPool",
	"Comment": "attempting to fetch a connection from a pool that is marked as being shut down should throw an exception",
	"Method": "void testGetConnectionOnShutdownPool(){\r\n    testClass.poolShuttingDown = true;\r\n    try {\r\n        testClass.getConnection();\r\n        fail(\"Should have thrown an exception\");\r\n    } catch (SQLException e) {\r\n    }\r\n}"
}, {
	"Path": "boofcv.app.calib.ImageSelectorAndSaver.setTemplate",
	"Comment": "creates a template of the fiducial and this is then used to determine how blurred the image is",
	"Method": "void setTemplate(GrayF32 image,List<Point2D_F64> sides){\r\n    if (sides.size() != 4)\r\n        throw new IllegalArgumentException(\"Expected 4 sidesCollision\");\r\n    removePerspective.apply(image, sides.get(0), sides.get(1), sides.get(2), sides.get(3));\r\n    templateOriginal.setTo(removePerspective.getOutput());\r\n    GrayF32 blurred = new GrayF32(LENGTH, LENGTH);\r\n    BlurImageOps.gaussian(templateOriginal, blurred, -1, 2, null);\r\n    GrayF32 derivX = new GrayF32(LENGTH, LENGTH);\r\n    GrayF32 derivY = new GrayF32(LENGTH, LENGTH);\r\n    GImageDerivativeOps.gradient(DerivativeType.SOBEL, blurred, derivX, derivY, BorderType.EXTENDED);\r\n    GGradientToEdgeFeatures.intensityE(derivX, derivY, weights);\r\n    float max = ImageStatistics.max(weights);\r\n    PixelMath.divide(weights, max, weights);\r\n    totalWeight = ImageStatistics.sum(weights);\r\n    template.setTo(removePerspective.getOutput());\r\n    float mean = (float) ImageStatistics.mean(template);\r\n    PixelMath.divide(template, mean, template);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareGraph.connect",
	"Comment": "creates a new edge which will connect the two nodes.the side on each node which is connected\tis specified by the indexes.",
	"Method": "void connect(SquareNode a,int indexA,SquareNode b,int indexB,double distance){\r\n    SquareEdge edge = edgeManager.requestInstance();\r\n    edge.reset();\r\n    edge.a = a;\r\n    edge.sideA = indexA;\r\n    edge.b = b;\r\n    edge.sideB = indexB;\r\n    edge.distance = distance;\r\n    a.edges[indexA] = edge;\r\n    b.edges[indexB] = edge;\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedS32.getBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "int getBand(int x,int y,int band){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    return data[getIndex(x, y, band)];\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.chess.DetectChessboardSquarePoints.process",
	"Comment": "detects chessboard in the binary image.square corners must be disconnected.\treturns true if a chessboard was found, false otherwise.",
	"Method": "boolean process(T input,GrayU8 binary){\r\n    double maxCornerDistancePixels = maxCornerDistance.computeI(Math.min(input.width, input.height));\r\n    s2c.setMaxCornerDistance(maxCornerDistancePixels);\r\n    configureContourDetector(input);\r\n    boundPolygon.vertexes.reset();\r\n    detectorSquare.process(input, binary);\r\n    detectorSquare.refineAll();\r\n    List<DetectPolygonFromContour.Info> found = detectorSquare.getPolygonInfo();\r\n    clusters = s2c.process(found);\r\n    c2g.process(clusters);\r\n    List<SquareGrid> grids = c2g.getGrids().toList();\r\n    for (int i = 0; i < grids.size(); i++) {\r\n        SquareGrid grid = grids.get(i);\r\n        if (grid.rows == numCols && grid.columns == numRows) {\r\n            tools.transpose(grid);\r\n        }\r\n        if (grid.rows == numRows && grid.columns == numCols) {\r\n            if (grid.get(0, 0) == null) {\r\n                if (grid.get(0, -1) != null) {\r\n                    tools.flipColumns(grid);\r\n                } else if (grid.get(-1, 0) != null) {\r\n                    tools.flipRows(grid);\r\n                } else {\r\n                    continue;\r\n                }\r\n            }\r\n            if (!ensureCCW(grid))\r\n                continue;\r\n            putIntoCanonical(grid);\r\n            return computeCalibrationPoints(grid);\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.examples.recognition.ExampleClassifySceneKnn.computeClusters",
	"Comment": "extract dense features across the training set.then clusters are found within those features.",
	"Method": "AssignCluster<double[]> computeClusters(){\r\n    System.out.println(\"Image Features\");\r\n    List<TupleDesc_F64> features = new ArrayList();\r\n    for (String scene : train.keySet()) {\r\n        List<String> imagePaths = train.get(scene);\r\n        System.out.println(\"   \" + scene);\r\n        for (String path : imagePaths) {\r\n            GrayU8 image = UtilImageIO.loadImage(path, GrayU8.class);\r\n            describeImage.process(image);\r\n            for (TupleDesc_F64 d : describeImage.getDescriptions()) {\r\n                features.add(d.copy());\r\n            }\r\n        }\r\n    }\r\n    for (int i = 0; i < features.size(); i++) {\r\n        cluster.addReference(features.get(i));\r\n    }\r\n    System.out.println(\"Clustering\");\r\n    cluster.process(NUMBER_OF_WORDS);\r\n    UtilIO.save(cluster.getAssignment(), CLUSTER_FILE_NAME);\r\n    return cluster.getAssignment();\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TrifocalTransfer.transfer_1_to_3",
	"Comment": "transfer a point to third view give its observed location in view one and two.",
	"Method": "void transfer_1_to_3(double x1,double y1,double x2,double y2,Point3D_F64 p3){\r\n    adjuster.process(F21, x1, y1, x2, y2, pa, pb);\r\n    GeometryMath_F64.mult(F21, pa, la);\r\n    l.x = la.y;\r\n    l.y = -la.x;\r\n    l.z = -pb.x * la.y + pb.y * la.x;\r\n    MultiViewOps.transfer_1_to_3(tensor, pa, l, p3);\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TrifocalTransfer.transfer_1_to_2",
	"Comment": "transfer a point to third view give its observed location in view one and three.",
	"Method": "void transfer_1_to_2(double x1,double y1,double x3,double y3,Point3D_F64 p2){\r\n    adjuster.process(F31, x1, y1, x3, y3, pa, pb);\r\n    GeometryMath_F64.multTran(F31, pa, la);\r\n    l.x = la.y;\r\n    l.y = -la.x;\r\n    l.z = -pb.x * la.y + pb.y * la.x;\r\n    MultiViewOps.transfer_1_to_2(tensor, pa, l, p2);\r\n}"
}, {
	"Path": "boofcv.alg.geo.bundle.BundleAdjustmentMetricResidualFunction.configure",
	"Comment": "specifies the scenes structure and observed feature locations",
	"Method": "void configure(SceneStructureMetric structure,SceneObservations observations){\r\n    this.structure = structure;\r\n    this.observations = observations;\r\n    numObservations = observations.getObservationCount();\r\n    numParameters = structure.getParameterCount();\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.border.TestConvolveJustBorder_General_IL.compareToNoBorder",
	"Comment": "compare the results along the border to the results obtained by convolving a larger image with the noborder algorithm\twhose border has been filled with the fillvalue.",
	"Method": "void compareToNoBorder(){\r\n    performTests(9);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.LineImageOps.convert",
	"Comment": "find the point in which the line intersects the image border and create a line segment at those points",
	"Method": "LineSegment2D_F32 convert(LineParametric2D_F32 l,int width,int height){\r\n    double t0 = (0 - l.p.x) / l.getSlopeX();\r\n    double t1 = (0 - l.p.y) / l.getSlopeY();\r\n    double t2 = (width - l.p.x) / l.getSlopeX();\r\n    double t3 = (height - l.p.y) / l.getSlopeY();\r\n    Point2D_F32 a = computePoint(l, t0);\r\n    Point2D_F32 b = computePoint(l, t1);\r\n    Point2D_F32 c = computePoint(l, t2);\r\n    Point2D_F32 d = computePoint(l, t3);\r\n    List<Point2D_F32> inside = new ArrayList();\r\n    checkAddInside(width, height, a, inside);\r\n    checkAddInside(width, height, b, inside);\r\n    checkAddInside(width, height, c, inside);\r\n    checkAddInside(width, height, d, inside);\r\n    if (inside.size() != 2) {\r\n        return null;\r\n    }\r\n    return new LineSegment2D_F32(inside.get(0), inside.get(1));\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.TestCannyEdgeDynamic.canHandleNoTexture",
	"Comment": "test the pathological case where the input image has no texture.the threshold will be zero and the\tedge intensity will be zero everywhere.",
	"Method": "void canHandleNoTexture(){\r\n    GrayU8 input = new GrayU8(width, height);\r\n    GrayU8 output = new GrayU8(width, height);\r\n    ImageMiscOps.fill(output, 2);\r\n    CannyEdge<GrayU8, GrayS16> alg = FactoryEdgeDetectors.canny(2, false, true, GrayU8.class, GrayS16.class);\r\n    alg.process(input, 0.075f, 0.3f, output);\r\n    for (int i = 0; i < output.data.length; i++) {\r\n        assertEquals(0, output.data[i]);\r\n    }\r\n    alg = FactoryEdgeDetectors.canny(2, true, true, GrayU8.class, GrayS16.class);\r\n    ImageMiscOps.fill(output, 2);\r\n    alg.process(input, 0.075f, 0.3f, output);\r\n    List<EdgeContour> contour = alg.getContours();\r\n    assertTrue(contour.size() == 0);\r\n    for (int i = 0; i < output.data.length; i++) assertEquals(0, output.data[i]);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.ConnectLinesGrid.findBestCompatible",
	"Comment": "searches for a line in the list which the target is compatible with and can\tbe connected to.",
	"Method": "int findBestCompatible(LineSegment2D_F32 target,List<LineSegment2D_F32> candidates,int start){\r\n    int bestIndex = -1;\r\n    double bestDistance = Double.MAX_VALUE;\r\n    int bestFarthest = 0;\r\n    float targetAngle = UtilAngle.atanSafe(target.slopeY(), target.slopeX());\r\n    float cos = (float) Math.cos(targetAngle);\r\n    float sin = (float) Math.sin(targetAngle);\r\n    for (int i = start; i < candidates.size(); i++) {\r\n        LineSegment2D_F32 c = candidates.get(i);\r\n        float angle = UtilAngle.atanSafe(c.slopeY(), c.slopeX());\r\n        if (UtilAngle.distHalf(targetAngle, angle) > lineSlopeAngleTol)\r\n            continue;\r\n        closestFarthestPoints(target, c);\r\n        Point2D_F32 pt0 = closestIndex < 2 ? target.a : target.b;\r\n        Point2D_F32 pt1 = (closestIndex % 2) == 0 ? c.a : c.b;\r\n        float xx = pt1.x - pt0.x;\r\n        float yy = pt1.y - pt0.y;\r\n        float distX = Math.abs(cos * xx - sin * yy);\r\n        float distY = Math.abs(cos * yy + sin * xx);\r\n        if (distX >= bestDistance || distX > parallelTol || distY > tangentTol)\r\n            continue;\r\n        pt0 = farthestIndex < 2 ? target.a : target.b;\r\n        pt1 = (farthestIndex % 2) == 0 ? c.a : c.b;\r\n        float angleCombined = UtilAngle.atanSafe(pt1.y - pt0.y, pt1.x - pt0.x);\r\n        if (UtilAngle.distHalf(targetAngle, angleCombined) <= lineSlopeAngleTol) {\r\n            bestDistance = distX;\r\n            bestIndex = i;\r\n            bestFarthest = farthestIndex;\r\n        }\r\n    }\r\n    if (bestDistance < parallelTol) {\r\n        farthestIndex = bestFarthest;\r\n        return bestIndex;\r\n    }\r\n    return -1;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.TestLocalWeightedHistogramRotRect.computeHistogramBorder_compare",
	"Comment": "when given a region entirely inside, both inside and outside should produce identical solutions",
	"Method": "void computeHistogramBorder_compare(){\r\n    Planar<GrayF32> image = new Planar(GrayF32.class, 40, 50, 3);\r\n    InterpolatePixelMB interp = FactoryInterpolation.createPixelPL(FactoryInterpolation.bilinearPixelS(GrayF32.class, BorderType.EXTENDED));\r\n    GImageMiscOps.fillUniform(image, rand, 0, 100);\r\n    interp.setImage(image);\r\n    RectangleRotate_F32 rect = new RectangleRotate_F32(20, 25, 10, 15, 0);\r\n    LocalWeightedHistogramRotRect alg = new LocalWeightedHistogramRotRect(10, 3, 12, 3, 255, interp);\r\n    alg.computeHistogramBorder(image, rect);\r\n    int[] insideHistIndex = alg.sampleHistIndex.clone();\r\n    float[] insideHist = alg.histogram.clone();\r\n    alg = new LocalWeightedHistogramRotRect(10, 3, 12, 3, 255, interp);\r\n    alg.computeHistogramInside(rect);\r\n    for (int i = 0; i < insideHist.length; i++) {\r\n        assertEquals(insideHist[i], alg.histogram[i], 1e-4f);\r\n    }\r\n    for (int i = 0; i < insideHistIndex.length; i++) {\r\n        assertEquals(insideHistIndex[i], alg.sampleHistIndex[i], 1e-4f);\r\n    }\r\n}"
}, {
	"Path": "boofcv.misc.DiscretizedCircle.imageOffsets",
	"Comment": "computes the offsets for a discretized circle of the specified radius for an\timage with the specified width.",
	"Method": "int[] imageOffsets(double radius,int imgWidth){\r\n    double PI2 = Math.PI * 2.0;\r\n    double circumference = PI2 * radius;\r\n    int num = (int) Math.ceil(circumference);\r\n    num = num - num % 4;\r\n    double angleStep = PI2 / num;\r\n    int[] temp = new int[(int) Math.ceil(circumference)];\r\n    int i = 0;\r\n    int prev = 0;\r\n    for (double ang = 0; ang < PI2; ang += angleStep) {\r\n        int x = (int) Math.round(Math.cos(ang) * radius);\r\n        int y = (int) Math.round(Math.sin(ang) * radius);\r\n        int pixel = y * imgWidth + x;\r\n        if (pixel != prev) {\r\n            temp[i++] = pixel;\r\n        }\r\n        prev = pixel;\r\n    }\r\n    if (i == temp.length)\r\n        return temp;\r\n    else {\r\n        int[] ret = new int[i];\r\n        System.arraycopy(temp, 0, ret, 0, i);\r\n        return ret;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomDualTrackPnP.changePoseToReference",
	"Comment": "updates the relative position of all points so that the current frame is the reference frame.mathematically\tthis is not needed, but should help keep numbers from getting too large.",
	"Method": "void changePoseToReference(){\r\n    Se3_F64 keyToCurr = currToKey.invert(null);\r\n    List<PointTrack> all = trackerLeft.getAllTracks(null);\r\n    for (PointTrack t : all) {\r\n        LeftTrackInfo p = t.getCookie();\r\n        SePointOps_F64.transform(keyToCurr, p.location.location, p.location.location);\r\n    }\r\n    concatMotion();\r\n}"
}, {
	"Path": "boofcv.alg.feature.detdesc.DetectDescribeSurfPlanar.detect",
	"Comment": "detects and describes features inside provide images.all images are integral images.",
	"Method": "void detect(II grayII,Planar<II> colorII){\r\n    orientation.setImage(grayII);\r\n    describe.setImage(grayII, colorII);\r\n    descriptions.reset();\r\n    featureAngles.reset();\r\n    detector.detect(grayII);\r\n    foundPoints = detector.getFoundPoints();\r\n    for (int i = 0; i < foundPoints.size(); i++) {\r\n        ScalePoint p = foundPoints.get(i);\r\n        orientation.setObjectRadius(p.scale);\r\n        double angle = orientation.compute(p.x, p.y);\r\n        describe.describe(p.x, p.y, angle, p.scale, descriptions.grow());\r\n        featureAngles.push(angle);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.impl.TestBinaryThinning.checkSameInnerAndOuter",
	"Comment": "randomly generate an image to create a whole bunch of potential patterns then see if the border\tand inner algorithms produce the same result",
	"Method": "void checkSameInnerAndOuter(){\r\n    GrayU8 img = new GrayU8(200, 300);\r\n    ImageMiscOps.fillUniform(img, rand, 0, 2);\r\n    BinaryThinning alg = new BinaryThinning();\r\n    alg.binary = img;\r\n    alg.inputBorder.setImage(img);\r\n    for (int maskIndex = 0; maskIndex < alg.masks.length; maskIndex++) {\r\n        BinaryThinning.Mask mask = alg.masks[maskIndex];\r\n        for (int i = 1; i < img.height - 1; i++) {\r\n            for (int j = 1; j < img.width - 1; j++) {\r\n                if (img.get(j, i) == 1) {\r\n                    boolean border = mask.borderMask(j, i);\r\n                    boolean inner = mask.innerMask(img.getIndex(j, i));\r\n                    assertEquals(border, inner);\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.example.ExampleActivity.crashWithCustomSeverity",
	"Comment": "the severity of error reports can be altered. this can be useful for capturing handledexceptions which occur often but are not visible to the user.",
	"Method": "void crashWithCustomSeverity(View view){\r\n    RuntimeException exception = new RuntimeException(\"Error Report with altered Severity\");\r\n    Bugsnag.notify(exception, Severity.INFO);\r\n    displayToastNotification();\r\n}"
}, {
	"Path": "boofcv.core.encoding.ConvertYV12.yu12ToBoof",
	"Comment": "converts a yu12 encoded byte array into a boofcv formatted image.",
	"Method": "void yu12ToBoof(byte[] data,int width,int height,ImageBase output){\r\n    if (output instanceof Planar) {\r\n        Planar ms = (Planar) output;\r\n        if (ms.getBandType() == GrayU8.class) {\r\n            ImplConvertYV12.yv12ToPlanarRgb_U8(data, ms);\r\n        } else if (ms.getBandType() == GrayF32.class) {\r\n            ImplConvertYV12.yv12ToPlanarRgb_F32(data, ms);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unsupported output band format\");\r\n        }\r\n    } else if (output instanceof ImageGray) {\r\n        if (output.getClass() == GrayU8.class) {\r\n            yu12ToGray(data, width, height, (GrayU8) output);\r\n        } else if (output.getClass() == GrayF32.class) {\r\n            yu12ToGray(data, width, height, (GrayF32) output);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unsupported output type\");\r\n        }\r\n    } else if (output instanceof ImageInterleaved) {\r\n        if (output.getClass() == InterleavedU8.class) {\r\n            ImplConvertYV12.yv12ToInterleaved(data, (InterleavedU8) output);\r\n        } else if (output.getClass() == InterleavedF32.class) {\r\n            ImplConvertYV12.yv12ToInterleaved(data, (InterleavedF32) output);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unsupported output type\");\r\n        }\r\n    } else {\r\n        throw new IllegalArgumentException(\"Boofcv image type not yet supported\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareGrid.get",
	"Comment": "looks up the node based on its coordinate.negative values wrap",
	"Method": "SquareNode get(int row,int col){\r\n    return nodes.get(indexOf(row, col));\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.TestImageLineIntegral.nearBorder_nonZero",
	"Comment": "see if it handles borders correctly with both slopes are not zero",
	"Method": "void nearBorder_nonZero(){\r\n    GrayU8 img = new GrayU8(2, 2);\r\n    img.set(0, 0, 100);\r\n    img.set(0, 1, 200);\r\n    img.set(1, 0, 140);\r\n    img.set(1, 1, 150);\r\n    alg.setImage(FactoryGImageGray.wrap(img));\r\n    checkSolution(0, 0, 2, 2, sqrt(2) * (100 + 150));\r\n    checkSolution(2, 0, 0, 2, sqrt(2) * (200 + 140));\r\n    double r = Math.sqrt(1 + 4) / 2;\r\n    checkSolution(0, 0, 2, 1, r * (100 + 140));\r\n    checkSolution(0, 0, 1, 2, r * (100 + 200));\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.FeatureLaplacePyramid.detectCandidateFeatures",
	"Comment": "use the feature detector to find candidate features in each level.only compute the needed image derivatives.",
	"Method": "void detectCandidateFeatures(T image,double sigma){\r\n    float scaleThreshold = (float) (baseThreshold / Math.pow(sigma, scalePower));\r\n    detector.setThreshold(scaleThreshold);\r\n    computeDerivative.setInput(image);\r\n    D derivX = null, derivY = null;\r\n    D derivXX = null, derivYY = null, derivXY = null;\r\n    if (detector.getRequiresGradient()) {\r\n        derivX = computeDerivative.getDerivative(true);\r\n        derivY = computeDerivative.getDerivative(false);\r\n    }\r\n    if (detector.getRequiresHessian()) {\r\n        derivXX = computeDerivative.getDerivative(true, true);\r\n        derivYY = computeDerivative.getDerivative(false, false);\r\n        derivXY = computeDerivative.getDerivative(true, false);\r\n    }\r\n    detector.process(image, derivX, derivY, derivXX, derivYY, derivXY);\r\n    List<Point2D_I16> m = maximums;\r\n    m.clear();\r\n    if (detector.isDetectMaximums()) {\r\n        QueueCorner q = detector.getMaximums();\r\n        for (int i = 0; i < q.size; i++) {\r\n            m.add(q.get(i).copy());\r\n        }\r\n    }\r\n    if (detector.isDetectMinimums()) {\r\n        QueueCorner q = detector.getMinimums();\r\n        for (int i = 0; i < q.size; i++) {\r\n            m.add(q.get(i).copy());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.binary.VisualizeBinaryData.renderContours",
	"Comment": "draws contours. internal and external contours are different user specified colors.",
	"Method": "BufferedImage renderContours(List<EdgeContour> edges,int colors,int width,int height,BufferedImage out,BufferedImage renderContours,List<Contour> contours,int colorExternal,int colorInternal,int width,int height,BufferedImage out,BufferedImage renderContours,List<Contour> contours,int colorExternal,int colorInternal,int width,int height,BufferedImage out){\r\n    if (out == null) {\r\n        out = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB);\r\n    } else {\r\n        Graphics2D g2 = out.createGraphics();\r\n        g2.setColor(Color.BLACK);\r\n        g2.fillRect(0, 0, width, height);\r\n    }\r\n    colorExternal = checkColors(colorExternal, contours.size());\r\n    int index = 0;\r\n    for (Contour c : contours) {\r\n        int color = colorExternal[index++];\r\n        for (Point2D_I32 p : c.external) {\r\n            out.setRGB(p.x, p.y, color);\r\n        }\r\n        for (List<Point2D_I32> l : c.internal) {\r\n            for (Point2D_I32 p : l) {\r\n                out.setRGB(p.x, p.y, colorInternal);\r\n            }\r\n        }\r\n    }\r\n    return out;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionHandle.maybeCaptureStackTrace",
	"Comment": "depending on options, return a stack trace or an empty string",
	"Method": "String maybeCaptureStackTrace(){\r\n    if (this.detectUnclosedStatements) {\r\n        return this.pool.captureStackTrace(STATEMENT_NOT_CLOSED);\r\n    }\r\n    return this.noStackTrace;\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.noborder.TestConvolveImageStandardSparse.compareToGeneral",
	"Comment": "automatically compares all the box filters against a generalize convolution",
	"Method": "void compareToGeneral(){\r\n    Method[] methods = ConvolveImageStandardSparse.class.getMethods();\r\n    int numFound = 0;\r\n    for (Method m : methods) {\r\n        Class<?>[] paramTypes = m.getParameterTypes();\r\n        if (paramTypes.length < 3)\r\n            continue;\r\n        checkMethod(m, width, height, kernelRadius, kernelRadius * 2 + 1, rand);\r\n        checkMethod(m, width, height, 0, kernelRadius * 2 + 1, rand);\r\n        numFound++;\r\n    }\r\n    assertEquals(5, numFound);\r\n}"
}, {
	"Path": "org.boon.Boon.resourceObject",
	"Comment": "load json list as resource.looks in file system first and then classpath.",
	"Method": "T resourceObject(String path,Class<T> type,T resourceObject,Path path,Class<T> type){\r\n    return fromMap(resourceMap(path), type);\r\n}"
}, {
	"Path": "boofcv.alg.geo.h.HomographyInducedStereo3Pts.process",
	"Comment": "estimates the homography from view 1 to view 2 induced by a plane from 3 point associations.\teach pair must pass the epipolar constraint.this can fail if the points are colinear.",
	"Method": "boolean process(AssociatedPair p1,AssociatedPair p2,AssociatedPair p3){\r\n    fillM(p1.p1, p2.p1, p3.p1);\r\n    b.x = computeB(p1.p2);\r\n    b.y = computeB(p2.p2);\r\n    b.z = computeB(p3.p2);\r\n    if (!solver.setA(M))\r\n        return false;\r\n    GeometryMath_F64.toMatrix(b, temp0);\r\n    solver.solve(temp0, temp1);\r\n    GeometryMath_F64.toTuple3D(temp1, A_inv_b);\r\n    GeometryMath_F64.addOuterProd(A, -1, e2, A_inv_b, H);\r\n    adjust.adjust(H, p1);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.CalibrationDetectorSquareGrid.createLayout",
	"Comment": "creates a target that is composed of squares.the squares are spaced out and each corner provides\ta calibration point.",
	"Method": "List<Point2D_F64> createLayout(int numRows,int numCols,double squareWidth,double spaceWidth){\r\n    List<Point2D_F64> all = new ArrayList();\r\n    double width = (numCols * squareWidth + (numCols - 1) * spaceWidth);\r\n    double height = (numRows * squareWidth + (numRows - 1) * spaceWidth);\r\n    double startX = -width / 2;\r\n    double startY = -height / 2;\r\n    for (int i = numRows - 1; i >= 0; i--) {\r\n        double y = startY + i * (squareWidth + spaceWidth) + squareWidth;\r\n        List<Point2D_F64> top = new ArrayList();\r\n        List<Point2D_F64> bottom = new ArrayList();\r\n        for (int j = 0; j < numCols; j++) {\r\n            double x = startX + j * (squareWidth + spaceWidth);\r\n            top.add(new Point2D_F64(x, y));\r\n            top.add(new Point2D_F64(x + squareWidth, y));\r\n            bottom.add(new Point2D_F64(x, y - squareWidth));\r\n            bottom.add(new Point2D_F64(x + squareWidth, y - squareWidth));\r\n        }\r\n        all.addAll(top);\r\n        all.addAll(bottom);\r\n    }\r\n    return all;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionPartition.getQueryExecuteTimeLimitinNanoSeconds",
	"Comment": "store the unit translation here to avoid recalculating it in the constructor of statementhandle.",
	"Method": "long getQueryExecuteTimeLimitinNanoSeconds(){\r\n    return this.queryExecuteTimeLimitInNanoSeconds;\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.DescribeDenseSiftAlg.computeDescriptor",
	"Comment": "computes the descriptor centered at the specified coordinate",
	"Method": "void computeDescriptor(int cx,int cy,TupleDesc_F64 desc){\r\n    desc.fill(0);\r\n    int widthPixels = widthSubregion * widthGrid;\r\n    int radius = widthPixels / 2;\r\n    for (int i = 0; i < widthPixels; i++) {\r\n        int angleIndex = (cy - radius + i) * savedAngle.width + (cx - radius);\r\n        float subY = i / (float) widthSubregion;\r\n        for (int j = 0; j < widthPixels; j++, angleIndex++) {\r\n            float subX = j / (float) widthSubregion;\r\n            double angle = savedAngle.data[angleIndex];\r\n            float weightGaussian = gaussianWeight[i * widthPixels + j];\r\n            float weightGradient = savedMagnitude.data[angleIndex];\r\n            trilinearInterpolation(weightGaussian * weightGradient, subX, subY, angle, desc);\r\n        }\r\n    }\r\n    normalizeDescriptor(desc, maxDescriptorElementValue);\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.array.Interpolate1D_F32.hunt",
	"Comment": "to speed up finding the appropriate indexes to use in the interpolation it can use its\tprevious results to search a smaller region than it would otherwise.",
	"Method": "void hunt(float val){\r\n    int lowerLimit = center;\r\n    int upperLimit;\r\n    int inc = 1;\r\n    if (val >= x[lowerLimit] && ascend) {\r\n        for (; ; ) {\r\n            upperLimit = lowerLimit + inc;\r\n            if (upperLimit >= size - 1) {\r\n                upperLimit = size - 1;\r\n                break;\r\n            } else if (val < x[upperLimit] && ascend) {\r\n                break;\r\n            } else {\r\n                lowerLimit = upperLimit;\r\n                inc += inc;\r\n            }\r\n        }\r\n    } else {\r\n        upperLimit = lowerLimit;\r\n        for (; ; ) {\r\n            lowerLimit = lowerLimit - inc;\r\n            if (lowerLimit <= 0) {\r\n                lowerLimit = 0;\r\n                break;\r\n            } else if (val >= x[lowerLimit] && ascend) {\r\n                break;\r\n            } else {\r\n                upperLimit = lowerLimit;\r\n                inc += inc;\r\n            }\r\n        }\r\n    }\r\n    bisectionSearch(val, lowerLimit, upperLimit);\r\n}"
}, {
	"Path": "boofcv.alg.flow.BroxWarpingSpacial.process",
	"Comment": "computes dense optical flow from the provided image pyramid.image gradient for each layer should be\tcomputed directly from the layer images.",
	"Method": "void process(ImagePyramid<GrayF32> image1,ImagePyramid<GrayF32> image2){\r\n    boolean first = true;\r\n    for (int i = image1.getNumLayers() - 1; i >= 0; i--) {\r\n        GrayF32 layer1 = image1.getLayer(i);\r\n        GrayF32 layer2 = image2.getLayer(i);\r\n        resizeForLayer(layer1.width, layer2.height);\r\n        gradient.process(layer1, deriv1X, deriv1Y);\r\n        gradient.process(layer2, deriv2X, deriv2Y);\r\n        hessian.process(deriv2X, deriv2Y, deriv2XX, deriv2YY, deriv2XY);\r\n        if (!first) {\r\n            interpolateFlowScale(layer1.width, layer1.height);\r\n        } else {\r\n            first = false;\r\n            flowU.reshape(layer1.width, layer1.height);\r\n            flowV.reshape(layer1.width, layer1.height);\r\n            ImageMiscOps.fill(flowU, 0);\r\n            ImageMiscOps.fill(flowV, 0);\r\n        }\r\n        processLayer(layer1, layer2, deriv1X, deriv1Y, deriv2X, deriv2Y, deriv2XX, deriv2YY, deriv2XY);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.MultiViewOps.transfer_1_to_3",
	"Comment": "transfers a point from the first view to the second view using the observed location in the third view",
	"Method": "Point3D_F64 transfer_1_to_3(TrifocalTensor T,Point2D_F64 x1,Vector3D_F64 l2,Point3D_F64 x3,Point3D_F64 transfer_1_to_3,TrifocalTensor T,Point2D_F64 x1,Point2D_F64 x3,Point3D_F64 x2){\r\n    if (x2 == null)\r\n        x2 = new Point3D_F64();\r\n    TrifocalTransfer transfer = new TrifocalTransfer();\r\n    transfer.setTrifocal(T);\r\n    transfer.transfer_1_to_2(x1.x, x1.y, x3.x, x3.y, x2);\r\n    return x2;\r\n}"
}, {
	"Path": "boofcv.factory.feature.orientation.FactoryOrientation.sift",
	"Comment": "creates an implementation of the sift orientation estimation algorithm",
	"Method": "OrientationImage<T> sift(ConfigSiftScaleSpace configSS,ConfigSiftOrientation configOri,Class<T> imageType){\r\n    if (configSS == null)\r\n        configSS = new ConfigSiftScaleSpace();\r\n    configSS.checkValidity();\r\n    OrientationHistogramSift<GrayF32> ori = FactoryOrientationAlgs.sift(configOri, GrayF32.class);\r\n    SiftScaleSpace ss = new SiftScaleSpace(configSS.firstOctave, configSS.lastOctave, configSS.numScales, configSS.sigma0);\r\n    return new OrientationSiftToImage(ori, ss, imageType);\r\n}"
}, {
	"Path": "boofcv.alg.geo.MultiViewOps.transfer_1_to_2",
	"Comment": "transfers a point from the first view to the second view using the observed location in the third view",
	"Method": "Point3D_F64 transfer_1_to_2(TrifocalTensor T,Point2D_F64 x1,Vector3D_F64 l3,Point3D_F64 x2,Point3D_F64 transfer_1_to_2,TrifocalTensor T,Point2D_F64 x1,Point2D_F64 x2,Point3D_F64 x3){\r\n    if (x3 == null)\r\n        x3 = new Point3D_F64();\r\n    TrifocalTransfer transfer = new TrifocalTransfer();\r\n    transfer.setTrifocal(T);\r\n    transfer.transfer_1_to_3(x1.x, x1.y, x2.x, x2.y, x3);\r\n    return x3;\r\n}"
}, {
	"Path": "boofcv.abst.geo.pose.CheckEstimateNofPnP.checkMultipleCalls",
	"Comment": "call it multiple times and make sure the same solutions are returned.",
	"Method": "void checkMultipleCalls(){\r\n    List<Point2D3D> inputs = createObservations(worldToCamera0, alg.getMinimumPoints());\r\n    assertTrue(alg.process(inputs, solutions));\r\n    assertTrue(solutions.size() > 0);\r\n    List<Se3_F64> orig = new ArrayList();\r\n    for (Se3_F64 m : solutions.toList()) {\r\n        orig.add(m.copy());\r\n    }\r\n    for (int i = 0; i < 2; i++) {\r\n        assertTrue(alg.process(inputs, solutions));\r\n        assertEquals(orig.size(), solutions.size());\r\n        for (int j = 0; j < orig.size(); j++) {\r\n            Se3_F64 o = orig.get(j);\r\n            Se3_F64 f = solutions.get(j);\r\n            assertTrue(MatrixFeatures_DDRM.isIdentical(o.getR(), f.getR(), 1e-8));\r\n            assertTrue(f.getT().isIdentical(o.getT(), 1e-8));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.EdgeIntensityEllipse.process",
	"Comment": "processes the edge along the ellipse and determines if the edge intensity is strong enough\tto pass or not",
	"Method": "boolean process(EllipseRotated_F64 ellipse){\r\n    if (numContourPoints <= 0) {\r\n        score = 0;\r\n        return true;\r\n    }\r\n    double cphi = Math.cos(ellipse.phi);\r\n    double sphi = Math.sin(ellipse.phi);\r\n    averageInside = 0;\r\n    averageOutside = 0;\r\n    int total = 0;\r\n    for (int contourIndex = 0; contourIndex < numContourPoints; contourIndex++) {\r\n        double theta = contourIndex * Math.PI * 2.0 / numContourPoints;\r\n        double ct = Math.cos(theta);\r\n        double st = Math.sin(theta);\r\n        double px = ellipse.center.x + ellipse.a * ct * cphi - ellipse.b * st * sphi;\r\n        double py = ellipse.center.y + ellipse.a * ct * sphi + ellipse.b * st * cphi;\r\n        double edx = ellipse.a * ct * ellipse.b * ellipse.b;\r\n        double edy = ellipse.b * st * ellipse.a * ellipse.a;\r\n        double r = Math.sqrt(edx * edx + edy * edy);\r\n        edx /= r;\r\n        edy /= r;\r\n        double dx = edx * cphi - edy * sphi;\r\n        double dy = edx * sphi + edy * cphi;\r\n        double xin = px - dx * tangentDistance;\r\n        double yin = py - dy * tangentDistance;\r\n        double xout = px + dx * tangentDistance;\r\n        double yout = py + dy * tangentDistance;\r\n        if (integral.isInside(xin, yin) && integral.isInside(xout, yout)) {\r\n            averageInside += integral.compute(px, py, xin, yin);\r\n            averageOutside += integral.compute(px, py, xout, yout);\r\n            total++;\r\n        }\r\n    }\r\n    score = 0;\r\n    if (total > 0) {\r\n        score = Math.abs(averageOutside - averageInside) / (total * tangentDistance);\r\n    }\r\n    return score >= passThreshold;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeEncoder.detectAdjacentAndPositionPatterns",
	"Comment": "look for adjacent blocks that are the same color as well as patterns that\tcould be confused for position patterns 1,1,3,1,1\tin vertical and horizontal directions",
	"Method": "void detectAdjacentAndPositionPatterns(int N,QrCodeCodeWordLocations matrix,FoundFeatures features){\r\n    for (int foo = 0; foo < 2; foo++) {\r\n        for (int row = 0; row < N; row++) {\r\n            int index = row * N;\r\n            for (int col = 1; col < N; col++, index++) {\r\n                if (matrix.data[index] == matrix.data[index + 1])\r\n                    features.adjacent++;\r\n            }\r\n            index = row * N;\r\n            for (int col = 6; col < N; col++, index++) {\r\n                if (matrix.data[index] && !matrix.data[index + 1] && matrix.data[index + 2] && matrix.data[index + 3] && matrix.data[index + 4] && !matrix.data[index + 5] && matrix.data[index + 6])\r\n                    features.position++;\r\n            }\r\n        }\r\n        CommonOps_BDRM.transposeSquare(matrix);\r\n    }\r\n    features.adjacent -= 8 * 9 + 2 * 9 * 8 + (N - 18) * 2;\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.TestSegmentMeanShiftSearchColor.simpleTest",
	"Comment": "process a random image and do a basic sanity check on the output",
	"Method": "void simpleTest(){\r\n    Planar<GrayF32> image = new Planar(GrayF32.class, 20, 25, 2);\r\n    GImageMiscOps.fillUniform(image, rand, 0, 256);\r\n    SegmentMeanShiftSearchColor<Planar<GrayF32>> alg = new SegmentMeanShiftSearchColor(30, 0.05f, interp, 2, 2, 200, false, imageType);\r\n    alg.process(image);\r\n    FastQueue<Point2D_I32> locations = alg.getModeLocation();\r\n    GrowQueue_I32 counts = alg.getRegionMemberCount();\r\n    GrayS32 peaks = alg.getPixelToRegion();\r\n    FastQueue<float[]> values = alg.getModeColor();\r\n    assertTrue(locations.size > 20);\r\n    assertEquals(locations.size, counts.size);\r\n    assertEquals(locations.size, values.size);\r\n    int totalMembers = 0;\r\n    for (int i = 0; i < counts.size; i++) {\r\n        totalMembers += counts.get(i);\r\n    }\r\n    assertEquals(20 * 25, totalMembers);\r\n    for (int y = 0; y < peaks.height; y++) {\r\n        for (int x = 0; x < peaks.width; x++) {\r\n            int peak = peaks.get(x, y);\r\n            assertTrue(counts.get(peak) > 0);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.mls.TestImageDeformPointMLS_F32.testAllAtOnce_CloserToCloser",
	"Comment": "see if the distorted point is closer to the closest control point",
	"Method": "void testAllAtOnce_CloserToCloser(){\r\n    for (TypeDeformMLS type : TypeDeformMLS.values()) {\r\n        ImageDeformPointMLS_F32 alg = new ImageDeformPointMLS_F32(type);\r\n        alg.configure(width, height, rows, cols);\r\n        alg.addControl(5, 5);\r\n        alg.addControl(10, 20);\r\n        alg.addControl(30, 50);\r\n        alg.addControl(16, 0);\r\n        alg.setDistorted(0, 10, 12);\r\n        alg.setDistorted(1, 14, 30);\r\n        alg.setDistorted(2, 25, 45);\r\n        alg.setDistorted(3, 20, 8);\r\n        alg.fixateUndistorted();\r\n        alg.fixateDistorted();\r\n        Point2D_F32 a = new Point2D_F32();\r\n        Point2D_F32 b = new Point2D_F32();\r\n        alg.compute(4, 4, a);\r\n        alg.compute(1, 4, b);\r\n        float distA = a.distance(10, 12);\r\n        float distB = b.distance(10, 12);\r\n        assertTrue(distA < distB);\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.sfm.FactoryVisualOdometry.stereoDualTrackerPnP",
	"Comment": "creates a stereo visual odometry algorithm that independently tracks features in left and right camera.",
	"Method": "StereoVisualOdometry<T> stereoDualTrackerPnP(int thresholdAdd,int thresholdRetire,double inlierPixelTol,double epipolarPixelTol,int ransacIterations,int refineIterations,PointTracker<T> trackerLeft,PointTracker<T> trackerRight,DescribeRegionPoint<T, Desc> descriptor,Class<T> imageType){\r\n    EstimateNofPnP pnp = FactoryMultiView.pnp_N(EnumPNP.P3P_FINSTERWALDER, -1);\r\n    DistanceFromModelMultiView<Se3_F64, Point2D3D> distanceMono = new PnPDistanceReprojectionSq();\r\n    PnPStereoDistanceReprojectionSq distanceStereo = new PnPStereoDistanceReprojectionSq();\r\n    PnPStereoEstimator pnpStereo = new PnPStereoEstimator(pnp, distanceMono, 0);\r\n    ModelManagerSe3_F64 manager = new ModelManagerSe3_F64();\r\n    EstimatorToGenerator<Se3_F64, Stereo2D3D> generator = new EstimatorToGenerator(pnpStereo);\r\n    double ransacTOL = 2 * inlierPixelTol * inlierPixelTol;\r\n    ModelMatcher<Se3_F64, Stereo2D3D> motion = new Ransac(2323, manager, generator, distanceStereo, ransacIterations, ransacTOL);\r\n    RefinePnPStereo refinePnP = null;\r\n    Class<Desc> descType = descriptor.getDescriptionType();\r\n    ScoreAssociation<Desc> scorer = FactoryAssociation.defaultScore(descType);\r\n    AssociateStereo2D<Desc> associateStereo = new AssociateStereo2D(scorer, epipolarPixelTol, descType);\r\n    AssociateDescription2D<Desc> associateUnique = associateStereo;\r\n    if (!associateStereo.uniqueDestination() || !associateStereo.uniqueSource()) {\r\n        associateUnique = new EnforceUniqueByScore.Describe2D(associateStereo, true, true);\r\n    }\r\n    if (refineIterations > 0) {\r\n        refinePnP = new PnPStereoRefineRodrigues(1e-12, refineIterations);\r\n    }\r\n    TriangulateTwoViewsCalibrated triangulate = FactoryMultiView.triangulateTwoGeometric();\r\n    VisOdomDualTrackPnP<T, Desc> alg = new VisOdomDualTrackPnP(thresholdAdd, thresholdRetire, epipolarPixelTol, trackerLeft, trackerRight, descriptor, associateUnique, triangulate, motion, refinePnP);\r\n    return new WrapVisOdomDualTrackPnP(pnpStereo, distanceMono, distanceStereo, associateStereo, alg, refinePnP, imageType);\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapperComplex.handleCollectionOfValues",
	"Comment": "processes an collection of maps.this can inject into an array and appears to be using some of the typetype lib.",
	"Method": "void handleCollectionOfValues(Object newInstance,FieldAccess field,Collection<Value> acollectionOfValues){\r\n    Collection collectionOfValues = acollectionOfValues;\r\n    if (null == collectionOfValues) {\r\n        field.setObject(newInstance, null);\r\n        return;\r\n    }\r\n    if (field.typeEnum() == INSTANCE) {\r\n        field.setObject(newInstance, fromList((List) acollectionOfValues, field.type()));\r\n        return;\r\n    }\r\n    if (collectionOfValues instanceof ValueList) {\r\n        collectionOfValues = ((ValueList) collectionOfValues).list();\r\n    }\r\n    Class<?> componentClass = field.getComponentClass();\r\n    switch(field.typeEnum()) {\r\n        case LIST:\r\n        case SET:\r\n        case COLLECTION:\r\n            Collection<Object> newCollection = Conversions.createCollection(field.type(), collectionOfValues.size());\r\n            for (Value value : (List<Value>) collectionOfValues) {\r\n                if (value.isContainer()) {\r\n                    Object oValue = value.toValue();\r\n                    if (oValue instanceof Map) {\r\n                        newCollection.add(fromValueMap((Map) oValue, componentClass));\r\n                    }\r\n                } else {\r\n                    newCollection.add(Conversions.coerce(componentClass, value.toValue()));\r\n                }\r\n            }\r\n            field.setObject(newInstance, newCollection);\r\n            break;\r\n        case ARRAY:\r\n        case ARRAY_INT:\r\n        case ARRAY_BYTE:\r\n        case ARRAY_SHORT:\r\n        case ARRAY_FLOAT:\r\n        case ARRAY_DOUBLE:\r\n        case ARRAY_LONG:\r\n        case ARRAY_STRING:\r\n        case ARRAY_OBJECT:\r\n            TypeType componentType = field.componentType();\r\n            int index = 0;\r\n            switch(componentType) {\r\n                case INT:\r\n                    int[] iarray = new int[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        iarray[index] = value.intValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, iarray);\r\n                    return;\r\n                case SHORT:\r\n                    short[] sarray = new short[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        sarray[index] = value.shortValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, sarray);\r\n                    return;\r\n                case DOUBLE:\r\n                    double[] darray = new double[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        darray[index] = value.doubleValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, darray);\r\n                    return;\r\n                case FLOAT:\r\n                    float[] farray = new float[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        farray[index] = value.floatValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, farray);\r\n                    return;\r\n                case LONG:\r\n                    long[] larray = new long[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        larray[index] = value.longValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, larray);\r\n                    return;\r\n                case BYTE:\r\n                    byte[] barray = new byte[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        barray[index] = value.byteValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, barray);\r\n                    return;\r\n                case CHAR:\r\n                    char[] chars = new char[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        chars[index] = value.charValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, chars);\r\n                    return;\r\n                case STRING:\r\n                    CharBuf buffer = CharBuf.create(100);\r\n                    String[] strings = new String[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        strings[index] = value.stringValue(buffer);\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, strings);\r\n                    return;\r\n                default:\r\n                    Object array = Array.newInstance(componentClass, collectionOfValues.size());\r\n                    Object o;\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        if (value instanceof ValueContainer) {\r\n                            o = value.toValue();\r\n                            if (o instanceof List) {\r\n                                o = fromList((List) o, componentClass);\r\n                                if (componentClass.isInstance(o)) {\r\n                                    Array.set(array, index, o);\r\n                                } else {\r\n                                    break;\r\n                                }\r\n                            } else if (o instanceof Map) {\r\n                                o = fromMap((Map) o, componentClass);\r\n                                if (componentClass.isInstance(o)) {\r\n                                    Array.set(array, index, o);\r\n                                } else {\r\n                                    break;\r\n                                }\r\n                            }\r\n                        } else {\r\n                            o = value.toValue();\r\n                            if (componentClass.isInstance(o)) {\r\n                                Array.set(array, index, o);\r\n                            } else {\r\n                                Array.set(array, index, Conversions.coerce(componentClass, o));\r\n                            }\r\n                        }\r\n                        index++;\r\n                    }\r\n                    field.setValue(newInstance, array);\r\n            }\r\n            break;\r\n    }\r\n}"
}, {
	"Path": "org.bimserver.shared.GuidCompressor.cv_to_64",
	"Comment": "conversion of an integer into a number with base 64\tusing the table cconversiontable",
	"Method": "boolean cv_to_64(long number,char[] code,int len){\r\n    long act;\r\n    int iDigit, nDigits;\r\n    char[] result = new char[5];\r\n    if (len > 5)\r\n        return false;\r\n    act = number;\r\n    nDigits = len - 1;\r\n    for (iDigit = 0; iDigit < nDigits; iDigit++) {\r\n        result[nDigits - iDigit - 1] = cConversionTable[(int) (act % 64)];\r\n        act /= 64;\r\n    }\r\n    result[len - 1] = '\\0';\r\n    if (act != 0)\r\n        return false;\r\n    for (int i = 0; i < result.length; i++) code[i] = result[i];\r\n    return true;\r\n}"
}, {
	"Path": "com.bugsnag.android.Error.getMetaData",
	"Comment": "get any additional diagnostic metadata currently attached to this error.this will contain any metadata set by setmetadata or addtotab.",
	"Method": "MetaData getMetaData(){\r\n    return metaData;\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.TestImageLineIntegral.nearBorder_SlopeZero",
	"Comment": "test cases where the slope for x or y is zero across multiple pixels and sampling is done near the image\tborder",
	"Method": "void nearBorder_SlopeZero(){\r\n    GrayU8 img = new GrayU8(10, 15);\r\n    img.set(0, 0, 100);\r\n    img.set(9, 14, 120);\r\n    alg.setImage(FactoryGImageGray.wrap(img));\r\n    checkSolution(0.5, 0, 0.5, 0.5, 50);\r\n    checkSolution(9.5, 14.5, 9.5, 15, 0.5 * 120);\r\n    checkSolution(0, 0.5, 0.5, 0.5, 50);\r\n    checkSolution(9.5, 14.5, 10.0, 14.5, 0.5 * 120);\r\n}"
}, {
	"Path": "boofcv.alg.geo.PerspectiveOps.scaleIntrinsic",
	"Comment": "multiplies each element of the intrinsic parameters by the provided scale factor.useful\tif the image has been rescaled.",
	"Method": "void scaleIntrinsic(CameraPinhole param,double scale){\r\n    param.width = (int) (param.width * scale);\r\n    param.height = (int) (param.height * scale);\r\n    param.cx *= scale;\r\n    param.cy *= scale;\r\n    param.fx *= scale;\r\n    param.fy *= scale;\r\n    param.skew *= scale;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonBinaryGrayRefine.refine",
	"Comment": "refines the fit to the specified polygon. only info.polygon is modified",
	"Method": "boolean refine(DetectPolygonFromContour.Info info){\r\n    double before, after;\r\n    if (edgeIntensity.computeEdge(info.polygon, !detector.isOutputClockwise())) {\r\n        before = edgeIntensity.getAverageOutside() - edgeIntensity.getAverageInside();\r\n    } else {\r\n        return false;\r\n    }\r\n    boolean success = false;\r\n    if (refineContour != null) {\r\n        List<Point2D_I32> contour = detector.getContour(info);\r\n        refineContour.process(contour, info.splits, work);\r\n        if (adjustForBias != null)\r\n            adjustForBias.process(work, detector.isOutputClockwise());\r\n        if (edgeIntensity.computeEdge(work, !detector.isOutputClockwise())) {\r\n            after = edgeIntensity.getAverageOutside() - edgeIntensity.getAverageInside();\r\n            if (after > before) {\r\n                info.edgeInside = edgeIntensity.getAverageInside();\r\n                info.edgeOutside = edgeIntensity.getAverageOutside();\r\n                info.polygon.set(work);\r\n                success = true;\r\n                before = after;\r\n            }\r\n        }\r\n    }\r\n    if (functionAdjust != null) {\r\n        functionAdjust.adjust(info, detector.isOutputClockwise());\r\n    }\r\n    if (refineGray != null) {\r\n        work.vertexes.resize(info.polygon.size());\r\n        if (refineGray.refine(info.polygon, work)) {\r\n            if (edgeIntensity.computeEdge(work, !detector.isOutputClockwise())) {\r\n                after = edgeIntensity.getAverageOutside() - edgeIntensity.getAverageInside();\r\n                if (after * 1.5 > before) {\r\n                    info.edgeInside = edgeIntensity.getAverageInside();\r\n                    info.edgeOutside = edgeIntensity.getAverageOutside();\r\n                    info.polygon.set(work);\r\n                    success = true;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return success;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.ConfigNew.getString",
	"Comment": "returns the string for given key. the one in the config, or if it does not exist, the given default value.",
	"Method": "String getString(ConfigKey configKey,String getString,ConfigKey configKey,String defaultValue){\r\n    try {\r\n        final FindResult res = findNode(configKey.keyName, true);\r\n        final String value = res.getNode().getString(res.getName());\r\n        return StringEscapeUtils.unescapeJson(value);\r\n    } catch (final JSONException ignored) {\r\n        setString(configKey, defaultValue);\r\n        return defaultValue;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.TestPruneStructureFromSceneMetric.prunePoints_neighbors_exact",
	"Comment": "prunes and makes sure the distance and count are correctly implemented",
	"Method": "void prunePoints_neighbors_exact(){\r\n    createPerfectScene(2, 5);\r\n    PruneStructureFromSceneMetric alg = new PruneStructureFromSceneMetric(structure, observations);\r\n    alg.prunePoints(1, 5.01);\r\n    assertEquals(4, structure.points.length);\r\n    alg.prunePoints(1, 4.99);\r\n    assertEquals(0, structure.points.length);\r\n    assertEquals(0, observations.getObservationCount());\r\n    createPerfectScene(3, 5);\r\n    alg = new PruneStructureFromSceneMetric(structure, observations);\r\n    alg.prunePoints(3, 5.01);\r\n    assertEquals(5, structure.points.length);\r\n}"
}, {
	"Path": "com.bugsnag.android.DeviceData.calculateTotalMemory",
	"Comment": "get the total memory available on the current android device, in bytes",
	"Method": "long calculateTotalMemory(){\r\n    Runtime runtime = Runtime.getRuntime();\r\n    if (runtime.maxMemory() != Long.MAX_VALUE) {\r\n        return runtime.maxMemory();\r\n    } else {\r\n        return runtime.totalMemory();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareGraph.findSideIntersect",
	"Comment": "finds the side which intersects the line on the shape.the line is assumed to pass through the shape\tso if there is no intersection it is considered a bug",
	"Method": "int findSideIntersect(SquareNode n,LineSegment2D_F64 line,Point2D_F64 intersection,LineSegment2D_F64 storage){\r\n    for (int j = 0, i = 3; j < 4; i = j, j++) {\r\n        storage.a = n.square.get(i);\r\n        storage.b = n.square.get(j);\r\n        if (Intersection2D_F64.intersection(line, storage, intersection) != null) {\r\n            return i;\r\n        }\r\n    }\r\n    return -1;\r\n}"
}, {
	"Path": "com.gazbert.bxbot.core.engine.TestTradingEngine.testEngineShutsDownWhenItReceivesUnexpectedExceptionFromExchangeAdapter",
	"Comment": "tests the engine starts up, executes 1 trade cycle successfully, but then receives unexpected exception fromexchange adapter on the 2nd cycle. we expect the engine to shutdown.",
	"Method": "void testEngineShutsDownWhenItReceivesUnexpectedExceptionFromExchangeAdapter(){\r\n    setupConfigLoadingExpectations();\r\n    final String exceptionErrorMsg = \"I had to rewire the grav thrust because somebody won't replace that crappy compression coil.\";\r\n    final Map<String, BigDecimal> balancesAvailable = new HashMap();\r\n    balancesAvailable.put(ENGINE_EMERGENCY_STOP_CURRENCY, new BigDecimal(\"0.5\"));\r\n    final BalanceInfo balanceInfo = PowerMock.createMock(BalanceInfo.class);\r\n    expect(exchangeAdapter.getBalanceInfo()).andReturn(balanceInfo);\r\n    expect(balanceInfo.getBalancesAvailable()).andReturn(balancesAvailable);\r\n    tradingStrategy.execute();\r\n    expect(exchangeAdapter.getBalanceInfo()).andThrow(new IllegalStateException(exceptionErrorMsg));\r\n    emailAlerter.sendMessage(eq(CRITICAL_EMAIL_ALERT_SUBJECT), contains(\"An unexpected FATAL error has occurred in\" + \" Exchange Adapter or Trading Strategy! Details: \" + exceptionErrorMsg));\r\n    PowerMock.replayAll();\r\n    final TradingEngine tradingEngine = new TradingEngine(exchangeConfigService, engineConfigService, strategyConfigService, marketConfigService, emailAlerter);\r\n    tradingEngine.start();\r\n    waitForEngineStateChange(tradingEngine, EngineState.SHUTDOWN, NUMBER_OF_TRADE_CYCLES);\r\n    assertFalse(tradingEngine.isRunning());\r\n    PowerMock.verifyAll();\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.TestClusterLabeledImage.uniform",
	"Comment": "uniform image given different values.should produce an output image of all zeros.",
	"Method": "void uniform(){\r\n    GrayS32 input = new GrayS32(5, 7);\r\n    GrayS32 output = new GrayS32(5, 7);\r\n    for (int value = 0; value < 3; value++) {\r\n        GImageMiscOps.fill(input, value);\r\n        for (int i = 0; i < rules.length; i++) {\r\n            GImageMiscOps.fillUniform(output, rand, 0, 1000);\r\n            ClusterLabeledImage alg = new ClusterLabeledImage(rules[i]);\r\n            alg.process(input, output, counts);\r\n            assertEquals(1, counts.size);\r\n            assertEquals(5 * 7, counts.get(0));\r\n            for (int index = 0; index < output.data.length; index++) assertEquals(0, output.data[index]);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.geo.calibration.CalibrateMonoPlanar.process",
	"Comment": "after calibration points have been found this invokes the zhang99 algorithm to\testimate calibration parameters.error statistics are also computed.",
	"Method": "T process(){\r\n    if (zhang99 == null)\r\n        throw new IllegalArgumentException(\"Please call configure first.\");\r\n    if (!zhang99.process(observations)) {\r\n        throw new RuntimeException(\"Zhang99 algorithm failed!\");\r\n    }\r\n    foundZhang = zhang99.getOptimized();\r\n    errors = computeErrors(observations, foundZhang, layout);\r\n    foundIntrinsic = foundZhang.getIntrinsic().getCameraModel();\r\n    foundIntrinsic.width = imageWidth;\r\n    foundIntrinsic.height = imageHeight;\r\n    return (T) foundIntrinsic;\r\n}"
}, {
	"Path": "boofcv.gui.JavaRuntimeLauncher.setFrozenTime",
	"Comment": "specifies the amount of time the process has to complete.after which it is considered frozen andwill be killed",
	"Method": "void setFrozenTime(long frozenTime){\r\n    this.frozenTime = frozenTime;\r\n}"
}, {
	"Path": "boofcv.struct.image.ImageGray.createSameShape",
	"Comment": "creates a single band image of the specified type that will have the same\tshape as this image",
	"Method": "B createSameShape(Class<B> type){\r\n    return GeneralizedImageOps.createSingleBand(type, width, height);\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.EquirectangularTools_F64.equiToLatLon",
	"Comment": "converts the equirectangular coordinate into a latitude and longitude",
	"Method": "void equiToLatLon(double x,double y,GeoLL_F64 geo){\r\n    geo.lon = (x / width - 0.5) * GrlConstants.PI2;\r\n    geo.lat = (y / (height - 1) - 0.5) * GrlConstants.PI;\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.impl.TestThresholdSauvola.simple",
	"Comment": "provide it a simple input image with obvious thresholding.there will be regions of white space\twhich exceed its radius.",
	"Method": "void simple(){\r\n    int width = 11;\r\n    GrayU8 expected = new GrayU8(30, 35);\r\n    for (int y = width / 2; y < expected.height - width / 2; y++) {\r\n        expected.set(20, y, 1);\r\n        expected.set(21, y, 1);\r\n        expected.set(22, y, 1);\r\n    }\r\n    GrayF32 input = new GrayF32(expected.width, expected.height);\r\n    for (int i = 0; i < input.width * input.height; i++) {\r\n        input.data[i] = expected.data[i] == 0 ? 255 : 0;\r\n    }\r\n    GrayU8 found = new GrayU8(expected.width, expected.height);\r\n    ConfigLength regionWidth = ConfigLength.fixed(width);\r\n    int radius = regionWidth.computeI(Math.min(input.width, input.height)) / 2;\r\n    ThresholdSauvola alg = new ThresholdSauvola(regionWidth, 0.5f, true);\r\n    alg.process(input, found);\r\n    BoofTesting.assertEqualsInner(expected, found, 0, radius, radius, false);\r\n    alg.setDown(false);\r\n    alg.process(input, found);\r\n    BinaryImageOps.invert(expected, expected);\r\n    BoofTesting.assertEqualsInner(expected, found, 0, radius, radius, false);\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernel.random1D_I32",
	"Comment": "creates a random 1d kernel drawn from a uniform distribution.",
	"Method": "Kernel1D_S32 random1D_I32(int width,int offset,int min,int max,Random rand){\r\n    Kernel1D_S32 ret = new Kernel1D_S32(width, offset);\r\n    int range = max - min;\r\n    for (int i = 0; i < ret.data.length; i++) {\r\n        ret.data[i] = rand.nextInt(range) + min;\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "org.bimserver.shared.GuidCompressor.uncompressGuidString",
	"Comment": "converts a compressed string representation of a guid into an uncompressed one",
	"Method": "String uncompressGuidString(String compressedString){\r\n    Guid guid = new Guid();\r\n    getGuidFromCompressedString(compressedString, guid);\r\n    return getUncompressedStringFromGuid(guid);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.UtilShapePolygon.convert",
	"Comment": "finds the intersections between the four lines and converts it into a quadrilateral",
	"Method": "boolean convert(LineGeneral2D_F64[] lines,Polygon2D_F64 poly){\r\n    for (int i = 0; i < poly.size(); i++) {\r\n        int j = (i + 1) % poly.size();\r\n        if (null == Intersection2D_F64.intersection(lines[i], lines[j], poly.get(j)))\r\n            return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.distort.DistortImageOps.scale",
	"Comment": "rescales the input image and writes the results into the output image.the scale\tfactor is determined independently of the width and height.",
	"Method": "void scale(T input,T output,BorderType borderType,InterpolationType interpType){\r\n    PixelTransformAffine_F32 model = DistortSupport.transformScale(output, input, null);\r\n    if (input instanceof ImageGray) {\r\n        distortSingle((ImageGray) input, (ImageGray) output, model, interpType, borderType);\r\n    } else if (input instanceof Planar) {\r\n        distortPL((Planar) input, (Planar) output, model, borderType, interpType);\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedS16.getBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "int getBand(int x,int y,int band){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    return data[getIndex(x, y, band)];\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.KltTracker.isFullyInside",
	"Comment": "returns true if the features is entirely enclosed inside of the image.",
	"Method": "boolean isFullyInside(float x,float y){\r\n    if (x < allowedLeft || x > allowedRight)\r\n        return false;\r\n    if (y < allowedTop || y > allowedBottom)\r\n        return false;\r\n    return true;\r\n}"
}, {
	"Path": "com.gazbert.bxbot.exchanges.AbstractExchangeAdapter.setNetworkConfig",
	"Comment": "sets the network config for the exchange adapter. this helper method expects the network config to be present.",
	"Method": "void setNetworkConfig(ExchangeConfig exchangeConfig){\r\n    final NetworkConfig networkConfig = exchangeConfig.getNetworkConfig();\r\n    if (networkConfig == null) {\r\n        final String errorMsg = NETWORK_CONFIG_MISSING + exchangeConfig;\r\n        LOG.error(errorMsg);\r\n        throw new IllegalArgumentException(errorMsg);\r\n    }\r\n    connectionTimeout = networkConfig.getConnectionTimeout();\r\n    if (connectionTimeout == 0) {\r\n        final String errorMsg = CONNECTION_TIMEOUT_PROPERTY_NAME + \" cannot be 0 value.\" + exchangeConfig;\r\n        LOG.error(errorMsg);\r\n        throw new IllegalArgumentException(errorMsg);\r\n    }\r\n    LOG.info(() -> CONNECTION_TIMEOUT_PROPERTY_NAME + \": \" + connectionTimeout);\r\n    final List<Integer> nonFatalErrorCodesFromConfig = networkConfig.getNonFatalErrorCodes();\r\n    if (nonFatalErrorCodesFromConfig != null) {\r\n        nonFatalNetworkErrorCodes.addAll(nonFatalErrorCodesFromConfig);\r\n    }\r\n    LOG.info(() -> NON_FATAL_ERROR_CODES_PROPERTY_NAME + \": \" + nonFatalNetworkErrorCodes);\r\n    final List<String> nonFatalErrorMessagesFromConfig = networkConfig.getNonFatalErrorMessages();\r\n    if (nonFatalErrorMessagesFromConfig != null) {\r\n        nonFatalNetworkErrorMessages.addAll(nonFatalErrorMessagesFromConfig);\r\n    }\r\n    LOG.info(() -> NON_FATAL_ERROR_MESSAGES_PROPERTY_NAME + \": \" + nonFatalNetworkErrorMessages);\r\n}"
}, {
	"Path": "boofcv.alg.distort.pinhole.TestPinholePtoN_F32.basic",
	"Comment": "do the same calculation but using a different but equivalent equation",
	"Method": "void basic(){\r\n    PinholePtoN_F32 alg = new PinholePtoN_F32();\r\n    alg.set(fx, fy, skew, x_c, y_c);\r\n    Point2D_F32 in = new Point2D_F32(100, 120);\r\n    Point2D_F32 out = new Point2D_F32();\r\n    alg.compute(in.x, in.y, out);\r\n    Point2D_F32 expected = new Point2D_F32();\r\n    FMatrixRMaj K_inv = new FMatrixRMaj(3, 3, true, fx, skew, x_c, 0, fy, y_c, 0, 0, 1);\r\n    CommonOps_FDRM.invert(K_inv);\r\n    GeometryMath_F32.mult(K_inv, in, expected);\r\n    assertEquals(expected.x, out.x, 1e-5);\r\n    assertEquals(expected.y, out.y, 1e-5);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionHandle.getThreadUsingConnection",
	"Comment": "returns the thread that is currently utilizing this connection.",
	"Method": "Thread getThreadUsingConnection(){\r\n    return this.threadUsingConnection;\r\n}"
}, {
	"Path": "boofcv.gui.image.ProcessImageSequence.addComponent",
	"Comment": "if a component is added here then keyboard and mouse events will be used to control the\timage processing.",
	"Method": "void addComponent(JComponent comp){\r\n    comp.addMouseListener(this);\r\n    comp.addKeyListener(this);\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.TestSelfCalibrationLinearRotationMulti.extractReferenceW",
	"Comment": "explicitly compute null space and feed it in. then see if the correct\tcalibration is found",
	"Method": "void extractReferenceW(){\r\n    SelfCalibrationLinearRotationMulti alg = new SelfCalibrationLinearRotationMulti();\r\n    DMatrixRMaj w = new DMatrixRMaj(3, 3);\r\n    CommonOps_DDRM.multTransB(K, K, w);\r\n    CommonOps_DDRM.invert(w);\r\n    CommonOps_DDRM.divide(w, w.get(2, 2));\r\n    DMatrixRMaj x = new DMatrixRMaj(6, 1);\r\n    x.data[0] = w.get(0, 0);\r\n    x.data[1] = w.get(0, 1);\r\n    x.data[2] = w.get(0, 2);\r\n    x.data[3] = w.get(1, 1);\r\n    x.data[4] = w.get(1, 2);\r\n    x.data[5] = w.get(2, 2);\r\n    CameraPinhole found = new CameraPinhole();\r\n    alg.extractReferenceW(x);\r\n    alg.convertW(alg.W0, found);\r\n    assertEquals(camera.fx, found.fx, UtilEjml.TEST_F64);\r\n    assertEquals(camera.fy, found.fy, UtilEjml.TEST_F64);\r\n    assertEquals(camera.skew, found.skew, UtilEjml.TEST_F64);\r\n    assertEquals(camera.cx, found.cx, UtilEjml.TEST_F64);\r\n    assertEquals(camera.cy, found.cy, UtilEjml.TEST_F64);\r\n}"
}, {
	"Path": "boofcv.alg.transform.ii.IntegralImageOps.isInBounds",
	"Comment": "checks to see if the kernel is applied at this specific spot if all the pixels\twould be inside the image bounds or not",
	"Method": "boolean isInBounds(int x,int y,IntegralKernel kernel,int width,int height){\r\n    for (ImageRectangle r : kernel.blocks) {\r\n        if (x + r.x0 < 0 || y + r.y0 < 0)\r\n            return false;\r\n        if (x + r.x1 >= width || y + r.y1 >= height)\r\n            return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.StatementHandle.queryTimerEnd",
	"Comment": "call the onqueryexecutetimelimitexceeded hook if necessary",
	"Method": "void queryTimerEnd(String sql,long queryStartTime){\r\n    if ((this.queryExecuteTimeLimit != 0) && (this.connectionHook != null)) {\r\n        long timeElapsed = (System.nanoTime() - queryStartTime);\r\n        if (timeElapsed > this.queryExecuteTimeLimit) {\r\n            this.connectionHook.onQueryExecuteTimeLimitExceeded(this.connectionHandle, this, sql, this.logParams, timeElapsed);\r\n        }\r\n    }\r\n    if (this.statisticsEnabled) {\r\n        this.statistics.incrementStatementsExecuted();\r\n        this.statistics.addStatementExecuteTime(System.nanoTime() - queryStartTime);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.DepthSparse3D.process",
	"Comment": "given a pixel coordinate in the visual camera, compute the 3d coordinate of that point.",
	"Method": "boolean process(int x,int y){\r\n    visualToDepth.compute(x, y);\r\n    int depthX = (int) visualToDepth.distX;\r\n    int depthY = (int) visualToDepth.distY;\r\n    if (depthImage.isInBounds(depthX, depthY)) {\r\n        double value = lookupDepth(depthX, depthY);\r\n        if (value == 0)\r\n            return false;\r\n        p2n.compute(x, y, norm);\r\n        worldPt.z = value * depthScale;\r\n        worldPt.x = worldPt.z * norm.x;\r\n        worldPt.y = worldPt.z * norm.y;\r\n        return true;\r\n    } else {\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.EllipseClustersIntoGrid.findLargestAnglesForAllNodes",
	"Comment": "finds the two edges with the greatest angular distance between them.",
	"Method": "void findLargestAnglesForAllNodes(){\r\n    for (int i = 0; i < listInfo.size(); i++) {\r\n        NodeInfo info = listInfo.get(i);\r\n        if (info.edges.size < 2)\r\n            continue;\r\n        for (int k = 0, j = info.edges.size - 1; k < info.edges.size; j = k, k++) {\r\n            double angleA = info.edges.get(j).angle;\r\n            double angleB = info.edges.get(k).angle;\r\n            double distance = UtilAngle.distanceCCW(angleA, angleB);\r\n            if (distance > info.angleBetween) {\r\n                info.angleBetween = distance;\r\n                info.left = info.edges.get(j).target;\r\n                info.right = info.edges.get(k).target;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.fiducial.FactoryFiducialCalibration.squareGrid",
	"Comment": "detector for a grid of square targets. all squares must be entirely visible inside the image.",
	"Method": "CalibrationDetectorSquareGrid squareGrid(ConfigSquareGrid config){\r\n    config.checkValidity();\r\n    return new CalibrationDetectorSquareGrid(config);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestBoneCP.testIsConnectionHandleAliveNormalCaseWithConnectionTestTriggerException",
	"Comment": "test method for com.jolbox.bonecp.bonecp isconnectionhandlealive.",
	"Method": "void testIsConnectionHandleAliveNormalCaseWithConnectionTestTriggerException(){\r\n    Statement mockStatement = EasyMock.createNiceMock(Statement.class);\r\n    reset(mockConfig, mockConnection, mockDatabaseMetadata, mockResultSet);\r\n    expect(mockConfig.getConnectionTestStatement()).andReturn(\"whatever\").once();\r\n    expect(mockConnection.createStatement()).andReturn(mockStatement).once();\r\n    expect(mockStatement.execute((String) anyObject())).andThrow(new RuntimeException()).once();\r\n    mockStatement.close();\r\n    expectLastCall().once();\r\n    replay(mockConfig, mockConnection, mockDatabaseMetadata, mockStatement, mockResultSet);\r\n    try {\r\n        mockConnection.logicallyClosed = new AtomicBoolean(true);\r\n        testClass.isConnectionHandleAlive(mockConnection);\r\n        fail(\"Should have thrown an exception\");\r\n    } catch (RuntimeException e) {\r\n    }\r\n    verify(mockConfig, mockConnection, mockResultSet, mockDatabaseMetadata, mockStatement);\r\n}"
}, {
	"Path": "boofcv.gui.SelectAlgorithmAndInputPanel.setInputImage",
	"Comment": "specifies an image which contains the original input image.after this has been called the\tview input image widget is activated and when selected this image will be displayed instead\tof the main gui.this functionality is optional.",
	"Method": "void setInputImage(BufferedImage image){\r\n    inputImage = image;\r\n    SwingUtilities.invokeLater(new Runnable() {\r\n        public void run() {\r\n            if (inputImage == null) {\r\n                originalCheck.setEnabled(false);\r\n            } else {\r\n                originalCheck.setEnabled(true);\r\n                origPanel.setImage(inputImage);\r\n                origPanel.setPreferredSize(new Dimension(inputImage.getWidth(), inputImage.getHeight()));\r\n                origPanel.repaint();\r\n            }\r\n        }\r\n    });\r\n}"
}, {
	"Path": "boofcv.gui.SelectAlgorithmAndInputPanel.setInputImage",
	"Comment": "specifies an image which contains the original input image.after this has been called the\tview input image widget is activated and when selected this image will be displayed instead\tof the main gui.this functionality is optional.",
	"Method": "void setInputImage(BufferedImage image){\r\n    if (inputImage == null) {\r\n        originalCheck.setEnabled(false);\r\n    } else {\r\n        originalCheck.setEnabled(true);\r\n        origPanel.setImage(inputImage);\r\n        origPanel.setPreferredSize(new Dimension(inputImage.getWidth(), inputImage.getHeight()));\r\n        origPanel.repaint();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.TestBinaryEllipseDetector.filterByEdge",
	"Comment": "handle a situation where a shape should be filtered out based on its edge intensity",
	"Method": "void filterByEdge(){\r\n    List<EllipseRotated_F64> expected = new ArrayList();\r\n    expected.add(new EllipseRotated_F64(50, 65, 20, 10, 0.5));\r\n    GrayU8 image = TestBinaryEllipseDetectorPixel.renderEllipses_F64(200, 210, expected, 0);\r\n    GrayU8 binary = image.createSameShape();\r\n    ThresholdImageOps.threshold(image, binary, 30, true);\r\n    BinaryEllipseDetector<GrayU8> alg = create();\r\n    alg.process(image, binary);\r\n    List<EllipseRotated_F64> found = alg.getFoundEllipses(null);\r\n    TestBinaryEllipseDetectorPixel.checkEquals_F64(expected, found, 1.0, 0.1);\r\n    image = TestBinaryEllipseDetectorPixel.renderEllipses_F64(200, 210, expected, 255 - THRESHOLD + 5);\r\n    alg.process(image, binary);\r\n    assertEquals(0, alg.getFound().size());\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.ReidSolomonCodes.findErrorLocatorPolynomial",
	"Comment": "compute the error locator polynomial when given the error locations in the message.",
	"Method": "void findErrorLocatorPolynomial(int messageLength,GrowQueue_I32 errorLocations,GrowQueue_I8 errorLocator){\r\n    tmp1.resize(2);\r\n    tmp1.data[1] = 1;\r\n    errorLocator.resize(1);\r\n    errorLocator.data[0] = 1;\r\n    for (int i = 0; i < errorLocations.size; i++) {\r\n        int where = messageLength - errorLocations.get(i) - 1;\r\n        tmp1.data[0] = (byte) math.power(2, where);\r\n        tmp0.setTo(errorLocator);\r\n        math.polyMult(tmp0, tmp1, errorLocator);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.PnPLepetitEPnP.process",
	"Comment": "compute camera motion given a set of features with observations and 3d locations",
	"Method": "void process(List<Point3D_F64> worldPts,List<Point2D_F64> observed,Se3_F64 solutionModel){\r\n    if (worldPts.size() < 4)\r\n        throw new IllegalArgumentException(\"Must provide at least 4 points\");\r\n    if (worldPts.size() != observed.size())\r\n        throw new IllegalArgumentException(\"Must have the same number of observations and world points\");\r\n    selectWorldControlPoints(worldPts, controlWorldPts);\r\n    computeBarycentricCoordinates(controlWorldPts, alphas, worldPts);\r\n    constructM(observed, alphas, M);\r\n    extractNullPoints(M);\r\n    if (numControl == 4) {\r\n        L_full.reshape(6, 10);\r\n        y.reshape(6, 1);\r\n        UtilLepetitEPnP.constraintMatrix6x10(L_full, y, controlWorldPts, nullPts);\r\n        estimateCase1(solutions.get(0));\r\n        estimateCase2(solutions.get(1));\r\n        estimateCase3(solutions.get(2));\r\n        if (worldPts.size() == 4)\r\n            estimateCase4(solutions.get(3));\r\n    } else {\r\n        L_full.reshape(3, 6);\r\n        y.reshape(3, 1);\r\n        UtilLepetitEPnP.constraintMatrix3x6(L_full, y, controlWorldPts, nullPts);\r\n        estimateCase1(solutions.get(0));\r\n        estimateCase2(solutions.get(1));\r\n        if (worldPts.size() == 3)\r\n            estimateCase3_planar(solutions.get(2));\r\n    }\r\n    computeResultFromBest(solutionModel);\r\n}"
}, {
	"Path": "boofcv.factory.fiducial.FactoryFiducialCalibration.binaryGrid",
	"Comment": "detector for a grid of binary targets.allows for squares to be obscured or partially outside of the\timage.",
	"Method": "CalibrationDetectorSquareFiducialGrid binaryGrid(ConfigSquareGridBinary config){\r\n    config.checkValidity();\r\n    return new CalibrationDetectorSquareFiducialGrid(config);\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationRefineDualQuadratic.recomputeQ",
	"Comment": "compuets the absolute dual quadratic from the first camera parameters and\tplane at infinity",
	"Method": "void recomputeQ(DMatrixRMaj p,DMatrix4x4 Q){\r\n    Equation eq = new Equation();\r\n    DMatrix3x3 K = new DMatrix3x3();\r\n    encodeK(K, 0, 3, param.data);\r\n    eq.alias(p, \"p\", K, \"K\");\r\n    eq.process(\"w=K*K'\");\r\n    eq.process(\"Q=[w , -w*p;-p'*w , p'*w*p]\");\r\n    DMatrixRMaj _Q = eq.lookupDDRM(\"Q\");\r\n    CommonOps_DDRM.divide(_Q, NormOps_DDRM.normF(_Q));\r\n    ConvertDMatrixStruct.convert(_Q, Q);\r\n}"
}, {
	"Path": "org.boon.collections.DoubleList.toDoubleList",
	"Comment": "creates a primitive list based on an input list and a property path",
	"Method": "DoubleList toDoubleList(Collection<?> inputList,String propertyPath){\r\n    if (inputList.size() == 0) {\r\n        return new DoubleList(0);\r\n    }\r\n    DoubleList outputList = new DoubleList(inputList.size());\r\n    if (propertyPath.contains(\".\") || propertyPath.contains(\"[\")) {\r\n        String[] properties = StringScanner.splitByDelimiters(propertyPath, \".[]\");\r\n        for (Object o : inputList) {\r\n            outputList.add(BeanUtils.getPropertyDouble(o, properties));\r\n        }\r\n    } else {\r\n        Map<String, FieldAccess> fields = BeanUtils.getFieldsFromObject(inputList.iterator().next());\r\n        FieldAccess fieldAccess = fields.get(propertyPath);\r\n        for (Object o : inputList) {\r\n            outputList.add(fieldAccess.getDouble(o));\r\n        }\r\n    }\r\n    return outputList;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.data.managers.AccountController.alertFailedLogin",
	"Comment": "alerts a failed login with a popup showing the specific error.",
	"Method": "void alertFailedLogin(String exceptionClass,String message,int tries){\r\n    System.out.println(\"Error: \" + exceptionClass + StringLiterals.NEWLINE + message);\r\n    JOptionPane.showMessageDialog(WindowStuffHelper.ALWAYS_ON_TOP_PARENT, \"Unfortunately, your login has failed. Reason: \" + StringLiterals.NEWLINE + exceptionClass + \": \" + message + StringLiterals.NEWLINE + \"This is try number \" + tries + \".\" + StringLiterals.NEWLINE + \"Press OK to try again.\", \"Login Failed\", JOptionPane.ERROR_MESSAGE);\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.CalibrationDetectorChessboard.gridChess",
	"Comment": "this target is composed of a checkered chess board like squares.each corner of an interior square\ttouches an adjacent square, but the sides are separated.only interior square corners provide\tcalibration points.",
	"Method": "List<Point2D_F64> gridChess(int numRows,int numCols,double squareWidth){\r\n    List<Point2D_F64> all = new ArrayList();\r\n    numCols = numCols - 1;\r\n    numRows = numRows - 1;\r\n    double startX = -((numCols - 1) * squareWidth) / 2.0;\r\n    double startY = -((numRows - 1) * squareWidth) / 2.0;\r\n    for (int i = numRows - 1; i >= 0; i--) {\r\n        double y = startY + i * squareWidth;\r\n        for (int j = 0; j < numCols; j++) {\r\n            double x = startX + j * squareWidth;\r\n            all.add(new Point2D_F64(x, y));\r\n        }\r\n    }\r\n    return all;\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.fh04.SegmentFelzenszwalbHuttenlocher04.find",
	"Comment": "finds the root given child.if the child does not point directly to the parent find the parent and make\tthe child point directly towards it.",
	"Method": "int find(int child){\r\n    int root = graph.data[child];\r\n    if (root == graph.data[root])\r\n        return root;\r\n    int inputChild = child;\r\n    while (root != child) {\r\n        child = root;\r\n        root = graph.data[child];\r\n    }\r\n    graph.data[inputChild] = root;\r\n    return root;\r\n}"
}, {
	"Path": "com.bugsnag.android.Client.setMetaData",
	"Comment": "set the global diagnostic information to be send with every error.",
	"Method": "void setMetaData(MetaData metaData){\r\n    config.setMetaData(metaData);\r\n}"
}, {
	"Path": "boofcv.examples.recognition.ExampleClassifySceneKnn.learnAndSave",
	"Comment": "process all the data in the training data set to learn the classifications.see code for details.",
	"Method": "void learnAndSave(){\r\n    System.out.println(\"======== Learning Classifier\");\r\n    AssignCluster<double[]> assignment;\r\n    if (new File(CLUSTER_FILE_NAME).exists()) {\r\n        assignment = UtilIO.load(CLUSTER_FILE_NAME);\r\n    } else {\r\n        System.out.println(\" Computing clusters\");\r\n        assignment = computeClusters();\r\n    }\r\n    FeatureToWordHistogram_F64 featuresToHistogram = new FeatureToWordHistogram_F64(assignment, HISTOGRAM_HARD);\r\n    List<HistogramScene> memory;\r\n    if (!new File(HISTOGRAM_FILE_NAME).exists()) {\r\n        System.out.println(\" computing histograms\");\r\n        memory = computeHistograms(featuresToHistogram);\r\n        UtilIO.save(memory, HISTOGRAM_FILE_NAME);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.GenericCalibrationZhang99.linearEstimate",
	"Comment": "see how well it computes an initial guess at the parameters given perfect inputs",
	"Method": "void linearEstimate(){\r\n    List<Point2D_F64> grid = GenericCalibrationGrid.standardLayout();\r\n    for (Zhang99IntrinsicParam intrinsic : createParametersForLinearTest(rand)) {\r\n        Zhang99AllParam expected = GenericCalibrationGrid.createStandardParam(intrinsic, 3, rand);\r\n        List<CalibrationObservation> observations = GenericCalibrationGrid.createObservations(expected, grid);\r\n        CalibrationPlanarGridZhang99 alg = new CalibrationPlanarGridZhang99(grid, intrinsic.createLike());\r\n        Zhang99AllParam found = expected.createLike();\r\n        alg.linearEstimate(observations, found);\r\n        checkIntrinsicOnly((CM) expected.getIntrinsic().getCameraModel(), (CM) found.getIntrinsic().getCameraModel(), 0.01, 0.1, 0.1);\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.JsonWriter.replaceTop",
	"Comment": "replace the value on the top of the stack with the given value.",
	"Method": "void replaceTop(JsonScope topOfStack){\r\n    stack.set(stack.size() - 1, topOfStack);\r\n}"
}, {
	"Path": "boofcv.alg.transform.ii.IntegralImageOps.convolveSparse",
	"Comment": "convolves a kernel around a single point in the integral image.",
	"Method": "float convolveSparse(GrayF32 integral,IntegralKernel kernel,int x,int y,double convolveSparse,GrayF64 integral,IntegralKernel kernel,int x,int y,int convolveSparse,GrayS32 integral,IntegralKernel kernel,int x,int y,long convolveSparse,GrayS64 integral,IntegralKernel kernel,int x,int y){\r\n    return ImplIntegralImageOps.convolveSparse(integral, kernel, x, y);\r\n}"
}, {
	"Path": "boofcv.misc.CircularIndex.distanceP",
	"Comment": "returns how many elements away in the positive direction you need to travel to get from\tindex0 to index1.",
	"Method": "int distanceP(int index0,int index1,int size){\r\n    int difference = index1 - index0;\r\n    if (difference < 0) {\r\n        difference = size + difference;\r\n    }\r\n    return difference;\r\n}"
}, {
	"Path": "boofcv.alg.geo.structure.ProjectiveStructureByFactorization.initialize",
	"Comment": "initializes internal data structures. must be called first",
	"Method": "void initialize(int numFeatures,int numViews){\r\n    depths.reshape(numViews, numFeatures);\r\n    pixels.reshape(numViews * 2, numFeatures);\r\n    pixelScale = 0;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.grid.DetectSquareGridFiducial.configureContourDetector",
	"Comment": "configures the contour detector based on the image size. setting a maximum contour and turning off recording\tof inner contours and improve speed and reduce the memory foot print significantly.",
	"Method": "void configureContourDetector(T gray){\r\n    int maxContourSize = Math.max(gray.width, gray.height) / Math.max(numCols, numRows);\r\n    BinaryContourFinder contourFinder = detectorSquare.getDetector().getContourFinder();\r\n    contourFinder.setMaxContour(maxContourSize * 4 * 2);\r\n    contourFinder.setSaveInnerContour(false);\r\n}"
}, {
	"Path": "boofcv.alg.misc.GImageStatistics.meanDiffAbs",
	"Comment": "computes the mean of the absolute value of the difference between the two images across all bands",
	"Method": "double meanDiffAbs(T inputA,T inputB){\r\n    if (inputA instanceof ImageGray) {\r\n        if (GrayU8.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((GrayU8) inputA, (GrayU8) inputB);\r\n        } else if (GrayS8.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((GrayS8) inputA, (GrayS8) inputB);\r\n        } else if (GrayU16.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((GrayU16) inputA, (GrayU16) inputB);\r\n        } else if (GrayS16.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((GrayS16) inputA, (GrayS16) inputB);\r\n        } else if (GrayS32.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((GrayS32) inputA, (GrayS32) inputB);\r\n        } else if (GrayS64.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((GrayS64) inputA, (GrayS64) inputB);\r\n        } else if (GrayF32.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((GrayF32) inputA, (GrayF32) inputB);\r\n        } else if (GrayF64.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((GrayF64) inputA, (GrayF64) inputB);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type\");\r\n        }\r\n    } else if (inputA instanceof ImageInterleaved) {\r\n        if (InterleavedU8.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((InterleavedU8) inputA, (InterleavedU8) inputB);\r\n        } else if (InterleavedS8.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((InterleavedS8) inputA, (InterleavedS8) inputB);\r\n        } else if (InterleavedU16.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((InterleavedU16) inputA, (InterleavedU16) inputB);\r\n        } else if (InterleavedS16.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((InterleavedS16) inputA, (InterleavedS16) inputB);\r\n        } else if (InterleavedS32.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((InterleavedS32) inputA, (InterleavedS32) inputB);\r\n        } else if (InterleavedS64.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((InterleavedS64) inputA, (InterleavedS64) inputB);\r\n        } else if (InterleavedF32.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((InterleavedF32) inputA, (InterleavedF32) inputB);\r\n        } else if (InterleavedF64.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffAbs((InterleavedF64) inputA, (InterleavedF64) inputB);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type\");\r\n        }\r\n    } else {\r\n        throw new IllegalArgumentException(\"Planar images needs to be added\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomQuadPnP.estimateMotion",
	"Comment": "estimates camera egomotion between the two most recent image frames",
	"Method": "boolean estimateMotion(){\r\n    modelFitData.reset();\r\n    Point2D_F64 normLeft = new Point2D_F64();\r\n    Point2D_F64 normRight = new Point2D_F64();\r\n    for (int i = 0; i < quadViews.size; i++) {\r\n        QuadView obs = quadViews.get(i);\r\n        leftImageToNorm.compute(obs.v0.x, obs.v0.y, normLeft);\r\n        rightImageToNorm.compute(obs.v1.x, obs.v1.y, normRight);\r\n        triangulate.triangulate(normLeft, normRight, leftToRight, obs.X);\r\n        if (!Double.isInfinite(obs.X.normSq())) {\r\n            Stereo2D3D data = modelFitData.grow();\r\n            leftImageToNorm.compute(obs.v2.x, obs.v2.y, data.leftObs);\r\n            rightImageToNorm.compute(obs.v3.x, obs.v3.y, data.rightObs);\r\n            data.location.set(obs.X);\r\n        }\r\n    }\r\n    if (!matcher.process(modelFitData.toList()))\r\n        return false;\r\n    Se3_F64 oldToNew = matcher.getModelParameters();\r\n    if (modelRefiner != null) {\r\n        Se3_F64 found = new Se3_F64();\r\n        if (modelRefiner.fitModel(matcher.getMatchSet(), oldToNew, found)) {\r\n            found.invert(newToOld);\r\n        } else {\r\n            oldToNew.invert(newToOld);\r\n        }\r\n    } else {\r\n        oldToNew.invert(newToOld);\r\n    }\r\n    Se3_F64 temp = new Se3_F64();\r\n    newToOld.concat(leftCamToWorld, temp);\r\n    leftCamToWorld.set(temp);\r\n    return true;\r\n}"
}, {
	"Path": "org.boon.core.reflection.BeanUtils.getCollectionProp",
	"Comment": "this is an amazing little recursive method. it walks a fanout ofnested collection to pull out the leaf nodes",
	"Method": "Object getCollectionProp(Object o,String propName,int index,String[] path){\r\n    o = _getFieldValuesFromCollectionOrArray(o, propName);\r\n    if (index + 1 == path.length) {\r\n        return o;\r\n    } else {\r\n        index++;\r\n        return getCollectionProp(o, path[index], index, path);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.sfot.SparseFlowObjectTracker.update",
	"Comment": "given the input image compute the new location of the target region and store the results in output.",
	"Method": "boolean update(Image input,RectangleRotate_F64 output){\r\n    if (trackLost)\r\n        return false;\r\n    trackFeatures(input, region);\r\n    if (pairs.size() < config.numberOfSamples) {\r\n        System.out.println(\"Lack of sample pairs\");\r\n        trackLost = true;\r\n        return false;\r\n    }\r\n    if (!estimateMotion.process(pairs.toList())) {\r\n        System.out.println(\"estimate motion failed\");\r\n        trackLost = true;\r\n        return false;\r\n    }\r\n    if (estimateMotion.getFitQuality() > config.robustMaxError) {\r\n        System.out.println(\"exceeded Max estimation error\");\r\n        trackLost = true;\r\n        return false;\r\n    }\r\n    ScaleTranslateRotate2D model = estimateMotion.getModelParameters();\r\n    region.width *= model.scale;\r\n    region.height *= model.scale;\r\n    double c = Math.cos(model.theta);\r\n    double s = Math.sin(model.theta);\r\n    double x = region.cx;\r\n    double y = region.cy;\r\n    region.cx = (x * c - y * s) * model.scale + model.transX;\r\n    region.cy = (x * s + y * c) * model.scale + model.transY;\r\n    region.theta += model.theta;\r\n    output.set(region);\r\n    swapImages();\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.BaseDetectFiducialSquare.computeFractionBoundary",
	"Comment": "computes the fraction of pixels inside the image border which are black",
	"Method": "double computeFractionBoundary(float pixelThreshold){\r\n    final int w = square.width;\r\n    int radius = (int) (w * borderWidthFraction);\r\n    int innerWidth = w - 2 * radius;\r\n    int total = w * w - innerWidth * innerWidth;\r\n    int count = 0;\r\n    for (int y = 0; y < radius; y++) {\r\n        int indexTop = y * w;\r\n        int indexBottom = (w - radius + y) * w;\r\n        for (int x = 0; x < w; x++) {\r\n            if (square.data[indexTop++] < pixelThreshold)\r\n                count++;\r\n            if (square.data[indexBottom++] < pixelThreshold)\r\n                count++;\r\n        }\r\n    }\r\n    for (int y = radius; y < w - radius; y++) {\r\n        int indexLeft = y * w;\r\n        int indexRight = y * w + w - radius;\r\n        for (int x = 0; x < radius; x++) {\r\n            if (square.data[indexLeft++] < pixelThreshold)\r\n                count++;\r\n            if (square.data[indexRight++] < pixelThreshold)\r\n                count++;\r\n        }\r\n    }\r\n    return count / (double) total;\r\n}"
}, {
	"Path": "org.boon.Str.addObjects",
	"Comment": "add many objects converted to strings together.null are ignored so be careful.",
	"Method": "String addObjects(Object objects){\r\n    int length = 0;\r\n    for (Object obj : objects) {\r\n        if (obj == null) {\r\n            continue;\r\n        }\r\n        length += obj.toString().length();\r\n    }\r\n    CharBuf builder = CharBuf.createExact(length);\r\n    for (Object str : objects) {\r\n        if (str == null) {\r\n            continue;\r\n        }\r\n        builder.add(str.toString());\r\n    }\r\n    return builder.toString();\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationLinearDualQuadratic.constructMatrix",
	"Comment": "constructs the linear system by applying specified constraints",
	"Method": "void constructMatrix(DMatrixRMaj L){\r\n    L.reshape(cameras.size * eqs, 10);\r\n    double RR = this.aspectRatio * this.aspectRatio;\r\n    int index = 0;\r\n    for (int i = 0; i < cameras.size; i++) {\r\n        Projective P = cameras.get(i);\r\n        DMatrix3x3 A = P.A;\r\n        DMatrix3 B = P.a;\r\n        L.data[index++] = A.a11 * A.a31;\r\n        L.data[index++] = (A.a12 * A.a31 + A.a11 * A.a32);\r\n        L.data[index++] = (A.a13 * A.a31 + A.a11 * A.a33);\r\n        L.data[index++] = (B.a1 * A.a31 + A.a11 * B.a3);\r\n        L.data[index++] = A.a12 * A.a32;\r\n        L.data[index++] = (A.a13 * A.a32 + A.a12 * A.a33);\r\n        L.data[index++] = (B.a1 * A.a32 + A.a12 * B.a3);\r\n        L.data[index++] = A.a13 * A.a33;\r\n        L.data[index++] = (B.a1 * A.a33 + A.a13 * B.a3);\r\n        L.data[index++] = B.a1 * B.a3;\r\n        L.data[index++] = A.a21 * A.a31;\r\n        L.data[index++] = (A.a22 * A.a31 + A.a21 * A.a32);\r\n        L.data[index++] = (A.a23 * A.a31 + A.a21 * A.a33);\r\n        L.data[index++] = (B.a2 * A.a31 + A.a21 * B.a3);\r\n        L.data[index++] = A.a22 * A.a32;\r\n        L.data[index++] = (A.a23 * A.a32 + A.a22 * A.a33);\r\n        L.data[index++] = (B.a2 * A.a32 + A.a22 * B.a3);\r\n        L.data[index++] = A.a23 * A.a33;\r\n        L.data[index++] = (B.a2 * A.a33 + A.a23 * B.a3);\r\n        L.data[index++] = B.a2 * B.a3;\r\n        if (zeroSkew) {\r\n            L.data[index++] = A.a11 * A.a21;\r\n            L.data[index++] = (A.a12 * A.a21 + A.a11 * A.a22);\r\n            L.data[index++] = (A.a13 * A.a21 + A.a11 * A.a23);\r\n            L.data[index++] = (B.a1 * A.a21 + A.a11 * B.a2);\r\n            L.data[index++] = A.a12 * A.a22;\r\n            L.data[index++] = (A.a13 * A.a22 + A.a12 * A.a23);\r\n            L.data[index++] = (B.a1 * A.a22 + A.a12 * B.a2);\r\n            L.data[index++] = A.a13 * A.a23;\r\n            L.data[index++] = (B.a1 * A.a23 + A.a13 * B.a2);\r\n            L.data[index++] = B.a1 * B.a2;\r\n        }\r\n        if (knownAspect) {\r\n            L.data[index++] = A.a11 * A.a11 * RR - A.a21 * A.a21;\r\n            L.data[index++] = 2 * (A.a11 * A.a12 * RR - A.a21 * A.a22);\r\n            L.data[index++] = 2 * (A.a11 * A.a13 * RR - A.a21 * A.a23);\r\n            L.data[index++] = 2 * (A.a11 * B.a1 * RR - A.a21 * B.a2);\r\n            L.data[index++] = A.a12 * A.a12 * RR - A.a22 * A.a22;\r\n            L.data[index++] = 2 * (A.a12 * A.a13 * RR - A.a22 * A.a23);\r\n            L.data[index++] = 2 * (A.a12 * B.a1 * RR - A.a22 * B.a2);\r\n            L.data[index++] = A.a13 * A.a13 * RR - A.a23 * A.a23;\r\n            L.data[index++] = 2 * (A.a13 * B.a1 * RR - A.a23 * B.a2);\r\n            L.data[index++] = B.a1 * B.a1 * RR - B.a2 * B.a2;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.transform.fft.GDiscreteFourierTransformOps.realToComplex",
	"Comment": "converts a regular image into a complex interleaved image with the imaginary component set to zero.",
	"Method": "void realToComplex(GrayF real,ImageInterleaved complex){\r\n    if (complex instanceof InterleavedF32) {\r\n        DiscreteFourierTransformOps.realToComplex((GrayF32) real, (InterleavedF32) complex);\r\n    } else if (complex instanceof InterleavedF64) {\r\n        DiscreteFourierTransformOps.realToComplex((GrayF64) real, (InterleavedF64) complex);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown image type\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.examples.recognition.ExampleColorHistogramLookup.coupledRGB",
	"Comment": "constructs a 3d histogram using rgb.rgb is a popular color space, but the resulting histogram will\tdepend on lighting conditions and might not produce the accurate results.",
	"Method": "List<double[]> coupledRGB(List<File> images){\r\n    List<double[]> points = new ArrayList();\r\n    Planar<GrayF32> rgb = new Planar(GrayF32.class, 1, 1, 3);\r\n    for (File f : images) {\r\n        BufferedImage buffered = UtilImageIO.loadImage(f.getPath());\r\n        if (buffered == null)\r\n            throw new RuntimeException(\"Can't load image!\");\r\n        rgb.reshape(buffered.getWidth(), buffered.getHeight());\r\n        ConvertBufferedImage.convertFrom(buffered, rgb, true);\r\n        Histogram_F64 histogram = new Histogram_F64(10, 10, 10);\r\n        histogram.setRange(0, 0, 255);\r\n        histogram.setRange(1, 0, 255);\r\n        histogram.setRange(2, 0, 255);\r\n        GHistogramFeatureOps.histogram(rgb, histogram);\r\n        UtilFeature.normalizeL2(histogram);\r\n        points.add(histogram.value);\r\n    }\r\n    return points;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.DetectCircleGrid.pruneIncorrectShape",
	"Comment": "remove grids which cannot possible match the expected shape",
	"Method": "void pruneIncorrectShape(FastQueue<Grid> grids,int numRows,int numCols){\r\n    for (int i = grids.size() - 1; i >= 0; i--) {\r\n        Grid g = grids.get(i);\r\n        if ((g.rows != numRows || g.columns != numCols) && (g.rows != numCols || g.columns != numRows)) {\r\n            grids.remove(i);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.TestDescribePointBriefSO.testOrientation",
	"Comment": "checks to see if changing orientation changes the description",
	"Method": "void testOrientation(){\r\n    GrayF32 input = createImage(width, height);\r\n    DescribePointBriefSO<GrayF32> alg = createAlg();\r\n    TupleDesc_B desc1 = alg.createFeature();\r\n    TupleDesc_B desc2 = alg.createFeature();\r\n    alg.setImage(input);\r\n    alg.process(input.width / 2, input.height / 2, 0, briefRadius, desc1);\r\n    alg.process(input.width / 2, input.height / 2, 1, briefRadius, desc2);\r\n    boolean identical = true;\r\n    for (int i = 0; i < desc1.data.length; i++) {\r\n        if (desc1.data[i] != desc2.data[i])\r\n            identical = false;\r\n    }\r\n    assertFalse(identical);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodePositionPatternDetector.process",
	"Comment": "detects position patterns inside the image and forms a graph.",
	"Method": "void process(T gray,GrayU8 binary){\r\n    configureContourDetector(gray);\r\n    recycleData();\r\n    positionPatterns.reset();\r\n    interpolate.setImage(gray);\r\n    squareDetector.process(gray, binary);\r\n    long time0 = System.nanoTime();\r\n    squaresToPositionList();\r\n    long time1 = System.nanoTime();\r\n    createPositionPatternGraph();\r\n    double milli = (time1 - time0) * 1e-6;\r\n    milliGraph.update(milli);\r\n    if (profiler) {\r\n        DetectPolygonFromContour<T> detectorPoly = squareDetector.getDetector();\r\n        System.out.printf(\" contour %5.1f shapes %5.1f adjust_bias %5.2f PosPat %6.2f\", detectorPoly.getMilliContour(), detectorPoly.getMilliShapes(), squareDetector.getMilliAdjustBias(), milliGraph.getAverage());\r\n    }\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.logging.ConsoleOutStream.formatString",
	"Comment": "formats the given message with the timestamp appended to the front.",
	"Method": "String formatString(String s){\r\n    if (s.equals(newLine)) {\r\n        return s;\r\n    }\r\n    return String.format(\"[%s]: %s\", timestamp(), s);\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactorySteerCoefficients.separable",
	"Comment": "coefficients for even or odd parity separable polynomials.",
	"Method": "SteerableCoefficients separable(int order){\r\n    return new Separable(order);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.BaseDetectFiducialSquare.configureContourDetector",
	"Comment": "configures the contour detector based on the image size. setting a maximum contour and turning off recording\tof inner contours and improve speed and reduce the memory foot print significantly.",
	"Method": "void configureContourDetector(T gray){\r\n    int maxContourSize = Math.min(gray.width, gray.height) * 4;\r\n    BinaryContourFinder contourFinder = squareDetector.getDetector().getContourFinder();\r\n    contourFinder.setMaxContour(maxContourSize);\r\n    contourFinder.setSaveInnerContour(false);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldLearning.learnAmbiguousNegative",
	"Comment": "mark regions which were local maximums and had high confidence as negative.these regions were\tcandidates for the tracker but were not selected",
	"Method": "void learnAmbiguousNegative(Rectangle2D_F64 targetRegion){\r\n    TldHelperFunctions.convertRegion(targetRegion, targetRegion_I32);\r\n    if (detection.isSuccess()) {\r\n        TldRegion best = detection.getBest();\r\n        double overlap = helper.computeOverlap(best.rect, targetRegion_I32);\r\n        if (overlap <= config.overlapLower) {\r\n            template.addDescriptor(false, best.rect);\r\n        }\r\n        List<ImageRectangle> ambiguous = detection.getAmbiguousRegions();\r\n        for (ImageRectangle r : ambiguous) {\r\n            overlap = helper.computeOverlap(r, targetRegion_I32);\r\n            if (overlap <= config.overlapLower) {\r\n                fern.learnFernNoise(false, r);\r\n                template.addDescriptor(false, r);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationRefineDualQuadratic.refine",
	"Comment": "refine calibration matrix k given the dual absolute quadratic q.",
	"Method": "boolean refine(List<CameraPinhole> calibration,DMatrix4x4 Q){\r\n    if (calibration.size() != cameras.size)\r\n        throw new RuntimeException(\"Calibration and cameras do not match\");\r\n    if (cameras.size < 3)\r\n        throw new IllegalArgumentException(\"At least 3 cameras are required. You should have more\");\r\n    computeNumberOfCalibrationParameters();\r\n    func = new ResidualK();\r\n    ConvertDMatrixStruct.convert(Q, _Q);\r\n    nullspace.process(_Q, 1, p);\r\n    CommonOps_DDRM.divide(p, p.get(3));\r\n    p.numRows = 3;\r\n    encode(calibration, p, param);\r\n    optimizer.setVerbose(System.out, 0);\r\n    optimizer.setFunction(func, null);\r\n    optimizer.initialize(param.data, 1e-6, 1e-5);\r\n    if (!UtilOptimize.process(optimizer, 100))\r\n        return false;\r\n    decode(optimizer.getParameters(), calibration, p);\r\n    recomputeQ(p, Q);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TrifocalLinearPoint7.process",
	"Comment": "estimates the trifocal tensor given the set of observations",
	"Method": "boolean process(List<AssociatedTriple> observations,TrifocalTensor solution){\r\n    if (observations.size() < 7)\r\n        throw new IllegalArgumentException(\"At least 7 correspondences must be provided. Found \" + observations.size());\r\n    LowLevelMultiViewOps.computeNormalization(observations, N1, N2, N3);\r\n    createLinearSystem(observations);\r\n    solveLinearSystem();\r\n    extractEpipoles.setTensor(solutionN);\r\n    extractEpipoles.extractEpipoles(e2, e3);\r\n    enforce.process(e2, e3, A);\r\n    enforce.extractSolution(solutionN);\r\n    removeNormalization(solution);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.misc.GImageMiscOps.insertBand",
	"Comment": "computes the mean of the absolute value of the difference between the two images.",
	"Method": "void insertBand(ImageGray input,int band,ImageMultiBand output){\r\n    if (output instanceof ImageInterleaved) {\r\n        if (InterleavedI8.class.isAssignableFrom(output.getClass())) {\r\n            ImageMiscOps.insertBand((GrayI8) input, band, (InterleavedI8) output);\r\n        } else if (InterleavedI16.class.isAssignableFrom(output.getClass())) {\r\n            ImageMiscOps.insertBand((GrayI16) input, band, (InterleavedI16) output);\r\n        } else if (InterleavedS32.class == output.getClass()) {\r\n            ImageMiscOps.insertBand((GrayS32) input, band, (InterleavedS32) output);\r\n        } else if (InterleavedS64.class == output.getClass()) {\r\n            ImageMiscOps.insertBand((GrayS64) input, band, (InterleavedS64) output);\r\n        } else if (InterleavedF32.class == output.getClass()) {\r\n            ImageMiscOps.insertBand((GrayF32) input, band, (InterleavedF32) output);\r\n        } else if (InterleavedF64.class == output.getClass()) {\r\n            ImageMiscOps.insertBand((GrayF64) input, band, (InterleavedF64) output);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type: \" + input.getClass().getSimpleName());\r\n        }\r\n    } else if (output instanceof Planar) {\r\n        Planar m = (Planar) output;\r\n        m.getBand(band).setTo(input);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown image type: \" + input.getClass().getSimpleName());\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.PackedBits8.growArray",
	"Comment": "increases the size of the data array so that it can store an addition number of bits",
	"Method": "void growArray(int amountBits,boolean saveValue){\r\n    size = size + amountBits;\r\n    int N = size / 8 + (size % 8 == 0 ? 0 : 1);\r\n    if (N > data.length) {\r\n        int extra = Math.min(1024, N + 10);\r\n        byte[] tmp = new byte[N + extra];\r\n        if (saveValue)\r\n            System.arraycopy(data, 0, tmp, 0, data.length);\r\n        this.data = tmp;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.TestLinearContourLabelChang2004.checkContour",
	"Comment": "creates a list of every pixel with the specified label that is on the contour.removes duplicate points\tin the found contour.sees if the two lists are equivalent.",
	"Method": "void checkContour(LinearContourLabelChang2004 alg,GrayS32 labeled,int rule){\r\n    FastQueue<ContourPacked> contours = alg.getContours();\r\n    for (int i = 0; i < contours.size(); i++) {\r\n        ContourPacked c = contours.get(i);\r\n        assertTrue(c.id > 0);\r\n        List<Point2D_I32> found = new ArrayList();\r\n        addPointsToList(alg, c.externalIndex, found);\r\n        for (int j = 0; j < c.internalIndexes.size; j++) {\r\n            addPointsToList(alg, c.internalIndexes.get(j), found);\r\n        }\r\n        found = removeDuplicates(found);\r\n        List<Point2D_I32> expected = rule == 8 ? findContour8(labeled, c.id) : findContour4(labeled, c.id);\r\n        assertEquals(expected.size(), found.size());\r\n        for (Point2D_I32 f : found) {\r\n            boolean match = false;\r\n            for (Point2D_I32 e : expected) {\r\n                if (f.x == e.x && f.y == e.y) {\r\n                    match = true;\r\n                    break;\r\n                }\r\n            }\r\n            assertTrue(match);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.BinaryEllipseDetectorPixel.adjustElipseForBinaryBias",
	"Comment": "in a binary image the contour on the right and bottom is off by one pixel. this is because the block region\textends the entire pixel not just the lower extent which is where it is indexed from.",
	"Method": "void adjustElipseForBinaryBias(EllipseRotated_F64 ellipse){\r\n    ellipse.center.x += 0.5;\r\n    ellipse.center.y += 0.5;\r\n    ellipse.a += 0.5;\r\n    ellipse.b += 0.5;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.TestSquaresIntoRegularClusters.connectNodes_oneCluster",
	"Comment": "very easy scenario where a rectangular grid should be perefectly connected",
	"Method": "void connectNodes_oneCluster(){\r\n    List<Polygon2D_F64> squares = new ArrayList();\r\n    double width = 1;\r\n    for (int i = 0; i < 3; i++) {\r\n        for (int j = 0; j < 4; j++) {\r\n            squares.add(createSquare(i * 2 * width, j * 2 * width, 0, width));\r\n        }\r\n    }\r\n    SquaresIntoRegularClusters alg = new SquaresIntoRegularClusters(1.0, 6, 1.35);\r\n    alg.computeNodeInfo(squares);\r\n    alg.connectNodes();\r\n    assertEquals(2 * 4 + (2 + 4) * 3 + (1 * 2 * 4), countConnections(alg.nodes.toList()));\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.GenericFeatureDetectorTests.checkMultipleCalls",
	"Comment": "multiple calls to the same input should return the same results",
	"Method": "void checkMultipleCalls(){\r\n    GrayF32 input = new GrayF32(width, height);\r\n    renderCheckered(input);\r\n    Object alg = createDetector(50);\r\n    int firstFound = detectFeature(input, alg);\r\n    int secondFound = detectFeature(input, alg);\r\n    assertEquals(firstFound, secondFound);\r\n}"
}, {
	"Path": "org.boon.slumberdb.service.server.ResponseHandler.handleResponseFromDataStore",
	"Comment": "main exit from system.if you are debugging something not coming out of the system.start here.",
	"Method": "void handleResponseFromDataStore(Result result){\r\n    if (debug) {\r\n        logger.info(\"ResponseHandler::handleResponseFromDataStore\", result);\r\n    }\r\n    if (result instanceof SingleResult) {\r\n        SingleResult singleResult = (SingleResult) result;\r\n        int size = handleSingleResult(singleResult);\r\n        counter(size, singleResult.source());\r\n    } else if (result instanceof SearchBatchResult) {\r\n        SearchBatchResult searchBatchResult = (SearchBatchResult) result;\r\n        sendBatchResponse((BatchResult) result);\r\n        int size = searchBatchResult.getResults().size();\r\n        counter(size, searchBatchResult.source());\r\n    } else if (result instanceof BatchResult) {\r\n        BatchResult batchResult = (BatchResult) result;\r\n        int size = handleBatchResult(batchResult);\r\n        counter(size, batchResult.source());\r\n    } else if (result instanceof ErrorResult) {\r\n        ErrorResult errorResult = (ErrorResult) result;\r\n        int size = handleErrorResult(errorResult);\r\n        counter(size, errorResult.source());\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TrifocalLinearPoint7.removeNormalization",
	"Comment": "translates the trifocal tensor back into regular coordinate system",
	"Method": "void removeNormalization(TrifocalTensor solution){\r\n    DMatrixRMaj N2_inv = N2.matrixInv();\r\n    DMatrixRMaj N3_inv = N3.matrixInv();\r\n    DMatrixRMaj N1 = this.N1.matrix();\r\n    for (int i = 0; i < 3; i++) {\r\n        DMatrixRMaj T = solution.getT(i);\r\n        for (int j = 0; j < 3; j++) {\r\n            for (int k = 0; k < 3; k++) {\r\n                double sum = 0;\r\n                for (int r = 0; r < 3; r++) {\r\n                    double n1 = N1.get(r, i);\r\n                    DMatrixRMaj TN = solutionN.getT(r);\r\n                    for (int s = 0; s < 3; s++) {\r\n                        double n2 = N2_inv.get(j, s);\r\n                        for (int t = 0; t < 3; t++) {\r\n                            sum += n1 * n2 * N3_inv.get(k, t) * TN.get(s, t);\r\n                        }\r\n                    }\r\n                }\r\n                T.set(j, k, sum);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.TestPruneStructureFromSceneMetric.checkAllObservationsArePerfect",
	"Comment": "see if all the observations are perfect. this acts as a sanity check on the scenes structure after modification",
	"Method": "void checkAllObservationsArePerfect(){\r\n    Point3D_F64 worldX = new Point3D_F64();\r\n    Point3D_F64 cameraX = new Point3D_F64();\r\n    Point2D_F64 predicted = new Point2D_F64();\r\n    Point2D_F64 found = new Point2D_F64();\r\n    for (int viewIdx = 0; viewIdx < structure.views.length; viewIdx++) {\r\n        BundleAdjustmentCamera camera = structure.cameras[structure.views[viewIdx].camera].model;\r\n        Se3_F64 worldToView = structure.views[viewIdx].worldToView;\r\n        for (int obsIdx = 0; obsIdx < observations.views[viewIdx].size(); obsIdx++) {\r\n            Point f = structure.points[observations.views[viewIdx].point.get(obsIdx)];\r\n            f.get(worldX);\r\n            worldToView.transform(worldX, cameraX);\r\n            assertTrue(cameraX.z > 0);\r\n            camera.project(cameraX.x, cameraX.y, cameraX.z, predicted);\r\n            observations.views[viewIdx].get(obsIdx, found);\r\n            assertTrue(predicted.distance(found) < 1e-4);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TestTrifocalExtractGeometries.extractEpipoles",
	"Comment": "randomly general several scenarios and see if it produces the correct solution",
	"Method": "void extractEpipoles(){\r\n    TrifocalExtractGeometries alg = new TrifocalExtractGeometries();\r\n    for (int i = 0; i < 5; i++) {\r\n        createRandomScenario();\r\n        Point3D_F64 found2 = new Point3D_F64();\r\n        Point3D_F64 found3 = new Point3D_F64();\r\n        TrifocalTensor input = tensor.copy();\r\n        alg.setTensor(input);\r\n        alg.extractEpipoles(found2, found3);\r\n        for (int j = 0; j < 3; j++) assertTrue(MatrixFeatures_DDRM.isIdentical(tensor.getT(j), input.getT(j), 1e-8));\r\n        Point3D_F64 space = new Point3D_F64();\r\n        GeometryMath_F64.multTran(F2, found2, space);\r\n        assertEquals(0, space.norm(), 1e-8);\r\n        GeometryMath_F64.multTran(F3, found3, space);\r\n        assertEquals(0, space.norm(), 1e-8);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.flow.DenseFlowPyramidBase.warpImageTaylor",
	"Comment": "takes the flow from the previous lower resolution layer and uses it to initialize the flow\tin the current layer.adjusts for change in image scale.",
	"Method": "void warpImageTaylor(GrayF32 before,GrayF32 flowX,GrayF32 flowY,GrayF32 after){\r\n    interp.setBorder(FactoryImageBorder.single(before.getImageType().getImageClass(), BorderType.EXTENDED));\r\n    interp.setImage(before);\r\n    for (int y = 0; y < before.height; y++) {\r\n        int pixelIndex = y * before.width;\r\n        for (int x = 0; x < before.width; x++, pixelIndex++) {\r\n            float u = flowX.data[pixelIndex];\r\n            float v = flowY.data[pixelIndex];\r\n            float wx = x + u;\r\n            float wy = y + v;\r\n            after.data[pixelIndex] = interp.get(wx, wy);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.boon.slumberdb.stores.log.CollectorManager.manageInputWriterChannel",
	"Comment": "queue and batch writer main logic.this is where the magic happens.",
	"Method": "void manageInputWriterChannel(){\r\n    try {\r\n        ByteBuffer dataToWriteToFile;\r\n        dataToWriteToFile = inputChannel.poll();\r\n        if (dataToWriteToFile == null) {\r\n            queueEmptyMaybeFlush();\r\n            dataToWriteToFile = inputChannel.poll();\r\n        }\r\n        if (dataToWriteToFile == null) {\r\n            dataToWriteToFile = waitForNextDataToWrite();\r\n        }\r\n        if (dataToWriteToFile != null) {\r\n            writer.nextBufferToWrite(dataToWriteToFile);\r\n            if (RECYCLE_BUFFER) {\r\n                recycleChannel.offer(dataToWriteToFile);\r\n            }\r\n        }\r\n    } catch (InterruptedException ex) {\r\n        throw ex;\r\n    } catch (Exception ex) {\r\n        ex.printStackTrace();\r\n        ex.printStackTrace(System.err);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.DescribePointBinaryCompare.setImage",
	"Comment": "specifies the image from which feature descriptions are to be created.",
	"Method": "void setImage(T image){\r\n    this.image = image;\r\n    for (int i = 0; i < definition.samplePoints.length; i++) {\r\n        Point2D_I32 a = definition.samplePoints[i];\r\n        offsets[i] = image.stride * a.y + a.x;\r\n    }\r\n    for (int i = 0; i < definition.compare.length; i++) {\r\n        Point2D_I32 p = definition.compare[i];\r\n        offsetsA[i] = offsets[p.x];\r\n        offsetsB[i] = offsets[p.y];\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareCrossClustersIntoGrids.checkEdgeCount",
	"Comment": "looks at the edge count in each node and sees if it has the expected number",
	"Method": "boolean checkEdgeCount(SquareGrid grid){\r\n    int left = 0, right = grid.columns - 1;\r\n    int top = 0, bottom = grid.rows - 1;\r\n    for (int row = 0; row < grid.rows; row++) {\r\n        boolean skip = grid.get(row, 0) == null;\r\n        for (int col = 0; col < grid.columns; col++) {\r\n            SquareNode n = grid.get(row, col);\r\n            if (skip) {\r\n                if (n != null)\r\n                    return false;\r\n            } else {\r\n                boolean horizontalEdge = col == left || col == right;\r\n                boolean verticalEdge = row == top || row == bottom;\r\n                boolean outer = horizontalEdge || verticalEdge;\r\n                int connections = n.getNumberOfConnections();\r\n                if (outer) {\r\n                    if (horizontalEdge && verticalEdge) {\r\n                        if (connections != 1)\r\n                            return false;\r\n                    } else if (connections != 2)\r\n                        return false;\r\n                } else {\r\n                    if (connections != 4)\r\n                        return false;\r\n                }\r\n            }\r\n            skip = !skip;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.BinaryImageOps.labelToClusters",
	"Comment": "scans through the labeled image and adds the coordinate of each pixel that has been\tlabeled to a list specific to its label.",
	"Method": "List<List<Point2D_I32>> labelToClusters(GrayS32 labelImage,int numLabels,FastQueue<Point2D_I32> queue){\r\n    List<List<Point2D_I32>> ret = new ArrayList();\r\n    for (int i = 0; i < numLabels + 1; i++) {\r\n        ret.add(new ArrayList<Point2D_I32>());\r\n    }\r\n    if (queue == null) {\r\n        queue = new FastQueue(numLabels, Point2D_I32.class, true);\r\n    } else\r\n        queue.reset();\r\n    for (int y = 0; y < labelImage.height; y++) {\r\n        int start = labelImage.startIndex + y * labelImage.stride;\r\n        int end = start + labelImage.width;\r\n        for (int index = start; index < end; index++) {\r\n            int v = labelImage.data[index];\r\n            if (v > 0) {\r\n                Point2D_I32 p = queue.grow();\r\n                p.set(index - start, y);\r\n                ret.get(v).add(p);\r\n            }\r\n        }\r\n    }\r\n    if (ret.get(0).size() != 0)\r\n        throw new RuntimeException(\"BUG!\");\r\n    ret.remove(0);\r\n    return ret;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setQueryExecuteTimeLimitInMs",
	"Comment": "queries taking longer than this limit to execute are logged.",
	"Method": "void setQueryExecuteTimeLimitInMs(long queryExecuteTimeLimit){\r\n    setQueryExecuteTimeLimit(queryExecuteTimeLimit, TimeUnit.MILLISECONDS);\r\n}"
}, {
	"Path": "boofcv.abst.tracker.GenericTrackerObjectRectangleTests.zoom",
	"Comment": "zoom in and out without any visual translation of the object.e.g. the center is constant",
	"Method": "void zoom(double dir){\r\n    TrackerObjectQuad<T> tracker = create(imageType);\r\n    render(1, 0, 0);\r\n    assertTrue(tracker.initialize(input, initRegion));\r\n    double centerX = 20 + 50;\r\n    double centerY = 25 + (160 - 25) / 2.0;\r\n    for (int i = 0; i < 20; i++) {\r\n        double scale = 1 + dir * 0.2 * (i / 9.0);\r\n        double w2 = 100 * scale / 2.0;\r\n        double h2 = (160 - 25) * scale / 2.0;\r\n        double tranX = centerX - centerX * scale;\r\n        double tranY = centerY - centerY * scale;\r\n        render(scale, tranX, tranY);\r\n        assertTrue(tracker.process(input, where));\r\n        checkSolution(centerX - w2, centerY - h2, centerX + w2, centerY + h2, tolScale);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.misc.TestImplAverageDownSample.horizontal_3_to_2",
	"Comment": "the division will not be along pixels and symmetries are avoided",
	"Method": "void horizontal_3_to_2(){\r\n    List<Method> methods = find(\"horizontal\");\r\n    for (Method m : methods) {\r\n        Class typeSrc = m.getParameterTypes()[0];\r\n        Class typeDst = m.getParameterTypes()[1];\r\n        ImageGray src = GeneralizedImageOps.createSingleBand(typeSrc, 9, 3);\r\n        ImageGray dst = GeneralizedImageOps.createSingleBand(typeDst, 4, 3);\r\n        fillHorizontal(src);\r\n        m.invoke(null, src, dst);\r\n        for (int y = 0; y < src.height; y++) {\r\n            assertEquals(0.6666667f, GeneralizedImageOps.get(dst, 0, y), 1e-4f);\r\n            assertEquals(2.8888889f, GeneralizedImageOps.get(dst, 1, y), 1e-4f);\r\n            assertEquals(5.1111111f, GeneralizedImageOps.get(dst, 2, y), 1e-4f);\r\n            assertEquals(7.3333333f, GeneralizedImageOps.get(dst, 3, y), 1e-4f);\r\n        }\r\n    }\r\n    assertEquals(4, methods.size());\r\n}"
}, {
	"Path": "com.bugsnag.android.DeviceData.getScreenDensity",
	"Comment": "the screen density scaling factor of the current android device",
	"Method": "Float getScreenDensity(){\r\n    if (displayMetrics != null) {\r\n        return displayMetrics.density;\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.EstimateSceneUncalibrated.scoreForTriangulation",
	"Comment": "compute score to decide which motion to initialize structure from. a homography is fit to the\tobservations and the error compute. the homography should be a poor fit if the scene had 3d structure.\tthe 50% homography error is then scaled by the number of pairs to bias the score good matches",
	"Method": "double scoreForTriangulation(Motion motion){\r\n    DMatrixRMaj H = new DMatrixRMaj(3, 3);\r\n    View viewA = motion.viewSrc;\r\n    View viewB = motion.viewDst;\r\n    pairs.reset();\r\n    for (int i = 0; i < motion.associated.size(); i++) {\r\n        AssociatedIndex ai = motion.associated.get(i);\r\n        pairs.grow().set(viewA.observationPixels.get(ai.src), viewB.observationPixels.get(ai.dst));\r\n    }\r\n    if (!computeH.process(pairs.toList(), H))\r\n        return -1;\r\n    if (!refineH.fitModel(pairs.toList(), H, H))\r\n        return -1;\r\n    MultiViewOps.errorsHomographySymm(pairs.toList(), H, null, errors);\r\n    errors.sort();\r\n    return errors.getFraction(0.5) * Math.max(5, pairs.size - 20);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.HysteresisEdgeTracePoints.getContours",
	"Comment": "returns the found contours.returned data structures are subject to modification next time process is called.",
	"Method": "List<EdgeContour> getContours(){\r\n    return contours;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.ConfigNew.setFromObject",
	"Comment": "saves given object under the key. just for internal use, no typ checking!",
	"Method": "void setFromObject(ConfigKey configKey,Object obj){\r\n    switch(configKey.type) {\r\n        case BOOLEAN:\r\n            setBool(configKey, (Boolean) obj);\r\n            break;\r\n        case STRING:\r\n            setString(configKey, (String) obj);\r\n            break;\r\n        case INTEGER:\r\n            setInt(configKey, (Integer) obj);\r\n            break;\r\n        case DOUBLE:\r\n            setDouble(configKey, (Double) obj);\r\n            break;\r\n        default:\r\n            setJSONObject(configKey, new JSONObject(obj));\r\n            break;\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.setAutoCaptureSessions",
	"Comment": "sets whether or not bugsnag should automatically capture and report user sessions wheneverthe app enters the foreground.by default this behavior is disabled.",
	"Method": "void setAutoCaptureSessions(boolean autoCapture){\r\n    this.autoCaptureSessions = autoCapture;\r\n}"
}, {
	"Path": "boofcv.alg.geo.rectify.RectifyCalibrated.process",
	"Comment": "computes rectification transforms for both cameras and optionally a single calibration\tmatrix.",
	"Method": "void process(DMatrixRMaj K1,Se3_F64 worldToCamera1,DMatrixRMaj K2,Se3_F64 worldToCamera2){\r\n    SimpleMatrix sK1 = SimpleMatrix.wrap(K1);\r\n    SimpleMatrix sK2 = SimpleMatrix.wrap(K2);\r\n    SimpleMatrix R1 = SimpleMatrix.wrap(worldToCamera1.getR());\r\n    SimpleMatrix R2 = SimpleMatrix.wrap(worldToCamera2.getR());\r\n    SimpleMatrix T1 = new SimpleMatrix(3, 1, true, new double[] { worldToCamera1.getT().x, worldToCamera1.getT().y, worldToCamera1.getT().z });\r\n    SimpleMatrix T2 = new SimpleMatrix(3, 1, true, new double[] { worldToCamera2.getT().x, worldToCamera2.getT().y, worldToCamera2.getT().z });\r\n    SimpleMatrix KR1 = sK1.mult(R1);\r\n    SimpleMatrix KR2 = sK2.mult(R2);\r\n    SimpleMatrix c1 = R1.transpose().mult(T1.scale(-1));\r\n    SimpleMatrix c2 = R2.transpose().mult(T2.scale(-1));\r\n    selectAxises(R1, R2, c1, c2);\r\n    SimpleMatrix RR = new SimpleMatrix(3, 3, true, new double[] { v1.x, v1.y, v1.z, v2.x, v2.y, v2.z, v3.x, v3.y, v3.z });\r\n    K = sK1.plus(sK2).scale(0.5);\r\n    K.set(0, 1, 0);\r\n    SimpleMatrix KRR = K.mult(RR);\r\n    rect1.set(KRR.mult(KR1.invert()).getDDRM());\r\n    rect2.set(KRR.mult(KR2.invert()).getDDRM());\r\n    rectifiedR = RR.getDDRM();\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.TestDescribePointBriefSO.testIntensityInvariance",
	"Comment": "vary the intensity of the input image and see if the description changes.",
	"Method": "void testIntensityInvariance(){\r\n    GrayF32 input = createImage(width, height);\r\n    GrayF32 mod = input.clone();\r\n    GPixelMath.multiply(input, 2, mod);\r\n    DescribePointBriefSO<GrayF32> alg = createAlg();\r\n    TupleDesc_B desc1 = alg.createFeature();\r\n    TupleDesc_B desc2 = alg.createFeature();\r\n    alg.setImage(input);\r\n    alg.process(input.width / 2, input.height / 2, 0, briefRadius, desc1);\r\n    alg.setImage(mod);\r\n    alg.process(input.width / 2, input.height / 2, 0, briefRadius, desc2);\r\n    int count = 0;\r\n    for (int i = 0; i < desc1.numBits; i++) {\r\n        count += desc1.isBitTrue(i) == desc2.isBitTrue(i) ? 1 : 0;\r\n    }\r\n    assertTrue(count > desc1.numBits - 3);\r\n}"
}, {
	"Path": "boofcv.core.image.ConvertImage.convert",
	"Comment": "converts pixel values in the input image into an integer values from 0 to numvalues.",
	"Method": "GrayS8 convert(GrayU8 input,GrayS8 output,InterleavedS8 convert,InterleavedU8 input,InterleavedS8 output,GrayU16 convert,GrayU8 input,GrayU16 output,InterleavedU16 convert,InterleavedU8 input,InterleavedU16 output,GrayS16 convert,GrayU8 input,GrayS16 output,InterleavedS16 convert,InterleavedU8 input,InterleavedS16 output,GrayS32 convert,GrayU8 input,GrayS32 output,InterleavedS32 convert,InterleavedU8 input,InterleavedS32 output,GrayS64 convert,GrayU8 input,GrayS64 output,InterleavedS64 convert,InterleavedU8 input,InterleavedS64 output,GrayF32 convert,GrayU8 input,GrayF32 output,InterleavedF32 convert,InterleavedU8 input,InterleavedF32 output,GrayF64 convert,GrayU8 input,GrayF64 output,InterleavedF64 convert,InterleavedU8 input,InterleavedF64 output,InterleavedU8 convert,Planar<GrayU8> input,InterleavedU8 output,Planar<GrayU8> convert,InterleavedU8 input,Planar<GrayU8> output,GrayU8 convert,GrayU8 input,int min,int max,int numValues,GrayU8 output,GrayU8 convert,GrayS8 input,GrayU8 output,InterleavedU8 convert,InterleavedS8 input,InterleavedU8 output,GrayU16 convert,GrayS8 input,GrayU16 output,InterleavedU16 convert,InterleavedS8 input,InterleavedU16 output,GrayS16 convert,GrayS8 input,GrayS16 output,InterleavedS16 convert,InterleavedS8 input,InterleavedS16 output,GrayS32 convert,GrayS8 input,GrayS32 output,InterleavedS32 convert,InterleavedS8 input,InterleavedS32 output,GrayS64 convert,GrayS8 input,GrayS64 output,InterleavedS64 convert,InterleavedS8 input,InterleavedS64 output,GrayF32 convert,GrayS8 input,GrayF32 output,InterleavedF32 convert,InterleavedS8 input,InterleavedF32 output,GrayF64 convert,GrayS8 input,GrayF64 output,InterleavedF64 convert,InterleavedS8 input,InterleavedF64 output,InterleavedS8 convert,Planar<GrayS8> input,InterleavedS8 output,Planar<GrayS8> convert,InterleavedS8 input,Planar<GrayS8> output,GrayU8 convert,GrayS8 input,int min,int max,int numValues,GrayU8 output,GrayU8 convert,GrayU16 input,GrayU8 output,InterleavedU8 convert,InterleavedU16 input,InterleavedU8 output,GrayS8 convert,GrayU16 input,GrayS8 output,InterleavedS8 convert,InterleavedU16 input,InterleavedS8 output,GrayS16 convert,GrayU16 input,GrayS16 output,InterleavedS16 convert,InterleavedU16 input,InterleavedS16 output,GrayS32 convert,GrayU16 input,GrayS32 output,InterleavedS32 convert,InterleavedU16 input,InterleavedS32 output,GrayS64 convert,GrayU16 input,GrayS64 output,InterleavedS64 convert,InterleavedU16 input,InterleavedS64 output,GrayF32 convert,GrayU16 input,GrayF32 output,InterleavedF32 convert,InterleavedU16 input,InterleavedF32 output,GrayF64 convert,GrayU16 input,GrayF64 output,InterleavedF64 convert,InterleavedU16 input,InterleavedF64 output,InterleavedU16 convert,Planar<GrayU16> input,InterleavedU16 output,Planar<GrayU16> convert,InterleavedU16 input,Planar<GrayU16> output,GrayU8 convert,GrayU16 input,int min,int max,int numValues,GrayU8 output,GrayU8 convert,GrayS16 input,GrayU8 output,InterleavedU8 convert,InterleavedS16 input,InterleavedU8 output,GrayS8 convert,GrayS16 input,GrayS8 output,InterleavedS8 convert,InterleavedS16 input,InterleavedS8 output,GrayU16 convert,GrayS16 input,GrayU16 output,InterleavedU16 convert,InterleavedS16 input,InterleavedU16 output,GrayS32 convert,GrayS16 input,GrayS32 output,InterleavedS32 convert,InterleavedS16 input,InterleavedS32 output,GrayS64 convert,GrayS16 input,GrayS64 output,InterleavedS64 convert,InterleavedS16 input,InterleavedS64 output,GrayF32 convert,GrayS16 input,GrayF32 output,InterleavedF32 convert,InterleavedS16 input,InterleavedF32 output,GrayF64 convert,GrayS16 input,GrayF64 output,InterleavedF64 convert,InterleavedS16 input,InterleavedF64 output,InterleavedS16 convert,Planar<GrayS16> input,InterleavedS16 output,Planar<GrayS16> convert,InterleavedS16 input,Planar<GrayS16> output,GrayU8 convert,GrayS16 input,int min,int max,int numValues,GrayU8 output,GrayU8 convert,GrayS32 input,GrayU8 output,InterleavedU8 convert,InterleavedS32 input,InterleavedU8 output,GrayS8 convert,GrayS32 input,GrayS8 output,InterleavedS8 convert,InterleavedS32 input,InterleavedS8 output,GrayU16 convert,GrayS32 input,GrayU16 output,InterleavedU16 convert,InterleavedS32 input,InterleavedU16 output,GrayS16 convert,GrayS32 input,GrayS16 output,InterleavedS16 convert,InterleavedS32 input,InterleavedS16 output,GrayS64 convert,GrayS32 input,GrayS64 output,InterleavedS64 convert,InterleavedS32 input,InterleavedS64 output,GrayF32 convert,GrayS32 input,GrayF32 output,InterleavedF32 convert,InterleavedS32 input,InterleavedF32 output,GrayF64 convert,GrayS32 input,GrayF64 output,InterleavedF64 convert,InterleavedS32 input,InterleavedF64 output,InterleavedS32 convert,Planar<GrayS32> input,InterleavedS32 output,Planar<GrayS32> convert,InterleavedS32 input,Planar<GrayS32> output,GrayU8 convert,GrayS32 input,int min,int max,int numValues,GrayU8 output,GrayU8 convert,GrayS64 input,GrayU8 output,InterleavedU8 convert,InterleavedS64 input,InterleavedU8 output,GrayS8 convert,GrayS64 input,GrayS8 output,InterleavedS8 convert,InterleavedS64 input,InterleavedS8 output,GrayU16 convert,GrayS64 input,GrayU16 output,InterleavedU16 convert,InterleavedS64 input,InterleavedU16 output,GrayS16 convert,GrayS64 input,GrayS16 output,InterleavedS16 convert,InterleavedS64 input,InterleavedS16 output,GrayS32 convert,GrayS64 input,GrayS32 output,InterleavedS32 convert,InterleavedS64 input,InterleavedS32 output,GrayF32 convert,GrayS64 input,GrayF32 output,InterleavedF32 convert,InterleavedS64 input,InterleavedF32 output,GrayF64 convert,GrayS64 input,GrayF64 output,InterleavedF64 convert,InterleavedS64 input,InterleavedF64 output,InterleavedS64 convert,Planar<GrayS64> input,InterleavedS64 output,Planar<GrayS64> convert,InterleavedS64 input,Planar<GrayS64> output,GrayU8 convert,GrayS64 input,long min,long max,int numValues,GrayU8 output,GrayU8 convert,GrayF32 input,GrayU8 output,InterleavedU8 convert,InterleavedF32 input,InterleavedU8 output,GrayS8 convert,GrayF32 input,GrayS8 output,InterleavedS8 convert,InterleavedF32 input,InterleavedS8 output,GrayU16 convert,GrayF32 input,GrayU16 output,InterleavedU16 convert,InterleavedF32 input,InterleavedU16 output,GrayS16 convert,GrayF32 input,GrayS16 output,InterleavedS16 convert,InterleavedF32 input,InterleavedS16 output,GrayS32 convert,GrayF32 input,GrayS32 output,InterleavedS32 convert,InterleavedF32 input,InterleavedS32 output,GrayS64 convert,GrayF32 input,GrayS64 output,InterleavedS64 convert,InterleavedF32 input,InterleavedS64 output,GrayF64 convert,GrayF32 input,GrayF64 output,InterleavedF64 convert,InterleavedF32 input,InterleavedF64 output,InterleavedF32 convert,Planar<GrayF32> input,InterleavedF32 output,Planar<GrayF32> convert,InterleavedF32 input,Planar<GrayF32> output,GrayU8 convert,GrayF32 input,float min,float max,int numValues,GrayU8 output,GrayU8 convert,GrayF64 input,GrayU8 output,InterleavedU8 convert,InterleavedF64 input,InterleavedU8 output,GrayS8 convert,GrayF64 input,GrayS8 output,InterleavedS8 convert,InterleavedF64 input,InterleavedS8 output,GrayU16 convert,GrayF64 input,GrayU16 output,InterleavedU16 convert,InterleavedF64 input,InterleavedU16 output,GrayS16 convert,GrayF64 input,GrayS16 output,InterleavedS16 convert,InterleavedF64 input,InterleavedS16 output,GrayS32 convert,GrayF64 input,GrayS32 output,InterleavedS32 convert,InterleavedF64 input,InterleavedS32 output,GrayS64 convert,GrayF64 input,GrayS64 output,InterleavedS64 convert,InterleavedF64 input,InterleavedS64 output,GrayF32 convert,GrayF64 input,GrayF32 output,InterleavedF32 convert,InterleavedF64 input,InterleavedF32 output,InterleavedF64 convert,Planar<GrayF64> input,InterleavedF64 output,Planar<GrayF64> convert,InterleavedF64 input,Planar<GrayF64> output,GrayU8 convert,GrayF64 input,double min,double max,int numValues,GrayU8 output){\r\n    if (output == null) {\r\n        output = new GrayU8(input.width, input.height);\r\n    } else {\r\n        output.reshape(input.width, input.height);\r\n    }\r\n    if (numValues < 0 || numValues > 256)\r\n        throw new IllegalArgumentException(\"0 <= numValues <= 256\");\r\n    numValues -= 1;\r\n    double range = max - min;\r\n    for (int y = 0; y < input.height; y++) {\r\n        int indexIn = input.startIndex + y * input.stride;\r\n        int indexOut = output.startIndex + y * output.stride;\r\n        for (int x = 0; x < input.width; x++) {\r\n            int value = (int) (numValues * ((input.data[indexIn++]) - min) / range + 0.5);\r\n            output.data[indexOut++] = (byte) value;\r\n        }\r\n    }\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.factory.feature.detect.interest.FactoryDetectPoint.createHessian",
	"Comment": "creates a hessian based blob detector. minimums and maximums.",
	"Method": "GeneralFeatureDetector<T, D> createHessian(HessianBlobIntensity.Type type,ConfigGeneralDetector configDetector,Class<D> derivType){\r\n    if (configDetector == null)\r\n        configDetector = new ConfigGeneralDetector();\r\n    GeneralFeatureIntensity<T, D> intensity = FactoryIntensityPoint.hessian(type, derivType);\r\n    return createGeneral(intensity, configDetector);\r\n}"
}, {
	"Path": "boofcv.struct.wavelet.WaveletDescription.getBorder",
	"Comment": "describes how border conditions along the image are handled",
	"Method": "BorderIndex1D getBorder(){\r\n    return border;\r\n}"
}, {
	"Path": "boofcv.abst.feature.dense.TestDescribeImageDenseSift.checkBorder",
	"Comment": "features should not be sampled so that they go over the image border",
	"Method": "void checkBorder(){\r\n    for (Class type : imageTypes) {\r\n        ImageGray image = GeneralizedImageOps.createSingleBand(type, width, height);\r\n        GImageMiscOps.fillUniform(image, rand, 0, 200);\r\n        DescribeImageDense alg = createAlg(type, 8, 9);\r\n        alg.process(image);\r\n        List<Point2D_I32> locations = alg.getLocations();\r\n        int w = getWidthScaleOfOne();\r\n        int r = w / 2;\r\n        int numCols = (image.width - w) / 8;\r\n        int numRows = (image.height - w) / 9;\r\n        assertEquals(numCols * numRows, locations.size());\r\n        for (Point2D_I32 p : locations) {\r\n            assertTrue(p.x >= r && p.x <= width - r);\r\n            assertTrue(p.y >= r && p.y <= height - r);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.TestBinaryEllipseDetectorPixel.isApproximatelyElliptical_small",
	"Comment": "test to see if it is approximately elliptical when the number of pixels is smaller\tthan the threshold",
	"Method": "void isApproximatelyElliptical_small(){\r\n    EllipseRotated_F64 ellipse = new EllipseRotated_F64(5, 3, 10, 6, 0);\r\n    List<Point2D_F64> negative = TestShapeFittingOps.createRectangle_F64(20, 10, 60 - 4);\r\n    List<Point2D_F64> positive = TestShapeFittingOps.createEllipse_F64(ellipse, 60 - 4);\r\n    BinaryEllipseDetectorPixel alg = new BinaryEllipseDetectorPixel();\r\n    alg.setMaxDistanceFromEllipse(1.5);\r\n    assertFalse(alg.isApproximatelyElliptical(ellipse, negative, 100));\r\n    assertTrue(alg.isApproximatelyElliptical(ellipse, positive, 100));\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionHandle.refreshConnection",
	"Comment": "destroys the internal connection handle and creates a new one.",
	"Method": "void refreshConnection(){\r\n    this.connection.close();\r\n    try {\r\n        this.connection = this.pool.obtainRawInternalConnection();\r\n    } catch (SQLException e) {\r\n        throw markPossiblyBroken(e);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.misc.GPixelMath.pow2",
	"Comment": "raises each pixel in the input image to the power of two. both the input and output image can be the same\tinstance.",
	"Method": "void pow2(T input,T output){\r\n    if (input instanceof ImageGray) {\r\n        if (GrayF32.class == input.getClass()) {\r\n            PixelMath.pow2((GrayF32) input, (GrayF32) output);\r\n        } else if (GrayF64.class == input.getClass()) {\r\n            PixelMath.pow2((GrayF64) input, (GrayF64) output);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type: \" + input.getClass().getSimpleName());\r\n        }\r\n    } else if (input instanceof Planar) {\r\n        Planar in = (Planar) input;\r\n        Planar out = (Planar) output;\r\n        for (int i = 0; i < in.getNumBands(); i++) {\r\n            pow2(in.getBand(i), out.getBand(i));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.demonstrations.feature.disparity.VisualizeStereoDisparity.changeImageView",
	"Comment": "changes which image is being displayed depending on gui selection",
	"Method": "void changeImageView(){\r\n    JComponent comp;\r\n    if (control.selectedView < 3) {\r\n        BufferedImage img;\r\n        switch(control.selectedView) {\r\n            case 0:\r\n                img = disparityOut;\r\n                break;\r\n            case 1:\r\n                img = colorLeft;\r\n                break;\r\n            case 2:\r\n                img = colorRight;\r\n                break;\r\n            default:\r\n                throw new RuntimeException(\"Unknown option\");\r\n        }\r\n        gui.setImage(img);\r\n        gui.setPreferredSize(new Dimension(origLeft.getWidth(), origLeft.getHeight()));\r\n        comp = gui;\r\n    } else {\r\n        if (!computedCloud) {\r\n            computedCloud = true;\r\n            DisparityToColorPointCloud d2c = new DisparityToColorPointCloud();\r\n            double baseline = calib.getRightToLeft().getT().norm();\r\n            d2c.configure(baseline, rectK, rectR, leftRectToPixel, control.minDisparity, control.maxDisparity);\r\n            d2c.process(activeAlg.getDisparity(), colorLeft);\r\n            CameraPinhole rectifiedPinhole = PerspectiveOps.matrixToPinhole(rectK, colorLeft.getWidth(), colorLeft.getHeight(), null);\r\n            pcv.clearPoints();\r\n            pcv.setCameraHFov(PerspectiveOps.computeHFov(rectifiedPinhole));\r\n            pcv.setTranslationStep(5);\r\n            pcv.addCloud(d2c.getCloud(), d2c.getCloudColor());\r\n        }\r\n        comp = pcv.getComponent();\r\n        comp.requestFocusInWindow();\r\n    }\r\n    panel.remove(gui);\r\n    panel.remove(pcv.getComponent());\r\n    panel.add(comp, BorderLayout.CENTER);\r\n    panel.validate();\r\n    comp.repaint();\r\n    processedImage = true;\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.SegmentMeanShiftSearch.weight",
	"Comment": "returns the weight given the normalized distance.instead of computing the kernel distance every time\ta lookup table with linear interpolation is used.the distance has a domain from 0 to 1, inclusive",
	"Method": "float weight(float distance){\r\n    float findex = distance * 100f;\r\n    int index = (int) findex;\r\n    if (index >= 99)\r\n        return weightTable[99];\r\n    float sample0 = weightTable[index];\r\n    float sample1 = weightTable[index + 1];\r\n    float w = findex - index;\r\n    return sample0 * (1f - w) + sample1 * w;\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernel.random",
	"Comment": "creates a random kernel of the specified type where each element is drawn from an uniform\tdistribution.",
	"Method": "T random(Class<?> type,int radius,int min,int max,Random rand,T random,Class<?> type,int width,int offset,int min,int max,Random rand){\r\n    if (Kernel1D_F32.class == type) {\r\n        return (T) FactoryKernel.random1D_F32(width, offset, min, max, rand);\r\n    } else if (Kernel1D_F64.class == type) {\r\n        return (T) FactoryKernel.random1D_F64(width, offset, min, max, rand);\r\n    } else if (Kernel1D_S32.class == type) {\r\n        return (T) FactoryKernel.random1D_I32(width, offset, min, max, rand);\r\n    } else if (Kernel2D_S32.class == type) {\r\n        return (T) FactoryKernel.random2D_I32(width, offset, min, max, rand);\r\n    } else if (Kernel2D_F32.class == type) {\r\n        return (T) FactoryKernel.random2D_F32(width, offset, min, max, rand);\r\n    } else if (Kernel2D_F64.class == type) {\r\n        return (T) FactoryKernel.random2D_F64(width, offset, min, max, rand);\r\n    } else {\r\n        throw new RuntimeException(\"Unknown kernel type. \" + type.getSimpleName());\r\n    }\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapperComplex.fromMap",
	"Comment": "frommap converts a map into a java object.this version will see if there is a class parameter in the map, and dies if there is not.",
	"Method": "T fromMap(Map<String, Object> map,Class<T> cls,Object fromMap,Map<String, Object> map){\r\n    String clazz = (String) map.get(\"class\");\r\n    Class cls = Reflection.loadClass(clazz);\r\n    return fromMap(map, cls);\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.TestCameraToEquirectangular_F32.setDirection",
	"Comment": "rotate the camera and see if the camera center is pointing in the right direction now",
	"Method": "void setDirection(){\r\n    CameraPinholeRadial intrinsic = new CameraPinholeRadial(400, 400, 0, imgWidth / 2, imgHeight / 2, imgWidth, imgHeight);\r\n    intrinsic.setRadial(0.1f, 0.2f);\r\n    CameraToEquirectangular_F32 alg = new CameraToEquirectangular_F32();\r\n    alg.setCameraModel(intrinsic);\r\n    alg.setEquirectangularShape(equiWidth, equiHeight);\r\n    alg.setDirection(0, (float) Math.PI / 2, 0);\r\n    assertPointing(alg, imgWidth / 2, imgHeight / 2, 1, 0, 0);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomPixelDepthPnP.estimateMotion",
	"Comment": "estimates motion from the set of tracks and their 3d location",
	"Method": "boolean estimateMotion(){\r\n    List<PointTrack> active = tracker.getActiveTracks(null);\r\n    List<Point2D3D> obs = new ArrayList();\r\n    for (PointTrack t : active) {\r\n        Point2D3D p = t.getCookie();\r\n        pixelToNorm.compute(t.x, t.y, p.observation);\r\n        obs.add(p);\r\n    }\r\n    if (!motionEstimator.process(obs))\r\n        return false;\r\n    if (doublePass) {\r\n        if (!performSecondPass(active, obs))\r\n            return false;\r\n    }\r\n    tracker.finishTracking();\r\n    Se3_F64 keyToCurr;\r\n    if (refine != null) {\r\n        keyToCurr = new Se3_F64();\r\n        refine.fitModel(motionEstimator.getMatchSet(), motionEstimator.getModelParameters(), keyToCurr);\r\n    } else {\r\n        keyToCurr = motionEstimator.getModelParameters();\r\n    }\r\n    keyToCurr.invert(currToKey);\r\n    int N = motionEstimator.getMatchSet().size();\r\n    for (int i = 0; i < N; i++) {\r\n        int index = motionEstimator.getInputIndex(i);\r\n        Point2D3DTrack t = active.get(index).getCookie();\r\n        t.lastInlier = tick;\r\n        inlierTracks.add(t);\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldTemplateMatching.computeConfidence",
	"Comment": "compute a value which indicates how confident the specified region is to be a member of the positive set.\tthe confidence value is from 0 to 1.1 indicates 100% confidence.\tpositive and negative templates are used to compute the confidence value.only the point in each set\twhich is closest to the specified region are used in the calculation.",
	"Method": "double computeConfidence(int x0,int y0,int x1,int y1,double computeConfidence,ImageRectangle r){\r\n    return computeConfidence(r.x0, r.y0, r.x1, r.y1);\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.TestImageLineIntegral.inside_SlopeZero",
	"Comment": "tests an integral inside a single pixel where x or y slope is zero",
	"Method": "void inside_SlopeZero(){\r\n    GrayU8 img = new GrayU8(10, 15);\r\n    img.set(6, 6, 100);\r\n    alg.setImage(FactoryGImageGray.wrap(img));\r\n    checkSolution(6.5, 6, 6.5, 7, 100);\r\n    checkSolution(6.5, 6, 6.5, 6.9, 0.9 * 100);\r\n    checkSolution(6.5, 6.1, 6.5, 7.0, 0.9 * 100);\r\n    checkSolution(6, 6.5, 7, 6.5, 100);\r\n    checkSolution(6, 6.5, 6.9, 6.5, 0.9 * 100);\r\n    checkSolution(6.1, 6.5, 7, 6.5, 0.9 * 100);\r\n}"
}, {
	"Path": "boofcv.examples.stereo.ExampleStereoTwoViewsOneCamera.estimateCameraMotion",
	"Comment": "estimates the camera motion robustly using ransac and a set of associated points.",
	"Method": "Se3_F64 estimateCameraMotion(CameraPinholeRadial intrinsic,List<AssociatedPair> matchedNorm,List<AssociatedPair> inliers){\r\n    ModelMatcherMultiview<Se3_F64, AssociatedPair> epipolarMotion = FactoryMultiViewRobust.baselineRansac(new ConfigEssential(), new ConfigRansac(200, 0.5));\r\n    epipolarMotion.setIntrinsic(0, intrinsic);\r\n    epipolarMotion.setIntrinsic(1, intrinsic);\r\n    if (!epipolarMotion.process(matchedNorm))\r\n        throw new RuntimeException(\"Motion estimation failed\");\r\n    inliers.addAll(epipolarMotion.getMatchSet());\r\n    return epipolarMotion.getModelParameters();\r\n}"
}, {
	"Path": "boofcv.alg.filter.derivative.impl.TestGradientSobel_Outer.process_I8_naive",
	"Comment": "see if the same results are returned by the simple naive algorithm",
	"Method": "void process_I8_naive(){\r\n    for (int offY = 0; offY < 3; offY++) {\r\n        for (int offX = 0; offX < 3; offX++) {\r\n            int w = width + offX;\r\n            int h = height + offY;\r\n            GrayU8 img = new GrayU8(w, h);\r\n            ImageMiscOps.fillUniform(img, new Random(0xfeed), 0, 100);\r\n            GrayS16 derivX = new GrayS16(w, h);\r\n            GrayS16 derivY = new GrayS16(w, h);\r\n            GrayS16 derivX2 = new GrayS16(w, h);\r\n            GrayS16 derivY2 = new GrayS16(w, h);\r\n            GradientSobel_Naive.process(img, derivX2, derivY2);\r\n            GradientSobel_Outer.process_I8(img, derivX, derivY);\r\n            BoofTesting.assertEquals(derivX2, derivX, 0);\r\n            BoofTesting.assertEquals(derivY2, derivY, 0);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.normalized.TestConvolveNormalizedNaive_IL.convolve",
	"Comment": "check it against one specific type to see if the core algorithm is correct",
	"Method": "void convolve(int convolve,int cx,int cy,int band,Kernel2D_S32 kernel,InterleavedU8 image){\r\n    int total = 0;\r\n    int weight = 0;\r\n    for (int i = 0; i < kernel.width; i++) {\r\n        int y = cy + i - kernel.offset;\r\n        for (int j = 0; j < kernel.width; j++) {\r\n            int x = cx + j - kernel.offset;\r\n            if (image.isInBounds(x, y)) {\r\n                int w = kernel.get(j, i);\r\n                int v = image.getBand(x, y, band);\r\n                weight += w;\r\n                total += w * v;\r\n            }\r\n        }\r\n    }\r\n    return (total + weight / 2) / weight;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldRegionTracker.process",
	"Comment": "creates several tracks inside the target rectangle and compuets their motion",
	"Method": "boolean process(ImagePyramid<I> image,Rectangle2D_F64 targetRectangle){\r\n    boolean success = true;\r\n    updateCurrent(image);\r\n    spawnGrid(targetRectangle);\r\n    if (!trackFeature())\r\n        success = false;\r\n    setCurrentToPrevious();\r\n    return success;\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.TestAssociateSurfBasic.checkAssociateByIntensity",
	"Comment": "two features with different laplacian signs should never be associated",
	"Method": "void checkAssociateByIntensity(){\r\n    FastQueue<BrightFeature> src = new FastQueue(10, BrightFeature.class, false);\r\n    FastQueue<BrightFeature> dst = new FastQueue(10, BrightFeature.class, false);\r\n    src.add(createDesc(true, 10));\r\n    dst.add(createDesc(true, 0));\r\n    dst.add(createDesc(false, 10));\r\n    alg.setSrc(src);\r\n    alg.setDst(dst);\r\n    alg.associate();\r\n    FastQueue<AssociatedIndex> matches = alg.getMatches();\r\n    assertEquals(1, matches.size());\r\n    assertEquals(0, matches.get(0).dst);\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.DetectDescribeAssociate.setUpdateDescription",
	"Comment": "if a feature is associated should the description be updated with the latest observation?",
	"Method": "void setUpdateDescription(boolean updateDescription){\r\n    this.updateDescription = updateDescription;\r\n}"
}, {
	"Path": "boofcv.deepboof.ImageClassifierNiNImageNet.preprocess",
	"Comment": "massage the input image into a format recognized by the network",
	"Method": "Planar<GrayF32> preprocess(Planar<GrayF32> image){\r\n    super.preprocess(image);\r\n    imageBgr.bands[0] = imageRgb.bands[2];\r\n    imageBgr.bands[1] = imageRgb.bands[1];\r\n    imageBgr.bands[2] = imageRgb.bands[0];\r\n    GPixelMath.divide(imageBgr, 255, imageBgr);\r\n    for (int band = 0; band < 3; band++) {\r\n        DataManipulationOps.normalize(imageBgr.getBand(band), mean[band], stdev[band]);\r\n    }\r\n    return imageBgr;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeEncoder.selectMask",
	"Comment": "selects a mask by minimizing the appearance of certain patterns. this is inspired by\twhat was described in the reference manual. i had a hard time understanding some\tof the specifics so i improvised.",
	"Method": "QrCodeMaskPattern selectMask(QrCode qr){\r\n    int N = qr.getNumberOfModules();\r\n    int totalBytes = QrCode.VERSION_INFO[qr.version].codewords;\r\n    List<Point2D_I32> locations = QrCode.LOCATION_BITS[qr.version];\r\n    QrCodeMaskPattern bestMask = null;\r\n    double bestScore = Double.MAX_VALUE;\r\n    PackedBits8 bits = new PackedBits8();\r\n    bits.size = totalBytes * 8;\r\n    bits.data = qr.rawbits;\r\n    if (bits.size > locations.size())\r\n        throw new RuntimeException(\"BUG in code\");\r\n    QrCodeCodeWordLocations matrix = new QrCodeCodeWordLocations(qr.version);\r\n    for (QrCodeMaskPattern mask : QrCodeMaskPattern.values()) {\r\n        double score = scoreMask(N, locations, bits, matrix, mask);\r\n        if (score < bestScore) {\r\n            bestScore = score;\r\n            bestMask = mask;\r\n        }\r\n    }\r\n    return bestMask;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.pokemon.PokemonCalculationUtils.moveRating",
	"Comment": "rates the moveset against the best possible moveset of that species.",
	"Method": "double moveRating(Pokemon p,boolean primary){\r\n    final PokemonSettings pMeta = PokemonMeta.getPokemonSettings(p.getPokemonId());\r\n    double highestDps = 0;\r\n    final List<PokemonMove> moves = primary ? pMeta.getQuickMovesList() : pMeta.getCinematicMovesList();\r\n    for (final PokemonMove move : moves) {\r\n        final double dps = dpsForMove(p.getPokemonId(), move, primary);\r\n        if (dps > highestDps) {\r\n            highestDps = dps;\r\n        }\r\n    }\r\n    final double currentDps = dpsForMove(p, primary);\r\n    return Utilities.percentage(currentDps, highestDps);\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.impl.TestBinaryThinning.thinning_line2pixel",
	"Comment": "a line 2 pixels thick.should be left with a line 1 pixel thick",
	"Method": "void thinning_line2pixel(){\r\n    GrayU8 img = new GrayU8(20, 25);\r\n    ImageMiscOps.fill(img.subimage(0, 5, 20, 7), 1);\r\n    BinaryThinning alg = new BinaryThinning();\r\n    alg.apply(img, -1);\r\n    assertEquals(20, ImageStatistics.sum(img));\r\n    for (int i = 1; i < 19; i++) {\r\n        assertEquals(1, img.get(i, 6));\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.transform.wavelet.FactoryWaveletHaar.generateInv_I32",
	"Comment": "create a description for the inverse transform.note that this will not produce\tan exact copy of the original due to rounding error.",
	"Method": "WlCoef_I32 generateInv_I32(){\r\n    WlCoef_I32 ret = new WlCoef_I32();\r\n    ret.scaling = new int[] { 1, 1 };\r\n    ret.wavelet = new int[] { ret.scaling[0], -ret.scaling[0] };\r\n    ret.denominatorScaling = 2;\r\n    ret.denominatorWavelet = 2;\r\n    return ret;\r\n}"
}, {
	"Path": "org.boon.validation.ValidationContext.getParentObject",
	"Comment": "get the parent object. allows the fieldvalidators to accessthe parent object.",
	"Method": "Object getParentObject(){\r\n    return parentObject;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.StatementHandle.getInternalStatement",
	"Comment": "returns the statement being wrapped around by this wrapper.",
	"Method": "Statement getInternalStatement(){\r\n    return this.internalStatement;\r\n}"
}, {
	"Path": "boofcv.gui.SelectAlgorithmPanel.setMainGUI",
	"Comment": "used to add the main gui to this panel. must use this function.\talgorithm change events will not be posted until this function has been set.",
	"Method": "void setMainGUI(Component gui){\r\n    this.gui = gui;\r\n    SwingUtilities.invokeLater(new Runnable() {\r\n        public void run() {\r\n            add(gui, BorderLayout.CENTER);\r\n        }\r\n    });\r\n}"
}, {
	"Path": "boofcv.gui.SelectAlgorithmPanel.setMainGUI",
	"Comment": "used to add the main gui to this panel. must use this function.\talgorithm change events will not be posted until this function has been set.",
	"Method": "void setMainGUI(Component gui){\r\n    add(gui, BorderLayout.CENTER);\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.normalized.TestConvolveNormalizedNaive_SB.vertical",
	"Comment": "check it against one specific type to see if the core algorithm is correct",
	"Method": "void vertical(int vertical,int x,int y,Kernel1D_S32 kernel,GrayU8 image){\r\n    int total = 0;\r\n    int weight = 0;\r\n    for (int i = 0; i < kernel.width; i++) {\r\n        if (image.isInBounds(x, y + i - kernel.offset)) {\r\n            int w = kernel.get(i);\r\n            int v = image.get(x, y + i - kernel.offset);\r\n            total += w * v;\r\n            weight += w;\r\n        }\r\n    }\r\n    return (total + weight / 2) / weight;\r\n}"
}, {
	"Path": "org.boon.validation.validators.LongRangeValidator.dynamicallyInitIfNeeded",
	"Comment": "if the type was not initialized, we can still figure it out at runtime.",
	"Method": "void dynamicallyInitIfNeeded(Object value){\r\n    if (!isInitialized()) {\r\n        if (value instanceof Integer) {\r\n            init(new Integer(min.intValue()), new Integer(max.intValue()));\r\n        } else if (value instanceof Byte) {\r\n            init(new Byte(min.byteValue()), new Byte(max.byteValue()));\r\n        } else if (value instanceof Short) {\r\n            init(new Short(min.shortValue()), new Short(max.shortValue()));\r\n        } else {\r\n            init(min, max);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.testing.BoofTesting.findMethodThenCall",
	"Comment": "searches for all functions with the specified name in the target class.once it finds\tthat function it invokes the specified function in the owner class. that function must\ttake in a method as its one and only parameter.the method will be one of the matching\tones in the target class.",
	"Method": "int findMethodThenCall(Object owner,String ownerMethod,Class target,String targetMethod){\r\n    int total = 0;\r\n    Method[] list = target.getMethods();\r\n    try {\r\n        Method om = owner.getClass().getMethod(ownerMethod, Method.class);\r\n        for (Method m : list) {\r\n            if (!m.getName().equals(targetMethod))\r\n                continue;\r\n            om.invoke(owner, m);\r\n            total++;\r\n        }\r\n    } catch (NoSuchMethodException | IllegalAccessException | InvocationTargetException e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "boofcv.javacv.UtilOpenCV.loadPinholeRadial",
	"Comment": "loads a pinhole camera model with radian and tangential distortion in opencv format",
	"Method": "CameraPinholeRadial loadPinholeRadial(String fileName){\r\n    FileStorage fs = new FileStorage(new File(fileName).getAbsolutePath(), FileStorage.READ);\r\n    IntPointer width = new IntPointer(1);\r\n    IntPointer height = new IntPointer(1);\r\n    read(fs.get(\"image_width\"), width, -1);\r\n    read(fs.get(\"image_height\"), height, -1);\r\n    Mat K = new Mat();\r\n    read(fs.get(\"camera_matrix\"), K);\r\n    Mat distortion = new Mat();\r\n    read(fs.get(\"distortion_coefficients\"), distortion);\r\n    CameraPinholeRadial boof = new CameraPinholeRadial();\r\n    boof.width = width.get();\r\n    boof.height = height.get();\r\n    DoubleRawIndexer indexerK = K.createIndexer();\r\n    boof.fx = indexerK.get(0, 0);\r\n    boof.skew = indexerK.get(0, 1);\r\n    boof.fy = indexerK.get(1, 1);\r\n    boof.cx = indexerK.get(0, 2);\r\n    boof.cy = indexerK.get(1, 2);\r\n    DoubleRawIndexer indexerD = distortion.createIndexer();\r\n    if (distortion.rows() >= 5)\r\n        boof.setRadial(indexerD.get(0, 0), indexerD.get(1, 0), indexerD.get(4, 0));\r\n    else if (distortion.rows() >= 2)\r\n        boof.setRadial(indexerD.get(0, 0), indexerD.get(1, 0));\r\n    if (distortion.rows() >= 5)\r\n        boof.fsetTangental(indexerD.get(2, 0), indexerD.get(3, 0));\r\n    return boof;\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.ImplDisparityScoreSadRectFive_S16.computeScoreFive",
	"Comment": "compute the final score by sampling the 5 regions.four regions are sampled around the center\tregion.out of those four only the two with the smallest score are used.",
	"Method": "void computeScoreFive(int top,int middle,int bottom,int score,int width){\r\n    for (int d = minDisparity; d < maxDisparity; d++) {\r\n        int indexSrc = (d - minDisparity) * width + (d - minDisparity) + radiusX;\r\n        int indexDst = (d - minDisparity) * width + (d - minDisparity);\r\n        int end = indexSrc + (width - d - 4 * radiusX);\r\n        while (indexSrc < end) {\r\n            int s = 0;\r\n            int val0 = top[indexSrc - radiusX];\r\n            int val1 = top[indexSrc + radiusX];\r\n            int val2 = bottom[indexSrc - radiusX];\r\n            int val3 = bottom[indexSrc + radiusX];\r\n            if (val1 < val0) {\r\n                int temp = val0;\r\n                val0 = val1;\r\n                val1 = temp;\r\n            }\r\n            if (val3 < val2) {\r\n                int temp = val2;\r\n                val2 = val3;\r\n                val3 = temp;\r\n            }\r\n            if (val3 < val0) {\r\n                s += val2;\r\n                s += val3;\r\n            } else if (val2 < val1) {\r\n                s += val2;\r\n                s += val0;\r\n            } else {\r\n                s += val0;\r\n                s += val1;\r\n            }\r\n            score[indexDst++] = s + middle[indexSrc++];\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.impl.ImplRectifyImageOps_F64.adjustUncalibrated",
	"Comment": "internal function which applies the rectification adjustment to an uncalibrated stereo pair",
	"Method": "void adjustUncalibrated(DMatrixRMaj rectifyLeft,DMatrixRMaj rectifyRight,RectangleLength2D_F64 bound,double scale){\r\n    double deltaX = -bound.x0 * scale;\r\n    double deltaY = -bound.y0 * scale;\r\n    SimpleMatrix A = new SimpleMatrix(3, 3, true, new double[] { scale, 0, deltaX, 0, scale, deltaY, 0, 0, 1 });\r\n    SimpleMatrix rL = SimpleMatrix.wrap(rectifyLeft);\r\n    SimpleMatrix rR = SimpleMatrix.wrap(rectifyRight);\r\n    rectifyLeft.set(A.mult(rL).getDDRM());\r\n    rectifyRight.set(A.mult(rR).getDDRM());\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.getMaxConnectionAge",
	"Comment": "returns the maxconnectionage with the specified granularity.",
	"Method": "long getMaxConnectionAge(long getMaxConnectionAge,TimeUnit timeUnit){\r\n    return timeUnit.convert(this.maxConnectionAgeInSeconds, TimeUnit.SECONDS);\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapperComplex.toMap",
	"Comment": "this could be refactored to use core.typetype class and it would run faster.converts an object into a map",
	"Method": "Map<String, Object> toMap(Object object){\r\n    if (object == null) {\r\n        return null;\r\n    }\r\n    if (object instanceof Map) {\r\n        return (Map<String, Object>) object;\r\n    }\r\n    Map<String, Object> map = new LinkedHashMap();\r\n    final Map<String, FieldAccess> fieldMap = Reflection.getAllAccessorFields(object.getClass());\r\n    List<FieldAccess> fields = new ArrayList(fieldMap.values());\r\n    Collections.reverse(fields);\r\n    if (outputType) {\r\n        map.put(\"class\", object.getClass().getName());\r\n    }\r\n    for (FieldAccess access : fields) {\r\n        String fieldName = access.name();\r\n        if (access.isStatic()) {\r\n            continue;\r\n        }\r\n        if (ignoreSet != null) {\r\n            if (ignoreSet.contains(fieldName)) {\r\n                continue;\r\n            }\r\n        }\r\n        Object value = access.getValue(object);\r\n        if (value == null) {\r\n            continue;\r\n        }\r\n        switch(access.typeEnum()) {\r\n            case BYTE:\r\n            case BYTE_WRAPPER:\r\n            case SHORT:\r\n            case SHORT_WRAPPER:\r\n            case INT:\r\n            case INTEGER_WRAPPER:\r\n            case LONG:\r\n            case LONG_WRAPPER:\r\n            case FLOAT:\r\n            case FLOAT_WRAPPER:\r\n            case DOUBLE:\r\n            case DOUBLE_WRAPPER:\r\n            case CHAR:\r\n            case CHAR_WRAPPER:\r\n            case BIG_DECIMAL:\r\n            case BIG_INT:\r\n            case BOOLEAN:\r\n            case BOOLEAN_WRAPPER:\r\n            case CURRENCY:\r\n            case CALENDAR:\r\n            case DATE:\r\n                map.put(fieldName, value);\r\n                break;\r\n            case ARRAY:\r\n            case ARRAY_INT:\r\n            case ARRAY_BYTE:\r\n            case ARRAY_SHORT:\r\n            case ARRAY_FLOAT:\r\n            case ARRAY_DOUBLE:\r\n            case ARRAY_LONG:\r\n            case ARRAY_STRING:\r\n            case ARRAY_OBJECT:\r\n                if (Typ.isBasicType(access.getComponentClass())) {\r\n                    map.put(fieldName, value);\r\n                } else {\r\n                    int length = Arry.len(value);\r\n                    List<Map<String, Object>> list = new ArrayList(length);\r\n                    for (int index = 0; index < length; index++) {\r\n                        Object item = Arry.fastIndex(value, index);\r\n                        list.add(toMap(item));\r\n                    }\r\n                    map.put(fieldName, list);\r\n                }\r\n                break;\r\n            case COLLECTION:\r\n            case LIST:\r\n            case SET:\r\n                Collection<?> collection = (Collection<?>) value;\r\n                Class<?> componentType = access.getComponentClass();\r\n                if (Typ.isBasicType(componentType)) {\r\n                    map.put(fieldName, value);\r\n                } else if (Typ.isEnum(componentType)) {\r\n                    List<String> list = new ArrayList(collection.size());\r\n                    for (Object item : collection) {\r\n                        if (item != null) {\r\n                            list.add(item.toString());\r\n                        }\r\n                    }\r\n                    map.put(fieldName, list);\r\n                } else {\r\n                    List<Map<String, Object>> list = new ArrayList(collection.size());\r\n                    for (Object item : collection) {\r\n                        if (item != null) {\r\n                            list.add(toMap(item));\r\n                        }\r\n                    }\r\n                    map.put(fieldName, list);\r\n                }\r\n                break;\r\n            case MAP:\r\n                map.put(fieldName, value);\r\n                break;\r\n            case INSTANCE:\r\n                map.put(fieldName, toMap(value));\r\n                break;\r\n            case INTERFACE:\r\n            case ABSTRACT:\r\n                final Map<String, Object> abstractMap = toMap(value);\r\n                abstractMap.put(\"class\", Boon.className(value));\r\n                map.put(fieldName, abstractMap);\r\n                break;\r\n            case ENUM:\r\n                map.put(fieldName, value);\r\n                break;\r\n            default:\r\n                map.put(fieldName, Conversions.toString(value));\r\n                break;\r\n        }\r\n    }\r\n    return map;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.TestEllipsesIntoClusters.noCluster_distance",
	"Comment": "points should not be clustered together due to distance apart",
	"Method": "void noCluster_distance(){\r\n    EllipsesIntoClusters alg = new EllipsesIntoClusters(2.0, 0.5, 0.5);\r\n    List<EllipseInfo> input = new ArrayList();\r\n    input.add(create(0, 0, 2, 1, 0));\r\n    input.add(create(4.1, 0, 2, 1, 0));\r\n    alg.init(input);\r\n    alg.connect(input);\r\n    assertEquals(2, alg.clusters.size());\r\n    input.get(1).ellipse.center.x = 4;\r\n    alg.init(input);\r\n    alg.connect(input);\r\n    assertEquals(1, alg.clusters.size());\r\n}"
}, {
	"Path": "boofcv.struct.image.Planar.setNumberOfBands",
	"Comment": "changes the number of bands in the image.a new array is declared and individual bands are recycled\tif possible",
	"Method": "void setNumberOfBands(int numberOfBands){\r\n    if (numberOfBands == this.bands.length)\r\n        return;\r\n    T[] bands = (T[]) Array.newInstance(type, numberOfBands);\r\n    int N = Math.min(numberOfBands, this.bands.length);\r\n    for (int i = 0; i < N; i++) {\r\n        bands[i] = this.bands[i];\r\n    }\r\n    for (int i = N; i < bands.length; i++) {\r\n        bands[i] = GeneralizedImageOps.createSingleBand(type, width, height);\r\n    }\r\n    this.bands = bands;\r\n}"
}, {
	"Path": "boofcv.core.encoding.ConvertNV21.nv21ToBoof",
	"Comment": "converts a nv21 encoded byte array into a boofcv formatted image.",
	"Method": "void nv21ToBoof(byte[] data,int width,int height,ImageBase output){\r\n    if (output instanceof Planar) {\r\n        Planar ms = (Planar) output;\r\n        if (ms.getBandType() == GrayU8.class) {\r\n            ConvertNV21.nv21TPlanarRgb_U8(data, width, height, ms);\r\n        } else if (ms.getBandType() == GrayF32.class) {\r\n            ConvertNV21.nv21ToPlanarRgb_F32(data, width, height, ms);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unsupported output band format\");\r\n        }\r\n    } else if (output instanceof ImageGray) {\r\n        if (output.getClass() == GrayU8.class) {\r\n            nv21ToGray(data, width, height, (GrayU8) output);\r\n        } else if (output.getClass() == GrayF32.class) {\r\n            nv21ToGray(data, width, height, (GrayF32) output);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unsupported output type\");\r\n        }\r\n    } else if (output instanceof ImageInterleaved) {\r\n        if (output.getClass() == InterleavedU8.class) {\r\n            ConvertNV21.nv21ToInterleaved(data, width, height, (InterleavedU8) output);\r\n        } else if (output.getClass() == InterleavedF32.class) {\r\n            ConvertNV21.nv21ToInterleaved(data, width, height, (InterleavedF32) output);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unsupported output type\");\r\n        }\r\n    } else {\r\n        throw new IllegalArgumentException(\"Boofcv image type not yet supported\");\r\n    }\r\n}"
}, {
	"Path": "org.boon.Boon.toJson",
	"Comment": "helper method to quickly convert a java object into json.facade into the json system.",
	"Method": "String toJson(Object value){\r\n    return JsonFactory.toJson(value);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.intensity.impl.GenerateImplFastCorner.generateSamples",
	"Comment": "todo only be considered finished when that list is exhausted",
	"Method": "String generateSamples(){\r\n    String output = \"\";\r\n    tabs = 2;\r\n    Stack<Action> actions = new Stack();\r\n    actions.add(selectNextSample());\r\n    while (!actions.empty()) {\r\n        Action action = actions.peek();\r\n        System.out.println(\"Action bit=\" + action.bit + \" up=\" + action.sampleUp + \" n=\" + action.consider + \" TOTAL=\" + actions.size());\r\n        debugSampleState();\r\n        if (action.consider == 0) {\r\n            output += strSample(tabs++, action);\r\n            action.consider++;\r\n            if (action.sampleUp) {\r\n                samples[action.bit].add(Sample.UP);\r\n            } else {\r\n                samples[action.bit].add(Sample.DOWN);\r\n            }\r\n        } else if (action.consider == 1) {\r\n            output += strElse(tabs++);\r\n            action.consider++;\r\n            removeSample(action.bit);\r\n            System.out.println(\"removed sample\");\r\n            debugSampleState();\r\n            updateSamples(action);\r\n        } else {\r\n            removeSample(action.bit);\r\n            output += strCloseIf(tabs--);\r\n            actions.pop();\r\n            continue;\r\n        }\r\n        Solution solution = checkSoluton();\r\n        if (solution != null) {\r\n            output += strReturn(tabs--, solution.up ? 1 : -1);\r\n        } else {\r\n            action = selectNextSample();\r\n            if (action == null) {\r\n                output += strReturn(tabs--, 0);\r\n            } else {\r\n                actions.add(action);\r\n            }\r\n        }\r\n    }\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.abst.geo.pose.CheckEstimate1ofPnP.checkMinimumPoints",
	"Comment": "sanity check to see if the minimum number of observations has been set.",
	"Method": "void checkMinimumPoints(){\r\n    assertTrue(alg.getMinimumPoints() != 0);\r\n}"
}, {
	"Path": "boofcv.struct.geo.PairLineNorm.set",
	"Comment": "sets the value of p1 and p2 to be equal to the values of the passed in objects",
	"Method": "void set(Vector3D_F64 l1,Vector3D_F64 l2){\r\n    this.l1.set(l1);\r\n    this.l2.set(l2);\r\n}"
}, {
	"Path": "com.bugsnag.android.ErrorStoreTest.tearDown",
	"Comment": "removes any files from the errorstore generated during testing",
	"Method": "void tearDown(){\r\n    FileUtils.clearFilesInDir(errorStorageDir);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.TestSiftScaleSpace.checkOctaveBlur",
	"Comment": "checks to see if the first image in each octave has the expected amount of image blur",
	"Method": "void checkOctaveBlur(){\r\n    GrayF32 original = new GrayF32(300, 340);\r\n    GImageMiscOps.fillUniform(original, rand, 0, 100);\r\n    GrayF32 expected = new GrayF32(300, 340);\r\n    float sigma0 = 1.6f;\r\n    int lastOctave = 5;\r\n    for (int firstOctave = -1; firstOctave < 2; firstOctave++) {\r\n        SiftScaleSpace alg = new SiftScaleSpace(firstOctave, lastOctave, 2, sigma0);\r\n        alg.initialize(original);\r\n        for (int i = firstOctave; i <= lastOctave; i++) {\r\n            float sigma = (float) (sigma0 * Math.pow(2, i));\r\n            GBlurImageOps.gaussian(original, expected, sigma, -1, null);\r\n            double averageError = compareImage(expected, alg.getImageScale(0), i);\r\n            assertTrue(averageError < 2, \"first \" + firstOctave + \" oct \" + i + \" error = \" + averageError);\r\n            assertTrue(i < lastOctave == alg.computeNextOctave());\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.DetectDescribeAssociate.checkValidSpawn",
	"Comment": "returns true if a new track can be spawned here.intended to be overloaded",
	"Method": "boolean checkValidSpawn(int setIndex,PointTrack p){\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.filter.derivative.impl.TestGradientSobel_UnrolledOuter.process_F32_naive",
	"Comment": "see if the same results are returned by imagebyte2d equivalent",
	"Method": "void process_F32_naive(){\r\n    for (int offY = 0; offY < 3; offY++) {\r\n        for (int offX = 0; offX < 3; offX++) {\r\n            int w = width + offX;\r\n            int h = height + offY;\r\n            GrayF32 img = new GrayF32(w, h);\r\n            ImageMiscOps.fillUniform(img, rand, 0f, 255f);\r\n            GrayF32 derivX = new GrayF32(w, h);\r\n            GrayF32 derivY = new GrayF32(w, h);\r\n            GrayF32 derivX2 = new GrayF32(w, h);\r\n            GrayF32 derivY2 = new GrayF32(w, h);\r\n            GradientSobel_Naive.process(img, derivX2, derivY2);\r\n            GradientSobel_UnrolledOuter.process_F32(img, derivX, derivY);\r\n            BoofTesting.assertEquals(derivX2, derivX, 1e-4f);\r\n            BoofTesting.assertEquals(derivY2, derivY, 1e-4f);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.feature.detect.intensity.FactoryIntensityPoint.laplacian",
	"Comment": "blob detector which uses a 3x3 kernel to approximate the second order derivatives and compute a laplacian\tblob.",
	"Method": "GeneralFeatureIntensity<I, ?> laplacian(){\r\n    return new WrapperLaplacianBlobIntensity();\r\n}"
}, {
	"Path": "com.examples.model.test.movies.crud.BatchResults.result",
	"Comment": "happy case. all updates went through.factory method for batch results.",
	"Method": "BatchResults result(long version,BatchResults result,long version,int failed){\r\n    return new BatchResults(version, failed);\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.BinaryImageOps.thin",
	"Comment": "applies a morphological thinning operation to the image.also known as skeletonization.",
	"Method": "GrayU8 thin(GrayU8 input,int maxIterations,GrayU8 output){\r\n    output = InputSanityCheck.checkDeclare(input, output);\r\n    output.setTo(input);\r\n    BinaryThinning thinning = new BinaryThinning();\r\n    thinning.apply(output, maxIterations);\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.sfot.SparseFlowObjectTracker.trackFeatures",
	"Comment": "tracks features from the previous image into the current image. tracks are created inside the specified\tregion in a grid pattern.",
	"Method": "void trackFeatures(Image input,RectangleRotate_F64 region){\r\n    pairs.reset();\r\n    currentImage.process(input);\r\n    for (int i = 0; i < currentImage.getNumLayers(); i++) {\r\n        Image layer = currentImage.getLayer(i);\r\n        gradient.process(layer, currentDerivX[i], currentDerivY[i]);\r\n    }\r\n    float cx = (float) region.cx;\r\n    float cy = (float) region.cy;\r\n    float height = (float) (region.height);\r\n    float width = (float) (region.width);\r\n    float c = (float) Math.cos(region.theta);\r\n    float s = (float) Math.sin(region.theta);\r\n    float p = 1.0f / (config.numberOfSamples - 1);\r\n    for (int i = 0; i < config.numberOfSamples; i++) {\r\n        float y = (p * i - 0.5f) * height;\r\n        for (int j = 0; j < config.numberOfSamples; j++) {\r\n            float x = (p * j - 0.5f) * width;\r\n            float xx = cx + x * c - y * s;\r\n            float yy = cy + x * s + y * c;\r\n            track.x = xx;\r\n            track.y = yy;\r\n            klt.setImage(previousImage, previousDerivX, previousDerivY);\r\n            if (!klt.setDescription(track)) {\r\n                continue;\r\n            }\r\n            klt.setImage(currentImage, currentDerivX, currentDerivY);\r\n            KltTrackFault fault = klt.track(track);\r\n            if (fault != KltTrackFault.SUCCESS) {\r\n                continue;\r\n            }\r\n            float xc = track.x;\r\n            float yc = track.y;\r\n            if (!klt.setDescription(track)) {\r\n                continue;\r\n            }\r\n            klt.setImage(previousImage, previousDerivX, previousDerivY);\r\n            fault = klt.track(track);\r\n            if (fault != KltTrackFault.SUCCESS) {\r\n                continue;\r\n            }\r\n            float error = UtilPoint2D_F32.distanceSq(track.x, track.y, xx, yy);\r\n            if (error > maximumErrorFB) {\r\n                continue;\r\n            }\r\n            AssociatedPair a = pairs.grow();\r\n            a.p1.x = xx;\r\n            a.p1.y = yy;\r\n            a.p2.x = xc;\r\n            a.p2.y = yc;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestBoneCP.testIsConnectionHandleAliveNormalCaseWithConnectionTestTriggerExceptionInFinally",
	"Comment": "test method for com.jolbox.bonecp.bonecp isconnectionhandlealive.",
	"Method": "void testIsConnectionHandleAliveNormalCaseWithConnectionTestTriggerExceptionInFinally(){\r\n    Statement mockStatement = EasyMock.createNiceMock(Statement.class);\r\n    reset(mockConfig, mockConnection, mockDatabaseMetadata, mockResultSet);\r\n    expect(mockConfig.getConnectionTestStatement()).andReturn(\"whatever\").once();\r\n    expect(mockConnection.createStatement()).andReturn(mockStatement).once();\r\n    expect(mockStatement.execute((String) anyObject())).andThrow(new RuntimeException()).once();\r\n    mockStatement.close();\r\n    expectLastCall().andThrow(new SQLException()).once();\r\n    mockConnection.logicallyClosed = new AtomicBoolean(false);\r\n    replay(mockConfig, mockConnection, mockDatabaseMetadata, mockStatement, mockResultSet);\r\n    try {\r\n        testClass.isConnectionHandleAlive(mockConnection);\r\n        fail(\"Should have thrown an exception\");\r\n    } catch (RuntimeException e) {\r\n    }\r\n    verify(mockConfig, mockConnection, mockResultSet, mockDatabaseMetadata, mockStatement);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.process",
	"Comment": "process the contour and returns true if a polyline could be found.",
	"Method": "boolean process(List<Point2D_I32> contour){\r\n    reset();\r\n    if (loops) {\r\n        if (contour.size() < 3)\r\n            return false;\r\n        if (!findInitialTriangle(contour))\r\n            return false;\r\n    } else {\r\n        if (contour.size() < 2)\r\n            return false;\r\n        addCorner(0);\r\n        addCorner(contour.size() - 1);\r\n        initializeScore(contour, false);\r\n    }\r\n    savePolyline();\r\n    sequentialSideFit(contour, loops);\r\n    if (fatalError)\r\n        return false;\r\n    int MIN_SIZE = loops ? 3 : 2;\r\n    double bestScore = Double.MAX_VALUE;\r\n    int bestSize = -1;\r\n    for (int i = 0; i < Math.min(maxSides - (MIN_SIZE - 1), polylines.size); i++) {\r\n        if (polylines.get(i).score < bestScore) {\r\n            bestPolyline = polylines.get(i);\r\n            bestScore = bestPolyline.score;\r\n            bestSize = i + MIN_SIZE;\r\n        }\r\n    }\r\n    if (bestSize < minSides) {\r\n        return false;\r\n    }\r\n    for (int i = 0, j = bestSize - 1; i < bestSize; j = i, i++) {\r\n        Point2D_I32 a = contour.get(bestPolyline.splits.get(i));\r\n        Point2D_I32 b = contour.get(bestPolyline.splits.get(j));\r\n        double length = a.distance(b);\r\n        double thresholdSideError = this.maxSideError.compute(length);\r\n        if (bestPolyline.sideErrors.get(i) >= thresholdSideError * thresholdSideError) {\r\n            bestPolyline = null;\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.transform.fft.GeneralPurposeFFT_F32_2D.realInverseFull",
	"Comment": "computes 2d inverse dft of real data leaving the result in a\t. this method computes full real inverse transform, i.e. you will get the\tsame result as from complexinverse called with all imaginary\tpart equal 0. because the result is stored in a, the input\tarray must be of size rowscolumns, with only the first rowscolumns\telements filled with real data.",
	"Method": "void realInverseFull(float[] a,boolean scale){\r\n    if (rows == 1 || columns == 1) {\r\n        if (rows > 1)\r\n            fftRows.realInverseFull(a, scale);\r\n        else\r\n            fftColumns.realInverseFull(a, scale);\r\n        return;\r\n    }\r\n    if (isPowerOfTwo) {\r\n        for (int r = 0; r < rows; r++) {\r\n            fftColumns.realInverse2(a, r * columns, scale);\r\n        }\r\n        cdft2d_sub(1, a, scale);\r\n        rdft2d_sub(1, a);\r\n        fillSymmetric(a);\r\n    } else {\r\n        declareRadixRealData();\r\n        mixedRadixRealInverseFull(a, scale);\r\n    }\r\n}"
}, {
	"Path": "boofcv.examples.features.ExampleAssociatePoints.associate",
	"Comment": "detect and associate point features in the two images.display the results.",
	"Method": "void associate(BufferedImage imageA,BufferedImage imageB){\r\n    T inputA = ConvertBufferedImage.convertFromSingle(imageA, null, imageType);\r\n    T inputB = ConvertBufferedImage.convertFromSingle(imageB, null, imageType);\r\n    pointsA = new ArrayList();\r\n    pointsB = new ArrayList();\r\n    FastQueue<TD> descA = UtilFeature.createQueue(detDesc, 100);\r\n    FastQueue<TD> descB = UtilFeature.createQueue(detDesc, 100);\r\n    describeImage(inputA, pointsA, descA);\r\n    describeImage(inputB, pointsB, descB);\r\n    associate.setSource(descA);\r\n    associate.setDestination(descB);\r\n    associate.associate();\r\n    AssociationPanel panel = new AssociationPanel(20);\r\n    panel.setAssociation(pointsA, pointsB, associate.getMatches());\r\n    panel.setImages(imageA, imageB);\r\n    ShowImages.showWindow(panel, \"Associated Features\", true);\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.border.TestConvolveJustBorder_General_SB.compareToNoBorder",
	"Comment": "compare the results along the border to the results obtained by convolving a larger image with the noborder algorithm\twhose border has been filled with the fillvalue.",
	"Method": "void compareToNoBorder(){\r\n    performTests(9);\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.DescribePointBrief.setImage",
	"Comment": "specifies the image from which feature descriptions are to be created.",
	"Method": "void setImage(T image){\r\n    blur.reshape(image.width, image.height);\r\n    filterBlur.process(image, blur);\r\n    describe.setImage(image);\r\n}"
}, {
	"Path": "boofcv.alg.distort.mls.ImageDeformPointMLS_F32.configure",
	"Comment": "specifies the input image size and the size of the grid it will use to approximate the idea solution. all\tcontrol points are discarded",
	"Method": "void configure(int width,int height,int gridRows,int gridCols){\r\n    int s = Math.max(width, height);\r\n    scaleX = s / (float) (gridCols - 1);\r\n    scaleY = s / (float) (gridRows - 1);\r\n    if (gridRows > gridCols) {\r\n        scaleY /= (gridCols - 1) / (float) (gridRows - 1);\r\n    } else {\r\n        scaleX /= (gridRows - 1) / (float) (gridCols - 1);\r\n    }\r\n    this.gridRows = gridRows;\r\n    this.gridCols = gridCols;\r\n    grid.resize(gridCols * gridRows);\r\n    reset();\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldTracker.selectPyramidScale",
	"Comment": "selects the scale for the image pyramid based on image size and feature size",
	"Method": "int[] selectPyramidScale(int imageWidth,int imageHeight,int minSize){\r\n    int w = Math.max(imageWidth, imageHeight);\r\n    int maxScale = w / minSize;\r\n    int n = 1;\r\n    int scale = 1;\r\n    while (scale * 2 < maxScale) {\r\n        n++;\r\n        scale *= 2;\r\n    }\r\n    int[] ret = new int[n];\r\n    scale = 1;\r\n    for (int i = 0; i < n; i++) {\r\n        ret[i] = scale;\r\n        scale *= 2;\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.GGradientToEdgeFeatures.nonMaxSuppressionCrude4",
	"Comment": "sets edge intensities to zero if the pixel has an intensity which is less than any of\tthe two adjacent pixels.pixel adjacency is determined based upon the sign of the image gradient.less precise\tthan other methods, but faster.",
	"Method": "void nonMaxSuppressionCrude4(GrayF32 intensity,D derivX,D derivY,GrayF32 output){\r\n    if (derivX instanceof GrayF32) {\r\n        GradientToEdgeFeatures.nonMaxSuppressionCrude4(intensity, (GrayF32) derivX, (GrayF32) derivY, output);\r\n    } else if (derivX instanceof GrayS16) {\r\n        GradientToEdgeFeatures.nonMaxSuppressionCrude4(intensity, (GrayS16) derivX, (GrayS16) derivY, output);\r\n    } else if (derivX instanceof GrayS32) {\r\n        GradientToEdgeFeatures.nonMaxSuppressionCrude4(intensity, (GrayS32) derivX, (GrayS32) derivY, output);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown input type\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.scene.FeatureToWordHistogram_F64.process",
	"Comment": "no more features are being added.normalized the computed histogram.",
	"Method": "void process(){\r\n    processed = true;\r\n    for (int i = 0; i < histogram.length; i++) {\r\n        histogram[i] /= total;\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.filter.binary.BinaryContourInterface.copyContour",
	"Comment": "convenience function which loads a contour and creates copy of all the points and returns\ta new list",
	"Method": "List<Point2D_I32> copyContour(BinaryContourInterface finder,int contourID){\r\n    FastQueue<Point2D_I32> storage = new FastQueue(Point2D_I32.class, true);\r\n    finder.loadContour(contourID, storage);\r\n    List<Point2D_I32> list = new ArrayList(storage.size);\r\n    for (int i = 0; i < storage.size; i++) {\r\n        list.add(storage.get(i));\r\n    }\r\n    return list;\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.TestCameraToEquirectangular_F64.setDirection",
	"Comment": "rotate the camera and see if the camera center is pointing in the right direction now",
	"Method": "void setDirection(){\r\n    CameraPinholeRadial intrinsic = new CameraPinholeRadial(400, 400, 0, imgWidth / 2, imgHeight / 2, imgWidth, imgHeight);\r\n    intrinsic.setRadial(0.1, 0.2);\r\n    CameraToEquirectangular_F64 alg = new CameraToEquirectangular_F64();\r\n    alg.setCameraModel(intrinsic);\r\n    alg.setEquirectangularShape(equiWidth, equiHeight);\r\n    alg.setDirection(0, Math.PI / 2, 0);\r\n    assertPointing(alg, imgWidth / 2, imgHeight / 2, 1, 0, 0);\r\n}"
}, {
	"Path": "com.bugsnag.android.JsonStreamTest.setUp",
	"Comment": "deletes a file in the cache directory if it already exists from previous test cases",
	"Method": "void setUp(){\r\n    writer = new StringWriter();\r\n    stream = new JsonStream(writer);\r\n    File cacheDir = InstrumentationRegistry.getContext().getCacheDir();\r\n    file = new File(cacheDir, \"whoops\");\r\n    file.delete();\r\n}"
}, {
	"Path": "org.boon.Lists.deepCopy",
	"Comment": "clones each list item into a new instance with copied fields.it is like doing a clone operation.if the passed list is a linkedlist then the returned list will be alinkedlist.if the passed list is a copyonwritearraylist then the returned list willbe a copyonwritearraylist list.all other lists become arraylist.",
	"Method": "List<V> deepCopy(Collection<V> collection,List<T> deepCopy,Collection<V> src,Class<T> dest,List<V> deepCopy,List<V> list){\r\n    if (list instanceof LinkedList) {\r\n        return deepCopyToList(list, new LinkedList<V>());\r\n    } else if (list instanceof CopyOnWriteArrayList) {\r\n        return deepCopyToList(list, new CopyOnWriteArrayList<V>());\r\n    } else {\r\n        return deepCopy((Collection) list);\r\n    }\r\n}"
}, {
	"Path": "org.boon.sort.Ordering.max",
	"Comment": "gets the max item from the array.sorts the list descending first.",
	"Method": "T max(List<T> list,T max,T[] array,T max,List<T> list,String sortBy,T max,T[] array,String sortBy){\r\n    if (array.length > 1) {\r\n        Sorting.sortDesc(array, sortBy);\r\n        return array[0];\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationLinearRotationMulti.setConstraints",
	"Comment": "specifies linear constraints\tknown aspect ratio constraint can only be used if zero skew is also assumped.",
	"Method": "void setConstraints(boolean zeroSkew,boolean principlePointOrigin,boolean knownAspect,double aspect){\r\n    if (knownAspect && !zeroSkew)\r\n        throw new IllegalArgumentException(\"If aspect is known then skew must be zero\");\r\n    this.zeroSkew = zeroSkew;\r\n    this.principlePointOrigin = principlePointOrigin;\r\n    this.knownAspectRatio = knownAspect;\r\n    this.aspectRatio = aspect;\r\n    notZeros.resize(6);\r\n    for (int i = 0; i < 6; i++) {\r\n        notZeros.data[i] = i;\r\n    }\r\n    if (principlePointOrigin) {\r\n        notZeros.remove(4);\r\n        notZeros.remove(2);\r\n    }\r\n    if (zeroSkew) {\r\n        notZeros.remove(1);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.MergeRegionMeanShift.process",
	"Comment": "merges together similar regions which are in close proximity to each other.after merging\tmost of the input data structures are modified to take in account thechanges.",
	"Method": "void process(GrayS32 pixelToRegion,GrowQueue_I32 regionMemberCount,FastQueue<float[]> regionColor,FastQueue<Point2D_I32> modeLocation){\r\n    stopRequested = false;\r\n    initializeMerge(regionMemberCount.size);\r\n    markMergeRegions(regionColor, modeLocation, pixelToRegion);\r\n    if (stopRequested)\r\n        return;\r\n    performMerge(pixelToRegion, regionMemberCount);\r\n}"
}, {
	"Path": "org.boon.core.reflection.BeanUtils.getFieldsFromObject",
	"Comment": "get fields from object or map.allows maps to act like they have fields.",
	"Method": "Map<String, FieldAccess> getFieldsFromObject(Class<?> cls,Map<String, FieldAccess> getFieldsFromObject,Object object){\r\n    try {\r\n        Map<String, FieldAccess> fields;\r\n        if (object instanceof Map) {\r\n            fields = getFieldsFromMap((Map<String, Object>) object);\r\n        } else {\r\n            fields = getPropertyFieldAccessMap(object.getClass());\r\n        }\r\n        return fields;\r\n    } catch (Exception ex) {\r\n        requireNonNull(object, \"Item cannot be null\");\r\n        return handle(Map.class, ex, \"Unable to get fields from object\", className(object));\r\n    }\r\n}"
}, {
	"Path": "io.github.bucket4j.Bandwidth.simple",
	"Comment": "specifies simple limitation capacity tokens per period time window.",
	"Method": "Bandwidth simple(long capacity,Duration period){\r\n    Refill refill = Refill.greedy(capacity, period);\r\n    return classic(capacity, refill);\r\n}"
}, {
	"Path": "boofcv.alg.geo.TestDecomposeHomography.multipleCalls",
	"Comment": "checks to see if the same solution is returned when invoked multiple times",
	"Method": "void multipleCalls(){\r\n    DMatrixRMaj H = MultiViewOps.createHomography(R, T, d, N);\r\n    DecomposeHomography alg = new DecomposeHomography();\r\n    alg.decompose(H);\r\n    alg.decompose(H);\r\n    List<Se3_F64> foundSE = alg.getSolutionsSE();\r\n    List<Vector3D_F64> foundN = alg.getSolutionsN();\r\n    TestDecomposeEssential.checkUnique(foundSE);\r\n    checkHasOriginal(foundSE, foundN, R, T, d, N);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.getCloseConnectionWatchTimeout",
	"Comment": "returns the closeconnectionwatchtimeout with the specified granularity.",
	"Method": "long getCloseConnectionWatchTimeout(long getCloseConnectionWatchTimeout,TimeUnit timeUnit){\r\n    return timeUnit.convert(this.closeConnectionWatchTimeoutInMs, TimeUnit.MILLISECONDS);\r\n}"
}, {
	"Path": "boofcv.demonstrations.feature.associate.VisualizeAssociationScoreApp.processImage",
	"Comment": "extracts image information and then passes that info onto scorepanel for display.data is not\trecycled to avoid threading issues.",
	"Method": "void processImage(){\r\n    final List<Point2D_F64> leftPts = new ArrayList();\r\n    final List<Point2D_F64> rightPts = new ArrayList();\r\n    final List<TupleDesc> leftDesc = new ArrayList();\r\n    final List<TupleDesc> rightDesc = new ArrayList();\r\n    final ProgressMonitor progressMonitor = new ProgressMonitor(this, \"Compute Feature Information\", \"\", 0, 4);\r\n    extractImageFeatures(progressMonitor, 0, imageLeft, leftDesc, leftPts);\r\n    extractImageFeatures(progressMonitor, 2, imageRight, rightDesc, rightPts);\r\n    SwingUtilities.invokeLater(new Runnable() {\r\n        public void run() {\r\n            progressMonitor.close();\r\n            scorePanel.setScorer(controlPanel.getSelected());\r\n            scorePanel.setLocation(leftPts, rightPts, leftDesc, rightDesc);\r\n            repaint();\r\n        }\r\n    });\r\n}"
}, {
	"Path": "boofcv.demonstrations.feature.associate.VisualizeAssociationScoreApp.processImage",
	"Comment": "extracts image information and then passes that info onto scorepanel for display.data is not\trecycled to avoid threading issues.",
	"Method": "void processImage(){\r\n    progressMonitor.close();\r\n    scorePanel.setScorer(controlPanel.getSelected());\r\n    scorePanel.setLocation(leftPts, rightPts, leftDesc, rightDesc);\r\n    repaint();\r\n}"
}, {
	"Path": "boofcv.factory.weights.FactoryWeights.distance",
	"Comment": "creates a weight function for the provided distributions.",
	"Method": "WeightDistance_F32 distance(WeightType type,float param,boolean safe){\r\n    if (safe)\r\n        throw new IllegalArgumentException(\"Safe distributons not implemented yet\");\r\n    switch(type) {\r\n        case GAUSSIAN_SQ:\r\n            return new WeightDistanceSqGaussian_F32(param);\r\n        case UNIFORM:\r\n            return new WeightDistanceUniform_F32(param);\r\n    }\r\n    throw new IllegalArgumentException(\"Unknown type \" + type);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareRegularClustersIntoGrids.pickNot",
	"Comment": "there are only two edges on target.pick the edge which does not go to the provided child",
	"Method": "SquareNode pickNot(SquareNode target,SquareNode child,SquareNode pickNot,SquareNode target,SquareNode child0,SquareNode child1){\r\n    for (int i = 0; i < 4; i++) {\r\n        SquareEdge e = target.edges[i];\r\n        if (e == null)\r\n            continue;\r\n        SquareNode c = e.destination(target);\r\n        if (c != child0 && c != child1)\r\n            return c;\r\n    }\r\n    throw new RuntimeException(\"There was no odd one out some how\");\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.BaseTestDescribePointBinaryCompare.changeInInputSize",
	"Comment": "change the input image size and see if it handles that case properly.",
	"Method": "void changeInInputSize(){\r\n    T inputA = createImage(width, height);\r\n    T inputB = createImage(width - 5, height - 5);\r\n    DescribePointBinaryCompare<T> alg = createAlg(def);\r\n    TupleDesc_B desc = createFeature();\r\n    alg.setImage(inputA);\r\n    alg.process(inputA.width / 2, inputA.height / 2, desc);\r\n    alg.setImage(inputB);\r\n    alg.process(inputA.width / 2, inputA.height / 2, desc);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.EstimateSceneCalibrated.triangulateNoLocation",
	"Comment": "go through all connections to the view and triangulate all features which have\tnot been triangulated already",
	"Method": "void triangulateNoLocation(View target){\r\n    Se3_F64 otherToTarget = new Se3_F64();\r\n    Se3_F64 worldToTarget = target.viewToWorld.invert(null);\r\n    for (Motion c : target.connections) {\r\n        boolean isSrc = c.viewSrc == target;\r\n        View other = c.destination(target);\r\n        if (other.state != ViewState.PROCESSED)\r\n            continue;\r\n        other.viewToWorld.concat(worldToTarget, otherToTarget);\r\n        triangulationError.configure(target.camera.pinhole, other.camera.pinhole);\r\n        for (int i = 0; i < c.associated.size(); i++) {\r\n            AssociatedIndex a = c.associated.get(i);\r\n            int indexTarget = isSrc ? a.src : a.dst;\r\n            int indexOther = isSrc ? a.dst : a.src;\r\n            if (target.features3D[indexTarget] != null || other.features3D[indexOther] != null)\r\n                continue;\r\n            Point2D_F64 normOther = other.observationNorm.get(indexOther);\r\n            Point2D_F64 normTarget = target.observationNorm.get(indexTarget);\r\n            double angle = triangulationAngle(normOther, normTarget, otherToTarget);\r\n            if (angle < TRIANGULATE_MIN_ANGLE)\r\n                continue;\r\n            Feature3D f = new Feature3D();\r\n            if (!triangulate.triangulate(normOther, normTarget, otherToTarget, f.worldPt))\r\n                continue;\r\n            if (f.worldPt.z <= 0)\r\n                continue;\r\n            double error = triangulationError.process(normOther, normTarget, otherToTarget, f.worldPt);\r\n            if (error > maxPixelError * maxPixelError)\r\n                continue;\r\n            other.viewToWorld.transform(f.worldPt, f.worldPt);\r\n            f.views.add(target);\r\n            f.views.add(other);\r\n            f.obsIdx.add(indexTarget);\r\n            f.obsIdx.add(indexOther);\r\n            graph.features3D.add(f);\r\n            target.features3D[indexTarget] = f;\r\n            other.features3D[indexOther] = f;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TrifocalLinearPoint7.solveLinearSystem",
	"Comment": "computes the null space of the linear system to find the trifocal tensor",
	"Method": "boolean solveLinearSystem(){\r\n    if (!svdNull.decompose(A))\r\n        return false;\r\n    SingularOps_DDRM.nullVector(svdNull, true, vectorizedSolution);\r\n    solutionN.convertFrom(vectorizedSolution);\r\n    return true;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setDefaultCatalog",
	"Comment": "sets the defaultcatalog setting for newly created connections. if not set, use driver default.",
	"Method": "void setDefaultCatalog(String defaultCatalog){\r\n    this.defaultCatalog = checkNotNull(defaultCatalog);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.TestPolylineSplitMerge.isConvexUsingMaxDistantPoints_positive",
	"Comment": "create a rectangle and feed it every point in the rectangle and see if it has the expected response",
	"Method": "void isConvexUsingMaxDistantPoints_positive(){\r\n    List<Point2D_I32> contour = rect(5, 6, 12, 20);\r\n    for (int i = 0; i < contour.size(); i++) {\r\n        int farthest = -1;\r\n        double distance = -1;\r\n        for (int j = 0; j < contour.size(); j++) {\r\n            double d = contour.get(i).distance(contour.get(j));\r\n            if (d > distance) {\r\n                distance = d;\r\n                farthest = j;\r\n            }\r\n        }\r\n        assertTrue(PolylineSplitMerge.isConvexUsingMaxDistantPoints(contour, i, farthest));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.transform.fft.GeneralPurposeFFT_F32_2D.realForwardFull",
	"Comment": "computes 2d forward dft of real data leaving the result in a\t. this method computes full real forward transform, i.e. you will get the\tsame result as from complexforward called with all imaginary\tpart equal 0. because the result is stored in a, the input\tarray must be of size rowscolumns, with only the first rowscolumns\telements filled with real data. to get back the original data, use\tcomplexinverse on the output of this method.",
	"Method": "void realForwardFull(float[] a){\r\n    if (rows == 1 || columns == 1) {\r\n        if (rows > 1)\r\n            fftRows.realForwardFull(a);\r\n        else\r\n            fftColumns.realForwardFull(a);\r\n        return;\r\n    }\r\n    if (isPowerOfTwo) {\r\n        for (int r = 0; r < rows; r++) {\r\n            fftColumns.realForward(a, r * columns);\r\n        }\r\n        cdft2d_sub(-1, a, true);\r\n        rdft2d_sub(1, a);\r\n        fillSymmetric(a);\r\n    } else {\r\n        declareRadixRealData();\r\n        mixedRadixRealForwardFull(a);\r\n    }\r\n}"
}, {
	"Path": "org.bimserver.tests.GuidCompressor.cv_to_64",
	"Comment": "conversion of an integer into a number with base 64\tusing the table cconversiontable",
	"Method": "boolean cv_to_64(long number,char[] code,int len){\r\n    long act;\r\n    int iDigit, nDigits;\r\n    char[] result = new char[5];\r\n    if (len > 5)\r\n        return false;\r\n    act = number;\r\n    nDigits = len - 1;\r\n    for (iDigit = 0; iDigit < nDigits; iDigit++) {\r\n        result[nDigits - iDigit - 1] = cConversionTable[(int) (act % 64)];\r\n        act /= 64;\r\n    }\r\n    result[len - 1] = '\\0';\r\n    if (act != 0)\r\n        return false;\r\n    for (int i = 0; i < result.length; i++) code[i] = result[i];\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.UtilLepetitEPnP.constraintMatrix3x3",
	"Comment": "extracts the linear constraint matrix for planar case 2 from the full 4x6 constraint matrix.",
	"Method": "void constraintMatrix3x3(DMatrixRMaj L_3x6,DMatrixRMaj L_6x3){\r\n    int index = 0;\r\n    for (int i = 0; i < 3; i++) {\r\n        L_6x3.data[index++] = L_3x6.get(i, 0);\r\n        L_6x3.data[index++] = L_3x6.get(i, 1);\r\n        L_6x3.data[index++] = L_3x6.get(i, 3);\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.filter.TestFilterImageReflection.basicTest2",
	"Comment": "checks to see if the provided function is invoked and that it returned the correct border",
	"Method": "void basicTest2(){\r\n    FilterImageReflection filter = new FilterImageReflection(getClass(), \"methodDummy\", 2, 3, GrayU8.class, GrayU16.class);\r\n    GrayU8 in = new GrayU8(5, 5);\r\n    GrayU16 out = new GrayU16(5, 5);\r\n    filter.process(in, out);\r\n    assertEquals(2, filter.getHorizontalBorder());\r\n    assertEquals(3, filter.getVerticalBorder());\r\n    assertTrue(GrayU8.class == filter.getInputType().getImageClass());\r\n    assertTrue(GrayU16.class == filter.getOutputType().getImageClass());\r\n    assertEquals(1, out.get(0, 0));\r\n}"
}, {
	"Path": "boofcv.abst.filter.TestFilterImageReflection.basicTest3",
	"Comment": "some filters have a parameter which specify the number of times it is invoked",
	"Method": "void basicTest3(){\r\n    FilterImageReflection filter = new FilterImageReflection(getClass(), \"methodDummy2\", 2, 3, GrayU8.class, GrayU16.class);\r\n    GrayU8 in = new GrayU8(5, 5);\r\n    GrayU16 out = new GrayU16(5, 5);\r\n    filter.process(in, out);\r\n    assertEquals(2, filter.getHorizontalBorder());\r\n    assertEquals(3, filter.getVerticalBorder());\r\n    assertTrue(GrayU8.class == filter.getInputType().getImageClass());\r\n    assertTrue(GrayU16.class == filter.getOutputType().getImageClass());\r\n    assertEquals(1, out.get(0, 0));\r\n}"
}, {
	"Path": "boofcv.alg.transform.fft.GeneralPurposeFFT_F64_2D.realInverseFull",
	"Comment": "computes 2d inverse dft of real data leaving the result in a\t. this method computes full real inverse transform, i.e. you will get the\tsame result as from complexinverse called with all imaginary\tpart equal 0. because the result is stored in a, the input\tarray must be of size rowscolumns, with only the first rowscolumns\telements filled with real data.",
	"Method": "void realInverseFull(double[] a,boolean scale){\r\n    if (rows == 1 || columns == 1) {\r\n        if (rows > 1)\r\n            fftRows.realInverseFull(a, scale);\r\n        else\r\n            fftColumns.realInverseFull(a, scale);\r\n        return;\r\n    }\r\n    if (isPowerOfTwo) {\r\n        for (int r = 0; r < rows; r++) {\r\n            fftColumns.realInverse2(a, r * columns, scale);\r\n        }\r\n        cdft2d_sub(1, a, scale);\r\n        rdft2d_sub(1, a);\r\n        fillSymmetric(a);\r\n    } else {\r\n        declareRadixRealData();\r\n        mixedRadixRealInverseFull(a, scale);\r\n    }\r\n}"
}, {
	"Path": "boofcv.android.camera2.VisualizeCamera2Activity.selectResolution",
	"Comment": "selects a resolution which has the number of pixels closest to the requested value",
	"Method": "int selectResolution(int widthTexture,int heightTexture,Size[] resolutions){\r\n    timeOfLastUpdated = 0;\r\n    int bestIndex = -1;\r\n    double bestAspect = Double.MAX_VALUE;\r\n    double bestArea = 0;\r\n    for (int i = 0; i < resolutions.length; i++) {\r\n        Size s = resolutions[i];\r\n        int width = s.getWidth();\r\n        int height = s.getHeight();\r\n        double aspectScore = Math.abs(width * height - targetResolution);\r\n        if (aspectScore < bestAspect) {\r\n            bestIndex = i;\r\n            bestAspect = aspectScore;\r\n            bestArea = width * height;\r\n        } else if (Math.abs(aspectScore - bestArea) <= 1e-8) {\r\n            bestIndex = i;\r\n            double area = width * height;\r\n            if (area > bestArea) {\r\n                bestArea = area;\r\n            }\r\n        }\r\n    }\r\n    return bestIndex;\r\n}"
}, {
	"Path": "boofcv.abst.feature.detdesc.GenericTestsDetectDescribeMulti.detectFeatures",
	"Comment": "detects features inside the image and checks to see if it is in compliance of its reported capabilities",
	"Method": "void detectFeatures(){\r\n    DetectDescribeMulti<T, TD> alg = createDetDesc();\r\n    alg.process(image);\r\n    for (int n = 0; n < alg.getNumberOfSets(); n++) {\r\n        PointDescSet<TD> set = alg.getFeatureSet(n);\r\n        int N = set.getNumberOfFeatures();\r\n        assertTrue(N > 5);\r\n        for (int i = 0; i < N; i++) {\r\n            Point2D_F64 p = set.getLocation(i);\r\n            TD desc = set.getDescription(i);\r\n            assertTrue(desc != null);\r\n            assertTrue(p.x != 0 && p.y != 0);\r\n            assertTrue(p.x >= 0 && p.y >= 0 && p.x < image.width && p.y < image.height);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernelGaussian.gaussianWidth",
	"Comment": "create a gaussian kernel based on its width.supports kernels of even or odd widths",
	"Method": "Kernel2D_F64 gaussianWidth(double sigma,int width){\r\n    if (sigma <= 0)\r\n        sigma = sigmaForRadius(width / 2, 0);\r\n    else if (width <= 0)\r\n        throw new IllegalArgumentException(\"Must specify the width since it doesn't know if it should be even or odd\");\r\n    if (width % 2 == 0) {\r\n        int r = width / 2 - 1;\r\n        Kernel2D_F64 ret = new Kernel2D_F64(width);\r\n        double sum = 0;\r\n        for (int y = 0; y < width; y++) {\r\n            double dy = y <= r ? Math.abs(y - r) + 0.5 : Math.abs(y - r - 1) + 0.5;\r\n            for (int x = 0; x < width; x++) {\r\n                double dx = x <= r ? Math.abs(x - r) + 0.5 : Math.abs(x - r - 1) + 0.5;\r\n                double d = Math.sqrt(dx * dx + dy * dy);\r\n                double val = UtilGaussian.computePDF(0, sigma, d);\r\n                ret.set(x, y, val);\r\n                sum += val;\r\n            }\r\n        }\r\n        for (int i = 0; i < ret.data.length; i++) {\r\n            ret.data[i] /= sum;\r\n        }\r\n        return ret;\r\n    } else {\r\n        return gaussian2D_F64(sigma, width / 2, true, true);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.impl.TestImplPolynomialPixel_I.compareToBilinear",
	"Comment": "polynomial interpolation of order one is bilinear interpolation",
	"Method": "void compareToBilinear(){\r\n    GrayU8 img = new GrayU8(width, height);\r\n    GrayU8 expected = new GrayU8(width, height);\r\n    GrayU8 found = new GrayU8(width, height);\r\n    GImageMiscOps.fillUniform(img, rand, 0, 255);\r\n    Affine2D_F32 tran = new Affine2D_F32(1, 0, 0, 1, 0.25f, 0.25f);\r\n    InterpolatePixelS<GrayU8> alg = (InterpolatePixelS) new ImplPolynomialPixel_I(2, 0, 255);\r\n    alg.setBorder(FactoryImageBorder.singleValue(GrayU8.class, 0));\r\n    ImageDistort<GrayU8, GrayU8> distorter = FactoryDistort.distortSB(false, alg, GrayU8.class);\r\n    distorter.setModel(new PixelTransformAffine_F32(tran));\r\n    distorter.apply(img, found);\r\n    InterpolatePixelS<GrayU8> bilinear = FactoryInterpolation.bilinearPixelS(GrayU8.class, BorderType.ZERO);\r\n    distorter = FactoryDistort.distortSB(false, bilinear, GrayU8.class);\r\n    distorter.setModel(new PixelTransformAffine_F32(tran));\r\n    distorter.apply(img, expected);\r\n    BoofTesting.assertEquals(expected, found, 0);\r\n}"
}, {
	"Path": "boofcv.io.wrapper.images.LoadFileImageSequence.hasNext",
	"Comment": "true if there is another image to read and false if there are no more.",
	"Method": "boolean hasNext(){\r\n    if (loop)\r\n        return true;\r\n    else\r\n        return index < fileNames.size();\r\n}"
}, {
	"Path": "org.boon.core.reflection.BeanUtils.getProp",
	"Comment": "this is one is forgiving of null paths.this works with getters first, i.e., properties.",
	"Method": "Object getProp(Object object,String property){\r\n    if (object == null) {\r\n        return null;\r\n    }\r\n    if (isDigits(property)) {\r\n        object = idx(object, StringScanner.parseInt(property));\r\n    }\r\n    Class<?> cls = object.getClass();\r\n    Map<String, FieldAccess> fields = Reflection.getPropertyFieldAccessors(cls);\r\n    if (!fields.containsKey(property)) {\r\n        fields = Reflection.getAllAccessorFields(cls);\r\n    }\r\n    if (!fields.containsKey(property)) {\r\n        return null;\r\n    } else {\r\n        return fields.get(property).getValue(object);\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Error.getExceptionName",
	"Comment": "get the class name from the exception contained in this error report.",
	"Method": "String getExceptionName(){\r\n    if (exception instanceof BugsnagException) {\r\n        return ((BugsnagException) exception).getName();\r\n    } else {\r\n        return exception.getClass().getName();\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.StandardPointTrackerTwoPass.hintBeforeProcess",
	"Comment": "makes sure it can take a hint before process is called and not just for the second pass",
	"Method": "void hintBeforeProcess(){\r\n    tracker2 = createTracker();\r\n    tracker2.process((T) image);\r\n    tracker2.finishTracking();\r\n    tracker2.spawnTracks();\r\n    int allBefore = tracker2.getActiveTracks(null).size();\r\n    int activeBefore = tracker2.getAllTracks(null).size();\r\n    assertTrue(allBefore > 0);\r\n    assertTrue(activeBefore > 0);\r\n    List<PointTrack> tracks = tracker2.getAllTracks(null);\r\n    for (PointTrack t : tracks) {\r\n        tracker2.setHint(0, 0, t);\r\n    }\r\n    tracker2.process((T) image);\r\n    assertEquals(allBefore, tracker2.getAllTracks(null).size());\r\n    assertEquals(0, tracker2.getDroppedTracks(null).size());\r\n    assertEquals(0, tracker2.getNewTracks(null).size());\r\n    assertTrue(activeBefore != tracker2.getActiveTracks(null).size());\r\n    checkInside(tracker2.getAllTracks(null));\r\n    tracker2.finishTracking();\r\n    if (shouldDropTracks) {\r\n        assertTrue(allBefore > tracker2.getAllTracks(null).size());\r\n        assertTrue(tracker2.getDroppedTracks(null).size() > 0);\r\n    }\r\n    assertTrue(activeBefore > tracker2.getActiveTracks(null).size());\r\n    checkInside(tracker2.getAllTracks(null));\r\n}"
}, {
	"Path": "boofcv.abst.geo.bundle.SceneStructureMetric.getUnknownCameraCount",
	"Comment": "returns the number of cameras with parameters that are not fixed",
	"Method": "int getUnknownCameraCount(){\r\n    int total = 0;\r\n    for (int i = 0; i < cameras.length; i++) {\r\n        if (!cameras[i].known) {\r\n            total++;\r\n        }\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "boofcv.struct.convolve.Kernel1D_S32.wrap",
	"Comment": "creates a kernel whose elements are the specified data array and has\tthe specified width.",
	"Method": "Kernel1D_S32 wrap(int data,int width,int offset){\r\n    Kernel1D_S32 ret = new Kernel1D_S32();\r\n    ret.data = data;\r\n    ret.width = width;\r\n    ret.offset = offset;\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TrifocalAlgebraicPoint7.minimizeWithGeometricConstraints",
	"Comment": "minimize the algebraic error using lm.the two epipoles are the parameters being optimized.",
	"Method": "void minimizeWithGeometricConstraints(){\r\n    extractEpipoles.setTensor(solutionN);\r\n    extractEpipoles.extractEpipoles(e2, e3);\r\n    param[0] = e2.x;\r\n    param[1] = e2.y;\r\n    param[2] = e2.z;\r\n    param[3] = e3.x;\r\n    param[4] = e3.y;\r\n    param[5] = e3.z;\r\n    errorFunction.init();\r\n    optimizer.setFunction(errorFunction, null);\r\n    optimizer.initialize(param, gtol, ftol);\r\n    UtilOptimize.process(optimizer, maxIterations);\r\n    double[] found = optimizer.getParameters();\r\n    paramToEpipoles(found, e2, e3);\r\n    enforce.process(e2, e3, A);\r\n    enforce.extractSolution(solutionN);\r\n}"
}, {
	"Path": "boofcv.alg.distort.radtan.TestAddRadialNtoN_F32.againstManual",
	"Comment": "manually compute the distorted coordinate for a point and see if it matches",
	"Method": "void againstManual(){\r\n    double[] radial = new double[] { 0.01, -0.03 };\r\n    float t1 = 0.1f, t2 = -0.05f;\r\n    Point2D_F32 orig = new Point2D_F32(0.1f, -0.2f);\r\n    float x = orig.x, y = orig.y;\r\n    float r2 = x * x + y * y;\r\n    float mag = (float) radial[0] * r2 + (float) radial[1] * r2 * r2;\r\n    float distX = orig.x * (1 + mag) + 2 * t1 * x * y + t2 * (r2 + 2 * x * x);\r\n    float distY = orig.y * (1 + mag) + t1 * (r2 + 2 * y * y) + 2 * t2 * x * y;\r\n    AddRadialNtoN_F32 alg = new AddRadialNtoN_F32().setDistortion(radial, t1, t2);\r\n    Point2D_F32 found = new Point2D_F32();\r\n    alg.compute(orig.x, orig.y, found);\r\n    assertEquals(distX, found.x, 1e-4);\r\n    assertEquals(distY, found.y, 1e-4);\r\n}"
}, {
	"Path": "boofcv.factory.feature.associate.FactoryAssociation.scoreEuclidean",
	"Comment": "scores features based on the euclidean distance between them.the square is often used instead\tof the euclidean distance since it is much faster to compute.",
	"Method": "ScoreAssociation<D> scoreEuclidean(Class<D> tupleType,boolean squared){\r\n    if (TupleDesc_F64.class.isAssignableFrom(tupleType)) {\r\n        if (squared)\r\n            return (ScoreAssociation) new ScoreAssociateEuclideanSq_F64();\r\n        else\r\n            return (ScoreAssociation) new ScoreAssociateEuclidean_F64();\r\n    } else if (tupleType == TupleDesc_F32.class) {\r\n        if (squared)\r\n            return (ScoreAssociation) new ScoreAssociateEuclideanSq_F32();\r\n    }\r\n    throw new IllegalArgumentException(\"Euclidean score not yet supported for type \" + tupleType.getSimpleName());\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.TestCalibrationDetectorSquareFiducialGrid.createFisheyePoses",
	"Comment": "a custom set of poses are used because this fiducial requires high resolution data",
	"Method": "void createFisheyePoses(){\r\n    Se3_F64 markerToWorld = new Se3_F64();\r\n    ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI, 0, markerToWorld.R);\r\n    markerToWorld.T.set(0, 0, 0.12);\r\n    fisheye_poses.add(markerToWorld.copy());\r\n    markerToWorld.T.set(0.1, 0, 0.12);\r\n    fisheye_poses.add(markerToWorld.copy());\r\n    markerToWorld.T.set(0.25, 0, 0.2);\r\n    fisheye_poses.add(markerToWorld.copy());\r\n    markerToWorld.T.set(0.25, 0, 0.2);\r\n    ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI - 0.2, 0, markerToWorld.getR());\r\n    fisheye_poses.add(markerToWorld.copy());\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.FiducialDetectorPnP.computeStability",
	"Comment": "estimates the stability by perturbing each land mark by the specified number of pixels in the distorted image.",
	"Method": "boolean computeStability(int which,double disturbance,FiducialStability results){\r\n    if (!getFiducialToCamera(which, targetToCamera))\r\n        return false;\r\n    stability.setShape(getSideWidth(which), getSideHeight(which));\r\n    stability.computeStability(targetToCamera, disturbance, results);\r\n    return true;\r\n}"
}, {
	"Path": "test.me.corriekay.pokegoutil.gui.controller.LogControllerTest.lineIsTrimmedToMaxLength",
	"Comment": "test for number of lines being trimmed when it is more than the max limit.",
	"Method": "void lineIsTrimmedToMaxLength(){\r\n    printLines();\r\n    printLines();\r\n    final int expectedLength = numOfLines;\r\n    final String[] textareaLines = getLines();\r\n    assertThat(textAreaHas(expectedLength), textareaLines.length, is(expectedLength));\r\n}"
}, {
	"Path": "boofcv.app.calib.ImageSelectorAndSaver.updateScore",
	"Comment": "used when you just want to update the score for visualization purposes but not update the best image.",
	"Method": "void updateScore(GrayF32 image,List<Point2D_F64> sides){\r\n    removePerspective.apply(image, sides.get(0), sides.get(1), sides.get(2), sides.get(3));\r\n    GrayF32 current = removePerspective.getOutput();\r\n    float mean = (float) ImageStatistics.mean(current);\r\n    PixelMath.divide(current, mean, tempImage);\r\n    PixelMath.diffAbs(tempImage, template, difference);\r\n    PixelMath.multiply(difference, weights, difference);\r\n    currentScore = ImageStatistics.sum(difference) / totalWeight;\r\n}"
}, {
	"Path": "com.bugsnag.android.JsonWriter.getSerializeNulls",
	"Comment": "returns true if object members are serialized when their value is null.this has no impact on array elements. the default is true.",
	"Method": "boolean getSerializeNulls(){\r\n    return serializeNulls;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.TestQrCodeEncoder.multipleModes",
	"Comment": "see if it blows up when encoding using multiple encoding methods",
	"Method": "void multipleModes(){\r\n    new QrCodeEncoder().setVersion(2).setError(QrCode.ErrorLevel.M).setMask(QrCodeMaskPattern.M011).addNumeric(\"1234\").addKanji(\"?\").fixate();\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareRegularClustersIntoGrids.addRowsToGrid",
	"Comment": "competes the graph by traversing down the first column and adding the rows one at a time",
	"Method": "boolean addRowsToGrid(List<SquareNode> column,List<SquareNode> ordered){\r\n    for (int i = 0; i < column.size(); i++) {\r\n        column.get(i).graph = 0;\r\n    }\r\n    int numFirsRow = 0;\r\n    for (int j = 0; j < column.size(); j++) {\r\n        SquareNode n = column.get(j);\r\n        n.graph = SEARCHED;\r\n        ordered.add(n);\r\n        SquareNode nextRow;\r\n        if (j == 0) {\r\n            if (n.getNumberOfConnections() != 2) {\r\n                if (verbose)\r\n                    System.err.println(\"Unexpected number of connections. want 2 found \" + n.getNumberOfConnections());\r\n                return true;\r\n            }\r\n            nextRow = pickNot(n, column.get(j + 1));\r\n        } else if (j == column.size() - 1) {\r\n            if (n.getNumberOfConnections() != 2) {\r\n                if (verbose)\r\n                    System.err.println(\"Unexpected number of connections. want 2 found \" + n.getNumberOfConnections());\r\n                return true;\r\n            }\r\n            nextRow = pickNot(n, column.get(j - 1));\r\n        } else {\r\n            if (n.getNumberOfConnections() != 3) {\r\n                if (verbose)\r\n                    System.err.println(\"Unexpected number of connections. want 2 found \" + n.getNumberOfConnections());\r\n                return true;\r\n            }\r\n            nextRow = pickNot(n, column.get(j - 1), column.get(j + 1));\r\n        }\r\n        nextRow.graph = SEARCHED;\r\n        ordered.add(nextRow);\r\n        int numberLine = addLineToGrid(n, nextRow, ordered);\r\n        if (j == 0) {\r\n            numFirsRow = numberLine;\r\n        } else if (numberLine != numFirsRow) {\r\n            if (verbose)\r\n                System.err.println(\"Number of elements in rows do not match.\");\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.KltTracker.computeGandE_border",
	"Comment": "when part of the region is outside the image g and e need to be recomputed",
	"Method": "int computeGandE_border(KltFeature feature,float cx,float cy){\r\n    computeSubImageBounds(feature, cx, cy);\r\n    ImageMiscOps.fill(currDesc, Float.NaN);\r\n    currDesc.subimage(dstX0, dstY0, dstX1, dstY1, subimage);\r\n    interpInput.setImage(image);\r\n    interpInput.region(srcX0, srcY0, subimage);\r\n    int total = 0;\r\n    Gxx = 0;\r\n    Gyy = 0;\r\n    Gxy = 0;\r\n    Ex = 0;\r\n    Ey = 0;\r\n    for (int i = 0; i < lengthFeature; i++) {\r\n        float template = feature.desc.data[i];\r\n        float current = currDesc.data[i];\r\n        if (Float.isNaN(template) || Float.isNaN(current))\r\n            continue;\r\n        total++;\r\n        float dX = feature.derivX.data[i];\r\n        float dY = feature.derivY.data[i];\r\n        float d = template - current;\r\n        Ex += d * dX;\r\n        Ey += d * dY;\r\n        Gxx += dX * dX;\r\n        Gyy += dY * dY;\r\n        Gxy += dX * dY;\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "boofcv.android.camera2.VisualizeCamera2Activity.onDrawFrame",
	"Comment": "renders the visualizations. override and invoke super to add your own",
	"Method": "void onDrawFrame(SurfaceView view,Canvas canvas){\r\n    switch(bitmapMode) {\r\n        case UNSAFE:\r\n            canvas.drawBitmap(this.bitmap, imageToView, null);\r\n            break;\r\n        case DOUBLE_BUFFER:\r\n            bitmapLock.lock();\r\n            try {\r\n                canvas.drawBitmap(this.bitmap, imageToView, null);\r\n            } finally {\r\n                bitmapLock.unlock();\r\n            }\r\n            break;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.EnforceTrifocalGeometry.extractSolution",
	"Comment": "inserts the found trifocal tensor into the provided object.",
	"Method": "void extractSolution(TrifocalTensor tensor){\r\n    tensor.convertFrom(vectorT);\r\n}"
}, {
	"Path": "boofcv.io.image.ConvertBufferedImage.extractInterleavedU8",
	"Comment": "for bufferedimage stored as a byte array internally it extracts an\tinterleaved image.the input image and the returned image will both\tshare the same internal data array.using this function allows unnecessary\tmemory copying to be avoided.",
	"Method": "InterleavedU8 extractInterleavedU8(BufferedImage img){\r\n    DataBuffer buffer = img.getRaster().getDataBuffer();\r\n    if (buffer.getDataType() == DataBuffer.TYPE_BYTE && isKnownByteFormat(img)) {\r\n        WritableRaster raster = img.getRaster();\r\n        InterleavedU8 ret = new InterleavedU8();\r\n        ret.width = img.getWidth();\r\n        ret.height = img.getHeight();\r\n        ret.startIndex = ConvertRaster.getOffset(raster);\r\n        ret.imageType.numBands = raster.getNumBands();\r\n        ret.numBands = raster.getNumBands();\r\n        ret.stride = ConvertRaster.stride(raster);\r\n        ret.data = ((DataBufferByte) buffer).getData();\r\n        ret.subImage = ret.startIndex != 0;\r\n        return ret;\r\n    }\r\n    throw new IllegalArgumentException(\"Buffered image does not have an interleaved byte raster\");\r\n}"
}, {
	"Path": "com.bugsnag.android.Bugsnag.setSessionTrackingApiClient",
	"Comment": "replaces the default http client with a custom implementation. this allows for customrequirements such as certificate pinning to be achieved.the client implementation, and must be capable of sending session tracking payloads tothe bugsnag api.",
	"Method": "void setSessionTrackingApiClient(SessionTrackingApiClient apiClient){\r\n    getClient().setSessionTrackingApiClient(apiClient);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.TestBinaryEllipseDetectorPixel.isApproximatelyElliptical_large",
	"Comment": "test to see if it is approximately elliptical when the number of pixels is larger\tthan the threshold",
	"Method": "void isApproximatelyElliptical_large(){\r\n    EllipseRotated_F64 ellipse = new EllipseRotated_F64(5, 3, 10, 6, 0);\r\n    List<Point2D_F64> negative = TestShapeFittingOps.createRectangle_F64(20, 10, 60 - 4);\r\n    List<Point2D_F64> positive = TestShapeFittingOps.createEllipse_F64(ellipse, 60 - 4);\r\n    BinaryEllipseDetectorPixel alg = new BinaryEllipseDetectorPixel();\r\n    alg.setMaxDistanceFromEllipse(1.5);\r\n    assertFalse(alg.isApproximatelyElliptical(ellipse, negative, 20));\r\n    assertTrue(alg.isApproximatelyElliptical(ellipse, positive, 20));\r\n}"
}, {
	"Path": "boofcv.abst.feature.associate.StandardAssociateDescriptionChecks.checkSetThreshold",
	"Comment": "checks to see if changing the threshold increases or reduces the number of associations",
	"Method": "void checkSetThreshold(){\r\n    init();\r\n    listSrc.add(c(1));\r\n    listDst.add(c(1 + 0.1));\r\n    AssociateDescription<Desc> alg = createAlg();\r\n    alg.setSource(listSrc);\r\n    alg.setDestination(listDst);\r\n    alg.setMaxScoreThreshold(0.01);\r\n    alg.associate();\r\n    assertEquals(0, alg.getMatches().size);\r\n    alg.setMaxScoreThreshold(1.1 - 1);\r\n    alg.associate();\r\n    assertEquals(1, alg.getMatches().size);\r\n    alg.setMaxScoreThreshold(0.2);\r\n    alg.associate();\r\n    assertEquals(1, alg.getMatches().size);\r\n    alg.setMaxScoreThreshold(Double.MAX_VALUE);\r\n    alg.associate();\r\n    assertEquals(1, alg.getMatches().size);\r\n}"
}, {
	"Path": "boofcv.alg.geo.rectify.TestRectifyCalibrated.checkEpipolarGeometry",
	"Comment": "check to see if epipoles are at infinity after rectification",
	"Method": "void checkEpipolarGeometry(){\r\n    DMatrixRMaj K = new DMatrixRMaj(3, 3, true, 300, 0, 200, 0, 400, 205, 0, 0, 1);\r\n    Se3_F64 poseA1 = createPose(-0.3, 0.05, 0.07, 0.1, 0, 0.1).invert(null);\r\n    Se3_F64 poseA2 = createPose(0.2, -0.1, 0.02, 1, 0, 0.1).invert(null);\r\n    Point2D_F64 epi1 = PerspectiveOps.renderPixel(poseA1, K, new Point3D_F64(1, 0, 0.1));\r\n    Point2D_F64 epi2 = PerspectiveOps.renderPixel(poseA2, K, new Point3D_F64(0.1, 0, 0.1));\r\n    RectifyCalibrated alg = new RectifyCalibrated();\r\n    alg.process(K, poseA1, K, poseA2);\r\n    Point3D_F64 epi1a = new Point3D_F64();\r\n    GeometryMath_F64.mult(alg.getRect1(), epi1, epi1a);\r\n    Point3D_F64 epi2a = new Point3D_F64();\r\n    GeometryMath_F64.mult(alg.getRect2(), epi2, epi2a);\r\n    assertEquals(0, epi1a.getZ(), 1e-8);\r\n    assertEquals(0, epi2a.getZ(), 1e-8);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestSystemTests.testPartitionDrain",
	"Comment": "test that requesting connections from a partition that is empty will fetch it from other partitions that still have connections.",
	"Method": "void testPartitionDrain(){\r\n    CommonTestUtils.logTestInfo(\"Test connections obtained from alternate partition\");\r\n    config.setAcquireIncrement(1);\r\n    config.setMinConnectionsPerPartition(10);\r\n    config.setMaxConnectionsPerPartition(10);\r\n    config.setPartitionCount(2);\r\n    BoneCP dsb = new BoneCP(config);\r\n    for (int i = 0; i < 20; i++) {\r\n        dsb.getConnection();\r\n    }\r\n    assertEquals(20, dsb.getTotalLeased());\r\n    assertEquals(0, dsb.getTotalFree());\r\n    dsb.close();\r\n    CommonTestUtils.logPass();\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.TestFitLinesToContour.fitAnchored_perfect_input",
	"Comment": "easy case were the corners are all in perfect location.try all permutations of first anchor and second anchor.",
	"Method": "void fitAnchored_perfect_input(){\r\n    FitLinesToContour alg = new FitLinesToContour();\r\n    alg.setContour(createSquare(10, 12, 30, 40));\r\n    GrowQueue_I32 corners = createSquareCorners(10, 12, 30, 40);\r\n    GrowQueue_I32 found = new GrowQueue_I32();\r\n    for (int anchor0 = 0; anchor0 < 4; anchor0++) {\r\n        for (int j = 0; j < 4; j++) {\r\n            if (j == 1)\r\n                continue;\r\n            int anchor1 = (anchor0 + j) % 4;\r\n            alg.fitAnchored(anchor0, anchor1, corners, found);\r\n            assertEquals(4, found.size());\r\n            for (int i = 0; i < found.size(); i++) {\r\n                assertEquals(corners.get(i), found.get(i));\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.boon.sort.Ordering.min",
	"Comment": "returns the min value after sorting by the sortby parameter.",
	"Method": "T min(List<T> list,T min,T[] array,T min,List<T> list,String sortBy,T min,T[] array,String sortBy){\r\n    if (array.length > 1) {\r\n        Sorting.sort(array, sortBy);\r\n        return array[0];\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.background.BackgroundModel.setUnknownValue",
	"Comment": "specify the value of a segmented pixel which has no corresponding pixel in the background image.",
	"Method": "void setUnknownValue(int unknownValue){\r\n    if (unknownValue < 0 || unknownValue > 255)\r\n        throw new IllegalArgumentException(\"out of range. 0 to 255\");\r\n    this.unknownValue = (byte) unknownValue;\r\n}"
}, {
	"Path": "boofcv.alg.geo.triangulate.ResidualTriangulateChecks.perfect",
	"Comment": "give it perfect parameters and no noise in observations then try introducing some errors",
	"Method": "void perfect(){\r\n    createScene();\r\n    FunctionNtoM alg = createAlg(obsPts, motionWorldToCamera);\r\n    double[] input = new double[] { worldPoint.x, worldPoint.y, worldPoint.z };\r\n    double[] output = new double[alg.getNumOfOutputsM()];\r\n    alg.process(input, output);\r\n    double error = computeCost(output);\r\n    assertEquals(0, error, 1e-8);\r\n    input[0] += 1;\r\n    alg.process(input, output);\r\n    error = computeCost(output);\r\n    assertTrue(error > 0.1);\r\n}"
}, {
	"Path": "com.bugsnag.android.JsonWriter.setSerializeNulls",
	"Comment": "sets whether object members are serialized when their value is null.this has no impact on array elements. the default is true.",
	"Method": "void setSerializeNulls(boolean serializeNulls){\r\n    this.serializeNulls = serializeNulls;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoPlaneInfinity.sortTracksForEstimation",
	"Comment": "splits the set of active tracks into on plane and infinity sets.for each set also perform specific sanity\tchecks to make sure basic constraints are still being meet.if not then the track will not be considered for\tmotion estimation.",
	"Method": "void sortTracksForEstimation(){\r\n    planeSamples.reset();\r\n    farAngles.reset();\r\n    tracksOnPlane.clear();\r\n    tracksFar.clear();\r\n    List<PointTrack> active = tracker.getActiveTracks(null);\r\n    for (PointTrack t : active) {\r\n        VoTrack p = t.getCookie();\r\n        pixelToNorm.compute(t.x, t.y, n);\r\n        pointing.set(n.x, n.y, 1);\r\n        GeometryMath_F64.mult(cameraToPlane.getR(), pointing, pointing);\r\n        pointing.normalize();\r\n        if (p.onPlane) {\r\n            if (pointing.y > 0) {\r\n                PlanePtPixel ppp = planeSamples.grow();\r\n                ppp.normalizedCurr.set(n);\r\n                ppp.planeKey.set(p.ground);\r\n                tracksOnPlane.add(t);\r\n            }\r\n        } else {\r\n            boolean allGood = pointing.y < 0;\r\n            if (strictFar) {\r\n                allGood = isRotationFromAxisY(t, pointing);\r\n            }\r\n            if (allGood) {\r\n                computeAngleOfRotation(t, pointing);\r\n                tracksFar.add(t);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.triangulate.TriangulateProjectiveLinearDLT.normalizeRows",
	"Comment": "normalized rows in a for better numerical stability. solution is scale invariant so this will not change\tthe result, but will ensure all the inputs are of the same order of magnitude.",
	"Method": "void normalizeRows(DMatrixRMaj A){\r\n    int idx = 0;\r\n    for (int row = 0; row < A.numRows; row++) {\r\n        double r0 = A.data[idx];\r\n        double r1 = A.data[idx + 1];\r\n        double r2 = A.data[idx + 2];\r\n        double r3 = A.data[idx + 3];\r\n        double f_norm = Math.sqrt(r0 * r0 + r1 * r1 + r2 * r2 + r3 * r3);\r\n        A.data[idx++] = r0 / f_norm;\r\n        A.data[idx++] = r1 / f_norm;\r\n        A.data[idx++] = r2 / f_norm;\r\n        A.data[idx++] = r3 / f_norm;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.scene.ClassifierKNearestNeighborsBow.setClassificationData",
	"Comment": "provides a set of labeled word histograms to use to classify a new image",
	"Method": "void setClassificationData(List<HistogramScene> memory,int numScenes){\r\n    nn.setPoints(memory, false);\r\n    scenes = new double[numScenes];\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoPlaneInfinity.fuseEstimates",
	"Comment": "fuse the estimates for yaw from both sets of points using a weighted vector average and save the results\tinto currtokey",
	"Method": "void fuseEstimates(){\r\n    double x = closeMotionKeyToCurr.c * closeInlierCount + Math.cos(farAngle) * farInlierCount;\r\n    double y = closeMotionKeyToCurr.s * closeInlierCount + Math.sin(farAngle) * farInlierCount;\r\n    closeMotionKeyToCurr.setYaw(Math.atan2(y, x));\r\n    closeMotionKeyToCurr.invert(currToKey);\r\n}"
}, {
	"Path": "boofcv.gui.feature.VisualizeRegions.watersheds",
	"Comment": "sets the pixels of each watershed as red in the output image.watersheds have a value of 0",
	"Method": "BufferedImage watersheds(GrayS32 segments,BufferedImage output,int radius){\r\n    if (output == null)\r\n        output = new BufferedImage(segments.width, segments.height, BufferedImage.TYPE_INT_RGB);\r\n    if (radius <= 0) {\r\n        for (int y = 0; y < segments.height; y++) {\r\n            for (int x = 0; x < segments.width; x++) {\r\n                int index = segments.unsafe_get(x, y);\r\n                if (index == 0)\r\n                    output.setRGB(x, y, 0xFF0000);\r\n            }\r\n        }\r\n    } else {\r\n        for (int y = 0; y < segments.height; y++) {\r\n            for (int x = 0; x < segments.width; x++) {\r\n                int index = segments.unsafe_get(x, y);\r\n                if (index == 0) {\r\n                    for (int i = -radius; i <= radius; i++) {\r\n                        int yy = y + i;\r\n                        for (int j = -radius; j <= radius; j++) {\r\n                            int xx = x + j;\r\n                            if (segments.isInBounds(xx, yy)) {\r\n                                output.setRGB(xx, yy, 0xFF0000);\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.impl.TestImplPolynomialPixel_F32.compareToBilinear",
	"Comment": "polynomial interpolation of order one is bilinear interpolation",
	"Method": "void compareToBilinear(){\r\n    GrayF32 img = new GrayF32(width, height);\r\n    GrayF32 expected = new GrayF32(width, height);\r\n    GrayF32 found = new GrayF32(width, height);\r\n    GImageMiscOps.fillUniform(img, rand, 0, 255);\r\n    Affine2D_F32 tran = new Affine2D_F32(1, 0, 0, 1, 0.25f, 0.25f);\r\n    ImplPolynomialPixel_F32 alg = new ImplPolynomialPixel_F32(2, 0, 255);\r\n    alg.setBorder(FactoryImageBorder.singleValue(GrayF32.class, 0));\r\n    ImageDistort<GrayF32, GrayF32> distorter = FactoryDistort.distortSB(false, alg, GrayF32.class);\r\n    distorter.setModel(new PixelTransformAffine_F32(tran));\r\n    distorter.apply(img, found);\r\n    InterpolatePixelS<GrayF32> bilinear = FactoryInterpolation.bilinearPixelS(GrayF32.class, null);\r\n    bilinear.setBorder(FactoryImageBorder.singleValue(GrayF32.class, 0));\r\n    distorter = FactoryDistort.distortSB(false, bilinear, GrayF32.class);\r\n    distorter.setModel(new PixelTransformAffine_F32(tran));\r\n    distorter.apply(img, expected);\r\n    BoofTesting.assertEquals(expected, found, 1e-4f);\r\n}"
}, {
	"Path": "boofcv.alg.geo.rectify.TestRectifyCalibrated.compareWithKnown",
	"Comment": "compare results from rectified transform and a set of camera which are already rectified.",
	"Method": "void compareWithKnown(){\r\n    DMatrixRMaj K = new DMatrixRMaj(3, 3, true, 300, 0, 200, 0, 400, 205, 0, 0, 1);\r\n    Se3_F64 poseR1 = createPose(0, 0, 0, 0.1, 0, 0.1).invert(null);\r\n    Se3_F64 poseR2 = createPose(0, 0, 0, 1, 0, 0.1).invert(null);\r\n    Se3_F64 poseA1 = createPose(0, 0.05, 0, 0.1, 0, 0.1).invert(null);\r\n    Se3_F64 poseA2 = createPose(0, -0.1, 0, 1, 0, 0.1).invert(null);\r\n    RectifyCalibrated alg = new RectifyCalibrated();\r\n    alg.process(K, poseA1, K, poseA2);\r\n    DMatrixRMaj foundP1 = PerspectiveOps.createCameraMatrix(poseA1.getR(), poseA1.getT(), K, null);\r\n    DMatrixRMaj foundP2 = PerspectiveOps.createCameraMatrix(poseA2.getR(), poseA2.getT(), K, null);\r\n    DMatrixRMaj temp = new DMatrixRMaj(3, 4);\r\n    CommonOps_DDRM.mult(alg.getRect1(), foundP1, temp);\r\n    foundP1.set(temp);\r\n    CommonOps_DDRM.mult(alg.getRect2(), foundP2, temp);\r\n    foundP2.set(temp);\r\n    CommonOps_DDRM.scale(0.1 / Math.abs(foundP1.get(2, 3)), foundP1);\r\n    Point3D_F64 X = new Point3D_F64(0, 0, 3);\r\n    assertEquals(PerspectiveOps.renderPixel(poseR1, K, X).x, PerspectiveOps.renderPixel(foundP1, X).x, 1e-5);\r\n    assertEquals(PerspectiveOps.renderPixel(poseR1, K, X).y, PerspectiveOps.renderPixel(foundP1, X).y, 1e-5);\r\n    assertEquals(PerspectiveOps.renderPixel(poseR2, K, X).x, PerspectiveOps.renderPixel(foundP2, X).x, 1e-5);\r\n    assertEquals(PerspectiveOps.renderPixel(poseR2, K, X).y, PerspectiveOps.renderPixel(foundP2, X).y, 1e-5);\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.down.TestConvolveDownNoBorderStandard.compareToGeneral",
	"Comment": "automatically compares all the box filters against a generalize convolution",
	"Method": "void compareToGeneral(){\r\n    for (int plus = 0; plus <= kernelRadius + 1; plus++) {\r\n        width = 10 + plus;\r\n        height = 10 + plus;\r\n        for (skip = 1; skip <= 4; skip++) {\r\n            CompareToFull tests = new CompareToFull(ConvolveDownNoBorderStandard.class);\r\n            tests.performTests(15);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.examples.tracking.ExamplePointFeatureTracker.updateGUI",
	"Comment": "draw tracked features in blue, or red if they were just spawned.",
	"Method": "void updateGUI(SimpleImageSequence<T> sequence){\r\n    BufferedImage orig = sequence.getGuiImage();\r\n    Graphics2D g2 = orig.createGraphics();\r\n    for (PointTrack p : tracker.getActiveTracks(null)) {\r\n        int red = (int) (2.5 * (p.featureId % 100));\r\n        int green = (int) ((255.0 / 150.0) * (p.featureId % 150));\r\n        int blue = (int) (p.featureId % 255);\r\n        VisualizeFeatures.drawPoint(g2, (int) p.x, (int) p.y, new Color(red, green, blue));\r\n    }\r\n    for (PointTrack p : tracker.getNewTracks(null)) {\r\n        VisualizeFeatures.drawPoint(g2, (int) p.x, (int) p.y, Color.green);\r\n    }\r\n    gui.setImage(orig);\r\n    gui.repaint();\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCP.watchConnection",
	"Comment": "starts off a new thread to monitor this connection attempt.",
	"Method": "void watchConnection(ConnectionHandle connectionHandle){\r\n    String message = captureStackTrace(UNCLOSED_EXCEPTION_MESSAGE);\r\n    this.closeConnectionExecutor.submit(new CloseThreadMonitor(Thread.currentThread(), connectionHandle, message, this.closeConnectionWatchTimeoutInMs));\r\n}"
}, {
	"Path": "boofcv.alg.tracker.circulant.CirculantTracker.initialize",
	"Comment": "initializes tracking around the specified rectangle region",
	"Method": "void initialize(T image,int x0,int y0,int regionWidth,int regionHeight){\r\n    this.imageWidth = image.width;\r\n    this.imageHeight = image.height;\r\n    setTrackLocation(x0, y0, regionWidth, regionHeight);\r\n    initialLearning(image);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.PoolUtil.fillLogParams",
	"Comment": "returns sql statement used in this prepared statement together with the parameters.",
	"Method": "String fillLogParams(String sql,Map<Object, Object> logParams){\r\n    StringBuilder result = new StringBuilder();\r\n    Map<Object, Object> tmpLogParam = (logParams == null ? new HashMap<Object, Object>() : logParams);\r\n    Iterator<Object> it = tmpLogParam.values().iterator();\r\n    boolean inQuote = false;\r\n    boolean inQuote2 = false;\r\n    char[] sqlChar = sql != null ? sql.toCharArray() : new char[] {};\r\n    for (int i = 0; i < sqlChar.length; i++) {\r\n        if (sqlChar[i] == '\\'') {\r\n            inQuote = !inQuote;\r\n        }\r\n        if (sqlChar[i] == '\"') {\r\n            inQuote2 = !inQuote2;\r\n        }\r\n        if (sqlChar[i] == '?' && !(inQuote || inQuote2)) {\r\n            if (it.hasNext()) {\r\n                result.append(prettyPrint(it.next()));\r\n            } else {\r\n                result.append('?');\r\n            }\r\n        } else {\r\n            result.append(sqlChar[i]);\r\n        }\r\n    }\r\n    return result.toString();\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.TestPruneStructureFromSceneMetric.addCorruptObservations",
	"Comment": "take this many observations and turn into garbage observations",
	"Method": "void addCorruptObservations(int count){\r\n    List<ObsId> list = new ArrayList();\r\n    for (int viewIdx = 0; viewIdx < structure.views.length; viewIdx++) {\r\n        for (int i = 0; i < observations.views[viewIdx].size(); i++) {\r\n            list.add(new ObsId(viewIdx, i));\r\n        }\r\n    }\r\n    for (int i = 0; i < count; i++) {\r\n        int selected = rand.nextInt(list.size() - i);\r\n        ObsId o = list.get(selected);\r\n        list.set(selected, list.get(list.size() - i - 1));\r\n        list.set(list.size() - i - 1, o);\r\n        observations.views[o.view].set(o.point, 1000f, 1000f);\r\n    }\r\n    observations.checkOneObservationPerView();\r\n}"
}, {
	"Path": "boofcv.examples.enhance.ExampleImageEnhancement.histogram",
	"Comment": "histogram adjustment algorithms aim to spread out pixel intensity values uniformly across the allowed range.\tthis if an image is dark, it will have greater contrast and be brighter.",
	"Method": "void histogram(){\r\n    BufferedImage buffered = UtilImageIO.loadImage(UtilIO.pathExample(imagePath));\r\n    GrayU8 gray = ConvertBufferedImage.convertFrom(buffered, (GrayU8) null);\r\n    GrayU8 adjusted = gray.createSameShape();\r\n    int[] histogram = new int[256];\r\n    int[] transform = new int[256];\r\n    ListDisplayPanel panel = new ListDisplayPanel();\r\n    ImageStatistics.histogram(gray, 0, histogram);\r\n    EnhanceImageOps.equalize(histogram, transform);\r\n    EnhanceImageOps.applyTransform(gray, transform, adjusted);\r\n    panel.addImage(ConvertBufferedImage.convertTo(adjusted, null), \"Global\");\r\n    EnhanceImageOps.equalizeLocal(gray, 50, adjusted, histogram, transform);\r\n    panel.addImage(ConvertBufferedImage.convertTo(adjusted, null), \"Local\");\r\n    panel.addImage(ConvertBufferedImage.convertTo(gray, null), \"Original\");\r\n    panel.setPreferredSize(new Dimension(gray.width, gray.height));\r\n    mainPanel.addItem(panel, \"Histogram\");\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.TestPyramidKltTracker.setDescription_outside",
	"Comment": "test set description when a feature is completely outside the image",
	"Method": "void setDescription_outside(){\r\n    PyramidKltFeature feature = new PyramidKltFeature(pyramid.getNumLayers(), featureReadius);\r\n    feature.setPosition(-featureReadius - 1, -featureReadius - 1);\r\n    tracker.setImage(pyramid, derivX, derivY);\r\n    assertFalse(tracker.setDescription(feature));\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.GThresholdImageOps.computeOtsu2",
	"Comment": "computes a modified modified otsu threshold which maximizes the distance from the distributions means. in\textremely sparse histograms with the values clustered at the two means otsu will select a threshold which\tis at the lower peak and in binary data this can cause a total failure.",
	"Method": "int computeOtsu2(ImageGray input,int minValue,int maxValue,int computeOtsu2,int histogram,int length,int totalPixels){\r\n    double dlength = length;\r\n    double sum = 0;\r\n    for (int i = 0; i < length; i++) sum += (i / dlength) * histogram[i];\r\n    double sumB = 0;\r\n    int wB = 0;\r\n    double variance = 0;\r\n    double selectedMB = 0;\r\n    double selectedMF = 0;\r\n    int i;\r\n    for (i = 0; i < length; i++) {\r\n        wB += histogram[i];\r\n        if (wB == 0)\r\n            continue;\r\n        int wF = totalPixels - wB;\r\n        if (wF == 0)\r\n            break;\r\n        double f = i / dlength;\r\n        sumB += f * histogram[i];\r\n        double mB = sumB / wB;\r\n        double mF = (sum - sumB) / wF;\r\n        double varBetween = (double) wB * (double) wF * (mB - mF) * (mB - mF);\r\n        if (varBetween > variance) {\r\n            variance = varBetween;\r\n            selectedMB = mB;\r\n            selectedMF = mF;\r\n        }\r\n    }\r\n    return (int) (length * (selectedMB + selectedMF) / 2.0 + 0.5);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.SnapToEllipseEdge.computePointsAndWeights",
	"Comment": "computes the location of points along the line and their weights",
	"Method": "void computePointsAndWeights(EllipseRotated_F64 ellipse){\r\n    double localScale = ellipse.a;\r\n    samplePts.reset();\r\n    weights.reset();\r\n    int numSamples = radialSamples * 2 + 2;\r\n    int numPts = numSamples - 1;\r\n    Point2D_F64 sample = new Point2D_F64();\r\n    for (int i = 0; i < numSampleContour; i++) {\r\n        double theta = 2.0 * Math.PI * i / numSampleContour;\r\n        UtilEllipse_F64.computePoint(theta, ellipse, sample);\r\n        double tanX = sample.x - ellipse.center.x;\r\n        double tanY = sample.y - ellipse.center.y;\r\n        double r = Math.sqrt(tanX * tanX + tanY * tanY);\r\n        tanX /= r;\r\n        tanY /= r;\r\n        double x = sample.x - numSamples * tanX / 2.0;\r\n        double y = sample.y - numSamples * tanY / 2.0;\r\n        double lengthX = numSamples * tanX;\r\n        double lengthY = numSamples * tanY;\r\n        if (!integral.isInside(x, y) || !integral.isInside(x + lengthX, y + lengthY))\r\n            continue;\r\n        double sample0 = integral.compute(x, y, x + tanX, y + tanY);\r\n        x += tanX;\r\n        y += tanY;\r\n        for (int j = 0; j < numPts; j++) {\r\n            double sample1 = integral.compute(x, y, x + tanX, y + tanY);\r\n            double w = sample0 - sample1;\r\n            if (w < 0)\r\n                w = -w;\r\n            if (w > 0) {\r\n                samplePts.grow().set((x - ellipse.center.x) / localScale, (y - ellipse.center.y) / localScale);\r\n                weights.add(w);\r\n            }\r\n            x += tanX;\r\n            y += tanY;\r\n            sample0 = sample1;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.geo.calibration.CalibrateMonoPlanar.reset",
	"Comment": "resets internal data structures.must call before adding images",
	"Method": "void reset(){\r\n    observations = new ArrayList();\r\n    errors = null;\r\n    imageHeight = imageWidth = 0;\r\n}"
}, {
	"Path": "com.bugsnag.android.Client.setUserId",
	"Comment": "set a unique identifier for the user currently using your application.by default, this will be an automatically generated unique idyou can search for this information in your bugsnag dashboard.",
	"Method": "void setUserId(String id){\r\n    user.setId(id);\r\n    if (config.getPersistUserBetweenSessions()) {\r\n        storeInSharedPrefs(USER_ID_KEY, id);\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.DetectDescribeAssociate.dropTrack",
	"Comment": "remove from active list and mark so that it is dropped in the next cycle",
	"Method": "boolean dropTrack(PointTrack track){\r\n    if (!tracksAll.remove(track))\r\n        return false;\r\n    if (!sets[track.setId].tracks.remove(track)) {\r\n        return false;\r\n    }\r\n    tracksActive.remove(track);\r\n    tracksInactive.remove(track);\r\n    unused.add(track);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.factory.feature.orientation.FactoryOrientationAlgs.image_ii",
	"Comment": "estimates the orientation without calculating the image derivative.",
	"Method": "OrientationIntegral<II> image_ii(double objectRadiusToScale,int sampleRadius,double samplePeriod,int sampleWidth,double weightSigma,Class<II> integralImage){\r\n    return (OrientationIntegral<II>) new ImplOrientationImageAverageIntegral(objectRadiusToScale, sampleRadius, samplePeriod, sampleWidth, weightSigma, integralImage);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.MinimizeEnergyPrune.computeSegmentEnergy",
	"Comment": "computes the energy for a segment defined by the two corner indexes",
	"Method": "void computeSegmentEnergy(GrowQueue_I32 corners,double computeSegmentEnergy,GrowQueue_I32 corners,int cornerA,int cornerB){\r\n    int indexA = corners.get(cornerA);\r\n    int indexB = corners.get(cornerB);\r\n    if (indexA == indexB) {\r\n        return 100000.0;\r\n    }\r\n    Point2D_I32 a = contour.get(indexA);\r\n    Point2D_I32 b = contour.get(indexB);\r\n    line.p.x = a.x;\r\n    line.p.y = a.y;\r\n    line.slope.set(b.x - a.x, b.y - a.y);\r\n    double total = 0;\r\n    int length = circularDistance(indexA, indexB);\r\n    for (int k = 1; k < length; k++) {\r\n        Point2D_I32 c = getContour(indexA + 1 + k);\r\n        point.set(c.x, c.y);\r\n        total += Distance2D_F64.distanceSq(line, point);\r\n    }\r\n    return (total + splitPenalty) / a.distance2(b);\r\n}"
}, {
	"Path": "com.bugsnag.android.Client.setUserEmail",
	"Comment": "set the email address of the current user.you can search for this information in your bugsnag dashboard.",
	"Method": "void setUserEmail(String email){\r\n    user.setEmail(email);\r\n    if (config.getPersistUserBetweenSessions()) {\r\n        storeInSharedPrefs(USER_EMAIL_KEY, email);\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.feature.detdesc.ConfigCompleteSift.createPaper",
	"Comment": "creates a configuration similar to how it was originally described in the paper",
	"Method": "ConfigCompleteSift createPaper(){\r\n    ConfigCompleteSift config = new ConfigCompleteSift();\r\n    config.scaleSpace = ConfigSiftScaleSpace.createPaper();\r\n    config.detector = ConfigSiftDetector.createPaper();\r\n    config.orientation = ConfigSiftOrientation.createPaper();\r\n    return config;\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.TestSelectRectSubpixel_S32_F32.addSubpixelBias",
	"Comment": "given different local error values see if it is closer to the value with a smaller error",
	"Method": "void addSubpixelBias(){\r\n    GrayF32 img = new GrayF32(w, h);\r\n    SelectRectSubpixel.S32_F32 alg = new SelectRectSubpixel.S32_F32(-1, -1, -1);\r\n    alg.configure(img, 0, 20, 2);\r\n    alg.setLocalMax(20);\r\n    alg.columnScore[4] = 100;\r\n    alg.columnScore[5] = 50;\r\n    alg.columnScore[6] = 200;\r\n    alg.setDisparity(4, 5);\r\n    assertTrue(img.data[4] < 5 && img.data[4] > 4);\r\n    alg.columnScore[4] = 200;\r\n    alg.columnScore[6] = 100;\r\n    alg.setDisparity(4, 5);\r\n    assertTrue(img.data[4] < 6 && img.data[4] > 5);\r\n}"
}, {
	"Path": "boofcv.examples.imageprocessing.ExampleConvolution.normalize2D",
	"Comment": "convolves a 2d normalized kernel.this kernel is divided by its sum after computation.",
	"Method": "void normalize2D(GrayU8 gray){\r\n    Kernel2D_S32 kernel = FactoryKernelGaussian.gaussian2D(GrayU8.class, -1, 3);\r\n    GrayU8 output = new GrayU8(gray.width, gray.height);\r\n    GConvolveImageOps.convolveNormalized(kernel, gray, output);\r\n    panel.addImage(VisualizeImageData.standard(output, null), \"2D Normalized Kernel\");\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.TestDescribePlanar.checkNumBands",
	"Comment": "sanity check to see if input image and number of descriptors is the same",
	"Method": "void checkNumBands(){\r\n    DescribeRegionPoint[] descs = new DummyDesc[3];\r\n    descs[0] = new DummyDesc();\r\n    descs[1] = new DummyDesc();\r\n    descs[2] = new DummyDesc();\r\n    DummyAlg alg = new DummyAlg(descs);\r\n    assertThrows(IllegalArgumentException.class, () -> alg.setImage(new Planar(GrayS8.class, 1, 1, 2)));\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.ConvolveImageNoBorderSparse.convolve",
	"Comment": "convolves a 1d kernels around the specified pixel in the horizontal and vertical direction.\tthe convolution sum is divided by the specified divisors in the horizontal and vertical direction.",
	"Method": "float convolve(Kernel1D_F32 horizontal,Kernel1D_F32 vertical,GrayF32 input,int c_x,int c_y,float storage,float convolve,Kernel1D_S32 horizontal,Kernel1D_S32 vertical,GrayU8 input,int c_x,int c_y,int storage,float convolve,Kernel1D_S32 horizontal,Kernel1D_S32 vertical,GrayS16 input,int c_x,int c_y,int storage,float convolve,Kernel1D_S32 horizontal,Kernel1D_S32 vertical,GrayU8 input,int c_x,int c_y,int storage,int divisorHorizontal,int divisorVertical,float convolve,Kernel1D_S32 horizontal,Kernel1D_S32 vertical,GrayS16 input,int c_x,int c_y,int storage,int divisorHorizontal,int divisorVertical){\r\n    return ConvolveImageStandardSparse.convolve(horizontal, vertical, input, c_x, c_y, storage, divisorHorizontal, divisorVertical);\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.AssociateUniqueByScoreAlg.process",
	"Comment": "given a set of matches, enforce the uniqueness rules it was configured to.",
	"Method": "void process(FastQueue<AssociatedIndex> matches,int numSource,int numDestination){\r\n    if (checkSource) {\r\n        if (checkDestination) {\r\n            processSource(matches, numSource, firstPass);\r\n            processDestination(firstPass, numDestination, pruned);\r\n        } else {\r\n            processSource(matches, numSource, pruned);\r\n        }\r\n    } else if (checkDestination) {\r\n        processDestination(matches, numDestination, pruned);\r\n    } else {\r\n        pruned = matches;\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestStatistics.testStatsReset",
	"Comment": "tests that values are reset properly when instructed to do so.",
	"Method": "void testStatsReset(){\r\n    this.stats.resetStats();\r\n    checkValuesSetToZero(this.stats);\r\n}"
}, {
	"Path": "boofcv.examples.features.ExampleFitPolygon.fitCannyBinary",
	"Comment": "detects contours inside the binary image generated by canny.only the external contour is relevant. often\teasier to deal with than working with canny edges directly.",
	"Method": "void fitCannyBinary(GrayF32 input){\r\n    BufferedImage displayImage = new BufferedImage(input.width, input.height, BufferedImage.TYPE_INT_RGB);\r\n    GrayU8 binary = new GrayU8(input.width, input.height);\r\n    CannyEdge<GrayF32, GrayF32> canny = FactoryEdgeDetectors.canny(2, false, true, GrayF32.class, GrayF32.class);\r\n    canny.process(input, 0.1f, 0.3f, binary);\r\n    List<Contour> contours = BinaryImageOps.contourExternal(binary, ConnectRule.EIGHT);\r\n    Graphics2D g2 = displayImage.createGraphics();\r\n    g2.setStroke(new BasicStroke(2));\r\n    Random rand = new Random(234);\r\n    for (Contour c : contours) {\r\n        List<PointIndex_I32> vertexes = ShapeFittingOps.fitPolygon(c.external, true, minSide, cornerPenalty);\r\n        g2.setColor(new Color(rand.nextInt()));\r\n        VisualizeShapes.drawPolygon(vertexes, true, g2);\r\n    }\r\n    gui.addImage(displayImage, \"Canny Contour\");\r\n}"
}, {
	"Path": "boofcv.alg.sfm.TestStereoProcessingBase.centroid",
	"Comment": "finds the mean point in the image weighted by pixel intensity",
	"Method": "Point2D_F64 centroid(GrayU8 image){\r\n    double meanX = 0;\r\n    double meanY = 0;\r\n    double totalPixel = ImageStatistics.sum(image);\r\n    for (int i = 0; i < image.height; i++) {\r\n        for (int j = 0; j < image.width; j++) {\r\n            meanX += image.get(j, i) * j;\r\n            meanY += image.get(j, i) * i;\r\n        }\r\n    }\r\n    meanX /= totalPixel;\r\n    meanY /= totalPixel;\r\n    return new Point2D_F64(meanX, meanY);\r\n}"
}, {
	"Path": "com.bugsnag.android.example.ExampleActivity.crashWithCallback",
	"Comment": "when sending a handled error, a callback can be registered, which allows the error reportto be modified before it is sent.",
	"Method": "void crashWithCallback(View view){\r\n    RuntimeException exception = new RuntimeException(\"Customized Error Report\");\r\n    Bugsnag.notify(exception, new Callback() {\r\n        @Override\r\n        public void beforeNotify(Report report) {\r\n            report.getError().setMetaData(generateUserMetaData());\r\n        }\r\n    });\r\n    displayToastNotification();\r\n}"
}, {
	"Path": "com.bugsnag.android.example.ExampleActivity.crashWithCallback",
	"Comment": "when sending a handled error, a callback can be registered, which allows the error reportto be modified before it is sent.",
	"Method": "void crashWithCallback(View view){\r\n    report.getError().setMetaData(generateUserMetaData());\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.PairwiseImageMatching.addImage",
	"Comment": "adds a new observation from a camera. detects features inside the and saves those.",
	"Method": "void addImage(T image,String cameraName){\r\n    PairwiseImageGraph.View view = new PairwiseImageGraph.View(graph.nodes.size(), new FastQueue<TupleDesc>(TupleDesc.class, true) {\r\n        @Override\r\n        protected TupleDesc createInstance() {\r\n            return detDesc.createDescription();\r\n        }\r\n    });\r\n    view.camera = graph.cameras.get(cameraName);\r\n    if (view.camera == null)\r\n        throw new IllegalArgumentException(\"Must have added the camera first\");\r\n    view.index = graph.nodes.size();\r\n    graph.nodes.add(view);\r\n    detDesc.detect(image);\r\n    view.descriptions.growArray(detDesc.getNumberOfFeatures());\r\n    view.observationPixels.growArray(detDesc.getNumberOfFeatures());\r\n    for (int i = 0; i < detDesc.getNumberOfFeatures(); i++) {\r\n        Point2D_F64 p = detDesc.getLocation(i);\r\n        view.descriptions.grow().setTo(detDesc.getDescription(i));\r\n        view.observationPixels.grow().set(p);\r\n    }\r\n    if (view.camera.pixelToNorm == null) {\r\n        return;\r\n    }\r\n    view.observationNorm.growArray(detDesc.getNumberOfFeatures());\r\n    for (int i = 0; i < view.observationPixels.size; i++) {\r\n        Point2D_F64 p = view.observationPixels.get(i);\r\n        view.camera.pixelToNorm.compute(p.x, p.y, view.observationNorm.grow());\r\n    }\r\n    if (verbose != null) {\r\n        verbose.println(\"Detected Features: \" + detDesc.getNumberOfFeatures());\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.PairwiseImageMatching.addImage",
	"Comment": "adds a new observation from a camera. detects features inside the and saves those.",
	"Method": "void addImage(T image,String cameraName){\r\n    return detDesc.createDescription();\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.DetectFiducialSquareImage.hamming",
	"Comment": "computes the hamming score between two descriptions.larger the number better the fit",
	"Method": "int hamming(short[] a,short[] b){\r\n    int distance = 0;\r\n    for (int i = 0; i < a.length; i++) {\r\n        distance += DescriptorDistance.hamming((a[i] & 0xFFFF) ^ (b[i] & 0xFFFF));\r\n    }\r\n    return distance;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.EasyGeneralFeatureDetector.detect",
	"Comment": "detect features inside the image.excluding points in the exclude list.",
	"Method": "void detect(T input,QueueCorner exclude){\r\n    initializeDerivatives(input);\r\n    if (detector.getRequiresGradient() || detector.getRequiresHessian())\r\n        gradient.process(input, derivX, derivY);\r\n    if (detector.getRequiresHessian())\r\n        hessian.process(derivX, derivY, derivXX, derivYY, derivXY);\r\n    detector.setExcludeMaximum(exclude);\r\n    detector.process(input, derivX, derivY, derivXX, derivYY, derivXY);\r\n}"
}, {
	"Path": "boofcv.gui.SelectAlgorithmAndInputPanel.setBaseDirectory",
	"Comment": "sets the directory that relative references are relative too",
	"Method": "void setBaseDirectory(String baseDirectory){\r\n    this.baseDirectory = baseDirectory;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.windows.PokemonTable.restoreColumnOrder",
	"Comment": "loads the column order settings from configuration and applies them to the table.",
	"Method": "void restoreColumnOrder(){\r\n    final List<String> myColumnEnumNames = new LinkedList<String>();\r\n    final String columnOrder = config.getString(ConfigKey.POKEMONTABLE_COLUMNORDER);\r\n    if (columnOrder != null && !columnOrder.isEmpty()) {\r\n        myColumnEnumNames.addAll(Arrays.asList(columnOrder.split(COLUMN_SEPARATOR)));\r\n    } else {\r\n        myColumnEnumNames.addAll(Stream.of(PokeColumn.values()).map(Enum::toString).collect(Collectors.toList()));\r\n    }\r\n    int newIndex = 0;\r\n    for (final String enumName : myColumnEnumNames) {\r\n        try {\r\n            final PokeColumn pokeColumn = PokeColumn.valueOf(enumName);\r\n            final TableColumn c = this.getColumn(pokeColumn.heading);\r\n            if (c != null) {\r\n                final int currentIndex = this.convertColumnIndexToView(c.getModelIndex());\r\n                if (currentIndex != newIndex) {\r\n                    this.getColumnModel().moveColumn(currentIndex, newIndex);\r\n                }\r\n                newIndex++;\r\n            }\r\n        } catch (IllegalArgumentException exc) {\r\n            columnErrors.add(enumName);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeEncoder.addAutomatic",
	"Comment": "select the encoding based on the letters in the message. a very simple algorithm is used internally.",
	"Method": "QrCodeEncoder addAutomatic(String message){\r\n    if (containsKanji(message)) {\r\n        int start = 0;\r\n        boolean kanji = isKanji(message.charAt(0));\r\n        for (int i = 0; i < message.length(); i++) {\r\n            if (isKanji(message.charAt(i))) {\r\n                if (!kanji) {\r\n                    addAutomatic(message.substring(start, i));\r\n                    start = i;\r\n                    kanji = true;\r\n                }\r\n            } else {\r\n                if (kanji) {\r\n                    addKanji(message.substring(start, i));\r\n                    start = i;\r\n                    kanji = false;\r\n                }\r\n            }\r\n        }\r\n        if (kanji) {\r\n            addKanji(message.substring(start, message.length()));\r\n        } else {\r\n            addAutomatic(message.substring(start, message.length()));\r\n        }\r\n        return this;\r\n    } else if (containsByte(message)) {\r\n        return addBytes(message);\r\n    } else if (containsAlphaNumeric(message)) {\r\n        return addAlphanumeric(message);\r\n    } else {\r\n        return addNumeric(message);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.derivative.GeneralSparseGradientTests.testCenterImage",
	"Comment": "test to see if it produces identical results for pixels inside the image",
	"Method": "void testCenterImage(){\r\n    imageGradient(input, derivX, derivY);\r\n    alg.setImage(input);\r\n    for (int y = -sampleBoxY0; y < height - sampleBoxY1 - 1; y++) {\r\n        for (int x = -sampleBoxX0; x < width - sampleBoxX1 - 1; x++) {\r\n            G g = alg.compute(x, y);\r\n            double expectedX = GeneralizedImageOps.get(derivX, x, y);\r\n            double expectedY = GeneralizedImageOps.get(derivY, x, y);\r\n            assertEquals(expectedX, g.getX(), 1e-4);\r\n            assertEquals(expectedY, g.getY(), 1e-4);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareGraph.detachEdge",
	"Comment": "removes the edge from the two nodes and recycles the data structure",
	"Method": "void detachEdge(SquareEdge edge){\r\n    edge.a.edges[edge.sideA] = null;\r\n    edge.b.edges[edge.sideB] = null;\r\n    edge.distance = 0;\r\n    edgeManager.recycleInstance(edge);\r\n}"
}, {
	"Path": "boofcv.alg.geo.TestRectifyImageOps.fullViewLeft_calibrated",
	"Comment": "after the camera matrix has been adjusted and a forward rectification transform has been applied\tthe output image will be shrink and contained inside the output image.",
	"Method": "void fullViewLeft_calibrated(){\r\n    CameraPinholeRadial param = new CameraPinholeRadial().fsetK(300, 320, 0, 150, 130, width, height).fsetRadial(0.1, 1e-4);\r\n    FMatrixRMaj rect1 = CommonOps_FDRM.identity(3);\r\n    FMatrixRMaj rect2 = CommonOps_FDRM.identity(3);\r\n    FMatrixRMaj rectK = PerspectiveOps.pinholeToMatrix(param, (FMatrixRMaj) null);\r\n    RectifyImageOps.fullViewLeft(param, rect1, rect2, rectK);\r\n    Point2Transform2_F32 tran = RectifyImageOps.transformPixelToRect(param, rect1);\r\n    checkInside(tran);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.FitLinesToContour.sanityCheckCornerOrder",
	"Comment": "all the corners should be in increasing order from the first anchor.",
	"Method": "boolean sanityCheckCornerOrder(int numLines,GrowQueue_I32 corners){\r\n    int contourAnchor0 = corners.get(anchor0);\r\n    int previous = 0;\r\n    for (int i = 1; i < numLines; i++) {\r\n        int contourIndex = corners.get(CircularIndex.addOffset(anchor0, i, corners.size()));\r\n        int pixelsFromAnchor0 = CircularIndex.distanceP(contourAnchor0, contourIndex, contour.size());\r\n        if (pixelsFromAnchor0 < previous) {\r\n            return false;\r\n        } else {\r\n            previous = pixelsFromAnchor0;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.TestSiftDetector.process",
	"Comment": "tests the ability to detect a single square feature at multiple scales and color",
	"Method": "void process(){\r\n    int c_x = 40, c_y = 42;\r\n    SiftDetector alg = createDetector();\r\n    for (int radius : new int[] { 2, 5 }) {\r\n        int width = radius * 2 + 1;\r\n        for (boolean white : new boolean[] { true, false }) {\r\n            GrayF32 input = new GrayF32(80, 70);\r\n            if (white) {\r\n                GImageMiscOps.fillRectangle(input, 200, c_x - radius, c_y - radius, width, width);\r\n            } else {\r\n                GImageMiscOps.fill(input, 200);\r\n                GImageMiscOps.fillRectangle(input, 0, c_x - radius, c_y - radius, width, width);\r\n            }\r\n            alg.process(input);\r\n            FastQueue<ScalePoint> detections = alg.getDetections();\r\n            assertTrue(detections.size > 0);\r\n            boolean found = false;\r\n            for (int i = 0; i < detections.size(); i++) {\r\n                ScalePoint p = detections.get(i);\r\n                if (p.distance(c_x, c_y) <= 0.2) {\r\n                    assertEquals(radius * 1.25, p.scale, 0.5);\r\n                    assertTrue(white == p.white);\r\n                    found = true;\r\n                }\r\n            }\r\n            assertTrue(found);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.TestEdgeIntensityEllipse.scoreInsideAndOutside",
	"Comment": "makes sure the score stays about the same when it is inside and partially outside",
	"Method": "void scoreInsideAndOutside(){\r\n    EllipseRotated_F64 ellipse = new EllipseRotated_F64(50, 60, 10, 5, 0.1);\r\n    List<EllipseRotated_F64> list = new ArrayList();\r\n    list.add(ellipse);\r\n    GrayU8 image = TestBinaryEllipseDetectorPixel.renderEllipses_F64(200, 210, list, 0);\r\n    EdgeIntensityEllipse<GrayU8> alg = new EdgeIntensityEllipse(1.5, 20, 10.0, GrayU8.class);\r\n    alg.setImage(image);\r\n    assertTrue(alg.process(ellipse));\r\n    double score0 = alg.getEdgeIntensity();\r\n    ellipse.center.x = 5;\r\n    image = TestBinaryEllipseDetectorPixel.renderEllipses_F64(200, 210, list, 0);\r\n    alg.setImage(image);\r\n    assertTrue(alg.process(ellipse));\r\n    double score1 = alg.getEdgeIntensity();\r\n    assertEquals(score0, score1, 10);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareGridTools.orderNode",
	"Comment": "fills the ordered list with the corners in target node in canonical order.",
	"Method": "void orderNode(SquareNode target,SquareNode node,boolean pointingX){\r\n    int index0 = findIntersection(target, node);\r\n    int index1 = (index0 + 1) % 4;\r\n    int index2 = (index0 + 2) % 4;\r\n    int index3 = (index0 + 3) % 4;\r\n    if (index0 < 0)\r\n        throw new RuntimeException(\"Couldn't find intersection.  Probable bug\");\r\n    lineCenters.a = target.center;\r\n    lineCenters.b = node.center;\r\n    UtilLine2D_F64.convert(lineCenters, general);\r\n    Polygon2D_F64 poly = target.square;\r\n    if (pointingX) {\r\n        if (sign(general, poly.get(index0)) > 0) {\r\n            ordered[1] = poly.get(index1);\r\n            ordered[2] = poly.get(index0);\r\n        } else {\r\n            ordered[1] = poly.get(index0);\r\n            ordered[2] = poly.get(index1);\r\n        }\r\n        if (sign(general, poly.get(index2)) > 0) {\r\n            ordered[3] = poly.get(index2);\r\n            ordered[0] = poly.get(index3);\r\n        } else {\r\n            ordered[3] = poly.get(index3);\r\n            ordered[0] = poly.get(index2);\r\n        }\r\n    } else {\r\n        if (sign(general, poly.get(index0)) > 0) {\r\n            ordered[2] = poly.get(index1);\r\n            ordered[3] = poly.get(index0);\r\n        } else {\r\n            ordered[2] = poly.get(index0);\r\n            ordered[3] = poly.get(index1);\r\n        }\r\n        if (sign(general, poly.get(index2)) > 0) {\r\n            ordered[0] = poly.get(index2);\r\n            ordered[1] = poly.get(index3);\r\n        } else {\r\n            ordered[0] = poly.get(index3);\r\n            ordered[1] = poly.get(index2);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.kernel.impl.TestSteerableKernel_I32.checkCombining",
	"Comment": "checks to see if the basis kernels are correctly combined together.",
	"Method": "void checkCombining(){\r\n    double[] c = new double[] { 0.1, 0.2, 0.8 };\r\n    DummySteerableCoefficients coef = new DummySteerableCoefficients(c);\r\n    Kernel2D[] basis = new Kernel2D[3];\r\n    basis[0] = FactoryKernel.random2D_I32(width, width / 2, 0, 30, rand);\r\n    basis[1] = FactoryKernel.random2D_I32(width, width / 2, 0, 30, rand);\r\n    basis[2] = FactoryKernel.random2D_I32(width, width / 2, 0, 30, rand);\r\n    Kernel2D_S32 expected = new Kernel2D_S32(width);\r\n    for (int y = 0; y < width; y++) {\r\n        for (int x = 0; x < width; x++) {\r\n            int total = 0;\r\n            for (int i = 0; i < c.length; i++) {\r\n                total += c[i] * ((Kernel2D_S32) basis[i]).get(x, y);\r\n            }\r\n            expected.set(x, y, total);\r\n        }\r\n    }\r\n    SteerableKernel_I32 alg = new SteerableKernel_I32();\r\n    alg.setBasis(coef, basis);\r\n    Kernel2D_S32 found = alg.compute(60.0);\r\n    assertTrue(KernelMath.isEquals(expected.data, found.data, width * width));\r\n}"
}, {
	"Path": "boofcv.alg.flow.HornSchunckPyramid.warpImageTaylor",
	"Comment": "takes the flow from the previous lower resolution layer and uses it to initialize the flow\tin the current layer.adjusts for change in image scale.",
	"Method": "void warpImageTaylor(GrayF32 before,GrayF32 flowX,GrayF32 flowY,GrayF32 after){\r\n    interp.setImage(before);\r\n    for (int y = 0; y < before.height; y++) {\r\n        int pixelIndex = y * before.width;\r\n        for (int x = 0; x < before.width; x++, pixelIndex++) {\r\n            float u = flowX.data[pixelIndex];\r\n            float v = flowY.data[pixelIndex];\r\n            float wx = x + u;\r\n            float wy = y + v;\r\n            if (wx < 0 || wx > before.width - 1 || wy < 0 || wy > before.height - 1) {\r\n                after.data[pixelIndex] = 0;\r\n            } else {\r\n                after.data[pixelIndex] = interp.get(wx, wy);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.getFilters",
	"Comment": "get which keys should be filtered when sending metadata to bugsnag",
	"Method": "String[] getFilters(){\r\n    return metaData.getFilters();\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.KeyPointsCircleHexagonalGrid.computeEllipseCenters",
	"Comment": "finds the intersection of all the tangent lines with each other the computes the average of those points.\tthat location is where the center is set to.each intersection of lines is weighted by the acute angle.\tlines which are 90 degrees to each other are less sensitive to noise",
	"Method": "boolean computeEllipseCenters(){\r\n    keypoints.reset();\r\n    for (int tangentIdx = 0; tangentIdx < tangents.size(); tangentIdx++) {\r\n        Tangents t = tangents.get(tangentIdx);\r\n        Point2D_F64 center = keypoints.grow();\r\n        center.set(0, 0);\r\n        double totalWeight = 0;\r\n        for (int i = 0; i < t.size(); i += 2) {\r\n            UtilLine2D_F64.convert(t.get(i), t.get(i + 1), lineA);\r\n            for (int j = i + 2; j < t.size(); j += 2) {\r\n                UtilLine2D_F64.convert(t.get(j), t.get(j + 1), lineB);\r\n                double w = UtilVector2D_F64.acute(lineA.A, lineA.B, lineB.A, lineB.B);\r\n                if (w > Math.PI / 2.0)\r\n                    w = Math.PI - w;\r\n                if (w <= 0.02)\r\n                    continue;\r\n                if (null == Intersection2D_F64.intersection(lineA, lineB, location)) {\r\n                    return false;\r\n                }\r\n                center.x += location.x * w;\r\n                center.y += location.y * w;\r\n                totalWeight += w;\r\n            }\r\n        }\r\n        if (totalWeight == 0)\r\n            return false;\r\n        center.x /= totalWeight;\r\n        center.y /= totalWeight;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.distort.NarrowToWidePtoP_F32.setRotationWideToNarrow",
	"Comment": "specifies rotation matrix which determines the pointing direction of the camera",
	"Method": "void setRotationWideToNarrow(FMatrixRMaj R){\r\n    this.rotateWideToNarrow.set(R);\r\n}"
}, {
	"Path": "boofcv.io.image.UtilImageIO.loadImage",
	"Comment": "loads the image and converts into the specified image type.",
	"Method": "BufferedImage loadImage(String fileName,BufferedImage loadImage,String directory,String fileName,BufferedImage loadImage,URL url,T loadImage,String fileName,Class<T> imageType,T loadImage,String directory,String fileName,Class<T> imageType,T loadImage,File image,boolean orderRgb,ImageType<T> imageType){\r\n    BufferedImage img = loadImage(image.getAbsolutePath());\r\n    if (img == null)\r\n        return null;\r\n    T output = imageType.createImage(img.getWidth(), img.getHeight());\r\n    ConvertBufferedImage.convertFrom(img, orderRgb, output);\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.struct.pyramid.ImagePyramidBase.checkScales",
	"Comment": "used to internally check that the provided scales are valid.",
	"Method": "void checkScales(){\r\n    if (getScale(0) < 0) {\r\n        throw new IllegalArgumentException(\"The first layer must be more than zero.\");\r\n    }\r\n    double prevScale = 0;\r\n    for (int i = 0; i < getNumLayers(); i++) {\r\n        double s = getScale(i);\r\n        if (s < prevScale)\r\n            throw new IllegalArgumentException(\"Higher layers must be the same size or larger than previous layers.\");\r\n        prevScale = s;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.BaseTestDescribePointBinaryCompare.testIntensityInvariance",
	"Comment": "vary the intensity of the input image and see if the description changes.",
	"Method": "void testIntensityInvariance(){\r\n    T input = createImage(width, height);\r\n    T mod = (T) input.clone();\r\n    GPixelMath.multiply(input, 2, mod);\r\n    DescribePointBinaryCompare<T> alg = createAlg(def);\r\n    TupleDesc_B desc1 = createFeature();\r\n    TupleDesc_B desc2 = createFeature();\r\n    alg.setImage(input);\r\n    alg.process(input.width / 2, input.height / 2, desc1);\r\n    alg.setImage(mod);\r\n    alg.process(input.width / 2, input.height / 2, desc2);\r\n    int count = 0;\r\n    for (int i = 0; i < desc1.numBits; i++) {\r\n        count += desc1.isBitTrue(i) == desc2.isBitTrue(i) ? 1 : 0;\r\n    }\r\n    assertTrue(count > desc1.numBits - 3);\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.GenericOrientationImageTests.setRadius",
	"Comment": "estimate the direction at a couple of different scales and see if it produces the expected results.",
	"Method": "void setRadius(){\r\n    int x = width / 2;\r\n    int y = height / 2;\r\n    int N = 2 * (int) (Math.PI / angleTolerance);\r\n    double angle = UtilAngle.bound((N / 2) * angleTolerance);\r\n    createOrientedImage(angle);\r\n    alg.setImage(image);\r\n    alg.setObjectRadius(5);\r\n    double found = UtilAngle.bound(alg.compute(x, y));\r\n    assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n    alg.setObjectRadius(10);\r\n    found = UtilAngle.bound(alg.compute(x, y));\r\n    assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n    alg.setObjectRadius(2.5);\r\n    found = UtilAngle.bound(alg.compute(x, y));\r\n    assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n}"
}, {
	"Path": "boofcv.gui.DemonstrationBase.openNextFile",
	"Comment": "opens the next file in the directory by lexicographical order.",
	"Method": "void openNextFile(){\r\n    if (inputFilePath == null || inputMethod != InputMethod.IMAGE)\r\n        return;\r\n    File current = new File(UtilIO.ensureURL(inputFilePath).getFile());\r\n    File parent = current.getParentFile();\r\n    if (parent == null)\r\n        return;\r\n    File[] files = parent.listFiles();\r\n    if (files == null || files.length <= 1)\r\n        return;\r\n    File closest = null;\r\n    for (int i = 0; i < files.length; i++) {\r\n        File f = files[i];\r\n        String name = f.getName().toLowerCase();\r\n        if (name.endsWith(\".txt\") || name.endsWith(\".yaml\") || name.endsWith(\".xml\"))\r\n            continue;\r\n        if (current.compareTo(f) < 0) {\r\n            if (closest == null || closest.compareTo(f) > 0) {\r\n                closest = f;\r\n            }\r\n        }\r\n    }\r\n    if (closest != null) {\r\n        openFile(closest);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.setSplitVariables",
	"Comment": "selects and splits the side defined by the e0 corner. if convex a check is performed to\tensure that the polyline will be convex still.",
	"Method": "void setSplitVariables(List<Point2D_I32> contour,Element<Corner> e0,Element<Corner> e1){\r\n    int distance0 = CircularIndex.distanceP(e0.object.index, e1.object.index, contour.size());\r\n    int index0 = CircularIndex.plusPOffset(e0.object.index, minimumSideLength, contour.size());\r\n    int index1 = CircularIndex.minusPOffset(e1.object.index, minimumSideLength, contour.size());\r\n    splitter.selectSplitPoint(contour, index0, index1, resultsA);\r\n    if (convex) {\r\n        Point2D_I32 a = contour.get(e0.object.index);\r\n        Point2D_I32 b = contour.get(resultsA.index);\r\n        Point2D_I32 c = contour.get(next(e0).object.index);\r\n        if (UtilPolygons2D_I32.isPositiveZ(a, b, c)) {\r\n            e0.object.splitable = false;\r\n            return;\r\n        }\r\n    }\r\n    int dist0 = CircularIndex.distanceP(e0.object.index, resultsA.index, contour.size());\r\n    if (dist0 < minimumSideLength || (contour.size() - dist0) < minimumSideLength) {\r\n        throw new RuntimeException(\"Should be impossible\");\r\n    }\r\n    e0.object.splitLocation = resultsA.index;\r\n    e0.object.splitError0 = computeSideError(contour, e0.object.index, resultsA.index);\r\n    e0.object.splitError1 = computeSideError(contour, resultsA.index, e1.object.index);\r\n    if (e0.object.splitLocation >= contour.size())\r\n        throw new RuntimeException(\"Egads\");\r\n}"
}, {
	"Path": "boofcv.alg.geo.TestPositiveDepthConstraintCheck.testPositive",
	"Comment": "point a point in front of both cameras and see if it returns true",
	"Method": "void testPositive(){\r\n    DMatrixRMaj R = ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, -0.05, 0, null);\r\n    Vector3D_F64 T = new Vector3D_F64(1, 0, 0);\r\n    Se3_F64 fromAtoB = new Se3_F64(R, T);\r\n    Point3D_F64 pt = new Point3D_F64(0, 0, 2);\r\n    Point2D_F64 obsA = new Point2D_F64(0, 0);\r\n    Point3D_F64 pt_inB = SePointOps_F64.transform(fromAtoB, pt, null);\r\n    Point2D_F64 obsB = new Point2D_F64(pt_inB.x / pt_inB.z, pt_inB.y / pt_inB.z);\r\n    PositiveDepthConstraintCheck alg = new PositiveDepthConstraintCheck();\r\n    assertTrue(alg.checkConstraint(obsA, obsB, fromAtoB));\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomDualTrackPnP.estimateMotion",
	"Comment": "given the set of active tracks, estimate the cameras motion robustly",
	"Method": "boolean estimateMotion(){\r\n    List<Stereo2D3D> data = new ArrayList();\r\n    for (PointTrack l : candidates) {\r\n        LeftTrackInfo info = l.getCookie();\r\n        PointTrack r = info.right;\r\n        Stereo2D3D stereo = info.location;\r\n        leftImageToNorm.compute(l.x, l.y, info.location.leftObs);\r\n        rightImageToNorm.compute(r.x, r.y, info.location.rightObs);\r\n        data.add(stereo);\r\n    }\r\n    if (!matcher.process(data))\r\n        return false;\r\n    Se3_F64 keyToCurr = matcher.getModelParameters();\r\n    keyToCurr.invert(currToKey);\r\n    int N = matcher.getMatchSet().size();\r\n    for (int i = 0; i < N; i++) {\r\n        int index = matcher.getInputIndex(i);\r\n        LeftTrackInfo info = candidates.get(index).getCookie();\r\n        info.lastInlier = tick;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCP.getTotalLeased",
	"Comment": "return total number of connections currently in use by an application",
	"Method": "int getTotalLeased(){\r\n    int total = 0;\r\n    for (int i = 0; i < this.partitionCount && this.partitions[i] != null; i++) {\r\n        total += this.partitions[i].getCreatedConnections() - this.partitions[i].getAvailableConnections();\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.TestDescribeDenseSiftAlg.computeDescriptor",
	"Comment": "compute to the general descriptor algorithm.they should produce the same results",
	"Method": "void computeDescriptor(){\r\n    GrayF32 derivX = new GrayF32(100, 102);\r\n    GrayF32 derivY = new GrayF32(100, 102);\r\n    GImageMiscOps.fillUniform(derivX, rand, 0, 200);\r\n    GImageMiscOps.fillUniform(derivY, rand, 0, 200);\r\n    DescribeDenseSiftAlg<GrayF32> alg = new DescribeDenseSiftAlg(4, 4, 8, 0.5, 0.2, 10, 10, GrayF32.class);\r\n    DescribePointSift<GrayF32> algTest = new DescribePointSift(4, 4, 8, 1, 0.5, 0.2, GrayF32.class);\r\n    alg.setImageGradient(derivX, derivY);\r\n    algTest.setImageGradient(derivX, derivY);\r\n    List<Point2D_I32> samplePoints = new ArrayList();\r\n    samplePoints.add(new Point2D_I32(30, 35));\r\n    samplePoints.add(new Point2D_I32(45, 10));\r\n    samplePoints.add(new Point2D_I32(60, 12));\r\n    samplePoints.add(new Point2D_I32(50, 50));\r\n    TupleDesc_F64 found = new TupleDesc_F64(128);\r\n    TupleDesc_F64 expected = new TupleDesc_F64(128);\r\n    for (Point2D_I32 p : samplePoints) {\r\n        alg.computeDescriptor(p.x, p.y, found);\r\n        algTest.process(p.x, p.y, 1, 0, expected);\r\n        for (int i = 0; i < 128; i++) {\r\n            assertEquals(expected.value[i], found.value[i], 1e-8);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.EssentialNister5.solveForXandY",
	"Comment": "once z is known then x and y can be solved for using the b matrix",
	"Method": "void solveForXandY(double z){\r\n    this.z = z;\r\n    tmpA.data[0] = ((helper.K00 * z + helper.K01) * z + helper.K02) * z + helper.K03;\r\n    tmpA.data[1] = ((helper.K04 * z + helper.K05) * z + helper.K06) * z + helper.K07;\r\n    tmpY.data[0] = (((helper.K08 * z + helper.K09) * z + helper.K10) * z + helper.K11) * z + helper.K12;\r\n    tmpA.data[2] = ((helper.L00 * z + helper.L01) * z + helper.L02) * z + helper.L03;\r\n    tmpA.data[3] = ((helper.L04 * z + helper.L05) * z + helper.L06) * z + helper.L07;\r\n    tmpY.data[1] = (((helper.L08 * z + helper.L09) * z + helper.L10) * z + helper.L11) * z + helper.L12;\r\n    tmpA.data[4] = ((helper.M00 * z + helper.M01) * z + helper.M02) * z + helper.M03;\r\n    tmpA.data[5] = ((helper.M04 * z + helper.M05) * z + helper.M06) * z + helper.M07;\r\n    tmpY.data[2] = (((helper.M08 * z + helper.M09) * z + helper.M10) * z + helper.M11) * z + helper.M12;\r\n    CommonOps_DDRM.scale(-1, tmpY);\r\n    CommonOps_DDRM.solve(tmpA, tmpY, tmpX);\r\n    this.x = tmpX.get(0, 0);\r\n    this.y = tmpX.get(1, 0);\r\n}"
}, {
	"Path": "io.github.bucket4j.grid.ProxyManager.getProxy",
	"Comment": "locates proxy to bucket which actually stored outside current jvm.",
	"Method": "Bucket getProxy(K key,BucketConfiguration configuration,Bucket getProxy,K key,Supplier<BucketConfiguration> configurationLazySupplier,Optional<Bucket> getProxy,K key){\r\n    return getProxy(key, () -> configuration);\r\n}"
}, {
	"Path": "org.boon.slumberdb.stores.log.CollectorManager.processWrites",
	"Comment": "this is the main processing loop for the batch writer processing.",
	"Method": "void processWrites(){\r\n    while (true) {\r\n        try {\r\n            manageInputWriterChannel();\r\n        } catch (InterruptedException e) {\r\n            if (determineIfWeShouldExit()) {\r\n                break;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeAlignmentPatternLocator.process",
	"Comment": "uses the previously detected position patterns to seed the search for the alignment patterns",
	"Method": "boolean process(T image,QrCode qr){\r\n    this.qr = qr;\r\n    qr.alignment.reset();\r\n    reader.setImage(image);\r\n    reader.setMarker(qr);\r\n    threshold = (float) qr.threshCorner;\r\n    initializePatterns(qr);\r\n    if (qr.version <= 1)\r\n        return true;\r\n    return localizePositionPatterns(QrCode.VERSION_INFO[qr.version].alignment);\r\n}"
}, {
	"Path": "boofcv.deepboof.DataManipulationOps.normalize",
	"Comment": "normalizes a gray scale image by first subtracting the mean then dividing by stdev.",
	"Method": "void normalize(GrayF32 image,float mean,float stdev){\r\n    for (int y = 0; y < image.height; y++) {\r\n        int index = image.startIndex + y * image.stride;\r\n        int end = index + image.width;\r\n        while (index < end) {\r\n            image.data[index] = (image.data[index] - mean) / stdev;\r\n            index++;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.AssociateGreedy.getFitQuality",
	"Comment": "quality of fit scores for each association.lower fit scores are better.",
	"Method": "double[] getFitQuality(){\r\n    return fitQuality.data;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.helpers.LocationHelper.deleteCachedLocations",
	"Comment": "deletes the cached locations, and the location file too.cache will be started from scratch again.",
	"Method": "void deleteCachedLocations(){\r\n    FileHelper.deleteFile(LOCATION_FILE);\r\n    SAVED_LOCATIONS.clear();\r\n    System.out.println(\"Deleted cached locations.\");\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPDataSource.setLogWriter",
	"Comment": "sets the log writer for this datasource object to the given java.io.printwriter object.",
	"Method": "void setLogWriter(PrintWriter out){\r\n    this.logWriter = out;\r\n}"
}, {
	"Path": "boofcv.core.encoding.ConvertNV21.nv21ToGray",
	"Comment": "converts an nv21 image into a gray scale image.image type is determined at runtime.",
	"Method": "T nv21ToGray(byte[] data,int width,int height,T output,Class<T> outputType,GrayU8 nv21ToGray,byte[] data,int width,int height,GrayU8 output,GrayF32 nv21ToGray,byte[] data,int width,int height,GrayF32 output){\r\n    if (output != null) {\r\n        if (output.width != width || output.height != height)\r\n            throw new IllegalArgumentException(\"output width and height must be \" + width + \" \" + height);\r\n    } else {\r\n        output = new GrayF32(width, height);\r\n    }\r\n    ImplConvertNV21.nv21ToGray(data, output);\r\n    return output;\r\n}"
}, {
	"Path": "org.boon.datarepo.impl.FilterDefault.mainQueryPlan",
	"Comment": "this is the main criteria plan in case the name was notobvious.",
	"Method": "ResultSet mainQueryPlan(Criteria[] expressions){\r\n    ResultSetInternal results = new ResultSetImpl(this.fields);\r\n    if (expressions == null || expressions.length == 0) {\r\n        results.addResults(searchableCollection.all());\r\n    }\r\n    Group group = expressions.length == 1 && expressions[0] instanceof Group ? (Group) expressions[0] : ObjectFilter.and(expressions);\r\n    doFilterGroup(group, results);\r\n    return results;\r\n}"
}, {
	"Path": "boofcv.gui.DemonstrationBase.openVideo",
	"Comment": "before invoking this function make sure waitingtoopenimage is false and that the previous input has been stopped",
	"Method": "void openVideo(boolean reopen,String filePaths){\r\n    synchronized (lockStartingProcess) {\r\n        if (startingProcess) {\r\n            System.out.println(\"Ignoring video request.  Detected spamming\");\r\n            return;\r\n        }\r\n        startingProcess = true;\r\n    }\r\n    synchronized (inputStreams) {\r\n        if (inputStreams.size() != filePaths.length)\r\n            throw new IllegalArgumentException(\"Input streams not equal to \" + filePaths.length + \".  Override openVideo()\");\r\n    }\r\n    stopAllInputProcessing();\r\n    streamPaused = false;\r\n    boolean failed = false;\r\n    for (int which = 0; which < filePaths.length; which++) {\r\n        CacheSequenceStream cache = inputStreams.get(which);\r\n        SimpleImageSequence sequence = media.openVideo(filePaths[which], cache.getImageType());\r\n        if (sequence == null) {\r\n            failed = true;\r\n            System.out.println(\"Can't find file. \" + filePaths[which]);\r\n            break;\r\n        }\r\n        configureVideo(which, sequence);\r\n        synchronized (inputStreams) {\r\n            cache.reset();\r\n            cache.setSequence(sequence);\r\n        }\r\n    }\r\n    if (!failed) {\r\n        setInputName(new File(filePaths[0]).getName());\r\n        synchronized (inputStreams) {\r\n            inputMethod = InputMethod.VIDEO;\r\n            streamPeriod = 33;\r\n            if (threadProcess != null)\r\n                throw new RuntimeException(\"There was still an active stream thread!\");\r\n            threadProcess = new SynchronizedStreamsThread();\r\n        }\r\n        if (!reopen) {\r\n            for (int i = 0; i < inputStreams.size(); i++) {\r\n                CacheSequenceStream stream = inputStreams.get(i);\r\n                handleInputChange(i, inputMethod, stream.getWidth(), stream.getHeight());\r\n            }\r\n        }\r\n        threadPool.execute(threadProcess);\r\n    } else {\r\n        synchronized (inputStreams) {\r\n            inputMethod = InputMethod.NONE;\r\n            inputFilePath = null;\r\n        }\r\n        synchronized (lockStartingProcess) {\r\n            startingProcess = false;\r\n        }\r\n        showRejectDiaglog(\"Can't open file\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.examples.stereo.ExampleFundamentalMatrix.robustFundamental",
	"Comment": "given a set of noisy observations, compute the fundamental matrix while removing\tthe noise.",
	"Method": "DMatrixRMaj robustFundamental(List<AssociatedPair> matches,List<AssociatedPair> inliers){\r\n    ConfigRansac configRansac = new ConfigRansac();\r\n    configRansac.inlierThreshold = 0.1;\r\n    configRansac.maxIterations = 2000;\r\n    ConfigFundamental configFundamental = new ConfigFundamental();\r\n    configFundamental.which = EnumFundamental.LINEAR_7;\r\n    configFundamental.numResolve = 2;\r\n    configFundamental.errorModel = ConfigFundamental.ErrorModel.GEOMETRIC;\r\n    ModelMatcher<DMatrixRMaj, AssociatedPair> ransac = FactoryMultiViewRobust.fundamentalRansac(configFundamental, configRansac);\r\n    if (!ransac.process(matches))\r\n        throw new IllegalArgumentException(\"Failed\");\r\n    inliers.addAll(ransac.getMatchSet());\r\n    DMatrixRMaj F = new DMatrixRMaj(3, 3);\r\n    ModelFitter<DMatrixRMaj, AssociatedPair> refine = FactoryMultiView.fundamentalRefine(1e-8, 400, EpipolarError.SAMPSON);\r\n    if (!refine.fitModel(inliers, ransac.getModelParameters(), F))\r\n        throw new IllegalArgumentException(\"Failed\");\r\n    return F;\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationLinearDualQuadratic.solveForCalibration",
	"Comment": "given the solution for w and the constraints solve for the remaining parameters",
	"Method": "Intrinsic solveForCalibration(DMatrixRMaj w){\r\n    Intrinsic calib = new Intrinsic();\r\n    if (zeroSkew) {\r\n        calib.skew = 0;\r\n        calib.fy = Math.sqrt(w.get(1, 1));\r\n        if (knownAspect) {\r\n            calib.fx = calib.fy / aspectRatio;\r\n        } else {\r\n            calib.fx = Math.sqrt(w.get(0, 0));\r\n        }\r\n    } else if (knownAspect) {\r\n        calib.fy = Math.sqrt(w.get(1, 1));\r\n        calib.fx = calib.fy / aspectRatio;\r\n        calib.skew = w.get(0, 1) / calib.fy;\r\n    } else {\r\n        calib.fy = Math.sqrt(w.get(1, 1));\r\n        calib.skew = w.get(0, 1) / calib.fy;\r\n        calib.fx = Math.sqrt(w.get(0, 0) - calib.skew * calib.skew);\r\n    }\r\n    return calib;\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernel.random1D_F32",
	"Comment": "creates a random 1d kernel drawn from a uniform distribution.",
	"Method": "Kernel1D_F32 random1D_F32(int width,int offset,float min,float max,Random rand){\r\n    Kernel1D_F32 ret = new Kernel1D_F32(width, offset);\r\n    float range = max - min;\r\n    for (int i = 0; i < ret.data.length; i++) {\r\n        ret.data[i] = rand.nextFloat() * range + min;\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.factory.feature.describe.FactoryDescribePointAlgs.briefso",
	"Comment": "todo remove filterblur for all brief change to radius,sigma,type",
	"Method": "DescribePointBriefSO<T> briefso(BinaryCompareDefinition_I32 definition,BlurFilter<T> filterBlur){\r\n    Class<T> imageType = filterBlur.getInputType().getImageClass();\r\n    InterpolatePixelS<T> interp = FactoryInterpolation.bilinearPixelS(imageType, BorderType.EXTENDED);\r\n    return new DescribePointBriefSO(definition, filterBlur, interp);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.BinaryEllipseDetector.refine",
	"Comment": "if auto refine is turned off an ellipse can be refined after the fact using this function, provided\tthat the refinement algorithm was passed in to the constructor",
	"Method": "boolean refine(EllipseRotated_F64 ellipse){\r\n    if (autoRefine)\r\n        throw new IllegalArgumentException(\"Autorefine is true, no need to refine again\");\r\n    if (ellipseRefiner == null)\r\n        throw new IllegalArgumentException(\"Refiner has not been passed in\");\r\n    if (!ellipseRefiner.process(ellipse, ellipse)) {\r\n        return false;\r\n    } else {\r\n        return true;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.TestKltTracker.testTracking_border1",
	"Comment": "create a description of a feature next to the border then place the feature just outside of the image\tand see if it can track to its original position.",
	"Method": "void testTracking_border1(){\r\n    ImageMiscOps.fillUniform(image, rand, 0, 100);\r\n    GradientSobel.process(image, derivX, derivY, new ImageBorder1D_F32(BorderIndex1D_Extend.class));\r\n    KltTracker<GrayF32, GrayF32> tracker = createDefaultTracker();\r\n    tracker.setImage(image, derivX, derivY);\r\n    KltFeature feature = new KltFeature(3);\r\n    feature.setPosition(imageWidth - 4, imageHeight - 4);\r\n    tracker.setDescription(feature);\r\n    feature.setPosition(imageWidth - 2, imageHeight - 1);\r\n    assertTrue(tracker.track(feature) == KltTrackFault.SUCCESS);\r\n    assertEquals(imageWidth - 4, feature.x, 0.01);\r\n    assertEquals(imageHeight - 4, feature.y, 0.01);\r\n    feature.setPosition(3, 3);\r\n    tracker.setDescription(feature);\r\n    feature.setPosition(1, 2);\r\n    assertTrue(tracker.track(feature) == KltTrackFault.SUCCESS);\r\n    assertEquals(3, feature.x, 0.01);\r\n    assertEquals(3, feature.y, 0.01);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.StitchingFromMotion2D.resizeStitchImage",
	"Comment": "resizes the stitch image.if no transform is provided then the old stitch region is simply\tplaces on top of the new one and copied.pixels which do not exist in the old image are filled with zero.",
	"Method": "void resizeStitchImage(int widthStitch,int heightStitch,IT newToOldStitch){\r\n    workImage.reshape(widthStitch, heightStitch);\r\n    GImageMiscOps.fill(workImage, 0);\r\n    if (newToOldStitch != null) {\r\n        PixelTransform2_F32 newToOld = converter.convertPixel(newToOldStitch, null);\r\n        distorter.setModel(newToOld);\r\n        distorter.apply(stitchedImage, workImage);\r\n        IT tmp = (IT) worldToCurr.createInstance();\r\n        newToOldStitch.concat(worldToInit, tmp);\r\n        worldToInit.set(tmp);\r\n        computeCurrToInit_PixelTran();\r\n    } else {\r\n        int overlapWidth = Math.min(widthStitch, stitchedImage.width);\r\n        int overlapHeight = Math.min(heightStitch, stitchedImage.height);\r\n        GImageMiscOps.copy(0, 0, 0, 0, overlapWidth, overlapHeight, stitchedImage, workImage);\r\n    }\r\n    stitchedImage.reshape(widthStitch, heightStitch);\r\n    I tmp = stitchedImage;\r\n    stitchedImage = workImage;\r\n    workImage = tmp;\r\n    this.widthStitch = widthStitch;\r\n    this.heightStitch = heightStitch;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.TestKltTracker.testTracking_border2",
	"Comment": "place a feature on the border then put it inside the image.see if it moves towards the border",
	"Method": "void testTracking_border2(){\r\n    ImageMiscOps.fillUniform(image, rand, 0, 100);\r\n    GradientSobel.process(image, derivX, derivY, new ImageBorder1D_F32(BorderIndex1D_Extend.class));\r\n    KltTracker<GrayF32, GrayF32> tracker = createDefaultTracker();\r\n    tracker.setImage(image, derivX, derivY);\r\n    KltFeature feature = new KltFeature(3);\r\n    feature.setPosition(imageWidth - 3 - 1 + 2, imageHeight - 3 - 1 + 1);\r\n    tracker.setDescription(feature);\r\n    feature.setPosition(imageWidth - 3 - 1, imageHeight - 3 - 1);\r\n    assertTrue(tracker.track(feature) == KltTrackFault.SUCCESS);\r\n    assertEquals(imageWidth - 3 - 1 + 2, feature.x, 0.01);\r\n    assertEquals(imageHeight - 3 - 1 + 1, feature.y, 0.01);\r\n    feature.setPosition(2, 1);\r\n    tracker.setDescription(feature);\r\n    feature.setPosition(3, 3);\r\n    assertTrue(tracker.track(feature) == KltTrackFault.SUCCESS);\r\n    assertEquals(2, feature.x, 0.01);\r\n    assertEquals(1, feature.y, 0.01);\r\n}"
}, {
	"Path": "boofcv.core.image.GeneralizedImageOps.convert",
	"Comment": "converts an image from one type to another type.creates a new image instance if\tan output is not provided.",
	"Method": "T convert(ImageGray<?> src,T dst,Class<T> typeDst){\r\n    if (dst == null) {\r\n        dst = (T) createSingleBand(typeDst, src.width, src.height);\r\n    } else {\r\n        InputSanityCheck.checkSameShape(src, dst);\r\n    }\r\n    GConvertImage.convert(src, dst);\r\n    return dst;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setMaxConnectionAgeInSeconds",
	"Comment": "sets the maxconnectionage in seconds. any connections older than this setting will be closed\toff whether it is idle or not. connections currently in use will not be affected until they\tare returned to the pool.",
	"Method": "void setMaxConnectionAgeInSeconds(long maxConnectionAgeInSeconds){\r\n    setMaxConnectionAge(maxConnectionAgeInSeconds, TimeUnit.SECONDS);\r\n}"
}, {
	"Path": "boofcv.examples.sfm.ExampleVisualOdometryDepth.inlierPercent",
	"Comment": "if the algorithm implements accesspointtracks3d, then count the number of inlier features\tand return a string.",
	"Method": "String inlierPercent(VisualOdometry alg){\r\n    if (!(alg instanceof AccessPointTracks3D))\r\n        return \"\";\r\n    AccessPointTracks3D access = (AccessPointTracks3D) alg;\r\n    int count = 0;\r\n    int N = access.getAllTracks().size();\r\n    for (int i = 0; i < N; i++) {\r\n        if (access.isInlier(i))\r\n            count++;\r\n    }\r\n    return String.format(\"%%%5.3f\", 100.0 * count / N);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.TestDetectPolygonFromContour.usingSetLensDistortion",
	"Comment": "see if it uses the provided lens distortion transforms correctly.the distortion applied\tis actually the affine transform instead of lens distortion.it should find the original\trectangles.",
	"Method": "void usingSetLensDistortion(){\r\n    rectangles.add(new Rectangle2D_I32(30, 30, 60, 60));\r\n    rectangles.add(new Rectangle2D_I32(90, 30, 120, 60));\r\n    rectangles.add(new Rectangle2D_I32(30, 90, 60, 120));\r\n    rectangles.add(new Rectangle2D_I32(90, 90, 120, 120));\r\n    transform.set(0.8, 0, 0, 0.8, 1, 2);\r\n    transform = transform.invert(null);\r\n    for (Class imageType : imageTypes) {\r\n        checkDetected_LensDistortion(imageType, 0.5);\r\n    }\r\n}"
}, {
	"Path": "boofcv.examples.sfm.ExampleMultiviewSceneReconstruction.visualizeResults",
	"Comment": "opens a window showing the found point cloud. points are colorized using the pixel value inside\tone of the input images",
	"Method": "void visualizeResults(SceneStructureMetric structure,List<BufferedImage> colorImages){\r\n    List<Point3D_F64> cloudXyz = new ArrayList();\r\n    GrowQueue_I32 cloudRgb = new GrowQueue_I32();\r\n    Point3D_F64 world = new Point3D_F64();\r\n    Point3D_F64 camera = new Point3D_F64();\r\n    Point2D_F64 pixel = new Point2D_F64();\r\n    for (int i = 0; i < structure.points.length; i++) {\r\n        SceneStructureMetric.Point p = structure.points[i];\r\n        p.get(world);\r\n        for (int j = 0; j < p.views.size; j++) {\r\n            int viewIdx = p.views.get(j);\r\n            SePointOps_F64.transform(structure.views[viewIdx].worldToView, world, camera);\r\n            int cameraIdx = structure.views[viewIdx].camera;\r\n            structure.cameras[cameraIdx].model.project(camera.x, camera.y, camera.z, pixel);\r\n            BufferedImage image = colorImages.get(viewIdx);\r\n            int x = (int) pixel.x;\r\n            int y = (int) pixel.y;\r\n            if (x < 0 || y < 0 || x >= image.getWidth() || y >= image.getHeight())\r\n                continue;\r\n            cloudXyz.add(world.copy());\r\n            cloudRgb.add(image.getRGB((int) pixel.x, (int) pixel.y));\r\n            break;\r\n        }\r\n    }\r\n    PointCloudViewer viewer = VisualizeData.createPointCloudViewer();\r\n    viewer.setTranslationStep(0.05);\r\n    viewer.addCloud(cloudXyz, cloudRgb.data);\r\n    viewer.setCameraHFov(UtilAngle.radian(60));\r\n    SwingUtilities.invokeLater(() -> {\r\n        viewer.getComponent().setPreferredSize(new Dimension(500, 500));\r\n        ShowImages.showWindow(viewer.getComponent(), \"Reconstruction Points\", true);\r\n    });\r\n}"
}, {
	"Path": "boofcv.demonstrations.feature.associate.VisualizeAssociationScoreApp.extractImageFeatures",
	"Comment": "detects the locations of the features in the image and extracts descriptions of each of\tthe features.",
	"Method": "void extractImageFeatures(ProgressMonitor progressMonitor,int progress,T image,List<TupleDesc> descs,List<Point2D_F64> locs){\r\n    SwingUtilities.invokeLater(new Runnable() {\r\n        public void run() {\r\n            progressMonitor.setNote(\"Detecting\");\r\n        }\r\n    });\r\n    detector.detect(image);\r\n    SwingUtilities.invokeLater(new Runnable() {\r\n        public void run() {\r\n            progressMonitor.setProgress(progress + 1);\r\n            progressMonitor.setNote(\"Describing\");\r\n        }\r\n    });\r\n    describe.setImage(image);\r\n    orientation.setImage(image);\r\n    if (detector.hasScale()) {\r\n        for (int i = 0; i < detector.getNumberOfFeatures(); i++) {\r\n            double yaw = 0;\r\n            Point2D_F64 pt = detector.getLocation(i);\r\n            double radius = detector.getRadius(i);\r\n            if (describe.requiresOrientation()) {\r\n                orientation.setObjectRadius(radius);\r\n                yaw = orientation.compute(pt.x, pt.y);\r\n            }\r\n            TupleDesc d = describe.createDescription();\r\n            if (describe.process(pt.x, pt.y, yaw, radius, d)) {\r\n                descs.add(d);\r\n                locs.add(pt.copy());\r\n            }\r\n        }\r\n    } else {\r\n        orientation.setObjectRadius(1);\r\n        for (int i = 0; i < detector.getNumberOfFeatures(); i++) {\r\n            double yaw = 0;\r\n            Point2D_F64 pt = detector.getLocation(i);\r\n            if (describe.requiresOrientation()) {\r\n                yaw = orientation.compute(pt.x, pt.y);\r\n            }\r\n            TupleDesc d = describe.createDescription();\r\n            if (describe.process(pt.x, pt.y, yaw, 1, d)) {\r\n                descs.add(d);\r\n                locs.add(pt.copy());\r\n            }\r\n        }\r\n    }\r\n    SwingUtilities.invokeLater(new Runnable() {\r\n        public void run() {\r\n            progressMonitor.setProgress(progress + 2);\r\n        }\r\n    });\r\n}"
}, {
	"Path": "boofcv.demonstrations.feature.associate.VisualizeAssociationScoreApp.extractImageFeatures",
	"Comment": "detects the locations of the features in the image and extracts descriptions of each of\tthe features.",
	"Method": "void extractImageFeatures(ProgressMonitor progressMonitor,int progress,T image,List<TupleDesc> descs,List<Point2D_F64> locs){\r\n    progressMonitor.setNote(\"Detecting\");\r\n}"
}, {
	"Path": "boofcv.demonstrations.feature.associate.VisualizeAssociationScoreApp.extractImageFeatures",
	"Comment": "detects the locations of the features in the image and extracts descriptions of each of\tthe features.",
	"Method": "void extractImageFeatures(ProgressMonitor progressMonitor,int progress,T image,List<TupleDesc> descs,List<Point2D_F64> locs){\r\n    progressMonitor.setProgress(progress + 1);\r\n    progressMonitor.setNote(\"Describing\");\r\n}"
}, {
	"Path": "boofcv.demonstrations.feature.associate.VisualizeAssociationScoreApp.extractImageFeatures",
	"Comment": "detects the locations of the features in the image and extracts descriptions of each of\tthe features.",
	"Method": "void extractImageFeatures(ProgressMonitor progressMonitor,int progress,T image,List<TupleDesc> descs,List<Point2D_F64> locs){\r\n    progressMonitor.setProgress(progress + 2);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.TestPyramidKltTracker.track_largeOffset",
	"Comment": "test positive examples of tracking when there should be no fault at any point.\tlarger offset which will require the pyramid approach",
	"Method": "void track_largeOffset(){\r\n    PyramidKltFeature feature = new PyramidKltFeature(pyramid.getNumLayers(), featureReadius);\r\n    feature.setPosition(cornerX, cornerY);\r\n    tracker.setImage(pyramid, derivX, derivY);\r\n    tracker.setDescription(feature);\r\n    feature.setPosition(cornerX - 5.4f, cornerY + 5.3f);\r\n    assertTrue(tracker.track(feature) == KltTrackFault.SUCCESS);\r\n    assertEquals(cornerX, feature.x, 0.2);\r\n    assertEquals(cornerY, feature.y, 0.2);\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestNarrowToWidePtoP_F64.centerIsCenter",
	"Comment": "with no translation request a point in the center.should appear to be in the center in both views.",
	"Method": "void centerIsCenter(){\r\n    NarrowToWidePtoP_F64 alg = createAlg();\r\n    Point2D_F64 found = new Point2D_F64();\r\n    alg.compute(250, 250, found);\r\n    assertEquals(480, found.x, GrlConstants.TEST_SQ_F64);\r\n    assertEquals(480, found.y, GrlConstants.TEST_SQ_F64);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.SiftScaleSpace.pixelScaleCurrentToInput",
	"Comment": "returns the size of a pixel in the current octave relative to the size of a pixel\tin the input image",
	"Method": "double pixelScaleCurrentToInput(){\r\n    return Math.pow(2.0, currentOctave);\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.TestFundamentalResidualSimple.checkChangeInCost",
	"Comment": "first check to see if the error is very low for perfect parameters.then\tgive it incorrect parameters and make sure it is not zero.",
	"Method": "void checkChangeInCost(){\r\n    init(30, false);\r\n    DMatrixRMaj E = MultiViewOps.createEssential(a_to_b.getR(), a_to_b.getT(), null);\r\n    FundamentalResidualSimple alg = new FundamentalResidualSimple();\r\n    alg.setModel(E);\r\n    for (AssociatedPair p : pairs) {\r\n        assertEquals(0, alg.computeResidual(p), 1e-8);\r\n    }\r\n    E.data[1] += 0.1;\r\n    alg.setModel(E);\r\n    for (AssociatedPair p : pairs) {\r\n        assertTrue(Math.abs(alg.computeResidual(p)) > 1e-8);\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.MetaDataMergeTest.generateMetaData",
	"Comment": "generates a metadata object with a tab value containing a map with a null entry",
	"Method": "MetaData generateMetaData(){\r\n    MetaData metaData = new MetaData();\r\n    Map<Object, Object> nestedMap = new HashMap();\r\n    metaData.addToTab(\"foo\", \"bar\", nestedMap);\r\n    nestedMap.put(\"whoops\", null);\r\n    return metaData;\r\n}"
}, {
	"Path": "boofcv.alg.background.BackgroundModel.getUnknownValue",
	"Comment": "returns the value that pixels in the segmented image are assigned if there is no background information.",
	"Method": "int getUnknownValue(){\r\n    return unknownValue & 0xff;\r\n}"
}, {
	"Path": "boofcv.alg.geo.rectify.RectifyCalibrated.getRectifiedRotation",
	"Comment": "rotation matrix of rectified coordinate system. to convert back into left camera reference frame multiply\tthe triangulated point by the transpose of this matrix",
	"Method": "DMatrixRMaj getRectifiedRotation(){\r\n    return rectifiedR;\r\n}"
}, {
	"Path": "io.github.bucket4j.AbstractBucketBuilder.addLimit",
	"Comment": "adds limited bandwidth for all buckets which will be constructed by this builder.",
	"Method": "T addLimit(Bandwidth bandwidth){\r\n    configurationBuilder.addLimit(bandwidth);\r\n    return (T) this;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.intensity.impl.TestImplSsdCorner_S16.compareToManual",
	"Comment": "manually compute intensity values and see if they are the same",
	"Method": "void compareToManual(){\r\n    GImageMiscOps.fillUniform(input, rand, 0, 100);\r\n    GradientSobel.process(input, derivX, derivY, BoofDefaults.borderDerivative_I32());\r\n    for (int i = 0; i < height; i++) {\r\n        for (int j = 0; j < width; j++) {\r\n            int x = derivX.get(j, i);\r\n            int y = derivY.get(j, i);\r\n            derivXX.set(j, i, x * x);\r\n            derivXY.set(j, i, x * y);\r\n            derivYY.set(j, i, y * y);\r\n        }\r\n    }\r\n    Sdd alg = new Sdd(radius);\r\n    alg.process(derivX, derivY, new GrayF32(width, height));\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.getConnectionHookClassName",
	"Comment": "returns the connection hook class name as passed via the setter",
	"Method": "String getConnectionHookClassName(){\r\n    return this.connectionHookClassName;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setDefaultReadOnly",
	"Comment": "sets the defaultreadonly setting for newly created connections. if not set, use driver default.",
	"Method": "void setDefaultReadOnly(Boolean defaultReadOnly){\r\n    this.defaultReadOnly = checkNotNull(defaultReadOnly);\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.PointTrackerKltPyramid.getInactiveTracks",
	"Comment": "klt does not have inactive tracks since all tracks are dropped if a problem occurs.",
	"Method": "List<PointTrack> getInactiveTracks(List<PointTrack> list){\r\n    if (list == null)\r\n        list = new ArrayList();\r\n    return list;\r\n}"
}, {
	"Path": "boofcv.io.image.TestConvertBufferedImage.convertFromSingle_I16",
	"Comment": "not all types support conversion into 16 bit images, so the special case of 16bit image are handled here",
	"Method": "void convertFromSingle_I16(){\r\n    BufferedImage origImg = TestConvertRaster.createShortBuff(imgWidth, imgHeight, rand);\r\n    for (int j = 0; j < 2; j++) {\r\n        if (j == 1) {\r\n            origImg = origImg.getSubimage(1, 2, imgWidth - 1, imgHeight - 2);\r\n        }\r\n        GrayU16 imgU16 = ConvertBufferedImage.convertFromSingle(origImg, null, GrayU16.class);\r\n        assertEquals(origImg.getWidth(), imgU16.width);\r\n        assertEquals(origImg.getHeight(), imgU16.height);\r\n        BufferedImageChecks.checkEquals(origImg, imgU16, false, 1);\r\n        GrayS16 imgS16 = ConvertBufferedImage.convertFromSingle(origImg, null, GrayS16.class);\r\n        assertEquals(origImg.getWidth(), imgS16.width);\r\n        assertEquals(origImg.getHeight(), imgS16.height);\r\n        BufferedImageChecks.checkEquals(origImg, imgS16, false, 1);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.HysteresisEdgeTracePoints.startNewSegment",
	"Comment": "starts a new segment in the contour at the specified coordinate.",
	"Method": "void startNewSegment(int x,int y,EdgeSegment parent){\r\n    Point2D_I32 p = queuePoints.grow();\r\n    p.set(x, y);\r\n    EdgeSegment s = new EdgeSegment();\r\n    s.parent = parent.index;\r\n    s.parentPixel = parent.points.size() - 2;\r\n    s.index = e.segments.size();\r\n    s.points.add(p);\r\n    e.segments.add(s);\r\n    open.add(s);\r\n}"
}, {
	"Path": "boofcv.abst.geo.calibration.CalibrateMonoPlanar.computeErrors",
	"Comment": "after the parameters have been estimated this computes the error for each calibration point in\teach image and summary error statistics.",
	"Method": "List<ImageResults> computeErrors(List<CalibrationObservation> observation,Zhang99AllParam param,List<Point2D_F64> grid){\r\n    Zhang99OptimizationFunction function = new Zhang99OptimizationFunction(param, grid, observation);\r\n    double[] residuals = new double[grid.size() * observation.size() * 2];\r\n    function.process(param, residuals);\r\n    List<ImageResults> ret = new ArrayList();\r\n    int N = grid.size();\r\n    int index = 0;\r\n    for (int indexObs = 0; indexObs < observation.size(); indexObs++) {\r\n        ImageResults r = new ImageResults(N);\r\n        double meanX = 0;\r\n        double meanY = 0;\r\n        double meanErrorMag = 0;\r\n        double maxError = 0;\r\n        for (int i = 0; i < N; i++) {\r\n            double errorX = residuals[index++];\r\n            double errorY = residuals[index++];\r\n            double errorMag = Math.sqrt(errorX * errorX + errorY * errorY);\r\n            r.pointError[i] = errorMag;\r\n            meanX += errorX;\r\n            meanY += errorY;\r\n            meanErrorMag += errorMag;\r\n            if (maxError < errorMag) {\r\n                maxError = errorMag;\r\n            }\r\n        }\r\n        r.biasX = meanX /= N;\r\n        r.biasY = meanY /= N;\r\n        r.meanError = meanErrorMag /= N;\r\n        r.maxError = maxError;\r\n        ret.add(r);\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.EquirectangularTools_F64.equiToNorm",
	"Comment": "converts equirectangular into normalized pointing vector",
	"Method": "void equiToNorm(double x,double y,Point3D_F64 norm){\r\n    equiToLatLon(x, y, temp);\r\n    ConvertCoordinates3D_F64.latlonToUnitVector(temp.lat, temp.lon, norm);\r\n}"
}, {
	"Path": "boofcv.io.UtilIO.pathExampleURL",
	"Comment": "returns an absolute path to the file that is relative to the example directory",
	"Method": "URL pathExampleURL(String path){\r\n    try {\r\n        File fpath = new File(path);\r\n        if (fpath.isAbsolute())\r\n            return fpath.toURI().toURL();\r\n        String pathToBase = getPathToBase();\r\n        if (pathToBase != null) {\r\n            File pathExample = new File(pathToBase, \"data/example/\");\r\n            if (pathExample.exists()) {\r\n                return new File(pathExample.getPath(), path).getAbsoluteFile().toURL();\r\n            }\r\n        }\r\n        URL url = UtilIO.class.getClassLoader().getResource(path);\r\n        if (url == null) {\r\n            System.err.println();\r\n            System.err.println(\"Can't find data/example directory!  There are three likely causes for this problem.\");\r\n            System.err.println();\r\n            System.err.println(\"1) You checked out the source code from git and did not pull the data submodule too.\");\r\n            System.err.println(\"2) You are trying to run an example from outside the BoofCV directory tree.\");\r\n            System.err.println(\"3) You are trying to pass in your own image.\");\r\n            System.err.println();\r\n            System.err.println(\"Solutions:\");\r\n            System.err.println(\"1) Follow instructions in the boofcv/readme.md file to grab the data directory.\");\r\n            System.err.println(\"2) Launch the example from inside BoofCV's directory tree!\");\r\n            System.err.println(\"3) Don't use this function and just pass in the path directly\");\r\n            System.exit(1);\r\n        }\r\n        return url;\r\n    } catch (MalformedURLException e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.h.HomographyDirectLinearTransform.computeH",
	"Comment": "computes the svd of a and extracts the homography matrix from its null space",
	"Method": "boolean computeH(DMatrixRMaj A,DMatrixRMaj H){\r\n    if (!solverNullspace.process(A.copy(), 1, H))\r\n        return true;\r\n    H.numRows = 3;\r\n    H.numCols = 3;\r\n    return false;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setStatisticsEnabled",
	"Comment": "if set to true, keep track of some more statistics for exposure via jmx. will slow down the pool\toperation.",
	"Method": "void setStatisticsEnabled(boolean statisticsEnabled){\r\n    this.statisticsEnabled = statisticsEnabled;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.KeyPointsCircleHexagonalGrid.getKeyPoints",
	"Comment": "returns the location of each key point in the image from the most recently processed grid.",
	"Method": "FastQueue<Point2D_F64> getKeyPoints(){\r\n    return keypoints;\r\n}"
}, {
	"Path": "org.bimserver.shared.GuidCompressor.getNewIfcGloballyUniqueId",
	"Comment": "generates a new guid and returns a compressed string representation as used for ifcgloballyuniqueid",
	"Method": "String getNewIfcGloballyUniqueId(){\r\n    Guid guid = getGuidFromUncompressedString(UUID.randomUUID().toString());\r\n    String shortString = getCompressedStringFromGuid(guid);\r\n    return shortString;\r\n}"
}, {
	"Path": "boofcv.alg.bow.LearnSceneFromFiles.evaluate",
	"Comment": "given a set of images with known classification, predict which scene each one belongs in and compute\ta confusion matrix for the results.",
	"Method": "Confusion evaluate(Map<String, List<String>> set){\r\n    ClassificationHistogram histogram = new ClassificationHistogram(scenes.size());\r\n    int total = 0;\r\n    for (int i = 0; i < scenes.size(); i++) {\r\n        total += set.get(scenes.get(i)).size();\r\n    }\r\n    System.out.println(\"total images \" + total);\r\n    for (int i = 0; i < scenes.size(); i++) {\r\n        String scene = scenes.get(i);\r\n        List<String> images = set.get(scene);\r\n        System.out.println(\"  \" + scene + \" \" + images.size());\r\n        for (String image : images) {\r\n            int predicted = classify(image);\r\n            histogram.increment(i, predicted);\r\n        }\r\n    }\r\n    return histogram.createConfusion();\r\n}"
}, {
	"Path": "boofcv.factory.geo.FactoryMultiView.triangulateRefineEpipolar",
	"Comment": "refine the triangulation using sampson error.approximately takes in account epipolar constraints.",
	"Method": "RefineTriangulationEpipolar triangulateRefineEpipolar(double convergenceTol,int maxIterations){\r\n    return new RefineTriangulateEpipolar(convergenceTol, maxIterations);\r\n}"
}, {
	"Path": "boofcv.android.VisualizeImageData.renderLabeled",
	"Comment": "renders a labeled where each region is assigned a random color.",
	"Method": "void renderLabeled(GrayS32 labelImage,int numRegions,Bitmap output,byte[] storage){\r\n    if (storage == null)\r\n        storage = declareStorage(output, null);\r\n    int[] colors = new int[numRegions];\r\n    Random rand = new Random(123);\r\n    for (int i = 0; i < colors.length; i++) {\r\n        colors[i] = rand.nextInt();\r\n    }\r\n    int w = labelImage.getWidth();\r\n    int h = labelImage.getHeight();\r\n    int indexOut = 0;\r\n    for (int y = 0; y < h; y++) {\r\n        int indexSrc = labelImage.startIndex + y * labelImage.stride;\r\n        for (int x = 0; x < w; x++) {\r\n            int rgb = colors[labelImage.data[indexSrc++]];\r\n            storage[indexOut++] = (byte) (rgb & 0xFF);\r\n            storage[indexOut++] = (byte) ((rgb >> 8) & 0xFF);\r\n            storage[indexOut++] = (byte) ((rgb >> 16) & 0xFF);\r\n            storage[indexOut++] = (byte) 0xFF;\r\n        }\r\n    }\r\n    output.copyPixelsFromBuffer(ByteBuffer.wrap(storage));\r\n}"
}, {
	"Path": "boofcv.alg.geo.robust.StandardModelFitterTests.simpleTest",
	"Comment": "give it points which have been transform by the true affine model.see\tif the transform is correctly estimated",
	"Method": "void simpleTest(){\r\n    testWithN(minPoints);\r\n}"
}, {
	"Path": "boofcv.io.image.UtilImageIO.loadPPM_U8",
	"Comment": "reads a ppm image file directly into a planar image. to improve performance when reading\tmany images, the user can provide work space memory in the optional parameters",
	"Method": "Planar<GrayU8> loadPPM_U8(String fileName,Planar<GrayU8> storage,GrowQueue_I8 temp,Planar<GrayU8> loadPPM_U8,InputStream inputStream,Planar<GrayU8> storage,GrowQueue_I8 temp){\r\n    DataInputStream in = new DataInputStream(inputStream);\r\n    readLine(in);\r\n    String line = readLine(in);\r\n    while (line.charAt(0) == '#') line = readLine(in);\r\n    String[] s = line.split(\" \");\r\n    int w = Integer.parseInt(s[0]);\r\n    int h = Integer.parseInt(s[1]);\r\n    readLine(in);\r\n    if (storage == null || storage.getNumBands() != 3)\r\n        storage = new Planar(GrayU8.class, w, h, 3);\r\n    else\r\n        storage.reshape(w, h);\r\n    int length = w * h * 3;\r\n    if (temp == null)\r\n        temp = new GrowQueue_I8(length);\r\n    temp.resize(length);\r\n    byte[] data = temp.data;\r\n    read(in, data, length);\r\n    GrayU8 band0 = storage.getBand(0);\r\n    GrayU8 band1 = storage.getBand(1);\r\n    GrayU8 band2 = storage.getBand(2);\r\n    int indexIn = 0;\r\n    for (int y = 0; y < storage.height; y++) {\r\n        int indexOut = storage.startIndex + y * storage.stride;\r\n        for (int x = 0; x < storage.width; x++, indexOut++) {\r\n            band0.data[indexOut] = data[indexIn++];\r\n            band1.data[indexOut] = data[indexIn++];\r\n            band2.data[indexOut] = data[indexIn++];\r\n        }\r\n    }\r\n    return storage;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareCrossClustersIntoGrids.process",
	"Comment": "converts all the found clusters into grids, if they are valid.",
	"Method": "void process(List<List<SquareNode>> clusters){\r\n    grids.reset();\r\n    for (int i = 0; i < clusters.size(); i++) {\r\n        if (checkPreconditions(clusters.get(i)))\r\n            processCluster(clusters.get(i));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquaresIntoCrossClusters.process",
	"Comment": "processes the unordered set of squares and creates a graph out of them using prior knowledge and geometric\tconstraints.",
	"Method": "List<List<SquareNode>> process(List<DetectPolygonFromContour.Info> squares){\r\n    recycleData();\r\n    computeNodeInfo(squares);\r\n    connectNodes();\r\n    findClusters();\r\n    return clusters.toList();\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionHandle.getInternalConnection",
	"Comment": "returns the internal connection as obtained via the jdbc driver.",
	"Method": "Connection getInternalConnection(){\r\n    return this.connection;\r\n}"
}, {
	"Path": "boofcv.abst.feature.dense.TestGenericDenseDescribeImage.process",
	"Comment": "give it a known situation and see if it produces the expected results",
	"Method": "void process(boolean process,double x,double y,double orientation,double radius,TupleDesc description){\r\n    DummyFeature sparse = new DummyFeature();\r\n    GenericDenseDescribeImageDense alg = new GenericDenseDescribeImageDense(sparse, 1, 1.5, 3, 4);\r\n    GrayU8 image = new GrayU8(100, 110);\r\n    alg.process(image);\r\n    List<TupleDesc_F64> descs = alg.getDescriptions();\r\n    List<Point2D_I32> points = alg.getLocations();\r\n    assertEquals(descs.size(), points.size());\r\n    int featureRadius = (int) Math.round(1.5 * 7.0 / 2.0);\r\n    int w = (100 - 2 * featureRadius) / 3;\r\n    int h = (110 - 2 * featureRadius) / 4;\r\n    assertEquals(w * h - 1, points.size());\r\n    int count = 0;\r\n    for (int y = 0; y < h; y++) {\r\n        int pixelY = featureRadius + y * y;\r\n        for (int x = 0; x < w; x++) {\r\n            int pixelX = featureRadius + x * 3;\r\n            Point2D_I32 p = null;\r\n            if (count < 19) {\r\n                p = points.get(count);\r\n            } else if (count > 20) {\r\n                p = points.get(count + 1);\r\n            } else {\r\n                continue;\r\n            }\r\n            assertEquals(pixelX, p.x);\r\n            assertEquals(pixelY, p.y);\r\n            count++;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.io.image.TestUtilImageIO.loadImage_negative",
	"Comment": "see if load image fails gracefully if an image is not present",
	"Method": "void loadImage_negative(){\r\n    assertTrue(UtilImageIO.loadImage(\"asdasdasdasd\") == null);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.ConfigNew.getAsObject",
	"Comment": "returns the default value as object, so that it may can added again. just for internal use, no typ checking!",
	"Method": "Object getAsObject(ConfigKey configKey){\r\n    Object obj;\r\n    switch(configKey.type) {\r\n        case BOOLEAN:\r\n            obj = getBool(configKey);\r\n            break;\r\n        case STRING:\r\n            obj = getString(configKey);\r\n            break;\r\n        case INTEGER:\r\n            obj = getInt(configKey);\r\n            break;\r\n        case DOUBLE:\r\n            obj = getDouble(configKey);\r\n            break;\r\n        default:\r\n            obj = getJSONObject(configKey);\r\n            break;\r\n    }\r\n    return obj;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.StitchingFromMotion2D.configure",
	"Comment": "specifies size of stitch image and the location of the initial coordinate system.",
	"Method": "void configure(int widthStitch,int heightStitch,IT worldToInit){\r\n    this.worldToInit = (IT) worldToCurr.createInstance();\r\n    if (worldToInit != null)\r\n        this.worldToInit.set(worldToInit);\r\n    this.widthStitch = widthStitch;\r\n    this.heightStitch = heightStitch;\r\n}"
}, {
	"Path": "boofcv.alg.enhance.GEnhanceImageOps.applyTransform",
	"Comment": "applies the transformation table to the provided input image.",
	"Method": "void applyTransform(T input,int transform,int minValue,T output){\r\n    InputSanityCheck.checkSameShape(input, output);\r\n    if (input instanceof GrayU8) {\r\n        EnhanceImageOps.applyTransform((GrayU8) input, transform, (GrayU8) output);\r\n    } else if (input instanceof GrayS8) {\r\n        EnhanceImageOps.applyTransform((GrayS8) input, transform, minValue, (GrayS8) output);\r\n    } else if (input instanceof GrayU16) {\r\n        EnhanceImageOps.applyTransform((GrayU16) input, transform, (GrayU16) output);\r\n    } else if (input instanceof GrayS16) {\r\n        EnhanceImageOps.applyTransform((GrayS16) input, transform, minValue, (GrayS16) output);\r\n    } else if (input instanceof GrayS32) {\r\n        EnhanceImageOps.applyTransform((GrayS32) input, transform, minValue, (GrayS32) output);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Image type not supported. \" + input.getClass().getSimpleName());\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.SelectAlgorithmAndInputPanel.setMainGUI",
	"Comment": "used to add the main gui to this panel. must use this function.\talgorithm change events will not be posted until this function has been set.",
	"Method": "void setMainGUI(Component gui){\r\n    postAlgorithmEvents = true;\r\n    this.gui = gui;\r\n    SwingUtilities.invokeLater(new Runnable() {\r\n        public void run() {\r\n            add(gui, BorderLayout.CENTER);\r\n        }\r\n    });\r\n}"
}, {
	"Path": "boofcv.gui.SelectAlgorithmAndInputPanel.setMainGUI",
	"Comment": "used to add the main gui to this panel. must use this function.\talgorithm change events will not be posted until this function has been set.",
	"Method": "void setMainGUI(Component gui){\r\n    add(gui, BorderLayout.CENTER);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.hasSameConfiguration",
	"Comment": "returns true if this instance has the same config as a given config.",
	"Method": "boolean hasSameConfiguration(BoneCPConfig that){\r\n    if (that != null && Objects.equal(this.acquireIncrement, that.getAcquireIncrement()) && Objects.equal(this.acquireRetryDelayInMs, that.getAcquireRetryDelayInMs()) && Objects.equal(this.closeConnectionWatch, that.isCloseConnectionWatch()) && Objects.equal(this.logStatementsEnabled, that.isLogStatementsEnabled()) && Objects.equal(this.connectionHook, that.getConnectionHook()) && Objects.equal(this.connectionTestStatement, that.getConnectionTestStatement()) && Objects.equal(this.idleConnectionTestPeriodInSeconds, that.getIdleConnectionTestPeriod(TimeUnit.SECONDS)) && Objects.equal(this.idleMaxAgeInSeconds, that.getIdleMaxAge(TimeUnit.SECONDS)) && Objects.equal(this.initSQL, that.getInitSQL()) && Objects.equal(this.jdbcUrl, that.getJdbcUrl()) && Objects.equal(this.maxConnectionsPerPartition, that.getMaxConnectionsPerPartition()) && Objects.equal(this.minConnectionsPerPartition, that.getMinConnectionsPerPartition()) && Objects.equal(this.partitionCount, that.getPartitionCount()) && Objects.equal(this.releaseHelperThreads, that.getReleaseHelperThreads()) && Objects.equal(this.statementsCacheSize, that.getStatementsCacheSize()) && Objects.equal(this.username, that.getUsername()) && Objects.equal(this.password, that.getPassword()) && Objects.equal(this.lazyInit, that.isLazyInit()) && Objects.equal(this.transactionRecoveryEnabled, that.isTransactionRecoveryEnabled()) && Objects.equal(this.acquireRetryAttempts, that.getAcquireRetryAttempts()) && Objects.equal(this.statementReleaseHelperThreads, that.getStatementReleaseHelperThreads()) && Objects.equal(this.closeConnectionWatchTimeoutInMs, that.getCloseConnectionWatchTimeout()) && Objects.equal(this.connectionTimeoutInMs, that.getConnectionTimeoutInMs()) && Objects.equal(this.datasourceBean, that.getDatasourceBean()) && Objects.equal(this.getQueryExecuteTimeLimitInMs(), that.getQueryExecuteTimeLimitInMs()) && Objects.equal(this.poolAvailabilityThreshold, that.getPoolAvailabilityThreshold()) && Objects.equal(this.poolName, that.getPoolName()) && Objects.equal(this.disableConnectionTracking, that.isDisableConnectionTracking())) {\r\n        return true;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.reportedIssues.BoneCpDataSourceTest.testConnectionTimeoutOnDataSourceWithSync",
	"Comment": "this test passes because of the explicit lock ontestdatasource",
	"Method": "void testConnectionTimeoutOnDataSourceWithSync(){\r\n    exec(true);\r\n}"
}, {
	"Path": "boofcv.alg.geo.RectifyImageOps.createCalibrated",
	"Comment": "rectification for calibrated stereo pairs.two stereo camera care considered calibrated if\ttheir baseline is known.\tafter the rectification has been found it might still need to be adjusted\tfor maximum viewing area.see fullviewleft and allinsideleft for adjusting the rectification.",
	"Method": "RectifyCalibrated createCalibrated(){\r\n    return new RectifyCalibrated();\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionMaxAgeTester.testConnectionNotExpired",
	"Comment": "tests that a partition with expired connections should those connections killed off.",
	"Method": "void testConnectionNotExpired(){\r\n    BlockingQueue<ConnectionHandle> mockQueue = createNiceMock(LinkedBlockingQueue.class);\r\n    expect(mockConnectionPartition.getAvailableConnections()).andReturn(1);\r\n    expect(mockConnectionPartition.getFreeConnections()).andReturn(mockQueue).anyTimes();\r\n    ConnectionHandle mockConnection = createNiceMock(ConnectionHandle.class);\r\n    expect(mockQueue.poll()).andReturn(mockConnection).once();\r\n    expect(mockConnection.isExpired(anyLong())).andReturn(false).once();\r\n    expect(mockExecutor.isShutdown()).andReturn(false).once();\r\n    mockPool.putConnectionBackInPartition(mockConnection);\r\n    expectLastCall().once();\r\n    replay(mockQueue, mockExecutor, mockConnectionPartition, mockConnection, mockPool);\r\n    testClass.run();\r\n    verify(mockConnection, mockPool);\r\n}"
}, {
	"Path": "boofcv.app.CameraCalibration.handleWebcam",
	"Comment": "captures calibration data live using a webcam and a gui to assist the user",
	"Method": "void handleWebcam(){\r\n    final Webcam webcam = openSelectedCamera();\r\n    if (desiredWidth > 0 && desiredHeight > 0)\r\n        UtilWebcamCapture.adjustResolution(webcam, desiredWidth, desiredHeight);\r\n    webcam.open();\r\n    Runtime.getRuntime().addShutdownHook(new Thread() {\r\n        public void run() {\r\n            if (webcam.isOpen()) {\r\n                System.out.println(\"Closing webcam\");\r\n                webcam.close();\r\n            }\r\n        }\r\n    });\r\n    ComputeGeometryScore quality = new ComputeGeometryScore(zeroSkew, detector.getLayout());\r\n    AssistedCalibrationGui gui = new AssistedCalibrationGui(webcam.getViewSize());\r\n    JFrame frame = ShowImages.showWindow(gui, \"Webcam Calibration\", true);\r\n    GrayF32 gray = new GrayF32(webcam.getViewSize().width, webcam.getViewSize().height);\r\n    if (desiredWidth > 0 && desiredHeight > 0) {\r\n        if (gray.width != desiredWidth || gray.height != desiredHeight)\r\n            System.err.println(\"Actual camera resolution does not match desired.  Actual: \" + gray.width + \" \" + gray.height + \"  Desired: \" + desiredWidth + \" \" + desiredHeight);\r\n    }\r\n    AssistedCalibration assisted = new AssistedCalibration(detector, quality, gui, OUTPUT_DIRECTORY, IMAGE_DIRECTORY);\r\n    assisted.init(gray.width, gray.height);\r\n    BufferedImage image;\r\n    while ((image = webcam.getImage()) != null && !assisted.isFinished()) {\r\n        ConvertBufferedImage.convertFrom(image, gray);\r\n        try {\r\n            assisted.process(gray, image);\r\n        } catch (RuntimeException e) {\r\n            System.err.println(\"BUG!!! saving image to crash_image.png\");\r\n            UtilImageIO.saveImage(image, \"crash_image.png\");\r\n            throw e;\r\n        }\r\n    }\r\n    webcam.close();\r\n    if (assisted.isFinished()) {\r\n        frame.setVisible(false);\r\n        inputDirectory = new File(OUTPUT_DIRECTORY, IMAGE_DIRECTORY).getPath();\r\n        outputFileName = new File(OUTPUT_DIRECTORY, \"intrinsic.yaml\").getPath();\r\n        handleDirectory();\r\n    }\r\n}"
}, {
	"Path": "boofcv.app.CameraCalibration.handleWebcam",
	"Comment": "captures calibration data live using a webcam and a gui to assist the user",
	"Method": "void handleWebcam(){\r\n    if (webcam.isOpen()) {\r\n        System.out.println(\"Closing webcam\");\r\n        webcam.close();\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.image.VisualizeImageData.colorizeGradient",
	"Comment": "renders two gradients on the same image using two sets of colors, on for each input image.",
	"Method": "BufferedImage colorizeGradient(ImageGray derivX,ImageGray derivY,double maxAbsValue,BufferedImage colorizeGradient,GrayS16 derivX,GrayS16 derivY,int maxAbsValue,BufferedImage colorizeGradient,GrayF32 derivX,GrayF32 derivY,float maxAbsValue){\r\n    InputSanityCheck.checkSameShape(derivX, derivY);\r\n    BufferedImage output = new BufferedImage(derivX.width, derivX.height, BufferedImage.TYPE_INT_RGB);\r\n    WritableRaster raster = output.getRaster();\r\n    DataBufferInt buffer = (DataBufferInt) raster.getDataBuffer();\r\n    int[] outData = buffer.getData();\r\n    int outOffset = ConvertRaster.getOffset(raster);\r\n    if (maxAbsValue < 0) {\r\n        maxAbsValue = ImageStatistics.maxAbs(derivX);\r\n        maxAbsValue = Math.max(maxAbsValue, ImageStatistics.maxAbs(derivY));\r\n    }\r\n    if (maxAbsValue == 0)\r\n        return output;\r\n    int indexOut = outOffset;\r\n    for (int y = 0; y < derivX.height; y++) {\r\n        int indexX = derivX.startIndex + y * derivX.stride;\r\n        int indexY = derivY.startIndex + y * derivY.stride;\r\n        for (int x = 0; x < derivX.width; x++) {\r\n            float valueX = derivX.data[indexX++];\r\n            float valueY = derivY.data[indexY++];\r\n            int r = 0, g = 0, b = 0;\r\n            if (valueX > 0) {\r\n                r = (int) (255 * valueX / maxAbsValue);\r\n            } else {\r\n                g = -(int) (255 * valueX / maxAbsValue);\r\n            }\r\n            if (valueY > 0) {\r\n                b = (int) (255 * valueY / maxAbsValue);\r\n            } else {\r\n                int v = -(int) (255 * valueY / maxAbsValue);\r\n                r += v;\r\n                g += v;\r\n                if (r > 255)\r\n                    r = 255;\r\n                if (g > 255)\r\n                    g = 255;\r\n            }\r\n            outData[indexOut++] = r << 16 | g << 8 | b;\r\n        }\r\n    }\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.android.camera2.SimpleCamera2Activity.cameraIntrinsicNominal",
	"Comment": "returns the camera intrinsic parameters estimated from the physical parameters returned by\tthe camera2 api",
	"Method": "void cameraIntrinsicNominal(CameraPinhole intrinsic){\r\n    open.mLock.lock();\r\n    try {\r\n        if (open.mCameraCharacterstics != null) {\r\n            SizeF physicalSize = open.mCameraCharacterstics.get(CameraCharacteristics.SENSOR_INFO_PHYSICAL_SIZE);\r\n            Rect activeSize = open.mCameraCharacterstics.get(CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE);\r\n            Size pixelSize = open.mCameraCharacterstics.get(CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE);\r\n            float[] focalLengths = open.mCameraCharacterstics.get(CameraCharacteristics.LENS_INFO_AVAILABLE_FOCAL_LENGTHS);\r\n            if (focalLengths != null && focalLengths.length > 0 && physicalSize != null && activeSize != null && pixelSize != null) {\r\n                float fl = focalLengths[0];\r\n                float widthToPixel = pixelSize.getWidth() / physicalSize.getWidth();\r\n                float heightToPixel = pixelSize.getHeight() / physicalSize.getHeight();\r\n                float s = open.mCameraSize.getWidth() / (float) activeSize.width();\r\n                intrinsic.fx = fl * widthToPixel * s;\r\n                intrinsic.fy = fl * heightToPixel * s;\r\n                intrinsic.skew = 0;\r\n                intrinsic.cx = activeSize.centerX() * s;\r\n                intrinsic.cy = activeSize.centerY() * s;\r\n                intrinsic.width = open.mCameraSize.getWidth();\r\n                intrinsic.height = open.mCameraSize.getHeight();\r\n                return;\r\n            }\r\n        }\r\n        PerspectiveOps.createIntrinsic(open.mCameraSize.getWidth(), open.mCameraSize.hashCode(), UtilAngle.radian(60));\r\n    } finally {\r\n        open.mLock.unlock();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.TestStitchingFromMotion2D.setOriginToCurrent",
	"Comment": "note that this test does not actually check to see if the correct transform is applied",
	"Method": "void setOriginToCurrent(){\r\n    HelperMotion motion = new HelperMotion();\r\n    HelperDistort distort = new HelperDistort();\r\n    StitchingTransform trans = FactoryStitchingTransform.createAffine_F64();\r\n    StitchingFromMotion2D<GrayF32, Affine2D_F64> alg = new StitchingFromMotion2D(motion, distort, trans, 0.3);\r\n    alg.configure(200, 300, null);\r\n    assertTrue(alg.process(image));\r\n    alg.setOriginToCurrent();\r\n    assertEquals(2, distort.numSetModel);\r\n    assertEquals(2, distort.numApply);\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.TestDescribeDenseHogAlg.computeWeightBlockPixels",
	"Comment": "tests to see if the weight has the expected shape or at least some of the expected characteristics.",
	"Method": "void computeWeightBlockPixels(){\r\n    int pixelsPerCell = 3;\r\n    int[] cases = new int[] { 3, 4 };\r\n    for (int widthCells : cases) {\r\n        DescribeDenseHogAlg<GrayF32> helper = new DescribeDenseHogAlg(10, pixelsPerCell, widthCells, widthCells + 1, 1, imageType);\r\n        int widthPixelsX = widthCells * pixelsPerCell;\r\n        int widthPixelsY = (widthCells + 1) * pixelsPerCell;\r\n        int rx = widthPixelsX / 2 + widthPixelsX % 2;\r\n        int ry = widthPixelsY / 2 + widthPixelsY % 2;\r\n        int totalOne = 0;\r\n        double max = 0;\r\n        for (int i = 0; i < ry; i++) {\r\n            for (int j = 0; j < rx; j++) {\r\n                double v0 = helper.weights[i * widthPixelsX + j];\r\n                double v1 = helper.weights[i * widthPixelsX + (widthPixelsX - j - 1)];\r\n                double v2 = helper.weights[(widthPixelsY - i - 1) * widthPixelsX + (widthPixelsX - j - 1)];\r\n                double v3 = helper.weights[(widthPixelsY - i - 1) * widthPixelsX + j];\r\n                assertEquals(v0, v1, 1e-8);\r\n                assertEquals(v1, v2, 1e-8);\r\n                assertEquals(v2, v3, 1e-8);\r\n                max = Math.max(max, v0);\r\n                if (v0 == 1.0)\r\n                    totalOne++;\r\n            }\r\n        }\r\n        assertTrue(helper.weights[0] < helper.weights[1]);\r\n        assertTrue(helper.weights[0] < helper.weights[widthCells]);\r\n        assertEquals(1.0, max, 1e-8);\r\n        if (widthPixelsX % 2 == 1)\r\n            assertEquals(1, totalOne);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.RectifyImageOps.transformPixelToRect",
	"Comment": "creates a transform that applies rectification to unrectified distorted pixels.",
	"Method": "Point2Transform2_F64 transformPixelToRect(CameraPinholeRadial param,DMatrixRMaj rectify,Point2Transform2_F32 transformPixelToRect,CameraPinholeRadial param,FMatrixRMaj rectify){\r\n    return ImplRectifyImageOps_F32.transformPixelToRect(param, rectify);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeEncoder.bitsAtVersion",
	"Comment": "computes how many bits it takes to encode the message at this version number",
	"Method": "int bitsAtVersion(int version){\r\n    int total = 0;\r\n    for (int i = 0; i < segments.size(); i++) {\r\n        total += segments.get(i).sizeInBits(version);\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "boofcv.alg.geo.MultiViewOps.homographyStereo3Pts",
	"Comment": "computes the homography induced from a planar surface when viewed from two views using correspondences\tof three points. observations must be on the planar surface.",
	"Method": "DMatrixRMaj homographyStereo3Pts(DMatrixRMaj F,AssociatedPair p1,AssociatedPair p2,AssociatedPair p3){\r\n    HomographyInducedStereo3Pts alg = new HomographyInducedStereo3Pts();\r\n    alg.setFundamental(F, null);\r\n    if (!alg.process(p1, p2, p3))\r\n        return null;\r\n    return alg.getHomography();\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedF32.getBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "float getBand(int x,int y,int band){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    return data[getIndex(x, y, band)];\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.CalibrationPlanarGridZhang99.process",
	"Comment": "processes observed calibration point coordinates and computes camera intrinsic and extrinsic\tparameters.",
	"Method": "boolean process(List<CalibrationObservation> observations){\r\n    if (!linearEstimate(observations, initial))\r\n        return false;\r\n    status(\"Non-linear refinement\");\r\n    optimized.setNumberOfViews(observations.size());\r\n    if (!optimizedParam(observations, layout, initial, optimized, optimizer))\r\n        return false;\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.PnPLepetitEPnP.matchScale",
	"Comment": "examines the distance each point is from the centroid to determine the scaling difference\tbetween world control points and the null points.",
	"Method": "double matchScale(List<Point3D_F64> nullPts,FastQueue<Point3D_F64> controlWorldPts){\r\n    Point3D_F64 meanNull = UtilPoint3D_F64.mean(nullPts, numControl, null);\r\n    Point3D_F64 meanWorld = UtilPoint3D_F64.mean(controlWorldPts.toList(), numControl, null);\r\n    double top = 0;\r\n    double bottom = 0;\r\n    for (int i = 0; i < numControl; i++) {\r\n        Point3D_F64 wi = controlWorldPts.get(i);\r\n        Point3D_F64 ni = nullPts.get(i);\r\n        double dwx = wi.x - meanWorld.x;\r\n        double dwy = wi.y - meanWorld.y;\r\n        double dwz = wi.z - meanWorld.z;\r\n        double dnx = ni.x - meanNull.x;\r\n        double dny = ni.y - meanNull.y;\r\n        double dnz = ni.z - meanNull.z;\r\n        double n2 = dnx * dnx + dny * dny + dnz * dnz;\r\n        double w2 = dwx * dwx + dwy * dwy + dwz * dwz;\r\n        top += w2;\r\n        bottom += n2;\r\n    }\r\n    return Math.sqrt(top / bottom);\r\n}"
}, {
	"Path": "boofcv.testing.BoofTesting.findMethod",
	"Comment": "searches for a function which is a perfect match.if none it exists it checks\tto see if any matches that could accept an input of the specified type.if there\tis only one such match that is returned.",
	"Method": "Method findMethod(Class<?> type,String name,Class<?> params){\r\n    Method[] methods = type.getMethods();\r\n    List<Method> found = new ArrayList();\r\n    for (Method m : methods) {\r\n        if (m.getName().compareTo(name) != 0)\r\n            continue;\r\n        Class<?>[] a = m.getParameterTypes();\r\n        if (a.length != params.length)\r\n            continue;\r\n        boolean match = true;\r\n        for (int i = 0; i < a.length; i++) {\r\n            if (a[i] != params[i]) {\r\n                match = false;\r\n                break;\r\n            }\r\n        }\r\n        if (match) {\r\n            return m;\r\n        }\r\n        match = true;\r\n        for (int i = 0; i < a.length; i++) {\r\n            if (params[i] == a[i])\r\n                continue;\r\n            if (a[i].isPrimitive()) {\r\n                if (a[i] == Boolean.TYPE && params[i] == Boolean.class)\r\n                    continue;\r\n                if (a[i] == Byte.TYPE && params[i] == Byte.class)\r\n                    continue;\r\n                if (a[i] == Short.TYPE && params[i] == Short.class)\r\n                    continue;\r\n                if (a[i] == Integer.TYPE && params[i] == Integer.class)\r\n                    continue;\r\n                if (a[i] == Long.TYPE && params[i] == Long.class)\r\n                    continue;\r\n                if (a[i] == Float.TYPE && params[i] == Float.class)\r\n                    continue;\r\n                if (a[i] == Double.TYPE && params[i] == Double.class)\r\n                    continue;\r\n            }\r\n            if (!a[i].isAssignableFrom(params[i])) {\r\n                match = false;\r\n                break;\r\n            }\r\n        }\r\n        if (match) {\r\n            found.add(m);\r\n        }\r\n    }\r\n    if (found.size() == 1) {\r\n        return found.get(0);\r\n    }\r\n    throw new RuntimeException(\"Couldn't find matching *public* function to \" + name);\r\n}"
}, {
	"Path": "boofcv.alg.transform.pyramid.PyramidOps.declareOutput",
	"Comment": "creates an array of single band images for each layer in the provided pyramid.each image will\tbe the same size as the corresponding layer in the pyramid.",
	"Method": "O[] declareOutput(ImagePyramid<?> pyramid,Class<O> outputType){\r\n    O[] ret = (O[]) Array.newInstance(outputType, pyramid.getNumLayers());\r\n    for (int i = 0; i < ret.length; i++) {\r\n        int w = pyramid.getWidth(i);\r\n        int h = pyramid.getHeight(i);\r\n        ret[i] = GeneralizedImageOps.createSingleBand(outputType, w, h);\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.PairwiseImageGraph.findCameraMotions",
	"Comment": "finds all motions which are observations of the specified camera entirely, src and dst",
	"Method": "List<Motion> findCameraMotions(Camera target,List<Motion> storage){\r\n    if (storage == null)\r\n        storage = new ArrayList();\r\n    for (int i = 0; i < edges.size(); i++) {\r\n        Motion m = edges.get(i);\r\n        if (m.viewSrc.camera == target && m.viewDst.camera == target) {\r\n            storage.add(m);\r\n        }\r\n    }\r\n    return storage;\r\n}"
}, {
	"Path": "boofcv.gui.feature.AssociationScorePanel.drawDistribution",
	"Comment": "visualizes score distribution.larger circles mean its closer to the best\tfit score.",
	"Method": "void drawDistribution(Graphics2D g2,List<Point2D_F64> candidates,int offX,int offY,double scale){\r\n    findStatistics();\r\n    g2.setColor(Color.RED);\r\n    g2.setStroke(new BasicStroke(3));\r\n    double normalizer;\r\n    if (scorer.getScoreType().isZeroBest())\r\n        normalizer = best * containmentFraction;\r\n    else\r\n        normalizer = Math.abs(best) * (Math.exp(-1.0 / containmentFraction));\r\n    for (int i = 0; i < candidates.size(); i++) {\r\n        Point2D_F64 p = candidates.get(i);\r\n        double s = associationScore[i];\r\n        double ratio = 1 - Math.abs(s - best) / normalizer;\r\n        if (ratio < 0)\r\n            continue;\r\n        int r = maxCircleRadius - (int) (maxCircleRadius * ratio);\r\n        if (r > 0) {\r\n            int x = (int) (p.x * scale + offX);\r\n            int y = (int) (p.y * scale + offY);\r\n            g2.drawOval(x - r, y - r, r * 2 + 1, r * 2 + 1);\r\n        }\r\n    }\r\n    g2.setColor(Color.GREEN);\r\n    g2.setStroke(new BasicStroke(10));\r\n    int w = maxCircleRadius * 2 + 1;\r\n    Point2D_F64 p = candidates.get(indexBest);\r\n    int x = (int) (p.x * scale + offX);\r\n    int y = (int) (p.y * scale + offY);\r\n    g2.drawOval(x - maxCircleRadius, y - maxCircleRadius, w, w);\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.normalized.TestConvolveNormalizedNaive_SB.vertical2_U16_U8",
	"Comment": "check it against one specific type to see if the core algorithm is correct",
	"Method": "void vertical2_U16_U8(){\r\n    Kernel1D_S32 kernelY = new Kernel1D_S32(new int[] { 1, 2, 3, 4, 5, 6 }, 6, 4);\r\n    Kernel1D_S32 kernelX = new Kernel1D_S32(new int[] { 4, 2, 1, 4, 3, 6 }, 5, 2);\r\n    GrayU16 input = new GrayU16(15, 16);\r\n    ImageMiscOps.fillUniform(input, rand, 0, 80);\r\n    GrayU8 output = new GrayU8(15, 16);\r\n    ConvolveNormalizedNaive_SB.vertical(kernelX, kernelY, input, output);\r\n    GrayU8 alt = new GrayU8(15, 16);\r\n    ConvolveImageNoBorder.vertical(kernelY, input, alt, kernelX.computeSum() * kernelY.computeSum());\r\n    for (int y = 0; y < output.height; y++) {\r\n        for (int x = 0; x < output.width; x++) {\r\n            int expected = vertical2(x, y, kernelX, kernelY, input);\r\n            int found = output.get(x, y);\r\n            assertEquals(expected, found);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeBinaryGridToPixel.removeOutsideCornerFeatures",
	"Comment": "outside corners on position patterns are more likely to be damaged, so remove them",
	"Method": "void removeOutsideCornerFeatures(){\r\n    if (pairs.size() != storagePairs.size)\r\n        throw new RuntimeException(\"This can only be called when all the features have been added\");\r\n    pairs.remove(11);\r\n    pairs.remove(5);\r\n    pairs.remove(0);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.GridRansacLineDetector.convertToLineSegment",
	"Comment": "lines are found in polar form and this coverts them into line segments by finding\tthe extreme points of points on the line.",
	"Method": "LineSegment2D_F32 convertToLineSegment(List<Edgel> matchSet,LinePolar2D_F32 model){\r\n    float minT = Float.MAX_VALUE;\r\n    float maxT = -Float.MAX_VALUE;\r\n    LineParametric2D_F32 line = UtilLine2D_F32.convert(model, (LineParametric2D_F32) null);\r\n    Point2D_F32 p = new Point2D_F32();\r\n    for (Edgel e : matchSet) {\r\n        p.set(e.x, e.y);\r\n        float t = ClosestPoint2D_F32.closestPointT(line, e);\r\n        if (minT > t)\r\n            minT = t;\r\n        if (maxT < t)\r\n            maxT = t;\r\n    }\r\n    LineSegment2D_F32 segment = new LineSegment2D_F32();\r\n    segment.a.x = line.p.x + line.slope.x * minT;\r\n    segment.a.y = line.p.y + line.slope.y * minT;\r\n    segment.b.x = line.p.x + line.slope.x * maxT;\r\n    segment.b.y = line.p.y + line.slope.y * maxT;\r\n    return segment;\r\n}"
}, {
	"Path": "boofcv.abst.tracker.GenericTrackerObjectRectangleTests.reinitialize",
	"Comment": "see if it correctly reinitializes.should produce identical results when given the same inputs after\tbeing reinitialized.",
	"Method": "void reinitialize(){\r\n    Quadrilateral_F64 where1 = new Quadrilateral_F64();\r\n    TrackerObjectQuad<T> tracker = create(imageType);\r\n    render(1, 0, 0);\r\n    assertTrue(tracker.initialize(input, initRegion));\r\n    render(1, 3, -3);\r\n    assertTrue(tracker.process(input, where));\r\n    render(1, 6, -6);\r\n    assertTrue(tracker.process(input, where));\r\n    render(1, 0, 0);\r\n    assertTrue(tracker.initialize(input, initRegion));\r\n    render(1, 3, -3);\r\n    assertTrue(tracker.process(input, where1));\r\n    render(1, 6, -6);\r\n    assertTrue(tracker.process(input, where1));\r\n    checkSolution(where1.a.x, where1.a.y, where1.c.x, where1.c.y, 0.02);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.computeSideError",
	"Comment": "scores a side based on the sum of euclidean distance squared of each point along the line. euclidean squared\tis used because its fast to compute",
	"Method": "double computeSideError(List<Point2D_I32> contour,int indexA,int indexB){\r\n    assignLine(contour, indexA, indexB, line);\r\n    int numSamples;\r\n    double sumOfDistances = 0;\r\n    int length;\r\n    if (indexB >= indexA) {\r\n        length = indexB - indexA - 1;\r\n        numSamples = Math.min(length, maxNumberOfSideSamples);\r\n        for (int i = 0; i < numSamples; i++) {\r\n            int index = indexA + 1 + length * i / numSamples;\r\n            Point2D_I32 p = contour.get(index);\r\n            sumOfDistances += Distance2D_F64.distanceSq(line, p.x, p.y);\r\n        }\r\n        sumOfDistances /= numSamples;\r\n    } else {\r\n        length = contour.size() - indexA - 1 + indexB;\r\n        numSamples = Math.min(length, maxNumberOfSideSamples);\r\n        for (int i = 0; i < numSamples; i++) {\r\n            int where = length * i / numSamples;\r\n            int index = (indexA + 1 + where) % contour.size();\r\n            Point2D_I32 p = contour.get(index);\r\n            sumOfDistances += Distance2D_F64.distanceSq(line, p.x, p.y);\r\n        }\r\n        sumOfDistances /= numSamples;\r\n    }\r\n    if (numSamples > 0)\r\n        return sumOfDistances;\r\n    else\r\n        return 0;\r\n}"
}, {
	"Path": "org.boon.collections.IntList.toIntList",
	"Comment": "creates a primitive list based on an input list and a property path",
	"Method": "IntList toIntList(Collection<?> inputList,String propertyPath){\r\n    if (inputList.size() == 0) {\r\n        return new IntList(0);\r\n    }\r\n    IntList outputList = new IntList(inputList.size());\r\n    if (propertyPath.contains(\".\") || propertyPath.contains(\"[\")) {\r\n        String[] properties = StringScanner.splitByDelimiters(propertyPath, \".[]\");\r\n        for (Object o : inputList) {\r\n            outputList.add(BeanUtils.getPropertyInt(o, properties));\r\n        }\r\n    } else {\r\n        Map<String, FieldAccess> fields = BeanUtils.getFieldsFromObject(inputList.iterator().next());\r\n        FieldAccess fieldAccess = fields.get(propertyPath);\r\n        for (Object o : inputList) {\r\n            outputList.add(fieldAccess.getInt(o));\r\n        }\r\n    }\r\n    return outputList;\r\n}"
}, {
	"Path": "org.boon.core.reflection.Annotations.doGetPropertyDescriptor",
	"Comment": "this needs to be refactored and put into reflection or something.",
	"Method": "PropertyDescriptor doGetPropertyDescriptor(Class<?> type,String propertyName){\r\n    try {\r\n        BeanInfo beanInfo = Introspector.getBeanInfo(type);\r\n        PropertyDescriptor[] propertyDescriptors = beanInfo.getPropertyDescriptors();\r\n        for (PropertyDescriptor pd : propertyDescriptors) {\r\n            if (pd.getName().equals(propertyName)) {\r\n                return pd;\r\n            }\r\n        }\r\n        Class<?> superclass = type.getSuperclass();\r\n        if (superclass != null) {\r\n            return doGetPropertyDescriptor(superclass, propertyName);\r\n        }\r\n        return null;\r\n    } catch (Exception ex) {\r\n        throw new RuntimeException(\"Unable to get property \" + propertyName + \" for class \" + type, ex);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.TestKltTracker.testSubImages",
	"Comment": "process the same features in two different sets of image.only difference is that one is a sub image\tresults should be identical",
	"Method": "void testSubImages(){\r\n    ImageMiscOps.fillUniform(image, rand, 0, 100);\r\n    GradientSobel.process(image, derivX, derivY, new ImageBorder1D_F32(BorderIndex1D_Extend.class));\r\n    KltTracker<GrayF32, GrayF32> trackerA = createDefaultTracker();\r\n    trackerA.setImage(image, derivX, derivY);\r\n    KltTracker<GrayF32, GrayF32> trackerB = createDefaultTracker();\r\n    GrayF32 image = BoofTesting.createSubImageOf(this.image);\r\n    GrayF32 derivX = BoofTesting.createSubImageOf(this.derivX);\r\n    GrayF32 derivY = BoofTesting.createSubImageOf(this.derivY);\r\n    trackerB.setImage(image, derivX, derivY);\r\n    for (int y = 0; y < imageHeight; y += 4) {\r\n        for (int x = 0; x < imageWidth; x += 4) {\r\n            KltFeature featureA = new KltFeature(3);\r\n            KltFeature featureB = new KltFeature(3);\r\n            featureA.setPosition(x, y);\r\n            featureB.setPosition(x, y);\r\n            trackerA.setDescription(featureA);\r\n            trackerB.setDescription(featureB);\r\n            float dx = rand.nextFloat() * 2 - 1;\r\n            float dy = rand.nextFloat() * 2 - 1;\r\n            featureA.setPosition(x + dx, y + dy);\r\n            featureB.setPosition(x + dx, y + dy);\r\n            KltTrackFault faultA = trackerA.track(featureA);\r\n            KltTrackFault faultB = trackerB.track(featureB);\r\n            assertTrue(faultA == faultB);\r\n            if (x == 4)\r\n                System.out.println();\r\n            if (faultA == KltTrackFault.SUCCESS) {\r\n                assertTrue(featureA.x == featureB.x);\r\n                assertTrue(featureA.y == featureB.y);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.transform.wavelet.impl.TestImplWaveletTransformNaive.encodeDecode_I32",
	"Comment": "see if it can handle odd image sizes and output with extra padding",
	"Method": "void encodeDecode_I32(){\r\n    testEncodeDecode_I32(20, 30, 20, 30);\r\n    testEncodeDecode_I32(19, 29, 20, 30);\r\n    testEncodeDecode_I32(19, 29, 22, 32);\r\n    testEncodeDecode_I32(19, 29, 24, 34);\r\n    testEncodeDecode_I32(20, 30, 24, 34);\r\n}"
}, {
	"Path": "boofcv.gui.JavaRuntimeLauncher.monitorSlave",
	"Comment": "prints printout the standard printout and error from the slave and checks its health.exits ifthe slave has finished or is declared frozen.",
	"Method": "boolean monitorSlave(Process pr,BufferedReader input,BufferedReader error){\r\n    System.in.skip(System.in.available());\r\n    boolean frozen = false;\r\n    long startTime = System.currentTimeMillis();\r\n    long lastAliveMessage = startTime;\r\n    for (; ; ) {\r\n        while (System.in.available() > 0) {\r\n            if (System.in.read() == 'q') {\r\n                System.out.println(\"User requested for the application to quit by pressing 'q'\");\r\n                System.exit(0);\r\n            }\r\n        }\r\n        synchronized (streamLock) {\r\n            printBuffer(error, printErr);\r\n        }\r\n        if (input.ready()) {\r\n            synchronized (streamLock) {\r\n                printBuffer(input, printOut);\r\n            }\r\n        } else {\r\n            Thread.sleep(500);\r\n        }\r\n        try {\r\n            pr.exitValue();\r\n            break;\r\n        } catch (IllegalThreadStateException e) {\r\n            if (killRequested) {\r\n                pr.destroy();\r\n                break;\r\n            }\r\n            if (frozenTime > 0 && System.currentTimeMillis() - startTime > frozenTime) {\r\n                pr.destroy();\r\n                frozen = true;\r\n                break;\r\n            }\r\n            if (System.currentTimeMillis() - lastAliveMessage > 60000) {\r\n                System.out.println(\"\\nMaster is still alive: \" + new Date() + \"  Press 'q' and enter to quit.\");\r\n                lastAliveMessage = System.currentTimeMillis();\r\n            }\r\n        }\r\n    }\r\n    synchronized (streamLock) {\r\n        printBuffer(error, printErr);\r\n        printBuffer(input, printOut);\r\n    }\r\n    durationMilli = System.currentTimeMillis() - startTime;\r\n    return !frozen && !killRequested;\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.TestDistanceEpipolarConstraint.basicCheck",
	"Comment": "give it a perfect observation and a noisy one.perfect should have a smaller distance",
	"Method": "void basicCheck(){\r\n    DistanceEpipolarConstraint alg = new DistanceEpipolarConstraint();\r\n    alg.setModel(F);\r\n    double perfect = alg.computeDistance(new AssociatedPair(p1, p2));\r\n    p1.x += 0.2;\r\n    p1.y += 0.2;\r\n    double noisy = alg.computeDistance(new AssociatedPair(p1, p2));\r\n    assertTrue(perfect < noisy * 0.1);\r\n}"
}, {
	"Path": "boofcv.io.image.ConvertBufferedImage.convertFrom",
	"Comment": "converts a buffered image into an image of the specified type.",
	"Method": "void convertFrom(BufferedImage src,T dst,boolean orderRgb,T convertFrom,BufferedImage src,boolean orderRgb,ImageType<T> imageType,T convertFrom,BufferedImage src,boolean orderRgb,T output,GrayU8 convertFrom,BufferedImage src,GrayU8 dst,T convertFrom,BufferedImage src,T dst,Class<T> type,GrayF32 convertFrom,BufferedImage src,GrayF32 dst,T convertFrom,BufferedImage src,Class type,boolean orderRgb){\r\n    T dst;\r\n    if (ImageGray.class.isAssignableFrom(type)) {\r\n        dst = (T) convertFromSingle(src, null, type);\r\n    } else if (ImageInterleaved.class.isAssignableFrom(type)) {\r\n        dst = (T) GeneralizedImageOps.createInterleaved(type, 1, 1, 3);\r\n        convertFromInterleaved(src, (ImageInterleaved) dst, orderRgb);\r\n    } else {\r\n        dst = (T) new Planar(GrayU8.class, 1, 1, 3);\r\n        convertFrom(src, dst, orderRgb);\r\n    }\r\n    return dst;\r\n}"
}, {
	"Path": "boofcv.struct.image.ImageType.isSameType",
	"Comment": "returns true if the passed in imagetype is the same as this image type",
	"Method": "boolean isSameType(ImageType o){\r\n    if (family != o.family)\r\n        return false;\r\n    if (dataType != o.dataType)\r\n        return false;\r\n    if (numBands != o.numBands)\r\n        return false;\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.descriptor.DescriptorDistance.hamming",
	"Comment": "computes the hamming distance between two binary feature descriptors",
	"Method": "int hamming(TupleDesc_B a,TupleDesc_B b,int hamming,int val){\r\n    int c;\r\n    int v = val;\r\n    v = v - ((v >> 1) & 0x55555555);\r\n    v = (v & 0x33333333) + ((v >> 2) & 0x33333333);\r\n    c = ((v + (v >> 4) & 0xF0F0F0F) * 0x1010101) >> 24;\r\n    return c;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonFromContour.getContour",
	"Comment": "returns the undistorted contour for a shape. data is potentially recycled the next time\tany function in this class is invoked.",
	"Method": "List<Point2D_I32> getContour(Info info){\r\n    contourTmp.reset();\r\n    contourFinder.loadContour(info.contour.externalIndex, contourTmp);\r\n    return contourTmp.toList();\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.GenericPlanarCalibrationDetectorChecks.pinhole_radial_fullview",
	"Comment": "simulated scene using a pinhole camera model with radial distortion. entire target is visible",
	"Method": "void pinhole_radial_fullview(){\r\n    CameraPinholeRadial model = CalibrationIO.load(getClass().getResource(\"pinhole_radial.yaml\"));\r\n    SimulatePlanarWorld simulator = new SimulatePlanarWorld();\r\n    simulator.setCamera(model);\r\n    List<Point2D_F64> locations2D = new ArrayList();\r\n    GrayF32 pattern = new GrayF32(1, 1);\r\n    for (int i = 0; i < targetConfigs.size(); i++) {\r\n        failedToDetect = 0;\r\n        DetectorFiducialCalibration detector = createDetector(targetConfigs.get(i));\r\n        renderTarget(targetConfigs.get(i), simulatedTargetWidth, pattern, locations2D);\r\n        simulator.resetScene();\r\n        Se3_F64 markerToWorld = new Se3_F64();\r\n        ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI, 0, markerToWorld.R);\r\n        simulator.addSurface(markerToWorld, simulatedTargetWidth, pattern);\r\n        markerToWorld.T.set(0, 0, 0.5);\r\n        checkRenderedResults(detector, simulator, locations2D);\r\n        markerToWorld.T.set(0, 0, 1);\r\n        checkRenderedResults(detector, simulator, locations2D);\r\n        markerToWorld.T.set(-0.33, 0, 1);\r\n        checkRenderedResults(detector, simulator, locations2D);\r\n        ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI - 1, 0, markerToWorld.getR());\r\n        checkRenderedResults(detector, simulator, locations2D);\r\n        ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI - 1, 0.8, markerToWorld.getR());\r\n        checkRenderedResults(detector, simulator, locations2D);\r\n        markerToWorld.T.set(-0.33, 0.33, 1);\r\n        ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI - 1, 0.8, markerToWorld.getR());\r\n        checkRenderedResults(detector, simulator, locations2D);\r\n        markerToWorld.T.set(0, -0.20, 1);\r\n        ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0.8, Math.PI, 0.8, markerToWorld.getR());\r\n        checkRenderedResults(detector, simulator, locations2D);\r\n        ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0.8, Math.PI, 1.8, markerToWorld.getR());\r\n        checkRenderedResults(detector, simulator, locations2D);\r\n        markerToWorld.T.set(0, -0.15, 1);\r\n        ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0.2, Math.PI, 2.4, markerToWorld.getR());\r\n        checkRenderedResults(detector, simulator, locations2D);\r\n    }\r\n    assertEquals(0, failedToDetect);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.DetectFiducialSquareBinary.setAmbiguityThreshold",
	"Comment": "parameters which specifies how tolerant it is of a square being ambiguous black or white.",
	"Method": "void setAmbiguityThreshold(double ambiguityThreshold){\r\n    if (ambiguityThreshold < 0 || ambiguityThreshold > 1)\r\n        throw new IllegalArgumentException(\"Must be from 0 to 1, inclusive\");\r\n    this.ambiguityThreshold = ambiguityThreshold;\r\n}"
}, {
	"Path": "boofcv.alg.misc.GImageStatistics.sum",
	"Comment": "returns the sum of all the pixels in the image across all bands.",
	"Method": "double sum(ImageBase input){\r\n    if (input instanceof ImageGray) {\r\n        if (GrayU8.class == input.getClass()) {\r\n            return ImageStatistics.sum((GrayU8) input);\r\n        } else if (GrayS8.class == input.getClass()) {\r\n            return ImageStatistics.sum((GrayS8) input);\r\n        } else if (GrayU16.class == input.getClass()) {\r\n            return ImageStatistics.sum((GrayU16) input);\r\n        } else if (GrayS16.class == input.getClass()) {\r\n            return ImageStatistics.sum((GrayS16) input);\r\n        } else if (GrayS32.class == input.getClass()) {\r\n            return ImageStatistics.sum((GrayS32) input);\r\n        } else if (GrayS64.class == input.getClass()) {\r\n            return ImageStatistics.sum((GrayS64) input);\r\n        } else if (GrayF32.class == input.getClass()) {\r\n            return ImageStatistics.sum((GrayF32) input);\r\n        } else if (GrayF64.class == input.getClass()) {\r\n            return ImageStatistics.sum((GrayF64) input);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type\");\r\n        }\r\n    } else if (input instanceof ImageInterleaved) {\r\n        if (InterleavedU8.class == input.getClass()) {\r\n            return ImageStatistics.sum((InterleavedU8) input);\r\n        } else if (InterleavedS8.class == input.getClass()) {\r\n            return ImageStatistics.sum((InterleavedS8) input);\r\n        } else if (InterleavedU16.class == input.getClass()) {\r\n            return ImageStatistics.sum((InterleavedU16) input);\r\n        } else if (InterleavedS16.class == input.getClass()) {\r\n            return ImageStatistics.sum((InterleavedS16) input);\r\n        } else if (InterleavedS32.class == input.getClass()) {\r\n            return ImageStatistics.sum((InterleavedS32) input);\r\n        } else if (InterleavedS64.class == input.getClass()) {\r\n            return ImageStatistics.sum((InterleavedS64) input);\r\n        } else if (InterleavedF32.class == input.getClass()) {\r\n            return ImageStatistics.sum((InterleavedF32) input);\r\n        } else if (InterleavedF64.class == input.getClass()) {\r\n            return ImageStatistics.sum((InterleavedF64) input);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type\");\r\n        }\r\n    } else if (input instanceof Planar) {\r\n        double sum = 0;\r\n        Planar in = (Planar) input;\r\n        for (int i = 0; i < in.getNumBands(); i++) {\r\n            sum += sum(in.getBand(i));\r\n        }\r\n        return sum;\r\n    } else {\r\n        throw new IllegalArgumentException(\"Planar image support needs to be added\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedF32.setBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "void setBand(int x,int y,int band,float value){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    data[getIndex(x, y, band)] = value;\r\n}"
}, {
	"Path": "boofcv.alg.transform.ii.GIntegralImageOps.convolve",
	"Comment": "general code for convolving a box filter across an image using the integral image.",
	"Method": "T convolve(T integral,IntegralKernel kernel,T output){\r\n    if (integral instanceof GrayF32) {\r\n        return (T) IntegralImageOps.convolve((GrayF32) integral, kernel, (GrayF32) output);\r\n    } else if (integral instanceof GrayF64) {\r\n        return (T) IntegralImageOps.convolve((GrayF64) integral, kernel, (GrayF64) output);\r\n    } else if (integral instanceof GrayS32) {\r\n        return (T) IntegralImageOps.convolve((GrayS32) integral, kernel, (GrayS32) output);\r\n    } else if (integral instanceof GrayS64) {\r\n        return (T) IntegralImageOps.convolve((GrayS64) integral, kernel, (GrayS64) output);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown input type: \" + integral.getClass().getSimpleName());\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.DescribePointBrief.process",
	"Comment": "computes the descriptor at the specified point.if the region go outside of the image then a description\twill not be made.",
	"Method": "void process(double c_x,double c_y,TupleDesc_B feature){\r\n    describe.process((int) c_x, (int) c_y, feature);\r\n}"
}, {
	"Path": "boofcv.examples.features.ExampleTemplateMatching.drawRectangles",
	"Comment": "helper function will is finds matches and displays the results as colored rectangles",
	"Method": "void drawRectangles(Graphics2D g2,GrayF32 image,GrayF32 template,GrayF32 mask,int expectedMatches){\r\n    List<Match> found = findMatches(image, template, mask, expectedMatches);\r\n    int r = 2;\r\n    int w = template.width + 2 * r;\r\n    int h = template.height + 2 * r;\r\n    for (Match m : found) {\r\n        System.out.println(\"Match \" + m.x + \" \" + m.y + \"    score \" + m.score);\r\n        int x0 = m.x - r;\r\n        int y0 = m.y - r;\r\n        int x1 = x0 + w;\r\n        int y1 = y0 + h;\r\n        g2.drawLine(x0, y0, x1, y0);\r\n        g2.drawLine(x1, y0, x1, y1);\r\n        g2.drawLine(x1, y1, x0, y1);\r\n        g2.drawLine(x0, y1, x0, y0);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareCrossClustersIntoGrids.firstRow2",
	"Comment": "adds the first row to the list of rows when the seed element has two edges",
	"Method": "List<SquareNode> firstRow2(SquareNode seed){\r\n    int indexLower = lowerEdgeIndex(seed);\r\n    int indexUpper = addOffset(indexLower, 1, seed.square.size());\r\n    List<SquareNode> listDown = new ArrayList();\r\n    List<SquareNode> list = new ArrayList();\r\n    if (!addToRow(seed, indexUpper, 1, true, listDown))\r\n        return null;\r\n    flipAdd(listDown, list);\r\n    list.add(seed);\r\n    seed.graph = 0;\r\n    if (!addToRow(seed, indexLower, -1, true, list))\r\n        return null;\r\n    return list;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareCrossClustersIntoGrids.firstRow1",
	"Comment": "adds the first row to the list of rows when the seed element has only one edge",
	"Method": "List<SquareNode> firstRow1(SquareNode seed){\r\n    for (int i = 0; i < seed.square.size(); i++) {\r\n        if (isOpenEdge(seed, i)) {\r\n            List<SquareNode> list = new ArrayList();\r\n            seed.graph = 0;\r\n            int corner = seed.edges[i].destinationSide(seed);\r\n            SquareNode dst = seed.edges[i].destination(seed);\r\n            int l = addOffset(corner, -1, dst.square.size());\r\n            int u = addOffset(corner, 1, dst.square.size());\r\n            if (dst.edges[u] != null) {\r\n                list.add(seed);\r\n                if (!addToRow(seed, i, -1, true, list))\r\n                    return null;\r\n            } else if (dst.edges[l] != null) {\r\n                List<SquareNode> tmp = new ArrayList();\r\n                if (!addToRow(seed, i, 1, true, tmp))\r\n                    return null;\r\n                flipAdd(tmp, list);\r\n                list.add(seed);\r\n            } else {\r\n                list.add(seed);\r\n            }\r\n            return list;\r\n        }\r\n    }\r\n    throw new RuntimeException(\"BUG\");\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestLensDistortionOps.transformChangeModel_F32_FULLVIEW",
	"Comment": "checks the border of the returned transform.makes sure that the entire original image is visible.\talso makes sure that the requested inverse transform is actually the inverse.",
	"Method": "void transformChangeModel_F32_FULLVIEW(){\r\n    CameraPinholeRadial param = new CameraPinholeRadial().fsetK(300, 320, 0, 150, 130, width, height).fsetRadial(0.1, 0.05);\r\n    CameraPinhole desired = new CameraPinhole(param);\r\n    Point2Transform2_F32 adjToDist = LensDistortionOps.transformChangeModel_F32(AdjustmentType.FULL_VIEW, param, desired, true, null);\r\n    Point2Transform2_F32 distToAdj = LensDistortionOps.transformChangeModel_F32(AdjustmentType.FULL_VIEW, param, desired, false, null);\r\n    checkBorderOutside(adjToDist, distToAdj);\r\n    param = new CameraPinholeRadial().fsetK(300, 320, 0, 150, 130, width, height).fsetRadial(-0.1, -0.05);\r\n    desired = new CameraPinhole(param);\r\n    adjToDist = LensDistortionOps.transformChangeModel_F32(AdjustmentType.FULL_VIEW, param, desired, true, null);\r\n    distToAdj = LensDistortionOps.transformChangeModel_F32(AdjustmentType.FULL_VIEW, param, desired, false, null);\r\n    checkBorderOutside(adjToDist, distToAdj);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.getAcquireRetryDelay",
	"Comment": "returns the acquireretrydelay setting with the specified granularity.",
	"Method": "long getAcquireRetryDelay(long getAcquireRetryDelay,TimeUnit timeUnit){\r\n    return timeUnit.convert(this.acquireRetryDelayInMs, TimeUnit.MILLISECONDS);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoPlaneInfinity.concatMotion",
	"Comment": "add motion estimate from key frame into the estimate from world",
	"Method": "void concatMotion(){\r\n    currToKey.concat(keyToWorld, temp);\r\n    keyToWorld.set(temp);\r\n    currToKey.reset();\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.LinearContourLabelChang2004.process",
	"Comment": "processes the binary image to find the contour of and label blobs.",
	"Method": "void process(GrayU8 binary,GrayS32 labeled){\r\n    labeled.reshape(binary.width, binary.height);\r\n    if (border.width != binary.width + 2 || border.height != binary.height + 2) {\r\n        border.reshape(binary.width + 2, binary.height + 2);\r\n        ImageMiscOps.fillBorder(border, 0, 1);\r\n    }\r\n    border.subimage(1, 1, border.width - 1, border.height - 1, null).setTo(binary);\r\n    ImageMiscOps.fill(labeled, 0);\r\n    binary = border;\r\n    packedPoints.reset();\r\n    contours.reset();\r\n    tracer.setInputs(binary, labeled, packedPoints);\r\n    int endY = binary.height - 1, enxX = binary.width - 1;\r\n    for (y = 1; y < endY; y++) {\r\n        indexIn = binary.startIndex + y * binary.stride + 1;\r\n        indexOut = labeled.startIndex + (y - 1) * labeled.stride;\r\n        x = 1;\r\n        int delta = scanForOne(binary.data, indexIn, indexIn + enxX - x) - indexIn;\r\n        x += delta;\r\n        indexIn += delta;\r\n        indexOut += delta;\r\n        while (x < enxX) {\r\n            int label = labeled.data[indexOut];\r\n            boolean handled = false;\r\n            if (label == 0 && binary.data[indexIn - binary.stride] != 1) {\r\n                handleStep1();\r\n                handled = true;\r\n                label = contours.size;\r\n            }\r\n            if (binary.data[indexIn + binary.stride] == 0) {\r\n                handleStep2(labeled, label);\r\n                handled = true;\r\n            }\r\n            if (!handled) {\r\n                if (labeled.data[indexOut] == 0)\r\n                    labeled.data[indexOut] = labeled.data[indexOut - 1];\r\n            }\r\n            delta = scanForOne(binary.data, indexIn + 1, indexIn + enxX - x) - indexIn;\r\n            x += delta;\r\n            indexIn += delta;\r\n            indexOut += delta;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.TestSelectRectSubpixel_F32_F32.addSubpixelBias",
	"Comment": "given different local error values see if it is closer to the value with a smaller error",
	"Method": "void addSubpixelBias(){\r\n    GrayF32 img = new GrayF32(w, h);\r\n    SelectRectSubpixel.F32_F32 alg = new SelectRectSubpixel.F32_F32(-1, -1, -1);\r\n    alg.configure(img, 0, 20, 2);\r\n    alg.setLocalMax(20);\r\n    alg.columnScore[4] = 100;\r\n    alg.columnScore[5] = 50;\r\n    alg.columnScore[6] = 200;\r\n    alg.setDisparity(4, 5);\r\n    assertTrue(img.data[4] < 5 && img.data[4] > 4);\r\n    alg.columnScore[4] = 200;\r\n    alg.columnScore[6] = 100;\r\n    alg.setDisparity(4, 5);\r\n    assertTrue(img.data[4] < 6 && img.data[4] > 5);\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.impl.GeneralBilinearRectangleChecks.checkBottomRightEdge",
	"Comment": "see if it handles edge conditions gracefully.should be barely inside",
	"Method": "void checkBottomRightEdge(){\r\n    checkRegion(10, 15, 0, 0);\r\n    checkRegion(10, 15, width - 10 - 1, height - 15 - 1);\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.SurfDescribeOps.rotatedWidth",
	"Comment": "computes the width of a square containment region that contains a rotated rectangle.",
	"Method": "double rotatedWidth(double width,double c,double s){\r\n    return Math.abs(c) * width + Math.abs(s) * width;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.StatementHandle.setDebugHandle",
	"Comment": "sets a debughandle, an object that is not used by the connection pool at all but may be set by an application to track\tthis particular connection handle for any purpose it deems fit.",
	"Method": "void setDebugHandle(Object debugHandle){\r\n    this.debugHandle = debugHandle;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.gui.controller.LogController.trimExcessLines",
	"Comment": "when text area contains more lines than maxlines, the lines at the beginning will be trimmed off.",
	"Method": "void trimExcessLines(){\r\n    final int numLinesToTrunk = textArea.getLineCount() - maxLines;\r\n    if (numLinesToTrunk > 0) {\r\n        try {\r\n            final int posOfLastLineToTrunk = textArea.getLineEndOffset(numLinesToTrunk - 1);\r\n            textArea.replaceRange(\"\", 0, posOfLastLineToTrunk);\r\n        } catch (final BadLocationException e) {\r\n            maxLines = Integer.MAX_VALUE;\r\n            System.err.println(\"Error trimming text area, trimming will be disabled!\");\r\n            ConsolePrintStream.printException(e);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.BoofSwingUtil.antialiasing",
	"Comment": "sets rendering hints that will enable antialiasing and make sub pixel rendering look good",
	"Method": "void antialiasing(Graphics2D g2){\r\n    g2.setRenderingHint(RenderingHints.KEY_STROKE_CONTROL, RenderingHints.VALUE_STROKE_PURE);\r\n    g2.setRenderingHint(RenderingHints.KEY_ANTIALIASING, RenderingHints.VALUE_ANTIALIAS_ON);\r\n}"
}, {
	"Path": "boofcv.alg.descriptor.TestDescriptorDistance.ncc_self_distance",
	"Comment": "when a correctly computed ncc descriptor is compared against itself the distance should be one",
	"Method": "void ncc_self_distance(){\r\n    NccFeature a = new NccFeature(5);\r\n    for (int i = 0; i < a.value.length; i++) a.value[i] = i * i;\r\n    double mean = 0;\r\n    for (int i = 0; i < a.value.length; i++) mean += a.value[i];\r\n    mean /= a.size();\r\n    double sigma = 0;\r\n    for (int i = 0; i < a.value.length; i++) {\r\n        double d = a.value[i] -= mean;\r\n        sigma += d * d;\r\n    }\r\n    sigma /= a.size();\r\n    a.mean = mean;\r\n    a.sigma = Math.sqrt(sigma);\r\n    assertEquals(1, DescriptorDistance.ncc(a, a), 1e-2);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.TestSquaresIntoCrossClusters.process_connect_threshold",
	"Comment": "tests the corner distance threshold.two nodes should be barely within tolerance of each other with the 3rd\tbarely not in tolerance",
	"Method": "void process_connect_threshold(){\r\n    SquaresIntoCrossClusters alg = new SquaresIntoCrossClusters(0.2, -1);\r\n    List<DetectPolygonFromContour.Info> squares = new ArrayList();\r\n    squares.add(createSquare(5, 6));\r\n    squares.add(createSquare(6.20001, 7));\r\n    squares.add(createSquare(6.1999999, 5));\r\n    List<List<SquareNode>> clusters = alg.process(squares);\r\n    assertEquals(2, clusters.size());\r\n}"
}, {
	"Path": "boofcv.alg.geo.MultiViewOps.projectiveToMetricKnownK",
	"Comment": "convert the projective camera matrix into a metric transform given the rectifying homography and a\tknown calibration matrix.",
	"Method": "void projectiveToMetricKnownK(DMatrixRMaj cameraMatrix,DMatrixRMaj H,DMatrixRMaj K,Se3_F64 worldToView){\r\n    DMatrixRMaj tmp = new DMatrixRMaj(3, 4);\r\n    CommonOps_DDRM.mult(cameraMatrix, H, tmp);\r\n    DMatrixRMaj K_inv = new DMatrixRMaj(3, 3);\r\n    CommonOps_DDRM.invert(K, K_inv);\r\n    DMatrixRMaj P = new DMatrixRMaj(3, 4);\r\n    CommonOps_DDRM.mult(K_inv, tmp, P);\r\n    CommonOps_DDRM.extract(P, 0, 0, worldToView.R);\r\n    worldToView.T.x = P.get(0, 3);\r\n    worldToView.T.y = P.get(1, 3);\r\n    worldToView.T.z = P.get(2, 3);\r\n    SingularValueDecomposition_F64<DMatrixRMaj> svd = DecompositionFactory_DDRM.svd(true, true, true);\r\n    DMatrixRMaj R = worldToView.R;\r\n    if (!svd.decompose(R))\r\n        throw new RuntimeException(\"SVD Failed\");\r\n    CommonOps_DDRM.multTransB(svd.getU(null, false), svd.getV(null, false), R);\r\n    double det = CommonOps_DDRM.det(R);\r\n    if (det < 0) {\r\n        CommonOps_DDRM.scale(-1, R);\r\n        worldToView.T.scale(-1);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationBase.getMinimumProjectives",
	"Comment": "minimum number of cameras required to estimate the parameters.",
	"Method": "int getMinimumProjectives(){\r\n    return minimumProjectives;\r\n}"
}, {
	"Path": "boofcv.android.camera.VideoRenderProcessing.imageToOutput",
	"Comment": "converts a coordinate from pixel to the output image coordinates",
	"Method": "void imageToOutput(double x,double y,Point2D_F64 pt){\r\n    pt.x = x / scale - tranX / scale;\r\n    pt.y = y / scale - tranY / scale;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.pokemon.PokemonCalculationUtils.gymDefense",
	"Comment": "gym defense takes the calculated gym weave damage over 100s and multiplies by tankinessto arrive at a ranking of how much damage a pokemon will output when defending a gym.",
	"Method": "long gymDefense(Pokemon p,long gymDefense,PokemonId pokemonId,PokemonMove move1,PokemonMove move2,int attackIV,int defenseIV,int staminaIV){\r\n    final double gymDefense = PokemonCalculationUtils.weaveDps(pokemonId, move1, move2, MOVE_2_ADDITIONAL_DELAY) * (PokemonMeta.getPokemonSettings(pokemonId).getStats().getBaseAttack() + attackIV) * PokemonCalculationUtils.tankiness(pokemonId, defenseIV, staminaIV);\r\n    return Math.round(gymDefense);\r\n}"
}, {
	"Path": "boofcv.gui.image.VisualizeImageData.disparity",
	"Comment": "renders a gray scale image using color values from cold to hot.",
	"Method": "BufferedImage disparity(ImageGray disparity,BufferedImage dst,int minDisparity,int maxDisparity,int invalidColor,BufferedImage disparity,GrayI src,BufferedImage dst,int minValue,int maxValue,int invalidColor,BufferedImage disparity,GrayF32 src,BufferedImage dst,int minValue,int maxValue,int invalidColor){\r\n    float range = maxValue - minValue;\r\n    for (int y = 0; y < src.height; y++) {\r\n        for (int x = 0; x < src.width; x++) {\r\n            float v = src.unsafe_get(x, y);\r\n            if (v > range) {\r\n                dst.setRGB(x, y, invalidColor);\r\n            } else {\r\n                int r, b;\r\n                if (v == 0) {\r\n                    r = b = 0;\r\n                } else {\r\n                    r = (int) (255 * v / maxValue);\r\n                    b = (int) (255 * (maxValue - v) / maxValue);\r\n                }\r\n                dst.setRGB(x, y, r << 16 | b);\r\n            }\r\n        }\r\n    }\r\n    return dst;\r\n}"
}, {
	"Path": "org.boon.datarepo.impl.RepoBuilderDefault.useUnsafe",
	"Comment": "turns on field unsafe access instead of reflection.reflection is the default.",
	"Method": "RepoBuilder useUnsafe(boolean useUnSafe){\r\n    this.useUnSafe = useUnSafe;\r\n    return this;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonBinaryGrayRefine.setHelper",
	"Comment": "specify a helper used to inject specialized code into the polygon detector",
	"Method": "void setHelper(PolygonHelper helper){\r\n    detector.setHelper(helper);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.RefinePolyLineCorner.createLine",
	"Comment": "given segment information create a line in general notation which has been normalized",
	"Method": "void createLine(int index0,int index1,List<Point2D_I32> contour,LineGeneral2D_F64 line){\r\n    if (index1 < 0)\r\n        System.out.println(\"SHIT\");\r\n    Point2D_I32 p0 = contour.get(index0);\r\n    Point2D_I32 p1 = contour.get(index1);\r\n    work.a.set(p0.x, p0.y);\r\n    work.b.set(p1.x, p1.y);\r\n    UtilLine2D_F64.convert(work, line);\r\n    line.normalize();\r\n}"
}, {
	"Path": "org.boon.expression.BoonExpressionContext.lookup",
	"Comment": "lookup an object and use its name as the default value if not found.",
	"Method": "Object lookup(String objectName){\r\n    return lookupWithDefault(objectName, objectName);\r\n}"
}, {
	"Path": "boofcv.abst.feature.orientation.ConfigSiftOrientation.createPaper",
	"Comment": "creates a configuration similar to how it was originally described in the paper",
	"Method": "ConfigSiftOrientation createPaper(){\r\n    ConfigSiftOrientation config = new ConfigSiftOrientation();\r\n    config.histogramSize = 36;\r\n    config.sigmaEnlarge = 1.5;\r\n    return config;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.StabilitySquareFiducialEstimate.process",
	"Comment": "processes the observation and generates a stability estimate",
	"Method": "boolean process(double sampleRadius,Quadrilateral_F64 input){\r\n    work.set(input);\r\n    samples.reset();\r\n    estimator.process(work, false);\r\n    estimator.getWorldToCamera().invert(referenceCameraToWorld);\r\n    samples.reset();\r\n    createSamples(sampleRadius, work.a, input.a);\r\n    createSamples(sampleRadius, work.b, input.b);\r\n    createSamples(sampleRadius, work.c, input.c);\r\n    createSamples(sampleRadius, work.d, input.d);\r\n    if (samples.size() < 10)\r\n        return false;\r\n    maxLocation = 0;\r\n    maxOrientation = 0;\r\n    for (int i = 0; i < samples.size(); i++) {\r\n        referenceCameraToWorld.concat(samples.get(i), difference);\r\n        ConvertRotation3D_F64.matrixToRodrigues(difference.getR(), rodrigues);\r\n        double theta = Math.abs(rodrigues.theta);\r\n        double d = difference.getT().norm();\r\n        if (theta > maxOrientation) {\r\n            maxOrientation = theta;\r\n        }\r\n        if (d > maxLocation) {\r\n            maxLocation = d;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.TestVisOdomMonoPlaneInfinity.maximizeCountInSpread_edge",
	"Comment": "see if it finds the largest inlier set when it requires the angle to wrap around",
	"Method": "void maximizeCountInSpread_edge(){\r\n    double[] data = new double[23];\r\n    data[0] = 1;\r\n    data[1] = 1.1;\r\n    data[2] = 1.2;\r\n    data[4] = 1.3;\r\n    data[5] = 1.5;\r\n    data[6] = 1.51;\r\n    data[7] = 1.5;\r\n    data[8] = 1.45;\r\n    data[9] = 2;\r\n    data[10] = 2.2;\r\n    data[11] = 2.3;\r\n    data[12] = -(Math.PI - 0.01);\r\n    data[13] = -(Math.PI - 0.02);\r\n    data[14] = -(Math.PI - 0.03);\r\n    data[15] = -(Math.PI - 0.04);\r\n    data[16] = -(Math.PI - 0.05);\r\n    data[17] = Math.PI - 0.01;\r\n    data[18] = Math.PI - 0.02;\r\n    data[19] = Math.PI - 0.03;\r\n    data[20] = Math.PI - 0.04;\r\n    data[21] = Math.PI - 0.05;\r\n    data[22] = Math.PI;\r\n    double found = VisOdomMonoPlaneInfinity.maximizeCountInSpread(data, 23, 0.5);\r\n    assertEquals(Math.PI, found, 1e-8);\r\n}"
}, {
	"Path": "org.boon.Boon.jsonResource",
	"Comment": "load json object as resourcelooks in file system first and then classpath.",
	"Method": "Object jsonResource(String path,Object jsonResource,Path path){\r\n    String str = IO.read(path);\r\n    if (str != null) {\r\n        return fromJson(str);\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "boofcv.alg.distort.RemovePerspectiveDistortion.apply",
	"Comment": "applies distortion removal to the specified region in the input image.the undistorted image is returned.",
	"Method": "boolean apply(T input,Point2D_F64 corner0,Point2D_F64 corner1,Point2D_F64 corner2,Point2D_F64 corner3){\r\n    if (createTransform(corner0, corner1, corner2, corner3)) {\r\n        distort.input(input).apply();\r\n        return true;\r\n    } else {\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.OrientationHistogramSift.findHistogramPeaks",
	"Comment": "finds local peaks in histogram and selects orientations.location of peaks is interpolated.",
	"Method": "void findHistogramPeaks(){\r\n    peaks.reset();\r\n    angles.reset();\r\n    peakAngle = 0;\r\n    double largest = 0;\r\n    int largestIndex = -1;\r\n    double before = histogramMag[histogramMag.length - 2];\r\n    double current = histogramMag[histogramMag.length - 1];\r\n    for (int i = 0; i < histogramMag.length; i++) {\r\n        double after = histogramMag[i];\r\n        if (current > before && current > after) {\r\n            int currentIndex = CircularIndex.addOffset(i, -1, histogramMag.length);\r\n            peaks.push(currentIndex);\r\n            if (current > largest) {\r\n                largest = current;\r\n                largestIndex = currentIndex;\r\n            }\r\n        }\r\n        before = current;\r\n        current = after;\r\n    }\r\n    if (largestIndex < 0)\r\n        return;\r\n    double threshold = largest * 0.8;\r\n    for (int i = 0; i < peaks.size; i++) {\r\n        int index = peaks.data[i];\r\n        current = histogramMag[index];\r\n        if (current >= threshold) {\r\n            double angle = computeAngle(index);\r\n            angles.push(angle);\r\n            if (index == largestIndex)\r\n                peakAngle = angle;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.misc.GImageMiscOps.fillBand",
	"Comment": "computes the mean of the absolute value of the difference between the two images.",
	"Method": "void fillBand(ImageMultiBand input,int band,double value){\r\n    if (input instanceof ImageInterleaved) {\r\n        if (InterleavedI8.class.isAssignableFrom(input.getClass())) {\r\n            ImageMiscOps.fillBand((InterleavedI8) input, band, (int) value);\r\n        } else if (InterleavedI16.class.isAssignableFrom(input.getClass())) {\r\n            ImageMiscOps.fillBand((InterleavedI16) input, band, (int) value);\r\n        } else if (InterleavedS32.class == input.getClass()) {\r\n            ImageMiscOps.fillBand((InterleavedS32) input, band, (int) value);\r\n        } else if (InterleavedS64.class == input.getClass()) {\r\n            ImageMiscOps.fillBand((InterleavedS64) input, band, (long) value);\r\n        } else if (InterleavedF32.class == input.getClass()) {\r\n            ImageMiscOps.fillBand((InterleavedF32) input, band, (float) value);\r\n        } else if (InterleavedF64.class == input.getClass()) {\r\n            ImageMiscOps.fillBand((InterleavedF64) input, band, value);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type: \" + input.getClass().getSimpleName());\r\n        }\r\n    } else if (input instanceof Planar) {\r\n        Planar m = (Planar) input;\r\n        fill(m.getBand(band), value);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown image type: \" + input.getClass().getSimpleName());\r\n    }\r\n}"
}, {
	"Path": "boofcv.io.wrapper.images.BufferedFileImageSequence.hasNext",
	"Comment": "true if there is another image to read and false if there are no more.",
	"Method": "boolean hasNext(){\r\n    if (loop)\r\n        return true;\r\n    else\r\n        return index < images.length;\r\n}"
}, {
	"Path": "com.bugsnag.android.AppData.getDurationMs",
	"Comment": "get the time in milliseconds since bugsnag was initialized, which is agood approximation for how long the app has been running.",
	"Method": "long getDurationMs(){\r\n    return SystemClock.elapsedRealtime() - startTimeMs;\r\n}"
}, {
	"Path": "boofcv.gui.learning.ConfusionMatrixPanel.renderLabels",
	"Comment": "renders the names on each category to the side of the confusion matrix",
	"Method": "void renderLabels(Graphics2D g2,double fontSize){\r\n    int numCategories = confusion.getNumRows();\r\n    int longestLabel = 0;\r\n    if (renderLabels) {\r\n        for (int i = 0; i < numCategories; i++) {\r\n            longestLabel = Math.max(longestLabel, labels.get(i).length());\r\n        }\r\n    }\r\n    Font fontLabel = new Font(\"monospaced\", Font.BOLD, (int) (0.055 * longestLabel * fontSize + 0.5));\r\n    g2.setFont(fontLabel);\r\n    FontMetrics metrics = g2.getFontMetrics(fontLabel);\r\n    g2.setColor(Color.WHITE);\r\n    g2.fillRect(gridWidth, 0, viewWidth - gridWidth, viewHeight);\r\n    g2.setColor(Color.BLACK);\r\n    for (int i = 0; i < numCategories; i++) {\r\n        String label = labels.get(i);\r\n        int y0 = i * gridHeight / numCategories;\r\n        int y1 = (i + 1) * gridHeight / numCategories;\r\n        Rectangle2D r = metrics.getStringBounds(label, null);\r\n        float adjX = (float) (r.getX() * 2 + r.getWidth()) / 2.0f;\r\n        float adjY = (float) (r.getY() * 2 + r.getHeight()) / 2.0f;\r\n        float x = ((viewWidth + gridWidth) / 2f - adjX);\r\n        float y = ((y1 + y0) / 2f - adjY);\r\n        g2.drawString(label, x, y);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.DescribeDenseHogFastAlg.computeCellHistograms",
	"Comment": "compute histograms for all the cells inside the image using precomputed derivative.",
	"Method": "void computeCellHistograms(){\r\n    int width = cellCols * pixelsPerCell;\r\n    int height = cellRows * pixelsPerCell;\r\n    float angleBinSize = GrlConstants.F_PI / orientationBins;\r\n    int indexCell = 0;\r\n    for (int i = 0; i < height; i += pixelsPerCell) {\r\n        for (int j = 0; j < width; j += pixelsPerCell, indexCell++) {\r\n            Cell c = cells[indexCell];\r\n            c.reset();\r\n            for (int k = 0; k < pixelsPerCell; k++) {\r\n                int indexPixel = (i + k) * derivX.width + j;\r\n                for (int l = 0; l < pixelsPerCell; l++, indexPixel++) {\r\n                    float pixelDX = this.derivX.data[indexPixel];\r\n                    float pixelDY = this.derivY.data[indexPixel];\r\n                    float angle = UtilAngle.atanSafe(pixelDY, pixelDX) + GrlConstants.F_PId2;\r\n                    float magnitude = (float) Math.sqrt(pixelDX * pixelDX + pixelDY * pixelDY);\r\n                    float findex0 = angle / angleBinSize;\r\n                    int index0 = (int) findex0;\r\n                    float weight1 = findex0 - index0;\r\n                    index0 %= orientationBins;\r\n                    int index1 = (index0 + 1) % orientationBins;\r\n                    c.histogram[index0] += magnitude * (1.0f - weight1);\r\n                    c.histogram[index1] += magnitude * weight1;\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.transform.ii.GIntegralImageOps.convolveSparse",
	"Comment": "convolves a kernel around a single point in the integral image.",
	"Method": "double convolveSparse(T integral,IntegralKernel kernel,int x,int y){\r\n    if (integral instanceof GrayF32) {\r\n        return IntegralImageOps.convolveSparse((GrayF32) integral, kernel, x, y);\r\n    } else if (integral instanceof GrayF64) {\r\n        return IntegralImageOps.convolveSparse((GrayF64) integral, kernel, x, y);\r\n    } else if (integral instanceof GrayS32) {\r\n        return IntegralImageOps.convolveSparse((GrayS32) integral, kernel, x, y);\r\n    } else if (integral instanceof GrayS64) {\r\n        return IntegralImageOps.convolveSparse((GrayS64) integral, kernel, x, y);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown input type\");\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.inProject",
	"Comment": "checks if the given class name should be marked as in the project or not",
	"Method": "boolean inProject(String className){\r\n    if (projectPackages != null) {\r\n        for (String packageName : projectPackages) {\r\n            if (packageName != null && className.startsWith(packageName)) {\r\n                return true;\r\n            }\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapObjectConversion.fromMap",
	"Comment": "frommap converts a map into a java object.this version will see if there is a class parameter in the map, and dies if there is not.",
	"Method": "T fromMap(Map<String, Object> map,Class<T> clazz,T fromMap,Map<String, Object> map,Class<T> clazz,String excludeProperties,Object fromMap,Map<String, Object> map,T fromMap,boolean respectIgnore,String view,FieldsAccessor fieldsAccessor,Map<String, Object> map,Class<T> cls,Set<String> ignoreSet){\r\n    Mapper mapper = new MapperComplex(ignoreSet, view, respectIgnore);\r\n    return mapper.fromMap(map, cls);\r\n}"
}, {
	"Path": "org.boon.Boon.handlebars",
	"Comment": "creates handlebars style template results from string template and context",
	"Method": "String handlebars(String template,Object context){\r\n    return BoonTemplate.template().replace(template, context);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.KltTracker.setDescription",
	"Comment": "sets the features description using the current image and the location of the feature stored in the feature.\tif the feature is an illegal location and cannot be set then false is returned.",
	"Method": "boolean setDescription(KltFeature feature){\r\n    setAllowedBounds(feature);\r\n    if (!isFullyInside(feature.x, feature.y)) {\r\n        if (isFullyOutside(feature.x, feature.y))\r\n            return false;\r\n        else\r\n            return internalSetDescriptionBorder(feature);\r\n    }\r\n    return internalSetDescription(feature);\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.PnPInfinitesimalPlanePoseEstimation.zeroMeanWorldPoints",
	"Comment": "ensure zero mean for world location. creates a local copy of the input",
	"Method": "void zeroMeanWorldPoints(List<AssociatedPair> points){\r\n    center.set(0, 0);\r\n    pointsAdj.reset();\r\n    for (int i = 0; i < points.size(); i++) {\r\n        AssociatedPair pair = points.get(i);\r\n        Point2D_F64 p = pair.p1;\r\n        pointsAdj.grow().p2.set(pair.p2);\r\n        center.x += p.x;\r\n        center.y += p.y;\r\n    }\r\n    center.x /= points.size();\r\n    center.y /= points.size();\r\n    for (int i = 0; i < points.size(); i++) {\r\n        Point2D_F64 p = points.get(i).p1;\r\n        pointsAdj.get(i).p1.set(p.x - center.x, p.y - center.y);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.template.TemplateMatching.getResults",
	"Comment": "returns all the found matches.the location is the location of the top left corner\tof the template.score is the first score with higher number being better",
	"Method": "FastQueue<Match> getResults(){\r\n    return results;\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.CalibrationPlanarGridZhang99.applyDistortion",
	"Comment": "applies radial and tangential distortion to the normalized image coordinate.",
	"Method": "void applyDistortion(Point2D_F64 normPt,double[] radial,double t1,double t2){\r\n    final double x = normPt.x;\r\n    final double y = normPt.y;\r\n    double a = 0;\r\n    double r2 = x * x + y * y;\r\n    double r2i = r2;\r\n    for (int i = 0; i < radial.length; i++) {\r\n        a += radial[i] * r2i;\r\n        r2i *= r2;\r\n    }\r\n    normPt.x = x + x * a + 2 * t1 * x * y + t2 * (r2 + 2 * x * x);\r\n    normPt.y = y + y * a + t1 * (r2 + 2 * y * y) + 2 * t2 * x * y;\r\n}"
}, {
	"Path": "boofcv.alg.transform.pyramid.PyramidOps.reshapeOutput",
	"Comment": "reshapes each image in the array to match the layers in the pyramid",
	"Method": "void reshapeOutput(ImagePyramid<?> pyramid,O[] output){\r\n    for (int i = 0; i < output.length; i++) {\r\n        int w = pyramid.getWidth(i);\r\n        int h = pyramid.getHeight(i);\r\n        output[i].reshape(w, h);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.MultiCameraToEquirectangular.setMaskToleranceAngle",
	"Comment": "specify the tolerance that the circle normal angle must be invertible in radians",
	"Method": "void setMaskToleranceAngle(float maskToleranceAngle){\r\n    this.maskToleranceAngle = maskToleranceAngle;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodePositionPatternDetector.createPositionPatternGraph",
	"Comment": "connects together position patterns. for each square, finds all of its neighbors based on center distance.\tthen considers them for connections",
	"Method": "void createPositionPatternGraph(){\r\n    search.setPoints((List) positionPatterns.toList(), false);\r\n    for (int i = 0; i < positionPatterns.size(); i++) {\r\n        PositionPatternNode f = positionPatterns.get(i);\r\n        double maximumQrCodeWidth = f.largestSide * (17 + 4 * maxVersionQR - 7.0) / 7.0;\r\n        double searchRadius = 1.2 * maximumQrCodeWidth;\r\n        searchRadius *= searchRadius;\r\n        search.findNearest(f, searchRadius, Integer.MAX_VALUE, searchResults);\r\n        if (searchResults.size > 1) {\r\n            for (int j = 0; j < searchResults.size; j++) {\r\n                NnData<SquareNode> r = searchResults.get(j);\r\n                if (r.point == f)\r\n                    continue;\r\n                considerConnect(f, r.point);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.TestRectifyImageOps.transformPixelToRectNorm_F64",
	"Comment": "test by using other tested functions, then manually applying the last step",
	"Method": "void transformPixelToRectNorm_F64(){\r\n    CameraPinholeRadial param = new CameraPinholeRadial().fsetK(300, 320, 0, 150, 130, width, height).fsetRadial(0.1, 1e-4);\r\n    DMatrixRMaj rect = new DMatrixRMaj(3, 3, true, 1.1, 0, 0, 0, 2, 0, 0.1, 0, 3);\r\n    DMatrixRMaj rectK = PerspectiveOps.pinholeToMatrix(param, (DMatrixRMaj) null);\r\n    DMatrixRMaj rectK_inv = new DMatrixRMaj(3, 3);\r\n    CommonOps_DDRM.invert(rectK, rectK_inv);\r\n    Point2Transform2_F64 tranRect = RectifyImageOps.transformPixelToRect(param, rect);\r\n    Point2Transform2_F64 alg = RectifyImageOps.transformPixelToRectNorm(param, rect, rectK);\r\n    double x = 10, y = 20;\r\n    Point2D_F64 rectified = new Point2D_F64();\r\n    tranRect.compute(x, y, rectified);\r\n    Point2D_F64 expected = new Point2D_F64();\r\n    GeometryMath_F64.mult(rectK_inv, new Point2D_F64(rectified.x, rectified.y), expected);\r\n    Point2D_F64 found = new Point2D_F64();\r\n    alg.compute(x, y, found);\r\n    assertEquals(expected.x, found.x, 1e-4);\r\n    assertEquals(expected.y, found.y, 1e-4);\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationLinearRotationMulti.convertW",
	"Comment": "converts w into a pinhole camera model by finding the cholesky decomposition",
	"Method": "void convertW(Homography2D_F64 w,CameraPinhole c){\r\n    tmp.set(w);\r\n    CommonOps_DDF3.divide(tmp, tmp.a33);\r\n    CommonOps_DDF3.cholU(tmp);\r\n    CommonOps_DDF3.invert(tmp, K);\r\n    CommonOps_DDF3.divide(K, K.a33);\r\n    c.fx = K.a11;\r\n    c.fy = knownAspectRatio ? (K.a22 + c.fx * aspectRatio) / 2.0 : K.a22;\r\n    c.skew = zeroSkew ? 0 : K.a12;\r\n    c.cx = principlePointOrigin ? 0 : K.a13;\r\n    c.cy = principlePointOrigin ? 0 : K.a23;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonFromContour.findCandidateShapes",
	"Comment": "finds blobs in the binary image.then looks for blobs that meet size and shape requirements.see code\tbelow for the requirements.those that remain are considered to be target candidates.",
	"Method": "void findCandidateShapes(){\r\n    List<ContourPacked> blobs = contourFinder.getContours();\r\n    for (int i = 0; i < blobs.size(); i++) {\r\n        ContourPacked c = blobs.get(i);\r\n        contourTmp.reset();\r\n        contourFinder.loadContour(c.externalIndex, contourTmp);\r\n        if (contourTmp.size() >= minimumContour) {\r\n            float edgeInside = -1, edgeOutside = -1;\r\n            boolean touchesBorder = touchesBorder(contourTmp.toList());\r\n            if (!canTouchBorder && touchesBorder) {\r\n                if (verbose)\r\n                    System.out.println(\"rejected polygon, touched border\");\r\n                continue;\r\n            }\r\n            if (helper != null)\r\n                if (!helper.filterContour(contourTmp.toList(), touchesBorder, true))\r\n                    continue;\r\n            if (contourEdgeIntensity != null) {\r\n                contourEdgeIntensity.process(contourTmp.toList(), true);\r\n                edgeInside = contourEdgeIntensity.getInsideAverage();\r\n                edgeOutside = contourEdgeIntensity.getOutsideAverage();\r\n                if (Math.abs(edgeOutside - edgeInside) < contourEdgeThreshold) {\r\n                    if (verbose)\r\n                        System.out.println(\"rejected polygon. contour edge intensity\");\r\n                    continue;\r\n                }\r\n            }\r\n            List<Point2D_I32> undistorted;\r\n            if (distToUndist != null) {\r\n                undistorted = this.undistorted.toList();\r\n                removeDistortionFromContour(contourTmp.toList(), this.undistorted);\r\n                if (helper != null)\r\n                    if (!helper.filterContour(this.undistorted.toList(), touchesBorder, false))\r\n                        continue;\r\n            } else {\r\n                undistorted = contourTmp.toList();\r\n            }\r\n            if (helper != null) {\r\n                helper.configureBeforePolyline(contourToPolyline, touchesBorder);\r\n            }\r\n            if (!contourToPolyline.process(undistorted, splits)) {\r\n                if (verbose)\r\n                    System.out.println(\"rejected polygon initial fit failed. contour size = \" + contourTmp.size());\r\n                continue;\r\n            }\r\n            polygonPixel.clear();\r\n            for (int j = 0; j < splits.size; j++) {\r\n                polygonPixel.add(undistorted.get(splits.get(j)));\r\n            }\r\n            boolean isCCW = UtilPolygons2D_I32.isCCW(polygonPixel);\r\n            if (contourEdgeIntensity != null) {\r\n                if (!isCCW) {\r\n                    float tmp = edgeInside;\r\n                    edgeInside = edgeOutside;\r\n                    edgeOutside = tmp;\r\n                }\r\n                if (edgeInside > edgeOutside) {\r\n                    if (verbose)\r\n                        System.out.println(\"White blob. Rejected\");\r\n                    continue;\r\n                }\r\n            }\r\n            if (outputClockwise == isCCW) {\r\n                flip(splits.data, splits.size);\r\n            }\r\n            polygonWork.vertexes.resize(splits.size());\r\n            polygonDistorted.vertexes.resize(splits.size());\r\n            for (int j = 0; j < splits.size(); j++) {\r\n                Point2D_I32 p = undistorted.get(splits.get(j));\r\n                Point2D_I32 q = contourTmp.get(splits.get(j));\r\n                polygonWork.get(j).set(p.x, p.y);\r\n                polygonDistorted.get(j).set(q.x, q.y);\r\n            }\r\n            if (touchesBorder) {\r\n                determineCornersOnBorder(polygonDistorted, borderCorners);\r\n            } else {\r\n                borderCorners.resize(0);\r\n            }\r\n            if (helper != null) {\r\n                if (!helper.filterPixelPolygon(polygonWork, polygonDistorted, borderCorners, touchesBorder)) {\r\n                    if (verbose)\r\n                        System.out.println(\"rejected by helper.filterPixelPolygon()\");\r\n                    continue;\r\n                }\r\n            }\r\n            double area = Area2D_F64.polygonSimple(polygonWork);\r\n            if (area < minimumArea) {\r\n                if (verbose)\r\n                    System.out.println(\"Rejected area\");\r\n                continue;\r\n            }\r\n            Info info = foundInfo.grow();\r\n            if (distToUndist != null) {\r\n                contourFinder.writeContour(c.externalIndex, undistorted);\r\n            }\r\n            info.splits.setTo(splits);\r\n            info.contourTouchesBorder = touchesBorder;\r\n            info.external = true;\r\n            info.edgeInside = edgeInside;\r\n            info.edgeOutside = edgeOutside;\r\n            info.contour = c;\r\n            info.polygon.set(polygonWork);\r\n            info.polygonDistorted.set(polygonDistorted);\r\n            info.borderCorners.setTo(borderCorners);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.RegionMergeTree.flowIntoRootNode",
	"Comment": "for each region in the merge list which is not a root node, find its root node and add to the root node\tits member count and set the indexin mergelist to the root node.if a node is a root node just note\twhat its new id will be after all the other segments are removed.",
	"Method": "void flowIntoRootNode(GrowQueue_I32 regionMemberCount){\r\n    rootID.resize(regionMemberCount.size);\r\n    int count = 0;\r\n    for (int i = 0; i < mergeList.size; i++) {\r\n        int p = mergeList.data[i];\r\n        if (p == i) {\r\n            rootID.data[i] = count++;\r\n            continue;\r\n        }\r\n        int gp = mergeList.data[p];\r\n        while (gp != p) {\r\n            p = gp;\r\n            gp = mergeList.data[p];\r\n        }\r\n        regionMemberCount.data[p] += regionMemberCount.data[i];\r\n        mergeList.data[i] = p;\r\n    }\r\n}"
}, {
	"Path": "com.examples.model.test.movies.crud.BatchResults.errors",
	"Comment": "indicates if there were failures or not.true indicates there are failed indexes.",
	"Method": "boolean errors(){\r\n    return failedIndexes.length > 0;\r\n}"
}, {
	"Path": "boofcv.abst.feature.describe.ConfigSiftScaleSpace.createPaper",
	"Comment": "creates a configuration similar to how it was originally described in the paper",
	"Method": "ConfigSiftScaleSpace createPaper(){\r\n    ConfigSiftScaleSpace config = new ConfigSiftScaleSpace();\r\n    config.sigma0 = 1.6f;\r\n    config.numScales = 3;\r\n    config.firstOctave = -1;\r\n    config.lastOctave = 5;\r\n    return config;\r\n}"
}, {
	"Path": "boofcv.abst.feature.detect.interest.ConfigSiftDetector.createPaper",
	"Comment": "creates a configuration similar to how it was originally described in the paper",
	"Method": "ConfigSiftDetector createPaper(){\r\n    ConfigSiftDetector config = new ConfigSiftDetector();\r\n    config.extract = new ConfigExtract(1, 0, 1, true, true, true);\r\n    config.extract.ignoreBorder = 1;\r\n    config.maxFeaturesPerScale = 0;\r\n    config.edgeR = 10;\r\n    return config;\r\n}"
}, {
	"Path": "org.boon.Boon.resource",
	"Comment": "loads a resource from the file system or classpath if not found.this allows you to have resources that exist in the jarand that can be configured outside of the jar easily.classpath is only used if file system resource is not found.",
	"Method": "String resource(String path,String resource,Path path){\r\n    String str = IO.read(path);\r\n    return str;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.FastHessianFeatureDetector.detectOctave",
	"Comment": "computes feature intensities for all the specified feature sizes and finds features\tinside of the middle feature sizes.",
	"Method": "void detectOctave(II integral,int skip,int featureSize){\r\n    int w = integral.width / skip;\r\n    int h = integral.height / skip;\r\n    for (int i = 0; i < intensity.length; i++) {\r\n        intensity[i].reshape(w, h);\r\n    }\r\n    for (int i = 0; i < featureSize.length; i++) {\r\n        GIntegralImageFeatureIntensity.hessian(integral, skip, featureSize[i], intensity[spaceIndex]);\r\n        spaceIndex++;\r\n        if (spaceIndex >= 3)\r\n            spaceIndex = 0;\r\n        if (i >= 2) {\r\n            findLocalScaleSpaceMax(featureSize, i - 1, skip);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.TestSplitMergeLineFitLoop.set_minimumSideLengthPixel",
	"Comment": "checks to make sure the minimum side length is correctly set",
	"Method": "void set_minimumSideLengthPixel(){\r\n    List<Point2D_I32> contour = new ArrayList();\r\n    for (int i = 0; i < 30; i++) {\r\n        contour.add(new Point2D_I32(i, 0));\r\n    }\r\n    ConfigLength cl = ConfigLength.relative(0.2, 0);\r\n    SplitMergeLineFitLoop alg = new SplitMergeLineFitLoop(0.001, cl, 100);\r\n    alg.process(contour, splits);\r\n    assertEquals(contour.size() / 5, alg.minimumSideLengthPixel);\r\n}"
}, {
	"Path": "boofcv.alg.geo.WorldToCameraToPixel.transform",
	"Comment": "computes location of 3d point in world as observed in the camera.point is returned if visible or null\tif not visible.",
	"Method": "boolean transform(Point3D_F64 worldPt,Point2D_F64 pixelPt,boolean transform,Point3D_F64 worldPt,Point2D_F64 pixelPt,Point2D_F64 normPt,Point2D_F64 transform,Point3D_F64 worldPt){\r\n    Point2D_F64 out = new Point2D_F64();\r\n    if (transform(worldPt, out))\r\n        return out;\r\n    else\r\n        return null;\r\n}"
}, {
	"Path": "boofcv.alg.denoise.wavelet.DenoiseVisuShrink_F32.denoise",
	"Comment": "applies visushrink denoising to the provided multilevel wavelet transform using\tthe provided threshold.",
	"Method": "void denoise(GrayF32 transform,int numLevels){\r\n    int scale = UtilWavelet.computeScale(numLevels);\r\n    final int h = transform.height;\r\n    final int w = transform.width;\r\n    final int innerWidth = w / scale;\r\n    final int innerHeight = h / scale;\r\n    GrayF32 subbandHH = transform.subimage(w / 2, h / 2, w, h, null);\r\n    float sigma = UtilDenoiseWavelet.estimateNoiseStdDev(subbandHH, null);\r\n    float threshold = (float) UtilDenoiseWavelet.universalThreshold(subbandHH, sigma);\r\n    rule.process(transform.subimage(innerWidth, 0, w, h, null), threshold);\r\n    rule.process(transform.subimage(0, innerHeight, innerWidth, h, null), threshold);\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.EquirectangularDistortBase_F32.compute",
	"Comment": "input is in pinhole camera pixel coordinates.output is in equirectangular coordinates",
	"Method": "void compute(int x,int y){\r\n    Point3D_F32 v = vectors[y * outWidth + x];\r\n    GeometryMath_F32.mult(R, v, n);\r\n    tools.normToEquiFV(n.x, n.y, n.z, out);\r\n    distX = out.x;\r\n    distY = out.y;\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.DescribeDenseSiftAlg.precomputeAngles",
	"Comment": "computes the angle of each pixel and its gradient magnitude",
	"Method": "void precomputeAngles(D image){\r\n    int savecIndex = 0;\r\n    for (int y = 0; y < image.height; y++) {\r\n        int pixelIndex = y * image.stride + image.startIndex;\r\n        for (int x = 0; x < image.width; x++, pixelIndex++, savecIndex++) {\r\n            float spacialDX = imageDerivX.getF(pixelIndex);\r\n            float spacialDY = imageDerivY.getF(pixelIndex);\r\n            savedAngle.data[savecIndex] = UtilAngle.domain2PI(Math.atan2(spacialDY, spacialDX));\r\n            savedMagnitude.data[savecIndex] = (float) Math.sqrt(spacialDX * spacialDX + spacialDY * spacialDY);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.GenericFeatureDetectorTests.checkNegativeMaxFeatures",
	"Comment": "if the maximum number of features is set to a negative number or zero then\tit should return the maximum number of features possible",
	"Method": "void checkNegativeMaxFeatures(){\r\n    GrayF32 input = new GrayF32(width, height);\r\n    GImageMiscOps.fillRectangle(input, 100, 10, 10, 15, 15);\r\n    GImageMiscOps.fillRectangle(input, 100, 30, 10, 35, 15);\r\n    GImageMiscOps.fillRectangle(input, 100, 10, 30, 15, 35);\r\n    GImageMiscOps.fillRectangle(input, 100, 30, 30, 35, 35);\r\n    Object alg = createDetector(1);\r\n    int firstFound = detectFeature(input, alg);\r\n    alg = createDetector(0);\r\n    int secondFound = detectFeature(input, alg);\r\n    assertTrue(secondFound > firstFound);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldTemplateMatching.setImage",
	"Comment": "must call this function before any of the others which process descriptions",
	"Method": "void setImage(T gray){\r\n    interpolate.setImage(gray);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.data.managers.AccountController.checkForSavedCredentials",
	"Comment": "check if there is any login saved and ask for user to use it or not.",
	"Method": "int checkForSavedCredentials(){\r\n    final LoginType savedLogin = checkSavedConfig();\r\n    if (savedLogin == LoginType.NONE) {\r\n        return JOptionPane.NO_OPTION;\r\n    } else {\r\n        UIManager.put(\"OptionPane.noButtonText\", \"No\");\r\n        UIManager.put(\"OptionPane.yesButtonText\", \"Yes\");\r\n        UIManager.put(\"OptionPane.okButtonText\", \"Ok\");\r\n        UIManager.put(\"OptionPane.cancelButtonText\", \"Exit\");\r\n        return JOptionPane.showConfirmDialog(WindowStuffHelper.ALWAYS_ON_TOP_PARENT, \"You have saved login data for \" + savedLogin.toString() + \". Want to login with that?\", \"Use Saved Login\", JOptionPane.YES_NO_CANCEL_OPTION, JOptionPane.PLAIN_MESSAGE);\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.TestPointTrackerKltPyramid.checkRecycle_Process_Spawn",
	"Comment": "checks to see if tracks are correctly recycled by process and spawn",
	"Method": "void checkRecycle_Process_Spawn(){\r\n    PointTrackerKltPyramid<GrayF32, GrayF32> alg = (PointTrackerKltPyramid<GrayF32, GrayF32>) createTracker();\r\n    alg.process(image);\r\n    alg.spawnTracks();\r\n    int total = alg.active.size();\r\n    assertTrue(total > 0);\r\n    assertEquals(0, alg.dropped.size());\r\n    GImageMiscOps.fill(image, 0);\r\n    alg.process(image);\r\n    int difference = total - alg.active.size();\r\n    assertEquals(difference, alg.dropped.size());\r\n    assertEquals(difference, alg.unused.size());\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestDistortImageOps.scale_InterpTypeStyle",
	"Comment": "checks to see if the two ways of specifying interpolation work",
	"Method": "void scale_InterpTypeStyle(){\r\n    GrayF32 input = new GrayF32(width, height);\r\n    GrayF32 output = new GrayF32(width, height);\r\n    GImageMiscOps.fillUniform(input, rand, 0, 100);\r\n    DistortImageOps.scale(input, output, BorderType.ZERO, InterpolationType.BILINEAR);\r\n    InterpolatePixelS<GrayF32> interp = FactoryInterpolation.bilinearPixelS(input, BorderType.EXTENDED);\r\n    interp.setImage(input);\r\n    float scaleX = (float) input.width / (float) output.width;\r\n    float scaleY = (float) input.height / (float) output.height;\r\n    if (input.getDataType().isInteger()) {\r\n        for (int i = 0; i < output.height; i++) {\r\n            for (int j = 0; j < output.width; j++) {\r\n                float val = interp.get(j * scaleX, i * scaleY);\r\n                assertEquals((int) val, output.get(j, i), 1e-4);\r\n            }\r\n        }\r\n    } else {\r\n        for (int i = 0; i < output.height; i++) {\r\n            for (int j = 0; j < output.width; j++) {\r\n                float val = interp.get(j * scaleX, i * scaleY);\r\n                assertEquals(val, output.get(j, i), 1e-4);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.android.camera.VideoDisplayActivity.setProcessing",
	"Comment": "changes the cv algorithm running.should only be called from a gui thread.",
	"Method": "void setProcessing(VideoProcessing processing){\r\n    if (this.processing != null) {\r\n        this.processing.stopProcessing();\r\n    }\r\n    if (Looper.getMainLooper().getThread() != Thread.currentThread()) {\r\n        throw new RuntimeException(\"Not called from a GUI thread. Bad stuff could happen\");\r\n    }\r\n    this.processing = processing;\r\n    if (processing != null && mCamera != null) {\r\n        processing.init(mDraw, mCamera, mCameraInfo, previewRotation);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.flow.HornSchunckPyramid.safe",
	"Comment": "ensures pixel values are inside the image.if output it is assigned to the nearest pixel inside the image",
	"Method": "float safe(int x,int y,GrayF32 image){\r\n    if (x < 0)\r\n        x = 0;\r\n    else if (x >= image.width)\r\n        x = image.width - 1;\r\n    if (y < 0)\r\n        y = 0;\r\n    else if (y >= image.height)\r\n        y = image.height - 1;\r\n    return image.unsafe_get(x, y);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.TestEllipseClustersIntoGrid.addEdgesToInfo_AND_findLargestAnglesForAllNodes",
	"Comment": "combines these two functions into a single test.this was done to ensure that their behavior is consistent\twith each other.",
	"Method": "void addEdgesToInfo_AND_findLargestAnglesForAllNodes(){\r\n    EllipseClustersIntoGrid alg = new HelperAlg();\r\n    setNodeInfo(alg.listInfo.grow(), 0, 0);\r\n    setNodeInfo(alg.listInfo.grow(), -1, 0);\r\n    setNodeInfo(alg.listInfo.grow(), 3, 1);\r\n    setNodeInfo(alg.listInfo.grow(), 0, 1);\r\n    setNodeInfo(alg.listInfo.grow(), 1, 2);\r\n    List<Node> cluster = new ArrayList();\r\n    cluster.add(createNode(0, 1, 2, 3));\r\n    cluster.add(createNode(1, 0, 2, 4));\r\n    cluster.add(createNode(2, 0, 1));\r\n    cluster.add(createNode(3, 0));\r\n    cluster.add(createNode(4));\r\n    alg.addEdgesToInfo(cluster);\r\n    checkEdgeInfo(alg.listInfo.get(0), 3);\r\n    checkEdgeInfo(alg.listInfo.get(1), 3);\r\n    checkEdgeInfo(alg.listInfo.get(2), 2);\r\n    checkEdgeInfo(alg.listInfo.get(3), 1);\r\n    checkEdgeInfo(alg.listInfo.get(4), 0);\r\n    alg.findLargestAnglesForAllNodes();\r\n    checkLargestAngle(alg.listInfo.get(0), alg.listInfo.get(1), alg.listInfo.get(2));\r\n    checkLargestAngle(alg.listInfo.get(1), alg.listInfo.get(4), alg.listInfo.get(0));\r\n    checkLargestAngle(alg.listInfo.get(2), alg.listInfo.get(0), alg.listInfo.get(1));\r\n    checkLargestAngle(alg.listInfo.get(3), null, null);\r\n    checkLargestAngle(alg.listInfo.get(4), null, null);\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.GenericPlanarCalibrationDetectorChecks.fisheye_fullview",
	"Comment": "see if it can detect targets distorted by fisheye lens. entire target is always seen",
	"Method": "void fisheye_fullview(){\r\n    CameraUniversalOmni model = CalibrationIO.load(getClass().getResource(\"fisheye.yaml\"));\r\n    SimulatePlanarWorld simulator = new SimulatePlanarWorld();\r\n    simulator.setCamera(model);\r\n    List<Point2D_F64> locations2D = new ArrayList();\r\n    GrayF32 pattern = new GrayF32(1, 1);\r\n    for (int i = 0; i < targetConfigs.size(); i++) {\r\n        DetectorFiducialCalibration detector = createDetector(targetConfigs.get(i));\r\n        renderTarget(targetConfigs.get(i), simulatedTargetWidth, pattern, locations2D);\r\n        simulator.resetScene();\r\n        Se3_F64 markerToWorld = new Se3_F64();\r\n        simulator.addSurface(markerToWorld, simulatedTargetWidth, pattern);\r\n        failedToDetect = 0;\r\n        for (int j = 0; j < fisheye_poses.size(); j++) {\r\n            markerToWorld.set(fisheye_poses.get(j));\r\n            checkRenderedResults(detector, simulator, locations2D);\r\n        }\r\n    }\r\n    assertTrue(failedToDetect <= fisheyeAllowedFails);\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedS8.getBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "int getBand(int x,int y,int band){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    return data[getIndex(x, y, band)];\r\n}"
}, {
	"Path": "org.boon.primitive.Dbl.reduceBy",
	"Comment": "a very fast reduce by.if performance is your thing, this seems to be as fast a plain for loop when benchmarking with jmh.",
	"Method": "double reduceBy(double[] array,ReduceBy reduceBy,double reduceBy,double[] array,int start,int length,ReduceBy reduceBy,double reduceBy,double[] array,int length,ReduceBy reduceBy,double reduceBy,double[] array,T object,double reduceBy,double[] array,T object,String methodName,double reduceBy,double[] array,int length,Object object,double reduceBy,double[] array,int length,Object function,String functionName,double reduceBy,double[] array,int start,int length,Object object){\r\n    if (object.getClass().isAnonymousClass()) {\r\n        return reduceByR(array, object);\r\n    }\r\n    try {\r\n        ConstantCallSite callSite = Invoker.invokeReducerLongIntReturnLongMethodHandle(object);\r\n        MethodHandle methodHandle = callSite.dynamicInvoker();\r\n        try {\r\n            double sum = 0;\r\n            for (int index = start; index < length; index++) {\r\n                double v = array[index];\r\n                sum = (double) methodHandle.invokeExact(sum, v);\r\n            }\r\n            return sum;\r\n        } catch (Throwable throwable) {\r\n            return handle(Long.class, throwable, \"Unable to perform reduceBy\");\r\n        }\r\n    } catch (Exception ex) {\r\n        return reduceByR(array, object);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.PnPLepetitEPnP.estimateCase1",
	"Comment": "simple analytical solution.just need to solve for the scale difference in one set\tof potential control points.",
	"Method": "void estimateCase1(double betas){\r\n    betas[0] = matchScale(nullPts[0], controlWorldPts);\r\n    betas[0] = adjustBetaSign(betas[0], nullPts[0]);\r\n    betas[1] = 0;\r\n    betas[2] = 0;\r\n    betas[3] = 0;\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapperSimple.handleCollectionOfValues",
	"Comment": "processes an collection of maps.this can inject into an array and appears to be using some of the typetype lib.",
	"Method": "void handleCollectionOfValues(Object newInstance,FieldAccess field,Collection<Value> acollectionOfValues){\r\n    Collection collectionOfValues = acollectionOfValues;\r\n    if (null == collectionOfValues) {\r\n        field.setObject(newInstance, null);\r\n        return;\r\n    }\r\n    if (field.typeEnum() == INSTANCE) {\r\n        field.setObject(newInstance, fromList((List) acollectionOfValues, field.type()));\r\n        return;\r\n    }\r\n    if (collectionOfValues instanceof ValueList) {\r\n        collectionOfValues = ((ValueList) collectionOfValues).list();\r\n    }\r\n    Class<?> componentClass = field.getComponentClass();\r\n    switch(field.typeEnum()) {\r\n        case LIST:\r\n        case SET:\r\n        case COLLECTION:\r\n            Collection<Object> newCollection = Conversions.createCollection(field.type(), collectionOfValues.size());\r\n            for (Value value : (List<Value>) collectionOfValues) {\r\n                if (value.isContainer()) {\r\n                    Object oValue = value.toValue();\r\n                    if (oValue instanceof Map) {\r\n                        newCollection.add(fromValueMap((Map) oValue, componentClass));\r\n                    }\r\n                } else {\r\n                    newCollection.add(Conversions.coerce(componentClass, value.toValue()));\r\n                }\r\n            }\r\n            field.setObject(newInstance, newCollection);\r\n            break;\r\n        case ARRAY:\r\n        case ARRAY_INT:\r\n        case ARRAY_BYTE:\r\n        case ARRAY_SHORT:\r\n        case ARRAY_FLOAT:\r\n        case ARRAY_DOUBLE:\r\n        case ARRAY_LONG:\r\n        case ARRAY_STRING:\r\n        case ARRAY_OBJECT:\r\n            TypeType componentType = field.componentType();\r\n            int index = 0;\r\n            switch(componentType) {\r\n                case INT:\r\n                    int[] iarray = new int[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        iarray[index] = value.intValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, iarray);\r\n                    return;\r\n                case SHORT:\r\n                    short[] sarray = new short[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        sarray[index] = value.shortValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, sarray);\r\n                    return;\r\n                case DOUBLE:\r\n                    double[] darray = new double[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        darray[index] = value.doubleValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, darray);\r\n                    return;\r\n                case FLOAT:\r\n                    float[] farray = new float[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        farray[index] = value.floatValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, farray);\r\n                    return;\r\n                case LONG:\r\n                    long[] larray = new long[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        larray[index] = value.longValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, larray);\r\n                    return;\r\n                case BYTE:\r\n                    byte[] barray = new byte[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        barray[index] = value.byteValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, barray);\r\n                    return;\r\n                case CHAR:\r\n                    char[] chars = new char[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        chars[index] = value.charValue();\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, chars);\r\n                    return;\r\n                case STRING:\r\n                    CharBuf buffer = CharBuf.create(100);\r\n                    String[] strings = new String[collectionOfValues.size()];\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        strings[index] = value.stringValue(buffer);\r\n                        index++;\r\n                    }\r\n                    field.setObject(newInstance, strings);\r\n                    return;\r\n                default:\r\n                    Object array = Array.newInstance(componentClass, collectionOfValues.size());\r\n                    Object o;\r\n                    for (Value value : (List<Value>) collectionOfValues) {\r\n                        if (value instanceof ValueContainer) {\r\n                            o = value.toValue();\r\n                            if (o instanceof List) {\r\n                                o = fromList((List) o, componentClass);\r\n                                if (componentClass.isInstance(o)) {\r\n                                    Array.set(array, index, o);\r\n                                } else {\r\n                                    break;\r\n                                }\r\n                            } else if (o instanceof Map) {\r\n                                o = fromMap((Map) o, componentClass);\r\n                                if (componentClass.isInstance(o)) {\r\n                                    Array.set(array, index, o);\r\n                                } else {\r\n                                    break;\r\n                                }\r\n                            }\r\n                        } else {\r\n                            o = value.toValue();\r\n                            if (componentClass.isInstance(o)) {\r\n                                Array.set(array, index, o);\r\n                            } else {\r\n                                Array.set(array, index, Conversions.coerce(componentClass, o));\r\n                            }\r\n                        }\r\n                        index++;\r\n                    }\r\n                    field.setValue(newInstance, array);\r\n            }\r\n            break;\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.image.ImageGray.setTo",
	"Comment": "sets the values of each pixel equal to the pixels in the specified matrix. if the images are not\tthe same shape this will be resized.",
	"Method": "void setTo(T orig){\r\n    if (width != orig.width || height != orig.height)\r\n        reshape(orig.width, orig.height);\r\n    if (!orig.isSubimage() && !isSubimage()) {\r\n        System.arraycopy(orig._getData(), orig.startIndex, _getData(), startIndex, stride * height);\r\n    } else {\r\n        int indexSrc = orig.startIndex;\r\n        int indexDst = startIndex;\r\n        for (int y = 0; y < height; y++) {\r\n            System.arraycopy(orig._getData(), indexSrc, _getData(), indexDst, width);\r\n            indexSrc += orig.stride;\r\n            indexDst += stride;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestNarrowToWidePtoP_F64.rotateCamera",
	"Comment": "rotate the camera and see if the point moves in the expected way",
	"Method": "void rotateCamera(){\r\n    NarrowToWidePtoP_F64 alg = createAlg();\r\n    Point2D_F64 found = new Point2D_F64();\r\n    DMatrixRMaj R = ConvertRotation3D_F64.eulerToMatrix(EulerType.YXZ, 0.1, 0, 0, null);\r\n    alg.setRotationWideToNarrow(R);\r\n    alg.compute(250, 250, found);\r\n    assertTrue(480 < found.x - 5);\r\n    R = ConvertRotation3D_F64.eulerToMatrix(EulerType.YXZ, -0.1, 0, 0, null);\r\n    alg.setRotationWideToNarrow(R);\r\n    alg.compute(250, 250, found);\r\n    assertTrue(480 > found.x + 5);\r\n    R = ConvertRotation3D_F64.eulerToMatrix(EulerType.YXZ, 0, -0.1, 0, null);\r\n    alg.setRotationWideToNarrow(R);\r\n    alg.compute(250, 250, found);\r\n    assertTrue(480 < found.y - 5);\r\n    R = ConvertRotation3D_F64.eulerToMatrix(EulerType.YXZ, 0, 0.1, 0, null);\r\n    alg.setRotationWideToNarrow(R);\r\n    alg.compute(250, 250, found);\r\n    assertTrue(480 > found.y + 5);\r\n}"
}, {
	"Path": "boofcv.alg.feature.color.Histogram_F64.getDimensionIndex",
	"Comment": "given a value it returns the corresponding bin index in this histogram for integer values.the discretion\tis taken in account and 1 is added to the range.",
	"Method": "int getDimensionIndex(int dimension,double value,int getDimensionIndex,int dimension,int value){\r\n    double min = valueMin[dimension];\r\n    double max = valueMax[dimension];\r\n    double fraction = ((value - min) / (max - min + 1.0));\r\n    return (int) (fraction * length[dimension]);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.FitLinesToContour.closestPoint",
	"Comment": "returns the closest point on the contour to the provided point in space",
	"Method": "int closestPoint(Point2D_F64 target){\r\n    double bestDistance = Double.MAX_VALUE;\r\n    int bestIndex = -1;\r\n    for (int i = 0; i < contour.size(); i++) {\r\n        Point2D_I32 c = contour.get(i);\r\n        double d = UtilPoint2D_F64.distanceSq(target.x, target.y, c.x, c.y);\r\n        if (d < bestDistance) {\r\n            bestDistance = d;\r\n            bestIndex = i;\r\n        }\r\n    }\r\n    return bestIndex;\r\n}"
}, {
	"Path": "com.bugsnag.android.Client.getMetaData",
	"Comment": "get the global diagnostic information currently stored in metadata.",
	"Method": "MetaData getMetaData(){\r\n    return config.getMetaData();\r\n}"
}, {
	"Path": "boofcv.alg.distort.radtan.RemoveRadialNtoN_F64.removeRadial",
	"Comment": "static function for removing radial and tangential distortion",
	"Method": "void removeRadial(double x,double y,double[] radial,double t1,double t2,Point2D_F64 out,double tol){\r\n    double origX = x;\r\n    double origY = y;\r\n    double prevSum = 0;\r\n    for (int iter = 0; iter < 500; iter++) {\r\n        double r2 = x * x + y * y;\r\n        double ri2 = r2;\r\n        double sum = 0;\r\n        for (int i = 0; i < radial.length; i++) {\r\n            sum += radial[i] * ri2;\r\n            ri2 *= r2;\r\n        }\r\n        double tx = 2.0 * t1 * x * y + t2 * (r2 + 2.0 * x * x);\r\n        double ty = t1 * (r2 + 2.0 * y * y) + 2.0 * t2 * x * y;\r\n        x = (origX - tx) / (1.0 + sum);\r\n        y = (origY - ty) / (1.0 + sum);\r\n        if (Math.abs(prevSum - sum) <= tol) {\r\n            break;\r\n        } else {\r\n            prevSum = sum;\r\n        }\r\n    }\r\n    out.set(x, y);\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.impl.ImplBinaryNaiveOps.getF",
	"Comment": "if a point is inside the image true is returned if its value is not zero, otherwise false is returned.",
	"Method": "boolean getF(GrayU8 image,int x,int y){\r\n    if (image.isInBounds(x, y)) {\r\n        return image.get(x, y) != 0;\r\n    } else {\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.SessionTrackingPayloadTest.setUp",
	"Comment": "configures a session tracking payload and session store, ensuring that 0 files are present",
	"Method": "void setUp(){\r\n    Context context = InstrumentationRegistry.getContext();\r\n    Configuration config = new Configuration(\"api-key\");\r\n    sessionStore = new SessionStore(config, context);\r\n    Assert.assertNotNull(sessionStore.storeDirectory);\r\n    storageDir = new File(sessionStore.storeDirectory);\r\n    FileUtils.clearFilesInDir(storageDir);\r\n    session = generateSession();\r\n    payload = generatePayloadFromSession(context, generateSession());\r\n    rootNode = streamableToJson(payload);\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapperSimple.fromMap",
	"Comment": "frommap converts a map into a java object.this version will see if there is a class parameter in the map, and dies if there is not.",
	"Method": "T fromMap(Map<String, Object> map,Class<T> cls,Object fromMap,Map<String, Object> map){\r\n    String clazz = (String) map.get(\"class\");\r\n    Class cls = Reflection.loadClass(clazz);\r\n    return fromMap(map, cls);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.getIdleConnectionTestPeriod",
	"Comment": "returns the idleconnectiontestperiod with the specified granularity.",
	"Method": "long getIdleConnectionTestPeriod(long getIdleConnectionTestPeriod,TimeUnit timeUnit){\r\n    return timeUnit.convert(this.idleConnectionTestPeriodInSeconds, TimeUnit.SECONDS);\r\n}"
}, {
	"Path": "boofcv.core.image.GConvertImage.convert",
	"Comment": "converts pixel values in the input image into an integer values from 0 to numvalues.",
	"Method": "void convert(ImageBase input,ImageBase output,GrayU8 convert,ImageGray input,double min,double max,int numValues,GrayU8 output){\r\n    if (min == 0 && max == 255 && numValues == 256) {\r\n        if (output == null)\r\n            output = new GrayU8(input.width, input.height);\r\n        convert(input, output);\r\n        return output;\r\n    }\r\n    ImageDataType type = input.getImageType().getDataType();\r\n    if (type == ImageDataType.U8) {\r\n        return ConvertImage.convert((GrayU8) input, (int) min, (int) max, numValues, output);\r\n    } else if (type == ImageDataType.S8) {\r\n        return ConvertImage.convert((GrayS8) input, (int) min, (int) max, numValues, output);\r\n    } else if (type == ImageDataType.U16) {\r\n        return ConvertImage.convert((GrayU16) input, (int) min, (int) max, numValues, output);\r\n    } else if (type == ImageDataType.S16) {\r\n        return ConvertImage.convert((GrayS16) input, (int) min, (int) max, numValues, output);\r\n    } else if (type == ImageDataType.S32) {\r\n        return ConvertImage.convert((GrayS32) input, (int) min, (int) max, numValues, output);\r\n    } else if (type == ImageDataType.S64) {\r\n        return ConvertImage.convert((GrayS64) input, (long) min, (long) max, numValues, output);\r\n    } else if (type == ImageDataType.F32) {\r\n        return ConvertImage.convert((GrayF32) input, (float) min, (float) max, numValues, output);\r\n    } else if (type == ImageDataType.F64) {\r\n        return ConvertImage.convert((GrayF64) input, min, max, numValues, output);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown image type: \" + type);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.impl.ImplBinaryNaiveOps.getT",
	"Comment": "if a point is inside the image true is returned if its value is not zero, otherwise true is returned.",
	"Method": "boolean getT(GrayU8 image,int x,int y){\r\n    if (image.isInBounds(x, y)) {\r\n        return image.get(x, y) != 0;\r\n    } else {\r\n        return true;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.EquirectangularTools_F32.equiToLatLon",
	"Comment": "converts the equirectangular coordinate into a latitude and longitude",
	"Method": "void equiToLatLon(float x,float y,GeoLL_F32 geo){\r\n    geo.lon = (x / width - 0.5f) * GrlConstants.F_PI2;\r\n    geo.lat = (y / (height - 1) - 0.5f) * GrlConstants.F_PI;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldAdjustRegion.adjustRectangle",
	"Comment": "estimate motion of points inside the rectangle and updates the rectangle using the found motion.",
	"Method": "void adjustRectangle(Rectangle2D_F64 rect,ScaleTranslate2D motion){\r\n    rect.p0.x = rect.p0.x * motion.scale + motion.transX;\r\n    rect.p0.y = rect.p0.y * motion.scale + motion.transY;\r\n    rect.p1.x = rect.p1.x * motion.scale + motion.transX;\r\n    rect.p1.y = rect.p1.y * motion.scale + motion.transY;\r\n}"
}, {
	"Path": "boofcv.alg.misc.GPixelMath.sqrt",
	"Comment": "computes the square root of each pixel in the input image. both the input and output image can be the\tsame instance.",
	"Method": "void sqrt(T input,T output){\r\n    if (input instanceof ImageGray) {\r\n        if (GrayF32.class == input.getClass()) {\r\n            PixelMath.sqrt((GrayF32) input, (GrayF32) output);\r\n        } else if (GrayF64.class == input.getClass()) {\r\n            PixelMath.sqrt((GrayF64) input, (GrayF64) output);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type: \" + input.getClass().getSimpleName());\r\n        }\r\n    } else if (input instanceof Planar) {\r\n        Planar in = (Planar) input;\r\n        Planar out = (Planar) output;\r\n        for (int i = 0; i < in.getNumBands(); i++) {\r\n            sqrt(in.getBand(i), out.getBand(i));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.TestMultiViewOps.computeLines",
	"Comment": "compute lines in each view using epipolar geometry that include point x. the first view is\tin normalized image coordinates",
	"Method": "void computeLines(Point3D_F64 X,Vector3D_F64 line1,Vector3D_F64 line2,Vector3D_F64 line3){\r\n    Point3D_F64 X2 = X.copy();\r\n    X2.y += 1;\r\n    line1.set(computeLine(X, X2, new Se3_F64(), null));\r\n    line2.set(computeLine(X, X2, worldToCam2, K));\r\n    line3.set(computeLine(X, X2, worldToCam3, K));\r\n}"
}, {
	"Path": "boofcv.struct.image.ImageInterleaved.setTo",
	"Comment": "sets this image equal to the specified image. automatically resized to match the input image.",
	"Method": "void setTo(T orig){\r\n    if (orig.width != width || orig.height != height || orig.numBands != numBands)\r\n        reshape(orig.width, orig.height, orig.numBands);\r\n    if (!orig.isSubimage() && !isSubimage()) {\r\n        System.arraycopy(orig._getData(), orig.startIndex, _getData(), startIndex, stride * height);\r\n    } else {\r\n        int indexSrc = orig.startIndex;\r\n        int indexDst = startIndex;\r\n        for (int y = 0; y < height; y++) {\r\n            System.arraycopy(orig._getData(), indexSrc, _getData(), indexDst, width * numBands);\r\n            indexSrc += orig.stride;\r\n            indexDst += stride;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.io.image.ConvertBufferedImage.extractGrayU8",
	"Comment": "for bufferedimage stored as a byte array internally it extracts an\timage.the input image and the returned image will both\tshare the same internal data array.using this function allows unnecessary\tmemory copying to be avoided.",
	"Method": "GrayU8 extractGrayU8(BufferedImage img){\r\n    WritableRaster raster = img.getRaster();\r\n    DataBuffer buffer = raster.getDataBuffer();\r\n    if (buffer.getDataType() == DataBuffer.TYPE_BYTE && isKnownByteFormat(img)) {\r\n        if (raster.getNumBands() != 1)\r\n            throw new IllegalArgumentException(\"Input image has more than one channel\");\r\n        GrayU8 ret = new GrayU8();\r\n        ret.width = img.getWidth();\r\n        ret.height = img.getHeight();\r\n        ret.startIndex = ConvertRaster.getOffset(img.getRaster());\r\n        ret.stride = ConvertRaster.stride(img.getRaster());\r\n        ret.data = ((DataBufferByte) buffer).getData();\r\n        return ret;\r\n    }\r\n    throw new IllegalArgumentException(\"Buffered image does not have a gray scale byte raster\");\r\n}"
}, {
	"Path": "boofcv.alg.geo.h.HomographyTotalLeastSquares.backsubstitution0134",
	"Comment": "backsubstitution for solving for 0,1 and 3,4 using solution for 6,7,8",
	"Method": "void backsubstitution0134(DMatrixRMaj P_plus,DMatrixRMaj P,DMatrixRMaj X,double H){\r\n    final int N = P.numRows;\r\n    DMatrixRMaj tmp = new DMatrixRMaj(N * 2, 1);\r\n    double H6 = H[6];\r\n    double H7 = H[7];\r\n    double H8 = H[8];\r\n    for (int i = 0, index = 0; i < N; i++) {\r\n        double x = -X.data[index], y = -X.data[index + 1];\r\n        double sum = P.data[index++] * H6 + P.data[index++] * H7 + H8;\r\n        tmp.data[i] = x * sum;\r\n        tmp.data[i + N] = y * sum;\r\n    }\r\n    double h0 = 0, h1 = 0, h3 = 0, h4 = 0;\r\n    for (int i = 0; i < N; i++) {\r\n        double P_pls_0 = P_plus.data[i];\r\n        double P_pls_1 = P_plus.data[i + N];\r\n        double tmp_i = tmp.data[i];\r\n        double tmp_j = tmp.data[i + N];\r\n        h0 += P_pls_0 * tmp_i;\r\n        h1 += P_pls_1 * tmp_i;\r\n        h3 += P_pls_0 * tmp_j;\r\n        h4 += P_pls_1 * tmp_j;\r\n    }\r\n    H[0] = -h0;\r\n    H[1] = -h1;\r\n    H[3] = -h3;\r\n    H[4] = -h4;\r\n}"
}, {
	"Path": "boofcv.alg.InputSanityCheck.checkDeclare",
	"Comment": "if the output has not been declared a new instance is declared.if an instance of the output\tis provided its bounds are checked.",
	"Method": "T checkDeclare(T input,T output,Out checkDeclare,In input,Out output,Class<Out> typeOut){\r\n    if (output == null) {\r\n        output = (Out) GeneralizedImageOps.createSingleBand(typeOut, input.width, input.height);\r\n    } else if (output.width != input.width || output.height != input.height)\r\n        throw new IllegalArgumentException(\"Width and/or height of input and output do not match. \" + input.width + \"x\" + input.height + \" \" + output.width + \"x\" + output.height);\r\n    return output;\r\n}"
}, {
	"Path": "com.bugsnag.android.EventReceiver.getIntentFilter",
	"Comment": "creates a new intent filter with all the intents to record breadcrumbs for",
	"Method": "IntentFilter getIntentFilter(){\r\n    IntentFilter filter = new IntentFilter();\r\n    for (String action : actions.keySet()) {\r\n        filter.addAction(action);\r\n    }\r\n    return filter;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldFernClassifier.reset",
	"Comment": "discard all information on fern values and their probabilities",
	"Method": "void reset(){\r\n    for (int i = 0; i < managers.length; i++) managers[i].reset();\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.template.GeneralTemplateMatchTests.subImage",
	"Comment": "provide inputs which are subimages and see if it produces the correct results",
	"Method": "void subImage(){\r\n    GImageMiscOps.fillUniform(image, rand, 0, 200);\r\n    Point2D_I32 a = new Point2D_I32(10, 12);\r\n    Point2D_I32 b = new Point2D_I32(20, 16);\r\n    setTemplate(a.x, a.y);\r\n    setTemplate(b.x, b.y);\r\n    T subImage = BoofTesting.createSubImageOf(image);\r\n    T subTemplate = BoofTesting.createSubImageOf(template);\r\n    alg.setInputImage(subImage);\r\n    alg.process(subTemplate);\r\n    checkExpected(a, b);\r\n    T subMask = BoofTesting.createSubImageOf(mask);\r\n    GImageMiscOps.fill(subMask, 1);\r\n    alg.setInputImage(subImage);\r\n    alg.process(subTemplate, subMask);\r\n    checkExpected(a, b);\r\n}"
}, {
	"Path": "boofcv.android.camera.VideoDisplayActivity.setProgressMessage",
	"Comment": "displays an indeterminate progress dialog. if the dialog is already open this will change the message being\tdisplayed.function blocks until the dialog has been declared.",
	"Method": "void setProgressMessage(String message){\r\n    runOnUiThread(new Runnable() {\r\n        public void run() {\r\n            synchronized (lockProgress) {\r\n                if (progressDialog != null) {\r\n                    progressDialog.setMessage(message);\r\n                    return;\r\n                }\r\n                progressDialog = new ProgressDialog(VideoDisplayActivity.this);\r\n                progressDialog.setMessage(message);\r\n                progressDialog.setIndeterminate(true);\r\n                progressDialog.setProgressStyle(ProgressDialog.STYLE_SPINNER);\r\n            }\r\n            long showTime = System.currentTimeMillis() + 1000;\r\n            while (showTime > System.currentTimeMillis()) {\r\n                Thread.yield();\r\n            }\r\n            synchronized (lockProgress) {\r\n                if (progressDialog != null)\r\n                    progressDialog.show();\r\n            }\r\n        }\r\n    });\r\n    while (progressDialog == null) {\r\n        Thread.yield();\r\n    }\r\n}"
}, {
	"Path": "boofcv.android.camera.VideoDisplayActivity.setProgressMessage",
	"Comment": "displays an indeterminate progress dialog. if the dialog is already open this will change the message being\tdisplayed.function blocks until the dialog has been declared.",
	"Method": "void setProgressMessage(String message){\r\n    synchronized (lockProgress) {\r\n        if (progressDialog != null) {\r\n            progressDialog.setMessage(message);\r\n            return;\r\n        }\r\n        progressDialog = new ProgressDialog(VideoDisplayActivity.this);\r\n        progressDialog.setMessage(message);\r\n        progressDialog.setIndeterminate(true);\r\n        progressDialog.setProgressStyle(ProgressDialog.STYLE_SPINNER);\r\n    }\r\n    long showTime = System.currentTimeMillis() + 1000;\r\n    while (showTime > System.currentTimeMillis()) {\r\n        Thread.yield();\r\n    }\r\n    synchronized (lockProgress) {\r\n        if (progressDialog != null)\r\n            progressDialog.show();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.TestRadialDistortionEstimateLinear.distort",
	"Comment": "applies distortion to the provided pixel in calibrated coordinates",
	"Method": "void distort(Point2D_F64 p,double coef){\r\n    double r = p.x * p.x + p.y * p.y;\r\n    double m = 0;\r\n    for (int i = 0; i < coef.length; i++) {\r\n        m += coef[i] * Math.pow(r, i + 1);\r\n    }\r\n    p.x += p.x * m;\r\n    p.y += p.y * m;\r\n}"
}, {
	"Path": "boofcv.alg.geo.bundle.TestBundleAdjustmentMetricResidualFunction.multipleCalls",
	"Comment": "makes sure that when given the same input it produces the same output",
	"Method": "void multipleCalls(){\r\n    SceneStructureMetric structure = createScene(rand);\r\n    SceneObservations obs = createObservations(rand, structure);\r\n    double[] param = new double[structure.getParameterCount()];\r\n    new CodecSceneStructureMetric().encode(structure, param);\r\n    BundleAdjustmentMetricResidualFunction alg = new BundleAdjustmentMetricResidualFunction();\r\n    alg.configure(structure, obs);\r\n    double[] expected = new double[alg.getNumOfOutputsM()];\r\n    double[] found = new double[alg.getNumOfOutputsM()];\r\n    alg.process(param, expected);\r\n    alg.process(param, found);\r\n    assertArrayEquals(expected, found, UtilEjml.TEST_F64);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldFernClassifier.computeFernValueRand",
	"Comment": "computes the value of a fern after adding noise to the image being sampled.",
	"Method": "int computeFernValueRand(float c_x,float c_y,float rectWidth,float rectHeight,TldFernDescription fern){\r\n    rectWidth -= 1;\r\n    rectHeight -= 1;\r\n    int desc = 0;\r\n    for (int i = 0; i < fern.pairs.length; i++) {\r\n        Point2D_F32 p_a = fern.pairs[i].a;\r\n        Point2D_F32 p_b = fern.pairs[i].b;\r\n        float valA = interpolate.get_fast(c_x + p_a.x * rectWidth, c_y + p_a.y * rectHeight);\r\n        float valB = interpolate.get_fast(c_x + p_b.x * rectWidth, c_y + p_b.y * rectHeight);\r\n        valA += rand.nextGaussian() * fernLearnNoise;\r\n        valB += rand.nextGaussian() * fernLearnNoise;\r\n        desc *= 2;\r\n        if (valA < valB) {\r\n            desc += 1;\r\n        }\r\n    }\r\n    return desc;\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.CalibrationDetectorCircleRegularGrid.createLayout",
	"Comment": "specifies the physical location of each point on the 2d calibration plane.the fiducial is centered on the\tcoordinate system",
	"Method": "List<Point2D_F64> createLayout(int numRows,int numCols,double centerDistance,double diameter){\r\n    List<Point2D_F64> ret = new ArrayList();\r\n    double radius = diameter / 2.0;\r\n    double width = (numCols - 1) * centerDistance;\r\n    double height = (numRows - 1) * centerDistance;\r\n    for (int row = 0; row < numRows; row++) {\r\n        double y = (numRows - row - 1) * centerDistance - height / 2;\r\n        for (int col = 0; col < numCols; col++) {\r\n            double x = col * centerDistance - width / 2;\r\n            ret.add(new Point2D_F64(x, y - radius));\r\n            ret.add(new Point2D_F64(x + radius, y));\r\n            ret.add(new Point2D_F64(x, y + radius));\r\n            ret.add(new Point2D_F64(x - radius, y));\r\n        }\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.TestGeneralFeatureDetector.handleLocalMinMaxFlags",
	"Comment": "makes sure flags that indicate the presence of local minimums and maximums are handled correctly",
	"Method": "void handleLocalMinMaxFlags(){\r\n    HelperIntensity intensity = new HelperIntensity(false, false, true);\r\n    HelperExtractor extractor = new HelperExtractor(true, true);\r\n    intensity.minimums = false;\r\n    intensity.minimums = false;\r\n    intensity.maximums = false;\r\n    extractor.maximums = false;\r\n    GeneralFeatureDetector<GrayF32, GrayF32> detector = new GeneralFeatureDetector(intensity, extractor);\r\n    assertFalse(detector.isDetectMinimums());\r\n    assertFalse(detector.isDetectMaximums());\r\n    intensity.minimums = true;\r\n    intensity.minimums = true;\r\n    intensity.maximums = false;\r\n    extractor.maximums = false;\r\n    detector = new GeneralFeatureDetector(intensity, extractor);\r\n    assertTrue(detector.isDetectMinimums());\r\n    assertFalse(detector.isDetectMaximums());\r\n    intensity.minimums = false;\r\n    intensity.minimums = false;\r\n    intensity.maximums = true;\r\n    extractor.maximums = true;\r\n    detector = new GeneralFeatureDetector(intensity, extractor);\r\n    assertFalse(detector.isDetectMinimums());\r\n    assertTrue(detector.isDetectMaximums());\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.impl.ImplOrientationAverageGradientIntegral.computeWeighted",
	"Comment": "compute the gradient while checking for border conditions",
	"Method": "double computeWeighted(double tl_x,double tl_y,double samplePeriod,SparseImageGradient<T, G> g){\r\n    tl_x += 0.5;\r\n    tl_y += 0.5;\r\n    double Dx = 0, Dy = 0;\r\n    int i = 0;\r\n    for (int y = 0; y < sampleWidth; y++) {\r\n        int pixelsY = (int) (tl_y + y * samplePeriod);\r\n        for (int x = 0; x < sampleWidth; x++, i++) {\r\n            int pixelsX = (int) (tl_x + x * samplePeriod);\r\n            double w = weights.data[i];\r\n            GradientValue v = g.compute(pixelsX, pixelsY);\r\n            Dx += w * v.getX();\r\n            Dy += w * v.getY();\r\n        }\r\n    }\r\n    return Math.atan2(Dy, Dx);\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.FundamentalLinear8.process",
	"Comment": "computes a fundamental or essential matrix from a set of associated point correspondences.",
	"Method": "boolean process(List<AssociatedPair> points,DMatrixRMaj solution,boolean process,DMatrixRMaj A,DMatrixRMaj F){\r\n    if (!solverNull.process(A, 1, F))\r\n        return true;\r\n    F.numRows = 3;\r\n    F.numCols = 3;\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.factory.weights.FactoryWeights.pixel",
	"Comment": "creates a weight function for the provided distributions.",
	"Method": "WeightPixel_F32 pixel(WeightType type,boolean safe){\r\n    if (safe)\r\n        throw new IllegalArgumentException(\"Safe distributons not implemented yet\");\r\n    switch(type) {\r\n        case GAUSSIAN_SQ:\r\n            return new WeightPixelGaussian_F32();\r\n        case UNIFORM:\r\n            return new WeightPixelUniform_F32();\r\n    }\r\n    throw new IllegalArgumentException(\"Unknown type \" + type);\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.GenericPlanarCalibrationDetectorChecks.checkDetectionsResetOnFailure",
	"Comment": "first call something was detected, second call nothing was detected.it should return an empty list",
	"Method": "void checkDetectionsResetOnFailure(){\r\n    DetectorFiducialCalibration detector = createDetector(targetConfigs.get(0));\r\n    GrayF32 original = renderEasy(targetConfigs.get(0), null);\r\n    detector.process(original);\r\n    assertTrue(detector.getDetectedPoints().size() > 0);\r\n    detector.process(new GrayF32(300, 400));\r\n    assertTrue(detector.getDetectedPoints() != null);\r\n    assertTrue(detector.getDetectedPoints().size() == 0);\r\n}"
}, {
	"Path": "boofcv.abst.feature.detdesc.TestDetectDescribeMultiFusion.checkFeatureNotInBounds",
	"Comment": "if a feature is not in bounds make sure everything is handled correctly",
	"Method": "void checkFeatureNotInBounds(){\r\n    DetectorInterestPointMulti detector = new DummyDetector(2);\r\n    DescribeRegionPoint describe = new TestDetectDescribeFusion.DummyRegionPoint();\r\n    DetectDescribeMultiFusion alg = new DetectDescribeMultiFusion(detector, null, describe);\r\n    alg.process(new GrayF32(2, 2));\r\n    assertEquals(2, alg.getNumberOfSets());\r\n    for (int n = 0; n < alg.getNumberOfSets(); n++) {\r\n        PointDescSet set = alg.getFeatureSet(n);\r\n        if (n == 0)\r\n            assertEquals(n + 8, set.getNumberOfFeatures());\r\n        else\r\n            assertEquals(n + 9, set.getNumberOfFeatures());\r\n        for (int i = 0; i < set.getNumberOfFeatures(); i++) {\r\n            assertTrue(set.getDescription(i) != null);\r\n            assertTrue(set.getLocation(i) != null);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.transform.wavelet.TestWaveletTransformOps.smallImage1",
	"Comment": "see if images which are the smallest possible can be transformed.",
	"Method": "void smallImage1(){\r\n    for (Class t : types) {\r\n        testSmallImage1(t);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.distanceSq",
	"Comment": "using double prevision here instead of int due to fear of overflow in very large images",
	"Method": "double distanceSq(Point2D_I32 a,Point2D_I32 b){\r\n    double dx = b.x - a.x;\r\n    double dy = b.y - a.y;\r\n    return dx * dx + dy * dy;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareCrossClustersIntoGrids.addToRow",
	"Comment": "given a node and the corner to the next node down the line, add to the list every other node until\tit hits the end of the row.",
	"Method": "boolean addToRow(SquareNode n,int corner,int sign,boolean skip,List<SquareNode> row){\r\n    SquareEdge e;\r\n    while ((e = n.edges[corner]) != null) {\r\n        if (e.a == n) {\r\n            n = e.b;\r\n            corner = e.sideB;\r\n        } else {\r\n            n = e.a;\r\n            corner = e.sideA;\r\n        }\r\n        if (!skip) {\r\n            if (n.graph != SquareNode.RESET_GRAPH) {\r\n                invalid = true;\r\n                return false;\r\n            }\r\n            n.graph = 0;\r\n            row.add(n);\r\n        }\r\n        skip = !skip;\r\n        sign *= -1;\r\n        corner = addOffset(corner, sign, n.square.size());\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.getConnectionTimeout",
	"Comment": "returns the connectiontimeout with the specified granularity.",
	"Method": "long getConnectionTimeout(long getConnectionTimeout,TimeUnit timeUnit){\r\n    return timeUnit.convert(this.connectionTimeoutInMs, TimeUnit.MILLISECONDS);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.edge.ScoreLineSegmentEdge.computeAverageDerivative",
	"Comment": "returns average tangential derivative along the line segment.derivative is computed in direction\tof tangent.a positive step in the tangent direction will have a positive value.if all samples\tgo outside the image then zero is returned.",
	"Method": "double computeAverageDerivative(Point2D_F64 a,Point2D_F64 b,double tanX,double tanY){\r\n    samplesInside = 0;\r\n    averageUp = averageDown = 0;\r\n    for (int i = 0; i < numSamples; i++) {\r\n        double x = (b.x - a.x) * i / (numSamples - 1) + a.x;\r\n        double y = (b.y - a.y) * i / (numSamples - 1) + a.y;\r\n        double x0 = x + tanX;\r\n        double y0 = y + tanY;\r\n        if (!BoofMiscOps.checkInside(integralImage.getWidth(), integralImage.getHeight(), x0, y0))\r\n            continue;\r\n        double x1 = x - tanX;\r\n        double y1 = y - tanY;\r\n        if (!BoofMiscOps.checkInside(integralImage.getWidth(), integralImage.getHeight(), x1, y1))\r\n            continue;\r\n        samplesInside++;\r\n        double up = integral.compute(x, y, x0, y0);\r\n        double down = integral.compute(x, y, x1, y1);\r\n        averageUp += up;\r\n        averageDown += down;\r\n    }\r\n    if (samplesInside == 0)\r\n        return 0;\r\n    averageUp /= samplesInside;\r\n    averageDown /= samplesInside;\r\n    return averageUp - averageDown;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestBoneCP.testGetConnectionLimitsHit",
	"Comment": "if we hit our limit, we should signal for more connections to be created on the fly",
	"Method": "void testGetConnectionLimitsHit(){\r\n    reset(mockPartition, mockConnectionHandles, mockConnection);\r\n    expect(mockConfig.getPoolAvailabilityThreshold()).andReturn(0).anyTimes();\r\n    expect(mockPartition.isUnableToCreateMoreTransactions()).andReturn(false).anyTimes();\r\n    expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes();\r\n    expect(mockPartition.getMaxConnections()).andReturn(10).anyTimes();\r\n    expect(mockPartition.getAvailableConnections()).andReturn(1).anyTimes();\r\n    BlockingQueue<Object> bq = new ArrayBlockingQueue<Object>(1);\r\n    bq.add(new Object());\r\n    expect(mockPartition.getPoolWatchThreadSignalQueue()).andReturn(bq);\r\n    expect(mockConnectionHandles.poll()).andReturn(mockConnection).once();\r\n    mockConnection.renewConnection();\r\n    expectLastCall().once();\r\n    replay(mockPartition, mockConnectionHandles, mockConnection);\r\n    testClass.getConnection();\r\n    verify(mockPartition, mockConnectionHandles, mockConnection);\r\n}"
}, {
	"Path": "boofcv.misc.CircularIndex.subtract",
	"Comment": "subtracts index1 from index0. positive number if its closer in the positive\tdirection or negative if closer in the negative direction.if equal distance then\tit will return a negative number.",
	"Method": "int subtract(int index0,int index1,int size){\r\n    int distance = distanceP(index0, index1, size);\r\n    if (distance >= size / 2 + size % 2) {\r\n        return distance - size;\r\n    } else {\r\n        return distance;\r\n    }\r\n}"
}, {
	"Path": "org.boon.core.value.ValueMapImpl.size",
	"Comment": "return the size of the map. use the map if it has already been created.",
	"Method": "int size(){\r\n    this.buildIfNeededMap();\r\n    return map.size();\r\n}"
}, {
	"Path": "com.gazbert.bxbot.core.engine.TestTradingEngine.testEngineExecutesTradeCyclesAndCanBeShutdownSuccessfully",
	"Comment": "tests the engine starts up and executes trade cycles successfully.scenario is at least one successful trade cycle and then we shut it down.",
	"Method": "void testEngineExecutesTradeCyclesAndCanBeShutdownSuccessfully(){\r\n    setupConfigLoadingExpectations();\r\n    final Map<String, BigDecimal> balancesAvailable = new HashMap();\r\n    balancesAvailable.put(ENGINE_EMERGENCY_STOP_CURRENCY, new BigDecimal(\"0.5\"));\r\n    final BalanceInfo balanceInfo = PowerMock.createMock(BalanceInfo.class);\r\n    expect(exchangeAdapter.getBalanceInfo()).andReturn(balanceInfo).atLeastOnce();\r\n    expect(balanceInfo.getBalancesAvailable()).andReturn(balancesAvailable).atLeastOnce();\r\n    tradingStrategy.execute();\r\n    expectLastCall().atLeastOnce();\r\n    PowerMock.replayAll();\r\n    final TradingEngine tradingEngine = new TradingEngine(exchangeConfigService, engineConfigService, strategyConfigService, marketConfigService, emailAlerter);\r\n    final Executor executor = Executors.newSingleThreadExecutor();\r\n    executor.execute(tradingEngine::start);\r\n    waitForEngineStateChange(tradingEngine, EngineState.RUNNING, NUMBER_OF_TRADE_CYCLES);\r\n    assertTrue(tradingEngine.isRunning());\r\n    tradingEngine.shutdown();\r\n    waitForEngineStateChange(tradingEngine, EngineState.SHUTDOWN, NUMBER_OF_TRADE_CYCLES);\r\n    assertFalse(tradingEngine.isRunning());\r\n    PowerMock.verifyAll();\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.watershed.WatershedVincentSoille1991.removeWatersheds",
	"Comment": "removes watershed pixels from the output image by merging them into an arbitrary neighbor.",
	"Method": "void removeWatersheds(){\r\n    removedWatersheds = true;\r\n    removeWatersheds.remove(output);\r\n}"
}, {
	"Path": "boofcv.factory.interpolate.FactoryInterpolation.createPixelS",
	"Comment": "creates an interpolation class of the specified type for the specified image type.",
	"Method": "InterpolatePixelS<T> createPixelS(double min,double max,InterpolationType type,BorderType borderType,ImageDataType dataType,InterpolatePixelS<T> createPixelS,double min,double max,InterpolationType type,BorderType borderType,Class<T> imageType){\r\n    InterpolatePixelS<T> alg;\r\n    switch(type) {\r\n        case NEAREST_NEIGHBOR:\r\n            alg = nearestNeighborPixelS(imageType);\r\n            break;\r\n        case BILINEAR:\r\n            return bilinearPixelS(imageType, borderType);\r\n        case BICUBIC:\r\n            alg = bicubicS(-0.5f, (float) min, (float) max, imageType);\r\n            break;\r\n        case POLYNOMIAL4:\r\n            alg = polynomialS(4, min, max, imageType);\r\n            break;\r\n        default:\r\n            throw new IllegalArgumentException(\"Add type: \" + type);\r\n    }\r\n    if (borderType != null)\r\n        alg.setBorder(FactoryImageBorder.single(imageType, borderType));\r\n    return alg;\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.UtilLepetitEPnP.computeCameraControl",
	"Comment": "computes the camera control points as weighted sum of null points.",
	"Method": "void computeCameraControl(double beta,List<Point3D_F64> nullPts,FastQueue<Point3D_F64> cameraPts,int numControl){\r\n    cameraPts.reset();\r\n    for (int i = 0; i < numControl; i++) {\r\n        cameraPts.grow().set(0, 0, 0);\r\n    }\r\n    for (int i = 0; i < numControl; i++) {\r\n        double b = beta[i];\r\n        for (int j = 0; j < numControl; j++) {\r\n            Point3D_F64 s = cameraPts.get(j);\r\n            Point3D_F64 p = nullPts[i].get(j);\r\n            s.x += b * p.x;\r\n            s.y += b * p.y;\r\n            s.z += b * p.z;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.rectify.RectifyFundamental.process",
	"Comment": "compute rectification transforms for the stereo pair given a fundamental matrix and its observations.",
	"Method": "void process(DMatrixRMaj F,List<AssociatedPair> observations,int width,int height){\r\n    int centerX = width / 2;\r\n    int centerY = height / 2;\r\n    MultiViewOps.extractEpipoles(F, epipole1, epipole2);\r\n    checkEpipoleInside(width, height);\r\n    SimpleMatrix R = rotateEpipole(epipole2, centerX, centerY);\r\n    SimpleMatrix T = translateToOrigin(centerX, centerY);\r\n    SimpleMatrix G = computeG(epipole2, centerX, centerY);\r\n    SimpleMatrix H = G.mult(R).mult(T);\r\n    SimpleMatrix Hzero = computeHZero(F, epipole2, H);\r\n    SimpleMatrix Ha = computeAffineH(observations, H.getDDRM(), Hzero.getDDRM());\r\n    rect1.set(Ha.mult(Hzero).getDDRM());\r\n    rect2.set(H.getDDRM());\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.TrackerMeanShiftComaniciu2003.updateWeights",
	"Comment": "update the weights for each element in the histogram.weights are used to favor colors which are\tless than expected.",
	"Method": "void updateWeights(float[] histogram){\r\n    for (int j = 0; j < weightHistogram.length; j++) {\r\n        float h = histogram[j];\r\n        if (h != 0) {\r\n            weightHistogram[j] = (float) Math.sqrt(keyHistogram[j] / h);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.getDelivery",
	"Comment": "retrieves the delivery used to make http requests to bugsnag.",
	"Method": "Delivery getDelivery(){\r\n    return delivery;\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.TestCameraToEquirectangular_F64.canonicalIsPointedPositiveZ",
	"Comment": "makes sure the canonical orientation is pointed along the positive z axis.this is done by projecting\tthe center of the pinhole at default orientation.",
	"Method": "void canonicalIsPointedPositiveZ(){\r\n    CameraPinholeRadial intrinsic = new CameraPinholeRadial(400, 400, 0, imgWidth / 2, imgHeight / 2, imgWidth, imgHeight);\r\n    intrinsic.setRadial(0.1, 0.2);\r\n    CameraToEquirectangular_F64 alg = new CameraToEquirectangular_F64();\r\n    alg.setCameraModel(intrinsic);\r\n    alg.setEquirectangularShape(equiWidth, equiHeight);\r\n    assertPointing(alg, imgWidth / 2, imgHeight / 2, 0, 0, 1);\r\n}"
}, {
	"Path": "boofcv.alg.distort.GeneralLensDistortionWideFOVChecks.blowup_extreme_angle_F32",
	"Comment": "give it spherical coordinate pointing slightly behind.see if it blows up when converting into pixels",
	"Method": "void blowup_extreme_angle_F32(){\r\n    LensDistortionWideFOV alg = create();\r\n    Point3Transform2_F32 distort = alg.distortStoP_F32();\r\n    Point2D_F32 found = new Point2D_F32();\r\n    float x = 1.0f;\r\n    float z = -0.001f;\r\n    float r = (float) Math.sqrt(x * x + z * z);\r\n    distort.compute(x / r, 0, z / x, found);\r\n    assertTrue(!UtilEjml.isUncountable(found.x));\r\n    assertTrue(!UtilEjml.isUncountable(found.y));\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.fh04.SegmentFelzenszwalbHuttenlocher04.mergeSmallRegions",
	"Comment": "look at the remaining regions and if there are any small ones marge them into a larger region",
	"Method": "void mergeSmallRegions(){\r\n    for (int i = 0; i < edgesNotMatched.size(); i++) {\r\n        Edge e = edgesNotMatched.get(i);\r\n        int rootA = find(e.indexA);\r\n        int rootB = find(e.indexB);\r\n        if (rootA == rootB)\r\n            continue;\r\n        int sizeA = regionSize.get(rootA);\r\n        int sizeB = regionSize.get(rootB);\r\n        if (sizeA < minimumSize || sizeB < minimumSize) {\r\n            graph.data[e.indexB] = rootA;\r\n            graph.data[rootB] = rootA;\r\n            regionSize.data[rootA] = sizeA + sizeB;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.distort.ChecksPointDeformKeyPoints.individualSrcSameAsAll",
	"Comment": "makes sure modifying a single points is the same as modifying all the points at once",
	"Method": "void individualSrcSameAsAll(){\r\n    List<Point2D_F32> src = createTestPoints();\r\n    List<Point2D_F32> dst = createTestPoints();\r\n    PointDeformKeyPoints alg = createAlgorithm();\r\n    alg.setImageShape(80, 100);\r\n    alg.setSource(src);\r\n    alg.setSource(dst);\r\n    alg.setSource(1, 20, 25);\r\n    Point2D_F32 expected = new Point2D_F32();\r\n    alg.compute(12, 19.5f, expected);\r\n    src.get(1).set(20, 25);\r\n    Point2D_F32 found = new Point2D_F32();\r\n    alg.compute(12, 19.5f, found);\r\n    assertEquals(expected.x, found.x, GrlConstants.TEST_F32);\r\n    assertEquals(expected.y, found.y, GrlConstants.TEST_F32);\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernel.random2D_I32",
	"Comment": "creates a random 2d kernel drawn from a uniform distribution.",
	"Method": "Kernel2D_S32 random2D_I32(int width,int offset,int min,int max,Random rand){\r\n    Kernel2D_S32 ret = new Kernel2D_S32(width, offset);\r\n    int range = max - min;\r\n    for (int i = 0; i < ret.data.length; i++) {\r\n        ret.data[i] = rand.nextInt(range) + min;\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "com.bugsnag.android.Bugsnag.setUserId",
	"Comment": "set a unique identifier for the user currently using your application.by default, this will be an automatically generated unique idyou can search for this information in your bugsnag dashboard.",
	"Method": "void setUserId(String id){\r\n    getClient().setUserId(id);\r\n}"
}, {
	"Path": "com.bugsnag.android.JsonWriter.beforeValue",
	"Comment": "inserts any necessary separators and whitespace before a literal value,inline array, or inline object. also adjusts the stack to expect either aclosing bracket or another element.",
	"Method": "void beforeValue(boolean root){\r\n    switch(peek()) {\r\n        case NONEMPTY_DOCUMENT:\r\n            if (!lenient) {\r\n                throw new IllegalStateException(\"JSON must have only one top-level value.\");\r\n            }\r\n        case EMPTY_DOCUMENT:\r\n            if (!lenient && !root) {\r\n                throw new IllegalStateException(\"JSON must start with an array or an object.\");\r\n            }\r\n            replaceTop(JsonScope.NONEMPTY_DOCUMENT);\r\n            break;\r\n        case EMPTY_ARRAY:\r\n            replaceTop(JsonScope.NONEMPTY_ARRAY);\r\n            newline();\r\n            break;\r\n        case NONEMPTY_ARRAY:\r\n            out.append(',');\r\n            newline();\r\n            break;\r\n        case DANGLING_NAME:\r\n            out.append(separator);\r\n            replaceTop(JsonScope.NONEMPTY_OBJECT);\r\n            break;\r\n        default:\r\n            throw new IllegalStateException(\"Nesting problem: \" + stack);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldRegionTracker.updateCurrent",
	"Comment": "computes the gradient and changes the reference to the current pyramid",
	"Method": "void updateCurrent(ImagePyramid<I> image){\r\n    this.currentImage = image;\r\n    for (int i = 0; i < image.getNumLayers(); i++) {\r\n        gradient.process(image.getLayer(i), currentDerivX[i], currentDerivY[i]);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.TestSiftDetector.processFeatureCandidate_Shift",
	"Comment": "the feature intensity is no longer symmetric.see if the interpolated peak moves in the expected direction\taway from the pixel level peak.",
	"Method": "void processFeatureCandidate_Shift(){\r\n    GrayF32 upper = new GrayF32(30, 40);\r\n    GrayF32 current = new GrayF32(30, 40);\r\n    GrayF32 lower = new GrayF32(30, 40);\r\n    SiftDetector alg = createDetector();\r\n    alg.pixelScaleToInput = 2.0;\r\n    alg.sigmaLower = 4;\r\n    alg.sigmaTarget = 5;\r\n    alg.sigmaUpper = 6;\r\n    alg.dogLower = lower;\r\n    alg.dogTarget = current;\r\n    alg.dogUpper = upper;\r\n    alg.derivXX.setImage(current);\r\n    alg.derivXY.setImage(current);\r\n    alg.derivYY.setImage(current);\r\n    int x = 15, y = 16;\r\n    for (float sign : new float[] { -1, 1 }) {\r\n        alg.detections.reset();\r\n        current.set(x, y - 1, sign * 90);\r\n        current.set(x, y, sign * 100);\r\n        current.set(x, y + 1, sign * 80);\r\n        current.set(x - 1, y, sign * 90);\r\n        current.set(x + 1, y, sign * 80);\r\n        upper.set(x, y, sign * 80);\r\n        lower.set(x, y, sign * 90);\r\n        alg.processFeatureCandidate(15, 16, sign * 100, sign > 0);\r\n        ScalePoint p = alg.getDetections().get(0);\r\n        assertTrue(Math.abs(x * 2 - p.x) < 2);\r\n        assertTrue(Math.abs(y * 2 - p.y) < 2);\r\n        assertTrue(Math.abs(5 - p.scale) < 2);\r\n        assertTrue(x * 2 > p.x);\r\n        assertTrue(y * 2 > p.y);\r\n        assertTrue(5 > p.scale);\r\n        upper.set(x, y, sign * 90);\r\n        lower.set(x, y, sign * 80);\r\n        alg.detections.reset();\r\n        alg.processFeatureCandidate(15, 16, sign * 100, sign > 0);\r\n        assertTrue(Math.abs(5 - p.scale) < 2);\r\n        assertTrue(5 < p.scale);\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.feature.describe.FactoryDescribeRegionPoint.surfColorFast",
	"Comment": "color variant of the surf descriptor which has been designed for speed and sacrifices some stability.",
	"Method": "DescribeRegionPoint<T, BrightFeature> surfColorFast(ConfigSurfDescribe.Speed config,ImageType<T> imageType){\r\n    Class bandType = imageType.getImageClass();\r\n    Class<II> integralType = GIntegralImageOps.getIntegralType(bandType);\r\n    DescribePointSurf<II> alg = FactoryDescribePointAlgs.surfSpeed(config, integralType);\r\n    if (imageType.getFamily() == ImageType.Family.PLANAR) {\r\n        DescribePointSurfPlanar<II> color = FactoryDescribePointAlgs.surfColor(alg, imageType.getNumBands());\r\n        return new SurfPlanar_to_DescribeRegionPoint(color, bandType, integralType);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown image type\");\r\n    }\r\n}"
}, {
	"Path": "org.boon.collections.FloatList.toFloatList",
	"Comment": "creates a primitive list based on an input list and a property path",
	"Method": "FloatList toFloatList(Collection<?> inputList,String propertyPath){\r\n    if (inputList.size() == 0) {\r\n        return new FloatList(0);\r\n    }\r\n    FloatList outputList = new FloatList(inputList.size());\r\n    if (propertyPath.contains(\".\") || propertyPath.contains(\"[\")) {\r\n        String[] properties = StringScanner.splitByDelimiters(propertyPath, \".[]\");\r\n        for (Object o : inputList) {\r\n            outputList.add(BeanUtils.getPropertyFloat(o, properties));\r\n        }\r\n    } else {\r\n        Map<String, FieldAccess> fields = BeanUtils.getFieldsFromObject(inputList.iterator().next());\r\n        FieldAccess fieldAccess = fields.get(propertyPath);\r\n        for (Object o : inputList) {\r\n            outputList.add(fieldAccess.getFloat(o));\r\n        }\r\n    }\r\n    return outputList;\r\n}"
}, {
	"Path": "test.me.corriekay.pokegoutil.gui.controller.LogControllerTest.linesArePrintedCorrectly",
	"Comment": "test for test lines are captured in the text area in the right order.",
	"Method": "void linesArePrintedCorrectly(){\r\n    printLines();\r\n    final String[] textareaLines = getLines();\r\n    for (int i = 0; i < numOfLines; i++) {\r\n        assertThat(\"line contains printed text\", textareaLines[i], containsString(testLines[i]));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.SiftScaleSpace.applyGaussian",
	"Comment": "applies the separable kernel to the input image and stores the results in the output image.",
	"Method": "void applyGaussian(GrayF32 input,GrayF32 output,Kernel1D kernel){\r\n    tempBlur.reshape(input.width, input.height);\r\n    GConvolveImageOps.horizontalNormalized(kernel, input, tempBlur);\r\n    GConvolveImageOps.verticalNormalized(kernel, tempBlur, output);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.MetricSceneGraph.sanityCheck",
	"Comment": "performs simple checks to see if the data structure is avlid",
	"Method": "void sanityCheck(){\r\n    for (View v : nodes) {\r\n        for (Motion m : v.connections) {\r\n            if (m.viewDst != v && m.viewSrc != v)\r\n                throw new RuntimeException(\"Not member of connection\");\r\n        }\r\n    }\r\n    for (Motion m : edges) {\r\n        if (m.viewDst != m.destination(m.viewSrc))\r\n            throw new RuntimeException(\"Unexpected result\");\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionMaxAgeTester.testConnectionExpired",
	"Comment": "tests that a partition with expired connections should those connections killed off.",
	"Method": "void testConnectionExpired(){\r\n    BlockingQueue<ConnectionHandle> mockQueue = createNiceMock(LinkedBlockingQueue.class);\r\n    expect(mockConnectionPartition.getAvailableConnections()).andReturn(1);\r\n    expect(mockConnectionPartition.getFreeConnections()).andReturn(mockQueue).anyTimes();\r\n    ConnectionHandle mockConnectionExpired = createNiceMock(ConnectionHandle.class);\r\n    ConnectionHandle mockConnection = createNiceMock(ConnectionHandle.class);\r\n    expect(mockQueue.poll()).andReturn(mockConnectionExpired).once();\r\n    expect(mockConnectionExpired.isExpired(anyLong())).andReturn(true).once();\r\n    expect(mockExecutor.isShutdown()).andReturn(false).once();\r\n    mockConnectionExpired.internalClose();\r\n    expectLastCall().once();\r\n    mockPool.postDestroyConnection(mockConnectionExpired);\r\n    expectLastCall().once();\r\n    expect(mockExecutor.schedule((Callable) anyObject(), anyLong(), (TimeUnit) anyObject())).andReturn(null).once();\r\n    replay(mockQueue, mockExecutor, mockConnectionPartition, mockConnection, mockPool, mockConnectionExpired);\r\n    testClass.run();\r\n    verify(mockConnectionExpired);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setServiceOrder",
	"Comment": "sets the queue serviceorder. values currently understood are fifo and lifo.",
	"Method": "void setServiceOrder(String serviceOrder){\r\n    this.serviceOrder = checkNotNull(serviceOrder);\r\n}"
}, {
	"Path": "boofcv.alg.transform.wavelet.UtilWavelet.computeDiv",
	"Comment": "returns the number that the output image needs to be divisible by.",
	"Method": "int computeDiv(int level){\r\n    if (level <= 1)\r\n        return 2;\r\n    return (int) Math.pow(2, level - 1);\r\n}"
}, {
	"Path": "com.bugsnag.android.DeviceData.getScreenDensityDpi",
	"Comment": "the screen density of the current android device in dpi, eg. 320",
	"Method": "Integer getScreenDensityDpi(){\r\n    if (displayMetrics != null) {\r\n        return displayMetrics.densityDpi;\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestCachedConnectionStrategy.testMoreThreadsThanConnectionsSteal",
	"Comment": "same test as above but this time the threads are done from using it. all connections should go back to the normal queue in the fallback\tstrategy.",
	"Method": "void testMoreThreadsThanConnectionsSteal(){\r\n    BoneCPConfig config = this.config.clone();\r\n    config.setNullOnConnectionTimeout(false);\r\n    config.setConnectionTimeoutInMs(Long.MAX_VALUE);\r\n    poolClass = new BoneCP(config);\r\n    final CountDownLatch cdl = new CountDownLatch(5);\r\n    for (int i = 0; i < 5; i++) {\r\n        new Thread() {\r\n            public void run() {\r\n                try {\r\n                    Connection c = poolClass.getConnection();\r\n                    c.close();\r\n                    cdl.countDown();\r\n                } catch (SQLException e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        }.start();\r\n    }\r\n    cdl.await();\r\n    poolClass.getConnection().close();\r\n    assertFalse(poolClass.cachedPoolStrategy);\r\n    assertEquals(5, poolClass.partitions[0].getFreeConnections().size());\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestCachedConnectionStrategy.testMoreThreadsThanConnectionsSteal",
	"Comment": "same test as above but this time the threads are done from using it. all connections should go back to the normal queue in the fallback\tstrategy.",
	"Method": "void testMoreThreadsThanConnectionsSteal(){\r\n    try {\r\n        Connection c = poolClass.getConnection();\r\n        c.close();\r\n        cdl.countDown();\r\n    } catch (SQLException e) {\r\n        e.printStackTrace();\r\n    }\r\n}"
}, {
	"Path": "org.boon.Boon._log",
	"Comment": "gets a console logger if in debug mode otherwise gets a logger with the nameboon.system.",
	"Method": "Logger _log(){\r\n    if (debugOn()) {\r\n        return new Logger(new TerminalLogger().level(LogLevel.DEBUG));\r\n    } else {\r\n        return logger == null ? configurableLogger(\"BOON.SYSTEM\") : logger;\r\n    }\r\n}"
}, {
	"Path": "boofcv.android.VisualizeImageData.regionBorders",
	"Comment": "draws border pixels of each region using the specified color.",
	"Method": "void regionBorders(GrayS32 pixelToRegion,int borderColor,Bitmap output,byte[] storage){\r\n    if (storage == null)\r\n        storage = declareStorage(output, null);\r\n    GrayU8 binary = new GrayU8(pixelToRegion.width, pixelToRegion.height);\r\n    ImageSegmentationOps.markRegionBorders(pixelToRegion, binary);\r\n    int indexOut = 0;\r\n    for (int y = 0; y < binary.height; y++) {\r\n        for (int x = 0; x < binary.width; x++) {\r\n            if (binary.unsafe_get(x, y) != 0) {\r\n                storage[indexOut++] = (byte) (borderColor & 0xFF);\r\n                storage[indexOut++] = (byte) ((borderColor >> 8) & 0xFF);\r\n                storage[indexOut++] = (byte) ((borderColor >> 16) & 0xFF);\r\n                storage[indexOut++] = (byte) 0xFF;\r\n            } else {\r\n                indexOut += 4;\r\n            }\r\n        }\r\n    }\r\n    output.copyPixelsFromBuffer(ByteBuffer.wrap(storage));\r\n}"
}, {
	"Path": "boofcv.alg.filter.derivative.GImageDerivativeOps.getDerivativeType",
	"Comment": "returns the type of image the derivative should be for the specified input type.",
	"Method": "Class<D> getDerivativeType(Class<I> imageType,ImageType<D> getDerivativeType,ImageType<I> imageType){\r\n    switch(imageType.getFamily()) {\r\n        case GRAY:\r\n            return ImageType.single(getDerivativeType(imageType.getImageClass()));\r\n        case PLANAR:\r\n            {\r\n                int numBands = imageType.getNumBands();\r\n                return ImageType.pl(numBands, getDerivativeType(imageType.getImageClass()));\r\n            }\r\n        case INTERLEAVED:\r\n            int numBands = imageType.getNumBands();\r\n            switch(imageType.getDataType()) {\r\n                case F32:\r\n                    return (ImageType) ImageType.il(numBands, ImageDataType.F32);\r\n                case F64:\r\n                    return (ImageType) ImageType.il(numBands, ImageDataType.F64);\r\n                case U8:\r\n                    return (ImageType) ImageType.il(numBands, ImageDataType.S16);\r\n                case U16:\r\n                    return (ImageType) ImageType.il(numBands, ImageDataType.S32);\r\n            }\r\n    }\r\n    throw new IllegalArgumentException(\"Unknown image type\");\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.ConnectLinesGrid.connectInSameElement",
	"Comment": "search for lines in the same region for it to be connected to.",
	"Method": "void connectInSameElement(List<LineSegment2D_F32> lines){\r\n    for (int i = 0; i < lines.size(); i++) {\r\n        LineSegment2D_F32 a = lines.get(i);\r\n        int index = findBestCompatible(a, lines, i + 1);\r\n        if (index == -1)\r\n            continue;\r\n        LineSegment2D_F32 b = lines.remove(index);\r\n        Point2D_F32 pt0 = farthestIndex < 2 ? a.a : a.b;\r\n        Point2D_F32 pt1 = (farthestIndex % 2) == 0 ? b.a : b.b;\r\n        a.a.set(pt0);\r\n        a.b.set(pt1);\r\n    }\r\n}"
}, {
	"Path": "org.boofcv.video.GradientActivity.onCameraResolutionChange",
	"Comment": "during camera initialization this function is called once after the resolution is known.\tthis is a good function to override and predeclare data structres which are dependent\ton the video feeds resolution.",
	"Method": "void onCameraResolutionChange(int width,int height,int sensorOrientation){\r\n    super.onCameraResolutionChange(width, height, sensorOrientation);\r\n    derivX.reshape(width, height);\r\n    derivY.reshape(width, height);\r\n}"
}, {
	"Path": "org.boon.datarepo.Collections.findPrimaryKey",
	"Comment": "placeholder for a generic way to discover a primary key.right now the primarykey must be called id.",
	"Method": "String findPrimaryKey(Map<String, FieldAccess> fields){\r\n    return \"id\";\r\n}"
}, {
	"Path": "boofcv.demonstrations.shapes.DetectBlackShapeAppBase.requestSaveInputImage",
	"Comment": "makes a request that the input image be saved. this request might be carried out immediately\tor when then next image is processed.",
	"Method": "void requestSaveInputImage(){\r\n    saveRequested = false;\r\n    switch(inputMethod) {\r\n        case IMAGE:\r\n            new Thread(() -> saveInputImage()).start();\r\n            break;\r\n        case VIDEO:\r\n        case WEBCAM:\r\n            if (streamPaused) {\r\n                saveInputImage();\r\n            } else {\r\n                saveRequested = true;\r\n            }\r\n            break;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.PositionFromPairLinear2.process",
	"Comment": "computes the translation given two or more feature observations and the known rotation",
	"Method": "boolean process(DMatrixRMaj R,List<Point3D_F64> worldPts,List<Point2D_F64> observed){\r\n    if (worldPts.size() != observed.size())\r\n        throw new IllegalArgumentException(\"Number of worldPts and observed must be the same\");\r\n    if (worldPts.size() < 2)\r\n        throw new IllegalArgumentException(\"A minimum of two points are required\");\r\n    int N = worldPts.size();\r\n    A.reshape(3 * N, 3);\r\n    b.reshape(A.numRows, 1);\r\n    for (int i = 0; i < N; i++) {\r\n        Point3D_F64 X = worldPts.get(i);\r\n        Point2D_F64 o = observed.get(i);\r\n        int indexA = i * 3 * 3;\r\n        int indexB = i * 3;\r\n        A.data[indexA + 1] = -1;\r\n        A.data[indexA + 2] = o.y;\r\n        A.data[indexA + 3] = 1;\r\n        A.data[indexA + 5] = -o.x;\r\n        A.data[indexA + 6] = -o.y;\r\n        A.data[indexA + 7] = o.x;\r\n        GeometryMath_F64.mult(R, X, RX);\r\n        b.data[indexB++] = 1 * RX.y - o.y * RX.z;\r\n        b.data[indexB++] = -1 * RX.x + o.x * RX.z;\r\n        b.data[indexB] = o.y * RX.x - o.x * RX.y;\r\n    }\r\n    if (!solver.setA(A))\r\n        return false;\r\n    solver.solve(b, x);\r\n    T.x = x.data[0];\r\n    T.y = x.data[1];\r\n    T.z = x.data[2];\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeDecoderImage.computeBoundingBox",
	"Comment": "3 or the 4 corners are from the position patterns. the 4th is extrapolated using the position pattern\tsides.",
	"Method": "void computeBoundingBox(QrCode qr){\r\n    qr.bounds.get(0).set(qr.ppCorner.get(0));\r\n    qr.bounds.get(1).set(qr.ppRight.get(1));\r\n    Intersection2D_F64.intersection(qr.ppRight.get(1), qr.ppRight.get(2), qr.ppDown.get(3), qr.ppDown.get(2), qr.bounds.get(2));\r\n    qr.bounds.get(3).set(qr.ppDown.get(3));\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.TestUnrollSiftScaleSpaceGradient.setImage",
	"Comment": "manually compute the precomputed set of scaled derivatives and see if they are the same",
	"Method": "void setImage(){\r\n    GrayF32 image = new GrayF32(640, 480);\r\n    GImageMiscOps.fillUniform(image, rand, 0, 200);\r\n    UnrollSiftScaleSpaceGradient alg = new UnrollSiftScaleSpaceGradient(new SiftScaleSpace(-1, 3, 3, 2));\r\n    alg.setImage(image);\r\n    SiftScaleSpace ss = new SiftScaleSpace(-1, 3, 3, 2);\r\n    ss.initialize(image);\r\n    GrayF32 derivX = new GrayF32(640, 480);\r\n    GrayF32 derivY = new GrayF32(640, 480);\r\n    int total = 0;\r\n    do {\r\n        for (int i = 0; i < ss.getNumScales(); i++, total++) {\r\n            GrayF32 scaleImage = ss.getImageScale(i);\r\n            derivX.reshape(scaleImage.width, scaleImage.height);\r\n            derivY.reshape(scaleImage.width, scaleImage.height);\r\n            GImageDerivativeOps.gradient(DerivativeType.THREE, scaleImage, derivX, derivY, BorderType.EXTENDED);\r\n            UnrollSiftScaleSpaceGradient.ImageScale found = alg.usedScales.get(total);\r\n            BoofTesting.assertEquals(derivX, found.derivX, 1e-4);\r\n            BoofTesting.assertEquals(derivY, found.derivY, 1e-4);\r\n            assertEquals(ss.computeSigmaScale(i), found.sigma, 1e-4);\r\n            assertEquals(image.width / (double) scaleImage.width, found.imageToInput, 1e-4);\r\n        }\r\n    } while (ss.computeNextOctave());\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCP.captureStackTrace",
	"Comment": "throw an exception to capture it so as to be able to print it out later on",
	"Method": "String captureStackTrace(String message){\r\n    StringBuilder stringBuilder = new StringBuilder(String.format(message, Thread.currentThread().getName()));\r\n    StackTraceElement[] trace = Thread.currentThread().getStackTrace();\r\n    for (int i = 0; i < trace.length; i++) {\r\n        stringBuilder.append(\" \" + trace[i] + \"\\r\\n\");\r\n    }\r\n    stringBuilder.append(\"\");\r\n    return stringBuilder.toString();\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.ConvolutionTestHelper.copyImgs",
	"Comment": "searches for images and creates copies.the same instance of all other variables is returned",
	"Method": "Object[] copyImgs(Object input){\r\n    Object[] output = new Object[input.length];\r\n    for (int i = 0; i < input.length; i++) {\r\n        Object o = input[i];\r\n        if (o instanceof ImageGray) {\r\n            ImageGray b = (ImageGray) o;\r\n            ImageGray img = (ImageGray) b.createNew(b.width, b.height);\r\n            img.setTo((ImageGray) o);\r\n            output[i] = img;\r\n        } else {\r\n            output[i] = o;\r\n        }\r\n    }\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.DescribePointPixelRegionNCC.isInBounds",
	"Comment": "the entire region must be inside the image because any outside pixels will change the statistics",
	"Method": "boolean isInBounds(int c_x,int c_y){\r\n    return BoofMiscOps.checkInside(image, c_x, c_y, radiusWidth, radiusHeight);\r\n}"
}, {
	"Path": "boofcv.abst.geo.bundle.GenericBundleAdjustmentProjectiveChecks.multipleCalls",
	"Comment": "same solution when called multiple times in a row. checks to see if it is correctly reset",
	"Method": "void multipleCalls(){\r\n    BundleAdjustment<SceneStructureProjective> alg = createAlg();\r\n    Tuple2<SceneStructureProjective, SceneObservations> a = createHorizontalMotion(123);\r\n    Tuple2<SceneStructureProjective, SceneObservations> c = createHorizontalMotion(234);\r\n    addNoiseToPoint3D(c);\r\n    alg.setParameters(a.data0, a.data1);\r\n    alg.optimize(c.data0);\r\n    alg.setParameters(a.data0, a.data1);\r\n    alg.optimize(a.data0);\r\n    Tuple2<SceneStructureProjective, SceneObservations> b = createHorizontalMotion(123);\r\n    assertEquals(a.data0, b.data0, 1e-6);\r\n}"
}, {
	"Path": "boofcv.alg.geo.structure.ProjectiveStructureByFactorization.setDepthsFrom3D",
	"Comment": "assigns depth to the z value of all the features in the list. features must be in the coordinate system\tof the view for this to be correct",
	"Method": "void setDepthsFrom3D(int view,List<Point3D_F64> locations){\r\n    if (locations.size() != pixels.numCols)\r\n        throw new IllegalArgumentException(\"Pixel count must be constant and match \" + pixels.numCols);\r\n    int N = depths.numCols;\r\n    for (int i = 0; i < N; i++) {\r\n        depths.set(view, i, locations.get(i).z);\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.DeviceData.isEmulator",
	"Comment": "guesses whether the current device is an emulator or not, erring on the side of caution",
	"Method": "boolean isEmulator(){\r\n    String fingerprint = Build.FINGERPRINT;\r\n    return fingerprint.startsWith(\"unknown\") || fingerprint.contains(\"generic\") || fingerprint.contains(\"vbox\");\r\n}"
}, {
	"Path": "org.boon.primitive.Flt.reduceBy",
	"Comment": "a very fast reduce by.if performance is your thing, this seems to be as fast a plain for loop when benchmarking with jmh.",
	"Method": "double reduceBy(float[] array,ReduceBy reduceBy,double reduceBy,float[] array,int start,int length,ReduceBy reduceBy,double reduceBy,float[] array,int length,ReduceBy reduceBy,double reduceBy,float[] array,T object,double reduceBy,float[] array,T object,String methodName,double reduceBy,float[] array,int length,Object object,double reduceBy,float[] array,int length,Object function,String functionName,double reduceBy,float[] array,int start,int length,Object object){\r\n    if (object.getClass().isAnonymousClass()) {\r\n        return reduceByR(array, object);\r\n    }\r\n    try {\r\n        ConstantCallSite callSite = Invoker.invokeReducerLongIntReturnLongMethodHandle(object);\r\n        MethodHandle methodHandle = callSite.dynamicInvoker();\r\n        try {\r\n            double sum = 0;\r\n            for (int index = start; index < length; index++) {\r\n                float v = array[index];\r\n                sum = (double) methodHandle.invokeExact(sum, v);\r\n            }\r\n            return sum;\r\n        } catch (Throwable throwable) {\r\n            return handle(Long.class, throwable, \"Unable to perform reduceBy\");\r\n        }\r\n    } catch (Exception ex) {\r\n        return reduceByR(array, object);\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.convolve.Kernel2D_F32.wrap",
	"Comment": "creates a kernel whose elements are the specified data array and has\tthe specified width.",
	"Method": "Kernel2D_F32 wrap(float data,int width,int offset){\r\n    if (width % 2 == 0 && width <= 0 && width * width > data.length)\r\n        throw new IllegalArgumentException(\"invalid width\");\r\n    Kernel2D_F32 ret = new Kernel2D_F32();\r\n    ret.data = data;\r\n    ret.width = width;\r\n    ret.offset = offset;\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.demonstrations.calibration.CalibrateStereoPlanarGuiApp.setRectification",
	"Comment": "computes stereo rectification and then passes the distortion along to the gui.",
	"Method": "void setRectification(StereoParameters param){\r\n    DMatrixRMaj K1 = PerspectiveOps.pinholeToMatrix(param.getLeft(), (DMatrixRMaj) null);\r\n    DMatrixRMaj K2 = PerspectiveOps.pinholeToMatrix(param.getRight(), (DMatrixRMaj) null);\r\n    RectifyCalibrated rectify = RectifyImageOps.createCalibrated();\r\n    rectify.process(K1, new Se3_F64(), K2, param.getRightToLeft().invert(null));\r\n    final DMatrixRMaj rect1 = rectify.getRect1();\r\n    final DMatrixRMaj rect2 = rectify.getRect2();\r\n    SwingUtilities.invokeLater(new Runnable() {\r\n        public void run() {\r\n            gui.setRectification(param.getLeft(), rect1, param.getRight(), rect2);\r\n        }\r\n    });\r\n    gui.repaint();\r\n}"
}, {
	"Path": "boofcv.demonstrations.calibration.CalibrateStereoPlanarGuiApp.setRectification",
	"Comment": "computes stereo rectification and then passes the distortion along to the gui.",
	"Method": "void setRectification(StereoParameters param){\r\n    gui.setRectification(param.getLeft(), rect1, param.getRight(), rect2);\r\n}"
}, {
	"Path": "org.boon.messages.MessageSpecification.setCurrentSubject",
	"Comment": "allows client objects to set the subject for the current threadper instance of the messagespecification.",
	"Method": "void setCurrentSubject(String subject){\r\n    ValidationContext.get().setCurrentSubject(subject);\r\n}"
}, {
	"Path": "boofcv.alg.geo.TestDecomposeEssential.checkAgainstKnown",
	"Comment": "check the decomposition against a known input.see if the solutions have the expected\tproperties and at least one matches the input.",
	"Method": "void checkAgainstKnown(){\r\n    DMatrixRMaj R = ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0.1, -0.4, 0.5, null);\r\n    Vector3D_F64 T = new Vector3D_F64(2, 1, -3);\r\n    DMatrixRMaj E = MultiViewOps.createEssential(R, T, null);\r\n    DecomposeEssential alg = new DecomposeEssential();\r\n    alg.decompose(E);\r\n    List<Se3_F64> solutions = alg.getSolutions();\r\n    assertEquals(4, solutions.size());\r\n    checkUnique(solutions);\r\n    checkHasOriginal(solutions, R, T);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.version.Updater.getUpdater",
	"Comment": "gets the instance of the updater to check for newer versions.",
	"Method": "Updater getUpdater(){\r\n    if (instance == null) {\r\n        instance = new Updater();\r\n    }\r\n    return instance;\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.TestDescribePointBriefSO.testScale",
	"Comment": "checks to see if changing orientation changes the description",
	"Method": "void testScale(){\r\n    GrayF32 input = createImage(width, height);\r\n    DescribePointBriefSO<GrayF32> alg = createAlg();\r\n    TupleDesc_B desc1 = alg.createFeature();\r\n    TupleDesc_B desc2 = alg.createFeature();\r\n    alg.setImage(input);\r\n    alg.process(input.width / 2, input.height / 2, 0, briefRadius, desc1);\r\n    alg.process(input.width / 2, input.height / 2, 0, 2 * briefRadius, desc2);\r\n    boolean identical = true;\r\n    for (int i = 0; i < desc1.data.length; i++) {\r\n        if (desc1.data[i] != desc2.data[i])\r\n            identical = false;\r\n    }\r\n    assertFalse(identical);\r\n}"
}, {
	"Path": "boofcv.alg.descriptor.DescriptorDistance.euclideanSq",
	"Comment": "returns the euclidean distance squared between the two descriptors.",
	"Method": "double euclideanSq(TupleDesc_F64 a,TupleDesc_F64 b,double euclideanSq,TupleDesc_F32 a,TupleDesc_F32 b){\r\n    final int N = a.value.length;\r\n    float total = 0;\r\n    for (int i = 0; i < N; i++) {\r\n        double d = a.value[i] - b.value[i];\r\n        total += d * d;\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.TrackerMeanShiftComaniciu2003.setTrackLocation",
	"Comment": "used to set the location of the track without changing any appearance history.",
	"Method": "void setTrackLocation(RectangleRotate_F32 location){\r\n    this.region.set(location);\r\n    this.minimumWidth = location.width * minimumSizeRatio;\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernelGaussian.gaussian2D_F32",
	"Comment": "creates a kernel for a 2d convolution.this should only be used for validation purposes.",
	"Method": "Kernel2D_F32 gaussian2D_F32(double sigma,int radius,boolean odd,boolean normalize){\r\n    Kernel1D_F32 kernel1D = gaussian1D_F32(sigma, radius, odd, false);\r\n    Kernel2D_F32 ret = KernelMath.convolve2D(kernel1D, kernel1D);\r\n    if (normalize) {\r\n        KernelMath.normalizeSumToOne(ret);\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.Zhang99ComputeTargetHomography.computeHomography",
	"Comment": "computes the homography from a list of detected grid points in the image.the\torder of the grid points is important and must follow the expected row major\tstarting at the top left.",
	"Method": "boolean computeHomography(CalibrationObservation observedPoints){\r\n    if (observedPoints.size() < 4)\r\n        throw new IllegalArgumentException(\"At least 4 points needed in each set of observations. \" + \" Filter these first please\");\r\n    List<AssociatedPair> pairs = new ArrayList();\r\n    for (int i = 0; i < observedPoints.size(); i++) {\r\n        int which = observedPoints.get(i).index;\r\n        Point2D_F64 obs = observedPoints.get(i);\r\n        pairs.add(new AssociatedPair(worldPoints.get(which), obs, true));\r\n    }\r\n    if (!computeHomography.process(pairs, found))\r\n        return false;\r\n    return true;\r\n}"
}, {
	"Path": "org.boon.slumberdb.stores.BaseDataStore.processWriteQueue",
	"Comment": "called from worker thread.processes the incoming queue for read and writes.",
	"Method": "void processWriteQueue(){\r\n    WriteStatus status = new WriteStatus();\r\n    while (true) {\r\n        DataStoreRequest operation = writeOperationsQueue.poll(dataStoreConfig.pollTimeoutMS(), TimeUnit.MILLISECONDS);\r\n        while (operation != null) {\r\n            status.tracker.addCall(operation, outputDataQueue);\r\n            writeOperationsBatch.add(operation);\r\n            if (writeOperationsBatch.size() > dataStoreConfig.processQueueMaxBatchSize()) {\r\n                break;\r\n            }\r\n            operation = writeOperationsQueue.poll();\r\n        }\r\n        if (writeOperationsBatch.size() > 0) {\r\n            try {\r\n                status.writeBatchSize.add(writeOperationsBatch.size());\r\n                recievedWriteBatch(new ArrayList(writeOperationsBatch));\r\n            } finally {\r\n                writeOperationsBatch.clear();\r\n            }\r\n        } else {\r\n            flushWritesIfNeeded();\r\n        }\r\n        if (status.writeBatchSize.size() > 1000) {\r\n            status.sendBatchSize(source, outputDataQueue);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.template.TestTemplateMatching.basicTest_BORDER",
	"Comment": "basic detection task with an extraction algorithm that has a border",
	"Method": "void basicTest_BORDER(){\r\n    expected = new ArrayList();\r\n    expected.add(new Match(10, 11, 15));\r\n    expected.add(new Match(16, 15, 18));\r\n    expected.add(new Match(0, 0, 18));\r\n    DummyIntensity intensity = new DummyIntensity(true, 4, 5);\r\n    TemplateMatching alg = new TemplateMatching(intensity);\r\n    alg.setImage(input);\r\n    alg.setTemplate(template, null, 10);\r\n    alg.process();\r\n    checkResults(alg.getResults().toList(), expected, 4, 5);\r\n}"
}, {
	"Path": "boofcv.android.camera.VideoRenderProcessing.outputToImage",
	"Comment": "converts a coordinate from output image coordinates to input image",
	"Method": "void outputToImage(double x,double y,Point2D_F64 pt){\r\n    pt.x = x * scale + tranX;\r\n    pt.y = y * scale + tranY;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.ImageMotionPointTrackerKey.changeKeyFrame",
	"Comment": "change the current frame into the keyframe. p1 location of existing tracks is set to\ttheir current location and new tracks are spawned.reference frame transformations are also updated",
	"Method": "void changeKeyFrame(){\r\n    List<PointTrack> inactive = tracker.getInactiveTracks(null);\r\n    for (PointTrack l : inactive) {\r\n        tracker.dropTrack(l);\r\n    }\r\n    List<PointTrack> active = tracker.getActiveTracks(null);\r\n    for (PointTrack l : active) {\r\n        AssociatedPairTrack p = l.getCookie();\r\n        p.p1.set(l);\r\n        p.lastUsed = totalFramesProcessed;\r\n    }\r\n    tracker.spawnTracks();\r\n    List<PointTrack> spawned = tracker.getNewTracks(null);\r\n    for (PointTrack l : spawned) {\r\n        AssociatedPairTrack p = l.getCookie();\r\n        if (p == null) {\r\n            l.cookie = p = new AssociatedPairTrack();\r\n            p.p2 = l;\r\n        }\r\n        p.p1.set(l);\r\n        p.lastUsed = totalFramesProcessed;\r\n    }\r\n    worldToKey.set(worldToCurr);\r\n    keyToCurr.reset();\r\n    keyFrame = true;\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.TestConvolveImage.fillTestImage",
	"Comment": "fillers the border in the larger image with an extended version of the smaller image.a duplicate\tof the smaller image is contained in the center of the larger image.",
	"Method": "void fillTestImage(ImageBase smaller,ImageBase larger,KernelBase kernel,String functionName){\r\n    computeBorder(kernel, functionName);\r\n    stripBorder(larger, borderX0, borderY0, borderX1, borderY1).setTo(smaller);\r\n    GImageMultiBand s = FactoryGImageMultiBand.wrap(smaller);\r\n    GImageMultiBand l = FactoryGImageMultiBand.wrap(larger);\r\n    float[] pixel = new float[s.getNumberOfBands()];\r\n    for (int y = 0; y < larger.height; y++) {\r\n        for (int x = 0; x < larger.width; x++) {\r\n            int sx = x - borderX0;\r\n            int sy = y - borderY0;\r\n            if (sx < 0)\r\n                sx = 0;\r\n            else if (sx >= smaller.width)\r\n                sx = smaller.width - 1;\r\n            if (sy < 0)\r\n                sy = 0;\r\n            else if (sy >= smaller.height)\r\n                sy = smaller.height - 1;\r\n            s.get(sx, sy, pixel);\r\n            l.set(x, y, pixel);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.circulant.CirculantTracker.get_subwindow",
	"Comment": "copies the target into the output image and applies the cosine window to it.",
	"Method": "void get_subwindow(T image,GrayF64 output){\r\n    interp.setImage(image);\r\n    int index = 0;\r\n    for (int y = 0; y < workRegionSize; y++) {\r\n        float yy = regionTrack.y0 + y * stepY;\r\n        for (int x = 0; x < workRegionSize; x++) {\r\n            float xx = regionTrack.x0 + x * stepX;\r\n            if (interp.isInFastBounds(xx, yy))\r\n                output.data[index++] = interp.get_fast(xx, yy);\r\n            else if (BoofMiscOps.checkInside(image, xx, yy))\r\n                output.data[index++] = interp.get(xx, yy);\r\n            else {\r\n                output.data[index++] = rand.nextFloat() * maxPixelValue;\r\n            }\r\n        }\r\n    }\r\n    PixelMath.divide(output, maxPixelValue, output);\r\n    PixelMath.plus(output, -0.5f, output);\r\n    PixelMath.multiply(output, cosine, output);\r\n}"
}, {
	"Path": "com.bugsnag.android.example.ExampleActivity.crashWithUserDetails",
	"Comment": "user details can be added globally, which will then appear in all error reports sentto the bugsnag dashboard.",
	"Method": "void crashWithUserDetails(View view){\r\n    Bugsnag.setUser(\"123456\", \"joebloggs@example.com\", \"Joe Bloggs\");\r\n    RuntimeException exception = new RuntimeException(\"Error Report with User Info\");\r\n    Bugsnag.notify(exception);\r\n    displayToastNotification();\r\n}"
}, {
	"Path": "boofcv.gui.JavaRuntimeLauncher.launch",
	"Comment": "launches the class with the provided arguments.blocks until the process stops.",
	"Method": "Exit launch(Class mainClass,String args){\r\n    jvmArgs = configureArguments(mainClass, args);\r\n    try {\r\n        Runtime rt = Runtime.getRuntime();\r\n        Process pr = rt.exec(jvmArgs);\r\n        Thread.sleep(500);\r\n        BufferedReader input = new BufferedReader(new InputStreamReader(pr.getInputStream()));\r\n        BufferedReader error = new BufferedReader(new InputStreamReader(pr.getErrorStream()));\r\n        if (!monitorSlave(pr, input, error)) {\r\n            if (killRequested)\r\n                return Exit.REQUESTED;\r\n            else\r\n                return Exit.FROZEN;\r\n        }\r\n        if (pr.exitValue() != 0) {\r\n            return Exit.RETURN_NOT_ZERO;\r\n        } else {\r\n            return Exit.NORMAL;\r\n        }\r\n    } catch (IOException | InterruptedException e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.learning.ConfusionMatrixPanel.whatIsAtPoint",
	"Comment": "use to sample the panel to see what is being displayed at the location clicked.all coordinates\tare in panel coordinates.",
	"Method": "LocationInfo whatIsAtPoint(int pixelX,int pixelY,LocationInfo output){\r\n    if (output == null)\r\n        output = new LocationInfo();\r\n    int numCategories = confusion.getNumRows();\r\n    synchronized (this) {\r\n        if (pixelX >= gridWidth) {\r\n            output.insideMatrix = false;\r\n            output.col = output.row = pixelY * numCategories / gridHeight;\r\n        } else {\r\n            output.insideMatrix = true;\r\n            output.row = pixelY * numCategories / gridHeight;\r\n            output.col = pixelX * numCategories / gridWidth;\r\n        }\r\n    }\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.alg.filter.misc.AverageDownSampleOps.downSampleSize",
	"Comment": "computes the length of a down sampled image based on the original length and the square width",
	"Method": "int downSampleSize(int length,int squareWidth){\r\n    int ret = length / squareWidth;\r\n    if (length % squareWidth != 0)\r\n        ret++;\r\n    return ret;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.getAcquireRetryAttempts",
	"Comment": "after attempting to acquire a connection and failing, try to connect these many times before giving up. default 5.",
	"Method": "int getAcquireRetryAttempts(){\r\n    return this.acquireRetryAttempts;\r\n}"
}, {
	"Path": "boofcv.factory.feature.describe.FactoryDescribeRegionPoint.surfColorStable",
	"Comment": "color variant of the surf descriptor which has been designed for stability.",
	"Method": "DescribeRegionPoint<T, BrightFeature> surfColorStable(ConfigSurfDescribe.Stability config,ImageType<T> imageType){\r\n    Class bandType = imageType.getImageClass();\r\n    Class<II> integralType = GIntegralImageOps.getIntegralType(bandType);\r\n    DescribePointSurf<II> alg = FactoryDescribePointAlgs.surfStability(config, integralType);\r\n    if (imageType.getFamily() == ImageType.Family.PLANAR) {\r\n        DescribePointSurfPlanar<II> color = FactoryDescribePointAlgs.surfColor(alg, imageType.getNumBands());\r\n        return new SurfPlanar_to_DescribeRegionPoint(color, bandType, integralType);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown image type\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.descriptor.UtilFeature.combine",
	"Comment": "concats the list of tuples together into one big feature.the combined feature must be large\tenough to store all the inputs.",
	"Method": "TupleDesc_F64 combine(List<TupleDesc_F64> inputs,TupleDesc_F64 combined){\r\n    int N = 0;\r\n    for (int i = 0; i < inputs.size(); i++) {\r\n        N += inputs.get(i).size();\r\n    }\r\n    if (combined == null) {\r\n        combined = new TupleDesc_F64(N);\r\n    } else {\r\n        if (N != combined.size())\r\n            throw new RuntimeException(\"The combined feature needs to be \" + N + \"  not \" + combined.size());\r\n    }\r\n    int start = 0;\r\n    for (int i = 0; i < inputs.size(); i++) {\r\n        double[] v = inputs.get(i).value;\r\n        System.arraycopy(v, 0, combined.value, start, v.length);\r\n        start += v.length;\r\n    }\r\n    return combined;\r\n}"
}, {
	"Path": "com.gazbert.bxbot.exchanges.AbstractExchangeAdapter.getAuthenticationConfigItem",
	"Comment": "fetches an authentication item value from the adapter config.",
	"Method": "String getAuthenticationConfigItem(AuthenticationConfig authenticationConfig,String itemName){\r\n    final String itemValue = authenticationConfig.getItem(itemName);\r\n    return assertItemExists(itemName, itemValue);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonBinaryGrayRefine.getPolygons",
	"Comment": "returns a list of all polygons with an edge threshold above the minimum",
	"Method": "List<Polygon2D_F64> getPolygons(List<Polygon2D_F64> storage,List<DetectPolygonFromContour.Info> storageInfo){\r\n    if (storage == null)\r\n        storage = new ArrayList();\r\n    else\r\n        storage.clear();\r\n    if (storageInfo != null)\r\n        storageInfo.clear();\r\n    List<DetectPolygonFromContour.Info> detections = detector.getFound().toList();\r\n    for (int i = 0; i < detections.size(); i++) {\r\n        DetectPolygonFromContour.Info d = detections.get(i);\r\n        if (d.computeEdgeIntensity() >= minimumRefineEdgeIntensity) {\r\n            storage.add(d.polygon);\r\n            if (storageInfo != null) {\r\n                storageInfo.add(d);\r\n            }\r\n        }\r\n    }\r\n    return storage;\r\n}"
}, {
	"Path": "boofcv.abst.flow.GeneralDenseOpticalFlowChecks.checkPlanarMotion",
	"Comment": "very simple test where every pixel moves at the same speed along x and or y direction",
	"Method": "void checkPlanarMotion(){\r\n    for (int dy = -1; dy <= 1; dy++) {\r\n        for (int dx = -1; dx <= 1; dx++) {\r\n            DenseOpticalFlow<T> alg = createAlg(imageType);\r\n            shift(orig, dx, dy, shifted);\r\n            found.invalidateAll();\r\n            alg.process(orig, shifted, found);\r\n            ImageFlow.D flow = found.get(10, 10);\r\n            assertTrue(flow.isValid());\r\n            if (justCorrectSign) {\r\n                float sum = 0;\r\n                for (int y = 0; y < found.height; y++) {\r\n                    for (int x = 0; x < found.width; x++) {\r\n                        flow = found.get(x, y);\r\n                        sum += flow.x * dx;\r\n                        sum += flow.y * dy;\r\n                    }\r\n                }\r\n                assertTrue(sum >= 0);\r\n            } else {\r\n                assertEquals(dx, flow.x, 0.2);\r\n                assertEquals(dy, flow.y, 0.2);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.boon.Maps.map",
	"Comment": "note, you need to make sure that the iterators are from some sort of ordered collection.",
	"Method": "Map<K, V> map(Class<K> keyClass,Class<V> valueClass,Map<K, V> map,K k0,V v0,Map<K, V> map,K k0,V v0,K k1,V v1,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,K k10,V v10,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,K k10,V v10,K k11,V v11,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,K k10,V v10,K k11,V v11,K k12,V v12,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,K k10,V v10,K k11,V v11,K k12,V v12,K k13,V v13,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,K k10,V v10,K k11,V v11,K k12,V v12,K k13,V v13,K k14,V v14,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,K k10,V v10,K k11,V v11,K k12,V v12,K k13,V v13,K k14,V v14,K k15,V v15,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,K k10,V v10,K k11,V v11,K k12,V v12,K k13,V v13,K k14,V v14,K k15,V v15,K k16,V v16,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,K k10,V v10,K k11,V v11,K k12,V v12,K k13,V v13,K k14,V v14,K k15,V v15,K k16,V v16,K k17,V v17,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,K k10,V v10,K k11,V v11,K k12,V v12,K k13,V v13,K k14,V v14,K k15,V v15,K k16,V v16,K k17,V v17,K k18,V v18,Map<K, V> map,K k0,V v0,K k1,V v1,K k2,V v2,K k3,V v3,K k4,V v4,K k5,V v5,K k6,V v6,K k7,V v7,K k8,V v8,K k9,V v9,K k10,V v10,K k11,V v11,K k12,V v12,K k13,V v13,K k14,V v14,K k15,V v15,K k16,V v16,K k17,V v17,K k18,V v18,K k19,V v19,Map<K, V> map,List<K> keys,List<V> values,Map<K, V> map,LinkedHashSet<K> keys,LinkedHashSet<V> values,Map<K, V> map,Iterable<K> keys,Iterable<V> values,Map<K, V> map,K[] keys,V[] values,Map<K, V> map,Entry<K, V> entries){\r\n    Map<K, V> map = new LinkedHashMap(entries.length);\r\n    for (Entry<K, V> entry : entries) {\r\n        map.put(entry.key(), entry.value());\r\n    }\r\n    return map;\r\n}"
}, {
	"Path": "boofcv.alg.distort.mls.TestImageDeformPointMLS_F32.multipleCallsToFixate",
	"Comment": "should produce identical results when fixate is called multiple times",
	"Method": "void multipleCallsToFixate(){\r\n    for (TypeDeformMLS type : TypeDeformMLS.values()) {\r\n        ImageDeformPointMLS_F32 alg = new ImageDeformPointMLS_F32(type);\r\n        alg.configure(width, height, rows, cols);\r\n        alg.addControl(5, 5);\r\n        alg.addControl(10, 20);\r\n        alg.addControl(30, 50);\r\n        alg.addControl(16, 0);\r\n        alg.setDistorted(0, 10, 12);\r\n        alg.setDistorted(1, 14, 30);\r\n        alg.setDistorted(2, 25, 45);\r\n        alg.setDistorted(3, 20, 8);\r\n        alg.fixateUndistorted();\r\n        alg.fixateDistorted();\r\n        Point2D_F32 expected = new Point2D_F32();\r\n        alg.compute(4, 4, expected);\r\n        Point2D_F32 found = new Point2D_F32();\r\n        alg.fixateDistorted();\r\n        alg.compute(4, 4, found);\r\n        assertTrue(found.distance(expected) <= GrlConstants.TEST_F32);\r\n        alg.fixateUndistorted();\r\n        alg.fixateDistorted();\r\n        alg.compute(4, 4, found);\r\n        assertTrue(found.distance(expected) <= GrlConstants.TEST_F32);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.transform.pyramid.PyramidOps.filter",
	"Comment": "runs an image filter through each layer in the pyramid.\tit is assumed that the output has the same scales as the input.if not\tinitialized then it will be initialized.if already initialized it is\tassumed to be setup for the same input image size.",
	"Method": "void filter(ImagePyramid<I> input,FilterImageInterface<I, O> filter,O[] output){\r\n    for (int i = 0; i < input.getNumLayers(); i++) {\r\n        I imageIn = input.getLayer(i);\r\n        filter.process(imageIn, output[i]);\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionHandle.setDebugHandle",
	"Comment": "sets a debughandle, an object that is not used by the connection pool at all but may be set by an application to track\tthis particular connection handle for any purpose it deems fit.",
	"Method": "void setDebugHandle(Object debugHandle){\r\n    this.debugHandle = debugHandle;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.overhead.CreateSyntheticOverheadViewS.process",
	"Comment": "computes overhead view of input image.all pixels in input image are assumed to be on the ground plane.",
	"Method": "void process(T input,T output){\r\n    this.output = FactoryGImageGray.wrap(output, this.output);\r\n    interp.setImage(input);\r\n    int indexMap = 0;\r\n    for (int i = 0; i < output.height; i++) {\r\n        int indexOut = output.startIndex + i * output.stride;\r\n        for (int j = 0; j < output.width; j++, indexOut++, indexMap++) {\r\n            Point2D_F32 p = mapPixels[indexMap];\r\n            if (p != null) {\r\n                this.output.set(indexOut, interp.get(p.x, p.y));\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldFernManager.lookupFern",
	"Comment": "looks up the fern with the specified value.if non exist a new one is created and returned.",
	"Method": "TldFernFeature lookupFern(int value){\r\n    TldFernFeature found = table[value];\r\n    if (found == null) {\r\n        found = createFern();\r\n        found.init(value);\r\n        table[value] = found;\r\n    }\r\n    return found;\r\n}"
}, {
	"Path": "com.bugsnag.android.BeforeRecordBreadcrumbsTest.setUp",
	"Comment": "configures a client which does not automatically record breadcrumbs",
	"Method": "void setUp(){\r\n    Configuration configuration = new Configuration(\"api-key\");\r\n    configuration.setAutomaticallyCollectBreadcrumbs(false);\r\n    client = new Client(InstrumentationRegistry.getContext(), configuration);\r\n    assertEquals(0, client.breadcrumbs.store.size());\r\n}"
}, {
	"Path": "boofcv.abst.filter.transform.fft.GenericTestDiscreteFourierTransform.format_odd",
	"Comment": "see if the fourier transform is the expected one for odd sizes images",
	"Method": "void format_odd(){\r\n    T input = createImage(7, 1);\r\n    I transform = createTransform(7, 1);\r\n    GImageMiscOps.fillUniform(input, rand, -20, 20);\r\n    DiscreteFourierTransform<T, I> alg = createAlgorithm();\r\n    alg.forward(input, transform);\r\n    assertEquals(GeneralizedImageOps.get(transform, 3, 0, 0), GeneralizedImageOps.get(transform, 4, 0, 0), tolerance);\r\n    assertEquals(GeneralizedImageOps.get(transform, 3, 0, 1), -GeneralizedImageOps.get(transform, 4, 0, 1), tolerance);\r\n}"
}, {
	"Path": "boofcv.abst.feature.dense.TestDescribeImageDense_Convert.basic",
	"Comment": "checks to see if it converts the input image and that other functions are correctly\timplemented",
	"Method": "void basic(){\r\n    Dummy dummy = new Dummy();\r\n    DescribeImageDense<GrayU8, TupleDesc_F64> alg = new DescribeImageDense_Convert(dummy, ImageType.single(GrayU8.class));\r\n    GrayU8 foo = new GrayU8(10, 20);\r\n    foo.set(5, 2, 10);\r\n    alg.process(foo);\r\n    assertTrue(dummy.process);\r\n    assertEquals(5, alg.createDescription().size());\r\n    assertTrue(TupleDesc_F64.class == alg.getDescriptionType());\r\n    assertTrue(alg.getImageType().getDataType() == ImageDataType.U8);\r\n    assertTrue(null != alg.getDescriptions());\r\n    assertTrue(null != alg.getLocations());\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.DetectCircleHexagonalGrid.isClockWise",
	"Comment": "uses the cross product to determine if the grid is in clockwise order",
	"Method": "boolean isClockWise(Grid g){\r\n    EllipseRotated_F64 v00 = g.get(0, 0);\r\n    EllipseRotated_F64 v02 = g.columns < 3 ? g.get(1, 1) : g.get(0, 2);\r\n    EllipseRotated_F64 v20 = g.rows < 3 ? g.get(1, 1) : g.get(2, 0);\r\n    double a_x = v02.center.x - v00.center.x;\r\n    double a_y = v02.center.y - v00.center.y;\r\n    double b_x = v20.center.x - v00.center.x;\r\n    double b_y = v20.center.y - v00.center.y;\r\n    return a_x * b_y - a_y * b_x < 0;\r\n}"
}, {
	"Path": "org.boon.core.reflection.Invoker.invokeMethodFromObjectArg",
	"Comment": "invokes method from list or map depending on what the object arg is.",
	"Method": "Object invokeMethodFromObjectArg(Object object,MethodAccess method,Object args,Object invokeMethodFromObjectArg,boolean respectIgnore,String view,Set<String> ignoreProperties,Object object,MethodAccess method,Object args){\r\n    try {\r\n        if (args instanceof Map) {\r\n            return invokeMethodFromList(respectIgnore, view, ignoreProperties, object, method, Lists.list(args));\r\n        } else if (args instanceof List) {\r\n            List list = (List) args;\r\n            Class<?>[] paramTypes = method.parameterTypes();\r\n            if (paramTypes.length == 1 && list.size() > 0) {\r\n                Class<?> firstParamType = paramTypes[0];\r\n                Object firstArg = list.get(0);\r\n                if (firstArg instanceof Map) {\r\n                    return invokeMethodFromList(respectIgnore, view, ignoreProperties, object, method, list);\r\n                } else if (firstArg instanceof List && !Typ.isCollection(firstParamType) && !firstParamType.isArray()) {\r\n                    return invokeMethodFromList(respectIgnore, view, ignoreProperties, object, method, list);\r\n                } else {\r\n                    return invokeMethodFromList(respectIgnore, view, ignoreProperties, object, method, Lists.list(args));\r\n                }\r\n            } else {\r\n                return invokeMethodFromList(respectIgnore, view, ignoreProperties, object, method, list);\r\n            }\r\n        } else if (args == null) {\r\n            return method.invoke(object);\r\n        } else {\r\n            return invokeMethodFromList(respectIgnore, view, ignoreProperties, object, method, Lists.list(args));\r\n        }\r\n    } catch (Exception ex) {\r\n        return Exceptions.handle(Object.class, ex, \"Unable to invoke method object\", object, \"method\", method, \"args\", args);\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.BoofDefaults.borderDerivative_I32",
	"Comment": "creates a new instance of the default border for derivatives of integer images",
	"Method": "ImageBorder_S32 borderDerivative_I32(){\r\n    return new ImageBorder1D_S32((Class) BorderIndex1D_Extend.class);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareNode.distanceSqCorner",
	"Comment": "finds the euclidean distance squared of the closest corner to point p",
	"Method": "double distanceSqCorner(Point2D_F64 p){\r\n    double best = Double.MAX_VALUE;\r\n    for (int i = 0; i < 4; i++) {\r\n        double d = square.get(i).distance2(p);\r\n        if (d < best) {\r\n            best = d;\r\n        }\r\n    }\r\n    return best;\r\n}"
}, {
	"Path": "boofcv.alg.misc.GImageMiscOps.fillGaussian",
	"Comment": "sets each value in the image to a value drawn from a gaussian distribution.a user\tspecified lower and upper bound is provided to ensure that the values are within a legal\trange.a drawn value outside the allowed range will be set to the closest bound.",
	"Method": "void fillGaussian(ImageBase input,Random rand,double mean,double sigma,double lowerBound,double upperBound){\r\n    if (input instanceof ImageGray) {\r\n        if (GrayI8.class.isAssignableFrom(input.getClass())) {\r\n            ImageMiscOps.fillGaussian((GrayI8) input, rand, mean, sigma, (int) lowerBound, (int) upperBound);\r\n        } else if (GrayI16.class.isAssignableFrom(input.getClass())) {\r\n            ImageMiscOps.fillGaussian((GrayI16) input, rand, mean, sigma, (int) lowerBound, (int) upperBound);\r\n        } else if (GrayS32.class == input.getClass()) {\r\n            ImageMiscOps.fillGaussian((GrayS32) input, rand, mean, sigma, (int) lowerBound, (int) upperBound);\r\n        } else if (GrayS64.class == input.getClass()) {\r\n            ImageMiscOps.fillGaussian((GrayS64) input, rand, mean, sigma, (long) lowerBound, (long) upperBound);\r\n        } else if (GrayF32.class == input.getClass()) {\r\n            ImageMiscOps.fillGaussian((GrayF32) input, rand, mean, sigma, (float) lowerBound, (float) upperBound);\r\n        } else if (GrayF64.class == input.getClass()) {\r\n            ImageMiscOps.fillGaussian((GrayF64) input, rand, mean, sigma, lowerBound, upperBound);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type: \" + input.getClass().getSimpleName());\r\n        }\r\n    } else if (input instanceof Planar) {\r\n        Planar m = (Planar) input;\r\n        for (int i = 0; i < m.getNumBands(); i++) fillGaussian(input, rand, mean, sigma, lowerBound, upperBound);\r\n    } else if (input instanceof ImageInterleaved) {\r\n        if (InterleavedI8.class.isAssignableFrom(input.getClass())) {\r\n            ImageMiscOps.fillGaussian((InterleavedI8) input, rand, mean, sigma, (int) lowerBound, (int) upperBound);\r\n        } else if (InterleavedI16.class.isAssignableFrom(input.getClass())) {\r\n            ImageMiscOps.fillGaussian((InterleavedI16) input, rand, mean, sigma, (int) lowerBound, (int) upperBound);\r\n        } else if (InterleavedS32.class == input.getClass()) {\r\n            ImageMiscOps.fillGaussian((InterleavedS32) input, rand, mean, sigma, (int) lowerBound, (int) upperBound);\r\n        } else if (InterleavedS64.class == input.getClass()) {\r\n            ImageMiscOps.fillGaussian((InterleavedS64) input, rand, mean, sigma, (long) lowerBound, (long) upperBound);\r\n        } else if (InterleavedF32.class == input.getClass()) {\r\n            ImageMiscOps.fillGaussian((InterleavedF32) input, rand, mean, sigma, (float) lowerBound, (float) upperBound);\r\n        } else if (InterleavedF64.class == input.getClass()) {\r\n            ImageMiscOps.fillGaussian((InterleavedF64) input, rand, mean, sigma, lowerBound, upperBound);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type: \" + input.getClass().getSimpleName());\r\n        }\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown image type: \" + input.getClass().getSimpleName());\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestBoneCP.testIsConnectionHandleAliveNormalCaseWithConnectionTestStatement",
	"Comment": "test method for com.jolbox.bonecp.bonecp isconnectionhandlealive.",
	"Method": "void testIsConnectionHandleAliveNormalCaseWithConnectionTestStatement(){\r\n    reset(mockConfig, mockConnection, mockDatabaseMetadata, mockResultSet);\r\n    Statement mockStatement = EasyMock.createNiceMock(Statement.class);\r\n    expect(mockConfig.getConnectionTestStatement()).andReturn(\"whatever\").once();\r\n    expect(mockConnection.createStatement()).andReturn(mockStatement).once();\r\n    expect(mockStatement.execute((String) anyObject())).andReturn(true).once();\r\n    mockConnection.logicallyClosed = new AtomicBoolean(true);\r\n    replay(mockConfig, mockConnection, mockDatabaseMetadata, mockStatement);\r\n    assertTrue(testClass.isConnectionHandleAlive(mockConnection));\r\n    verify(mockConfig, mockConnection, mockDatabaseMetadata, mockStatement);\r\n}"
}, {
	"Path": "org.boon.validation.ValidationContext.setParentObject",
	"Comment": "allows our integration piece for jsf or spring mvc to set theparent object. the parent object is the form bean in spring mvc speak.",
	"Method": "void setParentObject(Object parentObject){\r\n    this.parentObject = parentObject;\r\n}"
}, {
	"Path": "com.bugsnag.android.Client.getUser",
	"Comment": "retrieves details of the user currently using your application.you can search for this information in your bugsnag dashboard.",
	"Method": "User getUser(){\r\n    return user;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldFernClassifier.lookupFernPN",
	"Comment": "for the specified regions, computes the values of each fern inside of it and then retrives their p and n values.\tthe sum of which is stored inside of info.",
	"Method": "boolean lookupFernPN(TldRegionFernInfo info){\r\n    ImageRectangle r = info.r;\r\n    float rectWidth = r.getWidth();\r\n    float rectHeight = r.getHeight();\r\n    float c_x = r.x0 + (rectWidth - 1) / 2.0f;\r\n    float c_y = r.y0 + (rectHeight - 1) / 2.0f;\r\n    int sumP = 0;\r\n    int sumN = 0;\r\n    for (int i = 0; i < ferns.length; i++) {\r\n        TldFernDescription fern = ferns[i];\r\n        int value = computeFernValue(c_x, c_y, rectWidth, rectHeight, fern);\r\n        TldFernFeature f = managers[i].table[value];\r\n        if (f != null) {\r\n            sumP += f.numP;\r\n            sumN += f.numN;\r\n        }\r\n    }\r\n    info.sumP = sumP;\r\n    info.sumN = sumN;\r\n    return sumN != 0 || sumP != 0;\r\n}"
}, {
	"Path": "boofcv.alg.transform.wavelet.UtilWavelet.borderInverseLower",
	"Comment": "returns the lower border for an inverse wavelet transform.",
	"Method": "int borderInverseLower(WlBorderCoef<?> desc,BorderIndex1D border){\r\n    WlCoef inner = desc.getInnerCoefficients();\r\n    int borderSize = borderForwardLower(inner);\r\n    WlCoef ll = borderSize > 0 ? inner : null;\r\n    WlCoef lu = ll;\r\n    WlCoef uu = inner;\r\n    int indexLU = 0;\r\n    if (desc.getLowerLength() > 0) {\r\n        ll = desc.getBorderCoefficients(0);\r\n        indexLU = desc.getLowerLength() * 2 - 2;\r\n        lu = desc.getBorderCoefficients(indexLU);\r\n    }\r\n    if (desc.getUpperLength() > 0) {\r\n        uu = desc.getBorderCoefficients(-2);\r\n    }\r\n    border.setLength(2000);\r\n    borderSize = checkInverseLower(ll, 0, border, borderSize);\r\n    borderSize = checkInverseLower(lu, indexLU, border, borderSize);\r\n    borderSize = checkInverseLower(uu, 1998, border, borderSize);\r\n    return borderSize;\r\n}"
}, {
	"Path": "com.bugsnag.android.Bugsnag.setUserName",
	"Comment": "set the name of the current user.you can search for this information in your bugsnag dashboard.",
	"Method": "void setUserName(String name){\r\n    getClient().setUserName(name);\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapperComplex.convertListOfMapsToObjects",
	"Comment": "this converts a list of maps to objects.i always forget that this exists. i need to remember.",
	"Method": "List<T> convertListOfMapsToObjects(List<Map> list,Class<T> componentType){\r\n    List<Object> newList = new ArrayList(list.size());\r\n    for (Object obj : list) {\r\n        if (obj instanceof Value) {\r\n            obj = ((Value) obj).toValue();\r\n        }\r\n        if (obj instanceof Map) {\r\n            Map map = (Map) obj;\r\n            if (map instanceof ValueMapImpl) {\r\n                newList.add(fromValueMap((Map<String, Value>) map, componentType));\r\n            } else {\r\n                newList.add(fromMap(map, componentType));\r\n            }\r\n        } else {\r\n            newList.add(Conversions.coerce(componentType, obj));\r\n        }\r\n    }\r\n    return (List<T>) newList;\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.GenericOrientationGradientTests.performEasyTests",
	"Comment": "points all pixels in the surrounding region in same direction.then sees if the found\tdirection for the region is in the expected direction.",
	"Method": "void performEasyTests(){\r\n    alg.setObjectRadius(1);\r\n    int N = 2 * (int) (Math.PI / angleTolerance);\r\n    int x = width / 2;\r\n    int y = height / 2;\r\n    for (int i = 0; i < N; i++) {\r\n        double angle = UtilAngle.bound(i * angleTolerance);\r\n        double c = Math.cos(angle);\r\n        double s = Math.sin(angle);\r\n        GImageMiscOps.fill(derivX, 0);\r\n        GImageMiscOps.fill(derivY, 0);\r\n        GImageMiscOps.fillRectangle(derivX, c * 100, x - regionSize / 2, y - regionSize / 2, regionSize, regionSize);\r\n        GImageMiscOps.fillRectangle(derivY, s * 100, x - regionSize / 2, y - regionSize / 2, regionSize, regionSize);\r\n        alg.setImage(derivX, derivY);\r\n        double found = UtilAngle.bound(alg.compute(x, y));\r\n        assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n    }\r\n}"
}, {
	"Path": "org.bytedeco.copiedstuff.Java2DFrameConverter.getFrame",
	"Comment": "returns a frame based on a bufferedimage, given gamma, and inverted channels flag.",
	"Method": "Frame getFrame(BufferedImage image,Frame getFrame,BufferedImage image,double gamma,Frame getFrame,BufferedImage image,double gamma,boolean flipChannels){\r\n    if (image == null) {\r\n        return null;\r\n    }\r\n    SampleModel sm = image.getSampleModel();\r\n    int depth = 0, numChannels = sm.getNumBands();\r\n    switch(image.getType()) {\r\n        case BufferedImage.TYPE_INT_RGB:\r\n        case BufferedImage.TYPE_INT_ARGB:\r\n        case BufferedImage.TYPE_INT_ARGB_PRE:\r\n        case BufferedImage.TYPE_INT_BGR:\r\n            depth = Frame.DEPTH_UBYTE;\r\n            numChannels = 4;\r\n            break;\r\n    }\r\n    if (depth == 0 || numChannels == 0) {\r\n        switch(sm.getDataType()) {\r\n            case DataBuffer.TYPE_BYTE:\r\n                depth = Frame.DEPTH_UBYTE;\r\n                break;\r\n            case DataBuffer.TYPE_USHORT:\r\n                depth = Frame.DEPTH_USHORT;\r\n                break;\r\n            case DataBuffer.TYPE_SHORT:\r\n                depth = Frame.DEPTH_SHORT;\r\n                break;\r\n            case DataBuffer.TYPE_INT:\r\n                depth = Frame.DEPTH_INT;\r\n                break;\r\n            case DataBuffer.TYPE_FLOAT:\r\n                depth = Frame.DEPTH_FLOAT;\r\n                break;\r\n            case DataBuffer.TYPE_DOUBLE:\r\n                depth = Frame.DEPTH_DOUBLE;\r\n                break;\r\n            default:\r\n                assert false;\r\n        }\r\n    }\r\n    if (frame == null || frame.imageWidth != image.getWidth() || frame.imageHeight != image.getHeight() || frame.imageDepth != depth || frame.imageChannels != numChannels) {\r\n        frame = new Frame(image.getWidth(), image.getHeight(), depth, numChannels);\r\n    }\r\n    copy(image, frame, gamma, flipChannels, null);\r\n    return frame;\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationLinearDualQuadratic.sanityCheck",
	"Comment": "makes sure that the found solution is valid and physically possible",
	"Method": "boolean sanityCheck(Intrinsic calib){\r\n    if (UtilEjml.isUncountable(calib.fx))\r\n        return false;\r\n    if (UtilEjml.isUncountable(calib.fy))\r\n        return false;\r\n    if (UtilEjml.isUncountable(calib.skew))\r\n        return false;\r\n    if (calib.fx < 0)\r\n        return false;\r\n    if (calib.fy < 0)\r\n        return false;\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.BenchmarkSurfDescribeOps.timeGradient_Sample",
	"Comment": "sample the gradient using sparseimagegradient instead of the completely\tunrolled code",
	"Method": "int timeGradient_Sample(int reps){\r\n    for (int i = 0; i < reps; i++) {\r\n        double tl_x = this.tl_x + 0.5;\r\n        double tl_y = this.tl_y + 0.5;\r\n        int j = 0;\r\n        for (int y = 0; y < regionSize; y++) {\r\n            for (int x = 0; x < regionSize; x++, j++) {\r\n                int xx = (int) (tl_x + x * period);\r\n                int yy = (int) (tl_y + y * period);\r\n                GradientValue deriv = g.compute(xx, yy);\r\n                derivX[j] = deriv.getX();\r\n                derivY[j] = deriv.getY();\r\n            }\r\n        }\r\n    }\r\n    return 0;\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.DescribeDenseHogAlg.computeWeightBlockPixels",
	"Comment": "compute gaussian weights applied to each pixel in the block",
	"Method": "void computeWeightBlockPixels(){\r\n    int rows = cellsPerBlockY * pixelsPerCell;\r\n    int cols = cellsPerBlockX * pixelsPerCell;\r\n    weights = new double[rows * cols];\r\n    double offsetRow = 0, offsetCol = 0;\r\n    int radiusRow = rows / 2, radiusCol = cols / 2;\r\n    if (rows % 2 == 0) {\r\n        offsetRow = 0.5;\r\n    }\r\n    if (cols % 2 == 0) {\r\n        offsetCol = 0.5;\r\n    }\r\n    int index = 0;\r\n    for (int row = 0; row < rows; row++) {\r\n        double drow = row - radiusRow + offsetRow;\r\n        double pdfRow = UtilGaussian.computePDF(0, radiusRow, drow);\r\n        for (int col = 0; col < cols; col++) {\r\n            double dcol = col - radiusCol + offsetCol;\r\n            double pdfCol = UtilGaussian.computePDF(0, radiusCol, dcol);\r\n            weights[index++] = pdfCol * pdfRow;\r\n        }\r\n    }\r\n    double max = 0;\r\n    for (int i = 0; i < weights.length; i++) {\r\n        if (weights[i] > max) {\r\n            max = weights[i];\r\n        }\r\n    }\r\n    for (int i = 0; i < weights.length; i++) {\r\n        weights[i] /= max;\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.learning.ConfusionMatrixPanel.renderMatrix",
	"Comment": "renders the confusion matrix and visualizes the value in each cell with a color and optionally a color.",
	"Method": "void renderMatrix(Graphics2D g2,double fontSize){\r\n    int numCategories = confusion.getNumRows();\r\n    Font fontNumber = new Font(\"Serif\", Font.BOLD, (int) (0.6 * fontSize + 0.5));\r\n    g2.setFont(fontNumber);\r\n    FontMetrics metrics = g2.getFontMetrics(fontNumber);\r\n    for (int i = 0; i < numCategories; i++) {\r\n        int y0 = i * gridHeight / numCategories;\r\n        int y1 = (i + 1) * gridHeight / numCategories;\r\n        for (int j = 0; j < numCategories; j++) {\r\n            int x0 = j * gridWidth / numCategories;\r\n            int x1 = (j + 1) * gridWidth / numCategories;\r\n            double value = confusion.unsafe_get(i, j);\r\n            int red, green, blue;\r\n            if (gray) {\r\n                red = green = blue = (int) (255 * (1.0 - value));\r\n            } else {\r\n                green = 0;\r\n                red = (int) (255 * value);\r\n                blue = (int) (255 * (1.0 - value));\r\n            }\r\n            g2.setColor(new Color(red, green, blue));\r\n            g2.fillRect(x0, y0, x1 - x0, y1 - y0);\r\n            if (showNumbers && (showZeros || value != 0)) {\r\n                int a = (red + green + blue) / 3;\r\n                String text = \"\" + (int) (value * 100.0 + 0.5);\r\n                Rectangle2D r = metrics.getStringBounds(text, null);\r\n                float adjX = (float) (r.getX() * 2 + r.getWidth()) / 2.0f;\r\n                float adjY = (float) (r.getY() * 2 + r.getHeight()) / 2.0f;\r\n                float x = ((x1 + x0) / 2f - adjX);\r\n                float y = ((y1 + y0) / 2f - adjY);\r\n                int gray = a > 127 ? 0 : 255;\r\n                g2.setColor(new Color(gray, gray, gray));\r\n                g2.drawString(text, x, y);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.boon.core.reflection.AnnotationData.getName",
	"Comment": "get the name of the annotation by lowercasing the first letterof the simple name, e.g., short name required becomes required.",
	"Method": "String getName(){\r\n    return name;\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.GenericOrientationImageTests.createOrientedImage",
	"Comment": "creates an integral image where the whole image has a gradient in the specified direction.",
	"Method": "void createOrientedImage(double angle){\r\n    double c = Math.cos(angle);\r\n    double s = Math.sin(angle);\r\n    for (int y = 0; y < height; y++) {\r\n        for (int x = 0; x < width; x++) {\r\n            double val = 125 + 2 * (x * c + y * s);\r\n            if (val < 0 || val > 255) {\r\n                throw new RuntimeException(\"Value is out of bounds for U8\");\r\n            }\r\n            GeneralizedImageOps.set(image, x, y, val);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.filter.convolve.FactoryConvolve.convolve",
	"Comment": "creates a filter for convolving 2d kernels along the image axis.",
	"Method": "ConvolveInterface<Input, Output> convolve(Kernel1D kernel,ImageType<Input> inputType,ImageType<Output> outputType,BorderType border,boolean isHorizontal,ConvolveInterface<Input, Output> convolve,Kernel2D kernel,Class<Input> inputType,Class<Output> outputType,BorderType borderType){\r\n    outputType = BoofTesting.convertToGenericType(outputType);\r\n    Class<?> borderClassType = FactoryImageBorder.lookupBorderClassType((Class) inputType);\r\n    Method m;\r\n    try {\r\n        switch(borderType) {\r\n            case SKIP:\r\n                m = ConvolveImageNoBorder.class.getMethod(\"convolve\", kernel.getClass(), inputType, outputType);\r\n                break;\r\n            case EXTENDED:\r\n                m = BoofTesting.findMethod(ConvolveImage.class, \"convolve\", kernel.getClass(), inputType, outputType, borderClassType);\r\n                break;\r\n            case REFLECT:\r\n                m = BoofTesting.findMethod(ConvolveImage.class, \"convolve\", kernel.getClass(), inputType, outputType, borderClassType);\r\n                break;\r\n            case WRAP:\r\n                m = BoofTesting.findMethod(ConvolveImage.class, \"convolve\", kernel.getClass(), inputType, outputType, borderClassType);\r\n                break;\r\n            case NORMALIZED:\r\n                m = ConvolveImageNormalized.class.getMethod(\"convolve\", kernel.getClass(), inputType, outputType);\r\n                break;\r\n            default:\r\n                throw new IllegalArgumentException(\"Unknown border type \" + borderType);\r\n        }\r\n    } catch (NoSuchMethodException e) {\r\n        throw new IllegalArgumentException(\"The specified convolution cannot be found\");\r\n    }\r\n    return new GenericConvolve(m, kernel, borderType, ImageType.single(inputType), ImageType.single(outputType));\r\n}"
}, {
	"Path": "boofcv.factory.feature.tracker.FactoryPointTracker.dda_FAST_BRIEF",
	"Comment": "creates a tracker which detects fast corner features and describes them with brief.",
	"Method": "PointTracker<I> dda_FAST_BRIEF(ConfigFastCorner configFast,ConfigGeneralDetector configExtract,int maxAssociationError,Class<I> imageType){\r\n    DescribePointBrief<I> brief = FactoryDescribePointAlgs.brief(FactoryBriefDefinition.gaussian2(new Random(123), 16, 512), FactoryBlurFilter.gaussian(ImageType.single(imageType), 0, 4));\r\n    GeneralFeatureDetector<I, D> corner = FactoryDetectPoint.createFast(configFast, configExtract, imageType);\r\n    EasyGeneralFeatureDetector<I, D> easy = new EasyGeneralFeatureDetector(corner, imageType, null);\r\n    ScoreAssociateHamming_B score = new ScoreAssociateHamming_B();\r\n    AssociateDescription2D<TupleDesc_B> association = new AssociateDescTo2D(FactoryAssociation.greedy(score, maxAssociationError, true));\r\n    DdaManagerGeneralPoint<I, D, TupleDesc_B> manager = new DdaManagerGeneralPoint(easy, new WrapDescribeBrief(brief, imageType), 1.0);\r\n    return new DetectDescribeAssociate(manager, association, false);\r\n}"
}, {
	"Path": "boofcv.struct.image.TestImageGray.constructor_w_h_n",
	"Comment": "test the constructor where the width,height and number of bands is specified.",
	"Method": "void constructor_w_h_n(){\r\n    DummyImage a = new DummyImage(10, 20);\r\n    assertEquals(10 * 20, a.data.length);\r\n    assertEquals(10, a.getWidth());\r\n    assertEquals(20, a.getHeight());\r\n    assertEquals(10, a.getStride());\r\n    assertEquals(0, a.getStartIndex());\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.TestCannyEdgeDynamic.basicTestPoints",
	"Comment": "just checks to see if it computes a reasonable threshold given fractional parameters",
	"Method": "void basicTestPoints(){\r\n    GrayU8 input = new GrayU8(width, height);\r\n    ImageMiscOps.fillRectangle(input, 50, 20, 30, 40, 50);\r\n    BlurFilter<GrayU8> blur = FactoryBlurFilter.gaussian(ImageType.single(GrayU8.class), -1, 1);\r\n    ImageGradient<GrayU8, GrayS16> gradient = FactoryDerivative.sobel(GrayU8.class, GrayS16.class);\r\n    CannyEdgeDynamic<GrayU8, GrayS16> alg = new CannyEdgeDynamic(blur, gradient, true);\r\n    alg.process(input, 0.2f, 0.4f, null);\r\n    List<EdgeContour> contour = alg.getContours();\r\n    int totalPass = 0;\r\n    for (EdgeContour e : contour) {\r\n        int total = 0;\r\n        for (EdgeSegment s : e.segments) {\r\n            total += s.points.size();\r\n        }\r\n        if (total >= 2 * 50 + 2 * 38)\r\n            totalPass++;\r\n    }\r\n    assertEquals(1, totalPass);\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.CalibrationDetectorCircleHexagonalGrid.createLayout",
	"Comment": "specifies the physical location of each point on the 2d calibration plane.the fiducial is centered on the\tcoordinate system",
	"Method": "List<Point2D_F64> createLayout(int numRows,int numCols,double centerDistance){\r\n    List<Point2D_F64> ret = new ArrayList();\r\n    double spaceX = centerDistance / 2.0;\r\n    double spaceY = centerDistance * Math.sin(UtilAngle.radian(60));\r\n    double width = (numCols - 1) * spaceX;\r\n    double height = (numRows - 1) * spaceY;\r\n    for (int row = 0; row < numRows; row++) {\r\n        double y = row * spaceY - height / 2;\r\n        for (int col = row % 2; col < numCols; col += 2) {\r\n            double x = col * spaceX - width / 2;\r\n            ret.add(new Point2D_F64(x, y));\r\n        }\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.CalibrationPlanarGridZhang99.setListener",
	"Comment": "used to listen in on progress and request that processing be stopped",
	"Method": "void setListener(Listener listener){\r\n    this.listener = listener;\r\n}"
}, {
	"Path": "org.boon.collections.FloatList.reduceBy",
	"Comment": "this would be a good opportunity to reintroduce dynamic invoke",
	"Method": "double reduceBy(Object function,double reduceBy,Object function,String name,double reduceBy,Flt.ReduceBy reduceBy){\r\n    return Flt.reduceBy(values, end, reduceBy);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.isLazyInit",
	"Comment": "returns true if connection pool is to be initialized lazily.",
	"Method": "boolean isLazyInit(){\r\n    return this.lazyInit;\r\n}"
}, {
	"Path": "boofcv.abst.geo.bundle.SceneStructureProjective.initialize",
	"Comment": "call this function first. specifies number of each type of data which is available.",
	"Method": "void initialize(int totalViews,int totalPoints){\r\n    views = new View[totalViews];\r\n    points = new Point[totalPoints];\r\n    for (int i = 0; i < views.length; i++) {\r\n        views[i] = new View();\r\n    }\r\n    for (int i = 0; i < points.length; i++) {\r\n        points[i] = new Point(pointSize);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.KeyPointsCircleHexagonalGrid.addTangents",
	"Comment": "computes tangent points to the two ellipses specified by the grid coordinates",
	"Method": "boolean addTangents(Grid grid,int rowA,int colA,int rowB,int colB){\r\n    EllipseRotated_F64 a = grid.get(rowA, colA);\r\n    EllipseRotated_F64 b = grid.get(rowB, colB);\r\n    if (a == null || b == null) {\r\n        return false;\r\n    }\r\n    if (!tangentFinder.process(a, b, A0, A1, A2, A3, B0, B1, B2, B3)) {\r\n        return false;\r\n    }\r\n    Tangents ta = tangents.get(grid.getIndexOfHexEllipse(rowA, colA));\r\n    Tangents tb = tangents.get(grid.getIndexOfHexEllipse(rowB, colB));\r\n    ta.grow().set(A0);\r\n    ta.grow().set(A3);\r\n    tb.grow().set(B0);\r\n    tb.grow().set(B3);\r\n    return true;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionHandle.isExpired",
	"Comment": "returns true if the given connection has exceeded the maxconnectionage.",
	"Method": "boolean isExpired(boolean isExpired,long currentTime){\r\n    return this.maxConnectionAgeInMs > 0 && (currentTime - this.connectionCreationTimeInMs) > this.maxConnectionAgeInMs;\r\n}"
}, {
	"Path": "boofcv.alg.transform.wavelet.CommonFactoryWavelet.checkEncodeDecode_I32",
	"Comment": "see if the provided wavelets can be used to transform the image and change it back without error",
	"Method": "void checkEncodeDecode_I32(WaveletDescription<WlCoef_I32> waveletDesc){\r\n    for (int makeOdd = 0; makeOdd <= 1; makeOdd++) {\r\n        GrayS32 orig = new GrayS32(width - makeOdd, height - makeOdd);\r\n        GrayS32 tran = new GrayS32(width, height);\r\n        GrayS32 rev = new GrayS32(width - makeOdd, height - makeOdd);\r\n        ImageMiscOps.fillUniform(orig, rand, -50, 50);\r\n        BorderIndex1D border = waveletDesc.getBorder();\r\n        ImplWaveletTransformNaive.horizontal(border, waveletDesc.forward, orig, tran);\r\n        ImplWaveletTransformNaive.horizontalInverse(border, waveletDesc.inverse, tran, rev);\r\n        BoofTesting.assertEquals(orig, rev, 0);\r\n        WaveletTransformOps.transform1(waveletDesc, orig, tran, null);\r\n        WaveletTransformOps.inverse1(waveletDesc, tran, rev, null, Integer.MIN_VALUE, Integer.MAX_VALUE);\r\n        BoofTesting.assertEquals(orig, rev, 0);\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.DetectDescribeAssociate.spawnTracks",
	"Comment": "takes the current crop of detected features and makes them the keyframe",
	"Method": "void spawnTracks(){\r\n    for (int setIndex = 0; setIndex < sets.length; setIndex++) {\r\n        SetTrackInfo<Desc> info = sets[setIndex];\r\n        if (info.isAssociated.length < info.featDst.size) {\r\n            info.isAssociated = new boolean[info.featDst.size];\r\n        }\r\n        for (int i = 0; i < info.featDst.size; i++) {\r\n            info.isAssociated[i] = false;\r\n        }\r\n        for (int i = 0; i < info.matches.size; i++) {\r\n            info.isAssociated[info.matches.data[i].dst] = true;\r\n        }\r\n        for (int i = 0; i < info.featDst.size; i++) {\r\n            if (info.isAssociated[i])\r\n                continue;\r\n            Point2D_F64 loc = info.locDst.get(i);\r\n            addNewTrack(setIndex, loc.x, loc.y, info.featDst.get(i));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.SiftScaleSpace.computeNextOctave",
	"Comment": "computes the next octave.if the last octave has already been computed false is returned.",
	"Method": "boolean computeNextOctave(){\r\n    currentOctave += 1;\r\n    if (currentOctave > lastOctave) {\r\n        return false;\r\n    }\r\n    if (octaveImages[numScales].width <= 5 || octaveImages[numScales].height <= 5)\r\n        return false;\r\n    PyramidOps.scaleDown2(octaveImages[numScales], tempImage0);\r\n    computeOctaveScales();\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.BaseTestDescribePointBinaryCompare.testManualCheck",
	"Comment": "compute the descriptor manually and see if it gets the same answer",
	"Method": "void testManualCheck(){\r\n    T input = createImage(width, height);\r\n    GImageGray a = FactoryGImageGray.wrap(input);\r\n    DescribePointBinaryCompare<T> alg = createAlg(def);\r\n    alg.setImage(input);\r\n    int c_x = input.width / 2;\r\n    int c_y = input.height / 2;\r\n    TupleDesc_B desc = createFeature();\r\n    alg.process(c_x, c_y, desc);\r\n    for (int i = 0; i < def.compare.length; i++) {\r\n        Point2D_I32 c = def.compare[i];\r\n        Point2D_I32 p0 = def.samplePoints[c.x];\r\n        Point2D_I32 p1 = def.samplePoints[c.y];\r\n        boolean expected = a.get(c_x + p0.x, c_y + p0.y).doubleValue() < a.get(c_x + p1.x, c_y + p1.y).doubleValue();\r\n        assertTrue(expected == desc.isBitTrue(def.compare.length - i - 1));\r\n    }\r\n}"
}, {
	"Path": "org.boon.messages.MessageUtils.generateLabelValue",
	"Comment": "generate the field. transforms firstname into first name. this allowsreasonable defaults for labels.",
	"Method": "String generateLabelValue(String fieldName){\r\n    final StringBuilder buffer = new StringBuilder(fieldName.length() * 2);\r\n    class GenerationCommand {\r\n        boolean capNextChar = false;\r\n        boolean lastCharWasUpperCase = false;\r\n        boolean lastCharWasNumber = false;\r\n        boolean lastCharWasSpecial = false;\r\n        boolean shouldContinue = true;\r\n        char[] chars = fieldName.toCharArray();\r\n        void processFieldName() {\r\n            for (int index = 0; index < chars.length; index++) {\r\n                char cchar = chars[index];\r\n                shouldContinue = true;\r\n                processCharWasNumber(buffer, index, cchar);\r\n                if (!shouldContinue) {\r\n                    continue;\r\n                }\r\n                processCharWasUpperCase(buffer, index, cchar);\r\n                if (!shouldContinue) {\r\n                    continue;\r\n                }\r\n                processSpecialChars(buffer, cchar);\r\n                if (!shouldContinue) {\r\n                    continue;\r\n                }\r\n                cchar = processCapitalizeCommand(cchar);\r\n                cchar = processFirstCharacterCheck(buffer, index, cchar);\r\n                if (!shouldContinue) {\r\n                    continue;\r\n                }\r\n                buffer.append(cchar);\r\n            }\r\n        }\r\n        private void processCharWasNumber(StringBuilder buffer, int index, char cchar) {\r\n            if (lastCharWasSpecial) {\r\n                return;\r\n            }\r\n            if (Character.isDigit(cchar)) {\r\n                if (index != 0 && !lastCharWasNumber) {\r\n                    buffer.append(' ');\r\n                }\r\n                lastCharWasNumber = true;\r\n                buffer.append(cchar);\r\n                this.shouldContinue = false;\r\n            } else {\r\n                lastCharWasNumber = false;\r\n            }\r\n        }\r\n        private char processFirstCharacterCheck(final StringBuilder buffer, int index, char cchar) {\r\n            if (index == 0) {\r\n                cchar = Character.toUpperCase(cchar);\r\n                buffer.append(cchar);\r\n                this.shouldContinue = false;\r\n            }\r\n            return cchar;\r\n        }\r\n        private char processCapitalizeCommand(char cchar) {\r\n            if (capNextChar) {\r\n                capNextChar = false;\r\n                cchar = Character.toUpperCase(cchar);\r\n            }\r\n            return cchar;\r\n        }\r\n        private void processSpecialChars(final StringBuilder buffer, char cchar) {\r\n            lastCharWasSpecial = false;\r\n            if (cchar == '.' || cchar == '_') {\r\n                buffer.append(' ');\r\n                capNextChar = true;\r\n                lastCharWasSpecial = false;\r\n                this.shouldContinue = false;\r\n            }\r\n        }\r\n        private void processCharWasUpperCase(final StringBuilder buffer, int index, char cchar) {\r\n            if (Character.isUpperCase(cchar)) {\r\n                if (index != 0 && !lastCharWasUpperCase) {\r\n                    buffer.append(' ');\r\n                }\r\n                lastCharWasUpperCase = true;\r\n                buffer.append(cchar);\r\n                this.shouldContinue = false;\r\n            } else {\r\n                lastCharWasUpperCase = false;\r\n            }\r\n        }\r\n    }\r\n    GenerationCommand gc = new GenerationCommand();\r\n    gc.processFieldName();\r\n    return buffer.toString().replace(\"  \", \" \");\r\n}"
}, {
	"Path": "org.boon.messages.MessageUtils.generateLabelValue",
	"Comment": "generate the field. transforms firstname into first name. this allowsreasonable defaults for labels.",
	"Method": "String generateLabelValue(String fieldName){\r\n    for (int index = 0; index < chars.length; index++) {\r\n        char cchar = chars[index];\r\n        shouldContinue = true;\r\n        processCharWasNumber(buffer, index, cchar);\r\n        if (!shouldContinue) {\r\n            continue;\r\n        }\r\n        processCharWasUpperCase(buffer, index, cchar);\r\n        if (!shouldContinue) {\r\n            continue;\r\n        }\r\n        processSpecialChars(buffer, cchar);\r\n        if (!shouldContinue) {\r\n            continue;\r\n        }\r\n        cchar = processCapitalizeCommand(cchar);\r\n        cchar = processFirstCharacterCheck(buffer, index, cchar);\r\n        if (!shouldContinue) {\r\n            continue;\r\n        }\r\n        buffer.append(cchar);\r\n    }\r\n}"
}, {
	"Path": "org.boon.messages.MessageUtils.generateLabelValue",
	"Comment": "generate the field. transforms firstname into first name. this allowsreasonable defaults for labels.",
	"Method": "String generateLabelValue(String fieldName){\r\n    if (lastCharWasSpecial) {\r\n        return;\r\n    }\r\n    if (Character.isDigit(cchar)) {\r\n        if (index != 0 && !lastCharWasNumber) {\r\n            buffer.append(' ');\r\n        }\r\n        lastCharWasNumber = true;\r\n        buffer.append(cchar);\r\n        this.shouldContinue = false;\r\n    } else {\r\n        lastCharWasNumber = false;\r\n    }\r\n}"
}, {
	"Path": "org.boon.messages.MessageUtils.generateLabelValue",
	"Comment": "generate the field. transforms firstname into first name. this allowsreasonable defaults for labels.",
	"Method": "String generateLabelValue(String fieldName){\r\n    if (index == 0) {\r\n        cchar = Character.toUpperCase(cchar);\r\n        buffer.append(cchar);\r\n        this.shouldContinue = false;\r\n    }\r\n    return cchar;\r\n}"
}, {
	"Path": "org.boon.messages.MessageUtils.generateLabelValue",
	"Comment": "generate the field. transforms firstname into first name. this allowsreasonable defaults for labels.",
	"Method": "String generateLabelValue(String fieldName){\r\n    if (capNextChar) {\r\n        capNextChar = false;\r\n        cchar = Character.toUpperCase(cchar);\r\n    }\r\n    return cchar;\r\n}"
}, {
	"Path": "org.boon.messages.MessageUtils.generateLabelValue",
	"Comment": "generate the field. transforms firstname into first name. this allowsreasonable defaults for labels.",
	"Method": "String generateLabelValue(String fieldName){\r\n    lastCharWasSpecial = false;\r\n    if (cchar == '.' || cchar == '_') {\r\n        buffer.append(' ');\r\n        capNextChar = true;\r\n        lastCharWasSpecial = false;\r\n        this.shouldContinue = false;\r\n    }\r\n}"
}, {
	"Path": "org.boon.messages.MessageUtils.generateLabelValue",
	"Comment": "generate the field. transforms firstname into first name. this allowsreasonable defaults for labels.",
	"Method": "String generateLabelValue(String fieldName){\r\n    if (Character.isUpperCase(cchar)) {\r\n        if (index != 0 && !lastCharWasUpperCase) {\r\n            buffer.append(' ');\r\n        }\r\n        lastCharWasUpperCase = true;\r\n        buffer.append(cchar);\r\n        this.shouldContinue = false;\r\n    } else {\r\n        lastCharWasUpperCase = false;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.TestPruneStructureFromSceneMetric.movePointBehindCameras",
	"Comment": "take this many observations and turn into garbage observations",
	"Method": "void movePointBehindCameras(int count){\r\n    List<Point> list = new ArrayList(Arrays.asList(structure.points));\r\n    Point3D_F64 world = new Point3D_F64();\r\n    for (int i = 0; i < count; i++) {\r\n        int selected = rand.nextInt(list.size() - i);\r\n        Point p = list.get(selected);\r\n        list.set(selected, list.get(list.size() - i - 1));\r\n        list.set(list.size() - i - 1, p);\r\n        p.get(world);\r\n        world.z = -world.z;\r\n        p.set(world.x, world.y, world.z);\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.geo.FactoryMultiView.triangulateRefineMetric",
	"Comment": "refine the triangulation by computing the difference between predicted and actual pixel location.\tdoes not take in account epipolar constraints.",
	"Method": "RefineTriangulationMetric triangulateRefineMetric(double convergenceTol,int maxIterations){\r\n    return new RefineTriangulateMetricEuclidean(convergenceTol, maxIterations);\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.TestPnPStereoRefineRodrigues.noisy",
	"Comment": "noisy input.should generate something close to the actual solution",
	"Method": "void noisy(){\r\n    generateScene(30, null, false);\r\n    PnPStereoRefineRodrigues alg = new PnPStereoRefineRodrigues(1e-12, 200);\r\n    alg.setLeftToRight(leftToRight);\r\n    Se3_F64 input = worldToLeft.copy();\r\n    DMatrixRMaj R = ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0.1, -0.04, -0.2, null);\r\n    CommonOps_DDRM.mult(R, input.getR().copy(), input.getR());\r\n    input.T.x += 0.2;\r\n    input.T.x -= 0.05;\r\n    input.T.z += 0.03;\r\n    Se3_F64 found = new Se3_F64();\r\n    assertTrue(alg.fitModel(pointPose, input, found));\r\n    assertTrue(alg.minimizer.getFunctionValue() < 1e-12);\r\n    assertTrue(MatrixFeatures_DDRM.isIdentical(worldToLeft.getR(), found.getR(), 1e-8));\r\n    assertTrue(found.getT().isIdentical(worldToLeft.getT(), 1e-8));\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionHandle.isConnectionAlive",
	"Comment": "sends a test query to the underlying connection and return true if connection is alive.",
	"Method": "boolean isConnectionAlive(){\r\n    return this.pool.isConnectionHandleAlive(this);\r\n}"
}, {
	"Path": "boofcv.struct.convolve.Kernel2D_S32.wrap",
	"Comment": "creates a kernel whose elements are the specified data array and has\tthe specified width.",
	"Method": "Kernel2D_S32 wrap(int data,int width,int offset){\r\n    if (width % 2 == 0 && width <= 0 && width * width > data.length)\r\n        throw new IllegalArgumentException(\"invalid width\");\r\n    Kernel2D_S32 ret = new Kernel2D_S32();\r\n    ret.data = data;\r\n    ret.width = width;\r\n    ret.offset = offset;\r\n    return ret;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestBoneCP.testGetConnectionUncheckedExceptionTriggeredWhileWaiting",
	"Comment": "like test 6, except we fake an unchecked exception to make sure our locks are released.",
	"Method": "void testGetConnectionUncheckedExceptionTriggeredWhileWaiting(){\r\n    reset(mockPartition, mockConnectionHandles, mockConnection);\r\n    expect(mockPartition.isUnableToCreateMoreTransactions()).andReturn(false).anyTimes();\r\n    expect(mockPartition.getFreeConnections()).andReturn(mockConnectionHandles).anyTimes();\r\n    expect(mockPartition.getMaxConnections()).andReturn(0).anyTimes();\r\n    replay(mockPartition, mockConnectionHandles, mockConnection, mockLock);\r\n    try {\r\n        testClass.getConnection();\r\n        fail(\"Should have thrown an exception\");\r\n    } catch (Throwable t) {\r\n    }\r\n    verify(mockPartition, mockConnectionHandles, mockConnection, mockLock);\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.Zhang99AllParam.getIntrinsic",
	"Comment": "converts to a generalized class that specifies camera intrinsic parameters",
	"Method": "Zhang99IntrinsicParam getIntrinsic(){\r\n    return this.intrinsic;\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.GenericQrCodeDetectorChecks.multipleMarkers",
	"Comment": "see if it can detect multiple fiducials in the image at the same time",
	"Method": "void multipleMarkers(){\r\n    QrCodeDetector<GrayF32> detector = createDetector();\r\n    CameraPinholeRadial model = CalibrationIO.load(getClass().getResource(\"calib/pinhole_radial.yaml\"));\r\n    SimulatePlanarWorld simulator = new SimulatePlanarWorld();\r\n    simulator.setCamera(model);\r\n    simulator.resetScene();\r\n    Se3_F64 markerToWorld0 = new Se3_F64();\r\n    Se3_F64 markerToWorld1 = new Se3_F64();\r\n    simulator.addSurface(markerToWorld0, simulatedTargetWidth, generateMarker());\r\n    simulator.addSurface(markerToWorld1, simulatedTargetWidth, generateMarker());\r\n    ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI, 0, markerToWorld0.R);\r\n    markerToWorld0.T.set(0.2, 0, 0.6);\r\n    ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI, 0, markerToWorld1.R);\r\n    markerToWorld1.T.set(-0.2, 0, 0.6);\r\n    simulator.render();\r\n    detector.process(simulator.getOutput());\r\n    if (display) {\r\n        ShowImages.showWindow(simulator.getOutput(), \"Foo\", true);\r\n        BoofMiscOps.sleep(10000);\r\n    }\r\n    List<QrCode> detections = detector.getDetections();\r\n    assertEquals(2, detections.size());\r\n}"
}, {
	"Path": "boofcv.abst.distort.FDistort.init",
	"Comment": "specifies the input and output image and sets interpolation to bilinear, black image border, cache is off.",
	"Method": "FDistort init(ImageBase input,ImageBase output){\r\n    this.input = input;\r\n    this.output = output;\r\n    inputType = input.getImageType();\r\n    interp(InterpolationType.BILINEAR);\r\n    border(0);\r\n    cached = false;\r\n    distorter = null;\r\n    outputToInput = null;\r\n    return this;\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.ImplDisparityScoreSadRectFive_F32.computeScoreFive",
	"Comment": "compute the final score by sampling the 5 regions.four regions are sampled around the center\tregion.out of those four only the two with the smallest score are used.",
	"Method": "void computeScoreFive(float top,float middle,float bottom,float score,int width){\r\n    for (int d = minDisparity; d < maxDisparity; d++) {\r\n        int indexSrc = (d - minDisparity) * width + (d - minDisparity) + radiusX;\r\n        int indexDst = (d - minDisparity) * width + (d - minDisparity);\r\n        int end = indexSrc + (width - d - 4 * radiusX);\r\n        while (indexSrc < end) {\r\n            int s = 0;\r\n            float val0 = top[indexSrc - radiusX];\r\n            float val1 = top[indexSrc + radiusX];\r\n            float val2 = bottom[indexSrc - radiusX];\r\n            float val3 = bottom[indexSrc + radiusX];\r\n            if (val1 < val0) {\r\n                float temp = val0;\r\n                val0 = val1;\r\n                val1 = temp;\r\n            }\r\n            if (val3 < val2) {\r\n                float temp = val2;\r\n                val2 = val3;\r\n                val3 = temp;\r\n            }\r\n            if (val3 < val0) {\r\n                s += val2;\r\n                s += val3;\r\n            } else if (val2 < val1) {\r\n                s += val2;\r\n                s += val0;\r\n            } else {\r\n                s += val0;\r\n                s += val1;\r\n            }\r\n            score[indexDst++] = s + middle[indexSrc++];\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.PairwiseImageMatching.fitEpipolar",
	"Comment": "uses ransac to fit an epipolar model to the associated features. adds list of matched features to the edge.",
	"Method": "boolean fitEpipolar(FastQueue<AssociatedIndex> matches,List<Point2D_F64> pointsA,List<Point2D_F64> pointsB,ModelMatcher<?, AssociatedPair> ransac,PairwiseImageGraph.Motion edge){\r\n    pairs.resize(matches.size);\r\n    for (int i = 0; i < matches.size; i++) {\r\n        AssociatedIndex a = matches.get(i);\r\n        pairs.get(i).p1.set(pointsA.get(a.src));\r\n        pairs.get(i).p2.set(pointsB.get(a.dst));\r\n    }\r\n    if (!ransac.process(pairs.toList()))\r\n        return false;\r\n    int N = ransac.getMatchSet().size();\r\n    for (int i = 0; i < N; i++) {\r\n        AssociatedIndex a = matches.get(ransac.getInputIndex(i));\r\n        edge.associated.add(a.copy());\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.boon.Boon.resourceList",
	"Comment": "load json list as resource .looks in file system first and then classpath.",
	"Method": "List<?> resourceList(String path,List<?> resourceList,Path path,List<T> resourceList,String path,Class<T> listOf,List<T> resourceList,Path path,Class<T> listOf){\r\n    List<Map> list = (List) jsonResource(path);\r\n    return MapObjectConversion.convertListOfMapsToObjects(listOf, list);\r\n}"
}, {
	"Path": "org.boon.Boon.fromJson",
	"Comment": "helper method to quickly convert json into a java object.facade into the json system.",
	"Method": "Object fromJson(String value,T fromJson,String value,Class<T> clazz){\r\n    return JsonFactory.fromJson(value, clazz);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.DetectFiducialSquareGrid.lookupDetection",
	"Comment": "looks up a detection given the fiducial id number.if not seen before the gridindex is saved and\ta new instance returned.",
	"Method": "Detection lookupDetection(long found,int gridIndex){\r\n    for (int i = 0; i < detections.size(); i++) {\r\n        Detection d = detections.get(i);\r\n        if (d.id == found) {\r\n            return d;\r\n        }\r\n    }\r\n    Detection d = detections.grow();\r\n    d.reset();\r\n    d.id = found;\r\n    d.gridIndex = gridIndex;\r\n    return d;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionThreadTester.testCloseConnection",
	"Comment": "should close off the connection by returning the connection to pool.",
	"Method": "void testCloseConnection(){\r\n    this.testClass = new ConnectionTesterThread(mockConnectionPartition, mockExecutor, mockPool, 123, 123, false);\r\n    expect(mockConnection.isClosed()).andReturn(false);\r\n    ConnectionPartition mockPartition = EasyMock.createNiceMock(ConnectionPartition.class);\r\n    BlockingQueue<Object> mockQueue = EasyMock.createNiceMock(BlockingQueue.class);\r\n    expect(mockConnection.getOriginatingPartition()).andReturn(mockPartition);\r\n    expect(mockPartition.getPoolWatchThreadSignalQueue()).andReturn(mockQueue);\r\n    expect(mockQueue.offer(anyObject())).andReturn(true).anyTimes();\r\n    mockPool.postDestroyConnection(mockConnection);\r\n    replay(mockConnection, mockPool, mockQueue, mockPartition);\r\n    this.testClass.closeConnection(mockConnection);\r\n    verify(mockPool, mockConnection, mockQueue);\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.PnPLepetitEPnP.adjustBetaSign",
	"Comment": "use the positive depth constraint to determine the sign of beta",
	"Method": "double adjustBetaSign(double beta,List<Point3D_F64> nullPts){\r\n    if (beta == 0)\r\n        return 0;\r\n    int N = alphas.numRows;\r\n    int positiveCount = 0;\r\n    for (int i = 0; i < N; i++) {\r\n        double z = 0;\r\n        for (int j = 0; j < numControl; j++) {\r\n            Point3D_F64 c = nullPts.get(j);\r\n            z += alphas.get(i, j) * c.z;\r\n        }\r\n        if (z > 0)\r\n            positiveCount++;\r\n    }\r\n    if (positiveCount < N / 2)\r\n        beta *= -1;\r\n    return beta;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.DetectCircleRegularGrid.isClockWise",
	"Comment": "uses the cross product to determine if the grid is in clockwise order",
	"Method": "boolean isClockWise(Grid g){\r\n    EllipseRotated_F64 v00 = g.get(0, 0);\r\n    EllipseRotated_F64 v02 = g.get(0, 1);\r\n    EllipseRotated_F64 v20 = g.get(1, 0);\r\n    double a_x = v02.center.x - v00.center.x;\r\n    double a_y = v02.center.y - v00.center.y;\r\n    double b_x = v20.center.x - v00.center.x;\r\n    double b_y = v20.center.y - v00.center.y;\r\n    return a_x * b_y - a_y * b_x < 0;\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.ThresholdBlockCommon.applyThreshold",
	"Comment": "applies the dynamically computed threshold to each pixel in the image, one block at a time",
	"Method": "void applyThreshold(T input,GrayU8 output){\r\n    for (int blockY = 0; blockY < stats.height; blockY++) {\r\n        for (int blockX = 0; blockX < stats.width; blockX++) {\r\n            thresholdBlock(blockX, blockY, input, output);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.ConfigFactory.createNewConfiguration",
	"Comment": "creates a new configuration object based on the provided parameterswill read the api key and other configuration values from the manifest if it is not provided",
	"Method": "Configuration createNewConfiguration(Context androidContext,String apiKey,boolean enableExceptionHandler){\r\n    Context appContext = androidContext.getApplicationContext();\r\n    boolean loadFromManifest = TextUtils.isEmpty(apiKey);\r\n    if (loadFromManifest) {\r\n        try {\r\n            PackageManager packageManager = appContext.getPackageManager();\r\n            String packageName = appContext.getPackageName();\r\n            ApplicationInfo ai = packageManager.getApplicationInfo(packageName, PackageManager.GET_META_DATA);\r\n            Bundle data = ai.metaData;\r\n            apiKey = data.getString(MF_API_KEY);\r\n        } catch (Exception ignore) {\r\n            Logger.warn(\"Bugsnag is unable to read api key from manifest.\");\r\n        }\r\n    }\r\n    if (apiKey == null) {\r\n        throw new NullPointerException(\"You must provide a Bugsnag API key\");\r\n    }\r\n    Configuration newConfig = new Configuration(apiKey);\r\n    newConfig.setEnableExceptionHandler(enableExceptionHandler);\r\n    if (loadFromManifest) {\r\n        try {\r\n            PackageManager packageManager = appContext.getPackageManager();\r\n            String packageName = appContext.getPackageName();\r\n            ApplicationInfo ai = packageManager.getApplicationInfo(packageName, PackageManager.GET_META_DATA);\r\n            Bundle data = ai.metaData;\r\n            populateConfigFromManifest(newConfig, data);\r\n        } catch (Exception ignore) {\r\n            Logger.warn(\"Bugsnag is unable to read config from manifest.\");\r\n        }\r\n    }\r\n    return newConfig;\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.calib.TestCalibrationDetectorSquareFiducialGrid.checkResults",
	"Comment": "specialized function which allows partial matches. hard to properly decode all the binary patterns at this\tresolution and it is designed for partial matches after all.",
	"Method": "void checkResults(SimulatePlanarWorld simulator,CalibrationObservation found,List<Point2D_F64> locations2D){\r\n    if (locations2D.size() < found.size() || found.size() < locations2D.size() * 2 / 4) {\r\n        visualize(simulator, locations2D, found);\r\n        fail(\"Number of detected points miss match. \" + found.size() + \" / \" + locations2D.size());\r\n    }\r\n    Point2D_F64 truth = new Point2D_F64();\r\n    int totalMatched = 0;\r\n    for (int i = 0; i < locations2D.size(); i++) {\r\n        Point2D_F64 p = locations2D.get(i);\r\n        simulator.computePixel(0, p.x, p.y, truth);\r\n        for (int j = 0; j < found.size(); j++) {\r\n            double distance = found.get(j).distance(truth);\r\n            if (distance <= fisheyeMatchTol) {\r\n                totalMatched++;\r\n                break;\r\n            }\r\n        }\r\n    }\r\n    assertEquals(totalMatched, found.size());\r\n}"
}, {
	"Path": "boofcv.struct.convolve.Kernel2D_F64.wrap",
	"Comment": "creates a kernel whose elements are the specified data array and has\tthe specified width.",
	"Method": "Kernel2D_F64 wrap(double data,int width,int offset){\r\n    if (width % 2 == 0 && width <= 0 && width * width > data.length)\r\n        throw new IllegalArgumentException(\"invalid width\");\r\n    Kernel2D_F64 ret = new Kernel2D_F64();\r\n    ret.data = data;\r\n    ret.width = width;\r\n    ret.offset = offset;\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.TestSquaresIntoRegularClusters.process",
	"Comment": "very basic test of the entire class.pass in squares which should be two clusters and see if two clusters\tcome out.",
	"Method": "void process(){\r\n    List<Polygon2D_F64> squares = new ArrayList();\r\n    double width = 1;\r\n    for (int i = 0; i < 3; i++) {\r\n        for (int j = 0; j < 4; j++) {\r\n            squares.add(createSquare(i * 2 * width, j * 2 * width, 0, width));\r\n            squares.add(createSquare(i * 2 * width + 100, j * 2 * width, 0, width));\r\n        }\r\n    }\r\n    SquaresIntoRegularClusters alg = new SquaresIntoRegularClusters(1.0, 6, 1.35);\r\n    List<List<SquareNode>> clusters = alg.process(squares);\r\n    assertEquals(2, clusters.size());\r\n    clusters = alg.process(squares);\r\n    assertEquals(2, clusters.size());\r\n}"
}, {
	"Path": "com.bugsnag.android.Error.setSeverity",
	"Comment": "set the severity of this error.by default, unhandled exceptions will be severity.error and handledexceptions sent with bugsnag.notify will be severity.warning.",
	"Method": "void setSeverity(Severity severity){\r\n    if (severity != null) {\r\n        this.severity = severity;\r\n        this.handledState.setCurrentSeverity(severity);\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.ApplicationLauncherApp.handleContextMenu",
	"Comment": "displays a context menu for a class leaf node\tallows copying of the name and the path to the source",
	"Method": "void handleContextMenu(JTree tree,int x,int y){\r\n    TreePath path = tree.getPathForLocation(x, y);\r\n    tree.setSelectionPath(path);\r\n    DefaultMutableTreeNode node = (DefaultMutableTreeNode) tree.getLastSelectedPathComponent();\r\n    if (node == null)\r\n        return;\r\n    if (!node.isLeaf()) {\r\n        tree.setSelectionPath(null);\r\n        return;\r\n    }\r\n    final AppInfo info = (AppInfo) node.getUserObject();\r\n    JMenuItem copyname = new JMenuItem(\"Copy Name\");\r\n    copyname.addActionListener(e -> {\r\n        Clipboard clipboard = Toolkit.getDefaultToolkit().getSystemClipboard();\r\n        clipboard.setContents(new StringSelection(info.app.getSimpleName()), null);\r\n    });\r\n    JMenuItem copypath = new JMenuItem(\"Copy Path\");\r\n    copypath.addActionListener(e -> {\r\n        String path1 = UtilIO.getSourcePath(info.app.getPackage().getName(), info.app.getSimpleName());\r\n        Clipboard clipboard = Toolkit.getDefaultToolkit().getSystemClipboard();\r\n        clipboard.setContents(new StringSelection(path1), null);\r\n    });\r\n    JMenuItem github = new JMenuItem(\"Go to Github\");\r\n    github.addActionListener(e -> openInGitHub(info));\r\n    JPopupMenu submenu = new JPopupMenu();\r\n    submenu.add(copyname);\r\n    submenu.add(copypath);\r\n    submenu.add(github);\r\n    submenu.show(tree, x, y);\r\n}"
}, {
	"Path": "org.boon.core.reflection.AnnotationData.doGetValues",
	"Comment": "get the values from the annotation.we use reflection to turn the annotation into a simple hashmapof values.",
	"Method": "Map<String, Object> doGetValues(Annotation annotation){\r\n    Map<String, Object> values = new HashMap<String, Object>();\r\n    Method[] methods = annotation.annotationType().getDeclaredMethods();\r\n    final Object[] noargs = (Object[]) null;\r\n    for (Method method : methods) {\r\n        if (method.getParameterTypes().length == 0) {\r\n            try {\r\n                Object value = method.invoke(annotation, noargs);\r\n                if (value instanceof Enum) {\r\n                    Enum enumVal = (Enum) value;\r\n                    value = enumVal.name();\r\n                }\r\n                values.put(method.getName(), value);\r\n            } catch (Exception ex) {\r\n                throw new RuntimeException(ex);\r\n            }\r\n        }\r\n    }\r\n    return values;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionMaxAgeTester.testConnectionNotExpiredLifoMode",
	"Comment": "tests that a partition with expired connections should those connections killed off.",
	"Method": "void testConnectionNotExpiredLifoMode(){\r\n    BlockingQueue<ConnectionHandle> mockQueue = createNiceMock(LinkedBlockingQueue.class);\r\n    expect(mockConnectionPartition.getAvailableConnections()).andReturn(1);\r\n    expect(mockConnectionPartition.getFreeConnections()).andReturn(mockQueue).anyTimes();\r\n    ConnectionHandle mockConnection = createNiceMock(ConnectionHandle.class);\r\n    expect(mockQueue.poll()).andReturn(mockConnection).once();\r\n    expect(mockConnection.isExpired(anyLong())).andReturn(false).once();\r\n    expect(mockExecutor.isShutdown()).andReturn(false).once();\r\n    expect(mockConnection.getOriginatingPartition()).andReturn(mockConnectionPartition).anyTimes();\r\n    expect(mockQueue.offer(mockConnection)).andReturn(false).anyTimes();\r\n    mockConnection.internalClose();\r\n    replay(mockQueue, mockExecutor, mockConnectionPartition, mockConnection, mockPool);\r\n    ConnectionMaxAgeThread testClass2 = new ConnectionMaxAgeThread(mockConnectionPartition, mockExecutor, mockPool, 5000, true);\r\n    testClass2.run();\r\n    verify(mockConnection, mockPool);\r\n}"
}, {
	"Path": "boofcv.abst.filter.transform.fft.GenericTestDiscreteFourierTransform.multipleCalls_differentSizes",
	"Comment": "call the same instance multiple times with images of different sizes",
	"Method": "void multipleCalls_differentSizes(){\r\n    checkMultipleCalls(new int[] { 1, 10, 100 });\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.TrackerMeanShiftLikelihood.initialize",
	"Comment": "specifies the initial target location so that it can learn its description",
	"Method": "void initialize(T image,RectangleLength2D_I32 initial){\r\n    if (!image.isInBounds(initial.x0, initial.y0))\r\n        throw new IllegalArgumentException(\"Initial rectangle is out of bounds!\");\r\n    if (!image.isInBounds(initial.x0 + initial.width, initial.y0 + initial.height))\r\n        throw new IllegalArgumentException(\"Initial rectangle is out of bounds!\");\r\n    pdf.reshape(image.width, image.height);\r\n    ImageMiscOps.fill(pdf, -1);\r\n    setTrackLocation(initial);\r\n    failed = false;\r\n    minimumSum = 0;\r\n    targetModel.setImage(image);\r\n    for (int y = 0; y < initial.height; y++) {\r\n        for (int x = 0; x < initial.width; x++) {\r\n            minimumSum += targetModel.compute(x + initial.x0, y + initial.y0);\r\n        }\r\n    }\r\n    minimumSum *= minFractionDrop;\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.ChecksSelectSparseStandardWta.multiplePeakFirstAtIndexZero",
	"Comment": "see if multiple peak detection works correctly when the first peak is at zero.there was a bug related to\tthis at one point.",
	"Method": "void multiplePeakFirstAtIndexZero(){\r\n    int maxDisparity = 10;\r\n    SelectSparseStandardWta<ArrayData> alg = createAlg(-1, 3);\r\n    int[] scores = new int[maxDisparity + 10];\r\n    for (int d = 0; d < 10; d++) {\r\n        scores[d] = d * 2 + 1;\r\n    }\r\n    assertTrue(alg.select(copyToCorrectType(scores, arrayType), maxDisparity));\r\n}"
}, {
	"Path": "org.boon.Boon.resourceFromTemplate",
	"Comment": "load a resource and apply the given template against it.if file resource is not found, tries to load the resource from classpath.uses jstl style template",
	"Method": "String resourceFromTemplate(String path,Object context,String resourceFromTemplate,Path path,Object context){\r\n    String str = IO.read(path);\r\n    if (str != null) {\r\n        str = Boon.jstl(str, context);\r\n    }\r\n    return str;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionThreadTester.testIdleConnectionIsKilled",
	"Comment": "tests that a connection that has been idle for more than the set time is closed off.",
	"Method": "void testIdleConnectionIsKilled(){\r\n    LinkedBlockingQueue<ConnectionHandle> fakeFreeConnections = new LinkedBlockingQueue<ConnectionHandle>(100);\r\n    fakeFreeConnections.add(mockConnection);\r\n    fakeFreeConnections.add(mockConnection);\r\n    BoneCPConfig localconfig = config.clone();\r\n    expect(mockPool.getConfig()).andReturn(localconfig.clone()).anyTimes();\r\n    expect(mockConnectionPartition.getFreeConnections()).andReturn(fakeFreeConnections).anyTimes();\r\n    expect(mockConnectionPartition.getAvailableConnections()).andReturn(2).anyTimes();\r\n    expect(mockConnection.isPossiblyBroken()).andReturn(false);\r\n    expect(mockConnection.getConnectionLastUsedInMs()).andReturn(0L);\r\n    mockConnection.internalClose();\r\n    mockPool.postDestroyConnection(mockConnection);\r\n    expectLastCall().once();\r\n    replay(mockPool, mockConnection, mockConnectionPartition, mockExecutor);\r\n    this.testClass = new ConnectionTesterThread(mockConnectionPartition, mockExecutor, mockPool, localconfig.getIdleMaxAge(TimeUnit.MILLISECONDS), localconfig.getIdleConnectionTestPeriodInMinutes(), false);\r\n    this.testClass.run();\r\n    verify(mockPool, mockConnectionPartition, mockExecutor, mockConnection);\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.TestSelectSparseStandardSubpixel_F32.addSubpixelBias",
	"Comment": "given different local error values see if it is closer to the value with a smaller error",
	"Method": "void addSubpixelBias(){\r\n    SelectSparseStandardSubpixel.F32 alg = new SelectSparseStandardSubpixel.F32(-1, -1);\r\n    float[] scores = new float[30];\r\n    Arrays.fill(scores, 0, 10, 500);\r\n    scores[4] = 100;\r\n    scores[5] = 50;\r\n    scores[6] = 200;\r\n    assertTrue(alg.select(scores, 10));\r\n    double found = alg.getDisparity();\r\n    assertTrue(found < 5 && found > 4);\r\n    scores[4] = 200;\r\n    scores[6] = 100;\r\n    assertTrue(alg.select(scores, 10));\r\n    found = alg.getDisparity();\r\n    assertTrue(found < 6 && found > 5);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TestTldDetection.selectBestRegionsFern_smaller",
	"Comment": "see if the case where there are fewer than the maximum number of regions is handled correctly",
	"Method": "void selectBestRegionsFern_smaller(){\r\n    TldDetection<GrayU8> alg = new TldDetection();\r\n    alg.config = new TldParameters();\r\n    alg.config.maximumCascadeConsider = 20;\r\n    for (int i = 0; i < 10; i++) {\r\n        alg.fernInfo.grow();\r\n        alg.fernInfo.get(i).r = new ImageRectangle(i, i, i, i);\r\n        alg.fernInfo.get(i).sumP = 20;\r\n        alg.fernInfo.get(i).sumN = 6;\r\n    }\r\n    alg.selectBestRegionsFern(200, 200);\r\n    assertEquals(10, alg.fernRegions.size());\r\n}"
}, {
	"Path": "org.boon.slumberdb.stores.log.CollectorManager.offer",
	"Comment": "this gets called by the http post handler or event bus handler.",
	"Method": "void offer(ByteBuffer batch){\r\n    batch.flip();\r\n    inputChannel.offer(batch);\r\n}"
}, {
	"Path": "org.boon.cache.FastConcurrentReadLruLfuFifoCache.get",
	"Comment": "get the value from the cache. it does not touch the lock soreads are fast.this does not touch the order list so it is fast.",
	"Method": "VALUE get(KEY key){\r\n    CacheEntry<KEY, VALUE> cacheEntry = map.get(key);\r\n    if (cacheEntry != null) {\r\n        cacheEntry.readCount.incrementAndGet();\r\n        return cacheEntry.value;\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.BoofSwingUtil.selectZoomToShowAll",
	"Comment": "select a zoom which will allow the entire image to be shown in the panel",
	"Method": "double selectZoomToShowAll(JComponent panel,int width,int height){\r\n    int w = panel.getWidth();\r\n    int h = panel.getHeight();\r\n    if (w == 0) {\r\n        w = panel.getPreferredSize().width;\r\n        h = panel.getPreferredSize().height;\r\n    }\r\n    double scale = Math.max(width / (double) w, height / (double) h);\r\n    if (scale > 1.0) {\r\n        return 1.0 / scale;\r\n    } else {\r\n        return 1.0;\r\n    }\r\n}"
}, {
	"Path": "org.boon.validation.ValidationContext.getProposedPropertyValue",
	"Comment": "gets the proposed property value.this is the value before it gets applied to the actual bean.",
	"Method": "Object getProposedPropertyValue(String propertyName){\r\n    return null;\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationLinearRotationMulti.computeInverseH",
	"Comment": "ensures the determinant is one then inverts the homogrpahy",
	"Method": "boolean computeInverseH(List<Homography2D_F64> homography0toI){\r\n    listHInv.reset();\r\n    int N = homography0toI.size();\r\n    for (int i = 0; i < N; i++) {\r\n        Homography2D_F64 H = homography0toI.get(i);\r\n        Homography2D_F64 Hinv = listHInv.grow();\r\n        double d = CommonOps_DDF3.det(H);\r\n        if (d < 0)\r\n            CommonOps_DDF3.divide(H, -Math.pow(-d, 1.0 / 3), Hinv);\r\n        else\r\n            CommonOps_DDF3.divide(H, Math.pow(d, 1.0 / 3), Hinv);\r\n        if (!CommonOps_DDF3.invert(Hinv, Hinv)) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.GenericOrientationIntegralTests.performEasyTests",
	"Comment": "points all pixels in the surrounding region in same direction.then sees if the found\tdirection for the region is in the expected direction.",
	"Method": "void performEasyTests(){\r\n    alg.setObjectRadius(10);\r\n    int N = 2 * (int) (Math.PI / angleTolerance);\r\n    int x = width / 2;\r\n    int y = height / 2;\r\n    for (int i = 0; i < N; i++) {\r\n        double angle = UtilAngle.bound(i * angleTolerance);\r\n        createOrientedImage(angle);\r\n        alg.setImage(ii);\r\n        double found = UtilAngle.bound(alg.compute(x, y));\r\n        assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.rectify.RectifyFundamental.translateToOrigin",
	"Comment": "create a transform which will move the specified point to the origin",
	"Method": "SimpleMatrix translateToOrigin(int x0,int y0){\r\n    SimpleMatrix T = SimpleMatrix.identity(3);\r\n    T.set(0, 2, -x0);\r\n    T.set(1, 2, -y0);\r\n    return T;\r\n}"
}, {
	"Path": "boofcv.alg.misc.GImageStatistics.variance",
	"Comment": "computes the variance of pixel intensity values inside the image.",
	"Method": "double variance(T input,double mean){\r\n    if (GrayU8.class == input.getClass()) {\r\n        return ImageStatistics.variance((GrayU8) input, mean);\r\n    } else if (GrayS8.class == input.getClass()) {\r\n        return ImageStatistics.variance((GrayS8) input, mean);\r\n    } else if (GrayU16.class == input.getClass()) {\r\n        return ImageStatistics.variance((GrayU16) input, mean);\r\n    } else if (GrayS16.class == input.getClass()) {\r\n        return ImageStatistics.variance((GrayS16) input, mean);\r\n    } else if (GrayS32.class == input.getClass()) {\r\n        return ImageStatistics.variance((GrayS32) input, mean);\r\n    } else if (GrayS64.class == input.getClass()) {\r\n        return ImageStatistics.variance((GrayS64) input, mean);\r\n    } else if (GrayF32.class == input.getClass()) {\r\n        return ImageStatistics.variance((GrayF32) input, (float) mean);\r\n    } else if (GrayF64.class == input.getClass()) {\r\n        return ImageStatistics.variance((GrayF64) input, mean);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown image Type\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.GeneralLensDistortionWideFOVChecks.blowup_extreme_angle_F64",
	"Comment": "give it spherical coordinate pointing slightly behind.see if it blows up when converting into pixels",
	"Method": "void blowup_extreme_angle_F64(){\r\n    LensDistortionWideFOV alg = create();\r\n    Point3Transform2_F64 distort = alg.distortStoP_F64();\r\n    Point2D_F64 found = new Point2D_F64();\r\n    double x = 1.0;\r\n    double z = -0.001;\r\n    double r = Math.sqrt(x * x + z * z);\r\n    distort.compute(x / r, 0, z / x, found);\r\n    assertTrue(!UtilEjml.isUncountable(found.x));\r\n    assertTrue(!UtilEjml.isUncountable(found.y));\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.TestLinearContourLabelChang2004.findContour4",
	"Comment": "create an unordered list of all points in the internal and external contour",
	"Method": "List<Point2D_I32> findContour4(GrayS32 labeled,int target){\r\n    List<Point2D_I32> list = new ArrayList();\r\n    ImageBorder<GrayS32> border = FactoryImageBorder.singleValue(labeled, 0);\r\n    for (int y = 0; y < labeled.height; y++) {\r\n        for (int x = 0; x < labeled.width; x++) {\r\n            if (target == labeled.get(x, y)) {\r\n                boolean isContour = false;\r\n                for (int i = 0; i < local.size(); i++) {\r\n                    Point2D_I32 a = local.get(i);\r\n                    if (get(border, x + a.x, y + a.y) != target) {\r\n                        isContour = true;\r\n                    }\r\n                }\r\n                if (isContour)\r\n                    list.add(new Point2D_I32(x, y));\r\n            }\r\n        }\r\n    }\r\n    return list;\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.GenericOrientationGradientTests.setScale",
	"Comment": "estimate the direction at a couple of different scales and see if it produces the expected results.",
	"Method": "void setScale(){\r\n    int x = width / 2;\r\n    int y = height / 2;\r\n    int N = 2 * (int) (Math.PI / angleTolerance);\r\n    double angle = UtilAngle.bound((N / 2) * angleTolerance);\r\n    double c = Math.cos(angle);\r\n    double s = Math.sin(angle);\r\n    GImageMiscOps.fill(derivX, c * 100);\r\n    GImageMiscOps.fill(derivY, s * 100);\r\n    alg.setImage(derivX, derivY);\r\n    alg.setObjectRadius(10);\r\n    double found = UtilAngle.bound(alg.compute(x, y));\r\n    assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n    alg.setObjectRadius(15);\r\n    found = UtilAngle.bound(alg.compute(x, y));\r\n    assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n    alg.setObjectRadius(5);\r\n    found = UtilAngle.bound(alg.compute(x, y));\r\n    assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.TestLinearContourLabelChang2004.findContour8",
	"Comment": "create an unordered list of all points in the internal and external contour",
	"Method": "List<Point2D_I32> findContour8(GrayS32 labeled,int target){\r\n    List<Point2D_I32> list = new ArrayList();\r\n    ImageBorder<GrayS32> border = FactoryImageBorder.singleValue(labeled, 0);\r\n    for (int y = 0; y < labeled.height; y++) {\r\n        for (int x = 0; x < labeled.width; x++) {\r\n            if (target == labeled.get(x, y)) {\r\n                boolean isContour = false;\r\n                for (int i = 0; i < local.size() - 1; i++) {\r\n                    Point2D_I32 a = local.get(i);\r\n                    Point2D_I32 b = local.get(i + 1);\r\n                    if (get(border, x + a.x, y + a.y) != target && get(border, x + b.x, y + b.y) != target) {\r\n                        isContour = true;\r\n                        break;\r\n                    }\r\n                }\r\n                if (!isContour && get(border, x + 1, y) != target)\r\n                    isContour = true;\r\n                if (!isContour && get(border, x - 1, y) != target)\r\n                    isContour = true;\r\n                if (!isContour && get(border, x, y + 1) != target)\r\n                    isContour = true;\r\n                if (!isContour && get(border, x, y - 1) != target)\r\n                    isContour = true;\r\n                if (isContour)\r\n                    list.add(new Point2D_I32(x, y));\r\n            }\r\n        }\r\n    }\r\n    return list;\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.BaseTestDescribeSurf.features_constant",
	"Comment": "if the image has a constant value then all the features should be zero.",
	"Method": "void features_constant(){\r\n    GImageMiscOps.fill(input, 50);\r\n    GIntegralImageOps.transform(input, ii);\r\n    sparse = TestImplSurfDescribeOps.createGradient(ii, 1);\r\n    alg.setImage(ii);\r\n    BrightFeature feat = alg.createDescription();\r\n    alg.describe(20, 20, 0.75, 1, feat);\r\n    for (double f : feat.value) assertEquals(0, f, 1e-4);\r\n}"
}, {
	"Path": "com.gazbert.bxbot.exchanges.AbstractExchangeAdapter.getAuthenticationConfig",
	"Comment": "fetches the authentication config for the exchange adapter.",
	"Method": "AuthenticationConfig getAuthenticationConfig(ExchangeConfig exchangeConfig){\r\n    final AuthenticationConfig authenticationConfig = exchangeConfig.getAuthenticationConfig();\r\n    if (authenticationConfig == null) {\r\n        final String errorMsg = AUTHENTICATION_CONFIG_MISSING + exchangeConfig;\r\n        LOG.error(errorMsg);\r\n        throw new IllegalArgumentException(errorMsg);\r\n    }\r\n    return authenticationConfig;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionHandle.setInternalConnection",
	"Comment": "sets the internal connection to use. be careful how to use this method, normally you should never need it! this is here\tfor odd use cases only!",
	"Method": "void setInternalConnection(Connection rawConnection){\r\n    this.connection = rawConnection;\r\n}"
}, {
	"Path": "boofcv.demonstrations.feature.describe.VisualizeRegionDescriptionApp.updateTargetDescription",
	"Comment": "extracts the target description and updates the panel.should only be called from a swing thread",
	"Method": "void updateTargetDescription(){\r\n    if (targetPt != null) {\r\n        TupleDesc feature = describe.createDescription();\r\n        describe.process(targetPt.x, targetPt.y, targetOrientation, targetRadius, feature);\r\n        tuplePanel.setDescription(feature);\r\n    } else {\r\n        tuplePanel.setDescription(null);\r\n    }\r\n    tuplePanel.repaint();\r\n}"
}, {
	"Path": "boofcv.gui.DemonstrationBase.openFile",
	"Comment": "opens a file.first it will attempt to open it as an image.if that fails it will try opening it as a\tvideo.if all else fails tell the user it has failed.if a streaming source was running before it will\tbe stopped.",
	"Method": "void openFile(File file){\r\n    String path = systemToUnix(file.getPath());\r\n    URL url = null;\r\n    try {\r\n        url = new URL(path);\r\n        if (!UtilIO.validURL(url)) {\r\n            url = null;\r\n        }\r\n    } catch (MalformedURLException ignore) {\r\n    }\r\n    if (url == null) {\r\n        try {\r\n            url = new File(UtilIO.pathExample(file.getPath())).toURI().toURL();\r\n            if (!UtilIO.validURL(url)) {\r\n                System.err.println(\"Can't open \" + file.getPath());\r\n                return;\r\n            }\r\n            inputFilePath = url.toString();\r\n        } catch (MalformedURLException e) {\r\n            System.err.println(e.getMessage());\r\n            return;\r\n        }\r\n    } else {\r\n        inputFilePath = path;\r\n    }\r\n    final String _path = inputFilePath;\r\n    BoofSwingUtil.invokeNowOrLater(() -> {\r\n        BoofSwingUtil.addToRecentFiles(DemonstrationBase.this, _path);\r\n        updateRecentItems();\r\n    });\r\n    BufferedImage buffered = inputFilePath.endsWith(\"mjpeg\") ? null : UtilImageIO.loadImage(inputFilePath);\r\n    if (buffered == null) {\r\n        if (allowVideos)\r\n            openVideo(false, inputFilePath);\r\n    } else if (allowImages) {\r\n        openImage(false, file.getName(), buffered);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.GenericOrientationIntegralTests.createOrientedImage",
	"Comment": "creates an integral image where the whole image has a gradient in the specified direction.",
	"Method": "void createOrientedImage(double angle){\r\n    T input = (T) ii.createNew(width, height);\r\n    double c = Math.cos(angle);\r\n    double s = Math.sin(angle);\r\n    for (int y = 0; y < height; y++) {\r\n        for (int x = 0; x < width; x++) {\r\n            double val = 10 * (x * c + y * s);\r\n            GeneralizedImageOps.set(input, x, y, val);\r\n        }\r\n    }\r\n    GIntegralImageOps.transform(input, ii);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.windows.renderer.NumberCellRenderer.withRatingColors",
	"Comment": "sets the rating colors for this cell renderer, based on a min and a max value.",
	"Method": "T withRatingColors(double min,double max){\r\n    if (min >= max) {\r\n        throw new IllegalArgumentException(String.format(\"Rating limits wrong. min (%s) has to be lower than max (%s).\", min, max));\r\n    }\r\n    this.isWithColors = true;\r\n    this.minValue = min;\r\n    this.maxValue = max;\r\n    return (T) this;\r\n}"
}, {
	"Path": "org.boon.primitive.ReaderCharacterSource.findNextChar",
	"Comment": "remember that this must work past buffer reader boundaries so we need to keeptrack where we were in the nested run.if we start with match then we skip to the the next match.",
	"Method": "char[] findNextChar(int match,int esc,char[] findNextChar,boolean inMiddleOfString,boolean wasEscapeChar,int match,int esc){\r\n    try {\r\n        ensureBuffer();\r\n        int idx = index;\r\n        char[] _chars = readBuf;\r\n        int length = this.length;\r\n        int ch = this.ch;\r\n        if (!inMiddleOfString) {\r\n            foundEscape = false;\r\n            if (ch == match) {\r\n            } else if (idx < length - 1) {\r\n                ch = _chars[idx];\r\n                if (ch == match) {\r\n                    idx++;\r\n                }\r\n            }\r\n        }\r\n        if (idx < length) {\r\n            ch = _chars[idx];\r\n        }\r\n        if (ch == '\"' && !wasEscapeChar) {\r\n            index = idx;\r\n            index++;\r\n            return EMPTY_CHARS;\r\n        }\r\n        int start = idx;\r\n        if (wasEscapeChar) {\r\n            idx++;\r\n        }\r\n        boolean foundEnd = false;\r\n        char[] results;\r\n        boolean _foundEscape = false;\r\n        while (true) {\r\n            ch = _chars[idx];\r\n            if (ch == match || ch == esc) {\r\n                if (ch == match) {\r\n                    foundEnd = true;\r\n                    break;\r\n                } else if (ch == esc) {\r\n                    wasEscapeChar = true;\r\n                    _foundEscape = true;\r\n                    if (idx + 1 < length) {\r\n                        wasEscapeChar = false;\r\n                        idx++;\r\n                    }\r\n                }\r\n            }\r\n            if (idx >= length)\r\n                break;\r\n            idx++;\r\n        }\r\n        foundEscape = _foundEscape;\r\n        if (idx == 0) {\r\n            results = EMPTY_CHARS;\r\n        } else {\r\n            results = Arrays.copyOfRange(_chars, start, idx);\r\n        }\r\n        index = idx;\r\n        if (foundEnd) {\r\n            index++;\r\n            if (index < length) {\r\n                ch = _chars[index];\r\n                this.ch = ch;\r\n            }\r\n            return results;\r\n        } else {\r\n            if (index >= length && !done) {\r\n                ensureBuffer();\r\n                char[] results2 = findNextChar(true, wasEscapeChar, match, esc);\r\n                return Chr.add(results, results2);\r\n            } else {\r\n                return die(char[].class, \"Unable to find close char \" + (char) match + \" \" + new String(results));\r\n            }\r\n        }\r\n    } catch (Exception ex) {\r\n        String str = CharScanner.errorDetails(\"findNextChar issue\", readBuf, index, ch);\r\n        return Exceptions.handle(char[].class, str, ex);\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.getNotifyReleaseStages",
	"Comment": "get for which releasestages errors should be sent to bugsnag.",
	"Method": "String[] getNotifyReleaseStages(){\r\n    return notifyReleaseStages;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldFernClassifier.setImage",
	"Comment": "call before any other functions.provides the image that is being sampled.",
	"Method": "void setImage(T gray){\r\n    interpolate.setImage(gray);\r\n}"
}, {
	"Path": "boofcv.examples.imageprocessing.ExampleFourierTransform.applyBoxFilter",
	"Comment": "demonstration of how to apply a box filter in the frequency domain and compares the results\tto a box filter which has been applied in the spatial domain",
	"Method": "void applyBoxFilter(GrayF32 input){\r\n    GrayF32 boxImage = new GrayF32(input.width, input.height);\r\n    InterleavedF32 boxTransform = new InterleavedF32(input.width, input.height, 2);\r\n    InterleavedF32 transform = new InterleavedF32(input.width, input.height, 2);\r\n    GrayF32 blurredImage = new GrayF32(input.width, input.height);\r\n    GrayF32 spatialBlur = new GrayF32(input.width, input.height);\r\n    DiscreteFourierTransform<GrayF32, InterleavedF32> dft = DiscreteFourierTransformOps.createTransformF32();\r\n    PixelMath.divide(input, 255.0f, input);\r\n    dft.forward(input, transform);\r\n    for (int y = 0; y < 15; y++) {\r\n        int yy = y - 7 < 0 ? boxImage.height + (y - 7) : y - 7;\r\n        for (int x = 0; x < 15; x++) {\r\n            int xx = x - 7 < 0 ? boxImage.width + (x - 7) : x - 7;\r\n            boxImage.set(xx, yy, 1.0f / (15 * 15));\r\n        }\r\n    }\r\n    dft.forward(boxImage, boxTransform);\r\n    displayTransform(transform, \"Input Image\");\r\n    displayTransform(boxTransform, \"Box Filter\");\r\n    DiscreteFourierTransformOps.multiplyComplex(transform, boxTransform, transform);\r\n    dft.inverse(transform, blurredImage);\r\n    PixelMath.multiply(blurredImage, 255.0f, blurredImage);\r\n    PixelMath.multiply(input, 255.0f, input);\r\n    BlurImageOps.mean(input, spatialBlur, 7, null);\r\n    BufferedImage originOut = ConvertBufferedImage.convertTo(input, null);\r\n    BufferedImage spacialOut = ConvertBufferedImage.convertTo(spatialBlur, null);\r\n    BufferedImage blurredOut = ConvertBufferedImage.convertTo(blurredImage, null);\r\n    ListDisplayPanel listPanel = new ListDisplayPanel();\r\n    listPanel.addImage(originOut, \"Original Image\");\r\n    listPanel.addImage(spacialOut, \"Spacial Domain Box\");\r\n    listPanel.addImage(blurredOut, \"Frequency Domain Box\");\r\n    ShowImages.showWindow(listPanel, \"Box Blur in Spacial and Frequency Domain of Input Image\");\r\n}"
}, {
	"Path": "boofcv.openkinect.StreamOpenKinectRgbDepth.stop",
	"Comment": "stops all the threads from running and closes the video channels and video device",
	"Method": "void stop(){\r\n    thread.requestStop = true;\r\n    long start = System.currentTimeMillis() + timeout;\r\n    while (start > System.currentTimeMillis() && thread.running) Thread.yield();\r\n    device.stopDepth();\r\n    device.stopVideo();\r\n    device.close();\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.GenericOrientationImageTests.performEasyTests",
	"Comment": "points all pixels in the surrounding region in same direction.then sees if the found\tdirection for the region is in the expected direction.",
	"Method": "void performEasyTests(){\r\n    alg.setObjectRadius(5);\r\n    int N = 2 * (int) (Math.PI / angleTolerance);\r\n    int x = width / 2;\r\n    int y = height / 2;\r\n    for (int i = 0; i < N; i++) {\r\n        double angle = UtilAngle.bound(i * angleTolerance);\r\n        createOrientedImage(angle);\r\n        alg.setImage(image);\r\n        double found = UtilAngle.bound(alg.compute(x, y));\r\n        assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n    }\r\n}"
}, {
	"Path": "boofcv.examples.stereo.ExampleRectifyUncalibratedStereo.rectify",
	"Comment": "rectifies the image using the provided fundamental matrix.both the fundamental matrix\tand set of inliers need to be accurate.small errors will cause large distortions.",
	"Method": "void rectify(DMatrixRMaj F,List<AssociatedPair> inliers,BufferedImage origLeft,BufferedImage origRight){\r\n    Planar<GrayF32> unrectLeft = ConvertBufferedImage.convertFromPlanar(origLeft, null, true, GrayF32.class);\r\n    Planar<GrayF32> unrectRight = ConvertBufferedImage.convertFromPlanar(origRight, null, true, GrayF32.class);\r\n    Planar<GrayF32> rectLeft = unrectLeft.createSameShape();\r\n    Planar<GrayF32> rectRight = unrectRight.createSameShape();\r\n    RectifyFundamental rectifyAlg = RectifyImageOps.createUncalibrated();\r\n    rectifyAlg.process(F, inliers, origLeft.getWidth(), origLeft.getHeight());\r\n    DMatrixRMaj rect1 = rectifyAlg.getRect1();\r\n    DMatrixRMaj rect2 = rectifyAlg.getRect2();\r\n    RectifyImageOps.fullViewLeft(origLeft.getWidth(), origLeft.getHeight(), rect1, rect2);\r\n    FMatrixRMaj rect1_F32 = new FMatrixRMaj(3, 3);\r\n    FMatrixRMaj rect2_F32 = new FMatrixRMaj(3, 3);\r\n    ConvertMatrixData.convert(rect1, rect1_F32);\r\n    ConvertMatrixData.convert(rect2, rect2_F32);\r\n    ImageDistort<GrayF32, GrayF32> imageDistortLeft = RectifyImageOps.rectifyImage(rect1_F32, BorderType.SKIP, GrayF32.class);\r\n    ImageDistort<GrayF32, GrayF32> imageDistortRight = RectifyImageOps.rectifyImage(rect2_F32, BorderType.SKIP, GrayF32.class);\r\n    DistortImageOps.distortPL(unrectLeft, rectLeft, imageDistortLeft);\r\n    DistortImageOps.distortPL(unrectRight, rectRight, imageDistortRight);\r\n    BufferedImage outLeft = ConvertBufferedImage.convertTo(rectLeft, null, true);\r\n    BufferedImage outRight = ConvertBufferedImage.convertTo(rectRight, null, true);\r\n    ShowImages.showWindow(new RectifiedPairPanel(true, outLeft, outRight), \"Rectified\");\r\n}"
}, {
	"Path": "boofcv.factory.feature.detect.line.FactoryDetectLineAlgs.houghPolar",
	"Comment": "creates a hough line detector based on polar parametrization.",
	"Method": "DetectLineHoughPolar<I, D> houghPolar(ConfigHoughPolar config,Class<I> imageType,Class<D> derivType){\r\n    if (config == null)\r\n        throw new IllegalArgumentException(\"This is no default since minCounts must be specified\");\r\n    ImageGradient<I, D> gradient = FactoryDerivative.sobel(imageType, derivType);\r\n    return new DetectLineHoughPolar(config.localMaxRadius, config.minCounts, config.resolutionRange, config.resolutionAngle, config.thresholdEdge, config.maxLines, gradient);\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernelGaussian.radiusForSigma",
	"Comment": "given the the sigma of a gaussian distribution and the order of its derivative, choose an appropriate radius.",
	"Method": "int radiusForSigma(double sigma,int order){\r\n    if (sigma <= 0)\r\n        throw new IllegalArgumentException(\"Sigma must be > 0\");\r\n    return (int) Math.ceil((((5 + 0.8 * order) * sigma) - 1) / 2);\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.fh04.SegmentFelzenszwalbHuttenlocher04.initialize",
	"Comment": "predeclares all memory required and sets data structures to their initial values",
	"Method": "void initialize(T input,GrayS32 output){\r\n    this.graph = output;\r\n    final int N = input.width * input.height;\r\n    regionSize.resize(N);\r\n    threshold.resize(N);\r\n    for (int i = 0; i < N; i++) {\r\n        regionSize.data[i] = 1;\r\n        threshold.data[i] = K;\r\n        graph.data[i] = i;\r\n    }\r\n    edges.reset();\r\n    edgesNotMatched.reset();\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.KeyPointsCircleRegularGrid.getKeyPoints",
	"Comment": "returns the location of each key point in the image from the most recently processed grid.",
	"Method": "FastQueue<Point2D_F64> getKeyPoints(){\r\n    return keypoints;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TestTldDetection.selectBestRegionsFern_larger",
	"Comment": "see if the case where there are more than the maximum number of regions is handled correctly",
	"Method": "void selectBestRegionsFern_larger(){\r\n    TldDetection<GrayU8> alg = new TldDetection();\r\n    alg.config = new TldParameters();\r\n    alg.config.maximumCascadeConsider = 20;\r\n    for (int i = 0; i < 30; i++) {\r\n        alg.fernInfo.grow();\r\n        alg.fernInfo.get(i).r = new ImageRectangle(i, i, i, i);\r\n        alg.fernInfo.get(i).sumP = 50 - i;\r\n        alg.fernInfo.get(i).sumN = 6;\r\n    }\r\n    alg.selectBestRegionsFern(200, 200);\r\n    assertEquals(20, alg.fernRegions.size());\r\n    for (int i = 0; i < 20; i++) {\r\n        assertTrue(alg.fernRegions.contains(alg.fernInfo.get(i).r));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonFromContour.touchesBorder",
	"Comment": "checks to see if some part of the contour touches the image border.most likely cropped",
	"Method": "boolean touchesBorder(List<Point2D_I32> contour){\r\n    int endX = imageWidth - 1;\r\n    int endY = imageHeight - 1;\r\n    for (int j = 0; j < contour.size(); j++) {\r\n        Point2D_I32 p = contour.get(j);\r\n        if (p.x == 0 || p.y == 0 || p.x == endX || p.y == endY) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.abst.filter.transform.fft.GenericTestDiscreteFourierTransform.format_even",
	"Comment": "see if the fourier transform is the expected one for even sizes images",
	"Method": "void format_even(){\r\n    T input = createImage(10, 1);\r\n    I transform = createTransform(10, 1);\r\n    GImageMiscOps.fillUniform(input, rand, -20, 20);\r\n    DiscreteFourierTransform<T, I> alg = createAlgorithm();\r\n    alg.forward(input, transform);\r\n    assertEquals(GeneralizedImageOps.get(transform, 4, 0, 0), GeneralizedImageOps.get(transform, 6, 0, 0), tolerance);\r\n    assertEquals(GeneralizedImageOps.get(transform, 4, 0, 1), -GeneralizedImageOps.get(transform, 6, 0, 1), tolerance);\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.BasicDisparitySelectRectTests.simpleTest",
	"Comment": "give it a hand crafted score with known results for wta.see if it produces those results",
	"Method": "void simpleTest(){\r\n    int y = 3;\r\n    GImageMiscOps.fill(disparity, 0);\r\n    alg.configure(disparity, 0, maxDisparity, 2);\r\n    int[] scores = new int[w * maxDisparity];\r\n    for (int d = 0; d < 10; d++) {\r\n        for (int x = 0; x < w; x++) {\r\n            scores[w * d + x] = Math.abs(d - 5);\r\n        }\r\n    }\r\n    ArrayData s = copyToCorrectType(scores);\r\n    alg.process(y, s);\r\n    assertEquals(0, GeneralizedImageOps.get(disparity, 0, y), 1e-8);\r\n    assertEquals(0, GeneralizedImageOps.get(disparity, 1, y), 1e-8);\r\n    assertEquals(0, GeneralizedImageOps.get(disparity, w - 2, y), 1e-8);\r\n    assertEquals(0, GeneralizedImageOps.get(disparity, w - 1, y), 1e-8);\r\n    for (int i = 0; i < 5; i++) assertEquals(i, GeneralizedImageOps.get(disparity, i + 2, y), 1e-8);\r\n    for (int i = 5; i < w - 4; i++) assertEquals(5, GeneralizedImageOps.get(disparity, i + 2, y), 1e-8);\r\n}"
}, {
	"Path": "boofcv.android.camera2.SimpleCamera2Activity.isCameraReadyReconfiguration",
	"Comment": "is the camera ready to change configurations again after the last requeset?",
	"Method": "boolean isCameraReadyReconfiguration(){\r\n    try {\r\n        open.mLock.lock();\r\n        return mPreviewSession != null;\r\n    } finally {\r\n        open.mLock.unlock();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestRemovePerspectiveDistortion.identity",
	"Comment": "the transform should not scale and produce a simple transform from input to output",
	"Method": "void identity(){\r\n    RemovePerspectiveDistortion<GrayF32> alg = new RemovePerspectiveDistortion(30, 40, ImageType.single(GrayF32.class));\r\n    alg.createTransform(new Point2D_F64(20, 30), new Point2D_F64(50, 30), new Point2D_F64(50, 70), new Point2D_F64(20, 70));\r\n    Point2D_F32 p = new Point2D_F32();\r\n    PointTransformHomography_F32 transform = alg.getTransform();\r\n    transform.compute(0, 0, p);\r\n    assertTrue(p.distance(20, 30) < UtilEjml.TEST_F64);\r\n    transform.compute(30, 40, p);\r\n    assertTrue(p.distance(50, 70) < UtilEjml.TEST_F64);\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.DescribeDenseHogAlg.addToHistogram",
	"Comment": "adds the magnitude to the histogram at the specified cell and orientation",
	"Method": "void addToHistogram(int cellX,int cellY,int orientationIndex,double magnitude){\r\n    if (cellX < 0 || cellX >= cellsPerBlockX)\r\n        return;\r\n    if (cellY < 0 || cellY >= cellsPerBlockY)\r\n        return;\r\n    int index = (cellY * cellsPerBlockX + cellX) * orientationBins + orientationIndex;\r\n    histogram[index] += magnitude;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquaresIntoRegularClusters.disconnectSingleConnections",
	"Comment": "nodes that have only a single connection to one other node are disconnected since they are likely to be noise.\tthis is done recursively",
	"Method": "void disconnectSingleConnections(){\r\n    List<SquareNode> open = new ArrayList();\r\n    List<SquareNode> open2 = new ArrayList();\r\n    for (int i = 0; i < nodes.size(); i++) {\r\n        SquareNode n = nodes.get(i);\r\n        checkDisconnectSingleEdge(open, n);\r\n    }\r\n    while (!open.isEmpty()) {\r\n        for (int i = 0; i < open.size(); i++) {\r\n            SquareNode n = open.get(i);\r\n            checkDisconnectSingleEdge(open2, n);\r\n            open.clear();\r\n            List<SquareNode> tmp = open;\r\n            open = open2;\r\n            open2 = tmp;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setMaxConnectionsPerPartition",
	"Comment": "sets the maximum number of connections that will be contained in every partition. \tsetting this to 5 with 3 partitions means you will have 15 unique connections to the database. \tnote that the connection pool will not create all these connections in one go but rather start off \twith minconnectionsperpartition and gradually increase connections as required.",
	"Method": "void setMaxConnectionsPerPartition(int maxConnectionsPerPartition){\r\n    this.maxConnectionsPerPartition = maxConnectionsPerPartition;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoPlaneInfinity.estimateFar",
	"Comment": "estimates only rotation using points at infinity.a robust estimation algorithm is used which finds an angle\twhich maximizes the inlier set, like ransac does.unlike ransac this will produce an optimal result.",
	"Method": "void estimateFar(){\r\n    farInlierCount = 0;\r\n    if (farAngles.size == 0)\r\n        return;\r\n    farAnglesCopy.reset();\r\n    farAnglesCopy.addAll(farAngles);\r\n    farAngle = maximizeCountInSpread(farAnglesCopy.data, farAngles.size, 2 * thresholdFarAngleError);\r\n    for (int i = 0; i < tracksFar.size(); i++) {\r\n        PointTrack t = tracksFar.get(i);\r\n        VoTrack p = t.getCookie();\r\n        if (UtilAngle.dist(farAngles.get(i), farAngle) <= thresholdFarAngleError) {\r\n            p.lastInlier = tick;\r\n            farInlierCount++;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.grid.DetectSquareGridFiducial.extractCalibrationPoints",
	"Comment": "extracts the calibration points from the corners of a fully ordered grid",
	"Method": "void extractCalibrationPoints(SquareGrid grid){\r\n    calibrationPoints.clear();\r\n    for (int row = 0; row < grid.rows; row++) {\r\n        row0.clear();\r\n        row1.clear();\r\n        for (int col = 0; col < grid.columns; col++) {\r\n            Polygon2D_F64 square = grid.get(row, col).square;\r\n            row0.add(square.get(0));\r\n            row0.add(square.get(1));\r\n            row1.add(square.get(3));\r\n            row1.add(square.get(2));\r\n        }\r\n        calibrationPoints.addAll(row0);\r\n        calibrationPoints.addAll(row1);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestLensDistortionOps.transformChangeModel_F32_EXPAND_modified",
	"Comment": "sees if the adjusted intrinsic parameters is correct but computing normalized image coordinates first\twith the original distorted image and then with the adjusted undistorted image.",
	"Method": "void transformChangeModel_F32_EXPAND_modified(){\r\n    float pixelX = 12.5f, pixelY = height - 3;\r\n    CameraPinholeRadial orig = new CameraPinholeRadial().fsetK(300, 320, 0, 150, 130, width, height).fsetRadial(0.1, 0.05);\r\n    CameraPinhole desired = new CameraPinhole(orig);\r\n    Point2Transform2_F32 distToNorm = LensDistortionOps.narrow(orig).undistort_F32(true, false);\r\n    Point2D_F32 norm = new Point2D_F32();\r\n    distToNorm.compute(pixelX, pixelY, norm);\r\n    CameraPinholeRadial adjusted = new CameraPinholeRadial();\r\n    Point2Transform2_F32 distToAdj = LensDistortionOps.transformChangeModel_F32(AdjustmentType.EXPAND, orig, desired, false, adjusted);\r\n    Point2D_F32 adjPixel = new Point2D_F32();\r\n    Point2D_F32 normFound = new Point2D_F32();\r\n    distToAdj.compute(pixelX, pixelY, adjPixel);\r\n    PerspectiveOps.convertPixelToNorm(adjusted, adjPixel, normFound);\r\n    assertEquals(norm.x, normFound.x, 1e-3);\r\n    assertEquals(norm.y, normFound.y, 1e-3);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.TestQrCodeEncoder.alphanumeric_specification",
	"Comment": "compare only the data portion against an example from the specification",
	"Method": "void alphanumeric_specification(){\r\n    QrCodeEncoder encoder = new QrCodeEncoder();\r\n    encoder.setVersion(1).setError(QrCode.ErrorLevel.H).setMask(new QrCodeMaskPattern.NONE(0b011)).addAlphanumeric(\"AC-42\").fixate();\r\n    byte[] expected = new byte[] { 0b00100000, 0b00101001, (byte) 0b11001110, (byte) 0b11100111, 0b00100001, 0 };\r\n    QrCodeEncoder.flipBits8(expected, expected.length);\r\n    assertEquals(encoder.packed.size / 8, expected.length);\r\n    for (int i = 0; i < expected.length; i++) {\r\n        assertEquals(expected[i], encoder.packed.data[i]);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.TestSquareCrossClustersIntoGrids.createCluster",
	"Comment": "creates a new two row graph.skip indicates if the first row skips the first column or not.the\tother two parameters specify how many nodes in each row",
	"Method": "List<SquareNode> createCluster(boolean skip,int levels){\r\n    int total = 0;\r\n    for (int i = 0; i < levels.length; i++) {\r\n        total += levels[i];\r\n    }\r\n    List<SquareNode> out = new ArrayList();\r\n    for (int i = 0; i < total; i++) {\r\n        out.add(new SquareNode());\r\n        out.get(i).graph = SquareNode.RESET_GRAPH;\r\n        out.get(i).square = new Polygon2D_F64(4);\r\n    }\r\n    int previous = 0;\r\n    for (int i = 0; i < levels.length - 1; i++) {\r\n        int current = previous + levels[i];\r\n        int next = current + levels[i + 1];\r\n        for (int a = 0; a < levels[i]; a++) {\r\n            SquareNode n = out.get(previous + a);\r\n            int right = skip ? current + a + 1 : current + a;\r\n            int left = right - 1;\r\n            if (right < next)\r\n                connect(n, 2, out.get(right), 0);\r\n            if (left >= current) {\r\n                connect(n, 3, out.get(left), 1);\r\n            }\r\n        }\r\n        previous = current;\r\n        skip = !skip;\r\n    }\r\n    return out;\r\n}"
}, {
	"Path": "boofcv.abst.distort.FDistort.input",
	"Comment": "changes the input image.the previous distortion is thrown away only if the input\timage has a different shape",
	"Method": "FDistort input(ImageBase input){\r\n    if (this.input == null || this.input.width != input.width || this.input.height != input.height) {\r\n        distorter = null;\r\n    }\r\n    this.input = input;\r\n    inputType = input.getImageType();\r\n    return this;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionThreadTester.testConnectionMarkedBroken",
	"Comment": "tests that a connection that is marked broken is closed internally and that the partition is marked as being \table to create new connections.",
	"Method": "void testConnectionMarkedBroken(){\r\n    BlockingQueue<ConnectionHandle> fakeFreeConnections = new LinkedBlockingQueue<ConnectionHandle>(100);\r\n    fakeFreeConnections.add(mockConnection);\r\n    BoneCPConfig localconfig = config.clone();\r\n    expect(mockPool.getConfig()).andReturn(localconfig).anyTimes();\r\n    expect(mockConnectionPartition.getAvailableConnections()).andReturn(1).anyTimes();\r\n    expect(mockConnectionPartition.getFreeConnections()).andReturn(fakeFreeConnections).anyTimes();\r\n    expect(mockConnection.isPossiblyBroken()).andReturn(true);\r\n    mockConnection.internalClose();\r\n    mockPool.postDestroyConnection(mockConnection);\r\n    expectLastCall().once();\r\n    replay(mockPool, mockConnection, mockConnectionPartition, mockExecutor);\r\n    this.testClass = new ConnectionTesterThread(mockConnectionPartition, mockExecutor, mockPool, localconfig.getIdleMaxAgeInMinutes(), localconfig.getIdleConnectionTestPeriodInMinutes(), false);\r\n    this.testClass.run();\r\n    verify(mockPool, mockConnectionPartition, mockExecutor, mockConnection);\r\n}"
}, {
	"Path": "org.boon.sort.Ordering.search",
	"Comment": "does a binary searchnote this will not sort the list ascending.",
	"Method": "T search(List<T> list,T item){\r\n    if (list.size() > 1) {\r\n        Object o = list;\r\n        int index = Collections.binarySearch((List<? extends Comparable<? super T>>) o, item);\r\n        return list.get(index);\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "org.bimserver.utils.SpringUtilities.makeGrid",
	"Comment": "aligns the first rowscolscomponents of parent ina grid. each component is as big as the maximumpreferred width and height of the components.the parent is made just big enough to fit them all.",
	"Method": "void makeGrid(Container parent,int rows,int cols,int initialX,int initialY,int xPad,int yPad){\r\n    SpringLayout layout;\r\n    try {\r\n        layout = (SpringLayout) parent.getLayout();\r\n    } catch (ClassCastException exc) {\r\n        System.err.println(\"The first argument to makeGrid must use SpringLayout.\");\r\n        return;\r\n    }\r\n    Spring xPadSpring = Spring.constant(xPad);\r\n    Spring yPadSpring = Spring.constant(yPad);\r\n    Spring initialXSpring = Spring.constant(initialX);\r\n    Spring initialYSpring = Spring.constant(initialY);\r\n    int max = rows * cols;\r\n    Spring maxWidthSpring = layout.getConstraints(parent.getComponent(0)).getWidth();\r\n    Spring maxHeightSpring = layout.getConstraints(parent.getComponent(0)).getWidth();\r\n    for (int i = 1; i < max; i++) {\r\n        SpringLayout.Constraints cons = layout.getConstraints(parent.getComponent(i));\r\n        maxWidthSpring = Spring.max(maxWidthSpring, cons.getWidth());\r\n        maxHeightSpring = Spring.max(maxHeightSpring, cons.getHeight());\r\n    }\r\n    for (int i = 0; i < max; i++) {\r\n        SpringLayout.Constraints cons = layout.getConstraints(parent.getComponent(i));\r\n        cons.setWidth(maxWidthSpring);\r\n        cons.setHeight(maxHeightSpring);\r\n    }\r\n    SpringLayout.Constraints lastCons = null;\r\n    SpringLayout.Constraints lastRowCons = null;\r\n    for (int i = 0; i < max; i++) {\r\n        SpringLayout.Constraints cons = layout.getConstraints(parent.getComponent(i));\r\n        if (i % cols == 0) {\r\n            lastRowCons = lastCons;\r\n            cons.setX(initialXSpring);\r\n        } else {\r\n            cons.setX(Spring.sum(lastCons.getConstraint(SpringLayout.EAST), xPadSpring));\r\n        }\r\n        if (i / cols == 0) {\r\n            cons.setY(initialYSpring);\r\n        } else {\r\n            cons.setY(Spring.sum(lastRowCons.getConstraint(SpringLayout.SOUTH), yPadSpring));\r\n        }\r\n        lastCons = cons;\r\n    }\r\n    SpringLayout.Constraints pCons = layout.getConstraints(parent);\r\n    pCons.setConstraint(SpringLayout.SOUTH, Spring.sum(Spring.constant(yPad), lastCons.getConstraint(SpringLayout.SOUTH)));\r\n    pCons.setConstraint(SpringLayout.EAST, Spring.sum(Spring.constant(xPad), lastCons.getConstraint(SpringLayout.EAST)));\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.BaseDetectFiducialSquare.checkSideSize",
	"Comment": "sanity check the polygon based on the size of its sides to see if it could be a fiducial that can\tbe decoded",
	"Method": "boolean checkSideSize(Polygon2D_F64 p){\r\n    double max = 0, min = Double.MAX_VALUE;\r\n    for (int i = 0; i < p.size(); i++) {\r\n        double l = p.getSideLength(i);\r\n        max = Math.max(max, l);\r\n        min = Math.min(min, l);\r\n    }\r\n    if (min < 10)\r\n        return false;\r\n    return !(min / max < thresholdSideRatio);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.direct.TestVisOdomDirectColorDepth.singleStepArtificialTranslation",
	"Comment": "generate low level synthetic data that should simulate a translation along one axis.then check to see if\thas the expected behavior at a high level",
	"Method": "void singleStepArtificialTranslation(){\r\n    Se3_F32 a = computeMotion(10, 20, 6, 0);\r\n    assertTrue(a.T.x < -0.02);\r\n    assertEquals(0, a.T.y, 1e-2f);\r\n    assertEquals(0, a.T.z, 1e-2f);\r\n    assertTrue(rotationMag(a) < GrlConstants.TEST_SQ_F64);\r\n    Se3_F32 b = computeMotion(20, 10, 6, 0);\r\n    assertTrue(b.T.x > 0.02);\r\n    assertEquals(0, b.T.y, 1e-2f);\r\n    assertEquals(0, b.T.z, 1e-2f);\r\n    assertTrue(rotationMag(b) < GrlConstants.TEST_SQ_F64);\r\n    assertEquals(a.T.x, -b.T.x, 1e-4f);\r\n    Se3_F32 c = computeMotion(10, 20, 0, 6);\r\n    assertEquals(0, c.T.x, 1e-2f);\r\n    assertTrue(c.T.y < -0.02);\r\n    assertEquals(0, c.T.z, 1e-2f);\r\n    assertTrue(rotationMag(c) < GrlConstants.TEST_SQ_F64);\r\n    assertEquals(a.T.x, c.T.y, 0.01);\r\n    Se3_F32 d = computeMotion(10, 20, 3, 0);\r\n    assertTrue(1.5f * Math.abs(a.T.x) < Math.abs(d.T.x));\r\n}"
}, {
	"Path": "com.gazbert.bxbot.exchanges.AbstractExchangeAdapter.getOptionalConfigItem",
	"Comment": "fetches an optional config item value from the adapter config.",
	"Method": "String getOptionalConfigItem(OptionalConfig optionalConfig,String itemName){\r\n    final String itemValue = optionalConfig.getItem(itemName);\r\n    LOG.info(() -> itemName + \": \" + itemValue);\r\n    return assertItemExists(itemName, itemValue);\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedS32.setBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "void setBand(int x,int y,int band,int value){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    data[getIndex(x, y, band)] = value;\r\n}"
}, {
	"Path": "boofcv.alg.filter.misc.TestAverageDownSampleOps.down_2inputs",
	"Comment": "down sample with just two inputs.compare to results from raw implementation.",
	"Method": "void down_2inputs(){\r\n    Class[] input = new Class[] { GrayU8.class, GrayU16.class, GrayF32.class, GrayF64.class };\r\n    Class[] middle = new Class[] { GrayF32.class, GrayF32.class, GrayF32.class, GrayF64.class };\r\n    for (int i = 0; i < input.length; i++) {\r\n        ImageGray in = GeneralizedImageOps.createSingleBand(input[i], 17, 14);\r\n        ImageGray mid = GeneralizedImageOps.createSingleBand(middle[i], 3, 14);\r\n        ImageGray found = GeneralizedImageOps.createSingleBand(input[i], 3, 4);\r\n        ImageGray expected = GeneralizedImageOps.createSingleBand(input[i], 3, 4);\r\n        GImageMiscOps.fillUniform(in, rand, 0, 100);\r\n        Method horizontal = ImplAverageDownSample.class.getDeclaredMethod(\"horizontal\", input[i], middle[i]);\r\n        Method vertical = BoofTesting.findMethod(ImplAverageDownSample.class, \"vertical\", middle[i], input[i]);\r\n        horizontal.invoke(null, in, mid);\r\n        vertical.invoke(null, mid, expected);\r\n        AverageDownSampleOps.down(in, found);\r\n        BoofTesting.assertEquals(expected, found, 1e-4);\r\n    }\r\n}"
}, {
	"Path": "org.boon.datarepo.impl.RepoBuilderDefault.cloneEdits",
	"Comment": "clones the object in the repo before editing and alsoclones returns values.this should limit two threads from getting the same object that is inthe repo.",
	"Method": "RepoBuilder cloneEdits(boolean cloneEdits){\r\n    this.cloneEdits = cloneEdits;\r\n    return this;\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernelGaussian.sigmaForRadius",
	"Comment": "given the the radius of a gaussian distribution and the order of its derivative, choose an appropriate sigma.",
	"Method": "double sigmaForRadius(double radius,int order){\r\n    if (radius <= 0)\r\n        throw new IllegalArgumentException(\"Radius must be > 0\");\r\n    return (radius * 2.0 + 1.0) / (5.0 + 0.8 * order);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.isTransactionRecoveryEnabled",
	"Comment": "returns true if the pool is configured to record all transaction activity and replay the transaction automatically in case\tof connection failures.",
	"Method": "boolean isTransactionRecoveryEnabled(){\r\n    return this.transactionRecoveryEnabled;\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedS64.setBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "void setBand(int x,int y,int band,long value){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    data[getIndex(x, y, band)] = value;\r\n}"
}, {
	"Path": "io.buji.pac4j.realm.Pac4jRealm.getPrincipalNameAttribute",
	"Comment": "returns the name of the attribute from commonprofile that will be used asthe value for the principal name.",
	"Method": "String getPrincipalNameAttribute(){\r\n    return principalNameAttribute;\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapperSimple.toMap",
	"Comment": "this could be refactored to use core.typetype class and it would run faster.converts an object into a map",
	"Method": "Map<String, Object> toMap(Object object){\r\n    if (object == null) {\r\n        return null;\r\n    }\r\n    if (object instanceof Map) {\r\n        return (Map<String, Object>) object;\r\n    }\r\n    Map<String, Object> map = new LinkedHashMap();\r\n    final Map<String, FieldAccess> fieldMap = Reflection.getAllAccessorFields(object.getClass());\r\n    List<FieldAccess> fields = new ArrayList(fieldMap.values());\r\n    Collections.reverse(fields);\r\n    for (FieldAccess access : fields) {\r\n        String fieldName = access.name();\r\n        if (access.isStatic()) {\r\n            continue;\r\n        }\r\n        Object value = access.getValue(object);\r\n        if (value == null) {\r\n            continue;\r\n        }\r\n        switch(access.typeEnum()) {\r\n            case BYTE:\r\n            case BYTE_WRAPPER:\r\n            case SHORT:\r\n            case SHORT_WRAPPER:\r\n            case INT:\r\n            case INTEGER_WRAPPER:\r\n            case LONG:\r\n            case LONG_WRAPPER:\r\n            case FLOAT:\r\n            case FLOAT_WRAPPER:\r\n            case DOUBLE:\r\n            case DOUBLE_WRAPPER:\r\n            case CHAR:\r\n            case CHAR_WRAPPER:\r\n            case BIG_DECIMAL:\r\n            case BIG_INT:\r\n            case BOOLEAN:\r\n            case BOOLEAN_WRAPPER:\r\n            case CURRENCY:\r\n            case CALENDAR:\r\n            case DATE:\r\n                map.put(fieldName, value);\r\n                break;\r\n            case ARRAY:\r\n            case ARRAY_INT:\r\n            case ARRAY_BYTE:\r\n            case ARRAY_SHORT:\r\n            case ARRAY_FLOAT:\r\n            case ARRAY_DOUBLE:\r\n            case ARRAY_LONG:\r\n            case ARRAY_STRING:\r\n            case ARRAY_OBJECT:\r\n                if (Typ.isBasicType(access.getComponentClass())) {\r\n                    map.put(fieldName, value);\r\n                } else {\r\n                    int length = Arry.len(value);\r\n                    List<Map<String, Object>> list = new ArrayList(length);\r\n                    for (int index = 0; index < length; index++) {\r\n                        Object item = Arry.fastIndex(value, index);\r\n                        list.add(toMap(item));\r\n                    }\r\n                    map.put(fieldName, list);\r\n                }\r\n                break;\r\n            case COLLECTION:\r\n            case LIST:\r\n            case SET:\r\n                Collection<?> collection = (Collection<?>) value;\r\n                Class<?> componentType = access.getComponentClass();\r\n                if (Typ.isBasicType(componentType)) {\r\n                    map.put(fieldName, value);\r\n                } else if (Typ.isEnum(componentType)) {\r\n                    List<String> list = new ArrayList(collection.size());\r\n                    for (Object item : collection) {\r\n                        if (item != null) {\r\n                            list.add(item.toString());\r\n                        }\r\n                    }\r\n                    map.put(fieldName, list);\r\n                } else {\r\n                    List<Map<String, Object>> list = new ArrayList(collection.size());\r\n                    for (Object item : collection) {\r\n                        if (item != null) {\r\n                            list.add(toMap(item));\r\n                        }\r\n                    }\r\n                    map.put(fieldName, list);\r\n                }\r\n                break;\r\n            case MAP:\r\n                map.put(fieldName, value);\r\n                break;\r\n            case INSTANCE:\r\n                map.put(fieldName, toMap(value));\r\n                break;\r\n            case INTERFACE:\r\n            case ABSTRACT:\r\n                final Map<String, Object> abstractMap = toMap(value);\r\n                abstractMap.put(\"class\", Boon.className(value));\r\n                map.put(fieldName, abstractMap);\r\n                break;\r\n            case ENUM:\r\n                map.put(fieldName, value);\r\n                break;\r\n            default:\r\n                map.put(fieldName, Conversions.toString(value));\r\n                break;\r\n        }\r\n    }\r\n    return map;\r\n}"
}, {
	"Path": "boofcv.deepboof.CheckBaseImageClassifier.checkForBlowUp",
	"Comment": "basic test which sees if it blows up.does not validate quality of results since a fake network\tis provided.regression test is required to validate correctness.\tthe real network is not used because it requires downloading external data and can be slow.",
	"Method": "void checkForBlowUp(){\r\n    Planar<GrayF32> input = createImage();\r\n    GImageMiscOps.fillUniform(input, rand, 0, 255);\r\n    BaseImageClassifier classifier = createClassifier();\r\n    createDummyNetwork(classifier, input.width, input.height);\r\n    classifier.classify(input);\r\n    int best = classifier.getBestResult();\r\n    assertTrue(best >= 0 && best < numCategories);\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.TestAssociateStereo2D.positive",
	"Comment": "very simple positive case with only a perfect observation and descriptor",
	"Method": "void positive(){\r\n    Point3D_F64 X = new Point3D_F64(0.02, -0.5, 3);\r\n    SfmTestHelper.renderPointPixel(param, X, leftP, rightP);\r\n    pointsLeft.grow().set(leftP);\r\n    pointsRight.grow().set(rightP);\r\n    descLeft.grow();\r\n    descRight.grow();\r\n    AssociateStereo2D<TupleDesc_F64> alg = new AssociateStereo2D(scorer, 0.5, TupleDesc_F64.class);\r\n    alg.setCalibration(param);\r\n    alg.setSource(pointsLeft, descLeft);\r\n    alg.setDestination(pointsRight, descRight);\r\n    alg.associate();\r\n    FastQueue<AssociatedIndex> matches = alg.getMatches();\r\n    assertEquals(1, matches.size);\r\n}"
}, {
	"Path": "boofcv.alg.geo.TestDecomposeEssential.checkUnique",
	"Comment": "makes sure each solution returned is unique by transforming a point.",
	"Method": "void checkUnique(List<Se3_F64> solutions){\r\n    Point3D_F64 orig = new Point3D_F64(1, 2, 3);\r\n    for (int i = 0; i < solutions.size(); i++) {\r\n        Point3D_F64 found = SePointOps_F64.transform(solutions.get(i), orig, null);\r\n        for (int j = i + 1; j < solutions.size(); j++) {\r\n            Point3D_F64 alt = SePointOps_F64.transform(solutions.get(j), orig, null);\r\n            GeometryUnitTest.assertNotEquals(found, alt, 1e-4);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setTransactionRecoveryEnabled",
	"Comment": "set to true to enable recording of all transaction activity and replay the transaction automatically in case\tof a connection failure.",
	"Method": "void setTransactionRecoveryEnabled(boolean transactionRecoveryEnabled){\r\n    this.transactionRecoveryEnabled = transactionRecoveryEnabled;\r\n}"
}, {
	"Path": "boofcv.alg.descriptor.ExperimentalDescriptorDistance.hamming",
	"Comment": "computes the hamming distance between two binary feature descriptors",
	"Method": "int hamming(TupleDesc_B a,TupleDesc_B b,int hamming,int val){\r\n    int distance = 0;\r\n    while (val != 0) {\r\n        val &= val - 1;\r\n        distance++;\r\n    }\r\n    return distance;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.windows.PokemonTab.removeSelection",
	"Comment": "helper method to remove the pokemon from the selectedrowslist.",
	"Method": "void removeSelection(Pokemon p){\r\n    final PokemonTableModel model = (PokemonTableModel) pt.getModel();\r\n    final int index = model.getIndexByPokemon(p);\r\n    if (index > 0 && selectedRowsList != null) {\r\n        selectedRowsList.remove(index);\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.convolve.Kernel1D_F32.wrap",
	"Comment": "creates a kernel whose elements are the specified data array and has\tthe specified width.",
	"Method": "Kernel1D_F32 wrap(float data,int width,int offset){\r\n    Kernel1D_F32 ret = new Kernel1D_F32();\r\n    ret.data = data;\r\n    ret.width = width;\r\n    ret.offset = offset;\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.android.camera2.SimpleCamera2Activity.startCameraTexture",
	"Comment": "after this function is called the camera will be start. it might not start immediately\tand there can be a delay.",
	"Method": "void startCameraTexture(TextureView view){\r\n    if (verbose)\r\n        Log.i(TAG, \"startCamera(TextureView=\" + (view != null) + \")\");\r\n    this.mTextureView = view;\r\n    this.mView = null;\r\n    this.mTextureView.setSurfaceTextureListener(mSurfaceTextureListener);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldDetection.computeTemplateConfidence",
	"Comment": "computes the confidence for all the regions which pass the fern test",
	"Method": "void computeTemplateConfidence(){\r\n    double max = 0;\r\n    for (int i = 0; i < fernRegions.size(); i++) {\r\n        ImageRectangle region = fernRegions.get(i);\r\n        double confidence = template.computeConfidence(region);\r\n        max = Math.max(max, confidence);\r\n        if (confidence < config.confidenceThresholdUpper)\r\n            continue;\r\n        TldRegion r = candidateDetections.grow();\r\n        r.connections = 0;\r\n        r.rect.set(region);\r\n        r.confidence = confidence;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldTemplateMatching.computeNccDescriptor",
	"Comment": "computes the ncc descriptor by sample points at evenly spaced distances inside the rectangle",
	"Method": "void computeNccDescriptor(NccFeature f,float x0,float y0,float x1,float y1){\r\n    double mean = 0;\r\n    float widthStep = (x1 - x0) / 15.0f;\r\n    float heightStep = (y1 - y0) / 15.0f;\r\n    int index = 0;\r\n    for (int y = 0; y < 15; y++) {\r\n        float sampleY = y0 + y * heightStep;\r\n        for (int x = 0; x < 15; x++) {\r\n            mean += f.value[index++] = interpolate.get_fast(x0 + x * widthStep, sampleY);\r\n        }\r\n    }\r\n    mean /= 15 * 15;\r\n    double variance = 0;\r\n    index = 0;\r\n    for (int y = 0; y < 15; y++) {\r\n        for (int x = 0; x < 15; x++) {\r\n            double v = f.value[index++] -= mean;\r\n            variance += v * v;\r\n        }\r\n    }\r\n    variance /= 15 * 15;\r\n    f.mean = mean;\r\n    f.sigma = Math.sqrt(variance);\r\n}"
}, {
	"Path": "com.bugsnag.android.SessionTracker.onAutoCaptureEnabled",
	"Comment": "track a new session when auto capture is enabled via config after initialisation.",
	"Method": "void onAutoCaptureEnabled(){\r\n    Session session = currentSession.get();\r\n    if (session != null && !foregroundActivities.isEmpty()) {\r\n        trackSessionIfNeeded(session);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.triangulate.TestTriangulateProjectiveLinearDLT.triangulate_metric_N",
	"Comment": "create 3 perfect observations and solve for the position. everything is in metric instead of an arbtirary\tprojective frame for ease of testing.",
	"Method": "void triangulate_metric_N(){\r\n    createScene();\r\n    TriangulateProjectiveLinearDLT alg = new TriangulateProjectiveLinearDLT();\r\n    Point4D_F64 found = new Point4D_F64();\r\n    alg.triangulate(obsPts, metricToProjective(motionWorldToCamera), found);\r\n    found.x /= found.w;\r\n    found.y /= found.w;\r\n    found.z /= found.w;\r\n    assertEquals(worldPoint.x, found.x, 1e-8);\r\n    assertEquals(worldPoint.y, found.y, 1e-8);\r\n    assertEquals(worldPoint.z, found.z, 1e-8);\r\n}"
}, {
	"Path": "com.gazbert.bxbot.core.engine.TestTradingEngine.testEngineExecutesNextTradeCyclesAfterReceivingExchangeNetworkException",
	"Comment": "tests the engine continues to execute next trade cycle if it receives a exchangenetworkexception.scenario is 1 successful trade cycle, 2nd cycle exchange adapter throws exchangenetworkexception, engine stays alive andsuccessfully executes subsequent trade cycles.",
	"Method": "void testEngineExecutesNextTradeCyclesAfterReceivingExchangeNetworkException(){\r\n    setupConfigLoadingExpectations();\r\n    final String exceptionErrorMsg = \"Man walks down the street in a hat like that, you know he's not afraid of anything...\";\r\n    final int numberOfTradeCycles = 3;\r\n    final BalanceInfo balanceInfo = PowerMock.createMock(BalanceInfo.class);\r\n    final Map<String, BigDecimal> balancesAvailable = new HashMap();\r\n    balancesAvailable.put(ENGINE_EMERGENCY_STOP_CURRENCY, new BigDecimal(\"0.5\"));\r\n    expect(exchangeAdapter.getBalanceInfo()).andReturn(balanceInfo);\r\n    expect(balanceInfo.getBalancesAvailable()).andReturn(balancesAvailable);\r\n    tradingStrategy.execute();\r\n    expect(exchangeAdapter.getBalanceInfo()).andThrow(new ExchangeNetworkException(exceptionErrorMsg));\r\n    expect(exchangeAdapter.getBalanceInfo()).andReturn(balanceInfo).atLeastOnce();\r\n    expect(balanceInfo.getBalancesAvailable()).andReturn(balancesAvailable).atLeastOnce();\r\n    tradingStrategy.execute();\r\n    expectLastCall().atLeastOnce();\r\n    PowerMock.replayAll();\r\n    final TradingEngine tradingEngine = new TradingEngine(exchangeConfigService, engineConfigService, strategyConfigService, marketConfigService, emailAlerter);\r\n    final Executor executor = Executors.newSingleThreadExecutor();\r\n    executor.execute(tradingEngine::start);\r\n    Thread.sleep(numberOfTradeCycles * STATE_CHANGE_WAIT_INTERVAL_IN_SECS * 1000);\r\n    waitForEngineStateChange(tradingEngine, EngineState.RUNNING, NUMBER_OF_TRADE_CYCLES);\r\n    assertTrue(tradingEngine.isRunning());\r\n    tradingEngine.shutdown();\r\n    waitForEngineStateChange(tradingEngine, EngineState.SHUTDOWN, NUMBER_OF_TRADE_CYCLES);\r\n    assertFalse(tradingEngine.isRunning());\r\n    PowerMock.verifyAll();\r\n}"
}, {
	"Path": "com.bugsnag.android.Exceptions.getExceptionName",
	"Comment": "get the class name from the exception contained in this error report.",
	"Method": "String getExceptionName(Throwable throwable){\r\n    if (throwable instanceof BugsnagException) {\r\n        return ((BugsnagException) throwable).getName();\r\n    } else {\r\n        return throwable.getClass().getName();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.TrackerMeanShiftLikelihood.updatePdfImage",
	"Comment": "computes the pdf only inside the image as needed amd update the dirty rectangle",
	"Method": "void updatePdfImage(int x0,int y0,int x1,int y1){\r\n    for (int y = y0; y < y1; y++) {\r\n        int indexOut = pdf.startIndex + pdf.stride * y + x0;\r\n        for (int x = x0; x < x1; x++, indexOut++) {\r\n            if (pdf.data[indexOut] < 0)\r\n                pdf.data[indexOut] = targetModel.compute(x, y);\r\n        }\r\n    }\r\n    if (dirty.x0 > x0)\r\n        dirty.x0 = x0;\r\n    if (dirty.y0 > y0)\r\n        dirty.y0 = y0;\r\n    if (dirty.x1 < x1)\r\n        dirty.x1 = x1;\r\n    if (dirty.y1 < y1)\r\n        dirty.y1 = y1;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonBinaryGrayRefine.setLensDistortion",
	"Comment": "specifies transforms which can be used to change coordinates from distorted to undistorted and the opposite\tcoordinates.the undistorted image is never explicitly created.",
	"Method": "void setLensDistortion(int width,int height,PixelTransform2_F32 distToUndist,PixelTransform2_F32 undistToDist){\r\n    detector.setLensDistortion(width, height, distToUndist, undistToDist);\r\n    if (refineGray != null)\r\n        refineGray.setLensDistortion(width, height, distToUndist, undistToDist);\r\n    edgeIntensity.setTransform(undistToDist);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.ConfigNew.getInt",
	"Comment": "returns the int for given key. the one in the config, or if it does not exist, the given default value.",
	"Method": "int getInt(ConfigKey configKey,int getInt,ConfigKey configKey,int defaultValue){\r\n    try {\r\n        final FindResult res = findNode(configKey.keyName, true);\r\n        return res.getNode().getInt(res.getName());\r\n    } catch (final JSONException ignored) {\r\n        setInt(configKey, defaultValue);\r\n        return defaultValue;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquaresIntoRegularClusters.areMiddlePointsClose",
	"Comment": "returns true if point p1 and p2 are close to the line defined by points p0 and p3.",
	"Method": "boolean areMiddlePointsClose(Point2D_F64 p0,Point2D_F64 p1,Point2D_F64 p2,Point2D_F64 p3){\r\n    UtilLine2D_F64.convert(p0, p3, line);\r\n    double tol1 = p0.distance(p1) * distanceTol;\r\n    if (Distance2D_F64.distance(line, p1) > tol1)\r\n        return false;\r\n    double tol2 = p2.distance(p3) * distanceTol;\r\n    if (Distance2D_F64.distance(lineB, p2) > tol2)\r\n        return false;\r\n    UtilLine2D_F64.convert(p0, p1, line);\r\n    if (Distance2D_F64.distance(line, p2) > tol2)\r\n        return false;\r\n    UtilLine2D_F64.convert(p3, p2, line);\r\n    if (Distance2D_F64.distance(line, p1) > tol1)\r\n        return false;\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.deepboof.BaseImageClassifier.preprocess",
	"Comment": "massage the input image into a format recognized by the network",
	"Method": "Planar<GrayF32> preprocess(Planar<GrayF32> image){\r\n    if (image.width == imageSize && image.height == imageSize) {\r\n        this.imageRgb.setTo(image);\r\n    } else if (image.width < imageSize || image.height < imageSize) {\r\n        throw new IllegalArgumentException(\"Image width or height is too small\");\r\n    } else {\r\n        massage.massage(image, imageRgb);\r\n    }\r\n    return imageRgb;\r\n}"
}, {
	"Path": "boofcv.examples.segmentation.ExampleSegmentColor.showSelectedColor",
	"Comment": "selectively displays only pixels which have a similar hue and saturation values to what is provided.\tthis is intended to be a simple example of color based segmentation.color based segmentation can be done\tin rgb color, but is more problematic due to it not being intensity invariant.more robust techniques\tcan use gaussian models instead of a uniform distribution, as is done below.",
	"Method": "void showSelectedColor(String name,BufferedImage image,float hue,float saturation){\r\n    Planar<GrayF32> input = ConvertBufferedImage.convertFromPlanar(image, null, true, GrayF32.class);\r\n    Planar<GrayF32> hsv = input.createSameShape();\r\n    ColorHsv.rgbToHsv_F32(input, hsv);\r\n    float maxDist2 = 0.4f * 0.4f;\r\n    GrayF32 H = hsv.getBand(0);\r\n    GrayF32 S = hsv.getBand(1);\r\n    float adjustUnits = (float) (Math.PI / 2.0);\r\n    BufferedImage output = new BufferedImage(input.width, input.height, BufferedImage.TYPE_INT_RGB);\r\n    for (int y = 0; y < hsv.height; y++) {\r\n        for (int x = 0; x < hsv.width; x++) {\r\n            float dh = UtilAngle.dist(H.unsafe_get(x, y), hue);\r\n            float ds = (S.unsafe_get(x, y) - saturation) * adjustUnits;\r\n            float dist2 = dh * dh + ds * ds;\r\n            if (dist2 <= maxDist2) {\r\n                output.setRGB(x, y, image.getRGB(x, y));\r\n            }\r\n        }\r\n    }\r\n    ShowImages.showWindow(output, \"Showing \" + name);\r\n}"
}, {
	"Path": "boofcv.examples.sfm.ExampleVisualOdometryMonocularPlane.inlierPercent",
	"Comment": "if the algorithm implements accesspointtracks3d, then count the number of inlier features\tand return a string.",
	"Method": "String inlierPercent(VisualOdometry<?> alg){\r\n    if (!(alg instanceof AccessPointTracks3D))\r\n        return \"\";\r\n    AccessPointTracks3D access = (AccessPointTracks3D) alg;\r\n    int count = 0;\r\n    int N = access.getAllTracks().size();\r\n    for (int i = 0; i < N; i++) {\r\n        if (access.isInlier(i))\r\n            count++;\r\n    }\r\n    return String.format(\"%%%5.3f\", 100.0 * count / N);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareCrossClustersIntoGrids.processCluster",
	"Comment": "converts the cluster into a grid data structure.if its not a grid then\tnothing happens",
	"Method": "void processCluster(List<SquareNode> cluster){\r\n    invalid = false;\r\n    if (cluster.size() == 1) {\r\n        SquareNode n = cluster.get(0);\r\n        if (n.getNumberOfConnections() == 0) {\r\n            SquareGrid grid = grids.grow();\r\n            grid.reset();\r\n            grid.columns = grid.rows = 1;\r\n            grid.nodes.add(n);\r\n            return;\r\n        }\r\n    }\r\n    for (int i = 0; i < cluster.size(); i++) {\r\n        cluster.get(i).graph = SquareNode.RESET_GRAPH;\r\n    }\r\n    SquareNode seed = findSeedNode(cluster);\r\n    if (seed == null)\r\n        return;\r\n    List<SquareNode> firstRow;\r\n    if (seed.getNumberOfConnections() == 1) {\r\n        firstRow = firstRow1(seed);\r\n    } else if (seed.getNumberOfConnections() == 2) {\r\n        firstRow = firstRow2(seed);\r\n    } else {\r\n        throw new RuntimeException(\"BUG\");\r\n    }\r\n    if (invalid || firstRow == null)\r\n        return;\r\n    List<List<SquareNode>> listRows = new ArrayList();\r\n    listRows.add(firstRow);\r\n    while (true) {\r\n        List<SquareNode> previous = listRows.get(listRows.size() - 1);\r\n        if (!addNextRow(previous.get(0), listRows)) {\r\n            break;\r\n        }\r\n    }\r\n    if (invalid || listRows.size() < 2)\r\n        return;\r\n    SquareGrid grid = assembleGrid(listRows);\r\n    if (grid == null || !checkEdgeCount(grid)) {\r\n        grids.removeTail();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.direct.VisOdomDirectColorDepth.constructLinearSystem",
	"Comment": "given the set of points in the key frame and their current observations",
	"Method": "void constructLinearSystem(Planar<I> input,Se3_F32 g){\r\n    int numBands = imageType.getNumBands();\r\n    inboundsPixels = 0;\r\n    for (int i = 0; i < keypixels.size(); i++) {\r\n        Pixel p = keypixels.data[i];\r\n        SePointOps_F32.transform(g, p.p3, S);\r\n        if (S.z <= 0) {\r\n            p.valid = false;\r\n            continue;\r\n        }\r\n        p.proj.x = (S.x / S.z) * fx + cx;\r\n        p.proj.y = (S.y / S.z) * fy + cy;\r\n        if (p.proj.x < 0 || p.proj.x > input.width - 1 || p.proj.y < 0 || p.proj.y > input.height - 1) {\r\n            p.valid = false;\r\n            continue;\r\n        } else {\r\n            p.valid = true;\r\n        }\r\n        inboundsPixels++;\r\n        float ZZ = S.z * S.z;\r\n        p.dP11 = fx / S.z;\r\n        p.dP13 = -S.x * fx / ZZ;\r\n        p.dP22 = fy / S.z;\r\n        p.dP23 = -S.y * fy / ZZ;\r\n    }\r\n    errorOptical = 0;\r\n    int row = 0;\r\n    for (int band = 0; band < numBands; band++) {\r\n        interpDX.setImage(derivX.getBand(band));\r\n        interpDY.setImage(derivY.getBand(band));\r\n        interpI.setImage(input.getBand(band));\r\n        for (int i = 0; i < keypixels.size(); i++) {\r\n            Pixel p = keypixels.data[i];\r\n            if (!p.valid)\r\n                continue;\r\n            SePointOps_F32.transform(g, p.p3, S);\r\n            float current = interpI.get(p.proj.x, p.proj.y);\r\n            float dx = interpDX.get(p.proj.x, p.proj.y);\r\n            float dy = interpDY.get(p.proj.x, p.proj.y);\r\n            float b1 = dx * p.dP11;\r\n            float b2 = dy * p.dP22;\r\n            float b3 = dx * p.dP13 + dy * p.dP23;\r\n            int indexA = row * 6;\r\n            A.data[indexA++] = -b2 * S.z + b3 * S.y;\r\n            A.data[indexA++] = b1 * S.z - b3 * S.x;\r\n            A.data[indexA++] = -b1 * S.y + b2 * S.x;\r\n            A.data[indexA++] = b1;\r\n            A.data[indexA++] = b2;\r\n            A.data[indexA] = b3;\r\n            float error = -(current - p.bands[band]);\r\n            y.data[row] = error;\r\n            errorOptical += Math.abs(error);\r\n            row += 1;\r\n        }\r\n    }\r\n    errorOptical /= row;\r\n    A.numRows = row;\r\n    y.numRows = row;\r\n}"
}, {
	"Path": "boofcv.alg.descriptor.TestUtilFeature.normalizeSumOne_zeros_F64",
	"Comment": "the descriptor is all zeros.see if it handles this special case.",
	"Method": "void normalizeSumOne_zeros_F64(){\r\n    TupleDesc_F64 feature = new TupleDesc_F64(64);\r\n    UtilFeature.normalizeSumOne(feature);\r\n    for (int i = 0; i < feature.value.length; i++) assertEquals(0, feature.value[i], 1e-4);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionHandle.isPossiblyBroken",
	"Comment": "gets true if connection has triggered an exception at some point.",
	"Method": "boolean isPossiblyBroken(){\r\n    return this.possiblyBroken;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.direct.FeatureSpatialDiversity_F32.process",
	"Comment": "computes the worst case spread for how features are laid out",
	"Method": "void process(){\r\n    computeCovarince();\r\n    float eigenvalue = smallestEigenvalue();\r\n    double stdev = Math.sqrt(eigenvalue);\r\n    double angle0 = Math.atan2(1.0, sigmas * (meanX - stdev));\r\n    double angle1 = Math.atan2(1.0, sigmas * (meanX + stdev));\r\n    spread = Math.abs(angle1 - angle0);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.Utilities.limit",
	"Comment": "limits given value between two other values if it is comparable.",
	"Method": "T limit(T min,T value,T max){\r\n    if (value.compareTo(min) < 0) {\r\n        return min;\r\n    }\r\n    if (value.compareTo(max) > 0) {\r\n        return max;\r\n    }\r\n    return value;\r\n}"
}, {
	"Path": "boofcv.abst.distort.FDistort.rotate",
	"Comment": "applies a distortion which will rotate the input image by the specified amount.",
	"Method": "FDistort rotate(double angleInputToOutput){\r\n    PixelTransform2_F32 outputToInput = DistortSupport.transformRotate(input.width / 2, input.height / 2, output.width / 2, output.height / 2, (float) angleInputToOutput);\r\n    return transform(outputToInput);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.helpers.LocationHelper.queryJsonFromUrl",
	"Comment": "queries the json for location from the google api.it uses the user chosen language to tell google in which language the city names should be returned.",
	"Method": "JSONObject queryJsonFromUrl(String latLong){\r\n    final String language = ConfigNew.getConfig().getString(ConfigKey.LANGUAGE);\r\n    final String apiUrl = \"http://maps.googleapis.com/maps/api/geocode/json?latlng=%s&sensor=true&language=%s\";\r\n    final String formattedUrl = String.format(apiUrl, latLong.replace(\" \", \" \"), language);\r\n    try {\r\n        final URL url = new URL(formattedUrl);\r\n        final String apiResponse = FileHelper.readFile(url.openStream());\r\n        return new JSONObject(apiResponse);\r\n    } catch (IOException e) {\r\n        System.out.println(ExceptionMessages.COULD_NOT_QUERY_LOCATION.with(e));\r\n        return new JSONObject();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomQuadPnP.associateF2F",
	"Comment": "associates images between left and left and right and right images",
	"Method": "void associateF2F(){\r\n    quadViews.reset();\r\n    for (int i = 0; i < detector.getNumberOfSets(); i++) {\r\n        SetMatches matches = setMatches[i];\r\n        assocSame.setSource(featsLeft0.location[i], featsLeft0.description[i]);\r\n        assocSame.setDestination(featsLeft1.location[i], featsLeft1.description[i]);\r\n        assocSame.associate();\r\n        setMatches(matches.match0to2, assocSame.getMatches(), featsLeft0.location[i].size);\r\n        assocSame.setSource(featsRight0.location[i], featsRight0.description[i]);\r\n        assocSame.setDestination(featsRight1.location[i], featsRight1.description[i]);\r\n        assocSame.associate();\r\n        setMatches(matches.match1to3, assocSame.getMatches(), featsRight0.location[i].size);\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.geo.bundle.SceneStructureProjective.getParameterCount",
	"Comment": "returns the total number of parameters which will be optimised",
	"Method": "int getParameterCount(){\r\n    return getUnknownViewCount() * 12 + points.length * pointSize;\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.impl.GeneralChecksInterpolationPixelS.checkPixelValueBoundsHonored",
	"Comment": "interpolates the whole image and sees if the values returned are within the specified bounds",
	"Method": "void checkPixelValueBoundsHonored(){\r\n    T img = createImage(20, 30);\r\n    GImageMiscOps.fillUniform(img, rand, 0, 100);\r\n    InterpolatePixelS<T> interp = wrap(img, 0, 100);\r\n    interp.setBorder(FactoryImageBorder.singleValue(img, 0));\r\n    for (int off = 0; off < 5; off++) {\r\n        float frac = off / 5.0f;\r\n        for (int y = 0; y < img.height; y++) {\r\n            for (int x = 0; x < img.width; x++) {\r\n                float v = interp.get(x + frac, y + frac);\r\n                assertTrue(v >= 0 && v <= 100);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.testing.BoofTesting.checkImageDimensionValidation",
	"Comment": "searches for functions that accept only images and makes sure they only accept\timages which have he same width and height.",
	"Method": "void checkImageDimensionValidation(Object testClass,int numFunctions){\r\n    int count = 0;\r\n    Method[] methods = testClass.getClass().getMethods();\r\n    for (Method m : methods) {\r\n        if (!areAllInputsImages(m))\r\n            continue;\r\n        Class[] params = m.getParameterTypes();\r\n        Object[] inputs = new Object[params.length];\r\n        for (int i = 0; i < params.length; i++) {\r\n            inputs[i] = GeneralizedImageOps.createSingleBand(params[i], 10, 20);\r\n        }\r\n        try {\r\n            m.invoke(testClass, inputs);\r\n        } catch (IllegalAccessException | InvocationTargetException e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n        for (int target = 0; target < params.length; target++) {\r\n            for (int i = 0; i < params.length; i++) {\r\n                if (i != target)\r\n                    inputs[i] = GeneralizedImageOps.createSingleBand(params[i], 10, 20);\r\n                else\r\n                    inputs[i] = GeneralizedImageOps.createSingleBand(params[i], 11, 22);\r\n            }\r\n            try {\r\n                m.invoke(testClass, inputs);\r\n                throw new RuntimeException(\"Expected an exception here\");\r\n            } catch (InvocationTargetException e) {\r\n                if (e.getTargetException().getClass() != IllegalArgumentException.class)\r\n                    throw new RuntimeException(e);\r\n            } catch (IllegalAccessException e) {\r\n                throw new RuntimeException(e);\r\n            }\r\n        }\r\n        count++;\r\n    }\r\n    if (count != numFunctions)\r\n        throw new RuntimeException(\"Unexpected number of functions\");\r\n}"
}, {
	"Path": "boofcv.factory.shape.FactoryShapeDetector.ellipse",
	"Comment": "creates an ellipse detector which will detect all ellipses in the image initially using a binary image and\tthen refine the estimate using a subpixel algorithm in the gray scale image.",
	"Method": "BinaryEllipseDetector<T> ellipse(ConfigEllipseDetector config,Class<T> imageType){\r\n    if (config == null)\r\n        config = new ConfigEllipseDetector();\r\n    config.checkValidity();\r\n    BinaryEllipseDetectorPixel detector = new BinaryEllipseDetectorPixel(config.contourRule);\r\n    detector.setMaxDistanceFromEllipse(config.maxDistanceFromEllipse);\r\n    detector.setMaximumContour(config.maximumContour);\r\n    detector.setMinimumContour(config.minimumContour);\r\n    detector.setMinimumMinorAxis(config.minimumMinorAxis);\r\n    detector.setInternalContour(config.processInternal);\r\n    detector.setMaxMajorToMinorRatio(config.maxMajorToMinorRatio);\r\n    SnapToEllipseEdge<T> refine = new SnapToEllipseEdge(config.numSampleContour, config.refineRadialSamples, imageType);\r\n    refine.setConvergenceTol(config.convergenceTol);\r\n    refine.setMaxIterations(config.maxIterations);\r\n    if (config.maxIterations <= 0 || config.numSampleContour <= 0) {\r\n        refine = null;\r\n    }\r\n    EdgeIntensityEllipse<T> check = new EdgeIntensityEllipse(config.checkRadialDistance, config.numSampleContour, config.minimumEdgeIntensity, imageType);\r\n    return new BinaryEllipseDetector(detector, refine, check, imageType);\r\n}"
}, {
	"Path": "com.gazbert.bxbot.core.engine.TestTradingEngine.testEngineShutsDownWhenItReceivesTradingApiExceptionFromExchangeAdapter",
	"Comment": "tests the engine starts up, executes 1 trade cycle successfully, but then receives tradingapiexception fromexchange adapter on the 2nd cycle. we expect the engine to shutdown.",
	"Method": "void testEngineShutsDownWhenItReceivesTradingApiExceptionFromExchangeAdapter(){\r\n    setupConfigLoadingExpectations();\r\n    final String exceptionErrorMsg = \"Ten percent of nothin' is ... let me do the math here ... nothin' into nothin' ... carry the nothin' ...\";\r\n    final Map<String, BigDecimal> balancesAvailable = new HashMap();\r\n    balancesAvailable.put(ENGINE_EMERGENCY_STOP_CURRENCY, new BigDecimal(\"0.5\"));\r\n    final BalanceInfo balanceInfo = PowerMock.createMock(BalanceInfo.class);\r\n    expect(exchangeAdapter.getBalanceInfo()).andReturn(balanceInfo);\r\n    expect(balanceInfo.getBalancesAvailable()).andReturn(balancesAvailable);\r\n    tradingStrategy.execute();\r\n    expect(exchangeAdapter.getBalanceInfo()).andThrow(new TradingApiException(exceptionErrorMsg));\r\n    emailAlerter.sendMessage(eq(CRITICAL_EMAIL_ALERT_SUBJECT), contains(\"A FATAL error has occurred in Exchange\" + \" Adapter! Details: \" + exceptionErrorMsg));\r\n    PowerMock.replayAll();\r\n    final TradingEngine tradingEngine = new TradingEngine(exchangeConfigService, engineConfigService, strategyConfigService, marketConfigService, emailAlerter);\r\n    tradingEngine.start();\r\n    waitForEngineStateChange(tradingEngine, EngineState.SHUTDOWN, NUMBER_OF_TRADE_CYCLES);\r\n    assertFalse(tradingEngine.isRunning());\r\n    PowerMock.verifyAll();\r\n}"
}, {
	"Path": "boofcv.alg.distort.LensDistortionOps.changeCameraModel",
	"Comment": "creates a distortion for modifying the input image from one camera model into another camera model.if\trequested the camera model can be further modified to ensure certain visibility requirements are meet\tand the adjusted camera model will be returned.",
	"Method": "ImageDistort<T, T> changeCameraModel(AdjustmentType type,BorderType borderType,O original,D desired,D modified,ImageType<T> imageType){\r\n    Class bandType = imageType.getImageClass();\r\n    boolean skip = borderType == BorderType.SKIP;\r\n    if (skip)\r\n        borderType = BorderType.EXTENDED;\r\n    InterpolatePixelS interp = FactoryInterpolation.createPixelS(0, 255, InterpolationType.BILINEAR, borderType, bandType);\r\n    Point2Transform2_F32 undistToDist = transformChangeModel_F32(type, original, desired, true, modified);\r\n    ImageDistort<T, T> distort = FactoryDistort.distort(true, interp, imageType);\r\n    distort.setModel(new PointToPixelTransform_F32(undistToDist));\r\n    distort.setRenderAll(!skip);\r\n    return distort;\r\n}"
}, {
	"Path": "boofcv.abst.shapes.polyline.ChecksGenericPointsToPolyline.checkDefaults",
	"Comment": "makes sure that the default values as specified in javadoc is true",
	"Method": "void checkDefaults(){\r\n    PointsToPolyline alg = createAlg(true);\r\n    assertEquals(3, alg.getMinimumSides());\r\n    assertEquals(Integer.MAX_VALUE, alg.getMaximumSides());\r\n    assertEquals(true, alg.isConvex());\r\n    assertEquals(true, alg.isLoop());\r\n    alg = createAlg(false);\r\n    assertEquals(3, alg.getMinimumSides());\r\n    assertEquals(Integer.MAX_VALUE, alg.getMaximumSides());\r\n    assertEquals(true, alg.isConvex());\r\n    assertEquals(false, alg.isLoop());\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.TestHelperNister5.setupA1_setupA2",
	"Comment": "validates a and b by computing solutions to constraint equations for a specific instance of x,y,z",
	"Method": "void setupA1_setupA2(){\r\n    double x = 0.5, y = 2, z = -0.2, w = 1;\r\n    SimpleMatrix E = SimpleMatrix.wrap(constructE(x, y, z, w));\r\n    DMatrixRMaj A = new DMatrixRMaj(10, 10);\r\n    DMatrixRMaj B = new DMatrixRMaj(10, 10);\r\n    HelperNister5 alg = new HelperNister5();\r\n    alg.setNullSpace(X, Y, Z, W);\r\n    alg.setupA1(A);\r\n    alg.setupA2(B);\r\n    DMatrixRMaj Y1 = new DMatrixRMaj(10, 1);\r\n    DMatrixRMaj Y2 = new DMatrixRMaj(10, 1);\r\n    CommonOps_DDRM.mult(A, createCoefsA(x, y, z), Y1);\r\n    CommonOps_DDRM.mult(B, createCoefsB(x, y, z), Y2);\r\n    DMatrixRMaj Y = new DMatrixRMaj(10, 1);\r\n    CommonOps_DDRM.add(Y1, Y2, Y);\r\n    SimpleMatrix EEt = E.mult(E.transpose());\r\n    SimpleMatrix EEtE = EEt.mult(E);\r\n    SimpleMatrix aE = E.scale(-0.5 * EEt.trace());\r\n    DMatrixRMaj eq2 = EEtE.plus(aE).getDDRM();\r\n    assertEquals(E.determinant(), Y.data[0], 1e-8);\r\n    assertEquals(eq2.data[0], Y.data[1], 1e-8);\r\n    assertEquals(eq2.data[1], Y.data[2], 1e-8);\r\n    assertEquals(eq2.data[2], Y.data[3], 1e-8);\r\n    assertEquals(eq2.data[3], Y.data[4], 1e-8);\r\n    assertEquals(eq2.data[4], Y.data[5], 1e-8);\r\n    assertEquals(eq2.data[5], Y.data[6], 1e-8);\r\n    assertEquals(eq2.data[6], Y.data[7], 1e-8);\r\n    assertEquals(eq2.data[7], Y.data[8], 1e-8);\r\n    assertEquals(eq2.data[8], Y.data[9], 1e-8);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.circulant.TestCirculantTracker.updateTrackLocation",
	"Comment": "check a few simple motions.it seems to be accurate to within 1 pixel.considering alphas seems to be the issue",
	"Method": "void updateTrackLocation(){\r\n    GrayF32 a = new GrayF32(100, 100);\r\n    GrayF32 b = new GrayF32(100, 100);\r\n    GImageMiscOps.fillUniform(a, rand, 0, 200);\r\n    GImageMiscOps.fillUniform(b, rand, 0, 200);\r\n    shiftCopy(0, 0, a, b);\r\n    CirculantTracker<GrayF32> alg = new CirculantTracker(1f / 16, 0.2, 1e-2, 0.075, 1.0, 64, 255, interp);\r\n    alg.initialize(a, 5, 6, 20, 25);\r\n    alg.updateTrackLocation(b);\r\n    float tolerance = 1f;\r\n    RectangleLength2D_F32 r = alg.getTargetLocation();\r\n    assertEquals(5, r.x0, tolerance);\r\n    assertEquals(6, r.y0, tolerance);\r\n    GImageMiscOps.fillUniform(b, rand, 0, 200);\r\n    shiftCopy(-3, 2, a, b);\r\n    alg.updateTrackLocation(b);\r\n    r = alg.getTargetLocation();\r\n    assertEquals(5 - 3, r.x0, tolerance);\r\n    assertEquals(6 + 2, r.y0, tolerance);\r\n    GImageMiscOps.fillUniform(b, rand, 0, 200);\r\n    shiftCopy(-6, 0, a, b);\r\n    alg.updateTrackLocation(b);\r\n    assertEquals(5 - 6, r.x0, tolerance);\r\n    assertEquals(6, r.y0, tolerance);\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.isAutomaticallyCollectingBreadcrumbs",
	"Comment": "returns whether automatic breadcrumb capture or common application events is enabled.",
	"Method": "boolean isAutomaticallyCollectingBreadcrumbs(){\r\n    return automaticallyCollectBreadcrumbs;\r\n}"
}, {
	"Path": "boofcv.abst.distort.FDistort.output",
	"Comment": "changes the output image.the previous distortion is thrown away only if the output\timage has a different shape",
	"Method": "FDistort output(ImageBase output){\r\n    if (this.output == null || this.output.width != output.width || this.output.height != output.height) {\r\n        distorter = null;\r\n    }\r\n    this.output = output;\r\n    return this;\r\n}"
}, {
	"Path": "boofcv.struct.image.StandardImageInterleavedTests.isSubimage",
	"Comment": "checks to see if the implementation specific to imageinterleavedtests\tworks",
	"Method": "void isSubimage(){\r\n    T a = createImage(10, 20, 3);\r\n    assertFalse(a.isSubimage());\r\n    assertTrue(a.subimage(0, 5, 0, 5, null).isSubimage());\r\n    assertTrue(a.subimage(2, 5, 2, 5, null).isSubimage());\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPDataSource.getPool",
	"Comment": "returns a handle to the pool. useful to obtain a handle to the \tstatistics for example.",
	"Method": "BoneCP getPool(){\r\n    FinalWrapper<BoneCP> wrapper = this.pool;\r\n    return wrapper == null ? null : wrapper.value;\r\n}"
}, {
	"Path": "boofcv.gui.JavaRuntimeLauncher.setMemoryInMB",
	"Comment": "specifies the amount of memory the process will be allocated in megabytes",
	"Method": "void setMemoryInMB(long memoryInMB){\r\n    this.memoryInMB = memoryInMB;\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.getEnableExceptionHandler",
	"Comment": "get whether or not bugsnag should automatically handle uncaught exceptions",
	"Method": "boolean getEnableExceptionHandler(){\r\n    return enableExceptionHandler;\r\n}"
}, {
	"Path": "boofcv.alg.filter.derivative.GeneralSparseGradientTests.testBorder",
	"Comment": "compute the input along the image border and see if has the expected results",
	"Method": "void testBorder(){\r\n    imageGradient(input, derivX, derivY);\r\n    alg.setImage(input);\r\n    for (int y = 0; y < height; y++) {\r\n        if (y < -sampleBoxY0 || y >= height - sampleBoxY1 - 1) {\r\n            for (int x = 0; x < width; x++) {\r\n                if (x < sampleBoxX0 || x >= width - sampleBoxX1 - 1) {\r\n                    G g = alg.compute(x, y);\r\n                    double expectedX = GeneralizedImageOps.get(derivX, x, y);\r\n                    double expectedY = GeneralizedImageOps.get(derivY, x, y);\r\n                    assertEquals(expectedX, g.getX(), 1e-4);\r\n                    assertEquals(expectedY, g.getY(), 1e-4);\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.DescribePointSurf.getCanonicalWidth",
	"Comment": "width of sampled region when sampling is aligned with image pixels",
	"Method": "int getCanonicalWidth(){\r\n    return widthLargeGrid * widthSubRegion + widthSample - (widthSample % 2);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.DetectFiducialSquareBinary.rotateUntilInLowerCorner",
	"Comment": "rotate the pattern until the black corner is in the lower right.sanity check to make\tsure there is only one black corner",
	"Method": "boolean rotateUntilInLowerCorner(Result result){\r\n    final int topLeft = getTotalGridElements() - gridWidth;\r\n    final int topRight = getTotalGridElements() - 1;\r\n    final int bottomLeft = 0;\r\n    final int bottomRight = gridWidth - 1;\r\n    if (classified[bottomLeft] + classified[bottomRight] + classified[topRight] + classified[topLeft] != 1)\r\n        return true;\r\n    result.rotation = 0;\r\n    while (classified[topLeft] != 1) {\r\n        result.rotation++;\r\n        rotateClockWise();\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.alg.misc.ImageStatistics.meanDiffAbs",
	"Comment": "computes the mean of absolute value error between the two images.",
	"Method": "double meanDiffAbs(GrayU8 imgA,GrayU8 imgB,double meanDiffAbs,InterleavedU8 imgA,InterleavedU8 imgB,double meanDiffAbs,GrayS8 imgA,GrayS8 imgB,double meanDiffAbs,InterleavedS8 imgA,InterleavedS8 imgB,double meanDiffAbs,byte[] dataA,int startIndexA,int strideA,byte[] dataB,int startIndexB,int strideB,int rows,int columns,double meanDiffAbs,GrayU16 imgA,GrayU16 imgB,double meanDiffAbs,InterleavedU16 imgA,InterleavedU16 imgB,double meanDiffAbs,GrayS16 imgA,GrayS16 imgB,double meanDiffAbs,InterleavedS16 imgA,InterleavedS16 imgB,double meanDiffAbs,short[] dataA,int startIndexA,int strideA,short[] dataB,int startIndexB,int strideB,int rows,int columns,double meanDiffAbs,GrayS32 imgA,GrayS32 imgB,double meanDiffAbs,InterleavedS32 imgA,InterleavedS32 imgB,double meanDiffAbs,int[] dataA,int startIndexA,int strideA,int[] dataB,int startIndexB,int strideB,int rows,int columns,double meanDiffAbs,GrayS64 imgA,GrayS64 imgB,double meanDiffAbs,InterleavedS64 imgA,InterleavedS64 imgB,double meanDiffAbs,long[] dataA,int startIndexA,int strideA,long[] dataB,int startIndexB,int strideB,int rows,int columns,double meanDiffAbs,GrayF32 imgA,GrayF32 imgB,double meanDiffAbs,InterleavedF32 imgA,InterleavedF32 imgB,double meanDiffAbs,float[] dataA,int startIndexA,int strideA,float[] dataB,int startIndexB,int strideB,int rows,int columns,double meanDiffAbs,GrayF64 imgA,GrayF64 imgB,double meanDiffAbs,InterleavedF64 imgA,InterleavedF64 imgB,double meanDiffAbs,double[] dataA,int startIndexA,int strideA,double[] dataB,int startIndexB,int strideB,int rows,int columns){\r\n    double total = 0;\r\n    for (int y = 0; y < rows; y++) {\r\n        int indexA = startIndexA + y * strideA;\r\n        int indexB = startIndexB + y * strideB;\r\n        int indexEnd = indexA + columns;\r\n        for (; indexA < indexEnd; indexA++, indexB++) {\r\n            double difference = (dataA[indexA]) - (dataB[indexB]);\r\n            total += Math.abs(difference);\r\n        }\r\n    }\r\n    return total / (double) (rows * columns);\r\n}"
}, {
	"Path": "boofcv.alg.transform.ii.GIntegralImageOps.getIntegralType",
	"Comment": "given the input image, return the type of image the integral image should be.",
	"Method": "Class<II> getIntegralType(Class<I> inputType){\r\n    if (inputType == GrayF32.class) {\r\n        return (Class<II>) GrayF32.class;\r\n    } else if (inputType == GrayU8.class) {\r\n        return (Class<II>) GrayS32.class;\r\n    } else if (inputType == GrayS32.class) {\r\n        return (Class<II>) GrayS32.class;\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown input image type: \" + inputType.getSimpleName());\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.ImplDisparityScoreSadRect_S16.computeFirstRow",
	"Comment": "initializes disparity calculation by finding the scores for the initial block of horizontal\trows.",
	"Method": "void computeFirstRow(GrayS16 left,GrayS16 right){\r\n    for (int row = 0; row < regionHeight; row++) {\r\n        int[] scores = horizontalScore[row];\r\n        UtilDisparityScore.computeScoreRow(left, right, row, scores, minDisparity, maxDisparity, regionWidth, elementScore);\r\n    }\r\n    for (int i = 0; i < lengthHorizontal; i++) {\r\n        int sum = 0;\r\n        for (int row = 0; row < regionHeight; row++) {\r\n            sum += horizontalScore[row][i];\r\n        }\r\n        verticalScore[i] = sum;\r\n    }\r\n    computeDisparity.process(radiusY, verticalScore);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionHandle.testInternalClose",
	"Comment": "closing a connection handle should release that connection back in the pool and mark it as closed.",
	"Method": "void testInternalClose(){\r\n    ConcurrentLinkedQueue<Statement> mockStatementHandles = createNiceMock(ConcurrentLinkedQueue.class);\r\n    StatementHandle mockStatement = createNiceMock(StatementHandle.class);\r\n    this.mockConnection.close();\r\n    expectLastCall().once().andThrow(new SQLException()).once();\r\n    Map<Connection, Reference<ConnectionHandle>> refs = new HashMap<Connection, Reference<ConnectionHandle>>();\r\n    expect(this.mockPool.getFinalizableRefs()).andReturn(refs).anyTimes();\r\n    FinalizableReferenceQueue finalizableRefQueue = new FinalizableReferenceQueue();\r\n    expect(this.mockPool.getFinalizableRefQueue()).andReturn(finalizableRefQueue).anyTimes();\r\n    expect(this.mockConnection.getPool()).andReturn(this.mockPool).anyTimes();\r\n    Field f = this.testClass.getClass().getDeclaredField(\"finalizableRefs\");\r\n    f.setAccessible(true);\r\n    f.set(this.testClass, refs);\r\n    replay(mockStatement, this.mockConnection, mockStatementHandles, this.mockPool);\r\n    this.testClass.internalClose();\r\n    try {\r\n        this.testClass.internalClose();\r\n        fail(\"Should have thrown an exception\");\r\n    } catch (Throwable t) {\r\n    }\r\n    verify(mockStatement, this.mockConnection, mockStatementHandles);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeAlignmentPatternLocator.localize",
	"Comment": "localizizes the alignment pattern crudely by searching for the black box in the center by looking\tfor its edges in the gray scale image",
	"Method": "boolean localize(QrCode.Alignment pattern,float guessY,float guessX){\r\n    for (int i = 0; i < arrayY.length; i++) {\r\n        float x = guessX - 1.5f + i * 3f / 12.0f;\r\n        float y = guessY - 1.5f + i * 3f / 12.0f;\r\n        arrayX[i] = reader.read(guessY, x);\r\n        arrayY[i] = reader.read(y, guessX);\r\n    }\r\n    int downX = greatestDown(arrayX);\r\n    if (downX == -1)\r\n        return false;\r\n    int upX = greatestUp(arrayX, downX);\r\n    if (upX == -1)\r\n        return false;\r\n    int downY = greatestDown(arrayY);\r\n    if (downY == -1)\r\n        return false;\r\n    int upY = greatestUp(arrayY, downY);\r\n    if (upY == -1)\r\n        return false;\r\n    pattern.moduleFound.x = guessX - 1.5f + (downX + upX) * 3f / 24.0f;\r\n    pattern.moduleFound.y = guessY - 1.5f + (downY + upY) * 3f / 24.0f;\r\n    reader.gridToImage((float) pattern.moduleFound.y, (float) pattern.moduleFound.x, pattern.pixel);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.GenericQrCodeDetectorChecks.rotation",
	"Comment": "see if a clear well defined qr code can be detected while rating",
	"Method": "void rotation(){\r\n    QrCodeDetector<GrayF32> detector = createDetector();\r\n    CameraPinholeRadial model = CalibrationIO.load(getClass().getResource(\"calib/pinhole_radial.yaml\"));\r\n    SimulatePlanarWorld simulator = new SimulatePlanarWorld();\r\n    simulator.setCamera(model);\r\n    simulator.resetScene();\r\n    Se3_F64 markerToWorld = new Se3_F64();\r\n    simulator.addSurface(markerToWorld, simulatedTargetWidth, generateMarker());\r\n    markerToWorld.T.set(0, 0, 0.5);\r\n    for (int i = 0; i < 30; i++) {\r\n        double roll = 2 * Math.PI * i / 30.0;\r\n        ConvertRotation3D_F64.eulerToMatrix(EulerType.XYZ, 0, Math.PI, roll, markerToWorld.R);\r\n        renderAndCheck(detector, simulator);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldHelperFunctions.computeOverlap",
	"Comment": "computes the fractional area of intersection between the two regions.",
	"Method": "double computeOverlap(ImageRectangle a,ImageRectangle b){\r\n    if (!a.intersection(b, work))\r\n        return 0;\r\n    int areaI = work.area();\r\n    int bottom = a.area() + b.area() - areaI;\r\n    return areaI / (double) bottom;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setStatementCacheSize",
	"Comment": "deprecated. use set statementcachesize instead. \tthe number of statements to cache.",
	"Method": "void setStatementCacheSize(int statementsCacheSize){\r\n    logger.warn(\"Please use setStatementsCacheSize in place of setStatementCacheSize. This method has been deprecated.\");\r\n    this.statementsCacheSize = statementsCacheSize;\r\n}"
}, {
	"Path": "boofcv.io.image.ConvertBufferedImage.checkDeclare",
	"Comment": "if the provided image does not have the same shape and same type a new one is declared and returned.",
	"Method": "BufferedImage checkDeclare(int width,int height,BufferedImage image,int type,BufferedImage checkDeclare,BufferedImage template,BufferedImage target){\r\n    int width = template.getWidth();\r\n    int height = template.getHeight();\r\n    int type = template.getType();\r\n    if (type == 0) {\r\n        if (target != null)\r\n            type = target.getType();\r\n        else\r\n            type = BufferedImage.TYPE_INT_RGB;\r\n    }\r\n    if (target == null)\r\n        return new BufferedImage(width, height, type);\r\n    if (target.getType() != type)\r\n        return new BufferedImage(width, height, type);\r\n    if (target.getWidth() != width || target.getHeight() != height)\r\n        return new BufferedImage(width, height, type);\r\n    return target;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.FitLinesToContour.fitLine",
	"Comment": "given a sequence of points on the contour find the best fit line.",
	"Method": "boolean fitLine(int contourIndex0,int contourIndex1,LineGeneral2D_F64 line){\r\n    int numPixels = CircularIndex.distanceP(contourIndex0, contourIndex1, contour.size());\r\n    if (numPixels < minimumLineLength)\r\n        return false;\r\n    Point2D_I32 c0 = contour.get(contourIndex0);\r\n    Point2D_I32 c1 = contour.get(contourIndex1);\r\n    double scale = c0.distance(c1);\r\n    double centerX = (c1.x + c0.x) / 2.0;\r\n    double centerY = (c1.y + c0.y) / 2.0;\r\n    int numSamples = Math.min(maxSamples, numPixels);\r\n    pointsFit.reset();\r\n    for (int i = 0; i < numSamples; i++) {\r\n        int index = i * (numPixels - 1) / (numSamples - 1);\r\n        Point2D_I32 c = contour.get(CircularIndex.addOffset(contourIndex0, index, contour.size()));\r\n        Point2D_F64 p = pointsFit.grow();\r\n        p.x = (c.x - centerX) / scale;\r\n        p.y = (c.y - centerY) / scale;\r\n    }\r\n    if (null == FitLine_F64.polar(pointsFit.toList(), linePolar)) {\r\n        return false;\r\n    }\r\n    UtilLine2D_F64.convert(linePolar, line);\r\n    line.C = scale * line.C - centerX * line.A - centerY * line.B;\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.geo.MultiViewOps.homographyStereoLinePt",
	"Comment": "computes the homography induced from a planar surface when viewed from two views using correspondences\tof a line and a point. observations must be on the planar surface.",
	"Method": "DMatrixRMaj homographyStereoLinePt(DMatrixRMaj F,PairLineNorm line,AssociatedPair point){\r\n    HomographyInducedStereoLinePt alg = new HomographyInducedStereoLinePt();\r\n    alg.setFundamental(F, null);\r\n    alg.process(line, point);\r\n    return alg.getHomography();\r\n}"
}, {
	"Path": "boofcv.examples.geometry.ExampleImageStitching.computeTransform",
	"Comment": "using abstracted code, find a transform which minimizes the difference between corresponding features\tin both images.this code is completely model independent and is the core algorithms.",
	"Method": "Homography2D_F64 computeTransform(T imageA,T imageB,DetectDescribePoint<T, FD> detDesc,AssociateDescription<FD> associate,ModelMatcher<Homography2D_F64, AssociatedPair> modelMatcher){\r\n    List<Point2D_F64> pointsA = new ArrayList();\r\n    FastQueue<FD> descA = UtilFeature.createQueue(detDesc, 100);\r\n    List<Point2D_F64> pointsB = new ArrayList();\r\n    FastQueue<FD> descB = UtilFeature.createQueue(detDesc, 100);\r\n    describeImage(imageA, detDesc, pointsA, descA);\r\n    describeImage(imageB, detDesc, pointsB, descB);\r\n    associate.setSource(descA);\r\n    associate.setDestination(descB);\r\n    associate.associate();\r\n    FastQueue<AssociatedIndex> matches = associate.getMatches();\r\n    List<AssociatedPair> pairs = new ArrayList();\r\n    for (int i = 0; i < matches.size(); i++) {\r\n        AssociatedIndex match = matches.get(i);\r\n        Point2D_F64 a = pointsA.get(match.src);\r\n        Point2D_F64 b = pointsB.get(match.dst);\r\n        pairs.add(new AssociatedPair(a, b, false));\r\n    }\r\n    if (!modelMatcher.process(pairs))\r\n        throw new RuntimeException(\"Model Matcher failed!\");\r\n    return modelMatcher.getModelParameters().copy();\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeDecoderBits.updateModeLogic",
	"Comment": "if only one mode then that mode is used. if more than one mode is used then set to multiple",
	"Method": "QrCode.Mode updateModeLogic(QrCode.Mode current,QrCode.Mode candidate){\r\n    if (current == candidate)\r\n        return current;\r\n    else if (current == QrCode.Mode.UNKNOWN) {\r\n        return candidate;\r\n    } else {\r\n        return QrCode.Mode.MIXED;\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.image.VisualizeImageData.grayMagnitudeTemp",
	"Comment": "renders a gray scale image using color values from cold to hot.",
	"Method": "BufferedImage grayMagnitudeTemp(ImageGray src,BufferedImage dst,double normalize,BufferedImage grayMagnitudeTemp,GrayI src,BufferedImage dst,int maxValue){\r\n    int halfValue = maxValue / 2 + maxValue % 2;\r\n    for (int y = 0; y < src.height; y++) {\r\n        for (int x = 0; x < src.width; x++) {\r\n            int v = Math.abs(src.get(x, y));\r\n            int r, b;\r\n            if (v >= halfValue) {\r\n                r = 255 * (v - halfValue) / halfValue;\r\n                b = 0;\r\n            } else {\r\n                r = 0;\r\n                b = 255 * v / halfValue;\r\n            }\r\n            if (v == 0) {\r\n                r = b = 0;\r\n            } else {\r\n                r = 255 * v / maxValue;\r\n                b = 255 * (maxValue - v) / maxValue;\r\n            }\r\n            dst.setRGB(x, y, r << 16 | b);\r\n        }\r\n    }\r\n    return dst;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setLazyInit",
	"Comment": "set to true to force the connection pool to obtain the initial connections lazily.",
	"Method": "void setLazyInit(boolean lazyInit){\r\n    this.lazyInit = lazyInit;\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.FundamentalLinear7.process",
	"Comment": "computes a fundamental or essential matrix from a set of associated point correspondences.",
	"Method": "boolean process(List<AssociatedPair> points,FastQueue<DMatrixRMaj> solutions,boolean process,DMatrixRMaj A){\r\n    if (!solverNull.process(A, 2, nullspace))\r\n        return false;\r\n    SpecializedOps_DDRM.subvector(nullspace, 0, 0, 9, false, 0, F1);\r\n    SpecializedOps_DDRM.subvector(nullspace, 0, 1, 9, false, 0, F2);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.examples.recognition.ExampleColorHistogramLookup.histogramGray",
	"Comment": "computes a histogram from the gray scale intensity image alone.probably the least effective at looking up\tsimilar images.",
	"Method": "List<double[]> histogramGray(List<File> images){\r\n    List<double[]> points = new ArrayList();\r\n    GrayU8 gray = new GrayU8(1, 1);\r\n    for (File f : images) {\r\n        BufferedImage buffered = UtilImageIO.loadImage(f.getPath());\r\n        if (buffered == null)\r\n            throw new RuntimeException(\"Can't load image!\");\r\n        gray.reshape(buffered.getWidth(), buffered.getHeight());\r\n        ConvertBufferedImage.convertFrom(buffered, gray, true);\r\n        TupleDesc_F64 imageHist = new TupleDesc_F64(150);\r\n        HistogramFeatureOps.histogram(gray, 255, imageHist);\r\n        UtilFeature.normalizeL2(imageHist);\r\n        points.add(imageHist.value);\r\n    }\r\n    return points;\r\n}"
}, {
	"Path": "boofcv.alg.descriptor.ConvertDescriptors.convertNcc",
	"Comment": "converts a regular feature description into a ncc feature description",
	"Method": "void convertNcc(TupleDesc_F64 input,NccFeature output){\r\n    if (input.size() != output.size())\r\n        throw new IllegalArgumentException(\"Feature lengths do not match.\");\r\n    double mean = 0;\r\n    for (int i = 0; i < input.value.length; i++) {\r\n        mean += input.value[i];\r\n    }\r\n    mean /= input.value.length;\r\n    double variance = 0;\r\n    for (int i = 0; i < input.value.length; i++) {\r\n        double d = output.value[i] = input.value[i] - mean;\r\n        variance += d * d;\r\n    }\r\n    variance /= output.size();\r\n    output.mean = mean;\r\n    output.sigma = Math.sqrt(variance);\r\n}"
}, {
	"Path": "boofcv.abst.feature.detdesc.GenericTestsDetectDescribePoint.checkMultipleCalls",
	"Comment": "make sure everything has been reset correctly and that multiple calls to the same input\tproduce the same output",
	"Method": "void checkMultipleCalls(){\r\n    DetectDescribePoint<T, D> alg1 = createDetDesc();\r\n    DetectDescribePoint<T, D> alg2 = createDetDesc();\r\n    alg1.detect(image);\r\n    alg1.detect(image);\r\n    alg2.detect(image);\r\n    checkIdenticalResponse(alg1, alg2);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPDataSource.getConfig",
	"Comment": "returns a configuration object built during initialization of the connection pool.",
	"Method": "BoneCPConfig getConfig(){\r\n    return this;\r\n}"
}, {
	"Path": "boofcv.alg.misc.GImageMiscOps.fillRectangle",
	"Comment": "draws a filled rectangle that is aligned along the image axis inside the image.",
	"Method": "void fillRectangle(ImageBase input,double value,int x0,int y0,int width,int height){\r\n    if (input instanceof ImageGray) {\r\n        if (GrayI8.class.isAssignableFrom(input.getClass())) {\r\n            ImageMiscOps.fillRectangle((GrayI8) input, (int) value, x0, y0, width, height);\r\n        } else if (GrayI16.class.isAssignableFrom(input.getClass())) {\r\n            ImageMiscOps.fillRectangle((GrayI16) input, (int) value, x0, y0, width, height);\r\n        } else if (GrayS32.class == input.getClass()) {\r\n            ImageMiscOps.fillRectangle((GrayS32) input, (int) value, x0, y0, width, height);\r\n        } else if (GrayS64.class == input.getClass()) {\r\n            ImageMiscOps.fillRectangle((GrayS64) input, (long) value, x0, y0, width, height);\r\n        } else if (GrayF32.class == input.getClass()) {\r\n            ImageMiscOps.fillRectangle((GrayF32) input, (float) value, x0, y0, width, height);\r\n        } else if (GrayF64.class == input.getClass()) {\r\n            ImageMiscOps.fillRectangle((GrayF64) input, value, x0, y0, width, height);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type: \" + input.getClass().getSimpleName());\r\n        }\r\n    } else if (input instanceof Planar) {\r\n        Planar m = (Planar) input;\r\n        for (int i = 0; i < m.getNumBands(); i++) fillRectangle(m.getBand(i), value, x0, y0, width, height);\r\n    } else if (input instanceof ImageInterleaved) {\r\n        if (InterleavedI8.class.isAssignableFrom(input.getClass())) {\r\n            ImageMiscOps.fillRectangle((InterleavedI8) input, (byte) value, x0, y0, width, height);\r\n        } else if (InterleavedI16.class.isAssignableFrom(input.getClass())) {\r\n            ImageMiscOps.fillRectangle((InterleavedI16) input, (short) value, x0, y0, width, height);\r\n        } else if (InterleavedS32.class == input.getClass()) {\r\n            ImageMiscOps.fillRectangle((InterleavedS32) input, (int) value, x0, y0, width, height);\r\n        } else if (InterleavedS64.class == input.getClass()) {\r\n            ImageMiscOps.fillRectangle((InterleavedS64) input, (long) value, x0, y0, width, height);\r\n        } else if (InterleavedF32.class == input.getClass()) {\r\n            ImageMiscOps.fillRectangle((InterleavedF32) input, (float) value, x0, y0, width, height);\r\n        } else if (InterleavedF64.class == input.getClass()) {\r\n            ImageMiscOps.fillRectangle((InterleavedF64) input, value, x0, y0, width, height);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type: \" + input.getClass().getSimpleName());\r\n        }\r\n    } else {\r\n        throw new IllegalArgumentException(\"Unknown image type: \" + input.getClass().getSimpleName());\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.EstimateSceneCalibrated.addUnvistedToStack",
	"Comment": "looks to see which connections have yet to be visited and adds them to the open list",
	"Method": "void addUnvistedToStack(View viewed,List<View> open){\r\n    for (int i = 0; i < viewed.connections.size(); i++) {\r\n        View other = viewed.connections.get(i).destination(viewed);\r\n        if (other.state == ViewState.UNPROCESSED) {\r\n            other.state = ViewState.PENDING;\r\n            open.add(other);\r\n            if (verbose != null)\r\n                verbose.println(\"  adding to open \" + viewed.index + \"->\" + other.index);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestDistortImageOps.boundBox_check",
	"Comment": "boundbox that checks to see if it is contained inside the output image.",
	"Method": "void boundBox_check(){\r\n    Affine2D_F32 affine = new Affine2D_F32(1, 0, 0, 1, 2, 3);\r\n    PixelTransformAffine_F32 transform = new PixelTransformAffine_F32(affine);\r\n    RectangleLength2D_I32 found = DistortImageOps.boundBox(10, 20, 30, 40, transform);\r\n    assertEquals(2, found.x0);\r\n    assertEquals(3, found.y0);\r\n    assertEquals(10, found.width);\r\n    assertEquals(20, found.height);\r\n    found = DistortImageOps.boundBox(10, 20, 8, 18, transform);\r\n    assertEquals(2, found.x0);\r\n    assertEquals(3, found.y0);\r\n    assertEquals(6, found.width);\r\n    assertEquals(15, found.height);\r\n    affine.set(new Affine2D_F32(1, 0, 0, 1, -2, -3));\r\n    found = DistortImageOps.boundBox(10, 20, 8, 18, transform);\r\n    assertEquals(0, found.x0);\r\n    assertEquals(0, found.y0);\r\n    assertEquals(8, found.width);\r\n    assertEquals(17, found.height);\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.getProjectPackages",
	"Comment": "get which packages should be considered part of your application.",
	"Method": "String[] getProjectPackages(){\r\n    return projectPackages;\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.DescribeDenseSiftAlg.setImageGradient",
	"Comment": "sets the gradient and precomputes pixel orientation and magnitude",
	"Method": "void setImageGradient(D derivX,D derivY){\r\n    InputSanityCheck.checkSameShape(derivX, derivY);\r\n    if (derivX.stride != derivY.stride || derivX.startIndex != derivY.startIndex)\r\n        throw new IllegalArgumentException(\"stride and start index must be the same\");\r\n    savedAngle.reshape(derivX.width, derivX.height);\r\n    savedMagnitude.reshape(derivX.width, derivX.height);\r\n    imageDerivX.wrap(derivX);\r\n    imageDerivY.wrap(derivY);\r\n    precomputeAngles(derivX);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.maximumDistance",
	"Comment": "finds the point in the contour which maximizes the distance between points a\tand b.",
	"Method": "int maximumDistance(List<Point2D_I32> contour,int indexA,int indexB){\r\n    Point2D_I32 a = contour.get(indexA);\r\n    Point2D_I32 b = contour.get(indexB);\r\n    int best = -1;\r\n    double bestDistance = -Double.MAX_VALUE;\r\n    for (int i = 0; i < contour.size(); i++) {\r\n        Point2D_I32 c = contour.get(i);\r\n        double d = distanceAbs(a, c) + distanceAbs(b, c);\r\n        if (d > bestDistance) {\r\n            bestDistance = d;\r\n            best = i;\r\n        }\r\n    }\r\n    return best;\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.ParamFundamentalEpipolar.encode",
	"Comment": "examines the matrix structure to determine how to parameterize f.",
	"Method": "void encode(DMatrixRMaj F,double[] param){\r\n    selectColumns(F);\r\n    double[] v = new double[] { F.get(0, col0), F.get(1, col0), F.get(2, col0), F.get(0, col1), F.get(1, col1), F.get(2, col1) };\r\n    double divisor = selectDivisor(v, param);\r\n    SimpleMatrix A = new SimpleMatrix(3, 2);\r\n    SimpleMatrix y = new SimpleMatrix(3, 1);\r\n    for (int i = 0; i < 3; i++) {\r\n        A.set(i, 0, v[i]);\r\n        A.set(i, 1, v[i + 3]);\r\n        y.set(i, 0, F.get(i, col2) / divisor);\r\n    }\r\n    SimpleMatrix x = A.solve(y);\r\n    param[5] = x.get(0);\r\n    param[6] = x.get(1);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.KltTracker.isDescriptionComplete",
	"Comment": "checks to see if the feature description is complete or if it was created by a feature partially\toutside the image",
	"Method": "boolean isDescriptionComplete(KltFeature feature){\r\n    for (int i = 0; i < lengthFeature; i++) {\r\n        if (Float.isNaN(feature.desc.data[i]))\r\n            return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.EssentialNister5.process",
	"Comment": "computes the essential matrix from point correspondences.",
	"Method": "boolean process(List<AssociatedPair> points,FastQueue<DMatrixRMaj> solutions){\r\n    if (points.size() != 5)\r\n        throw new IllegalArgumentException(\"Exactly 5 points are required, not \" + points.size());\r\n    solutions.reset();\r\n    computeSpan(points);\r\n    helper.setNullSpace(X, Y, Z, W);\r\n    helper.setupA1(A1);\r\n    helper.setupA2(A2);\r\n    solver.setA(A1);\r\n    solver.solve(A2, C);\r\n    helper.setDeterminantVectors(C);\r\n    helper.extractPolynomial(poly.getCoefficients());\r\n    if (!findRoots.process(poly))\r\n        return false;\r\n    for (Complex_F64 c : findRoots.getRoots()) {\r\n        if (!c.isReal())\r\n            continue;\r\n        solveForXandY(c.real);\r\n        DMatrixRMaj E = solutions.grow();\r\n        for (int i = 0; i < 9; i++) {\r\n            E.data[i] = x * X[i] + y * Y[i] + z * Z[i] + W[i];\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.simulation.SimulatePlanarWorld.computeProjectionTable",
	"Comment": "computes 3d pointing vector for every pixel in the simulated camera frame",
	"Method": "void computeProjectionTable(int width,int height){\r\n    output.reshape(width, height);\r\n    depthMap.reshape(width, height);\r\n    ImageMiscOps.fill(depthMap, -1);\r\n    pointing = new float[width * height * 3];\r\n    for (int y = 0; y < output.height; y++) {\r\n        for (int x = 0; x < output.width; x++) {\r\n            pixelTo3.compute(x, y, p3);\r\n            if (UtilEjml.isUncountable(p3.x)) {\r\n                depthMap.unsafe_set(x, y, Float.NaN);\r\n            } else {\r\n                pointing[(y * output.width + x) * 3] = (float) p3.x;\r\n                pointing[(y * output.width + x) * 3 + 1] = (float) p3.y;\r\n                pointing[(y * output.width + x) * 3 + 2] = (float) p3.z;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.DescribeSiftCommon.createGaussianWeightKernel",
	"Comment": "creates a gaussian weighting kernel with an even number of elements along its width",
	"Method": "float[] createGaussianWeightKernel(double sigma,int radius){\r\n    Kernel2D_F32 ker = FactoryKernelGaussian.gaussian2D_F32(sigma, radius, false, false);\r\n    float maxValue = KernelMath.maxAbs(ker.data, 4 * radius * radius);\r\n    KernelMath.divide(ker, maxValue);\r\n    return ker.data;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoPlaneInfinity.dropUnusedTracks",
	"Comment": "removes tracks which have not been included in the inlier set recently",
	"Method": "int dropUnusedTracks(){\r\n    List<PointTrack> all = tracker.getAllTracks(null);\r\n    int num = 0;\r\n    for (PointTrack t : all) {\r\n        VoTrack p = t.getCookie();\r\n        if (tick - p.lastInlier > thresholdRetire) {\r\n            tracker.dropTrack(t);\r\n            num++;\r\n        }\r\n    }\r\n    return num;\r\n}"
}, {
	"Path": "boofcv.abst.geo.bundle.SceneStructureMetric.getParameterCount",
	"Comment": "returns the total number of parameters which will be optimised",
	"Method": "int getParameterCount(){\r\n    return getUnknownViewCount() * 6 + points.length * pointSize + getUnknownCameraParameterCount();\r\n}"
}, {
	"Path": "com.bugsnag.android.ErrorStoreTest.setUp",
	"Comment": "generates a client and ensures that its errorstore has 0 files persisted",
	"Method": "void setUp(){\r\n    config = new Configuration(\"api-key\");\r\n    errorStore = new ErrorStore(config, InstrumentationRegistry.getContext());\r\n    assertNotNull(errorStore.storeDirectory);\r\n    errorStorageDir = new File(errorStore.storeDirectory);\r\n    FileUtils.clearFilesInDir(errorStorageDir);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setNullOnConnectionTimeout",
	"Comment": "sets the nullonconnectiontimeout.\tif true, return null on connection timeout rather than throw an exception. this performs\tbetter but must be handled differently in your application. this only\tmakes sense when using the connectiontimeout config option.",
	"Method": "void setNullOnConnectionTimeout(boolean nullOnConnectionTimeout){\r\n    this.nullOnConnectionTimeout = nullOnConnectionTimeout;\r\n}"
}, {
	"Path": "boofcv.alg.geo.TestPerspectiveOps.estimatePinhole",
	"Comment": "test using a known pinhole model which fits its assumptions perfectly",
	"Method": "void estimatePinhole(){\r\n    CameraPinhole expected = new CameraPinhole(500, 550, 0, 600, 700, 1200, 1400);\r\n    Point2Transform2_F64 pixelToNorm = new LensDistortionPinhole(expected).distort_F64(true, false);\r\n    CameraPinhole found = PerspectiveOps.estimatePinhole(pixelToNorm, expected.width, expected.height);\r\n    assertEquals(expected.fx, found.fx, UtilEjml.TEST_F64);\r\n    assertEquals(expected.fy, found.fy, UtilEjml.TEST_F64);\r\n    assertEquals(expected.cx, found.cx, UtilEjml.TEST_F64);\r\n    assertEquals(expected.cy, found.cy, UtilEjml.TEST_F64);\r\n    assertEquals(expected.skew, found.skew, UtilEjml.TEST_F64);\r\n    assertEquals(expected.width, found.width);\r\n    assertEquals(expected.height, found.height);\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.TestDescribePointBriefSO.changeInInputSize",
	"Comment": "change the input image size and see if it handles that case properly.",
	"Method": "void changeInInputSize(){\r\n    GrayF32 inputA = createImage(width, height);\r\n    GrayF32 inputB = createImage(width - 5, height - 5);\r\n    DescribePointBriefSO<GrayF32> alg = createAlg();\r\n    TupleDesc_B desc = alg.createFeature();\r\n    alg.setImage(inputA);\r\n    alg.process(inputA.width / 2, inputA.height / 2, 0, briefRadius, desc);\r\n    alg.setImage(inputB);\r\n    alg.process(inputA.width / 2, inputA.height / 2, 0, briefRadius, desc);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.EllipseClustersIntoHexagonalGrid.selectClosest",
	"Comment": "finds the closest that is the same distance from the two nodes and part of an approximate equilateral triangle",
	"Method": "Edge selectClosest(NodeInfo a,NodeInfo b,boolean checkSide){\r\n    double bestScore = Double.MAX_VALUE;\r\n    Edge bestEdgeA = null;\r\n    Edge edgeAB = a.findEdge(b);\r\n    double distAB = a.distance(b);\r\n    if (edgeAB == null) {\r\n        return null;\r\n    }\r\n    for (int i = 0; i < a.edges.size; i++) {\r\n        Edge edgeA = a.edges.get(i);\r\n        NodeInfo aa = a.edges.get(i).target;\r\n        if (aa.marked)\r\n            continue;\r\n        for (int j = 0; j < b.edges.size; j++) {\r\n            Edge edgeB = b.edges.get(j);\r\n            NodeInfo bb = b.edges.get(j).target;\r\n            if (bb.marked)\r\n                continue;\r\n            if (aa == bb) {\r\n                if (checkSide && UtilAngle.distanceCW(edgeAB.angle, edgeA.angle) > Math.PI * 0.75)\r\n                    continue;\r\n                double angle = UtilAngle.dist(edgeA.angle, edgeB.angle);\r\n                if (angle < 0.3)\r\n                    continue;\r\n                double da = EllipsesIntoClusters.axisAdjustedDistanceSq(a.ellipse, aa.ellipse);\r\n                double db = EllipsesIntoClusters.axisAdjustedDistanceSq(b.ellipse, aa.ellipse);\r\n                da = Math.sqrt(da);\r\n                db = Math.sqrt(db);\r\n                double diffRatio = Math.abs(da - db) / Math.max(da, db);\r\n                if (diffRatio > 0.3)\r\n                    continue;\r\n                double d = (da + db) / distAB + 0.1 * angle;\r\n                if (d < bestScore) {\r\n                    bestScore = d;\r\n                    bestEdgeA = a.edges.get(i);\r\n                }\r\n                break;\r\n            }\r\n        }\r\n    }\r\n    return bestEdgeA;\r\n}"
}, {
	"Path": "boofcv.alg.distort.pinhole.TestPinholePtoN_F64.basic",
	"Comment": "do the same calculation but using a different but equivalent equation",
	"Method": "void basic(){\r\n    PinholePtoN_F64 alg = new PinholePtoN_F64();\r\n    alg.set(fx, fy, skew, x_c, y_c);\r\n    Point2D_F64 in = new Point2D_F64(100, 120);\r\n    Point2D_F64 out = new Point2D_F64();\r\n    alg.compute(in.x, in.y, out);\r\n    Point2D_F64 expected = new Point2D_F64();\r\n    DMatrixRMaj K_inv = new DMatrixRMaj(3, 3, true, fx, skew, x_c, 0, fy, y_c, 0, 0, 1);\r\n    CommonOps_DDRM.invert(K_inv);\r\n    GeometryMath_F64.mult(K_inv, in, expected);\r\n    assertEquals(expected.x, out.x, 1e-5);\r\n    assertEquals(expected.y, out.y, 1e-5);\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapObjectConversion.toMapWithType",
	"Comment": "this could be refactored to use core.typetype class and it would run faster.converts an object into a map",
	"Method": "Map<String, Object> toMapWithType(Object object){\r\n    return mapperWithType.toMap(object);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.EstimateSceneCalibrated.triangulateStereoEdges",
	"Comment": "an edge has been declared as defining a good stereo pair. all associated feature will now be\ttriangulated. it is assumed that there is no global coordinate system at this point.",
	"Method": "void triangulateStereoEdges(Motion edge){\r\n    View viewA = edge.viewSrc;\r\n    View viewB = edge.viewDst;\r\n    triangulationError.configure(viewA.camera.pinhole, viewB.camera.pinhole);\r\n    for (int i = 0; i < edge.associated.size(); i++) {\r\n        AssociatedIndex f = edge.associated.get(i);\r\n        Point2D_F64 normA = viewA.observationNorm.get(f.src);\r\n        Point2D_F64 normB = viewB.observationNorm.get(f.dst);\r\n        double angle = triangulationAngle(normA, normB, edge.a_to_b);\r\n        if (angle < TRIANGULATE_MIN_ANGLE)\r\n            continue;\r\n        Feature3D feature3D = new Feature3D();\r\n        if (!triangulate.triangulate(normA, normB, edge.a_to_b, feature3D.worldPt)) {\r\n            continue;\r\n        }\r\n        if (feature3D.worldPt.z <= 0)\r\n            continue;\r\n        double error = triangulationError.process(normA, normB, edge.a_to_b, feature3D.worldPt);\r\n        if (error > maxPixelError * maxPixelError)\r\n            continue;\r\n        feature3D.views.add(viewA);\r\n        feature3D.views.add(viewB);\r\n        feature3D.obsIdx.add(f.src);\r\n        feature3D.obsIdx.add(f.dst);\r\n        feature3D.triangulationAngle = angle;\r\n        edge.stereoTriangulations.add(feature3D);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TrifocalExtractGeometries.setTensor",
	"Comment": "specifies the input tensor. the epipoles are immediately extracted since they\tare needed to extract all other data structures",
	"Method": "void setTensor(TrifocalTensor tensor){\r\n    this.tensor = tensor;\r\n    if (!svd.decompose(tensor.T1))\r\n        throw new RuntimeException(\"SVD failed?!\");\r\n    SingularOps_DDRM.nullVector(svd, true, v1);\r\n    SingularOps_DDRM.nullVector(svd, false, u1);\r\n    if (!svd.decompose(tensor.T2))\r\n        throw new RuntimeException(\"SVD failed?!\");\r\n    SingularOps_DDRM.nullVector(svd, true, v2);\r\n    SingularOps_DDRM.nullVector(svd, false, u2);\r\n    if (!svd.decompose(tensor.T3))\r\n        throw new RuntimeException(\"SVD failed?!\");\r\n    SingularOps_DDRM.nullVector(svd, true, v3);\r\n    SingularOps_DDRM.nullVector(svd, false, u3);\r\n    for (int i = 0; i < 3; i++) {\r\n        U.set(i, 0, u1.get(i));\r\n        U.set(i, 1, u2.get(i));\r\n        U.set(i, 2, u3.get(i));\r\n        V.set(i, 0, v1.get(i));\r\n        V.set(i, 1, v2.get(i));\r\n        V.set(i, 2, v3.get(i));\r\n    }\r\n    svd.decompose(U);\r\n    SingularOps_DDRM.nullVector(svd, false, tempE);\r\n    e2.set(tempE.get(0), tempE.get(1), tempE.get(2));\r\n    svd.decompose(V);\r\n    SingularOps_DDRM.nullVector(svd, false, tempE);\r\n    e3.set(tempE.get(0), tempE.get(1), tempE.get(2));\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.LocalWeightedHistogramRotRect.squareToImageSample",
	"Comment": "converts a point from square coordinates into image coordinates",
	"Method": "void squareToImageSample(float x,float y,RectangleRotate_F32 region){\r\n    x *= region.width - 1;\r\n    y *= region.height - 1;\r\n    imageX = x * c - y * s + region.cx;\r\n    imageY = x * s + y * c + region.cy;\r\n}"
}, {
	"Path": "boofcv.app.calib.AssistedCalibration.captureFiducialPoints",
	"Comment": "record the area covered in the image by the fiducial, update the quality calculation, and see if it should\tenable the save button.",
	"Method": "void captureFiducialPoints(){\r\n    Polygon2D_F64 p = regions.grow();\r\n    p.vertexes.resize(sidesCollision.size());\r\n    for (int i = 0; i < sidesCollision.size(); i++) {\r\n        p.get(i).set(sidesCollision.get(i));\r\n    }\r\n    quality.addObservations(detector.getDetectedPoints());\r\n    gui.getInfoPanel().updateGeometry(quality.getScore());\r\n    geometryTrigger |= quality.getScore() >= 1.0;\r\n    if (geometryTrigger && magnets.isEmpty()) {\r\n        gui.getInfoPanel().enabledFinishedButton();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.StitchingFromMotion2D.getWorldToCurr",
	"Comment": "transform from world coordinate system into the current image frame.",
	"Method": "Homography2D_F64 getWorldToCurr(Homography2D_F64 storage,IT getWorldToCurr){\r\n    return worldToCurr;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.SfmTestHelper.renderPointPixel",
	"Comment": "renders a 3d point in the left and right camera views given the stereo parameters. lens distortion\tis taken in account.",
	"Method": "void renderPointPixel(StereoParameters param,Point3D_F64 X,Point2D_F64 left,Point2D_F64 right){\r\n    Point3D_F64 rightX = new Point3D_F64();\r\n    SePointOps_F64.transform(param.getRightToLeft().invert(null), X, rightX);\r\n    Point2D_F64 normLeft = new Point2D_F64(X.x / X.z, X.y / X.z);\r\n    Point2D_F64 normRight = new Point2D_F64(rightX.x / rightX.z, rightX.y / rightX.z);\r\n    Point2D_F64 pixelLeft = PerspectiveOps.convertNormToPixel(param.left, normLeft.x, normLeft.y, null);\r\n    Point2D_F64 pixelRight = PerspectiveOps.convertNormToPixel(param.right, normRight.x, normRight.y, null);\r\n    Point2Transform2_F32 distLeft = LensDistortionOps.narrow(param.left).distort_F32(true, true);\r\n    Point2Transform2_F32 distRight = LensDistortionOps.narrow(param.right).distort_F32(true, true);\r\n    Point2D_F32 lensLeft = new Point2D_F32();\r\n    Point2D_F32 lensRight = new Point2D_F32();\r\n    distLeft.compute((float) pixelLeft.x, (float) pixelLeft.y, lensLeft);\r\n    distRight.compute((float) pixelRight.x, (float) pixelRight.y, lensRight);\r\n    left.set(lensLeft.x, lensLeft.y);\r\n    right.set(lensRight.x, lensRight.y);\r\n}"
}, {
	"Path": "boofcv.abst.geo.f.CheckEstimateNofEpipolar.checkConstraint",
	"Comment": "make sure the ordering of the epipolar constraint is computed correctly",
	"Method": "void checkConstraint(){\r\n    init(50, isPixels);\r\n    boolean workedOnce = false;\r\n    FastQueue<DMatrixRMaj> solutions = new QueueMatrix(3, 3);\r\n    for (int i = 0; i < 10; i++) {\r\n        List<AssociatedPair> pairs = randomPairs(alg.getMinimumPoints());\r\n        if (!alg.process(pairs, solutions)) {\r\n            continue;\r\n        }\r\n        if (solutions.size() <= 0)\r\n            continue;\r\n        workedOnce = true;\r\n        for (DMatrixRMaj F : solutions.toList()) {\r\n            double n = CommonOps_DDRM.elementMaxAbs(F);\r\n            CommonOps_DDRM.scale(1.0 / n, F);\r\n            for (AssociatedPair p : pairs) {\r\n                double correct = Math.abs(GeometryMath_F64.innerProd(p.p2, F, p.p1));\r\n                double wrong = Math.abs(GeometryMath_F64.innerProd(p.p1, F, p.p2));\r\n                assertTrue(correct < wrong * 0.001);\r\n            }\r\n        }\r\n    }\r\n    assertTrue(workedOnce);\r\n}"
}, {
	"Path": "boofcv.examples.features.ExampleTemplateMatching.showMatchIntensity",
	"Comment": "computes the template match intensity image and displays the results. brighter intensity indicates\ta better match to the template.",
	"Method": "void showMatchIntensity(GrayF32 image,GrayF32 template,GrayF32 mask){\r\n    TemplateMatchingIntensity<GrayF32> matchIntensity = FactoryTemplateMatching.createIntensity(TemplateScoreType.SUM_DIFF_SQ, GrayF32.class);\r\n    matchIntensity.setInputImage(image);\r\n    matchIntensity.process(template, mask);\r\n    GrayF32 intensity = matchIntensity.getIntensity();\r\n    float min = ImageStatistics.min(intensity);\r\n    float max = ImageStatistics.max(intensity);\r\n    float range = max - min;\r\n    PixelMath.plus(intensity, -min, intensity);\r\n    PixelMath.divide(intensity, range, intensity);\r\n    PixelMath.multiply(intensity, 255.0f, intensity);\r\n    BufferedImage output = new BufferedImage(image.width, image.height, BufferedImage.TYPE_INT_BGR);\r\n    VisualizeImageData.grayMagnitude(intensity, output, -1);\r\n    ShowImages.showWindow(output, \"Match Intensity\", true);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.QuadPoseEstimator.estimate",
	"Comment": "given the observed corners of the quad in the image in pixels estimate and store the results\tof its pose",
	"Method": "boolean estimate(Quadrilateral_F64 cornersPixels,Quadrilateral_F64 cornersNorm,Se3_F64 foundFiducialToCamera){\r\n    listObs.clear();\r\n    listObs.add(cornersPixels.a);\r\n    listObs.add(cornersPixels.b);\r\n    listObs.add(cornersPixels.c);\r\n    listObs.add(cornersPixels.d);\r\n    points.get(0).observation.set(cornersNorm.a);\r\n    points.get(1).observation.set(cornersNorm.b);\r\n    points.get(2).observation.set(cornersNorm.c);\r\n    points.get(3).observation.set(cornersNorm.d);\r\n    bestError = Double.MAX_VALUE;\r\n    estimateP3P(0);\r\n    estimateP3P(1);\r\n    estimateP3P(2);\r\n    estimateP3P(3);\r\n    if (bestError == Double.MAX_VALUE)\r\n        return false;\r\n    inputP3P.clear();\r\n    for (int i = 0; i < 4; i++) {\r\n        inputP3P.add(points.get(i));\r\n    }\r\n    if (bestError > 2) {\r\n        if (epnp.process(inputP3P, foundEPNP)) {\r\n            if (foundEPNP.T.z > 0) {\r\n                double error = computeErrors(foundEPNP);\r\n                if (error < bestError) {\r\n                    bestPose.set(foundEPNP);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    if (!refine.fitModel(inputP3P, bestPose, foundFiducialToCamera)) {\r\n        foundFiducialToCamera.set(bestPose);\r\n        return true;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "com.bugsnag.android.Bugsnag.setUserEmail",
	"Comment": "set the email address of the current user.you can search for this information in your bugsnag dashboard.",
	"Method": "void setUserEmail(String email){\r\n    getClient().setUserEmail(email);\r\n}"
}, {
	"Path": "org.boon.validation.readers.AnnotationValidatorMetaDataReader.convertAnnotationDataToValidatorMetaData",
	"Comment": "converts an annotationdata into a validatormetadata pojo.",
	"Method": "ValidatorMetaData convertAnnotationDataToValidatorMetaData(AnnotationData annotationData){\r\n    ValidatorMetaData metaData = new ValidatorMetaData();\r\n    metaData.setName(annotationData.getName());\r\n    metaData.setProperties(annotationData.getValues());\r\n    return metaData;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionHandle.testClose",
	"Comment": "closing a connection handle should release that connection back in the pool and mark it as closed.",
	"Method": "void testClose(){\r\n    this.testClass.doubleCloseCheck = true;\r\n    Connection mockInternalConnection = EasyMock.createNiceMock(Connection.class);\r\n    this.testClass.setInternalConnection(mockInternalConnection);\r\n    this.testClass.renewConnection();\r\n    this.mockPool.releaseConnection((Connection) anyObject());\r\n    expectLastCall().once().andThrow(new SQLException()).once();\r\n    expect(this.mockPool.getFinalizableRefs()).andReturn(new HashMap<Connection, Reference<ConnectionHandle>>()).anyTimes();\r\n    expect(this.mockPool.getConfig()).andReturn(this.config).anyTimes();\r\n    expect(mockInternalConnection.isClosed()).andReturn(false).anyTimes();\r\n    replay(this.mockPool, mockInternalConnection);\r\n    Thread testThread = new Thread(new Runnable() {\r\n        public void run() {\r\n            try {\r\n                TestConnectionHandle.this.started = true;\r\n                while (true) {\r\n                    Thread.sleep(20);\r\n                }\r\n            } catch (Exception e) {\r\n                TestConnectionHandle.this.interrupted = true;\r\n            }\r\n        }\r\n    });\r\n    testThread.start();\r\n    while (!this.started) {\r\n        Thread.sleep(20);\r\n    }\r\n    this.testClass.setThreadWatch(testThread);\r\n    this.testClass.close();\r\n    testThread.join();\r\n    assertTrue(this.interrupted);\r\n    Assert.assertTrue(this.testClass.logicallyClosed.get());\r\n    assertTrue(this.testClass.isClosed());\r\n    this.testClass.renewConnection();\r\n    try {\r\n        this.testClass.close();\r\n        fail(\"Should have thrown an exception\");\r\n    } catch (Throwable t) {\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionHandle.testClose",
	"Comment": "closing a connection handle should release that connection back in the pool and mark it as closed.",
	"Method": "void testClose(){\r\n    try {\r\n        TestConnectionHandle.this.started = true;\r\n        while (true) {\r\n            Thread.sleep(20);\r\n        }\r\n    } catch (Exception e) {\r\n        TestConnectionHandle.this.interrupted = true;\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.filter.transform.fft.GenericTestDiscreteFourierTransform.inputImageSize",
	"Comment": "makes sure it only accepts images which are the correct size",
	"Method": "void inputImageSize(){\r\n    int width = 20;\r\n    int height = 25;\r\n    T input = createImage(width, height);\r\n    DiscreteFourierTransform<T, I> alg = createAlgorithm();\r\n    try {\r\n        alg.forward(input, createTransform(width - 1, height));\r\n        fail(\"Should have thrown an exception\");\r\n    } catch (IllegalArgumentException ignore) {\r\n    }\r\n    try {\r\n        alg.inverse(createTransform(width - 1, height), input);\r\n        fail(\"Should have thrown an exception\");\r\n    } catch (IllegalArgumentException ignore) {\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.MultiViewOps.homographyStereo2Lines",
	"Comment": "computes the homography induced from a planar surface when viewed from two views using correspondences\tof two lines. observations must be on the planar surface.",
	"Method": "DMatrixRMaj homographyStereo2Lines(DMatrixRMaj F,PairLineNorm line0,PairLineNorm line1){\r\n    HomographyInducedStereo2Line alg = new HomographyInducedStereo2Line();\r\n    alg.setFundamental(F, null);\r\n    if (!alg.process(line0, line1))\r\n        return null;\r\n    return alg.getHomography();\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.TestCannyEdge.canHandleNoTexture_and_zeroThresh",
	"Comment": "image has no texture and the sadistic user and specified a threshold of zero.everything should\tbe an edge.",
	"Method": "void canHandleNoTexture_and_zeroThresh(){\r\n    GrayU8 input = new GrayU8(width, height);\r\n    GrayU8 output = new GrayU8(width, height);\r\n    CannyEdge<GrayU8, GrayS16> alg = createCanny(true);\r\n    alg.process(input, 0, 0, output);\r\n    List<EdgeContour> contour = alg.getContours();\r\n    assertTrue(contour.size() > 0);\r\n    int numEdgePixels = 0;\r\n    for (EdgeContour e : contour) {\r\n        for (EdgeSegment s : e.segments) {\r\n            numEdgePixels += s.points.size();\r\n        }\r\n    }\r\n    assertEquals(numEdgePixels, input.width * input.height);\r\n    for (int i = 0; i < output.data.length; i++) assertEquals(1, output.data[i]);\r\n}"
}, {
	"Path": "org.boon.core.reflection.Reflection.getPropertyFieldAccessMapFieldFirst",
	"Comment": "gets a list of fields merges with properties if field is not found.",
	"Method": "Map<String, FieldAccess> getPropertyFieldAccessMapFieldFirst(Class<?> clazz){\r\n    Map<String, FieldAccess> combinedFieldsFieldFirst = getCombinedFieldsFieldFirst(clazz);\r\n    if (combinedFieldsFieldFirst != null) {\r\n        return combinedFieldsFieldFirst;\r\n    } else {\r\n        Map<String, FieldAccess> fieldsFallbacks = null;\r\n        Map<String, FieldAccess> fieldsPrimary = null;\r\n        fieldsPrimary = Reflection.getAllAccessorFields(clazz, true);\r\n        fieldsFallbacks = Reflection.getPropertyFieldAccessors(clazz);\r\n        combineFieldMaps(fieldsFallbacks, fieldsPrimary);\r\n        combinedFieldsFieldFirst = fieldsPrimary;\r\n        putCombinedFieldsFieldFirst(clazz, combinedFieldsFieldFirst);\r\n        return combinedFieldsFieldFirst;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.TestMinimizeEnergyPrune.prune_obvious",
	"Comment": "adds an obviously redundant corner and see if it gets removed",
	"Method": "void prune_obvious(){\r\n    List<Point2D_I32> contours = createSquare(10, 12, 20, 30);\r\n    GrowQueue_I32 corners = createSquareCorners(10, 12, 20, 30);\r\n    corners.add(corners.get(3) + 4);\r\n    MinimizeEnergyPrune alg = new MinimizeEnergyPrune(1);\r\n    GrowQueue_I32 output = new GrowQueue_I32();\r\n    alg.prune(contours, corners, output);\r\n    assertEquals(4, output.size());\r\n    checkMatched(corners, output);\r\n}"
}, {
	"Path": "boofcv.abst.feature.detdesc.GenericTestsDetectDescribeMulti.checkMultipleCalls",
	"Comment": "make sure everything has been reset correctly and that multiple calls to the same input\tproduce the same output",
	"Method": "void checkMultipleCalls(){\r\n    DetectDescribeMulti<T, TD> alg1 = createDetDesc();\r\n    DetectDescribeMulti<T, TD> alg2 = createDetDesc();\r\n    alg1.process(image);\r\n    alg1.process(image);\r\n    alg2.process(image);\r\n    checkIdenticalResponse(alg1, alg2);\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.watershed.WatershedVincentSoille1991.sortPixels",
	"Comment": "very fast histogram based sorting.index of each pixel is placed inside a list for its intensity level.",
	"Method": "void sortPixels(GrayU8 input){\r\n    for (int i = 0; i < histogram.length; i++) {\r\n        histogram[i].reset();\r\n    }\r\n    for (int y = 0; y < input.height; y++) {\r\n        int index = input.startIndex + y * input.stride;\r\n        int indexOut = (y + 1) * output.stride + 1;\r\n        for (int x = 0; x < input.width; x++, index++, indexOut++) {\r\n            int value = input.data[index] & 0xFF;\r\n            histogram[value].add(indexOut);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.selfcalib.SelfCalibrationLinearRotationSingle.extractCalibration",
	"Comment": "extracts camera parameters from the solution. checks for errors",
	"Method": "boolean extractCalibration(DMatrixRMaj x,CameraPinhole calibration){\r\n    double s = x.data[5];\r\n    double cx = calibration.cx = x.data[2] / s;\r\n    double cy = calibration.cy = x.data[4] / s;\r\n    double fy = calibration.fy = Math.sqrt(x.data[3] / s - cy * cy);\r\n    double sk = calibration.skew = (x.data[1] / s - cx * cy) / fy;\r\n    calibration.fx = Math.sqrt(x.data[0] / s - sk * sk - cx * cx);\r\n    if (calibration.fx < 0 || calibration.fy < 0)\r\n        return false;\r\n    if (UtilEjml.isUncountable(fy) || UtilEjml.isUncountable(calibration.fx))\r\n        return false;\r\n    if (UtilEjml.isUncountable(sk))\r\n        return false;\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.SnapToEllipseEdge.process",
	"Comment": "refines provided list by snapping it to edges found in the image",
	"Method": "boolean process(EllipseRotated_F64 input,EllipseRotated_F64 refined){\r\n    refined.set(input);\r\n    previous.set(input);\r\n    for (int iteration = 0; iteration < maxIterations; iteration++) {\r\n        refined.set(previous);\r\n        computePointsAndWeights(refined);\r\n        if (fitter.process(samplePts.toList(), weights.data)) {\r\n            UtilEllipse_F64.convert(fitter.getEllipse(), refined);\r\n            double scale = previous.a;\r\n            refined.center.x = refined.center.x * scale + previous.center.x;\r\n            refined.center.y = refined.center.y * scale + previous.center.y;\r\n            refined.a *= scale;\r\n            refined.b *= scale;\r\n        } else {\r\n            return false;\r\n        }\r\n        if (change(previous, refined) <= convergenceTol) {\r\n            return true;\r\n        } else {\r\n            previous.set(refined);\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.UtilLepetitEPnP.constraintMatrix3x3a",
	"Comment": "extracts the linear constraint matrix for case 1 from the full 6x10 constraint matrix.",
	"Method": "void constraintMatrix3x3a(DMatrixRMaj L_3x6,DMatrixRMaj L_3x3){\r\n    int index = 0;\r\n    for (int i = 0; i < 3; i++) {\r\n        L_3x3.data[index++] = L_3x6.get(i, 0);\r\n        L_3x3.data[index++] = L_3x6.get(i, 1);\r\n        L_3x3.data[index++] = L_3x6.get(i, 2);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.MinimizeEnergyPrune.prune",
	"Comment": "given a contour and initial set of corners compute a new set of corner indexes",
	"Method": "boolean prune(List<Point2D_I32> contour,GrowQueue_I32 input,GrowQueue_I32 output){\r\n    this.contour = contour;\r\n    output.setTo(input);\r\n    removeDuplicates(output);\r\n    if (output.size() <= 3)\r\n        return false;\r\n    computeSegmentEnergy(output);\r\n    double total = 0;\r\n    for (int i = 0; i < output.size(); i++) {\r\n        total += energySegment[i];\r\n    }\r\n    FitLinesToContour fit = new FitLinesToContour();\r\n    fit.setContour(contour);\r\n    boolean modified = false;\r\n    while (output.size() > 3) {\r\n        double bestEnergy = total;\r\n        boolean betterFound = false;\r\n        bestCorners.reset();\r\n        for (int i = 0; i < output.size(); i++) {\r\n            workCorners1.reset();\r\n            for (int j = 0; j < output.size(); j++) {\r\n                if (i != j) {\r\n                    workCorners1.add(output.get(j));\r\n                }\r\n            }\r\n            removeDuplicates(workCorners1);\r\n            if (workCorners1.size() > 3) {\r\n                int anchor0 = CircularIndex.addOffset(i, -2, workCorners1.size());\r\n                int anchor1 = CircularIndex.addOffset(i, 1, workCorners1.size());\r\n                if (fit.fitAnchored(anchor0, anchor1, workCorners1, workCorners2)) {\r\n                    double score = 0;\r\n                    for (int j = 0, k = workCorners2.size() - 1; j < workCorners2.size(); k = j, j++) {\r\n                        score += computeSegmentEnergy(workCorners2, k, j);\r\n                    }\r\n                    if (score < bestEnergy) {\r\n                        betterFound = true;\r\n                        bestEnergy = score;\r\n                        bestCorners.reset();\r\n                        bestCorners.addAll(workCorners2);\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        if (betterFound) {\r\n            modified = true;\r\n            total = bestEnergy;\r\n            output.setTo(bestCorners);\r\n        } else {\r\n            break;\r\n        }\r\n    }\r\n    return modified;\r\n}"
}, {
	"Path": "boofcv.alg.misc.GImageStatistics.meanDiffSq",
	"Comment": "computes the mean of the difference squared between the two images.",
	"Method": "double meanDiffSq(T inputA,T inputB){\r\n    if (inputA instanceof ImageGray) {\r\n        if (GrayU8.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((GrayU8) inputA, (GrayU8) inputB);\r\n        } else if (GrayS8.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((GrayS8) inputA, (GrayS8) inputB);\r\n        } else if (GrayU16.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((GrayU16) inputA, (GrayU16) inputB);\r\n        } else if (GrayS16.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((GrayS16) inputA, (GrayS16) inputB);\r\n        } else if (GrayS32.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((GrayS32) inputA, (GrayS32) inputB);\r\n        } else if (GrayS64.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((GrayS64) inputA, (GrayS64) inputB);\r\n        } else if (GrayF32.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((GrayF32) inputA, (GrayF32) inputB);\r\n        } else if (GrayF64.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((GrayF64) inputA, (GrayF64) inputB);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type\");\r\n        }\r\n    } else if (inputA instanceof ImageInterleaved) {\r\n        if (InterleavedU8.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((InterleavedU8) inputA, (InterleavedU8) inputB);\r\n        } else if (InterleavedS8.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((InterleavedS8) inputA, (InterleavedS8) inputB);\r\n        } else if (InterleavedU16.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((InterleavedU16) inputA, (InterleavedU16) inputB);\r\n        } else if (InterleavedS16.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((InterleavedS16) inputA, (InterleavedS16) inputB);\r\n        } else if (InterleavedS32.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((InterleavedS32) inputA, (InterleavedS32) inputB);\r\n        } else if (InterleavedS64.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((InterleavedS64) inputA, (InterleavedS64) inputB);\r\n        } else if (InterleavedF32.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((InterleavedF32) inputA, (InterleavedF32) inputB);\r\n        } else if (InterleavedF64.class == inputA.getClass()) {\r\n            return ImageStatistics.meanDiffSq((InterleavedF64) inputA, (InterleavedF64) inputB);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Unknown image Type\");\r\n        }\r\n    } else {\r\n        throw new IllegalArgumentException(\"Planar images needs to be added\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.feature.detdesc.GenericTestsDetectDescribePoint.failBandMissMatch",
	"Comment": "see if a sanity check is performed for color images. the bands must match",
	"Method": "void failBandMissMatch(){\r\n    if (!(image instanceof ImageMultiBand)) {\r\n        return;\r\n    }\r\n    ImageMultiBand mb = (ImageMultiBand) image;\r\n    ImageMultiBand bad = (ImageMultiBand) mb.createSameShape();\r\n    bad.setNumberOfBands(mb.getNumBands() + 1);\r\n    DetectDescribePoint<T, D> alg = createDetDesc();\r\n    try {\r\n        alg.detect((T) bad);\r\n        fail(\"Should have thrown an exception\");\r\n    } catch (IllegalArgumentException ignore) {\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.TestDescribePointSurfPlanar.compareToSingleBand",
	"Comment": "computes the descriptor inside a random image.sees if it has the expected results by comparing it to\tthe single band algorithm which it uses internally.",
	"Method": "void compareToSingleBand(){\r\n    Planar<GrayF32> input = new Planar(GrayF32.class, width, height, 3);\r\n    GImageMiscOps.addUniform(input, rand, 0, 200);\r\n    DescribePointSurf<GrayF32> desc = new DescribePointSurf(GrayF32.class);\r\n    DescribePointSurfPlanar<GrayF32> alg = new DescribePointSurfPlanar(desc, 3);\r\n    GrayF32 gray = ConvertImage.average(input, null);\r\n    alg.setImage(gray, input);\r\n    for (int i = 0; i < 100; i++) {\r\n        double x = rand.nextDouble() * width;\r\n        double y = rand.nextDouble() * height;\r\n        double angle = rand.nextDouble() * Math.PI * 2;\r\n        double scale = rand.nextDouble() * 10 + 0.9;\r\n        BrightFeature found = alg.createDescription();\r\n        alg.describe(x, y, angle, scale, found);\r\n        desc.setImage(gray);\r\n        boolean expectedLaplace = desc.computeLaplaceSign((int) (x + 0.5), (int) (y + 0.5), scale);\r\n        assertEquals(expectedLaplace, found.white);\r\n        BrightFeature expected = desc.createDescription();\r\n        for (int b = 0; b < 3; b++) {\r\n            desc.setImage(input.getBand(b));\r\n            desc.describe(x, y, angle, scale, expected);\r\n            double norm = 0;\r\n            for (int j = 0; j < expected.size(); j++) {\r\n                double v = found.getDouble(j + b * expected.size());\r\n                norm += v * v;\r\n            }\r\n            norm = Math.sqrt(norm);\r\n            for (int j = 0; j < expected.size(); j++) {\r\n                assertEquals(expected.getDouble(j), found.getDouble(j + b * expected.size()) / norm, 1e-8);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TrifocalExtractGeometries.extractEpipoles",
	"Comment": "extracts the epipoles from the trifocal tensor.extracted epipoles will have a norm of 1\tas an artifact of using svd.",
	"Method": "void extractEpipoles(Point3D_F64 e2,Point3D_F64 e3){\r\n    e2.set(this.e2);\r\n    e3.set(this.e3);\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.OrientationHistogramSift.interpolateAngle",
	"Comment": "given the interpolated index, compute the angle from the 3 indexes.the angle for each index\tis computed from the weighted gradients.",
	"Method": "double interpolateAngle(int index0,int index1,int index2,double offset){\r\n    double angle1 = Math.atan2(histogramY[index1], histogramX[index1]);\r\n    double deltaAngle;\r\n    if (offset < 0) {\r\n        double angle0 = Math.atan2(histogramY[index0], histogramX[index0]);\r\n        deltaAngle = UtilAngle.dist(angle0, angle1);\r\n    } else {\r\n        double angle2 = Math.atan2(histogramY[index2], histogramX[index2]);\r\n        deltaAngle = UtilAngle.dist(angle2, angle1);\r\n    }\r\n    return UtilAngle.bound(angle1 + deltaAngle * offset);\r\n}"
}, {
	"Path": "boofcv.gui.feature.VisualizeRegions.regionBorders",
	"Comment": "draws border pixels of each region using the specified color.",
	"Method": "BufferedImage regionBorders(GrayS32 pixelToRegion,int borderColor,BufferedImage output){\r\n    if (output == null)\r\n        output = new BufferedImage(pixelToRegion.width, pixelToRegion.height, BufferedImage.TYPE_INT_RGB);\r\n    GrayU8 binary = new GrayU8(pixelToRegion.width, pixelToRegion.height);\r\n    ImageSegmentationOps.markRegionBorders(pixelToRegion, binary);\r\n    for (int y = 0; y < binary.height; y++) {\r\n        for (int x = 0; x < binary.width; x++) {\r\n            if (binary.unsafe_get(x, y) == 1) {\r\n                output.setRGB(x, y, borderColor);\r\n            }\r\n        }\r\n    }\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.alg.geo.impl.ImplRectifyImageOps_F64.adjustCalibrated",
	"Comment": "internal function which applies the rectification adjustment to a calibrated stereo pair",
	"Method": "void adjustCalibrated(DMatrixRMaj rectifyLeft,DMatrixRMaj rectifyRight,DMatrixRMaj rectifyK,RectangleLength2D_F64 bound,double scale){\r\n    double deltaX = -bound.x0 * scale;\r\n    double deltaY = -bound.y0 * scale;\r\n    SimpleMatrix A = new SimpleMatrix(3, 3, true, new double[] { scale, 0, deltaX, 0, scale, deltaY, 0, 0, 1 });\r\n    SimpleMatrix rL = SimpleMatrix.wrap(rectifyLeft);\r\n    SimpleMatrix rR = SimpleMatrix.wrap(rectifyRight);\r\n    SimpleMatrix K = SimpleMatrix.wrap(rectifyK);\r\n    SimpleMatrix K_inv = K.invert();\r\n    rL = K_inv.mult(rL);\r\n    rR = K_inv.mult(rR);\r\n    K = A.mult(K);\r\n    rectifyK.set(K.getDDRM());\r\n    rectifyLeft.set(K.mult(rL).getDDRM());\r\n    rectifyRight.set(K.mult(rR).getDDRM());\r\n}"
}, {
	"Path": "com.bugsnag.android.Bugsnag.setAutoCaptureSessions",
	"Comment": "sets whether or not bugsnag should automatically capture and report user sessions wheneverthe app enters the foreground.by default this behavior is disabled.",
	"Method": "void setAutoCaptureSessions(boolean autoCapture){\r\n    getClient().setAutoCaptureSessions(autoCapture);\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TestTrifocalLinearPoint7.checkLinearSystem",
	"Comment": "check the linear constraint matrix by seeing if the correct solution is in the null space",
	"Method": "void checkLinearSystem(){\r\n    TrifocalLinearPoint7 alg = new TrifocalLinearPoint7();\r\n    alg.N1 = new NormalizationPoint2D(0, 1, 0, 1);\r\n    alg.N2 = new NormalizationPoint2D(0, 1, 0, 1);\r\n    alg.N3 = new NormalizationPoint2D(0, 1, 0, 1);\r\n    alg.createLinearSystem(observationsNorm);\r\n    DMatrixRMaj A = alg.A;\r\n    DMatrixRMaj expectedA = createSystem(observationsNorm);\r\n    assertTrue(MatrixFeatures_DDRM.isIdentical(A, expectedA, UtilEjml.TEST_F64));\r\n    assertEquals(1, SingularOps_DDRM.nullity(A, UtilEjml.TEST_F64));\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.BaseTestDescribeSurf.checkBorder",
	"Comment": "can it process descriptors along the image border?if an exception\tis thrown then it failed the test",
	"Method": "void checkBorder(){\r\n    alg.setImage(ii);\r\n    for (int i = 0; i < 10; i++) {\r\n        double angle = (2.0 * Math.PI * i) / 10;\r\n        alg.describe(0, 0, angle, 1, alg.createDescription());\r\n        alg.describe(ii.width - 1, ii.height - 1, angle, 1, alg.createDescription());\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.TestRefinePolyLineCorner.optimize_kinky",
	"Comment": "test case where a local minimum will cause it to get stuck if a local search is performed",
	"Method": "void optimize_kinky(){\r\n    List<Point2D_I32> contour = new ArrayList();\r\n    addPoints(0, 0, 20, 0, contour);\r\n    addPoints(20, 0, 20, 20, contour);\r\n    contour.get(17).set(17, 1);\r\n    contour.get(18).set(18, 2);\r\n    RefinePolyLineCorner alg = new RefinePolyLineCorner(true);\r\n    alg.searchRadius = 5;\r\n    int found = alg.optimize(contour, 2, 16, 36);\r\n    assertEquals(20, found);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.DetectCircleGrid.pruneIncorrectSize",
	"Comment": "prune clusters which do not have the expected number of elements",
	"Method": "void pruneIncorrectSize(List<List<EllipsesIntoClusters.Node>> clusters,int N){\r\n    for (int i = clusters.size() - 1; i >= 0; i--) {\r\n        if (clusters.get(i).size() != N) {\r\n            clusters.remove(i);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setAcquireRetryDelayInMs",
	"Comment": "sets the number of ms to wait before attempting to obtain a connection again after a failure.",
	"Method": "void setAcquireRetryDelayInMs(long acquireRetryDelay){\r\n    setAcquireRetryDelay(acquireRetryDelay, TimeUnit.MILLISECONDS);\r\n}"
}, {
	"Path": "boofcv.alg.transform.pyramid.PyramidOps.scaleDown2",
	"Comment": "scales down the input by a factor of 2.every other pixel along both axises is skipped.",
	"Method": "void scaleDown2(T input,T output){\r\n    if (input instanceof GrayF32) {\r\n        ImplPyramidOps.scaleDown2((GrayF32) input, (GrayF32) output);\r\n    } else if (input instanceof GrayU8) {\r\n        ImplPyramidOps.scaleDown2((GrayU8) input, (GrayU8) output);\r\n    } else {\r\n        throw new IllegalArgumentException(\"Image type not yet supported\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.ConnectLinesGrid.closestFarthestPoints",
	"Comment": "finds the points on each line which are closest and farthest away from each other.",
	"Method": "void closestFarthestPoints(LineSegment2D_F32 a,LineSegment2D_F32 b){\r\n    dist[0] = a.a.distance2(b.a);\r\n    dist[1] = a.a.distance2(b.b);\r\n    dist[2] = a.b.distance2(b.a);\r\n    dist[3] = a.b.distance2(b.b);\r\n    farthestIndex = 0;\r\n    float closest = dist[0];\r\n    float farthest = dist[0];\r\n    for (int i = 1; i < 4; i++) {\r\n        float d = dist[i];\r\n        if (d < closest) {\r\n            closest = d;\r\n            closestIndex = i;\r\n        }\r\n        if (d > farthest) {\r\n            farthest = d;\r\n            farthestIndex = i;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.ReidSolomonCodes.correct",
	"Comment": "decodes the message and performs any necessary error correction",
	"Method": "boolean correct(GrowQueue_I8 input,GrowQueue_I8 ecc){\r\n    computeSyndromes(input, ecc, syndromes);\r\n    findErrorLocatorPolynomialBM(syndromes, errorLocatorPoly);\r\n    if (!findErrorLocations_BruteForce(errorLocatorPoly, input.size + ecc.size, errorLocations))\r\n        return false;\r\n    correctErrors(input, input.size + ecc.size, syndromes, errorLocatorPoly, errorLocations);\r\n    return true;\r\n}"
}, {
	"Path": "org.boon.slumberdb.mysql.BaseVersionedMySQLSupport.connect",
	"Comment": "connects to the db and tracks if successful so upstream stuff can try to reconnect.",
	"Method": "void connect(){\r\n    try {\r\n        MysqlDataSource dataSource = new MysqlDataSource();\r\n        dataSource.setURL(url);\r\n        dataSource.setPassword(password);\r\n        dataSource.setUser(userName);\r\n        connection = dataSource.getConnection();\r\n        connection.setAutoCommit(true);\r\n        closed = false;\r\n        totalConnectionOpen++;\r\n    } catch (SQLException sqlException) {\r\n        this.closed = true;\r\n        connection = null;\r\n        handle(\"Unable to connect\", sqlException);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.TestEnforceTrifocalGeometry.perfectInput",
	"Comment": "give it a set of perfect inputs and see if it computes a valid trifocal tensor",
	"Method": "void perfectInput(){\r\n    TrifocalLinearPoint7 constructA = new TrifocalLinearPoint7();\r\n    constructA.N1 = new NormalizationPoint2D(0, 1, 0, 1);\r\n    constructA.N2 = new NormalizationPoint2D(0, 1, 0, 1);\r\n    constructA.N3 = new NormalizationPoint2D(0, 1, 0, 1);\r\n    constructA.createLinearSystem(observations);\r\n    DMatrixRMaj A = constructA.A;\r\n    Point3D_F64 e2 = new Point3D_F64();\r\n    Point3D_F64 e3 = new Point3D_F64();\r\n    MultiViewOps.extractEpipoles(tensor, e2, e3);\r\n    EnforceTrifocalGeometry alg = new EnforceTrifocalGeometry();\r\n    alg.process(e2, e3, A);\r\n    TrifocalTensor found = new TrifocalTensor();\r\n    alg.extractSolution(found);\r\n    checkTrifocalWithConstraint(found, 1e-6);\r\n    DMatrixRMaj errors = new DMatrixRMaj(observations.size(), 1);\r\n    alg.computeErrorVector(A, errors);\r\n    for (int i = 0; i < errors.numRows; i++) assertEquals(0, errors.get(i), 1e-8);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.TestStereoSparse3D.checkGeometry",
	"Comment": "provide perfect image processing and validate the geometry",
	"Method": "void checkGeometry(){\r\n    Dummy disparity = new Dummy();\r\n    StereoSparse3D alg = new StereoSparse3D(disparity, GrayF32.class);\r\n    alg.setCalibration(param);\r\n    Point3D_F64 X = new Point3D_F64(0.2, -0.34, 3);\r\n    Point2D_F64 x1 = PerspectiveOps.renderPixel(new Se3_F64(), K1, X);\r\n    Point2D_F64 x2 = PerspectiveOps.renderPixel(param.rightToLeft.invert(null), K2, X);\r\n    Point2Transform2_F64 pixelToRect1 = RectifyImageOps.transformPixelToRect(param.left, alg.rect1);\r\n    Point2Transform2_F64 pixelToRect2 = RectifyImageOps.transformPixelToRect(param.right, alg.rect2);\r\n    Point2D_F64 r1 = new Point2D_F64();\r\n    Point2D_F64 r2 = new Point2D_F64();\r\n    pixelToRect1.compute(x1.x, x1.y, r1);\r\n    pixelToRect2.compute(x2.x, x2.y, r2);\r\n    disparity.d = r1.x - r2.x;\r\n    assertTrue(alg.process(x1.x, x1.y));\r\n    double x = alg.getX() / alg.getW();\r\n    double y = alg.getY() / alg.getW();\r\n    double z = alg.getZ() / alg.getW();\r\n    assertEquals(X.x, x, 1e-8);\r\n    assertEquals(X.y, y, 1e-8);\r\n    assertEquals(X.z, z, 1e-8);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.gui.controller.LoginController.tryLogin",
	"Comment": "try to login into pokemon go using the provided login credentials.",
	"Method": "void tryLogin(LoginData loginData){\r\n    final BpmResult loginResult = accountManager.login(loginData);\r\n    if (loginResult.isSuccess()) {\r\n        openMainWindow();\r\n    } else {\r\n        alertFailedLogin(loginResult.getErrorMessage());\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.ClusterLabeledImage.process",
	"Comment": "relabels the image such that all pixels with the same label are a member of the same graph.",
	"Method": "void process(GrayS32 input,GrayS32 output,GrowQueue_I32 regionMemberCount){\r\n    this.regionMemberCount = regionMemberCount;\r\n    regionMemberCount.reset();\r\n    setUpEdges(input, output);\r\n    ImageMiscOps.fill(output, -1);\r\n    mergeList.reset();\r\n    connectInner(input, output);\r\n    connectLeftRight(input, output);\r\n    connectBottom(input, output);\r\n    performMerge(output, regionMemberCount);\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.TestZhang99CalibrationMatrixFromHomography.checkK",
	"Comment": "compare two calibration matrices against each other taking in account the differences in tolerance\tfor different elements",
	"Method": "void checkK(DMatrixRMaj a,DMatrixRMaj b){\r\n    assertEquals(a.get(0, 0), b.get(0, 0), 0.05);\r\n    assertEquals(a.get(1, 1), b.get(1, 1), 0.05);\r\n    assertEquals(a.get(0, 1), b.get(0, 1), 0.01);\r\n    assertEquals(a.get(0, 2), b.get(0, 2), 2);\r\n    assertEquals(a.get(1, 2), b.get(1, 2), 2);\r\n    assertEquals(a.get(2, 2), b.get(2, 2), 1e-8);\r\n}"
}, {
	"Path": "org.boon.Boon.resourceListFromTemplate",
	"Comment": "load json list as resource.looks in file system first and then classpath.",
	"Method": "List<T> resourceListFromTemplate(String path,Class<T> listOf,Object context,List<T> resourceListFromTemplate,Path path,Class<T> listOf,Object context,List<?> resourceListFromTemplate,String path,Object context,List<?> resourceListFromTemplate,Path path,Object context){\r\n    return (List<?>) jsonResourceFromTemplate(path, context);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.KeyPointsCircleRegularGrid.addTangents",
	"Comment": "computes tangent points to the two ellipses specified by the grid coordinates",
	"Method": "boolean addTangents(Grid grid,int rowA,int colA,int rowB,int colB){\r\n    EllipseRotated_F64 a = grid.get(rowA, colA);\r\n    EllipseRotated_F64 b = grid.get(rowB, colB);\r\n    if (!tangentFinder.process(a, b, A0, A1, A2, A3, B0, B1, B2, B3)) {\r\n        return false;\r\n    }\r\n    Tangents ta = tangents.get(grid.getIndexOfRegEllipse(rowA, colA));\r\n    Tangents tb = tangents.get(grid.getIndexOfRegEllipse(rowB, colB));\r\n    double slopeX = b.center.x - a.center.x;\r\n    double slopeY = b.center.y - a.center.y;\r\n    double dx0 = A0.x - a.center.x;\r\n    double dy0 = A0.y - a.center.y;\r\n    double z = slopeX * dy0 - slopeY * dx0;\r\n    if (z < 0 == (rowA == rowB)) {\r\n        Point2D_F64 tmp = A0;\r\n        A0 = A3;\r\n        A3 = tmp;\r\n        tmp = B0;\r\n        B0 = B3;\r\n        B3 = tmp;\r\n    }\r\n    if (rowA == rowB) {\r\n        ta.t[ta.countT++].set(A0);\r\n        ta.b[ta.countB++].set(A3);\r\n        tb.t[tb.countT++].set(B0);\r\n        tb.b[tb.countB++].set(B3);\r\n    } else {\r\n        ta.r[ta.countL++].set(A0);\r\n        ta.l[ta.countR++].set(A3);\r\n        tb.r[tb.countL++].set(B0);\r\n        tb.l[tb.countR++].set(B3);\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "org.boon.Boon.putc",
	"Comment": "like puts, but prints out a whole slew of objects on the sameline using the template if the message is a character sequence.uses jstl style templates.",
	"Method": "void putc(Object context,Object messages){\r\n    for (Object message : messages) {\r\n        if (message instanceof CharSequence) {\r\n            String transformedMessage = jstl(message.toString(), context);\r\n            print(message);\r\n        } else {\r\n            print(message);\r\n        }\r\n        print(' ');\r\n    }\r\n    println();\r\n}"
}, {
	"Path": "org.boon.sort.Sort.sorts",
	"Comment": "helper method to create a sort that is a composite of other sorts.",
	"Method": "Sort sorts(Sort sorts){\r\n    if (sorts == null || sorts.length == 0) {\r\n        return null;\r\n    }\r\n    Sort main = sorts[0];\r\n    for (int index = 1; index < sorts.length; index++) {\r\n        main.then(sorts[index]);\r\n    }\r\n    return main;\r\n}"
}, {
	"Path": "boofcv.abst.geo.calibration.TestCalibrateStereoPlanar.fullBasic",
	"Comment": "give it a fake feature detector and a fairly benign scenario and see if it can correctly\testimate the camera parameters.",
	"Method": "void fullBasic(){\r\n    CalibrateStereoPlanar alg = new CalibrateStereoPlanar(layout);\r\n    alg.configure(true, 2, true);\r\n    for (int i = 0; i < targetToLeft.size(); i++) {\r\n        alg.addPair(createFakeObservations(i, true), createFakeObservations(i, false));\r\n    }\r\n    StereoParameters found = alg.process();\r\n    checkIntrinsic(found.left);\r\n    checkIntrinsic(found.right);\r\n    Se3_F64 rightToLeft = found.getRightToLeft();\r\n    Se3_F64 expected = leftToRight.invert(null);\r\n    assertEquals(0, expected.getT().distance(rightToLeft.T), 1.01e-3);\r\n    assertTrue(MatrixFeatures_DDRM.isIdentity(rightToLeft.getR(), 1e-3));\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.EstimateSceneCalibrated.triangulationAngle",
	"Comment": "computes the acture angle between two vectors. larger this angle is the better the triangulation\tof the features 3d location is in general",
	"Method": "double triangulationAngle(Point2D_F64 normA,Point2D_F64 normB,Se3_F64 a_to_b){\r\n    arrowA.set(normA.x, normA.y, 1);\r\n    arrowB.set(normB.x, normB.y, 1);\r\n    GeometryMath_F64.mult(a_to_b.R, arrowA, arrowA);\r\n    return UtilVector3D_F64.acute(arrowA, arrowB);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.gridline.TestGridLineModelDistance.distance",
	"Comment": "assuming two points have an angle less than the max, check the distance",
	"Method": "void distance(){\r\n    float theta = (float) (Math.PI / 4.0);\r\n    LinePolar2D_F32 l = new LinePolar2D_F32((float) (Math.sqrt(2 * 5 * 5)), theta);\r\n    GridLineModelDistance alg = new GridLineModelDistance(0.2f);\r\n    alg.setModel(l);\r\n    assertEquals(0, alg.computeDistance(new Edgel(5, 5, theta)), 1e-4);\r\n    assertEquals(7.0711, alg.computeDistance(new Edgel(0, 0, theta)), 0.1);\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.BinaryImageOps.clusterToBinary",
	"Comment": "sets each pixel in the list of clusters to one in the binary image.",
	"Method": "void clusterToBinary(List<List<Point2D_I32>> clusters,GrayU8 binary){\r\n    ImageMiscOps.fill(binary, 0);\r\n    for (List<Point2D_I32> l : clusters) {\r\n        for (Point2D_I32 p : l) {\r\n            binary.set(p.x, p.y, 1);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "org.boon.Boon.putl",
	"Comment": "like puts but prints out each object on its own line.if the object is a list or array,then each item in the list gets printed out on its own line.",
	"Method": "void putl(Object messages){\r\n    for (Object message : messages) {\r\n        if (message instanceof Collection || Typ.isArray(message)) {\r\n            Iterator iterator = Conversions.iterator(message);\r\n            while (iterator.hasNext()) {\r\n                puts(iterator.next());\r\n            }\r\n            continue;\r\n        }\r\n        print(message);\r\n        println();\r\n    }\r\n    println();\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomDualTrackPnP.getCandidates",
	"Comment": "returns a list of active tracks that passed geometric constraints",
	"Method": "List<PointTrack> getCandidates(){\r\n    return candidates;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.TestConnectLinesGrid.checkParallelTolerance",
	"Comment": "makes sure the parallel distance tolerance parameter is correctly set and processed",
	"Method": "void checkParallelTolerance(){\r\n    MatrixOfList<LineSegment2D_F32> grid = new MatrixOfList(1, 1);\r\n    grid.get(0, 0).add(new LineSegment2D_F32(0, 0, 2, 0));\r\n    grid.get(0, 0).add(new LineSegment2D_F32(3, 0, 5, 0));\r\n    ConnectLinesGrid app = new ConnectLinesGrid(2, 2, 0.1);\r\n    app.process(grid);\r\n    assertEquals(2, grid.createSingleList().size());\r\n    app = new ConnectLinesGrid(2, 2, 1.1);\r\n    app.process(grid);\r\n    assertEquals(1, grid.createSingleList().size());\r\n}"
}, {
	"Path": "org.boon.Boon.puth",
	"Comment": "like puts, but prints out a whole slew of objects on the sameline using the template if the message is a character sequence.uses handlebar style templates.",
	"Method": "void puth(Object context,Object messages){\r\n    for (Object message : messages) {\r\n        if (message instanceof CharSequence) {\r\n            String transformedMessage = handlebars(message.toString(), context);\r\n            print(message);\r\n        } else {\r\n            print(message);\r\n        }\r\n        print(' ');\r\n    }\r\n    println();\r\n}"
}, {
	"Path": "boofcv.alg.background.BackgroundModelMoving.segment",
	"Comment": "invoke to use the background image to segment the current frame into background and foreground pixels",
	"Method": "void segment(MotionModel homeToCurrent,T frame,GrayU8 segmented){\r\n    InputSanityCheck.checkSameShape(frame, segmented);\r\n    worldToHome.concat(homeToCurrent, worldToCurrent);\r\n    worldToCurrent.invert(currentToWorld);\r\n    _segment(currentToWorld, frame, segmented);\r\n}"
}, {
	"Path": "org.boon.Boon.puts",
	"Comment": "like print, but prints out a whole slew of objects on the same line.",
	"Method": "void puts(Object messages){\r\n    for (Object message : messages) {\r\n        print(message);\r\n        if (!(message instanceof Terminal.Escape))\r\n            print(' ');\r\n    }\r\n    println();\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestNarrowToWidePtoP_F32.rotateCamera",
	"Comment": "rotate the camera and see if the point moves in the expected way",
	"Method": "void rotateCamera(){\r\n    NarrowToWidePtoP_F32 alg = createAlg();\r\n    Point2D_F32 found = new Point2D_F32();\r\n    FMatrixRMaj R = ConvertRotation3D_F32.eulerToMatrix(EulerType.YXZ, 0.1f, 0, 0, null);\r\n    alg.setRotationWideToNarrow(R);\r\n    alg.compute(250, 250, found);\r\n    assertTrue(480 < found.x - 5);\r\n    R = ConvertRotation3D_F32.eulerToMatrix(EulerType.YXZ, -0.1f, 0, 0, null);\r\n    alg.setRotationWideToNarrow(R);\r\n    alg.compute(250, 250, found);\r\n    assertTrue(480 > found.x + 5);\r\n    R = ConvertRotation3D_F32.eulerToMatrix(EulerType.YXZ, 0, -0.1f, 0, null);\r\n    alg.setRotationWideToNarrow(R);\r\n    alg.compute(250, 250, found);\r\n    assertTrue(480 < found.y - 5);\r\n    R = ConvertRotation3D_F32.eulerToMatrix(EulerType.YXZ, 0, 0.1f, 0, null);\r\n    alg.setRotationWideToNarrow(R);\r\n    alg.compute(250, 250, found);\r\n    assertTrue(480 > found.y + 5);\r\n}"
}, {
	"Path": "boofcv.alg.bow.LearnSceneFromFiles.findImages",
	"Comment": "loads the paths to image files contained in subdirectories of the root directory.each sub directory\tis assumed to be a different category of images.",
	"Method": "Map<String, List<String>> findImages(File rootDir){\r\n    File[] files = rootDir.listFiles();\r\n    if (files == null)\r\n        return null;\r\n    List<File> imageDirectories = new ArrayList();\r\n    for (File f : files) {\r\n        if (f.isDirectory()) {\r\n            imageDirectories.add(f);\r\n        }\r\n    }\r\n    Map<String, List<String>> out = new HashMap();\r\n    for (File d : imageDirectories) {\r\n        List<String> images = new ArrayList();\r\n        files = d.listFiles();\r\n        if (files == null)\r\n            throw new RuntimeException(\"Should be a directory!\");\r\n        for (File f : files) {\r\n            if (f.isHidden() || f.isDirectory() || f.getName().endsWith(\".txt\")) {\r\n                continue;\r\n            }\r\n            images.add(f.getPath());\r\n        }\r\n        String key = d.getName().toLowerCase();\r\n        out.put(key, images);\r\n    }\r\n    return out;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCP.maybeSignalForMoreConnections",
	"Comment": "tests if this partition has hit a threshold and signal to the pool watch thread to create new connections",
	"Method": "void maybeSignalForMoreConnections(ConnectionPartition connectionPartition){\r\n    if (!connectionPartition.isUnableToCreateMoreTransactions() && !this.poolShuttingDown && connectionPartition.getAvailableConnections() * 100 / connectionPartition.getMaxConnections() <= this.poolAvailabilityThreshold) {\r\n        connectionPartition.getPoolWatchThreadSignalQueue().offer(new Object());\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.HoughTransformLineFootOfNorm.transform",
	"Comment": "computes the hough transform using the image gradient and a binary image which flags pixels as being edges or not.",
	"Method": "void transform(D derivX,D derivY,GrayU8 binary){\r\n    InputSanityCheck.checkSameShape(derivX, derivY, binary);\r\n    transform.reshape(derivX.width, derivY.height);\r\n    ImageMiscOps.fill(transform, 0);\r\n    originX = derivX.width / 2;\r\n    originY = derivX.height / 2;\r\n    candidates.reset();\r\n    if (derivX instanceof GrayF32)\r\n        _transform((GrayF32) derivX, (GrayF32) derivY, binary);\r\n    else if (derivX instanceof GrayS16)\r\n        _transform((GrayS16) derivX, (GrayS16) derivY, binary);\r\n    else if (derivX instanceof GrayS32)\r\n        _transform((GrayS32) derivX, (GrayS32) derivY, binary);\r\n    else\r\n        throw new IllegalArgumentException(\"Unsupported derivative image type: \" + derivX.getClass().getSimpleName());\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestNarrowToWidePtoP_F32.centerIsCenter",
	"Comment": "with no translation request a point in the center.should appear to be in the center in both views.",
	"Method": "void centerIsCenter(){\r\n    NarrowToWidePtoP_F32 alg = createAlg();\r\n    Point2D_F32 found = new Point2D_F32();\r\n    alg.compute(250, 250, found);\r\n    assertEquals(480, found.x, GrlConstants.TEST_SQ_F32);\r\n    assertEquals(480, found.y, GrlConstants.TEST_SQ_F32);\r\n}"
}, {
	"Path": "boofcv.alg.distort.mls.ImageDeformPointMLS_F32.addControl",
	"Comment": "adds a new control point at the specified location.initially the distorted and undistorted location will be\tset to the same",
	"Method": "int addControl(float x,float y){\r\n    Control c = controls.grow();\r\n    c.q.set(x, y);\r\n    setUndistorted(controls.size() - 1, x, y);\r\n    return controls.size() - 1;\r\n}"
}, {
	"Path": "boofcv.alg.filter.misc.AverageDownSampleOps.reshapeDown",
	"Comment": "reshapes an image so that it is the correct size to store the down sampled image",
	"Method": "void reshapeDown(ImageBase image,int inputWidth,int inputHeight,int squareWidth){\r\n    int w = downSampleSize(inputWidth, squareWidth);\r\n    int h = downSampleSize(inputHeight, squareWidth);\r\n    image.reshape(w, h);\r\n}"
}, {
	"Path": "boofcv.alg.geo.DecomposeEssential.extractTransform",
	"Comment": "there are four possible reconstructions from an essential matrix.this function will compute different\tpermutations depending on optiona and optionb being true or false.",
	"Method": "void extractTransform(DMatrixRMaj U,DMatrixRMaj V,DMatrixRMaj S,Se3_F64 se,boolean optionA,boolean optionB){\r\n    DMatrixRMaj R = se.getR();\r\n    Vector3D_F64 T = se.getT();\r\n    if (optionA)\r\n        CommonOps_DDRM.mult(U, Rz, temp);\r\n    else\r\n        CommonOps_DDRM.multTransB(U, Rz, temp);\r\n    CommonOps_DDRM.multTransB(temp, V, R);\r\n    if (optionB)\r\n        CommonOps_DDRM.multTransB(U, Rz, temp);\r\n    else\r\n        CommonOps_DDRM.mult(U, Rz, temp);\r\n    CommonOps_DDRM.mult(temp, S, temp2);\r\n    CommonOps_DDRM.multTransB(temp2, U, temp);\r\n    T.x = temp.get(2, 1);\r\n    T.y = temp.get(0, 2);\r\n    T.z = temp.get(1, 0);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.TestCannyEdge.constantGradient",
	"Comment": "test a pathological case. the input image has a constant gradient",
	"Method": "void constantGradient(){\r\n    GrayU8 input = new GrayU8(width, height);\r\n    GrayU8 output = new GrayU8(width, height);\r\n    for (int i = 0; i < input.width; i++) {\r\n        for (int j = 0; j < input.height; j++) {\r\n            input.unsafe_set(i, j, i * 2);\r\n        }\r\n    }\r\n    CannyEdge<GrayU8, GrayS16> alg = createCanny(true);\r\n    alg.process(input, 1, 2, output);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.TestQrCodeDecoderImage.message_numeric",
	"Comment": "run the entire algorithm on a rendered image but just care about the message",
	"Method": "void message_numeric(){\r\n    String message = \"\";\r\n    for (int i = 0; i < 20; i++) {\r\n        QrCode expected = new QrCodeEncoder().setVersion(1).setError(QrCode.ErrorLevel.M).setMask(QrCodeMaskPattern.M011).addNumeric(message).fixate();\r\n        QrCodeGeneratorImage generator = new QrCodeGeneratorImage(4);\r\n        generator.render(expected);\r\n        FastQueue<PositionPatternNode> pps = createPositionPatterns(generator);\r\n        QrCodeDecoderImage<GrayU8> decoder = new QrCodeDecoderImage(GrayU8.class);\r\n        decoder.process(pps, generator.getGray());\r\n        assertEquals(1, decoder.successes.size());\r\n        QrCode found = decoder.getFound().get(0);\r\n        assertEquals(expected.version, found.version);\r\n        assertEquals(expected.error, found.error);\r\n        assertEquals(expected.mode, found.mode);\r\n        assertEquals(message, new String(found.message));\r\n        message += (i % 10) + \"\";\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.QrCodePreciseDetector.setLensDistortion",
	"Comment": "specifies transforms which can be used to change coordinates from distorted to undistorted and the opposite\tcoordinates.the undistorted image is never explicitly created.",
	"Method": "void setLensDistortion(int width,int height,LensDistortionNarrowFOV model){\r\n    detectPositionPatterns.setLensDistortion(width, height, model);\r\n    decoder.setLensDistortion(width, height, model);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeAlignmentPatternLocator.centerOnSquare",
	"Comment": "if the initial guess is within the inner white circle or black dot this will ensure that it is centered\ton the black dot",
	"Method": "boolean centerOnSquare(QrCode.Alignment pattern,float guessY,float guessX){\r\n    float step = 1;\r\n    float bestMag = Float.MAX_VALUE;\r\n    float bestX = guessX;\r\n    float bestY = guessY;\r\n    for (int i = 0; i < 10; i++) {\r\n        for (int row = 0; row < 3; row++) {\r\n            float gridy = guessY - 1f + row;\r\n            for (int col = 0; col < 3; col++) {\r\n                float gridx = guessX - 1f + col;\r\n                samples[row * 3 + col] = reader.read(gridy, gridx);\r\n            }\r\n        }\r\n        float dx = (samples[2] + samples[5] + samples[8]) - (samples[0] + samples[3] + samples[6]);\r\n        float dy = (samples[6] + samples[7] + samples[8]) - (samples[0] + samples[1] + samples[2]);\r\n        float r = (float) Math.sqrt(dx * dx + dy * dy);\r\n        if (bestMag > r) {\r\n            bestMag = r;\r\n            bestX = guessX;\r\n            bestY = guessY;\r\n        } else {\r\n            step *= 0.75f;\r\n        }\r\n        if (r > 0) {\r\n            guessX = bestX + step * dx / r;\r\n            guessY = bestY + step * dy / r;\r\n        } else {\r\n            break;\r\n        }\r\n    }\r\n    pattern.moduleFound.x = bestX;\r\n    pattern.moduleFound.y = bestY;\r\n    reader.gridToImage((float) pattern.moduleFound.y, (float) pattern.moduleFound.x, pattern.pixel);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.selectCornerToRemove",
	"Comment": "selects the best corner to remove. if no corner was found that can be removed then null is returned",
	"Method": "Element<Corner> selectCornerToRemove(List<Point2D_I32> contour,ErrorValue sideError,boolean loops){\r\n    if (list.size() <= 3)\r\n        return null;\r\n    Element<Corner> target, end;\r\n    if (loops) {\r\n        target = list.getHead();\r\n        end = null;\r\n    } else {\r\n        target = list.getHead().next;\r\n        end = list.getTail();\r\n    }\r\n    Element<Corner> best = null;\r\n    double bestScore = -Double.MAX_VALUE;\r\n    while (target != end) {\r\n        Element<Corner> p = previous(target);\r\n        Element<Corner> n = next(target);\r\n        double before = (p.object.sideError + target.object.sideError) / 2.0 + cornerScorePenalty;\r\n        double after = computeSideError(contour, p.object.index, n.object.index);\r\n        if (before - after > bestScore) {\r\n            bestScore = before - after;\r\n            best = target;\r\n            sideError.value = after;\r\n        }\r\n        target = target.next;\r\n    }\r\n    return best;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.TestStitchingFromMotion2D.basicTest",
	"Comment": "given fake internal algorithms see if it performs as expected.tests several functions",
	"Method": "void basicTest(){\r\n    HelperMotion motion = new HelperMotion();\r\n    HelperDistort distort = new HelperDistort();\r\n    StitchingTransform trans = FactoryStitchingTransform.createAffine_F64();\r\n    StitchingFromMotion2D<GrayF32, Affine2D_F64> alg = new StitchingFromMotion2D(motion, distort, trans, 0.3);\r\n    alg.configure(200, 300, null);\r\n    assertTrue(alg.process(image));\r\n    assertEquals(0, motion.numReset);\r\n    assertEquals(1, motion.numProcess);\r\n    assertEquals(1, distort.numSetModel);\r\n    assertEquals(1, distort.numApply);\r\n    assertEquals(200, alg.getStitchedImage().width);\r\n    assertEquals(300, alg.getStitchedImage().height);\r\n    Affine2D_F64 found = alg.getWorldToCurr();\r\n    assertEquals(1, found.tx, 1e-5);\r\n    assertEquals(-2, found.ty, 1e-5);\r\n    assertTrue(alg.process(image));\r\n    assertEquals(0, motion.numReset);\r\n    assertEquals(2, motion.numProcess);\r\n    assertEquals(2, distort.numSetModel);\r\n    assertEquals(2, distort.numApply);\r\n    found = alg.getWorldToCurr();\r\n    assertEquals(1, found.tx, 1e-5);\r\n    assertEquals(-2, found.ty, 1e-5);\r\n    alg.reset();\r\n    assertEquals(1, motion.numReset);\r\n    found = alg.getWorldToCurr();\r\n    assertEquals(0, found.tx, 1e-5);\r\n    assertEquals(0, found.ty, 1e-5);\r\n}"
}, {
	"Path": "boofcv.android.camera2.SimpleCamera2Activity.displayDensityAdjusted",
	"Comment": "some times the size of a font of stroke needs to be specified in the input image\tbut then gets scaled to image resolution. this compensates for that.",
	"Method": "float displayDensityAdjusted(){\r\n    open.mLock.lock();\r\n    try {\r\n        if (open.mCameraSize == null)\r\n            return displayMetrics.density;\r\n        int rotation = getWindowManager().getDefaultDisplay().getRotation();\r\n        int screenWidth = (rotation == 0 || rotation == 2) ? displayMetrics.widthPixels : displayMetrics.heightPixels;\r\n        int cameraWidth = open.mSensorOrientation == 0 || open.mSensorOrientation == 180 ? open.mCameraSize.getWidth() : open.mCameraSize.getHeight();\r\n        return displayMetrics.density * cameraWidth / screenWidth;\r\n    } finally {\r\n        open.mLock.unlock();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonFromContour.process",
	"Comment": "examines the undistorted gray scale input image for squares. if p",
	"Method": "void process(T gray,GrayU8 binary){\r\n    if (verbose)\r\n        System.out.println(\"ENTER  DetectPolygonFromContour.process()\");\r\n    if (contourPadded != null && !contourPadded.isCreatePaddedCopy()) {\r\n        int padding = 2;\r\n        if (gray.width + padding != binary.width || gray.height + padding != binary.height) {\r\n            throw new IllegalArgumentException(\"Including padding, expected a binary image with shape \" + (gray.width + padding) + \"x\" + (gray.height + padding));\r\n        }\r\n    } else {\r\n        InputSanityCheck.checkSameShape(binary, gray);\r\n    }\r\n    if (imageWidth != gray.width || imageHeight != gray.height)\r\n        configure(gray.width, gray.height);\r\n    for (int i = 0; i < foundInfo.size; i++) {\r\n        foundInfo.get(i).reset();\r\n    }\r\n    foundInfo.reset();\r\n    if (contourEdgeIntensity != null)\r\n        contourEdgeIntensity.setImage(gray);\r\n    long time0 = System.nanoTime();\r\n    contourFinder.process(binary);\r\n    long time1 = System.nanoTime();\r\n    findCandidateShapes();\r\n    long time2 = System.nanoTime();\r\n    double a = (time1 - time0) * 1e-6;\r\n    double b = (time2 - time1) * 1e-6;\r\n    milliContour.update(a);\r\n    milliShapes.update(b);\r\n    if (verbose)\r\n        System.out.println(\"EXIT  DetectPolygonFromContour.process()\");\r\n}"
}, {
	"Path": "boofcv.alg.flow.TestDenseOpticalFlowKlt.negative",
	"Comment": "very simple negative case. the second image is blank so it should fail at tracking",
	"Method": "void negative(){\r\n    ImageMiscOps.fillRectangle(image0, 200, 7, 9, 5, 5);\r\n    processInputImage();\r\n    DenseOpticalFlowKlt<GrayF32, GrayF32> alg = createAlg();\r\n    ImageFlow flow = new ImageFlow(image0.width, image0.height);\r\n    alg.process(prev, prevDerivX, prevDerivY, curr, flow);\r\n    int totalFail = 0;\r\n    for (int i = 0; i < flow.data.length; i++) {\r\n        if (!flow.data[i].isValid()) {\r\n            totalFail++;\r\n        }\r\n    }\r\n    assertTrue(totalFail / (double) flow.data.length >= 0.90);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.TrackerMeanShiftComaniciu2003.initialize",
	"Comment": "specifies the initial image to learn the target description",
	"Method": "void initialize(T image,RectangleRotate_F32 initial){\r\n    this.region.set(initial);\r\n    calcHistogram.computeHistogram(image, initial);\r\n    System.arraycopy(calcHistogram.getHistogram(), 0, keyHistogram, 0, keyHistogram.length);\r\n    this.minimumWidth = initial.width * minimumSizeRatio;\r\n}"
}, {
	"Path": "boofcv.factory.geo.FactoryMultiViewRobust.homographyCalibratedRansac",
	"Comment": "estimates a homography from normalized image coordinates but computes the error in pixel coordinates",
	"Method": "RansacMultiView<Homography2D_F64, AssociatedPair> homographyCalibratedRansac(ConfigRansac ransac){\r\n    ModelManager<Homography2D_F64> manager = new ModelManagerHomography2D_F64();\r\n    GenerateHomographyLinear modelFitter = new GenerateHomographyLinear(false);\r\n    DistanceHomographyCalibratedSq distance = new DistanceHomographyCalibratedSq();\r\n    double ransacTol = ransac.inlierThreshold * ransac.inlierThreshold;\r\n    return new RansacMultiView(ransac.randSeed, manager, modelFitter, distance, ransac.maxIterations, ransacTol);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.getBestPolyline",
	"Comment": "returns the polyline with the best score or null if it failed to fit a polyline",
	"Method": "CandidatePolyline getBestPolyline(){\r\n    return bestPolyline;\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.ChecksMotionNPointHomogenous.minimalObservationTest",
	"Comment": "standard test using only the minimum number of observation",
	"Method": "void minimalObservationTest(){\r\n    standardTest(6);\r\n}"
}, {
	"Path": "boofcv.abst.geo.calibration.TestCalibrateMonoPlanar.fullBasic",
	"Comment": "give it a fake feature detector and a fairly benign scenario and see if it can correctly\testimate the camera parameters.",
	"Method": "void fullBasic(){\r\n    CalibrateMonoPlanar alg = new CalibrateMonoPlanar(layout);\r\n    alg.configurePinhole(true, 2, true);\r\n    for (int i = 0; i < targetToCamera.size(); i++) {\r\n        alg.addImage(createFakeObservations(i));\r\n    }\r\n    CameraPinholeRadial found = alg.process();\r\n    assertEquals(intrinsic.fx, found.fx, 1e-3);\r\n    assertEquals(intrinsic.fy, found.fy, 1e-3);\r\n    assertEquals(intrinsic.cx, found.cx, 1e-3);\r\n    assertEquals(intrinsic.cy, found.cy, 1e-3);\r\n    assertEquals(intrinsic.skew, found.skew, 1e-3);\r\n    assertEquals(intrinsic.radial[0], found.radial[0], 1e-5);\r\n    assertEquals(intrinsic.radial[1], found.radial[1], 1e-5);\r\n    assertEquals(intrinsic.t1, found.t1, 1e-5);\r\n    assertEquals(intrinsic.t2, found.t2, 1e-5);\r\n    assertEquals(intrinsic.width, found.width, 1e-3);\r\n    assertEquals(intrinsic.height, found.height, 1e-3);\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.BaseTestDescribeSurf.features_fraction",
	"Comment": "give it a scale factor which is a fraction and see if it blows up",
	"Method": "void features_fraction(){\r\n    TestImplSurfDescribeOps.createGradient(0, input);\r\n    GIntegralImageOps.transform(input, ii);\r\n    sparse = TestImplSurfDescribeOps.createGradient(ii, 1.5);\r\n    alg.setImage(ii);\r\n    BrightFeature feat = alg.createDescription();\r\n    alg.describe(25, 25, 0, 1.5, feat);\r\n    for (int i = 0; i < 64; i += 4) {\r\n        assertEquals(feat.value[i], feat.value[i + 1], 1e-4);\r\n        assertTrue(feat.value[i] > 0);\r\n        assertEquals(0, feat.value[i + 2], 1e-4);\r\n        assertEquals(0, feat.value[i + 3], 1e-4);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.TestRefinePolygonToGrayLine.alignedSquare",
	"Comment": "fit a square which is alligned to the image axis.it should get a nearly perfect fit.\tinitial conditions are be a bit off.",
	"Method": "void alignedSquare(){\r\n    rectangles.add(new Rectangle2D_I32(x0, y0, x1, y1));\r\n    Polygon2D_F64 original = new Polygon2D_F64(x0, y0, x0, y1, x1, y1, x1, y0);\r\n    for (Class imageType : imageTypes) {\r\n        for (int i = 0; i < 2; i++) {\r\n            boolean black = i == 0;\r\n            renderDistortedRectangles(black, imageType);\r\n            RefinePolygonToGrayLine alg = createAlg(original.size(), imageType);\r\n            for (int j = 0; j < 20; j++) {\r\n                Polygon2D_F64 input = original.copy();\r\n                addNoise(input, 2);\r\n                Polygon2D_F64 output = new Polygon2D_F64(original.size());\r\n                alg.setImage(image);\r\n                assertTrue(alg.refine(input, output));\r\n                assertTrue(original.isIdentical(output, 0.01));\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.TestZhang99OptimizationFunction.computeResidualsPerfect",
	"Comment": "give it perfect observations and see if the residuals are all zero",
	"Method": "void computeResidualsPerfect(){\r\n    Zhang99AllParam param = GenericCalibrationGrid.createStandardParam(TestPinholeCalibrationZhang99.createStandard(false, true, 2, rand), 3, rand);\r\n    double[] array = new double[param.numParameters()];\r\n    param.convertToParam(array);\r\n    List<Point2D_F64> gridPts = GenericCalibrationGrid.standardLayout();\r\n    List<CalibrationObservation> observations = new ArrayList();\r\n    for (int i = 0; i < param.views.length; i++) {\r\n        observations.add(estimate(param, param.views[i], gridPts));\r\n    }\r\n    Zhang99OptimizationFunction alg = new Zhang99OptimizationFunction(new Zhang99AllParam(new CalibParamPinholeRadial(false, 2, true), 3), gridPts, observations);\r\n    double[] residuals = new double[alg.getNumOfOutputsM()];\r\n    for (int i = 0; i < residuals.length; i++) residuals[i] = 1;\r\n    alg.process(array, residuals);\r\n    for (double r : residuals) {\r\n        assertEquals(0, r, 1e-8);\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Client.setAutoCaptureSessions",
	"Comment": "sets whether or not bugsnag should automatically capture and report user sessions wheneverthe app enters the foreground.by default this behavior is disabled.",
	"Method": "void setAutoCaptureSessions(boolean autoCapture){\r\n    config.setAutoCaptureSessions(autoCapture);\r\n    if (autoCapture) {\r\n        sessionTracker.onAutoCaptureEnabled();\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.filter.derivative.FactoryDerivative.gradientSB",
	"Comment": "returns the gradient for single band images of the specified type",
	"Method": "ImageGradient<I, D> gradientSB(DerivativeType type,Class<I> inputType,Class<D> derivType){\r\n    if (derivType == null)\r\n        derivType = GImageDerivativeOps.getDerivativeType(inputType);\r\n    Class which;\r\n    switch(type) {\r\n        case PREWITT:\r\n            which = GradientPrewitt.class;\r\n            break;\r\n        case SOBEL:\r\n            which = GradientSobel.class;\r\n            break;\r\n        case THREE:\r\n            which = GradientThree.class;\r\n            break;\r\n        case TWO_0:\r\n            which = GradientTwo0.class;\r\n            break;\r\n        case TWO_1:\r\n            which = GradientTwo1.class;\r\n            break;\r\n        default:\r\n            throw new IllegalArgumentException(\"Unknown type \" + type);\r\n    }\r\n    Method m = findDerivative(which, inputType, derivType);\r\n    return new ImageGradient_Reflection(m);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonFromContour.setLensDistortion",
	"Comment": "specifies transforms which can be used to change coordinates from distorted to undistorted and the opposite\tcoordinates.the undistorted image is never explicitly created.",
	"Method": "void setLensDistortion(int width,int height,PixelTransform2_F32 distToUndist,PixelTransform2_F32 undistToDist){\r\n    this.distToUndist = distToUndist;\r\n    this.undistToDist = undistToDist;\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.setAutomaticallyCollectBreadcrumbs",
	"Comment": "by default, we will automatically add breadcrumbs for common application events,such as activity lifecycle events, and system intents.to disable this behavior, set this property to false.",
	"Method": "void setAutomaticallyCollectBreadcrumbs(boolean automaticallyCollectBreadcrumbs){\r\n    this.automaticallyCollectBreadcrumbs = automaticallyCollectBreadcrumbs;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.TestQrCodeEncoder.numeric_specification",
	"Comment": "in the qr code specification an example is given. this compares the computed results\tto that example",
	"Method": "void numeric_specification(){\r\n    QrCode qr = new QrCodeEncoder().setVersion(1).setError(QrCode.ErrorLevel.M).setMask(new QrCodeMaskPattern.NONE(0b011)).addNumeric(\"01234567\").fixate();\r\n    byte[] expected = new byte[] { 0b00010000, 0b00100000, 0b00001100, 0b01010110, 0b01100001, (byte) 0b10000000, (byte) 0b11101100, 0b00010001, (byte) 0b11101100, 0b00010001, (byte) 0b11101100, 0b00010001, (byte) 0b11101100, 0b00010001, (byte) 0b11101100, 0b00010001, (byte) 0b10100101, 0b00100100, (byte) 0b11010100, (byte) 0b11000001, (byte) 0b11101101, 0b00110110, (byte) 0b11000111, (byte) 0b10000111, 0b00101100, 0b01010101 };\r\n    QrCodeEncoder.flipBits8(expected, expected.length);\r\n    assertEquals(qr.rawbits.length, expected.length);\r\n    for (int i = 0; i < expected.length; i++) {\r\n        assertEquals(expected[i], qr.rawbits[i]);\r\n    }\r\n}"
}, {
	"Path": "boofcv.app.PaperSize.lookup",
	"Comment": "sees if the specified work matches any of the units full name or short name.",
	"Method": "PaperSize lookup(String word){\r\n    for (PaperSize paper : values) {\r\n        if (paper.name.compareToIgnoreCase(word) == 0) {\r\n            return paper;\r\n        }\r\n    }\r\n    return null;\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.StandardPointTrackerTwoPass.performSecondPass_multiple",
	"Comment": "should be possible to do more than one second pass. very minimal test, just checks number of elements in lists.",
	"Method": "void performSecondPass_multiple(){\r\n    tracker2 = createTracker();\r\n    tracker2.process((T) image);\r\n    tracker2.finishTracking();\r\n    tracker2.spawnTracks();\r\n    int allBefore = tracker2.getActiveTracks(null).size();\r\n    int activeBefore = tracker2.getAllTracks(null).size();\r\n    tracker2.process((T) image);\r\n    tracker2.performSecondPass();\r\n    tracker2.performSecondPass();\r\n    tracker2.finishTracking();\r\n    checkInside(tracker2.getAllTracks(null));\r\n    assertEquals(allBefore, tracker2.getAllTracks(null).size());\r\n    assertEquals(activeBefore, tracker2.getActiveTracks(null).size());\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeDecoderImage.setLensDistortion",
	"Comment": "specifies transforms which can be used to change coordinates from distorted to undistorted and the opposite\tcoordinates.the undistorted image is never explicitly created.",
	"Method": "void setLensDistortion(int width,int height,LensDistortionNarrowFOV model){\r\n    alignmentLocator.setLensDistortion(width, height, model);\r\n    gridReader.setLensDistortion(width, height, model);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCP.getFinalizableRefQueue",
	"Comment": "watch for connections that should have been safely closed but the application forgot.",
	"Method": "FinalizableReferenceQueue getFinalizableRefQueue(){\r\n    return this.finalizableRefQueue;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.template.GeneralTemplateMatchTests.maskDifferentiate",
	"Comment": "if the mask is correctly applied then two matches will be found inside the image.otherwise just one.",
	"Method": "void maskDifferentiate(){\r\n    GImageMiscOps.fillUniform(image, rand, 0, 200);\r\n    int x = 10, y = 12, tw = 15, th = 15;\r\n    T template = image.createNew(tw, th);\r\n    GImageMiscOps.fillUniform(template, rand, 0, 200);\r\n    GImageMiscOps.fillBorder(template, 150, 2);\r\n    image.subimage(x - tw / 2, y - th / 2, x - tw / 2 + tw, y - th / 2 + th).setTo(template);\r\n    GImageMiscOps.fillBorder(template, 20, 2);\r\n    GImageMiscOps.fillBorder(template, 50, 1);\r\n    alg.setInputImage(image);\r\n    alg.process(template);\r\n    float valueNoMask = fractionBest(alg.getIntensity(), x, y);\r\n    float averageNoMask = fractionAverage(alg.getIntensity(), x, y);\r\n    T mask = (T) image.createNew(tw, th);\r\n    double v = image.getImageType().getDataType().isInteger() ? 100 : 1;\r\n    GImageMiscOps.fill(mask, v);\r\n    GImageMiscOps.fillBorder(mask, 0, 2);\r\n    alg.setInputImage(image);\r\n    alg.process(template, mask);\r\n    float valueMask = fractionBest(alg.getIntensity(), x, y);\r\n    float averageMask = fractionAverage(alg.getIntensity(), x, y);\r\n    float scoreNoMask = valueNoMask / averageNoMask;\r\n    float scoreMask = valueMask / averageMask;\r\n    assertTrue(valueMask >= valueNoMask);\r\n    assertTrue(scoreMask * 0.9 > scoreNoMask);\r\n}"
}, {
	"Path": "boofcv.alg.descriptor.TestUtilFeature.normalizeL2_zeros_F64",
	"Comment": "the descriptor is all zeros.see if it handles this special case.",
	"Method": "void normalizeL2_zeros_F64(){\r\n    TupleDesc_F64 feature = new TupleDesc_F64(64);\r\n    UtilFeature.normalizeL2(feature);\r\n    for (int i = 0; i < feature.value.length; i++) assertEquals(0, feature.value[i], 1e-4);\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.TestEssentialResidualSampson.checkChangeInCost",
	"Comment": "first check to see if the error is very low for perfect parameters.then\tgive it incorrect parameters and make sure it is not zero.",
	"Method": "void checkChangeInCost(){\r\n    init(30, false);\r\n    DMatrixRMaj E = MultiViewOps.createEssential(a_to_b.getR(), a_to_b.getT(), null);\r\n    EssentialResidualSampson alg = new EssentialResidualSampson();\r\n    alg.setCalibration1(intrinsic);\r\n    alg.setCalibration2(intrinsic);\r\n    alg.setModel(E);\r\n    for (AssociatedPair p : pairs) {\r\n        assertEquals(0, alg.computeResidual(p), 1e-8);\r\n    }\r\n    assertEquals(0, MultiViewOps.constraint(E, pairs.get(0).p1, pairs.get(0).p2), UtilEjml.TEST_F64);\r\n    AssociatedPair tmpPair = pairs.get(0).copy();\r\n    PerspectiveOps.convertNormToPixel(intrinsic, tmpPair.p1, tmpPair.p1);\r\n    PerspectiveOps.convertNormToPixel(intrinsic, tmpPair.p2, tmpPair.p2);\r\n    tmpPair.p1.x += 2;\r\n    tmpPair.p1.y -= 2;\r\n    PerspectiveOps.convertPixelToNorm(intrinsic, tmpPair.p1, tmpPair.p1);\r\n    PerspectiveOps.convertPixelToNorm(intrinsic, tmpPair.p2, tmpPair.p2);\r\n    assertTrue(Math.abs(alg.computeResidual(tmpPair)) > 1);\r\n    E.data[1] += 0.1;\r\n    alg.setModel(E);\r\n    for (AssociatedPair p : pairs) {\r\n        assertTrue(Math.abs(alg.computeResidual(p)) > 1e-8);\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.geo.FactoryMultiView.triangulatePoseFromPair",
	"Comment": "estimate the camera motion give two observations and the 3d world coordinate of each points.",
	"Method": "PoseFromPairLinear6 triangulatePoseFromPair(){\r\n    return new PoseFromPairLinear6();\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedU16.getBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "int getBand(int x,int y,int band){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    return data[getIndex(x, y, band)] & 0xFFFF;\r\n}"
}, {
	"Path": "boofcv.alg.geo.rectify.RectifyCalibrated.getCalibrationMatrix",
	"Comment": "if a single calibration matrix was requested then this returns it.",
	"Method": "DMatrixRMaj getCalibrationMatrix(){\r\n    return K.getDDRM();\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoPlaneInfinity.computeAngleOfRotation",
	"Comment": "computes the angle of rotation between two pointing vectors on the ground plane and adds it to a list.",
	"Method": "void computeAngleOfRotation(PointTrack t,Vector3D_F64 pointingPlane){\r\n    VoTrack p = t.getCookie();\r\n    groundCurr.x = pointingPlane.z;\r\n    groundCurr.y = -pointingPlane.x;\r\n    double norm = groundCurr.norm();\r\n    groundCurr.x /= norm;\r\n    groundCurr.y /= norm;\r\n    double dot = groundCurr.x * p.ground.x + groundCurr.y * p.ground.y;\r\n    if (dot > 1.0)\r\n        dot = 1.0;\r\n    double angle = Math.acos(dot);\r\n    if (groundCurr.x * p.ground.y - groundCurr.y * p.ground.x > 0)\r\n        angle = -angle;\r\n    farAngles.add(angle);\r\n}"
}, {
	"Path": "boofcv.alg.filter.derivative.impl.TestGradientSobel_Outer.process_F32_naive",
	"Comment": "see if the same results are returned by imagebyte2d equivalent",
	"Method": "void process_F32_naive(){\r\n    for (int offY = 0; offY < 3; offY++) {\r\n        for (int offX = 0; offX < 3; offX++) {\r\n            int w = width + offX;\r\n            int h = height + offY;\r\n            GrayF32 img = new GrayF32(w, h);\r\n            ImageMiscOps.fillUniform(img, rand, 0f, 255f);\r\n            GrayF32 derivX = new GrayF32(w, h);\r\n            GrayF32 derivY = new GrayF32(w, h);\r\n            GrayF32 derivX2 = new GrayF32(w, h);\r\n            GrayF32 derivY2 = new GrayF32(w, h);\r\n            GradientSobel_Naive.process(img, derivX2, derivY2);\r\n            GradientSobel_Outer.process_F32(img, derivX, derivY);\r\n            BoofTesting.assertEquals(derivX2, derivX, 1e-4f);\r\n            BoofTesting.assertEquals(derivY2, derivY, 1e-4f);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.BinaryEllipseDetector.process",
	"Comment": "detects ellipses inside the binary image and refines the edges for all detections inside the gray image",
	"Method": "void process(T gray,GrayU8 binary){\r\n    results.reset();\r\n    ellipseDetector.process(binary);\r\n    if (ellipseRefiner != null)\r\n        ellipseRefiner.setImage(gray);\r\n    intensityCheck.setImage(gray);\r\n    List<BinaryEllipseDetectorPixel.Found> found = ellipseDetector.getFound();\r\n    for (BinaryEllipseDetectorPixel.Found f : found) {\r\n        if (!intensityCheck.process(f.ellipse)) {\r\n            if (verbose)\r\n                System.out.println(\"Rejecting ellipse. Initial fit didn't have intense enough edge\");\r\n            continue;\r\n        }\r\n        EllipseInfo r = results.grow();\r\n        r.contour = f.contour;\r\n        if (ellipseRefiner != null) {\r\n            if (!ellipseRefiner.process(f.ellipse, r.ellipse)) {\r\n                if (verbose)\r\n                    System.out.println(\"Rejecting ellipse. Refined fit didn't have an intense enough edge\");\r\n                results.removeTail();\r\n                continue;\r\n            } else if (!intensityCheck.process(f.ellipse)) {\r\n                if (verbose)\r\n                    System.out.println(\"Rejecting ellipse. Refined fit didn't have an intense enough edge\");\r\n                continue;\r\n            }\r\n        } else {\r\n            r.ellipse.set(f.ellipse);\r\n        }\r\n        r.averageInside = intensityCheck.averageInside;\r\n        r.averageOutside = intensityCheck.averageOutside;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.robust.StandardModelGeneratorTests.simpleTest",
	"Comment": "give it points which have been transform by the true affine model.see\tif the transform is correctly estimated",
	"Method": "void simpleTest(){\r\n    Model model = helper.createRandomModel();\r\n    List<Point> dataSet = new ArrayList();\r\n    for (int i = 0; i < 10; i++) {\r\n        Point p = helper.createRandomPointFromModel(model);\r\n        dataSet.add(p);\r\n    }\r\n    ModelGenerator<Model, Point> fitter = createAlg();\r\n    Model found = createModelInstance();\r\n    assertTrue(fitter.generate(dataSet, found));\r\n    assertTrue(helper.doPointsFitModel(found, dataSet));\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.EstimateSceneCalibrated.determineScale",
	"Comment": "determine scale factor difference between edge triangulation and world",
	"Method": "double determineScale(View base,Motion edge){\r\n    View viewA = edge.viewSrc;\r\n    View viewB = edge.viewDst;\r\n    boolean baseIsA = base == viewA;\r\n    Point3D_F64 worldInBase3D = new Point3D_F64();\r\n    Point3D_F64 localInBase3D = new Point3D_F64();\r\n    GrowQueue_F64 scales = new GrowQueue_F64();\r\n    for (int i = 0; i < edge.stereoTriangulations.size(); i++) {\r\n        Feature3D edge3D = edge.stereoTriangulations.get(i);\r\n        int indexSrc = edge3D.obsIdx.get(0);\r\n        int indexDst = edge3D.obsIdx.get(1);\r\n        Feature3D world3D = baseIsA ? viewA.features3D[indexSrc] : viewB.features3D[indexDst];\r\n        if (world3D == null)\r\n            continue;\r\n        SePointOps_F64.transformReverse(base.viewToWorld, world3D.worldPt, worldInBase3D);\r\n        if (!baseIsA) {\r\n            SePointOps_F64.transform(edge.a_to_b, edge3D.worldPt, localInBase3D);\r\n        } else {\r\n            localInBase3D.set(edge3D.worldPt);\r\n        }\r\n        scales.add(worldInBase3D.z / localInBase3D.z);\r\n    }\r\n    if (scales.size < 20) {\r\n        throw new Exception(\"Not enough matches with known points\");\r\n    }\r\n    scales.sort();\r\n    return scales.getFraction(0.5);\r\n}"
}, {
	"Path": "boofcv.examples.sfm.ExampleMultiviewSceneReconstruction.process",
	"Comment": "process the images and reconstructor the scene as a point cloud using matching interest points between\timages.",
	"Method": "void process(CameraPinholeRadial intrinsic,List<BufferedImage> colorImages){\r\n    DetectDescribePoint detDesc = FactoryDetectDescribe.surfStable(null, null, null, GrayF32.class);\r\n    ScoreAssociation scorer = FactoryAssociation.defaultScore(detDesc.getDescriptionType());\r\n    AssociateDescription<TupleDesc> associate = FactoryAssociation.greedy(scorer, Double.MAX_VALUE, true);\r\n    PairwiseImageMatching<GrayF32> imageMatching = new PairwiseImageMatching(detDesc, associate);\r\n    imageMatching.setVerbose(System.out, 0);\r\n    String cameraName = \"camera\";\r\n    imageMatching.addCamera(cameraName, LensDistortionOps.narrow(intrinsic).undistort_F64(true, false), intrinsic);\r\n    for (int i = 0; i < colorImages.size(); i++) {\r\n        BufferedImage colorImage = colorImages.get(i);\r\n        if (colorImage.getWidth() != intrinsic.width || colorImage.getHeight() != intrinsic.height)\r\n            throw new RuntimeException(\"Looks like you tried to hack this example and run it on random images. Please RTFM\");\r\n        GrayF32 image = ConvertBufferedImage.convertFrom(colorImage, (GrayF32) null);\r\n        imageMatching.addImage(image, cameraName);\r\n    }\r\n    if (!imageMatching.process()) {\r\n        throw new RuntimeException(\"Failed to match images! total=\" + colorImages.size());\r\n    }\r\n    EstimateSceneCalibrated estimateScene = new EstimateSceneCalibrated();\r\n    estimateScene.setVerbose(System.out, 0);\r\n    if (!estimateScene.process(imageMatching.getGraph()))\r\n        throw new RuntimeException(\"Scene estimation failed\");\r\n    SceneStructureMetric structure = estimateScene.getSceneStructure();\r\n    SceneObservations observations = estimateScene.getObservations();\r\n    ConfigLevenbergMarquardt configLM = new ConfigLevenbergMarquardt();\r\n    configLM.dampeningInitial = 1e-12;\r\n    configLM.hessianScaling = true;\r\n    ConfigBundleAdjustment configSBA = new ConfigBundleAdjustment();\r\n    configSBA.configOptimizer = configLM;\r\n    BundleAdjustment<SceneStructureMetric> sba = FactoryMultiView.bundleAdjustmentMetric(configSBA);\r\n    sba.configure(1e-10, 1e-10, 100);\r\n    sba.setVerbose(System.out, 0);\r\n    ScaleSceneStructure bundleScale = new ScaleSceneStructure();\r\n    PruneStructureFromSceneMetric pruner = new PruneStructureFromSceneMetric(structure, observations);\r\n    pruner.prunePoints(3);\r\n    int pruneCycles = 5;\r\n    for (int i = 0; i < pruneCycles; i++) {\r\n        System.out.println(\"BA + Prune iteration = \" + i + \"  points=\" + structure.points.length + \"  obs=\" + observations.getObservationCount());\r\n        bundleScale.applyScale(structure, observations);\r\n        sba.setParameters(structure, observations);\r\n        if (!sba.optimize(structure)) {\r\n            throw new RuntimeException(\"Bundle adjustment failed!\");\r\n        }\r\n        bundleScale.undoScale(structure, observations);\r\n        if (i == pruneCycles - 1)\r\n            break;\r\n        System.out.println(\"Pruning....\");\r\n        pruner.pruneObservationsByErrorRank(0.97);\r\n        pruner.prunePoints(3, 0.4);\r\n        pruner.prunePoints(2);\r\n        pruner.pruneViews(10);\r\n    }\r\n    visualizeResults(structure, colorImages);\r\n    System.out.println(\"Done!\");\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.MergeSmallRegions.setupPruneList",
	"Comment": "identifies which regions are to be pruned based on their member counts. then sets up\tdata structures for graph and converting segment id to prune id.",
	"Method": "boolean setupPruneList(GrowQueue_I32 regionMemberCount){\r\n    segmentPruneFlag.resize(regionMemberCount.size);\r\n    pruneGraph.reset();\r\n    segmentToPruneID.resize(regionMemberCount.size);\r\n    for (int i = 0; i < regionMemberCount.size; i++) {\r\n        if (regionMemberCount.get(i) < minimumSize) {\r\n            segmentToPruneID.set(i, pruneGraph.size());\r\n            Node n = pruneGraph.grow();\r\n            n.init(i);\r\n            segmentPruneFlag.set(i, true);\r\n        } else {\r\n            segmentPruneFlag.set(i, false);\r\n        }\r\n    }\r\n    return pruneGraph.size() != 0;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TestTldRegionTracker.process",
	"Comment": "very basic test.feeds it the same image twice and sees if it does nothing without blowing up.",
	"Method": "void process(){\r\n    TldRegionTracker alg = createAlg();\r\n    Rectangle2D_F64 rect = new Rectangle2D_F64(10, 20, 115, 125);\r\n    alg.initialize(pyramid);\r\n    assertTrue(alg.process(pyramid, rect));\r\n    assertEquals(alg.getPairs().size, 10 * 10);\r\n    assertTrue(alg.process(pyramid, rect));\r\n    assertEquals(alg.getPairs().size, 10 * 10);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setInitSQL",
	"Comment": "specifies an initial sql statement that is run only when a connection is first created.",
	"Method": "void setInitSQL(String initSQL){\r\n    this.initSQL = checkNotNull(initSQL);\r\n}"
}, {
	"Path": "com.bugsnag.android.Client.setUserName",
	"Comment": "set the name of the current user.you can search for this information in your bugsnag dashboard.",
	"Method": "void setUserName(String name){\r\n    user.setName(name);\r\n    if (config.getPersistUserBetweenSessions()) {\r\n        storeInSharedPrefs(USER_NAME_KEY, name);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareGridTools.checkFlip",
	"Comment": "checks to see if it needs to be flipped.flipping is required if x and y axis in 2d grid\tare not ccw.",
	"Method": "boolean checkFlip(SquareGrid grid){\r\n    if (grid.columns == 1 || grid.rows == 1)\r\n        return false;\r\n    Point2D_F64 a = grid.get(0, 0).center;\r\n    Point2D_F64 b = grid.get(0, grid.columns - 1).center;\r\n    Point2D_F64 c = grid.get(grid.rows - 1, 0).center;\r\n    double x0 = b.x - a.x;\r\n    double y0 = b.y - a.y;\r\n    double x1 = c.x - a.x;\r\n    double y1 = c.y - a.y;\r\n    double z = x0 * y1 - y0 * x1;\r\n    return z < 0;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.direct.VisOdomDirectColorDepth.computeFeatureDiversity",
	"Comment": "computes the diversity of valid pixels in keyframe to the location in the current frame.",
	"Method": "double computeFeatureDiversity(Se3_F32 keyToCurrent){\r\n    diversity.reset();\r\n    for (int i = 0; i < keypixels.size(); i++) {\r\n        Pixel p = keypixels.data[i];\r\n        if (!p.valid)\r\n            continue;\r\n        SePointOps_F32.transform(keyToCurrent, p.p3, S);\r\n        diversity.addPoint(S.x, S.y, S.z);\r\n    }\r\n    diversity.process();\r\n    return diversity.getSpread();\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.TestPnPStereoDistanceReprojectionSq.checkBehindCamera_Right",
	"Comment": "have the observation be behind the right camera but not the left",
	"Method": "void checkBehindCamera_Right(){\r\n    checkBehind(0.1, 0.05);\r\n}"
}, {
	"Path": "boofcv.abst.geo.bundle.SceneStructureMetric.initialize",
	"Comment": "call this function first. specifies number of each type of data which is available.",
	"Method": "void initialize(int totalCameras,int totalViews,int totalPoints){\r\n    cameras = new Camera[totalCameras];\r\n    views = new View[totalViews];\r\n    points = new Point[totalPoints];\r\n    for (int i = 0; i < cameras.length; i++) {\r\n        cameras[i] = new Camera();\r\n    }\r\n    for (int i = 0; i < views.length; i++) {\r\n        views[i] = new View();\r\n    }\r\n    for (int i = 0; i < points.length; i++) {\r\n        points[i] = new Point(pointSize);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.KltTracker.setAllowedBounds",
	"Comment": "precompute image bounds that the feature is allowed inside of",
	"Method": "void setAllowedBounds(KltFeature feature){\r\n    widthFeature = feature.radius * 2 + 1;\r\n    lengthFeature = widthFeature * widthFeature;\r\n    allowedLeft = feature.radius;\r\n    allowedTop = feature.radius;\r\n    allowedRight = image.width - feature.radius - 1;\r\n    allowedBottom = image.height - feature.radius - 1;\r\n    outsideLeft = -feature.radius;\r\n    outsideTop = -feature.radius;\r\n    outsideRight = image.width + feature.radius - 1;\r\n    outsideBottom = image.height + feature.radius - 1;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.SplitMergeLineFitSegment.mergeSegments",
	"Comment": "merges lines together which have an acute angle less than the threshold.",
	"Method": "boolean mergeSegments(){\r\n    if (splits.size <= 2)\r\n        return false;\r\n    boolean change = false;\r\n    work.reset();\r\n    work.add(splits.data[0]);\r\n    for (int i = 0; i < splits.size - 2; i++) {\r\n        if (selectSplitBetween(splits.data[i], splits.data[i + 2]) < 0) {\r\n            change = true;\r\n        } else {\r\n            work.add(splits.data[i + 1]);\r\n        }\r\n    }\r\n    work.add(splits.data[splits.size - 1]);\r\n    GrowQueue_I32 tmp = work;\r\n    work = splits;\r\n    splits = tmp;\r\n    return change;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldTracker.getTargetRegion",
	"Comment": "returns the estimated location of the target in the current image",
	"Method": "Rectangle2D_F64 getTargetRegion(){\r\n    return targetRegion;\r\n}"
}, {
	"Path": "boofcv.alg.geo.impl.ImplRectifyImageOps_F32.adjustUncalibrated",
	"Comment": "internal function which applies the rectification adjustment to an uncalibrated stereo pair",
	"Method": "void adjustUncalibrated(FMatrixRMaj rectifyLeft,FMatrixRMaj rectifyRight,RectangleLength2D_F32 bound,float scale){\r\n    float deltaX = -bound.x0 * scale;\r\n    float deltaY = -bound.y0 * scale;\r\n    SimpleMatrix A = new SimpleMatrix(3, 3, true, new float[] { scale, 0, deltaX, 0, scale, deltaY, 0, 0, 1 });\r\n    SimpleMatrix rL = SimpleMatrix.wrap(rectifyLeft);\r\n    SimpleMatrix rR = SimpleMatrix.wrap(rectifyRight);\r\n    rectifyLeft.set(A.mult(rL).getFDRM());\r\n    rectifyRight.set(A.mult(rR).getFDRM());\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.TestEquirectangularRotate_F64.simpleTests",
	"Comment": "sees if recentering moves it to approximately the expected location",
	"Method": "void simpleTests(){\r\n    EquirectangularRotate_F64 alg = new EquirectangularRotate_F64();\r\n    alg.setEquirectangularShape(300, 251);\r\n    alg.setDirection(0, 0, 0);\r\n    alg.compute((int) (300.0 * 0.5), 250 / 2);\r\n    assertMatch(alg, 300.0 * 0.5, 250 / 2);\r\n    alg.setDirection(Math.PI / 2.0, 0, 0);\r\n    alg.compute((int) (300.0 * 0.5), 250 / 2);\r\n    assertMatch(alg, 300.0 * 0.75, 250 / 2);\r\n    alg.setDirection(0, Math.PI / 2, 0);\r\n    alg.compute((int) (300.0 * 0.5), 250 / 2);\r\n    assertEquals(0, alg.distY, GrlConstants.TEST_F64);\r\n    alg.setDirection(0, -Math.PI / 2, 0);\r\n    alg.compute((int) (300.0 * 0.5), 250 / 2);\r\n    assertEquals(250, alg.distY, GrlConstants.TEST_F64);\r\n    alg.setDirection(0, Math.PI / 4.0, 0);\r\n    alg.compute((int) (300.0 * 0.5), 250 / 2);\r\n    assertMatch(alg, 300.0 * 0.5, 250 / 4 + 0.5);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.helpers.LocationHelper.getLocation",
	"Comment": "returns a future that resolves some time in the future after the location is queried from google api.it returns a string for the location based on the cell id.",
	"Method": "CompletableFuture<Location> getLocation(S2CellId s2CellId){\r\n    return CompletableFuture.supplyAsync(() -> {\r\n        if (SAVED_LOCATIONS.containsKey(s2CellId.id())) {\r\n            return SAVED_LOCATIONS.get(s2CellId.id());\r\n        }\r\n        Location location = null;\r\n        final LatLongLocation latLng = new LatLongLocation(s2CellId);\r\n        try {\r\n            final JSONObject json = queryJsonFromUrl(latLng.toString());\r\n            final String formattedLocation = formattedLocationFromGoogleResponse(json);\r\n            final String city = cityFromGoogleResponse(json);\r\n            if (formattedLocation != null) {\r\n                location = new Location(formattedLocation, city != null ? city : \"\");\r\n                SAVED_LOCATIONS.put(s2CellId.id(), location);\r\n            } else {\r\n                location = new Location(\"Error: \" + json.optString(GoogleKey.STATUS));\r\n            }\r\n        } catch (IOException | JSONException e) {\r\n            location = new Location(\"Exception: \" + e.getMessage());\r\n        }\r\n        save();\r\n        return location;\r\n    });\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomDualTrackPnP.addNewTracks",
	"Comment": "spawns tracks in each image and associates features together.",
	"Method": "void addNewTracks(){\r\n    trackerLeft.spawnTracks();\r\n    trackerRight.spawnTracks();\r\n    List<PointTrack> newLeft = trackerLeft.getNewTracks(null);\r\n    List<PointTrack> newRight = trackerRight.getNewTracks(null);\r\n    addNewToList(inputLeft, newLeft, pointsLeft, descLeft);\r\n    addNewToList(inputRight, newRight, pointsRight, descRight);\r\n    assocL2R.setSource(pointsLeft, descLeft);\r\n    assocL2R.setDestination(pointsRight, descRight);\r\n    assocL2R.associate();\r\n    FastQueue<AssociatedIndex> matches = assocL2R.getMatches();\r\n    Point3D_F64 cameraP3 = new Point3D_F64();\r\n    for (int i = 0; i < matches.size; i++) {\r\n        AssociatedIndex m = matches.get(i);\r\n        PointTrack trackL = newLeft.get(m.src);\r\n        PointTrack trackR = newRight.get(m.dst);\r\n        LeftTrackInfo infoLeft = trackL.getCookie();\r\n        if (infoLeft == null)\r\n            trackL.cookie = infoLeft = new LeftTrackInfo();\r\n        RightTrackInfo infoRight = trackR.getCookie();\r\n        if (infoRight == null)\r\n            trackR.cookie = infoRight = new RightTrackInfo();\r\n        Stereo2D3D p2d3d = infoLeft.location;\r\n        leftImageToNorm.compute(trackL.x, trackL.y, p2d3d.leftObs);\r\n        rightImageToNorm.compute(trackR.x, trackR.y, p2d3d.rightObs);\r\n        if (triangulate.triangulate(p2d3d.leftObs, p2d3d.rightObs, leftToRight, cameraP3)) {\r\n            SePointOps_F64.transform(currToKey, cameraP3, p2d3d.location);\r\n            infoLeft.right = trackR;\r\n            infoLeft.lastConsistent = infoLeft.lastInlier = tick;\r\n            infoRight.left = trackL;\r\n        } else {\r\n            trackerLeft.dropTrack(trackL);\r\n            throw new RuntimeException(\"This special case needs to be handled!\");\r\n        }\r\n    }\r\n    GrowQueue_I32 unassignedRight = assocL2R.getUnassociatedDestination();\r\n    for (int i = 0; i < unassignedRight.size; i++) {\r\n        int index = unassignedRight.get(i);\r\n        trackerRight.dropTrack(newRight.get(index));\r\n    }\r\n    GrowQueue_I32 unassignedLeft = assocL2R.getUnassociatedSource();\r\n    for (int i = 0; i < unassignedLeft.size; i++) {\r\n        int index = unassignedLeft.get(i);\r\n        trackerLeft.dropTrack(newLeft.get(index));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.slic.SegmentSlic.assignLabelsToPixels",
	"Comment": "selects which region each pixel belongs to based on which cluster it is the closest to",
	"Method": "void assignLabelsToPixels(GrayS32 pixelToRegions,GrowQueue_I32 regionMemberCount,FastQueue<float[]> regionColor){\r\n    regionColor.reset();\r\n    for (int i = 0; i < clusters.size(); i++) {\r\n        float[] r = regionColor.grow();\r\n        float[] c = clusters.get(i).color;\r\n        for (int j = 0; j < numBands; j++) {\r\n            r[j] = c[j];\r\n        }\r\n    }\r\n    regionMemberCount.resize(clusters.size());\r\n    regionMemberCount.fill(0);\r\n    int indexPixel = 0;\r\n    for (int y = 0; y < pixelToRegions.height; y++) {\r\n        int indexOutput = pixelToRegions.startIndex + y * pixelToRegions.stride;\r\n        for (int x = 0; x < pixelToRegions.width; x++, indexPixel++, indexOutput++) {\r\n            Pixel p = pixels.data[indexPixel];\r\n            int best = -1;\r\n            float bestDistance = Float.MAX_VALUE;\r\n            for (int j = 0; j < p.clusters.size; j++) {\r\n                ClusterDistance d = p.clusters.data[j];\r\n                if (d.distance < bestDistance) {\r\n                    bestDistance = d.distance;\r\n                    best = d.cluster.id;\r\n                }\r\n            }\r\n            if (best == -1) {\r\n                regionColor.grow();\r\n                best = regionMemberCount.size();\r\n                regionMemberCount.add(0);\r\n            }\r\n            pixelToRegions.data[indexOutput] = best;\r\n            regionMemberCount.data[best]++;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.feature.describe.FactoryDescribeRegionPoint.pixel",
	"Comment": "creates a region descriptor based on pixel intensity values alone.a classic and fast to compute\tdescriptor, but much less stable than more modern ones.",
	"Method": "DescribeRegionPoint<T, D> pixel(int regionWidth,int regionHeight,Class<T> imageType){\r\n    return new WrapDescribePixelRegion(FactoryDescribePointAlgs.pixelRegion(regionWidth, regionHeight, imageType), imageType);\r\n}"
}, {
	"Path": "boofcv.alg.flow.DenseFlowPyramidBase.interpolateFlowScale",
	"Comment": "takes the flow from the previous lower resolution layer and uses it to initialize the flow\tin the current layer.adjusts for change in image scale.",
	"Method": "void interpolateFlowScale(GrayF32 prev,GrayF32 curr){\r\n    interp.setImage(prev);\r\n    float scaleX = (float) prev.width / (float) curr.width;\r\n    float scaleY = (float) prev.height / (float) curr.height;\r\n    float scale = (float) prev.width / (float) curr.width;\r\n    int indexCurr = 0;\r\n    for (int y = 0; y < curr.height; y++) {\r\n        float yy = y * scaleY;\r\n        for (int x = 0; x < curr.width; x++) {\r\n            float xx = x * scaleX;\r\n            if (interp.isInFastBounds(xx, yy)) {\r\n                curr.data[indexCurr++] = interp.get_fast(x * scaleX, y * scaleY) / scale;\r\n            } else {\r\n                curr.data[indexCurr++] = interp.get(x * scaleX, y * scaleY) / scale;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.TestPolylineSplitMerge.canBeSplit_special_case",
	"Comment": "special case that requires wrapping around to compute the correct length",
	"Method": "void canBeSplit_special_case(){\r\n    List<Point2D_I32> contour = new ArrayList();\r\n    for (int i = 0; i < 12; i++) {\r\n        contour.add(new Point2D_I32());\r\n    }\r\n    PolylineSplitMerge alg = new PolylineSplitMerge();\r\n    alg.setMinimumSideLength(5);\r\n    alg.setThresholdSideSplitScore(0);\r\n    alg.addCorner(0);\r\n    alg.addCorner(11);\r\n    alg.list.getHead().object.sideError = 1e-6;\r\n    alg.list.getTail().object.sideError = 1e-6;\r\n    assertTrue(alg.canBeSplit(contour, alg.list.getHead(), false));\r\n    assertFalse(alg.canBeSplit(contour, alg.list.getTail(), false));\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.PairwiseImageMatching.connectViews",
	"Comment": "associate features between the two views. then compute a homography and essential matrix using lsmed. add\tfeatures to the edge if they an inlier in essential. save fit score of homography vs essential.",
	"Method": "boolean connectViews(PairwiseImageGraph.View viewA,PairwiseImageGraph.View viewB,FastQueue<AssociatedIndex> matches){\r\n    PairwiseImageGraph.Motion edge = new PairwiseImageGraph.Motion();\r\n    int inliersEpipolar;\r\n    CameraPinhole pinhole0 = viewA.camera.pinhole;\r\n    CameraPinhole pinhole1 = viewB.camera.pinhole;\r\n    if (pinhole0 != null && pinhole1 != null) {\r\n        ransacEssential.setIntrinsic(0, pinhole0);\r\n        ransacEssential.setIntrinsic(1, pinhole1);\r\n        if (!fitEpipolar(matches, viewA.observationNorm.toList(), viewB.observationNorm.toList(), ransacEssential, edge)) {\r\n            if (verbose != null && verboseLevel >= 1) {\r\n                verbose.println(\" fit essential failed\");\r\n            }\r\n            return false;\r\n        }\r\n        edge.metric = true;\r\n        inliersEpipolar = ransacEssential.getMatchSet().size();\r\n        edge.F.set(ransacEssential.getModelParameters());\r\n    } else if (fitEpipolar(matches, viewA.observationPixels.toList(), viewB.observationPixels.toList(), ransacFundamental, edge)) {\r\n        edge.metric = false;\r\n        inliersEpipolar = ransacFundamental.getMatchSet().size();\r\n        edge.F.set(ransacFundamental.getModelParameters());\r\n    } else {\r\n        if (verbose != null && verboseLevel >= 1) {\r\n            verbose.println(\" fit fundamental failed\");\r\n        }\r\n        return false;\r\n    }\r\n    if (inliersEpipolar < MIN_FEATURE_ASSOCIATED) {\r\n        if (verbose != null && verboseLevel >= 1) {\r\n            verbose.println(\" too too few inliers. \" + inliersEpipolar + \" min=\" + MIN_FEATURE_ASSOCIATED + \" obsA=\" + viewA.observationNorm.size + \" obsB=\" + viewB.observationNorm.size);\r\n        }\r\n        return false;\r\n    }\r\n    double fractionA = inliersEpipolar / (double) viewA.descriptions.size;\r\n    double fractionB = inliersEpipolar / (double) viewB.descriptions.size;\r\n    if (fractionA < MIN_ASSOCIATE_FRACTION | fractionB < MIN_ASSOCIATE_FRACTION)\r\n        return false;\r\n    edge.viewSrc = viewA;\r\n    edge.viewDst = viewB;\r\n    edge.index = graph.edges.size();\r\n    viewA.connections.add(edge);\r\n    viewB.connections.add(edge);\r\n    graph.edges.add(edge);\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.examples.geometry.ExampleImageStitching.stitch",
	"Comment": "given two input images create and display an image where the two have been overlayed on top of each other.",
	"Method": "void stitch(BufferedImage imageA,BufferedImage imageB,Class<T> imageType){\r\n    T inputA = ConvertBufferedImage.convertFromSingle(imageA, null, imageType);\r\n    T inputB = ConvertBufferedImage.convertFromSingle(imageB, null, imageType);\r\n    DetectDescribePoint detDesc = FactoryDetectDescribe.surfStable(new ConfigFastHessian(1, 2, 200, 1, 9, 4, 4), null, null, imageType);\r\n    ScoreAssociation<BrightFeature> scorer = FactoryAssociation.scoreEuclidean(BrightFeature.class, true);\r\n    AssociateDescription<BrightFeature> associate = FactoryAssociation.greedy(scorer, 2, true);\r\n    ModelMatcher<Homography2D_F64, AssociatedPair> modelMatcher = FactoryMultiViewRobust.homographyRansac(null, new ConfigRansac(60, 3));\r\n    Homography2D_F64 H = computeTransform(inputA, inputB, detDesc, associate, modelMatcher);\r\n    renderStitching(imageA, imageB, H);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.KltTracker.internalSetDescriptionBorder",
	"Comment": "computes the descriptor for border features.all it needs to do\tis save the pixel value, but derivative information is also computed\tso that it can reject bad features immediately.",
	"Method": "boolean internalSetDescriptionBorder(KltFeature feature){\r\n    computeSubImageBounds(feature, feature.x, feature.y);\r\n    ImageMiscOps.fill(feature.desc, Float.NaN);\r\n    feature.desc.subimage(dstX0, dstY0, dstX1, dstY1, subimage);\r\n    interpInput.setImage(image);\r\n    interpInput.region(srcX0, srcY0, subimage);\r\n    feature.derivX.subimage(dstX0, dstY0, dstX1, dstY1, subimage);\r\n    interpDeriv.setImage(derivX);\r\n    interpDeriv.region(srcX0, srcY0, subimage);\r\n    feature.derivY.subimage(dstX0, dstY0, dstX1, dstY1, subimage);\r\n    interpDeriv.setImage(derivY);\r\n    interpDeriv.region(srcX0, srcY0, subimage);\r\n    int total = 0;\r\n    Gxx = Gyy = Gxy = 0;\r\n    for (int i = 0; i < lengthFeature; i++) {\r\n        if (Float.isNaN(feature.desc.data[i]))\r\n            continue;\r\n        total++;\r\n        float dX = feature.derivX.data[i];\r\n        float dY = feature.derivY.data[i];\r\n        Gxx += dX * dX;\r\n        Gyy += dY * dY;\r\n        Gxy += dX * dY;\r\n    }\r\n    feature.Gxx = Gxx;\r\n    feature.Gyy = Gyy;\r\n    feature.Gxy = Gxy;\r\n    float det = Gxx * Gyy - Gxy * Gxy;\r\n    return (det >= config.minDeterminant * total);\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.TestDescribePointSift.computeRawDescriptor_rotation",
	"Comment": "have a constant gradient, which has an easy to understand descriptor, then rotate the feature and see\tif the description changes as expected.",
	"Method": "void computeRawDescriptor_rotation(){\r\n    GrayF32 derivX = new GrayF32(60, 55);\r\n    GrayF32 derivY = new GrayF32(60, 55);\r\n    ImageMiscOps.fill(derivX, 5.0f);\r\n    DescribePointSift<GrayF32> alg = new DescribePointSift(4, 4, 8, 1.5, 0.5, 0.2, GrayF32.class);\r\n    alg.setImageGradient(derivX, derivY);\r\n    for (int i = 0; i < 8; i++) {\r\n        double angle = UtilAngle.bound(i * Math.PI / 4);\r\n        alg.descriptor = new TupleDesc_F64(128);\r\n        alg.computeRawDescriptor(20, 21, 1, angle);\r\n        int bin = (int) (UtilAngle.domain2PI(-angle) * 8 / (2 * Math.PI));\r\n        for (int j = 0; j < 128; j++) {\r\n            if (j % 8 == bin) {\r\n                assertTrue(alg.descriptor.value[j] > 0);\r\n            } else {\r\n                assertEquals(0, alg.descriptor.value[j], 1e-4);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.TestPyramidKltTracker.track_smallOffset",
	"Comment": "test positive examples of tracking when there should be no fault at any point.\tonly a small offset easily done with a single layer tracker",
	"Method": "void track_smallOffset(){\r\n    PyramidKltFeature feature = new PyramidKltFeature(pyramid.getNumLayers(), featureReadius);\r\n    feature.setPosition(cornerX, cornerY);\r\n    tracker.setImage(pyramid, derivX, derivY);\r\n    tracker.setDescription(feature);\r\n    feature.setPosition(cornerX - 1.3f, cornerY + 1.2f);\r\n    assertTrue(tracker.track(feature) == KltTrackFault.SUCCESS);\r\n    assertEquals(cornerX, feature.x, 0.2);\r\n    assertEquals(cornerY, feature.y, 0.2);\r\n}"
}, {
	"Path": "boofcv.alg.geo.rectify.TestRectifyFundamental.checkEpipoles",
	"Comment": "checks to see that the epipoles go to infinity after applying the transforms",
	"Method": "void checkEpipoles(){\r\n    createScene();\r\n    Point3D_F64 epipole1 = new Point3D_F64();\r\n    Point3D_F64 epipole2 = new Point3D_F64();\r\n    MultiViewOps.extractEpipoles(F, epipole1, epipole2);\r\n    RectifyFundamental alg = new RectifyFundamental();\r\n    alg.process(F, pairs, 500, 520);\r\n    DMatrixRMaj R1 = alg.getRect1();\r\n    DMatrixRMaj R2 = alg.getRect2();\r\n    assertTrue(Math.abs(epipole1.z) > 1e-8);\r\n    assertTrue(Math.abs(epipole2.z) > 1e-8);\r\n    GeometryMath_F64.mult(R1, epipole1, epipole1);\r\n    GeometryMath_F64.mult(R2, epipole2, epipole2);\r\n    assertEquals(0, epipole1.z, 1e-12);\r\n    assertEquals(0, epipole2.z, 1e-12);\r\n}"
}, {
	"Path": "boofcv.android.ConvertBitmap.bitmapToPlanar",
	"Comment": "converts bitmap image into planar image of the appropriate type.",
	"Method": "Planar<T> bitmapToPlanar(Bitmap input,Planar<T> output,Class<T> type,byte[] storage){\r\n    if (output == null) {\r\n        output = new Planar(type, input.getWidth(), input.getHeight(), 3);\r\n    } else {\r\n        int numBands = Math.min(4, Math.max(3, output.getNumBands()));\r\n        output.reshape(input.getWidth(), input.getHeight(), numBands);\r\n    }\r\n    if (storage == null)\r\n        storage = declareStorage(input, null);\r\n    input.copyPixelsToBuffer(ByteBuffer.wrap(storage));\r\n    if (type == GrayU8.class)\r\n        ImplConvertBitmap.arrayToPlanar_U8(storage, input.getConfig(), (Planar) output);\r\n    else if (type == GrayF32.class)\r\n        ImplConvertBitmap.arrayToPlanar_F32(storage, input.getConfig(), (Planar) output);\r\n    else\r\n        throw new IllegalArgumentException(\"Unsupported BoofCV Type\");\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.RefinePolyLineCorner.optimize",
	"Comment": "searches around the current c1 point for the best place to put the corner",
	"Method": "int optimize(List<Point2D_I32> contour,int c0,int c1,int c2){\r\n    double bestDistance = computeCost(contour, c0, c1, c2, 0);\r\n    int bestIndex = 0;\r\n    for (int i = -searchRadius; i <= searchRadius; i++) {\r\n        if (i == 0) {\r\n            if (bestIndex != 0)\r\n                break;\r\n        } else {\r\n            double found = computeCost(contour, c0, c1, c2, i);\r\n            if (found < bestDistance) {\r\n                bestDistance = found;\r\n                bestIndex = i;\r\n            }\r\n        }\r\n    }\r\n    return CircularIndex.addOffset(c1, bestIndex, contour.size());\r\n}"
}, {
	"Path": "boofcv.factory.geo.FactoryMultiView.triangulateTwoGeometric",
	"Comment": "triangulate two view by finding the intersection of two rays.",
	"Method": "TriangulateTwoViewsCalibrated triangulateTwoGeometric(){\r\n    return new WrapGeometricTriangulation();\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquaresIntoCrossClusters.candidateIsMuchCloser",
	"Comment": "checks to see if the two corners which are to be connected are by far the two closest corners between the two\tsquares",
	"Method": "boolean candidateIsMuchCloser(SquareNode node0,SquareNode node1,double distance2){\r\n    double length = Math.max(node0.largestSide, node1.largestSide) * tooFarFraction;\r\n    length *= length;\r\n    if (distance2 > length)\r\n        return false;\r\n    return distance2 <= length;\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.ImplDisparityScoreSadRectFive_U8.computeScoreFive",
	"Comment": "compute the final score by sampling the 5 regions.four regions are sampled around the center\tregion.out of those four only the two with the smallest score are used.",
	"Method": "void computeScoreFive(int top,int middle,int bottom,int score,int width){\r\n    for (int d = minDisparity; d < maxDisparity; d++) {\r\n        int indexSrc = (d - minDisparity) * width + (d - minDisparity) + radiusX;\r\n        int indexDst = (d - minDisparity) * width + (d - minDisparity);\r\n        int end = indexSrc + (width - d - 4 * radiusX);\r\n        while (indexSrc < end) {\r\n            int s = 0;\r\n            int val0 = top[indexSrc - radiusX];\r\n            int val1 = top[indexSrc + radiusX];\r\n            int val2 = bottom[indexSrc - radiusX];\r\n            int val3 = bottom[indexSrc + radiusX];\r\n            if (val1 < val0) {\r\n                int temp = val0;\r\n                val0 = val1;\r\n                val1 = temp;\r\n            }\r\n            if (val3 < val2) {\r\n                int temp = val2;\r\n                val2 = val3;\r\n                val3 = temp;\r\n            }\r\n            if (val3 < val0) {\r\n                s += val2;\r\n                s += val3;\r\n            } else if (val2 < val1) {\r\n                s += val2;\r\n                s += val0;\r\n            } else {\r\n                s += val0;\r\n                s += val1;\r\n            }\r\n            score[indexDst++] = s + middle[indexSrc++];\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.TestRegionMergeTree.markMerge_quick",
	"Comment": "tests focused on the quick test.all these cases should result in no change",
	"Method": "void markMerge_quick(){\r\n    int[] expected = new int[] { 1, 1, 2, 2, 2, 3, 5 };\r\n    RegionMergeTree alg = new RegionMergeTree();\r\n    alg.mergeList.resize(7);\r\n    alg.mergeList.data = new int[] { 1, 1, 2, 2, 2, 3, 5 };\r\n    alg.markMerge(3, 4);\r\n    for (int i = 0; i < expected.length; i++) assertEquals(expected[i], alg.mergeList.data[i]);\r\n    alg.markMerge(3, 2);\r\n    for (int i = 0; i < expected.length; i++) assertEquals(expected[i], alg.mergeList.data[i]);\r\n    alg.markMerge(2, 3);\r\n    for (int i = 0; i < expected.length; i++) assertEquals(expected[i], alg.mergeList.data[i]);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.TestRefinePolyLineCorner.tooFewPoints",
	"Comment": "test to see if it gracefully handles the case where there are too few points",
	"Method": "void tooFewPoints(){\r\n    RefinePolyLineCorner alg = new RefinePolyLineCorner(true);\r\n    GrowQueue_I32 corners = new GrowQueue_I32();\r\n    List<Point2D_I32> contour = new ArrayList();\r\n    for (int i = 0; i < 3; i++) {\r\n        assertFalse(alg.fit(contour, corners));\r\n        corners.add(i);\r\n        contour.add(new Point2D_I32(i, 2));\r\n    }\r\n    assertTrue(alg.fit(contour, corners));\r\n}"
}, {
	"Path": "boofcv.alg.sfm.TestStereoProcessingBase.checkRectification",
	"Comment": "center a point in the left and right images.search for the point and see if after rectification\tthe point can be found on the same row in both images.",
	"Method": "void checkRectification(){\r\n    Point3D_F64 X = new Point3D_F64(-0.01, 0.1, 3);\r\n    StereoParameters param = createStereoParam(width, height);\r\n    GrayU8 left = new GrayU8(width, height);\r\n    GrayU8 right = new GrayU8(width, height);\r\n    Point2D_F64 lensLeft = new Point2D_F64();\r\n    Point2D_F64 lensRight = new Point2D_F64();\r\n    SfmTestHelper.renderPointPixel(param, X, lensLeft, lensRight);\r\n    left.set((int) lensLeft.x, (int) lensLeft.y, 200);\r\n    right.set((int) lensRight.x, (int) lensRight.y, 200);\r\n    StereoProcessingBase<GrayU8> alg = new StereoProcessingBase(GrayU8.class);\r\n    alg.setCalibration(param);\r\n    alg.setImages(left, right);\r\n    alg.initialize();\r\n    assertFalse(Math.abs(lensLeft.y - lensRight.y) <= 1);\r\n    Point2D_F64 foundLeft = centroid(alg.getImageLeftRect());\r\n    Point2D_F64 foundRight = centroid(alg.getImageRightRect());\r\n    assertTrue(Math.abs(foundLeft.y - foundRight.y) <= 1);\r\n    assertTrue(foundRight.x < foundLeft.x);\r\n}"
}, {
	"Path": "boofcv.testing.BoofTesting.assertEqualsBorder",
	"Comment": "checks to see if only the image borders are equal to each other within tolerance",
	"Method": "void assertEqualsBorder(ImageGray imgA,ImageGray imgB,double tol,int borderX,int borderY){\r\n    if (imgA.getWidth() != imgB.getWidth())\r\n        throw new RuntimeException(\"Widths are not equals\");\r\n    if (imgA.getHeight() != imgB.getHeight())\r\n        throw new RuntimeException(\"Heights are not equals\");\r\n    GImageGray a = FactoryGImageGray.wrap(imgA);\r\n    GImageGray b = FactoryGImageGray.wrap(imgB);\r\n    for (int y = 0; y < imgA.getHeight(); y++) {\r\n        for (int x = 0; x < borderX; x++) {\r\n            compareValues(tol, a, b, x, y);\r\n        }\r\n        for (int x = imgA.getWidth() - borderX; x < imgA.getWidth(); x++) {\r\n            compareValues(tol, a, b, x, y);\r\n        }\r\n    }\r\n    for (int x = borderX; x < imgA.getWidth() - borderX; x++) {\r\n        for (int y = 0; y < borderY; y++) {\r\n            compareValues(tol, a, b, x, y);\r\n        }\r\n        for (int y = imgA.getHeight() - borderY; y < imgA.getHeight(); y++) {\r\n            compareValues(tol, a, b, x, y);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.SegmentMeanShiftSearch.distanceSq",
	"Comment": "returns the euclidean distance squared between the two vectors",
	"Method": "float distanceSq(float[] a,float[] b){\r\n    float ret = 0;\r\n    for (int i = 0; i < a.length; i++) {\r\n        float d = a[i] - b[i];\r\n        ret += d * d;\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "org.boon.core.value.ValueMapImpl.entrySet",
	"Comment": "if the map has not been built yet, then we just return a fake entry set.",
	"Method": "Set<Entry<String, Value>> entrySet(){\r\n    buildIfNeededMap();\r\n    return map.entrySet();\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPDataSource.isWrapperFor",
	"Comment": "returns true if this either implements the interface argument or is directly or indirectly a wrapper for an object that does.",
	"Method": "boolean isWrapperFor(Class<?> arg0){\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.alg.geo.robust.SelectBestStereoTransform.select",
	"Comment": "selects the transform which describes a view where observations appear in front of the camera the most",
	"Method": "void select(List<Se3_F64> candidatesAtoB,List<AssociatedPair> observations,Se3_F64 model){\r\n    Se3_F64 bestModel = null;\r\n    int bestCount = -1;\r\n    for (int i = 0; i < candidatesAtoB.size(); i++) {\r\n        Se3_F64 s = candidatesAtoB.get(i);\r\n        int count = 0;\r\n        for (AssociatedPair p : observations) {\r\n            if (depthCheck.checkConstraint(p.p1, p.p2, s)) {\r\n                count++;\r\n            }\r\n        }\r\n        if (count > bestCount) {\r\n            bestCount = count;\r\n            bestModel = s;\r\n        }\r\n    }\r\n    if (bestModel == null)\r\n        throw new RuntimeException(\"BUG\");\r\n    model.set(bestModel);\r\n}"
}, {
	"Path": "org.boon.core.Dates.euroUTCSystemDateString",
	"Comment": "useful for generated file names and generated work directories.",
	"Method": "String euroUTCSystemDateString(long timestamp){\r\n    Calendar calendar = Calendar.getInstance();\r\n    calendar.setTimeInMillis(timestamp);\r\n    calendar.setTimeZone(UTC_TIME_ZONE);\r\n    int day = calendar.get(Calendar.DAY_OF_MONTH);\r\n    int month = calendar.get(Calendar.MONTH);\r\n    int year = calendar.get(Calendar.YEAR);\r\n    int hour = calendar.get(Calendar.HOUR_OF_DAY);\r\n    int minute = calendar.get(Calendar.MINUTE);\r\n    int second = calendar.get(Calendar.SECOND);\r\n    CharBuf buf = CharBuf.create(16);\r\n    buf.add(Str.zfill(day, 2)).add('_');\r\n    buf.add(Str.zfill(month, 2)).add('_');\r\n    buf.add(year).add('_');\r\n    buf.add(Str.zfill(hour, 2)).add('_');\r\n    buf.add(Str.zfill(minute, 2)).add('_');\r\n    buf.add(Str.zfill(second, 2)).add(\"_utc_euro\");\r\n    return buf.toString();\r\n}"
}, {
	"Path": "org.boon.validation.readers.AnnotationValidatorMetaDataReader.setValidationAnnotationPackages",
	"Comment": "we allow a set of validation annotation packages to be configured.",
	"Method": "void setValidationAnnotationPackages(Set<String> validationAnnotationPackages){\r\n    this.validationAnnotationPackages = validationAnnotationPackages;\r\n}"
}, {
	"Path": "org.boon.StringScanner.splitByCharsNoneEmpty",
	"Comment": "split string by a list of delimiters but none are empty within a range",
	"Method": "String[] splitByCharsNoneEmpty(String string,char delimiters,String[] splitByCharsNoneEmpty,String string,int start,int end,char delimiters){\r\n    Exceptions.requireNonNull(string);\r\n    char[][] comps = CharScanner.splitByCharsNoneEmpty(FastStringUtils.toCharArray(string), start, end, delimiters);\r\n    return Str.fromCharArrayOfArrayToStringArray(comps);\r\n}"
}, {
	"Path": "boofcv.abst.filter.transform.fft.GenericTestDiscreteFourierTransform.multipleCalls_sameSize",
	"Comment": "call the same instance multiples times with images of the same size",
	"Method": "void multipleCalls_sameSize(){\r\n    checkMultipleCalls(new int[] { 52, 52, 52 });\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.BinaryEllipseDetectorPixel.isApproximatelyElliptical",
	"Comment": "look at the maximum distance contour points are from the ellipse and see if they exceed a maximum threshold",
	"Method": "boolean isApproximatelyElliptical(EllipseRotated_F64 ellipse,List<Point2D_F64> points,int maxSamples){\r\n    closestPoint.setEllipse(ellipse);\r\n    double maxDistance2 = maxDistanceFromEllipse * maxDistanceFromEllipse;\r\n    if (points.size() <= maxSamples) {\r\n        for (int i = 0; i < points.size(); i++) {\r\n            Point2D_F64 p = points.get(i);\r\n            closestPoint.process(p);\r\n            double d = closestPoint.getClosest().distance2(p);\r\n            if (d > maxDistance2) {\r\n                return false;\r\n            }\r\n        }\r\n    } else {\r\n        for (int i = 0; i < maxSamples; i++) {\r\n            Point2D_F64 p = points.get(i * points.size() / maxSamples);\r\n            closestPoint.process(p);\r\n            double d = closestPoint.getClosest().distance2(p);\r\n            if (d > maxDistance2) {\r\n                return false;\r\n            }\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.examples.stereo.ExampleStereoDisparity.denseDisparity",
	"Comment": "computes the dense disparity between between two stereo images.the input images\tmust be rectified with lens distortion removed to work!floating point images\tare also supported.",
	"Method": "GrayU8 denseDisparity(GrayU8 rectLeft,GrayU8 rectRight,int regionSize,int minDisparity,int maxDisparity){\r\n    StereoDisparity<GrayU8, GrayU8> disparityAlg = FactoryStereoDisparity.regionWta(DisparityAlgorithms.RECT_FIVE, minDisparity, maxDisparity, regionSize, regionSize, 25, 1, 0.2, GrayU8.class);\r\n    disparityAlg.process(rectLeft, rectRight);\r\n    return disparityAlg.getDisparity();\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedU8.getBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "int getBand(int x,int y,int band){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    return data[getIndex(x, y, band)] & 0xFF;\r\n}"
}, {
	"Path": "boofcv.factory.fiducial.FactoryFiducialCalibration.chessboard",
	"Comment": "detector for chessboard targets.squares can be partially outside, but inside corners must be entirely\tinside the image.",
	"Method": "CalibrationDetectorChessboard chessboard(ConfigChessboard config){\r\n    config.checkValidity();\r\n    return new CalibrationDetectorChessboard(config);\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.slic.SegmentSlic.initializeClusters",
	"Comment": "initialize all the clusters at regularly spaced intervals.their locations are perturbed a bit to reduce\tthe likelihood of a bad location.initial color is set to the image color at the location",
	"Method": "void initializeClusters(){\r\n    int offsetX = Math.max(BORDER, ((input.width - 1) % gridInterval) / 2);\r\n    int offsetY = Math.max(BORDER, ((input.height - 1) % gridInterval) / 2);\r\n    int clusterId = 0;\r\n    clusters.reset();\r\n    for (int y = offsetY; y < input.height - BORDER; y += gridInterval) {\r\n        for (int x = offsetX; x < input.width - BORDER; x += gridInterval) {\r\n            Cluster c = clusters.grow();\r\n            c.id = clusterId++;\r\n            if (c.color == null)\r\n                c.color = new float[numBands];\r\n            perturbCenter(c, x, y);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.impl.TestImplSurfDescribeOps.createGradient",
	"Comment": "creates an image with a constant gradient in the specified direction",
	"Method": "void createGradient(double theta,I image,SparseScaleGradient<II, ?> createGradient,II ii,double scale){\r\n    SparseScaleGradient<II, ?> ret = SurfDescribeOps.createGradient(false, (Class<II>) ii.getClass());\r\n    ret.setImage(ii);\r\n    ret.setWidth(4);\r\n    return ret;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.ConfigNew.getJSONObject",
	"Comment": "returns the jsonobject for given key. the one in the config, or if it does not exist, the given default value.",
	"Method": "JSONObject getJSONObject(ConfigKey configKey,JSONObject getJSONObject,ConfigKey configKey,JSONObject defaultValue){\r\n    try {\r\n        final FindResult res = findNode(configKey.keyName, false);\r\n        return res.getNode().getJSONObject(res.getName());\r\n    } catch (final JSONException ignored) {\r\n        setJSONObject(configKey, defaultValue);\r\n        return defaultValue;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.transform.pyramid.TestPyramidDiscreteSampleBlur.checkSigmas",
	"Comment": "makes sure the amount of gaussian blur in each level is correctly computed",
	"Method": "void checkSigmas(){\r\n    Kernel1D_F32 kernel = FactoryKernelGaussian.gaussian(Kernel1D_F32.class, -1, 3);\r\n    PyramidDiscreteSampleBlur<GrayF32> alg = new PyramidDiscreteSampleBlur(kernel, 3, ImageType.single(GrayF32.class), true, new int[] { 1, 2, 4 });\r\n    assertEquals(0, alg.getSigma(0), 1e-8);\r\n    assertEquals(3, alg.getSigma(1), 1e-8);\r\n    assertEquals(6.7082, alg.getSigma(2), 1e-3);\r\n    alg = new PyramidDiscreteSampleBlur(kernel, 3, ImageType.single(GrayF32.class), true, new int[] { 2, 4, 8 });\r\n    assertEquals(0, alg.getSigma(0), 1e-8);\r\n    assertEquals(6, alg.getSigma(1), 1e-8);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquaresIntoClusters.findClusters",
	"Comment": "put sets of nodes into the same list if they are some how connected",
	"Method": "void findClusters(){\r\n    for (int i = 0; i < nodes.size(); i++) {\r\n        SquareNode n = nodes.get(i);\r\n        if (n.graph < 0) {\r\n            n.graph = clusters.size();\r\n            List<SquareNode> graph = clusters.grow();\r\n            graph.add(n);\r\n            addToCluster(n, graph);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.ConnectionHandle.getProxyTarget",
	"Comment": "this method will be intercepted by the proxy if it is enabled to return the internal target.",
	"Method": "Object getProxyTarget(){\r\n    try {\r\n        return Proxy.getInvocationHandler(this.connection).invoke(null, this.getClass().getMethod(\"getProxyTarget\"), null);\r\n    } catch (Throwable t) {\r\n        throw new RuntimeException(\"BoneCP: Internal error - transaction replay log is not turned on?\", t);\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.hooks.AcquireFailConfig.getAcquireRetryDelayInMs",
	"Comment": "getter for acquireretrydelay. by default starts off with whatever is set in the config.",
	"Method": "long getAcquireRetryDelayInMs(){\r\n    return this.acquireRetryDelayInMs;\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.DescribeDenseHogAlg.computeCellHistogram",
	"Comment": "computes the histogram for the block with the specified lower extent",
	"Method": "void computeCellHistogram(int pixelX0,int pixelY0,int cellX,int cellY){\r\n    float angleBinSize = GrlConstants.F_PI / orientationBins;\r\n    for (int i = 0; i < pixelsPerCell; i++) {\r\n        int indexPixel = (pixelY0 + i) * derivX.stride + pixelX0;\r\n        int indexBlock = (cellY * pixelsPerCell + i) * pixelsPerCell * cellsPerBlockX + cellX * pixelsPerCell;\r\n        double spatialWeightY0, spatialWeightY1, spatialWeightY2;\r\n        if (i <= pixelsPerCell / 2) {\r\n            spatialWeightY1 = (i + pixelsPerCell / 2.0) / pixelsPerCell;\r\n            spatialWeightY0 = 1.0 - spatialWeightY1;\r\n            spatialWeightY2 = 0;\r\n        } else {\r\n            spatialWeightY0 = 0;\r\n            spatialWeightY2 = (i - pixelsPerCell / 2.0) / pixelsPerCell;\r\n            spatialWeightY1 = 1.0 - spatialWeightY2;\r\n        }\r\n        for (int j = 0; j < pixelsPerCell; j++, indexPixel++, indexBlock++) {\r\n            double spatialWeightX0, spatialWeightX1, spatialWeightX2;\r\n            if (j <= pixelsPerCell / 2) {\r\n                spatialWeightX1 = (j + pixelsPerCell / 2.0) / pixelsPerCell;\r\n                spatialWeightX0 = 1.0 - spatialWeightX1;\r\n                spatialWeightX2 = 0;\r\n            } else {\r\n                spatialWeightX0 = 0;\r\n                spatialWeightX2 = (j - pixelsPerCell / 2.0) / pixelsPerCell;\r\n                spatialWeightX1 = 1.0 - spatialWeightX2;\r\n            }\r\n            float angle = this.orientation.data[indexPixel];\r\n            double magnitude = this.magnitude.data[indexPixel];\r\n            magnitude *= this.weights[indexBlock];\r\n            float findex0 = angle / angleBinSize;\r\n            int index0 = (int) findex0;\r\n            double oriWeight1 = findex0 - index0;\r\n            index0 %= orientationBins;\r\n            int index1 = (index0 + 1) % orientationBins;\r\n            addToHistogram(cellX - 1, cellY - 1, index0, (1.0 - oriWeight1) * magnitude * spatialWeightX0 * spatialWeightY0);\r\n            addToHistogram(cellX - 1, cellY - 1, index1, oriWeight1 * magnitude * spatialWeightX0 * spatialWeightY0);\r\n            addToHistogram(cellX, cellY - 1, index0, (1.0 - oriWeight1) * magnitude * spatialWeightX1 * spatialWeightY0);\r\n            addToHistogram(cellX, cellY - 1, index1, oriWeight1 * magnitude * spatialWeightX1 * spatialWeightY0);\r\n            addToHistogram(cellX + 1, cellY - 1, index0, (1.0 - oriWeight1) * magnitude * spatialWeightX2 * spatialWeightY0);\r\n            addToHistogram(cellX + 1, cellY - 1, index1, oriWeight1 * magnitude * spatialWeightX2 * spatialWeightY0);\r\n            addToHistogram(cellX - 1, cellY, index0, (1.0 - oriWeight1) * magnitude * spatialWeightX0 * spatialWeightY1);\r\n            addToHistogram(cellX - 1, cellY, index1, oriWeight1 * magnitude * spatialWeightX0 * spatialWeightY1);\r\n            addToHistogram(cellX, cellY, index0, (1.0 - oriWeight1) * magnitude * spatialWeightX1 * spatialWeightY1);\r\n            addToHistogram(cellX, cellY, index1, oriWeight1 * magnitude * spatialWeightX1 * spatialWeightY1);\r\n            addToHistogram(cellX + 1, cellY, index0, (1.0 - oriWeight1) * magnitude * spatialWeightX2 * spatialWeightY1);\r\n            addToHistogram(cellX + 1, cellY, index1, oriWeight1 * magnitude * spatialWeightX2 * spatialWeightY1);\r\n            addToHistogram(cellX - 1, cellY + 1, index0, (1.0 - oriWeight1) * magnitude * spatialWeightX0 * spatialWeightY2);\r\n            addToHistogram(cellX - 1, cellY + 1, index1, oriWeight1 * magnitude * spatialWeightX0 * spatialWeightY2);\r\n            addToHistogram(cellX, cellY + 1, index0, (1.0 - oriWeight1) * magnitude * spatialWeightX1 * spatialWeightY2);\r\n            addToHistogram(cellX, cellY + 1, index1, oriWeight1 * magnitude * spatialWeightX1 * spatialWeightY2);\r\n            addToHistogram(cellX + 1, cellY + 1, index0, (1.0 - oriWeight1) * magnitude * spatialWeightX2 * spatialWeightY2);\r\n            addToHistogram(cellX + 1, cellY + 1, index1, oriWeight1 * magnitude * spatialWeightX2 * spatialWeightY2);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.TestPnPStereoDistanceReprojectionSq.checkBehindCamera_Left",
	"Comment": "have the observation be behind the left camera but not the right",
	"Method": "void checkBehindCamera_Left(){\r\n    checkBehind(-0.1, -0.05);\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.isLogStatementsEnabled",
	"Comment": "returns true if sql logging is currently enabled, false otherwise.",
	"Method": "boolean isLogStatementsEnabled(){\r\n    return this.logStatementsEnabled;\r\n}"
}, {
	"Path": "boofcv.alg.transform.fft.GeneralPurposeFFT_F64_2D.realForwardFull",
	"Comment": "computes 2d forward dft of real data leaving the result in a\t. this method computes full real forward transform, i.e. you will get the\tsame result as from complexforward called with all imaginary\tpart equal 0. because the result is stored in a, the input\tarray must be of size rowscolumns, with only the first rowscolumns\telements filled with real data. to get back the original data, use\tcomplexinverse on the output of this method.",
	"Method": "void realForwardFull(double[] a){\r\n    if (rows == 1 || columns == 1) {\r\n        if (rows > 1)\r\n            fftRows.realForwardFull(a);\r\n        else\r\n            fftColumns.realForwardFull(a);\r\n        return;\r\n    }\r\n    if (isPowerOfTwo) {\r\n        for (int r = 0; r < rows; r++) {\r\n            fftColumns.realForward(a, r * columns);\r\n        }\r\n        cdft2d_sub(-1, a, true);\r\n        rdft2d_sub(1, a);\r\n        fillSymmetric(a);\r\n    } else {\r\n        declareRadixRealData();\r\n        mixedRadixRealForwardFull(a);\r\n    }\r\n}"
}, {
	"Path": "boofcv.deepboof.BaseImageClassifier.classify",
	"Comment": "the original implementation takes in an image then crops it randomly.this is primarily for training but is\treplicated here to reduce the number of differences",
	"Method": "void classify(Planar<GrayF32> image){\r\n    DataManipulationOps.imageToTensor(preprocess(image), tensorInput, 0);\r\n    innerProcess(tensorInput);\r\n}"
}, {
	"Path": "com.bugsnag.android.Error.getExceptionMessage",
	"Comment": "get the message from the exception contained in this error report.",
	"Method": "String getExceptionMessage(){\r\n    String localizedMessage = exception.getLocalizedMessage();\r\n    return localizedMessage != null ? localizedMessage : \"\";\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomMonoPlaneInfinity.process",
	"Comment": "estimates the motion which the camera undergoes relative to the first frame processed.",
	"Method": "boolean process(T image){\r\n    tracker.process(image);\r\n    tick++;\r\n    if (first) {\r\n        addNewTracks();\r\n        first = false;\r\n    } else {\r\n        sortTracksForEstimation();\r\n        estimateFar();\r\n        if (!estimateClose()) {\r\n            return false;\r\n        }\r\n        fuseEstimates();\r\n        dropUnusedTracks();\r\n        if (thresholdAdd <= 0 || closeInlierCount < thresholdAdd) {\r\n            changeCurrToReference();\r\n            addNewTracks();\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.pokemon.PokemonCalculationUtils.dpsForMove",
	"Comment": "calculates the no weave dps for current move. just plain damage, without dodging or any other attack.",
	"Method": "double dpsForMove(Pokemon p,boolean primary,double dpsForMove,PokemonId pokemonId,PokemonMove move,boolean primary){\r\n    final MoveSettings moveMeta = PokemonMeta.getMoveSettings(move);\r\n    final int moveDelay = primary ? 0 : MOVE2_CHARGE_DELAY_MS;\r\n    double dps = (double) moveMeta.getPower() / (double) (moveMeta.getDurationMs() + moveDelay) * MILLISECONDS_FACTOR;\r\n    if (PokemonUtils.hasStab(pokemonId, move)) {\r\n        dps = dps * STAB_MULTIPLIER;\r\n    }\r\n    return dps;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareGraph.checkConnect",
	"Comment": "checks to see if the two nodes can be connected.if one of the nodes is already connected to\tanother it then checks to see if the proposed connection is more desirable.if it is the old\tconnection is removed and a new one created.otherwise nothing happens.",
	"Method": "void checkConnect(SquareNode a,int indexA,SquareNode b,int indexB,double distance){\r\n    if (a.edges[indexA] != null && a.edges[indexA].distance > distance) {\r\n        detachEdge(a.edges[indexA]);\r\n    }\r\n    if (b.edges[indexB] != null && b.edges[indexB].distance > distance) {\r\n        detachEdge(b.edges[indexB]);\r\n    }\r\n    if (a.edges[indexA] == null && b.edges[indexB] == null) {\r\n        connect(a, indexA, b, indexB, distance);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.TestEllipseClustersIntoGrid.checkEdgeInfo",
	"Comment": "makes sure expected number of edges is found and that the edges are correctly sorted by angle",
	"Method": "void checkEdgeInfo(NodeInfo info,int numEdges){\r\n    assertEquals(info.edges.size, numEdges);\r\n    if (numEdges == 0)\r\n        return;\r\n    int numNotZero = 0;\r\n    for (int i = 0; i < numEdges; i++) {\r\n        if (info.edges.get(i).angle != 0)\r\n            numNotZero++;\r\n    }\r\n    assertTrue(numNotZero >= 1);\r\n    for (int i = 1, j = 0; i < numEdges; j = i, i++) {\r\n        EllipseClustersIntoGrid.Edge e0 = info.edges.get(j);\r\n        EllipseClustersIntoGrid.Edge e1 = info.edges.get(i);\r\n        assertTrue(e0.angle <= e1.angle);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.FastHessianFeatureDetector.checkMax",
	"Comment": "sees if the best score in the current layer is greater than all the scores in a 3x3 neighborhood\tin another layer.",
	"Method": "boolean checkMax(ImageBorder_F32 inten,float bestScore,int c_x,int c_y){\r\n    for (int y = c_y - 1; y <= c_y + 1; y++) {\r\n        for (int x = c_x - 1; x <= c_x + 1; x++) {\r\n            if (inten.get(x, y) >= bestScore) {\r\n                return false;\r\n            }\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.TestGThresholdImageOps.computeOtsu2_pathological",
	"Comment": "the histogram is composed of two values. see if it picks a threshold that can split this sest",
	"Method": "void computeOtsu2_pathological(){\r\n    int[] histogram = new int[256];\r\n    histogram[10] = 200;\r\n    histogram[120] = 500;\r\n    int found = GThresholdImageOps.computeOtsu2(histogram, histogram.length, 700);\r\n    assertEquals(65, found);\r\n}"
}, {
	"Path": "boofcv.android.camera.VideoDisplayActivity.hideProgressDialog",
	"Comment": "dismisses the progress dialog.can be called even if there is no progressdialog being shown.",
	"Method": "void hideProgressDialog(){\r\n    synchronized (lockProgress) {\r\n        if (progressDialog == null)\r\n            return;\r\n    }\r\n    if (Looper.getMainLooper().getThread() == Thread.currentThread()) {\r\n        synchronized (lockProgress) {\r\n            progressDialog.dismiss();\r\n            progressDialog = null;\r\n        }\r\n    } else {\r\n        runOnUiThread(new Runnable() {\r\n            public void run() {\r\n                synchronized (lockProgress) {\r\n                    progressDialog.dismiss();\r\n                    progressDialog = null;\r\n                }\r\n            }\r\n        });\r\n        while (progressDialog != null) {\r\n            Thread.yield();\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.android.camera.VideoDisplayActivity.hideProgressDialog",
	"Comment": "dismisses the progress dialog.can be called even if there is no progressdialog being shown.",
	"Method": "void hideProgressDialog(){\r\n    synchronized (lockProgress) {\r\n        progressDialog.dismiss();\r\n        progressDialog = null;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.trifocal.EnforceTrifocalGeometry.constructE",
	"Comment": "the matrix e is a linear system for computing the trifocal tensor.the columns\tare the unknown square matrices from view 2 and 3.the right most column in\tboth projection matrices are the provided epipoles, whose values are inserted into e",
	"Method": "void constructE(Point3D_F64 e2,Point3D_F64 e3){\r\n    E.zero();\r\n    for (int i = 0; i < 3; i++) {\r\n        for (int j = 0; j < 3; j++) {\r\n            for (int k = 0; k < 3; k++) {\r\n                int row = 9 * i + 3 * j + k;\r\n                int col1 = j * 3 + i;\r\n                int col2 = k * 3 + i + 9;\r\n                E.data[row * 18 + col1] = e3.getIndex(k);\r\n                E.data[row * 18 + col2] = -e2.getIndex(j);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "io.buji.pac4j.util.ShiroHelper.populateSubject",
	"Comment": "populate the authenticated user profiles in the shiro subject.",
	"Method": "void populateSubject(LinkedHashMap<String, CommonProfile> profiles){\r\n    if (profiles != null && profiles.size() > 0) {\r\n        final List<CommonProfile> listProfiles = ProfileHelper.flatIntoAProfileList(profiles);\r\n        try {\r\n            if (IS_FULLY_AUTHENTICATED_AUTHORIZER.isAuthorized(null, listProfiles)) {\r\n                SecurityUtils.getSubject().login(new Pac4jToken(listProfiles, false));\r\n            } else if (IS_REMEMBERED_AUTHORIZER.isAuthorized(null, listProfiles)) {\r\n                SecurityUtils.getSubject().login(new Pac4jToken(listProfiles, true));\r\n            }\r\n        } catch (final HttpAction e) {\r\n            throw new TechnicalException(e);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.ConfigNew.getDouble",
	"Comment": "returns the double for given key. the one in the config, or if it does not exist, the given default value.",
	"Method": "double getDouble(ConfigKey configKey,double getDouble,ConfigKey configKey,double defaultValue){\r\n    try {\r\n        final FindResult res = findNode(configKey.keyName, true);\r\n        return res.getNode().getDouble(res.getName());\r\n    } catch (final JSONException ignored) {\r\n        setDouble(configKey, defaultValue);\r\n        return defaultValue;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.impl.BinaryThinning.findOnePixels",
	"Comment": "scans through the image and record the array index of all marked pixels",
	"Method": "void findOnePixels(GrowQueue_I32 ones){\r\n    for (int y = 0; y < binary.height; y++) {\r\n        int index = binary.startIndex + y * binary.stride;\r\n        for (int x = 0; x < binary.width; x++, index++) {\r\n            if (binary.data[index] != 0) {\r\n                ones.add(index);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodePositionPatternDetector.setLensDistortion",
	"Comment": "specifies transforms which can be used to change coordinates from distorted to undistorted and the opposite\tcoordinates.the undistorted image is never explicitly created.",
	"Method": "void setLensDistortion(int width,int height,LensDistortionNarrowFOV model){\r\n    interpolate = FactoryInterpolation.bilinearPixelS(squareDetector.getInputType(), BorderType.EXTENDED);\r\n    if (model != null) {\r\n        PixelTransform2_F32 distToUndist = new PointToPixelTransform_F32(model.undistort_F32(true, true));\r\n        PixelTransform2_F32 undistToDist = new PointToPixelTransform_F32(model.distort_F32(true, true));\r\n        squareDetector.setLensDistortion(width, height, distToUndist, undistToDist);\r\n        Point2Transform2_F32 u2d = model.distort_F32(true, true);\r\n        this.interpolate = new InterpolatePixelDistortS(this.interpolate, u2d);\r\n    } else {\r\n        squareDetector.setLensDistortion(width, height, null, null);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldFernClassifier.computeFernValue",
	"Comment": "computes the value of the specified fern at the specified location in the image.",
	"Method": "int computeFernValue(float c_x,float c_y,float rectWidth,float rectHeight,TldFernDescription fern){\r\n    rectWidth -= 1;\r\n    rectHeight -= 1;\r\n    int desc = 0;\r\n    for (int i = 0; i < fern.pairs.length; i++) {\r\n        Point2D_F32 p_a = fern.pairs[i].a;\r\n        Point2D_F32 p_b = fern.pairs[i].b;\r\n        float valA = interpolate.get_fast(c_x + p_a.x * rectWidth, c_y + p_a.y * rectHeight);\r\n        float valB = interpolate.get_fast(c_x + p_b.x * rectWidth, c_y + p_b.y * rectHeight);\r\n        desc *= 2;\r\n        if (valA < valB) {\r\n            desc += 1;\r\n        }\r\n    }\r\n    return desc;\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.version.Updater.queryLatestVersion",
	"Comment": "queries the latest version from github.tries to save it locally under lateststable.",
	"Method": "void queryLatestVersion(){\r\n    final String callUrl = LATEST_VERSION_URL + VERSION_FILENAME;\r\n    try {\r\n        final URL url = new URL(callUrl);\r\n        final String latestVersionString = FileHelper.readFile(url.openStream());\r\n        latestStable = new ComparableVersion(latestVersionString);\r\n        System.out.println(\"Latest version from server: \" + latestVersionString);\r\n    } catch (IOException ex) {\r\n        System.out.println(\"Could not get latest version from Server. Reason: \" + ex.toString());\r\n        System.out.println(\"File URL: \" + callUrl);\r\n        System.out.println(\"If that problem persists, post your issue on GitHub and check for newer versions manually.\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.examples.stereo.ExampleStereoTwoViewsOneCamera.convertToNormalizedCoordinates",
	"Comment": "convert a set of associated point features from pixel coordinates into normalized image coordinates.",
	"Method": "List<AssociatedPair> convertToNormalizedCoordinates(List<AssociatedPair> matchedFeatures,CameraPinholeRadial intrinsic){\r\n    Point2Transform2_F64 p_to_n = LensDistortionOps.narrow(intrinsic).undistort_F64(true, false);\r\n    List<AssociatedPair> calibratedFeatures = new ArrayList();\r\n    for (AssociatedPair p : matchedFeatures) {\r\n        AssociatedPair c = new AssociatedPair();\r\n        p_to_n.compute(p.p1.x, p.p1.y, c.p1);\r\n        p_to_n.compute(p.p2.x, p.p2.y, c.p2);\r\n        calibratedFeatures.add(c);\r\n    }\r\n    return calibratedFeatures;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.EstimateSceneCalibrated.estimateAllFeatures",
	"Comment": "perform a breath first search to find the structure of all the remaining camrea views",
	"Method": "void estimateAllFeatures(View seedA,View seedB){\r\n    List<View> open = new ArrayList();\r\n    addUnvistedToStack(seedA, open);\r\n    addUnvistedToStack(seedB, open);\r\n    while (!open.isEmpty()) {\r\n        if (stopRequested)\r\n            return;\r\n        if (verbose != null)\r\n            verbose.println(\"### open.size=\" + open.size());\r\n        int bestCount = countFeaturesWith3D(open.get(0));\r\n        int bestIndex = 0;\r\n        for (int i = 1; i < open.size(); i++) {\r\n            int count = countFeaturesWith3D(open.get(i));\r\n            if (count > bestCount) {\r\n                bestCount = count;\r\n                bestIndex = i;\r\n            }\r\n        }\r\n        View v = open.remove(bestIndex);\r\n        if (verbose != null)\r\n            verbose.println(\"   processing view=\" + v.index + \" | 3D Features=\" + bestCount);\r\n        if (!determinePose(v)) {\r\n            throw new RuntimeException(\"Crap handle this\");\r\n        } else {\r\n            addTriangulatedFeaturesForAllEdges(v);\r\n            triangulateNoLocation(v);\r\n            viewsAdded.add(v);\r\n            addUnvistedToStack(v, open);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.flow.BroxWarpingSpacial.computeDivUVD",
	"Comment": "computes the divergence for u,v, and d. equation 8 and equation 10.",
	"Method": "void computeDivUVD(GrayF32 u,GrayF32 v,GrayF32 psi,GrayF32 divU,GrayF32 divV,GrayF32 divD){\r\n    final int stride = psi.stride;\r\n    for (int y = 1; y < psi.height - 1; y++) {\r\n        int index = y * stride + 1;\r\n        for (int x = 1; x < psi.width - 1; x++, index++) {\r\n            float psi_index = psi.data[index];\r\n            float coef0 = 0.5f * (psi.data[index + 1] + psi_index);\r\n            float coef1 = 0.5f * (psi.data[index - 1] + psi_index);\r\n            float coef2 = 0.5f * (psi.data[index + stride] + psi_index);\r\n            float coef3 = 0.5f * (psi.data[index - stride] + psi_index);\r\n            float u_index = u.data[index];\r\n            divU.data[index] = coef0 * (u.data[index + 1] - u_index) + coef1 * (u.data[index - 1] - u_index) + coef2 * (u.data[index + stride] - u_index) + coef3 * (u.data[index - stride] - u_index);\r\n            float v_index = v.data[index];\r\n            divV.data[index] = coef0 * (v.data[index + 1] - v_index) + coef1 * (v.data[index - 1] - v_index) + coef2 * (v.data[index + stride] - v_index) + coef3 * (v.data[index - stride] - v_index);\r\n            divD.data[index] = coef0 + coef1 + coef2 + coef3;\r\n        }\r\n    }\r\n    for (int x = 0; x < psi.width; x++) {\r\n        computeDivUVD_safe(x, 0, u, v, psi, divU, divV, divD);\r\n        computeDivUVD_safe(x, psi.height - 1, u, v, psi, divU, divV, divD);\r\n    }\r\n    for (int y = 1; y < psi.height - 1; y++) {\r\n        computeDivUVD_safe(0, y, u, v, psi, divU, divV, divD);\r\n        computeDivUVD_safe(psi.width - 1, y, u, v, psi, divU, divV, divD);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.RectifyImageOps.transformPixelToRectNorm",
	"Comment": "creates a transform that applies rectification to unrectified distorted pixels and outputs\tnormalized pixel coordinates.",
	"Method": "Point2Transform2_F64 transformPixelToRectNorm(CameraPinholeRadial param,DMatrixRMaj rectify,DMatrixRMaj rectifyK,Point2Transform2_F32 transformPixelToRectNorm,CameraPinholeRadial param,FMatrixRMaj rectify,FMatrixRMaj rectifyK){\r\n    return ImplRectifyImageOps_F32.transformPixelToRectNorm(param, rectify, rectifyK);\r\n}"
}, {
	"Path": "boofcv.alg.geo.calibration.TestZhang99ParamAll.toAndFromParametersArray",
	"Comment": "test to see if the conversion to and from a parameter array works well.",
	"Method": "void toAndFromParametersArray(){\r\n    Dummy dummy = new Dummy();\r\n    Zhang99AllParam p = new Zhang99AllParam(dummy, 2);\r\n    dummy.a = 3;\r\n    for (int i = 0; i < 2; i++) {\r\n        Zhang99AllParam.View v = p.views[i];\r\n        v.T.set(rand.nextDouble(), rand.nextDouble(), rand.nextDouble());\r\n        v.rotation.theta = rand.nextDouble();\r\n        v.rotation.unitAxisRotation.set(rand.nextGaussian(), rand.nextGaussian(), rand.nextGaussian());\r\n        v.rotation.unitAxisRotation.normalize();\r\n    }\r\n    double[] array = new double[p.numParameters()];\r\n    p.convertToParam(array);\r\n    Zhang99AllParam found = new Zhang99AllParam(new Dummy(), 2);\r\n    found.setFromParam(array);\r\n    checkEquals(p, found);\r\n}"
}, {
	"Path": "boofcv.io.jcodec.UtilJCodec.convertToBoof",
	"Comment": "converts an image in jcodec format into one in boofcv format.",
	"Method": "void convertToBoof(Picture input,ImageBase output){\r\n    if (input.getColor() == ColorSpace.RGB) {\r\n        ImplConvertJCodecPicture.RGB_to_PLU8(input, (Planar) output);\r\n    } else if (input.getColor() == ColorSpace.YUV420) {\r\n        if (output instanceof Planar) {\r\n            Planar ms = (Planar) output;\r\n            if (ms.getImageType().getDataType() == ImageDataType.U8) {\r\n                ImplConvertJCodecPicture.yuv420_to_PlRgb_U8(input, ms);\r\n            } else if (ms.getImageType().getDataType() == ImageDataType.F32) {\r\n                ImplConvertJCodecPicture.yuv420_to_PlRgb_F32(input, ms);\r\n            }\r\n        } else if (output instanceof GrayU8) {\r\n            ImplConvertJCodecPicture.yuv420_to_U8(input, (GrayU8) output);\r\n        } else if (output instanceof GrayF32) {\r\n            ImplConvertJCodecPicture.yuv420_to_F32(input, (GrayF32) output);\r\n        } else {\r\n            throw new RuntimeException(\"Unexpected output image type\");\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.TestDescribeSiftCommon.trilinearInterpolation",
	"Comment": "tests trilinear interpolation by checking out some of its properties instead of its value\texactly",
	"Method": "void trilinearInterpolation(){\r\n    DescribeSiftCommon alg = new DescribeSiftCommon(4, 4, 8, 0.5, 0.2);\r\n    TupleDesc_F64 descriptor = new TupleDesc_F64(128);\r\n    alg.trilinearInterpolation(2.0f, 1.25f, 2.0f, 0.5, descriptor);\r\n    double sum = 0;\r\n    int count = 0;\r\n    for (int i = 0; i < descriptor.size(); i++) {\r\n        sum += descriptor.value[i];\r\n        if (descriptor.value[i] != 0)\r\n            count++;\r\n    }\r\n    assertEquals(2.0, sum, 1e-6);\r\n    assertTrue(count > 1);\r\n    sum = 0;\r\n    descriptor.fill(0);\r\n    alg.trilinearInterpolation(2.0f, 3.25f, 3.25f, 0.5, descriptor);\r\n    for (int i = 0; i < descriptor.size(); i++) {\r\n        sum += descriptor.value[i];\r\n    }\r\n    assertEquals(2.0 * 0.75 * 0.75 * 1.0, sum, 1e-8);\r\n    descriptor.fill(0);\r\n    alg.trilinearInterpolation(2.0f, 3f, 3f, 2 * Math.PI / 8, descriptor);\r\n    count = 0;\r\n    for (int i = 0; i < descriptor.size(); i++) {\r\n        double weight = descriptor.value[i];\r\n        if (weight > 0) {\r\n            assertEquals(2.0, weight, 1e-8);\r\n            count++;\r\n        }\r\n    }\r\n    assertEquals(1, count);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.TestKltTracker.setDescription_outsideFail",
	"Comment": "set description should fail if a feature is entirely outside the image",
	"Method": "void setDescription_outsideFail(){\r\n    KltTracker<GrayF32, GrayF32> tracker = createDefaultTracker();\r\n    tracker.setImage(image, derivX, derivY);\r\n    KltFeature feature = new KltFeature(3);\r\n    feature.setPosition(-100, 200);\r\n    assertFalse(tracker.setDescription(feature));\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.direct.FeatureSpatialDiversity_F32.getSpread",
	"Comment": "number of radians in view that the smallest features lie along",
	"Method": "double getSpread(){\r\n    return spread;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldTemplateMatching.reset",
	"Comment": "discard previous results and puts it back into its initial state",
	"Method": "void reset(){\r\n    unused.addAll(templateNegative);\r\n    unused.addAll(templatePositive);\r\n    templateNegative.clear();\r\n    templatePositive.clear();\r\n}"
}, {
	"Path": "com.jolbox.bonecp.StatementHandle.checkClosed",
	"Comment": "checks if the connection is marked as being logically open and throws an exception if not.",
	"Method": "void checkClosed(){\r\n    if (this.logicallyClosed.get()) {\r\n        throw new SQLException(\"Statement is closed\");\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.SplitMergeLineFit.splitThresholdSq",
	"Comment": "computes the split threshold from the end point of two lines",
	"Method": "double splitThresholdSq(Point2D_I32 a,Point2D_I32 b){\r\n    return Math.max(2, a.distance2(b) * toleranceFractionSq);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.data.managers.GlobalSettingsController.setup",
	"Comment": "setup the globalsettingcontroller if it has not been initialized.",
	"Method": "void setup(){\r\n    if (instance == null) {\r\n        instance = new GlobalSettingsController();\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.GradientToEdgeFeatures.nonMaxSuppressionCrude4",
	"Comment": "sets edge intensities to zero if the pixel has an intensity which is less than any of\tthe two adjacent pixels.pixel adjacency is determined based upon the sign of the image gradient.less precise\tthan other methods, but faster.",
	"Method": "GrayF32 nonMaxSuppressionCrude4(GrayF32 intensity,GrayF32 derivX,GrayF32 derivY,GrayF32 output,GrayF32 nonMaxSuppressionCrude4,GrayF32 intensity,GrayS16 derivX,GrayS16 derivY,GrayF32 output,GrayF32 nonMaxSuppressionCrude4,GrayF32 intensity,GrayS32 derivX,GrayS32 derivY,GrayF32 output){\r\n    InputSanityCheck.checkSameShape(intensity, derivX, derivY);\r\n    output = InputSanityCheck.checkDeclare(intensity, output);\r\n    ImplEdgeNonMaxSuppressionCrude.inner4(intensity, derivX, derivY, output);\r\n    ImplEdgeNonMaxSuppressionCrude.border4(intensity, derivX, derivY, output);\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.alg.geo.PerspectiveOps.projectionSplit",
	"Comment": "splits the projection matrix into a 3x3 matrix and 3x1 vector.",
	"Method": "void projectionSplit(DMatrixRMaj P,DMatrixRMaj M,Vector3D_F64 T){\r\n    CommonOps_DDRM.extract(P, 0, 3, 0, 3, M, 0, 0);\r\n    T.x = P.get(0, 3);\r\n    T.y = P.get(1, 3);\r\n    T.z = P.get(2, 3);\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.SquareBase_to_FiducialDetector.getCenter",
	"Comment": "return the intersection of two lines defined by opposing corners.this should also be the geometric center",
	"Method": "void getCenter(int which,Point2D_F64 location){\r\n    Quadrilateral_F64 q = alg.getFound().get(which).distortedPixels;\r\n    UtilLine2D_F64.convert(q.a, q.c, line02);\r\n    UtilLine2D_F64.convert(q.b, q.d, line13);\r\n    Intersection2D_F64.intersection(line02, line13, location);\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.TestClusterLabeledImage.sameColorIslands",
	"Comment": "same color used on separate islands.each island should have its own color on output",
	"Method": "void sameColorIslands(){\r\n    GrayS32 input = new GrayS32(5, 5);\r\n    input.data = new int[] { 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1 };\r\n    int[] expected = new int[] { 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2 };\r\n    for (int i = 0; i < rules.length; i++) {\r\n        GrayS32 output = new GrayS32(5, 5);\r\n        ClusterLabeledImage alg = new ClusterLabeledImage(rules[i]);\r\n        alg.process(input, output, counts);\r\n        int[] convert = new int[3];\r\n        convert[0] = output.get(0, 0);\r\n        convert[1] = output.get(2, 0);\r\n        convert[2] = output.get(2, 4);\r\n        assertEquals(3, counts.size);\r\n        assertEquals(4, counts.get(convert[0]));\r\n        assertEquals(15, counts.get(convert[1]));\r\n        assertEquals(6, counts.get(convert[2]));\r\n        for (int j = 0; j < output.data.length; j++) {\r\n            assertEquals(convert[expected[j]], output.data[j]);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.HysteresisEdgeTraceMark.process",
	"Comment": "performs hysteresis thresholding using the provided lower and upper thresholds.",
	"Method": "void process(GrayF32 intensity,GrayS8 direction,float lower,float upper,GrayU8 output){\r\n    if (lower < 0)\r\n        throw new IllegalArgumentException(\"Lower must be >= 0!\");\r\n    InputSanityCheck.checkSameShape(intensity, direction, output);\r\n    this.intensity = intensity;\r\n    this.direction = direction;\r\n    this.output = output;\r\n    this.lower = lower;\r\n    ImageMiscOps.fill(output, 0);\r\n    for (int y = 0; y < intensity.height; y++) {\r\n        int indexInten = intensity.startIndex + y * intensity.stride;\r\n        for (int x = 0; x < intensity.width; x++, indexInten++) {\r\n            if (intensity.data[indexInten] >= upper) {\r\n                trace(x, y, indexInten);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestStatementHandle.testRemainingForCoverage",
	"Comment": "test other methods not covered by the standard methods above.",
	"Method": "void testRemainingForCoverage(){\r\n    Statement mockStatement = createNiceMock(Statement.class);\r\n    IStatementCache mockCache = createNiceMock(IStatementCache.class);\r\n    expect(mockConnection.getPool()).andReturn(mockPool).anyTimes();\r\n    expect(mockPool.getConfig()).andReturn(mockConfig).anyTimes();\r\n    expect(mockConfig.isStatisticsEnabled()).andReturn(true).anyTimes();\r\n    expect(mockConfig.getQueryExecuteTimeLimitInMs()).andReturn(1L).anyTimes();\r\n    replay(mockConnection, mockConfig, mockPool);\r\n    StatementHandle handle = new StatementHandle(mockStatement, mockConnection, true);\r\n    handle = new StatementHandle(mockStatement, null, mockCache, mockConnection, \"testSQL\", true);\r\n    handle.setLogicallyOpen();\r\n    handle.getConnection();\r\n    handle.logicallyClosed.set(true);\r\n    Method method = handle.getClass().getDeclaredMethod(\"checkClosed\");\r\n    method.setAccessible(true);\r\n    try {\r\n        method.invoke(handle);\r\n        Assert.fail(\"Exception should have been thrown\");\r\n    } catch (Throwable e) {\r\n    }\r\n    mockStatement.close();\r\n    expectLastCall();\r\n    replay(mockStatement, mockCache);\r\n    handle.close();\r\n    verify(mockStatement);\r\n    reset(mockStatement, mockCache);\r\n    handle.setLogicallyOpen();\r\n    Assert.assertFalse(handle.isClosed());\r\n    reset(mockCache);\r\n    mockCache.clear();\r\n    expectLastCall().once();\r\n    replay(mockCache);\r\n    handle.clearCache();\r\n    verify(mockCache);\r\n    handle.setOpenStackTrace(\"foo\");\r\n    assertEquals(\"foo\", handle.getOpenStackTrace());\r\n    handle.sql = \"foo\";\r\n    assertNotNull(handle.toString());\r\n    testClass.logStatementsEnabled = false;\r\n    testClass.addBatch(\"\");\r\n    testClass.clearBatch();\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeAlignmentPatternLocator.initializePatterns",
	"Comment": "creates a list of alignment patterns to look for and their grid coordinates",
	"Method": "void initializePatterns(QrCode qr){\r\n    int N = qr.getNumberOfModules();\r\n    int[] where = QrCode.VERSION_INFO[qr.version].alignment;\r\n    qr.alignment.reset();\r\n    lookup.reset();\r\n    for (int row = where.length - 1; row >= 0; row--) {\r\n        for (int col = 0; col < where.length; col++) {\r\n            boolean skip = false;\r\n            if (row == 0 && col == 0)\r\n                skip = true;\r\n            else if (row == where.length - 1 && col == where.length - 1)\r\n                skip = true;\r\n            else if (row == where.length - 1 && col == 0)\r\n                skip = true;\r\n            if (skip) {\r\n                lookup.add(null);\r\n            } else {\r\n                QrCode.Alignment a = qr.alignment.grow();\r\n                a.moduleX = where[col];\r\n                a.moduleY = N - where[row] - 1;\r\n                lookup.add(a);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.SquareGridTools.findIntersection",
	"Comment": "finds the side which intersects the line segment from the center of target to center of node",
	"Method": "int findIntersection(SquareNode target,SquareNode node){\r\n    lineCenters.a = target.center;\r\n    lineCenters.b = node.center;\r\n    for (int i = 0; i < 4; i++) {\r\n        int j = (i + 1) % 4;\r\n        lineSide.a = target.square.get(i);\r\n        lineSide.b = target.square.get(j);\r\n        if (Intersection2D_F64.intersection(lineCenters, lineSide, dummy) != null) {\r\n            return i;\r\n        }\r\n    }\r\n    return -1;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.GeneralFeatureDetector.setExcludeMinimum",
	"Comment": "specify points which are excluded when detecting maximums",
	"Method": "void setExcludeMinimum(QueueCorner exclude){\r\n    this.excludeMinimum = exclude;\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapObjectConversion.convertListOfMapsToObjects",
	"Comment": "this converts a list of maps to objects.i always forget that this exists. i need to remember.",
	"Method": "List<T> convertListOfMapsToObjects(boolean respectIgnore,String view,FieldsAccessor fieldsAccessor,Class<T> componentType,List<Map> list,Set<String> ignoreProperties,List<T> convertListOfMapsToObjects,Class<T> componentType,List<Map> list){\r\n    return mapper.convertListOfMapsToObjects(list, componentType);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.TestSquaresIntoCrossClusters.process_simple",
	"Comment": "create a simple perfect cluster.do a crude test based on number of edge histogram",
	"Method": "void process_simple(){\r\n    SquaresIntoCrossClusters alg = new SquaresIntoCrossClusters(0.05, -1);\r\n    List<DetectPolygonFromContour.Info> squares = new ArrayList();\r\n    squares.add(createSquare(7, 8));\r\n    squares.add(createSquare(9, 8));\r\n    squares.add(createSquare(8, 9));\r\n    squares.add(createSquare(7, 10));\r\n    squares.add(createSquare(9, 10));\r\n    List<List<SquareNode>> clusters = alg.process(squares);\r\n    assertEquals(1, clusters.size());\r\n    List<SquareNode> cluster = clusters.get(0);\r\n    int[] connections = new int[5];\r\n    for (SquareNode n : cluster) {\r\n        connections[n.getNumberOfConnections()]++;\r\n    }\r\n    assertEquals(0, connections[0]);\r\n    assertEquals(4, connections[1]);\r\n    assertEquals(0, connections[2]);\r\n    assertEquals(0, connections[3]);\r\n    assertEquals(1, connections[4]);\r\n}"
}, {
	"Path": "boofcv.struct.image.ImageMultiBand.reshape",
	"Comment": "reshape for multiband images which allows the number of bands to be changed a the same time too",
	"Method": "void reshape(int width,int height,int numberOfBands){\r\n    reshape(width, height);\r\n    setNumberOfBands(numberOfBands);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.overhead.CameraPlaneProjection.planeToNormalized",
	"Comment": "given a point on the plane find the normalized image coordinate",
	"Method": "boolean planeToNormalized(double pointX,double pointY,Point2D_F64 normalized){\r\n    plain3D.set(-pointY, 0, pointX);\r\n    SePointOps_F64.transform(planeToCamera, plain3D, camera3D);\r\n    if (camera3D.z <= 0)\r\n        return false;\r\n    normalized.x = camera3D.x / camera3D.z;\r\n    normalized.y = camera3D.y / camera3D.z;\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.factory.sfm.FactoryVisualOdometry.stereoDepth",
	"Comment": "stereo vision based visual odometry algorithm which runs a sparse feature tracker in the left camera and\testimates the range of tracks once when first detected using disparity between left and right cameras.",
	"Method": "StereoVisualOdometry<T> stereoDepth(double inlierPixelTol,int thresholdAdd,int thresholdRetire,int ransacIterations,int refineIterations,boolean doublePass,StereoDisparitySparse<T> sparseDisparity,PointTrackerTwoPass<T> tracker,Class<T> imageType){\r\n    StereoSparse3D<T> pixelTo3D = new StereoSparse3D(sparseDisparity, imageType);\r\n    Estimate1ofPnP estimator = FactoryMultiView.pnp_1(EnumPNP.P3P_FINSTERWALDER, -1, 2);\r\n    final DistanceFromModelMultiView<Se3_F64, Point2D3D> distance = new PnPDistanceReprojectionSq();\r\n    ModelManagerSe3_F64 manager = new ModelManagerSe3_F64();\r\n    EstimatorToGenerator<Se3_F64, Point2D3D> generator = new EstimatorToGenerator(estimator);\r\n    double ransacTOL = inlierPixelTol * inlierPixelTol;\r\n    ModelMatcher<Se3_F64, Point2D3D> motion = new Ransac(2323, manager, generator, distance, ransacIterations, ransacTOL);\r\n    RefinePnP refine = null;\r\n    if (refineIterations > 0) {\r\n        refine = FactoryMultiView.pnpRefine(1e-12, refineIterations);\r\n    }\r\n    VisOdomPixelDepthPnP<T> alg = new VisOdomPixelDepthPnP(thresholdAdd, thresholdRetire, doublePass, motion, pixelTo3D, refine, tracker, null, null);\r\n    return new WrapVisOdomPixelDepthPnP(alg, pixelTo3D, distance, imageType);\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.TestImageLineIntegral.across_SlopeZero",
	"Comment": "test cases where the slope for x or y is zero across multiple pixels",
	"Method": "void across_SlopeZero(){\r\n    GrayU8 img = new GrayU8(10, 15);\r\n    img.set(6, 6, 100);\r\n    img.set(6, 7, 50);\r\n    img.set(6, 8, 10);\r\n    img.set(7, 6, 50);\r\n    img.set(8, 6, 10);\r\n    alg.setImage(FactoryGImageGray.wrap(img));\r\n    checkSolution(6.5, 6, 6.5, 8, 150);\r\n    checkSolution(6.5, 6, 6.5, 7.5, 125);\r\n    checkSolution(6.5, 6.5, 6.5, 8, 100);\r\n    checkSolution(6.5, 6.5, 6.5, 7.5, 75);\r\n    checkSolution(6.5, 6, 6.5, 8.5, 155);\r\n    checkSolution(6, 6.5, 8, 6.5, 150);\r\n    checkSolution(6, 6.5, 7.5, 6.5, 125);\r\n    checkSolution(6.5, 6.5, 8, 6.5, 100);\r\n    checkSolution(6.5, 6.5, 7.5, 6.5, 75);\r\n    checkSolution(6, 6.5, 8.5, 6.5, 155);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.MinimizeEnergyPrune.removeDuplicates",
	"Comment": "look for two corners which point to the same point and removes one of them from the corner list",
	"Method": "void removeDuplicates(GrowQueue_I32 corners){\r\n    for (int i = 0; i < corners.size(); i++) {\r\n        Point2D_I32 a = contour.get(corners.get(i));\r\n        for (int j = corners.size() - 1; j > i; j--) {\r\n            Point2D_I32 b = contour.get(corners.get(j));\r\n            if (a.x == b.x && a.y == b.y) {\r\n                corners.remove(j);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.background.TestBackgroundGmmCommon.createTwoModels",
	"Comment": "alternates between two values and see if two stable gaussians form",
	"Method": "void createTwoModels(){\r\n    int maxGaussians = 2;\r\n    BackgroundGmmCommon alg = new BackgroundGmmCommon(1000, 0.0f, maxGaussians, imageType);\r\n    alg.setSignificantWeight(1e-4f);\r\n    alg.setMaxDistance(5);\r\n    alg.setInitialVariance(12);\r\n    int startIndex = 24;\r\n    float[] data = new float[50];\r\n    float stdev = 10f;\r\n    float variance = stdev * stdev;\r\n    for (int i = 0; i < 100000; i++) {\r\n        float pixelValue = i % 2 == 0 ? 10 : 100;\r\n        float adjusted = pixelValue + (float) (rand.nextGaussian() * stdev);\r\n        if (Math.abs(pixelValue - adjusted) > 3 * stdev) {\r\n            adjusted = pixelValue;\r\n        }\r\n        alg.updateMixture(adjusted, data, startIndex);\r\n    }\r\n    int ng = 0;\r\n    for (; ng < maxGaussians; ng++) {\r\n        if (0 == data[startIndex + ng * 3 + 1])\r\n            break;\r\n    }\r\n    assertEquals(2, ng);\r\n    float weight0 = data[startIndex];\r\n    float weight1 = data[startIndex + 3];\r\n    float variance0 = data[startIndex + 1];\r\n    float variance1 = data[startIndex + 3 + 1];\r\n    float mean0 = data[startIndex + 2];\r\n    float mean1 = data[startIndex + 3 + 2];\r\n    assertEquals(10, mean0, 0.5);\r\n    assertEquals(100, mean1, 0.5);\r\n    assertEquals(0.5f, weight0, 0.2);\r\n    assertEquals(0.5f, weight1, 0.2);\r\n    float varianceTol = variance / 4;\r\n    assertEquals(variance, variance0, varianceTol);\r\n    assertEquals(variance, variance1, varianceTol);\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.ThresholdBlockCommon.selectBlockSize",
	"Comment": "selects a block size which is close to the requested block size by the user",
	"Method": "void selectBlockSize(int width,int height,int requestedBlockWidth){\r\n    int rows = height / requestedBlockWidth;\r\n    int cols = width / requestedBlockWidth;\r\n    blockHeight = height / rows;\r\n    blockWidth = width / cols;\r\n}"
}, {
	"Path": "boofcv.alg.transform.pyramid.PyramidOps.gradient",
	"Comment": "computes the gradient for each image the pyramid.\tit is assumed that the gradient has the same scales as the input.if not\tinitialized then it will be initialized.if already initialized it is\tassumed to be setup for the same input image size.",
	"Method": "void gradient(ImagePyramid<I> input,ImageGradient<I, O> gradient,O[] derivX,O[] derivY){\r\n    for (int i = 0; i < input.getNumLayers(); i++) {\r\n        I imageIn = input.getLayer(i);\r\n        gradient.process(imageIn, derivX[i], derivY[i]);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.ensureTriangleOrder",
	"Comment": "make sure the next corner after the head is the closest one to the head",
	"Method": "void ensureTriangleOrder(List<Point2D_I32> contour){\r\n    Element<Corner> e = list.getHead();\r\n    Corner a = e.object;\r\n    e = e.next;\r\n    Corner b = e.object;\r\n    e = e.next;\r\n    Corner c = e.object;\r\n    int distB = CircularIndex.distanceP(a.index, b.index, contour.size());\r\n    int distC = CircularIndex.distanceP(a.index, c.index, contour.size());\r\n    if (distB > distC) {\r\n        list.reset();\r\n        list.pushTail(a);\r\n        list.pushTail(c);\r\n        list.pushTail(b);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.TrackerMeanShiftComaniciu2003.distanceHistogram",
	"Comment": "computes the difference between two histograms using sad.\tthis is a change from the paper, which uses bhattacharyya.bhattacharyya could give poor performance\teven with perfect data since two errors can cancel each other out.for example, part of the histogram\tis too small and another part is too large.",
	"Method": "double distanceHistogram(float histogramA,float histogramB){\r\n    double sumP = 0;\r\n    for (int i = 0; i < histogramA.length; i++) {\r\n        float q = histogramA[i];\r\n        float p = histogramB[i];\r\n        sumP += Math.abs(q - p);\r\n    }\r\n    return sumP;\r\n}"
}, {
	"Path": "boofcv.alg.geo.structure.TestDecomposeAbsoluteDualQuadratic.computeRectifyingHomography",
	"Comment": "create a dual quadratic from its definition and see if its correctly decomposed",
	"Method": "void computeRectifyingHomography(){\r\n    Equation eq = new Equation(K, \"K\");\r\n    DMatrixRMaj Q = // change scale of Q to make it more interesting\r\n    eq.process(\"I=diag([1,1,1,0])\").process(\"p=[2.1;0.4;-0.3]\").process(\"H=[K [0;0;0];-p'*K 1]\").process(\"Q=H*I*H'\").process(\"Q=Q*1e-3\").lookupDDRM(\"Q\");\r\n    DMatrixRMaj H = eq.lookupDDRM(\"H\");\r\n    DMatrix4x4 _Q = new DMatrix4x4();\r\n    ConvertDMatrixStruct.convert(Q, _Q);\r\n    DecomposeAbsoluteDualQuadratic alg = new DecomposeAbsoluteDualQuadratic();\r\n    assertTrue(alg.decompose(_Q));\r\n    DMatrixRMaj foundH = new DMatrixRMaj(4, 4);\r\n    assertTrue(alg.computeRectifyingHomography(foundH));\r\n    assertTrue(MatrixFeatures_DDRM.isIdentical(H, foundH, UtilEjml.TEST_F64));\r\n    assertTrue(MatrixFeatures_D.isIdentical(K, alg.getK(), UtilEjml.TEST_F64));\r\n}"
}, {
	"Path": "boofcv.alg.distort.mls.TestImageDeformPointMLS_F32.testAllAtOnce_OnControlPoints",
	"Comment": "when sampled exactly on a control point the distortion should be the distortion for that point",
	"Method": "void testAllAtOnce_OnControlPoints(){\r\n    for (TypeDeformMLS type : TypeDeformMLS.values()) {\r\n        ImageDeformPointMLS_F32 alg = new ImageDeformPointMLS_F32(type);\r\n        alg.configure(100, 100, 11, 11);\r\n        alg.addControl(10, 0);\r\n        alg.addControl(10, 20);\r\n        alg.addControl(30, 40);\r\n        alg.addControl(80, 30);\r\n        alg.setDistorted(0, 10, 5);\r\n        alg.setDistorted(1, 14, 30);\r\n        alg.setDistorted(2, 25, 45);\r\n        alg.setDistorted(3, 20, 8);\r\n        alg.fixateUndistorted();\r\n        alg.fixateDistorted();\r\n        checkCompute(10, 0, 10, 5, alg);\r\n        checkCompute(10, 20, 14, 30, alg);\r\n        checkCompute(30, 40, 25, 45, alg);\r\n        checkCompute(80, 30, 20, 8, alg);\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.distort.ChecksPointDeformKeyPoints.individualDstSameAsAll",
	"Comment": "makes sure modifying a single points is the same as modifying all the points at once",
	"Method": "void individualDstSameAsAll(){\r\n    List<Point2D_F32> src = createTestPoints();\r\n    List<Point2D_F32> dst = createTestPoints();\r\n    PointDeformKeyPoints alg = createAlgorithm();\r\n    alg.setImageShape(80, 100);\r\n    alg.setSource(src);\r\n    alg.setSource(dst);\r\n    alg.setDestination(1, 20, 25);\r\n    Point2D_F32 expected = new Point2D_F32();\r\n    alg.compute(12, 19.5f, expected);\r\n    dst.get(1).set(20, 25);\r\n    Point2D_F32 found = new Point2D_F32();\r\n    alg.compute(12, 19.5f, found);\r\n    assertEquals(expected.x, found.x, GrlConstants.TEST_F32);\r\n    assertEquals(expected.y, found.y, GrlConstants.TEST_F32);\r\n}"
}, {
	"Path": "boofcv.struct.convolve.Kernel1D_F64.wrap",
	"Comment": "creates a kernel whose elements are the specified data array and has\tthe specified width.",
	"Method": "Kernel1D_F64 wrap(double data,int width,int offset){\r\n    Kernel1D_F64 ret = new Kernel1D_F64();\r\n    ret.data = data;\r\n    ret.width = width;\r\n    ret.offset = offset;\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.alg.filter.kernel.impl.TestSteerableKernel_F32.checkCombining",
	"Comment": "checks to see if the basis kernels are correctly combined together.",
	"Method": "void checkCombining(){\r\n    double[] c = new double[] { 0.1, 0.2, 0.8 };\r\n    DummySteerableCoefficients coef = new DummySteerableCoefficients(c);\r\n    Kernel2D[] basis = new Kernel2D[3];\r\n    basis[0] = FactoryKernel.random2D_F32(width, width / 2, 0, 10, rand);\r\n    basis[1] = FactoryKernel.random2D_F32(width, width / 2, 0, 10, rand);\r\n    basis[2] = FactoryKernel.random2D_F32(width, width / 2, 0, 10, rand);\r\n    Kernel2D_F32 expected = new Kernel2D_F32(width);\r\n    for (int y = 0; y < width; y++) {\r\n        for (int x = 0; x < width; x++) {\r\n            float total = 0;\r\n            for (int i = 0; i < c.length; i++) {\r\n                total += c[i] * ((Kernel2D_F32) basis[i]).get(x, y);\r\n            }\r\n            expected.set(x, y, total);\r\n        }\r\n    }\r\n    SteerableKernel_F32 alg = new SteerableKernel_F32();\r\n    alg.setBasis(coef, basis);\r\n    Kernel2D_F32 found = alg.compute(60.0);\r\n    assertTrue(KernelMath.isEquals(expected.data, found.data, width * width, 1e-4f));\r\n}"
}, {
	"Path": "boofcv.alg.sfm.StereoProcessingBase.getRectK",
	"Comment": "intrinsic camera calibration matrix for both cameras after rectification",
	"Method": "DMatrixRMaj getRectK(){\r\n    return rectK;\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.squares.TestSquaresIntoRegularClusters.considerConnect_shape_offset",
	"Comment": "everything is good, but they are offset from each other by too much",
	"Method": "void considerConnect_shape_offset(){\r\n    List<Polygon2D_F64> squares = new ArrayList();\r\n    squares.add(new Polygon2D_F64(-1, 1, 1, 1, 1, -1, -1, -1));\r\n    squares.add(new Polygon2D_F64(3, 2, 5, 1, 5, -1, 3, -2));\r\n    SquaresIntoRegularClusters alg = new SquaresIntoRegularClusters(2, 6, 1.35);\r\n    alg.computeNodeInfo(squares);\r\n    SquareNode a = alg.nodes.get(0);\r\n    SquareNode b = alg.nodes.get(1);\r\n    alg.considerConnect(a, b);\r\n    assertNotConnected(a, b);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.combined.PyramidKltForCombined.performTracking",
	"Comment": "updates the track using the latest inputs.if tracking fails then the feature description\tin each layer is unchanged and its global position.",
	"Method": "boolean performTracking(PyramidKltFeature feature){\r\n    KltTrackFault result = tracker.track(feature);\r\n    if (result != KltTrackFault.SUCCESS) {\r\n        return false;\r\n    } else {\r\n        tracker.setDescription(feature);\r\n        return true;\r\n    }\r\n}"
}, {
	"Path": "boofcv.examples.calibration.ExampleCalibrateStereo.process",
	"Comment": "process calibration images, compute intrinsic parameters, save to a file",
	"Method": "void process(){\r\n    CalibrateStereoPlanar calibratorAlg = new CalibrateStereoPlanar(detector.getLayout());\r\n    calibratorAlg.configure(true, 2, false);\r\n    Collections.sort(left);\r\n    Collections.sort(right);\r\n    for (int i = 0; i < left.size(); i++) {\r\n        BufferedImage l = UtilImageIO.loadImage(left.get(i));\r\n        BufferedImage r = UtilImageIO.loadImage(right.get(i));\r\n        GrayF32 imageLeft = ConvertBufferedImage.convertFrom(l, (GrayF32) null);\r\n        GrayF32 imageRight = ConvertBufferedImage.convertFrom(r, (GrayF32) null);\r\n        CalibrationObservation calibLeft, calibRight;\r\n        if (!detector.process(imageLeft)) {\r\n            System.out.println(\"Failed to detect target in \" + left.get(i));\r\n            continue;\r\n        }\r\n        calibLeft = detector.getDetectedPoints();\r\n        if (!detector.process(imageRight)) {\r\n            System.out.println(\"Failed to detect target in \" + right.get(i));\r\n            continue;\r\n        }\r\n        calibRight = detector.getDetectedPoints();\r\n        calibratorAlg.addPair(calibLeft, calibRight);\r\n    }\r\n    StereoParameters stereoCalib = calibratorAlg.process();\r\n    calibratorAlg.printStatistics();\r\n    CalibrationIO.save(stereoCalib, \"stereo.yaml\");\r\n    stereoCalib.print();\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.TestConnectLinesGrid.connectToNeighborRegion",
	"Comment": "very basic check to see if lines are connected between regions.",
	"Method": "void connectToNeighborRegion(){\r\n    checkConnectNeighbor(0, 0);\r\n    checkConnectNeighbor(1, 0);\r\n    checkConnectNeighbor(2, 0);\r\n    checkConnectNeighbor(2, 1);\r\n    checkConnectNeighbor(2, 2);\r\n    checkConnectNeighbor(1, 2);\r\n    checkConnectNeighbor(0, 2);\r\n    checkConnectNeighbor(0, 1);\r\n}"
}, {
	"Path": "boofcv.misc.TestDiscretizedCircle.testCircles",
	"Comment": "make sure the circles have the expected properties.\tright now it just checks the lengths.i can do a better job..",
	"Method": "void testCircles(){\r\n    int[] pts;\r\n    pts = DiscretizedCircle.imageOffsets(1, 100);\r\n    assertEquals(4, pts.length);\r\n    pts = DiscretizedCircle.imageOffsets(2, 100);\r\n    assertEquals(12, pts.length);\r\n    pts = DiscretizedCircle.imageOffsets(3, 100);\r\n    assertEquals(16, pts.length);\r\n}"
}, {
	"Path": "com.bugsnag.android.ErrorStoreTest.checkFileMatchesErrorReport",
	"Comment": "ensures that the file can be serialised back into a json report, and contains the same infoas the original",
	"Method": "void checkFileMatchesErrorReport(File file,Error error){\r\n    assertFalse(file.length() <= 0);\r\n    JSONObject memory = getJsonObjectFromReport(new Report(\"api-key\", file));\r\n    JSONObject disk = getJsonObjectFromReport(new Report(\"api-key\", error));\r\n    validateReportPayload(memory);\r\n    validateReportPayload(disk);\r\n}"
}, {
	"Path": "boofcv.abst.geo.bundle.SceneStructureProjective.getUnknownViewCount",
	"Comment": "returns the number of view with parameters that are not fixed",
	"Method": "int getUnknownViewCount(){\r\n    int total = 0;\r\n    for (int i = 0; i < views.length; i++) {\r\n        if (!views[i].known) {\r\n            total++;\r\n        }\r\n    }\r\n    return total;\r\n}"
}, {
	"Path": "boofcv.android.camera2.SimpleCamera2Activity.handleNoCameraSelected",
	"Comment": "called if no camera was selected when trying to open a camera",
	"Method": "boolean handleNoCameraSelected(){\r\n    return true;\r\n}"
}, {
	"Path": "com.examples.model.test.movies.media.MovieListGetter.getMoviePlayList",
	"Comment": "vends a play list after applying content rules based on user likeable.",
	"Method": "List<MoviePlayListItem> getMoviePlayList(String username){\r\n    return retrievePlayList(username, ScreenDevice.UNKNOWN, DeviceConnectionSpeed.UNKNOWN, null);\r\n}"
}, {
	"Path": "com.bugsnag.android.DeviceData.retrieveUniqueInstallId",
	"Comment": "get the unique id for the current app installation, creating a unique uuid if needed",
	"Method": "String retrieveUniqueInstallId(){\r\n    SharedPreferences sharedPref = client.sharedPrefs;\r\n    String installId = sharedPref.getString(INSTALL_ID_KEY, null);\r\n    if (installId == null) {\r\n        installId = UUID.randomUUID().toString();\r\n        sharedPref.edit().putString(INSTALL_ID_KEY, installId).apply();\r\n    }\r\n    return installId;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.HysteresisEdgeTracePoints.process",
	"Comment": "performs hysteresis thresholding using the provided lower and upper thresholds.",
	"Method": "void process(GrayF32 intensity,GrayS8 direction,float lower,float upper){\r\n    if (lower < 0)\r\n        throw new IllegalArgumentException(\"Lower must be >= 0!\");\r\n    InputSanityCheck.checkSameShape(intensity, direction);\r\n    this.intensity = intensity;\r\n    this.direction = direction;\r\n    this.lower = lower;\r\n    queuePoints.reset();\r\n    contours.clear();\r\n    for (int y = 0; y < intensity.height; y++) {\r\n        int indexInten = intensity.startIndex + y * intensity.stride;\r\n        for (int x = 0; x < intensity.width; x++, indexInten++) {\r\n            if (intensity.data[indexInten] >= upper) {\r\n                trace(x, y, indexInten);\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.simulation.TestSimulatePlanarWorld.checkApparentSize",
	"Comment": "sees if a box appears to be the correct size using pinhole distortion",
	"Method": "void checkApparentSize(){\r\n    double markerZ = 2;\r\n    double markerWidth = 0.5;\r\n    CameraPinhole pinhole = new CameraPinhole(400, 400, 0, 300, 250, 600, 500);\r\n    GrayF32 marker = new GrayF32(40, 30);\r\n    GImageMiscOps.fill(marker, 255);\r\n    Se3_F64 markerToWorld = eulerXyz(0, 0, markerZ, 0, Math.PI, 0, null);\r\n    SimulatePlanarWorld alg = new SimulatePlanarWorld();\r\n    alg.setCamera(pinhole);\r\n    alg.addSurface(markerToWorld, markerWidth, marker);\r\n    alg.render();\r\n    Point2D_F64 p0 = new Point2D_F64();\r\n    Point2D_F64 p1 = new Point2D_F64();\r\n    double ratio = marker.height / (double) marker.width;\r\n    WorldToCameraToPixel w2p = new WorldToCameraToPixel();\r\n    w2p.configure(pinhole, new Se3_F64());\r\n    assertTrue(w2p.transform(new Point3D_F64(-markerWidth / 2, -ratio * markerWidth / 2, markerZ), p0));\r\n    assertTrue(w2p.transform(new Point3D_F64(markerWidth / 2, ratio * markerWidth / 2, markerZ), p1));\r\n    double expectedWidth = p1.x - p0.x;\r\n    double expectedHeight = p1.y - p0.y;\r\n    GrayF32 image = alg.getOutput();\r\n    assertEquals(expectedWidth, findWidth(image, image.height / 2), 1);\r\n    assertEquals(expectedWidth, findWidth(image, image.height / 2 - 10), 1);\r\n    assertEquals(expectedWidth, findWidth(image, image.height / 2 + 10), 1);\r\n    assertEquals(expectedHeight, findHeight(image, image.width / 2), 1);\r\n    assertEquals(expectedHeight, findHeight(image, image.width / 2 - 10), 1);\r\n    assertEquals(expectedHeight, findHeight(image, image.width / 2 + 10), 1);\r\n}"
}, {
	"Path": "boofcv.abst.geo.bundle.GenericBundleAdjustmentMetricChecks.multipleCalls",
	"Comment": "same solution when called multiple times in a row. checks to see if it is correctly reset",
	"Method": "void multipleCalls(){\r\n    BundleAdjustment<SceneStructureMetric> alg = createAlg();\r\n    Tuple2<SceneStructureMetric, SceneObservations> a = createHorizontalMotion(123, true);\r\n    Tuple2<SceneStructureMetric, SceneObservations> c = createHorizontalMotion(234, true);\r\n    addNoiseToPoint3D(c);\r\n    alg.setParameters(a.data0, a.data1);\r\n    alg.optimize(c.data0);\r\n    alg.setParameters(a.data0, a.data1);\r\n    alg.optimize(a.data0);\r\n    Tuple2<SceneStructureMetric, SceneObservations> b = createHorizontalMotion(123, true);\r\n    assertEquals(a.data0, b.data0, 1e-6, 1e-6, 1e-6);\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.normalized.TestConvolveNormalizedNaive_IL.horizontal",
	"Comment": "check it against one specific type to see if the core algorithm is correct",
	"Method": "void horizontal(int horizontal,int x,int y,int band,Kernel1D_S32 kernel,InterleavedU8 image){\r\n    int total = 0;\r\n    int weight = 0;\r\n    for (int i = 0; i < kernel.width; i++) {\r\n        if (image.isInBounds(x + i - kernel.offset, y)) {\r\n            int w = kernel.get(i);\r\n            int v = image.getBand(x + i - kernel.offset, y, band);\r\n            total += w * v;\r\n            weight += w;\r\n        }\r\n    }\r\n    return (total + weight / 2) / weight;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.StitchingFromMotion2D.checkLargeMotion",
	"Comment": "looks for sudden large changes in corner location to detect motion estimation faults.",
	"Method": "boolean checkLargeMotion(int width,int height){\r\n    if (first) {\r\n        getImageCorners(width, height, corners);\r\n        previousArea = computeArea(corners);\r\n        first = false;\r\n    } else {\r\n        getImageCorners(width, height, corners);\r\n        double area = computeArea(corners);\r\n        double change = Math.max(area / previousArea, previousArea / area) - 1;\r\n        if (change > maxJumpFraction) {\r\n            return true;\r\n        }\r\n        previousArea = area;\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "org.bimserver.shared.GuidCompressor.compressGuidString",
	"Comment": "converts an uncompressed string representation of a guid into a compressed one",
	"Method": "String compressGuidString(String uncompressedString){\r\n    Guid guid = getGuidFromUncompressedString(uncompressedString);\r\n    return getCompressedStringFromGuid(guid);\r\n}"
}, {
	"Path": "boofcv.alg.geo.structure.TestProjectiveReconstructionByFactorization.perfect_input",
	"Comment": "perfect observations and perfect input, output should be just perfect",
	"Method": "void perfect_input(){\r\n    int numViews = 8;\r\n    int numFeatures = 10;\r\n    simulate(numViews, numFeatures, false);\r\n    ProjectiveStructureByFactorization alg = new ProjectiveStructureByFactorization();\r\n    alg.initialize(features3D.size(), projections.size());\r\n    setPerfectDepths(numFeatures, alg);\r\n    for (int viewIdx = 0; viewIdx < projections.size(); viewIdx++) {\r\n        alg.setPixels(viewIdx, observations.get(viewIdx));\r\n    }\r\n    assertTrue(alg.process());\r\n    DMatrixRMaj P = new DMatrixRMaj(3, 4);\r\n    Point4D_F64 X = new Point4D_F64();\r\n    for (int viewIdx = 0; viewIdx < numViews; viewIdx++) {\r\n        alg.getCameraMatrix(viewIdx, P);\r\n        for (int featureIdx = 0; featureIdx < numFeatures; featureIdx++) {\r\n            alg.getFeature3D(featureIdx, X);\r\n            Point2D_F64 expected = observations.get(viewIdx).get(featureIdx);\r\n            Point3D_F64 xh = PerspectiveOps.renderPixel(P, X, (Point3D_F64) null);\r\n            Point2D_F64 found = new Point2D_F64(xh.x / xh.z, xh.y / xh.z);\r\n            assertTrue(expected.distance(found) < UtilEjml.TEST_F64);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.bundle.BundleAdjustmentProjectiveResidualFunction.configure",
	"Comment": "specifies the scenes structure and observed feature locations",
	"Method": "void configure(SceneStructureProjective structure,SceneObservations observations){\r\n    this.structure = structure;\r\n    this.observations = observations;\r\n    numObservations = observations.getObservationCount();\r\n    numParameters = structure.getParameterCount();\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.AssociateUniqueByScoreAlg.processDestination",
	"Comment": "selects a subset of matches that have at most one association for each destination feature.",
	"Method": "void processDestination(FastQueue<AssociatedIndex> matches,int numDestination,FastQueue<AssociatedIndex> output){\r\n    scores.resize(numDestination);\r\n    solutions.resize(numDestination);\r\n    for (int i = 0; i < numDestination; i++) {\r\n        solutions.data[i] = -1;\r\n    }\r\n    for (int i = 0; i < matches.size(); i++) {\r\n        AssociatedIndex a = matches.get(i);\r\n        int found = solutions.data[a.dst];\r\n        if (found != -1) {\r\n            if (found == -2) {\r\n                double bestScore = scores.data[a.dst];\r\n                int result = type.compareTo(bestScore, a.fitScore);\r\n                if (result < 0) {\r\n                    solutions.data[a.dst] = i;\r\n                    scores.data[a.dst] = a.fitScore;\r\n                }\r\n            } else {\r\n                AssociatedIndex currentBest = matches.get(found);\r\n                int result = type.compareTo(currentBest.fitScore, a.fitScore);\r\n                if (result < 0) {\r\n                    solutions.data[a.dst] = i;\r\n                    scores.data[a.dst] = a.fitScore;\r\n                } else if (result == 0) {\r\n                    solutions.data[a.dst] = -2;\r\n                }\r\n            }\r\n        } else {\r\n            solutions.data[a.dst] = i;\r\n            scores.data[a.dst] = i;\r\n        }\r\n    }\r\n    output.reset();\r\n    for (int i = 0; i < numDestination; i++) {\r\n        int index = solutions.data[i];\r\n        if (index >= 0) {\r\n            output.add(matches.get(index));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernel.random2D_F64",
	"Comment": "creates a random 2d kernel drawn from a uniform distribution.",
	"Method": "Kernel2D_F64 random2D_F64(int width,int offset,double min,double max,Random rand){\r\n    Kernel2D_F64 ret = new Kernel2D_F64(width, offset);\r\n    double range = max - min;\r\n    for (int i = 0; i < ret.data.length; i++) {\r\n        ret.data[i] = rand.nextDouble() * range + min;\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.testing.BoofTesting.checkImageDimensionReshape",
	"Comment": "searches for functions that accept only images and makes sure they only accept\timages which have he same width and height.",
	"Method": "void checkImageDimensionReshape(Object testClass,int numFunctions){\r\n    int count = 0;\r\n    Method[] methods = testClass.getClass().getMethods();\r\n    for (Method m : methods) {\r\n        if (!areAllInputsImages(m))\r\n            continue;\r\n        Class[] params = m.getParameterTypes();\r\n        Object[] inputs = new Object[params.length];\r\n        for (int i = 0; i < params.length; i++) {\r\n            inputs[i] = GeneralizedImageOps.createSingleBand(params[i], 10, 20);\r\n        }\r\n        try {\r\n            m.invoke(testClass, inputs);\r\n        } catch (IllegalAccessException | InvocationTargetException e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n        for (int target = 1; target < params.length; target++) {\r\n            for (int i = 0; i < params.length; i++) {\r\n                if (i != target)\r\n                    inputs[i] = GeneralizedImageOps.createSingleBand(params[i], 10, 20);\r\n                else\r\n                    inputs[i] = GeneralizedImageOps.createSingleBand(params[i], 11, 22);\r\n            }\r\n            try {\r\n                m.invoke(testClass, inputs);\r\n            } catch (IllegalAccessException | InvocationTargetException e) {\r\n                throw new RuntimeException(e);\r\n            }\r\n            for (int i = 1; i < params.length; i++) {\r\n                if (10 != ((ImageBase) inputs[i]).width || 20 != ((ImageBase) inputs[i]).height)\r\n                    throw new RuntimeException(\"Wasn't reshaped\");\r\n            }\r\n        }\r\n        count++;\r\n    }\r\n    if (count != numFunctions)\r\n        throw new RuntimeException(\"Unexpected number of functions. cnt=\" + count + \" funcs=\" + numFunctions);\r\n}"
}, {
	"Path": "boofcv.alg.distort.mls.ImageDeformPointMLS_F32.fixateUndistorted",
	"Comment": "precompute the portion of the equation which only concerns the undistorted location of each point on the\tgrid even the current undistorted location of each control point.",
	"Method": "void fixateUndistorted(){\r\n    if (controls.size() < 2)\r\n        throw new RuntimeException(\"Not enough control points specified.  Found \" + controls.size());\r\n    for (int row = 0; row < gridRows; row++) {\r\n        for (int col = 0; col < gridCols; col++) {\r\n            Cache cache = getGrid(row, col);\r\n            cache.weights.resize(controls.size);\r\n            cache.A.resize(controls.size);\r\n            cache.A_s.resize(controls.size());\r\n            float v_x = col;\r\n            float v_y = row;\r\n            computeWeights(cache, v_x, v_y);\r\n            computeAverageP(cache);\r\n            model.computeCache(cache, v_x, v_y);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.provider.BoneCPConnectionProvider.createPool",
	"Comment": "creates the given connection pool with the given configuration. extracted here to make unit mocking easier.",
	"Method": "BoneCP createPool(BoneCPConfig config){\r\n    try {\r\n        return new BoneCP(config);\r\n    } catch (SQLException e) {\r\n        throw new HibernateException(e);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.DetectCircleGrid.closestCorner4",
	"Comment": "number of ccw rotations to put selected corner into the canonical location.only works\twhen there are 4 possible solutions",
	"Method": "int closestCorner4(Grid g){\r\n    double bestDistance = g.get(0, 0).center.normSq();\r\n    int bestIdx = 0;\r\n    double d = g.get(0, g.columns - 1).center.normSq();\r\n    if (d < bestDistance) {\r\n        bestDistance = d;\r\n        bestIdx = 3;\r\n    }\r\n    d = g.get(g.rows - 1, g.columns - 1).center.normSq();\r\n    if (d < bestDistance) {\r\n        bestDistance = d;\r\n        bestIdx = 2;\r\n    }\r\n    d = g.get(g.rows - 1, 0).center.normSq();\r\n    if (d < bestDistance) {\r\n        bestIdx = 1;\r\n    }\r\n    return bestIdx;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.DetectPolygonBinaryGrayRefine.process",
	"Comment": "detects polygons inside the grayscale image and its thresholded version",
	"Method": "void process(T gray,GrayU8 binary){\r\n    detector.process(gray, binary);\r\n    if (refineGray != null)\r\n        refineGray.setImage(gray);\r\n    edgeIntensity.setImage(gray);\r\n    long time0 = System.nanoTime();\r\n    FastQueue<DetectPolygonFromContour.Info> detections = detector.getFound();\r\n    if (adjustForBias != null) {\r\n        int minSides = getMinimumSides();\r\n        for (int i = detections.size() - 1; i >= 0; i--) {\r\n            Polygon2D_F64 p = detections.get(i).polygon;\r\n            adjustForBias.process(p, detector.isOutputClockwise());\r\n            if (p.size() < minSides)\r\n                detections.remove(i);\r\n        }\r\n    }\r\n    long time1 = System.nanoTime();\r\n    double milli = (time1 - time0) * 1e-6;\r\n    milliAdjustBias.update(milli);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.combined.CombinedTrackerScalePoint.trackUsingKlt",
	"Comment": "tracks features in the list using klt and update their state",
	"Method": "void trackUsingKlt(List<CombinedTrack<TD>> tracks){\r\n    for (int i = 0; i < tracks.size(); ) {\r\n        CombinedTrack<TD> track = tracks.get(i);\r\n        if (!trackerKlt.performTracking(track.track)) {\r\n            tracks.remove(i);\r\n            tracksDormant.add(track);\r\n        } else {\r\n            track.set(track.track.x, track.track.y);\r\n            i++;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.filter.convolve.FactoryConvolveDown.convolveSB",
	"Comment": "creates a filter for convolving 2d kernels along the image axis.",
	"Method": "GenericConvolveDown<Input, Output> convolveSB(Kernel1D kernel,BorderType border,boolean isHorizontal,int skip,Class<Input> inputType,Class<Output> outputType,GenericConvolveDown<Input, Output> convolveSB,Kernel2D kernel,BorderType border,int skip,Class<Input> inputType,Class<Output> outputType){\r\n    outputType = BoofTesting.convertToGenericType(outputType);\r\n    Method m;\r\n    try {\r\n        switch(border) {\r\n            case SKIP:\r\n                m = ConvolveImageDownNoBorder.class.getMethod(\"convolve\", kernel.getClass(), inputType, outputType, int.class);\r\n                break;\r\n            case EXTENDED:\r\n                throw new IllegalArgumentException(\"Extended border is currently not supported.\");\r\n            case NORMALIZED:\r\n                m = ConvolveImageDownNormalized.class.getMethod(\"convolve\", kernel.getClass(), inputType, outputType, int.class);\r\n                break;\r\n            default:\r\n                throw new IllegalArgumentException(\"Unknown border type \" + border);\r\n        }\r\n    } catch (NoSuchMethodException e) {\r\n        throw new IllegalArgumentException(\"The specified convolution cannot be found\");\r\n    }\r\n    return new GenericConvolveDown(m, kernel, border, skip, ImageType.single(inputType), ImageType.single(outputType));\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.BasicDisparityTests.checkGradient",
	"Comment": "set the intensity values to have a gradient and see if it generates the correct\tsolution",
	"Method": "void checkGradient(){\r\n    initialize(0, maxDisparity);\r\n    int disparity = 5;\r\n    for (int y = 0; y < h; y++) {\r\n        for (int x = 0; x < w; x++) {\r\n            GeneralizedImageOps.set(left, x, y, 10 + x + y);\r\n            GeneralizedImageOps.set(right, x, y, 10 + x + disparity + y);\r\n        }\r\n    }\r\n    DI output = computeDisparity(left, right);\r\n    int borderX = getBorderX();\r\n    int borderY = getBorderY();\r\n    for (int y = borderY; y < h - borderY; y++) {\r\n        for (int x = 0; x < borderX; x++) {\r\n            double found = GeneralizedImageOps.get(output, x, y);\r\n            assertEquals(0, found, 1e-8);\r\n        }\r\n        for (int x = w - borderX; x < w; x++) {\r\n            double found = GeneralizedImageOps.get(output, x, y);\r\n            assertEquals(0, found, 1e-8);\r\n        }\r\n        for (int x = borderX + disparity; x < w - borderX; x++) {\r\n            double found = GeneralizedImageOps.get(output, x, y);\r\n            assertEquals(disparity, found, 1e-8);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.SiftScaleSpace.computeSigmaScale",
	"Comment": "computes the effective amount of blur at the given scale in the current octave.",
	"Method": "double computeSigmaScale(int scale,double computeSigmaScale,int octave,int scale){\r\n    return sigma0 * Math.pow(2, octave + scale / (double) numScales);\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.StandardPointTrackerTwoPass.processImage",
	"Comment": "calling process and finishtracking should be equivalent to process in pointtracker",
	"Method": "void processImage(T image){\r\n    PointTrackerTwoPass<T> tracker = (PointTrackerTwoPass<T>) this.tracker;\r\n    tracker.process(image);\r\n    tracker.finishTracking();\r\n}"
}, {
	"Path": "boofcv.alg.transform.wavelet.TestFactoryWaveletCoiflet.generate_F32",
	"Comment": "sees if the standard coifi wavelets have the expected characteristics",
	"Method": "void generate_F32(){\r\n    for (int i = 6; i <= 6; i += 2) {\r\n        WaveletDescription<WlCoef_F32> desc = FactoryWaveletCoiflet.generate_F32(i);\r\n        WlCoef_F32 coef = desc.forward;\r\n        double sumScaling = UtilWavelet.sumCoefficients(coef.scaling);\r\n        double sumWavelet = UtilWavelet.sumCoefficients(coef.wavelet);\r\n        assertEquals(Math.sqrt(2), sumScaling, 1e-4);\r\n        assertEquals(0, sumWavelet, 1e-4);\r\n        double energyScaling = UtilWavelet.computeEnergy(coef.scaling);\r\n        double energyWavelet = UtilWavelet.computeEnergy(coef.wavelet);\r\n        assertEquals(1, energyScaling, 1e-4);\r\n        assertEquals(1, energyWavelet, 1e-4);\r\n        int polyOrder = i / 2 - 1;\r\n        checkPolySumToZero(coef.scaling, polyOrder, -2);\r\n        checkPolySumToZero(coef.wavelet, polyOrder - 1, 0);\r\n        checkBiorthogonal_F32(desc);\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.image.TestImageInterleaved.constructor_w_h_n",
	"Comment": "test the constructor where the width,height and number of bands is specified.",
	"Method": "void constructor_w_h_n(){\r\n    DummyImage a = new DummyImage(10, 20, 3);\r\n    assertEquals(10 * 20 * 3, a.data.length);\r\n    assertEquals(10, a.getWidth());\r\n    assertEquals(20, a.getHeight());\r\n    assertEquals(3, a.getNumBands());\r\n    assertEquals(30, a.getStride());\r\n    assertEquals(0, a.getStartIndex());\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.ImageMotionPointTrackerKey.reset",
	"Comment": "makes the current frame the first frame and discards its past history",
	"Method": "void reset(){\r\n    totalFramesProcessed = 0;\r\n    tracker.dropAllTracks();\r\n    resetTransforms();\r\n}"
}, {
	"Path": "org.boon.core.Conversions.toBoolean",
	"Comment": "converts the value to boolean, and if it is null, it uses the default value passed.",
	"Method": "boolean toBoolean(Object value,boolean toBoolean,Object obj,boolean defaultValue){\r\n    if (obj == null) {\r\n        return defaultValue;\r\n    }\r\n    if (obj instanceof Boolean) {\r\n        return ((Boolean) obj).booleanValue();\r\n    } else if (obj instanceof Number || obj.getClass().isPrimitive()) {\r\n        int value = toInt(obj);\r\n        return value != 0 ? true : false;\r\n    } else if (obj instanceof String || obj instanceof CharSequence) {\r\n        String str = Conversions.toString(obj);\r\n        if (str.length() == 0) {\r\n            return false;\r\n        }\r\n        if (str.equals(\"false\")) {\r\n            return false;\r\n        } else {\r\n            return true;\r\n        }\r\n    } else if (Boon.isArray(obj)) {\r\n        return Boon.len(obj) > 0;\r\n    } else if (obj instanceof Collection) {\r\n        if (len(obj) > 0) {\r\n            List list = Lists.list((Collection) obj);\r\n            while (list.remove(null)) {\r\n            }\r\n            return Lists.len(list) > 0;\r\n        } else {\r\n            return false;\r\n        }\r\n    } else {\r\n        return toBoolean(Conversions.toString(obj));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.pose.TestPnPDistanceReprojectionSq.checkErrorSingle",
	"Comment": "provide an observation with a known solution and see if it is computed correctly",
	"Method": "void checkErrorSingle(){\r\n    DMatrixRMaj K = new DMatrixRMaj(3, 3, true, 100, 0.01, 200, 0, 150, 200, 0, 0, 1);\r\n    Se3_F64 worldToCamera = new Se3_F64();\r\n    worldToCamera.getT().set(0.1, -0.1, 0.2);\r\n    Point3D_F64 X = new Point3D_F64(0.1, -0.04, 2.3);\r\n    double deltaX = 0.1;\r\n    double deltaY = -0.2;\r\n    Point2D_F64 observed = PerspectiveOps.renderPixel(worldToCamera, K, X);\r\n    observed.x += deltaX;\r\n    observed.y += deltaY;\r\n    PerspectiveOps.convertPixelToNorm(K, observed, observed);\r\n    PnPDistanceReprojectionSq alg = new PnPDistanceReprojectionSq();\r\n    alg.setIntrinsic(0, PerspectiveOps.matrixToPinhole(K, 0, 0, null));\r\n    alg.setModel(worldToCamera);\r\n    double found = alg.computeDistance(new Point2D3D(observed, X));\r\n    double expected = deltaX * deltaX + deltaY * deltaY;\r\n    assertEquals(expected, found, 1e-8);\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernelGaussian.derivative",
	"Comment": "creates a 1d gaussian kernel with the specified properties.",
	"Method": "T derivative(int order,boolean isFloat,double sigma,int radius){\r\n    if (order == 0) {\r\n        return gaussian(1, isFloat, 32, sigma, radius);\r\n    }\r\n    if (radius <= 0)\r\n        radius = FactoryKernelGaussian.radiusForSigma(sigma, order);\r\n    else if (sigma <= 0) {\r\n        sigma = FactoryKernelGaussian.sigmaForRadius(radius, order);\r\n    }\r\n    Kernel1D_F32 k = derivative1D_F32(order, sigma, radius, true);\r\n    if (isFloat)\r\n        return (T) k;\r\n    return (T) KernelMath.convert(k, MIN_FRAC);\r\n}"
}, {
	"Path": "io.buji.pac4j.subject.Pac4jPrincipal.getName",
	"Comment": "returns a name for the principal based upon one of the attributesof the main commonprofile.the attribute name used to query the commonprofile is specified in the constructor.",
	"Method": "String getName(){\r\n    CommonProfile profile = this.getProfile();\r\n    if (null == principalNameAttribute) {\r\n        return profile.getId();\r\n    }\r\n    Object attrValue = profile.getAttribute(principalNameAttribute);\r\n    return (null == attrValue) ? null : String.valueOf(attrValue);\r\n}"
}, {
	"Path": "boofcv.factory.sfm.FactoryMotion2D.createMotion2D",
	"Comment": "estimates the 2d motion of an image using different models.",
	"Method": "ImageMotion2D<I, IT> createMotion2D(int ransacIterations,double inlierThreshold,int outlierPrune,int absoluteMinimumTracks,double respawnTrackFraction,double respawnCoverageFraction,boolean refineEstimate,PointTracker<I> tracker,IT motionModel){\r\n    ModelManager<IT> manager;\r\n    ModelGenerator<IT, AssociatedPair> fitter;\r\n    DistanceFromModel<IT, AssociatedPair> distance;\r\n    ModelFitter<IT, AssociatedPair> modelRefiner = null;\r\n    if (motionModel instanceof Homography2D_F64) {\r\n        GenerateHomographyLinear mf = new GenerateHomographyLinear(true);\r\n        manager = (ModelManager) new ModelManagerHomography2D_F64();\r\n        fitter = (ModelGenerator) mf;\r\n        if (refineEstimate)\r\n            modelRefiner = (ModelFitter) mf;\r\n        distance = (DistanceFromModel) new DistanceHomographySq();\r\n    } else if (motionModel instanceof Affine2D_F64) {\r\n        manager = (ModelManager) new ModelManagerAffine2D_F64();\r\n        GenerateAffine2D mf = new GenerateAffine2D();\r\n        fitter = (ModelGenerator) mf;\r\n        if (refineEstimate)\r\n            modelRefiner = (ModelFitter) mf;\r\n        distance = (DistanceFromModel) new DistanceAffine2DSq();\r\n    } else if (motionModel instanceof Se2_F64) {\r\n        manager = (ModelManager) new ModelManagerSe2_F64();\r\n        MotionTransformPoint<Se2_F64, Point2D_F64> alg = new MotionSe2PointSVD_F64();\r\n        GenerateSe2_AssociatedPair mf = new GenerateSe2_AssociatedPair(alg);\r\n        fitter = (ModelGenerator) mf;\r\n        distance = (DistanceFromModel) new DistanceSe2Sq();\r\n    } else {\r\n        throw new RuntimeException(\"Unknown model type: \" + motionModel.getClass().getSimpleName());\r\n    }\r\n    ModelMatcher<IT, AssociatedPair> modelMatcher = new Ransac(123123, manager, fitter, distance, ransacIterations, inlierThreshold);\r\n    ImageMotionPointTrackerKey<I, IT> lowlevel = new ImageMotionPointTrackerKey(tracker, modelMatcher, modelRefiner, motionModel, outlierPrune);\r\n    ImageMotionPtkSmartRespawn<I, IT> smartRespawn = new ImageMotionPtkSmartRespawn(lowlevel, absoluteMinimumTracks, respawnTrackFraction, respawnCoverageFraction);\r\n    return new WrapImageMotionPtkSmartRespawn(smartRespawn);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.LineImageOps.pruneSimilarLines",
	"Comment": "prunes similar looking lines, but keeps the lines with the most intensity.",
	"Method": "List<LineParametric2D_F32> pruneSimilarLines(List<LineParametric2D_F32> lines,float intensity,float toleranceAngle,float toleranceDist,int imgWidth,int imgHeight){\r\n    int[] indexSort = new int[intensity.length];\r\n    QuickSort_F32 sort = new QuickSort_F32();\r\n    sort.sort(intensity, 0, lines.size(), indexSort);\r\n    float[] theta = new float[lines.size()];\r\n    List<LineSegment2D_F32> segments = new ArrayList(lines.size());\r\n    for (int i = 0; i < lines.size(); i++) {\r\n        LineParametric2D_F32 l = lines.get(i);\r\n        theta[i] = UtilAngle.atanSafe(l.getSlopeY(), l.getSlopeX());\r\n        segments.add(convert(l, imgWidth, imgHeight));\r\n    }\r\n    for (int i = segments.size() - 1; i >= 0; i--) {\r\n        LineSegment2D_F32 a = segments.get(indexSort[i]);\r\n        if (a == null)\r\n            continue;\r\n        for (int j = i - 1; j >= 0; j--) {\r\n            LineSegment2D_F32 b = segments.get(indexSort[j]);\r\n            if (b == null)\r\n                continue;\r\n            if (UtilAngle.distHalf(theta[indexSort[i]], theta[indexSort[j]]) > toleranceAngle)\r\n                continue;\r\n            Point2D_F32 p = Intersection2D_F32.intersection(a, b, null);\r\n            if (p != null && p.x >= 0 && p.y >= 0 && p.x < imgWidth && p.y < imgHeight) {\r\n                segments.set(indexSort[j], null);\r\n            } else {\r\n                float distA = Distance2D_F32.distance(a, b.a);\r\n                float distB = Distance2D_F32.distance(a, b.b);\r\n                if (distA <= toleranceDist || distB < toleranceDist) {\r\n                    segments.set(indexSort[j], null);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    List<LineParametric2D_F32> ret = new ArrayList();\r\n    for (int i = 0; i < segments.size(); i++) {\r\n        if (segments.get(i) != null) {\r\n            ret.add(lines.get(i));\r\n        }\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "com.bugsnag.android.EventReceiver.buildActions",
	"Comment": "builds a map of intent actions and their breadcrumb type.noisy breadcrumbs are commented out, along with anything that involves a state change.",
	"Method": "Map<String, BreadcrumbType> buildActions(){\r\n    Map<String, BreadcrumbType> actions = new HashMap();\r\n    actions.put(\"android.appwidget.action.APPWIDGET_DELETED\", BreadcrumbType.USER);\r\n    actions.put(\"android.appwidget.action.APPWIDGET_DISABLED\", BreadcrumbType.USER);\r\n    actions.put(\"android.appwidget.action.APPWIDGET_ENABLED\", BreadcrumbType.USER);\r\n    actions.put(\"android.appwidget.action.APPWIDGET_HOST_RESTORED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.appwidget.action.APPWIDGET_RESTORED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.appwidget.action.APPWIDGET_UPDATE\", BreadcrumbType.STATE);\r\n    actions.put(\"android.appwidget.action.APPWIDGET_UPDATE_OPTIONS\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.ACTION_POWER_CONNECTED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.ACTION_POWER_DISCONNECTED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.ACTION_SHUTDOWN\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.AIRPLANE_MODE\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.BATTERY_LOW\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.BATTERY_OKAY\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.BOOT_COMPLETED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.CAMERA_BUTTON\", BreadcrumbType.USER);\r\n    actions.put(\"android.intent.action.CLOSE_SYSTEM_DIALOGS\", BreadcrumbType.USER);\r\n    actions.put(\"android.intent.action.CONFIGURATION_CHANGED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.CONTENT_CHANGED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.DATE_CHANGED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.DEVICE_STORAGE_LOW\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.DEVICE_STORAGE_OK\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.DOCK_EVENT\", BreadcrumbType.USER);\r\n    actions.put(\"android.intent.action.DREAMING_STARTED\", BreadcrumbType.NAVIGATION);\r\n    actions.put(\"android.intent.action.DREAMING_STOPPED\", BreadcrumbType.NAVIGATION);\r\n    actions.put(\"android.intent.action.INPUT_METHOD_CHANGED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.LOCALE_CHANGED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.REBOOT\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.SCREEN_OFF\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.SCREEN_ON\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.TIMEZONE_CHANGED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.intent.action.TIME_SET\", BreadcrumbType.STATE);\r\n    actions.put(\"android.media.RINGER_MODE_CHANGED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.os.action.DEVICE_IDLE_MODE_CHANGED\", BreadcrumbType.STATE);\r\n    actions.put(\"android.os.action.POWER_SAVE_MODE_CHANGED\", BreadcrumbType.STATE);\r\n    return actions;\r\n}"
}, {
	"Path": "boofcv.struct.image.ImageBase.isInBounds",
	"Comment": "returns true if the pixel coordinate is inside the image or false if not.",
	"Method": "boolean isInBounds(int x,int y){\r\n    return x >= 0 && x < width && y >= 0 && y < height;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.TestImageMotionPointTrackerKey.testPrune",
	"Comment": "see if tracks are pruned after not being in inlier set for x time",
	"Method": "void testPrune(){\r\n    Se2_F32 computed = new Se2_F32(4, 5, 6);\r\n    Se2_F32 model = new Se2_F32();\r\n    DummyTracker tracker = new DummyTracker();\r\n    DummyModelMatcher<Se2_F32> matcher = new DummyModelMatcher(computed, 5);\r\n    GrayU8 input = new GrayU8(20, 30);\r\n    ImageMotionPointTrackerKey<GrayU8, Se2_F32> alg = new ImageMotionPointTrackerKey(tracker, matcher, null, model, 5);\r\n    alg.totalFramesProcessed = 9;\r\n    for (int i = 0; i < 10; i++) {\r\n        PointTrack t = new PointTrack();\r\n        AssociatedPairTrack a = new AssociatedPairTrack();\r\n        a.lastUsed = i;\r\n        t.cookie = a;\r\n        tracker.list.add(t);\r\n    }\r\n    alg.process(input);\r\n    assertEquals(6, tracker.numDropped);\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.OrientationHistogramSift.computeWeight",
	"Comment": "computes the weight based on a centered gaussian shaped function.interpolation is used to speed up the process",
	"Method": "double computeWeight(double deltaX,double deltaY,double sigma){\r\n    double d = ((deltaX * deltaX + deltaY * deltaY) / (sigma * sigma)) / approximateStep;\r\n    if (approximateGauss.interpolate(d)) {\r\n        return approximateGauss.value;\r\n    } else\r\n        return 0;\r\n}"
}, {
	"Path": "boofcv.struct.BoofDefaults.borderDerivative_F32",
	"Comment": "creates a new instance of the default border for derivatives of grayf32",
	"Method": "ImageBorder_F32 borderDerivative_F32(){\r\n    return new ImageBorder1D_F32((Class) BorderIndex1D_Extend.class);\r\n}"
}, {
	"Path": "boofcv.alg.transform.wavelet.CommonFactoryWavelet.checkEncodeDecode_F32",
	"Comment": "see if the provided wavelets can be used to transform the image and change it back without error",
	"Method": "void checkEncodeDecode_F32(WaveletDescription<WlCoef_F32> waveletDesc){\r\n    for (int makeOdd = 0; makeOdd <= 1; makeOdd++) {\r\n        GrayF32 orig = new GrayF32(width - makeOdd, height - makeOdd);\r\n        GrayF32 tran = new GrayF32(width, height);\r\n        GrayF32 rev = new GrayF32(width - makeOdd, height - makeOdd);\r\n        ImageMiscOps.fillUniform(orig, rand, 0, 50);\r\n        BorderIndex1D border = waveletDesc.getBorder();\r\n        ImplWaveletTransformNaive.horizontal(border, waveletDesc.forward, orig, tran);\r\n        ImplWaveletTransformNaive.horizontalInverse(border, waveletDesc.inverse, tran, rev);\r\n        BoofTesting.assertEquals(orig, rev, 1e-4f);\r\n        ImplWaveletTransformNaive.vertical(border, waveletDesc.forward, orig, tran);\r\n        ImplWaveletTransformNaive.verticalInverse(border, waveletDesc.inverse, tran, rev);\r\n        BoofTesting.assertEquals(orig, rev, 1e-4f);\r\n        WaveletTransformOps.transform1(waveletDesc, orig, tran, null);\r\n        WaveletTransformOps.inverse1(waveletDesc, tran, rev, null, 0, 255);\r\n        BoofTesting.assertEquals(orig, rev, 1e-4f);\r\n    }\r\n}"
}, {
	"Path": "org.boon.sort.Ordering.searchForIndex",
	"Comment": "does a binary searchnote this will not sort the list ascending.",
	"Method": "int searchForIndex(List<?> list,Object item){\r\n    if (list.size() > 1) {\r\n        Object o = list;\r\n        return Collections.binarySearch((List<? extends Comparable<? super Object>>) o, item);\r\n    } else {\r\n        return -1;\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedF64.getBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "double getBand(int x,int y,int band){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    return data[getIndex(x, y, band)];\r\n}"
}, {
	"Path": "boofcv.factory.fiducial.ConfigQrCode.fast",
	"Comment": "default configuration for a qr code detector which is optimized for speed",
	"Method": "ConfigQrCode fast(){\r\n    ConfigQrCode config = new ConfigQrCode();\r\n    config.threshold = ConfigThreshold.global(ThresholdType.GLOBAL_OTSU);\r\n    return config;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.edge.SnapToLineEdge.computePointsAndWeights",
	"Comment": "computes the location of points along the line and their weights",
	"Method": "void computePointsAndWeights(double slopeX,double slopeY,double x0,double y0,double tanX,double tanY){\r\n    samplePts.reset();\r\n    weights.reset();\r\n    int numSamples = radialSamples * 2 + 2;\r\n    int numPts = numSamples - 1;\r\n    double widthX = numSamples * tanX;\r\n    double widthY = numSamples * tanY;\r\n    for (int i = 0; i < lineSamples; i++) {\r\n        double frac = i / (double) (lineSamples - 1);\r\n        double x = x0 + slopeX * frac - widthX / 2.0;\r\n        double y = y0 + slopeY * frac - widthY / 2.0;\r\n        if (!integral.isInside(x, y) || !integral.isInside(x + widthX, y + widthY))\r\n            continue;\r\n        double sample0 = integral.compute(x, y, x + tanX, y + tanY);\r\n        x += tanX;\r\n        y += tanY;\r\n        for (int j = 0; j < numPts; j++) {\r\n            double sample1 = integral.compute(x, y, x + tanX, y + tanY);\r\n            double w = sample0 - sample1;\r\n            if (w < 0)\r\n                w = -w;\r\n            if (w > 0) {\r\n                weights.add(w);\r\n                samplePts.grow().set((x - center.x) / localScale, (y - center.y) / localScale);\r\n            }\r\n            x += tanX;\r\n            y += tanY;\r\n            sample0 = sample1;\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.LocalWeightedHistogramRotRect.isInFastBounds",
	"Comment": "checks to see if the region can be sampled using the fast algorithm",
	"Method": "boolean isInFastBounds(RectangleRotate_F32 region){\r\n    squareToImageSample(-0.5f, -0.5f, region);\r\n    if (!interpolate.isInFastBounds(imageX, imageY))\r\n        return false;\r\n    squareToImageSample(-0.5f, 0.5f, region);\r\n    if (!interpolate.isInFastBounds(imageX, imageY))\r\n        return false;\r\n    squareToImageSample(0.5f, 0.5f, region);\r\n    if (!interpolate.isInFastBounds(imageX, imageY))\r\n        return false;\r\n    squareToImageSample(0.5f, -0.5f, region);\r\n    if (!interpolate.isInFastBounds(imageX, imageY))\r\n        return false;\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.examples.geometry.ExampleImageStitching.describeImage",
	"Comment": "detects features inside the two images and computes descriptions at those points.",
	"Method": "void describeImage(T image,DetectDescribePoint<T, FD> detDesc,List<Point2D_F64> points,FastQueue<FD> listDescs){\r\n    detDesc.detect(image);\r\n    listDescs.reset();\r\n    for (int i = 0; i < detDesc.getNumberOfFeatures(); i++) {\r\n        points.add(detDesc.getLocation(i).copy());\r\n        listDescs.grow().setTo(detDesc.getDescription(i));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.cloud.PointCloudUtils.statistics",
	"Comment": "computes the mean and standard deviation of each axis in the point cloud computed in dependently",
	"Method": "void statistics(List<Point3D_F64> cloud,Point3D_F64 mean,Point3D_F64 stdev){\r\n    final int N = cloud.size();\r\n    for (int i = 0; i < N; i++) {\r\n        Point3D_F64 p = cloud.get(i);\r\n        mean.x += p.x / N;\r\n        mean.y += p.y / N;\r\n        mean.z += p.z / N;\r\n    }\r\n    for (int i = 0; i < N; i++) {\r\n        Point3D_F64 p = cloud.get(i);\r\n        double dx = p.x - mean.x;\r\n        double dy = p.y - mean.y;\r\n        double dz = p.z - mean.z;\r\n        stdev.x += dx * dx / N;\r\n        stdev.y += dy * dy / N;\r\n        stdev.z += dz * dz / N;\r\n    }\r\n    stdev.x = Math.sqrt(stdev.x);\r\n    stdev.y = Math.sqrt(stdev.y);\r\n    stdev.z = Math.sqrt(stdev.z);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.QuadPoseEstimator.estimateP3P",
	"Comment": "estimates the pose using p3p from 3 out of 4 points.then use all 4 to pick the best solution",
	"Method": "void estimateP3P(int excluded){\r\n    inputP3P.clear();\r\n    for (int i = 0; i < 4; i++) {\r\n        if (i != excluded) {\r\n            inputP3P.add(points.get(i));\r\n        }\r\n    }\r\n    solutions.reset();\r\n    if (!p3p.process(inputP3P, solutions)) {\r\n        return;\r\n    }\r\n    for (int i = 0; i < solutions.size; i++) {\r\n        double error = computeErrors(solutions.get(i));\r\n        if (error < bestError) {\r\n            bestError = error;\r\n            bestPose.set(solutions.get(i));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestUtils.mockLogger",
	"Comment": "creates a mock logger, sets it in the specified class, and returns it for configuration.",
	"Method": "Logger mockLogger(Class<?> loggingClass){\r\n    Logger mockLogger = createNiceMock(Logger.class);\r\n    Field field = loggingClass.getDeclaredField(\"logger\");\r\n    setFinalStatic(field, mockLogger);\r\n    return mockLogger;\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.brief.FactoryBriefDefinition.randomGaussian",
	"Comment": "randomly selects a point which is inside a square region using a gaussian distribution.",
	"Method": "void randomGaussian(Random rand,double sigma,int radius,Point2D_I32 pt){\r\n    int x, y;\r\n    while (true) {\r\n        x = (int) (rand.nextGaussian() * sigma);\r\n        y = (int) (rand.nextGaussian() * sigma);\r\n        if (Math.sqrt(x * x + y * y) < radius)\r\n            break;\r\n    }\r\n    pt.set(x, y);\r\n}"
}, {
	"Path": "boofcv.alg.filter.derivative.impl.TestGradientSobel_UnrolledOuter.process_I8_naive",
	"Comment": "see if the same results are returned by imagebyte2d equivalent",
	"Method": "void process_I8_naive(){\r\n    for (int offY = 0; offY < 3; offY++) {\r\n        for (int offX = 0; offX < 3; offX++) {\r\n            int w = width + offX;\r\n            int h = height + offY;\r\n            GrayU8 img = new GrayU8(w, h);\r\n            ImageMiscOps.fillUniform(img, new Random(0xfeed), 0, 100);\r\n            GrayS16 derivX = new GrayS16(w, h);\r\n            GrayS16 derivY = new GrayS16(w, h);\r\n            GrayS16 derivX2 = new GrayS16(w, h);\r\n            GrayS16 derivY2 = new GrayS16(w, h);\r\n            GradientSobel_Naive.process(img, derivX2, derivY2);\r\n            GradientSobel_UnrolledOuter.process_I8(img, derivX, derivY);\r\n            BoofTesting.assertEquals(derivX2, derivX, 0);\r\n            BoofTesting.assertEquals(derivY2, derivY, 0);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.normalized.TestConvolveNormalizedNaive_SB.horizontal",
	"Comment": "check it against one specific type to see if the core algorithm is correct",
	"Method": "void horizontal(int horizontal,int x,int y,Kernel1D_S32 kernel,GrayU8 image){\r\n    int total = 0;\r\n    int weight = 0;\r\n    for (int i = 0; i < kernel.width; i++) {\r\n        if (image.isInBounds(x + i - kernel.offset, y)) {\r\n            int w = kernel.get(i);\r\n            int v = image.get(x + i - kernel.offset, y);\r\n            total += w * v;\r\n            weight += w;\r\n        }\r\n    }\r\n    return (total + weight / 2) / weight;\r\n}"
}, {
	"Path": "org.boofcv.video.MainActivity.requestCameraPermission",
	"Comment": "newer versions of android require explicit permission from the user",
	"Method": "void requestCameraPermission(){\r\n    int permissionCheck = ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA);\r\n    if (permissionCheck != android.content.pm.PackageManager.PERMISSION_GRANTED) {\r\n        ActivityCompat.requestPermissions(this, new String[] { Manifest.permission.CAMERA }, 0);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.sfm.overhead.CreateSyntheticOverheadView.getOverheadToPixel",
	"Comment": "returns corresponding pixel to pixel coordinate in overhead image",
	"Method": "Point2D_F32 getOverheadToPixel(int x,int y){\r\n    return mapPixels[y * overheadWidth + x];\r\n}"
}, {
	"Path": "org.bimserver.tests.GuidCompressor.uncompressGuidString",
	"Comment": "converts a compressed string representation of a guid into an uncompressed one",
	"Method": "String uncompressGuidString(String compressedString){\r\n    Guid guid = new Guid();\r\n    getGuidFromCompressedString(compressedString, guid);\r\n    return getUncompressedStringFromGuid(guid);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.edge.EdgeIntensityPolygon.computeEdge",
	"Comment": "checks to see if its a valid polygon or a false positive by looking at edge intensity",
	"Method": "boolean computeEdge(Polygon2D_F64 polygon,boolean ccw){\r\n    averageInside = 0;\r\n    averageOutside = 0;\r\n    double tangentSign = ccw ? 1 : -1;\r\n    int totalSides = 0;\r\n    for (int i = polygon.size() - 1, j = 0; j < polygon.size(); i = j, j++) {\r\n        Point2D_F64 a = polygon.get(i);\r\n        Point2D_F64 b = polygon.get(j);\r\n        double dx = b.x - a.x;\r\n        double dy = b.y - a.y;\r\n        double t = Math.sqrt(dx * dx + dy * dy);\r\n        dx /= t;\r\n        dy /= t;\r\n        if (t < 3 * cornerOffset) {\r\n            offsetA.set(a);\r\n            offsetB.set(b);\r\n        } else {\r\n            offsetA.x = a.x + cornerOffset * dx;\r\n            offsetA.y = a.y + cornerOffset * dy;\r\n            offsetB.x = b.x - cornerOffset * dx;\r\n            offsetB.y = b.y - cornerOffset * dy;\r\n        }\r\n        double tanX = -dy * tangentDistance * tangentSign;\r\n        double tanY = dx * tangentDistance * tangentSign;\r\n        scorer.computeAverageDerivative(offsetA, offsetB, tanX, tanY);\r\n        if (scorer.getSamplesInside() > 0) {\r\n            totalSides++;\r\n            averageInside += scorer.getAverageUp() / tangentDistance;\r\n            averageOutside += scorer.getAverageDown() / tangentDistance;\r\n        }\r\n    }\r\n    if (totalSides > 0) {\r\n        averageInside /= totalSides;\r\n        averageOutside /= totalSides;\r\n    } else {\r\n        averageInside = averageOutside = 0;\r\n        return false;\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.app.calib.AssistedCalibration.checkMagnetCapturePicture",
	"Comment": "checks to see if its near one of the magnets in the image broder",
	"Method": "boolean checkMagnetCapturePicture(){\r\n    boolean captured = false;\r\n    Iterator<Magnet> iter = magnets.iterator();\r\n    while (iter.hasNext()) {\r\n        Magnet i = iter.next();\r\n        if (i.handlePictureTaken()) {\r\n            iter.remove();\r\n            captured = true;\r\n        }\r\n    }\r\n    return captured;\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.SquareImage_to_FiducialDetector.addPatternImage",
	"Comment": "add a new pattern to be detected.this function takes in a raw gray scale image and thresholds it.",
	"Method": "void addPatternImage(T pattern,double threshold,double lengthSide){\r\n    GrayU8 binary = new GrayU8(pattern.width, pattern.height);\r\n    GThresholdImageOps.threshold(pattern, binary, threshold, false);\r\n    alg.addPattern(binary, lengthSide);\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.DescribePointBrief.createFeature",
	"Comment": "function which creates a description of the appropriate size.",
	"Method": "TupleDesc_B createFeature(){\r\n    return new TupleDesc_B(describe.getDefinition().getLength());\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.BinaryImageOps.selectRandomColors",
	"Comment": "several blob rending functions take in an array of colors so that the random blobs can be drawn\twith the same color each time.this function selects a random color for each blob and returns it\tin an array.",
	"Method": "int[] selectRandomColors(int numBlobs,Random rand){\r\n    int[] colors = new int[numBlobs + 1];\r\n    colors[0] = 0;\r\n    int B = 100;\r\n    for (int i = 1; i < colors.length; i++) {\r\n        int c;\r\n        while (true) {\r\n            c = rand.nextInt(0xFFFFFF);\r\n            if ((c & 0xFF) > B || ((c >> 8) & 0xFF) > B || ((c >> 8) & 0xFF) > B) {\r\n                break;\r\n            }\r\n        }\r\n        colors[i] = c;\r\n    }\r\n    return colors;\r\n}"
}, {
	"Path": "org.boon.collections.IntList.reduceBy",
	"Comment": "this would be a good opportunity to reintroduce dynamic invoke",
	"Method": "long reduceBy(Object function,long reduceBy,Object function,String name,long reduceBy,Int.ReduceBy reduceBy){\r\n    return Int.reduceBy(values, end, reduceBy);\r\n}"
}, {
	"Path": "boofcv.abst.feature.tracker.DetectDescribeAssociate.getUnused",
	"Comment": "returns an unused track.if there are no unused tracks then it creates a ne one.",
	"Method": "PointTrack getUnused(){\r\n    PointTrack p;\r\n    if (unused.size() > 0) {\r\n        p = unused.remove(unused.size() - 1);\r\n    } else {\r\n        p = new PointTrack();\r\n        p.setDescription(manager.createDescription());\r\n    }\r\n    return p;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCPConfig.setAcquireRetryAttempts",
	"Comment": "after attempting to acquire a connection and failing, try to connect these many times before giving up. default 5.",
	"Method": "void setAcquireRetryAttempts(int acquireRetryAttempts){\r\n    this.acquireRetryAttempts = acquireRetryAttempts;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.TestStitchingFromMotion2D.checkInitialTransform",
	"Comment": "checks to see if the user specified initial transformation is correctly applied",
	"Method": "void checkInitialTransform(){\r\n    HelperMotion motion = new HelperMotion();\r\n    HelperDistort distort = new HelperDistort();\r\n    StitchingTransform trans = FactoryStitchingTransform.createAffine_F64();\r\n    StitchingFromMotion2D<GrayF32, Affine2D_F64> alg = new StitchingFromMotion2D(motion, distort, trans, 0.3);\r\n    alg.configure(200, 300, motion0);\r\n    assertTrue(alg.process(image));\r\n    Affine2D_F64 expected = motion0.concat(translation, null);\r\n    Affine2D_F64 found = alg.getWorldToCurr();\r\n    assertEquals(expected.a11, found.a11, 1e-5);\r\n    assertEquals(expected.tx, found.tx, 1e-5);\r\n    assertEquals(expected.ty, found.ty, 1e-5);\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.ui.SmartScroller.checkScrollBar",
	"Comment": "analyze every adjustment event to determine when the viewport needs to be repositioned.",
	"Method": "void checkScrollBar(AdjustmentEvent e){\r\n    JScrollBar scrollBar = (JScrollBar) e.getSource();\r\n    BoundedRangeModel listModel = scrollBar.getModel();\r\n    int value = listModel.getValue();\r\n    int extent = listModel.getExtent();\r\n    int maximum = listModel.getMaximum();\r\n    boolean valueChanged = previousValue != value;\r\n    boolean maximumChanged = previousMaximum != maximum;\r\n    if (valueChanged && !maximumChanged) {\r\n        if (viewportPosition == START)\r\n            adjustScrollBar = value != 0;\r\n        else\r\n            adjustScrollBar = value + extent >= maximum;\r\n    }\r\n    if (adjustScrollBar && viewportPosition == END) {\r\n        scrollBar.removeAdjustmentListener(this);\r\n        value = maximum - extent;\r\n        scrollBar.setValue(value);\r\n        scrollBar.addAdjustmentListener(this);\r\n    }\r\n    if (adjustScrollBar && viewportPosition == START) {\r\n        scrollBar.removeAdjustmentListener(this);\r\n        value = value + maximum - previousMaximum;\r\n        scrollBar.setValue(value);\r\n        scrollBar.addAdjustmentListener(this);\r\n    }\r\n    previousValue = value;\r\n    previousMaximum = maximum;\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.RegionMergeTree.performMerge",
	"Comment": "merges regions together and updates the provided data structures for said changes.",
	"Method": "void performMerge(GrayS32 pixelToRegion,GrowQueue_I32 regionMemberCount){\r\n    flowIntoRootNode(regionMemberCount);\r\n    setToRootNodeNewID(regionMemberCount);\r\n    BinaryImageOps.relabel(pixelToRegion, mergeList.data);\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.ImplDisparityScoreSadRect_U8.computeFirstRow",
	"Comment": "initializes disparity calculation by finding the scores for the initial block of horizontal\trows.",
	"Method": "void computeFirstRow(GrayU8 left,GrayU8 right){\r\n    for (int row = 0; row < regionHeight; row++) {\r\n        int[] scores = horizontalScore[row];\r\n        UtilDisparityScore.computeScoreRow(left, right, row, scores, minDisparity, maxDisparity, regionWidth, elementScore);\r\n    }\r\n    for (int i = 0; i < lengthHorizontal; i++) {\r\n        int sum = 0;\r\n        for (int row = 0; row < regionHeight; row++) {\r\n            sum += horizontalScore[row][i];\r\n        }\r\n        verticalScore[i] = sum;\r\n    }\r\n    computeDisparity.process(radiusY, verticalScore);\r\n}"
}, {
	"Path": "com.bugsnag.android.DeviceData.getScreenResolution",
	"Comment": "the screen resolution of the current android device in px, eg. 1920x1080",
	"Method": "String getScreenResolution(){\r\n    if (displayMetrics != null) {\r\n        int max = Math.max(displayMetrics.widthPixels, displayMetrics.heightPixels);\r\n        int min = Math.min(displayMetrics.widthPixels, displayMetrics.heightPixels);\r\n        return String.format(Locale.US, \"%dx%d\", max, min);\r\n    } else {\r\n        return null;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.HoughTransformLineFootOfNorm.parameterize",
	"Comment": "takes the detected point along the line and its gradient and converts it into transform space.",
	"Method": "void parameterize(int x,int y,float derivX,float derivY){\r\n    x -= originX;\r\n    y -= originY;\r\n    float v = (x * derivX + y * derivY) / (derivX * derivX + derivY * derivY);\r\n    int x0 = (int) (v * derivX) + originX;\r\n    int y0 = (int) (v * derivY) + originY;\r\n    if (transform.isInBounds(x0, y0)) {\r\n        int index = transform.startIndex + y0 * transform.stride + x0;\r\n        if (transform.data[index]++ == 1)\r\n            candidates.add(x0, y0);\r\n    }\r\n}"
}, {
	"Path": "org.boon.validation.validators.AbstractCompareValidator.lookupCompareToPropertyValue",
	"Comment": "this method looks of the validationcontext to get thecomparetoproperty.",
	"Method": "Object lookupCompareToPropertyValue(){\r\n    return ValidationContext.getCurrentInstance().getProposedPropertyValue(compareToProperty);\r\n}"
}, {
	"Path": "boofcv.abst.geo.pose.CheckEstimateNofPnP.checkMinimumPoints",
	"Comment": "sanity check to see if the minimum number of observations has been set.",
	"Method": "void checkMinimumPoints(){\r\n    assertTrue(alg.getMinimumPoints() != 0);\r\n}"
}, {
	"Path": "boofcv.gui.SelectAlgorithmPanel.refreshAlgorithm",
	"Comment": "tells it to switch again to the current algorithm.useful if the input has changed and information\tneeds to be rendered again.",
	"Method": "void refreshAlgorithm(){\r\n    Object cookie = algCookies.get(algBox.getSelectedIndex());\r\n    String name = (String) algBox.getSelectedItem();\r\n    performSetAlgorithm(name, cookie);\r\n}"
}, {
	"Path": "boofcv.abst.filter.TestFilterSequence.compareToManualSequence",
	"Comment": "perform a sequence of convolutions manually.should produce the same results",
	"Method": "void compareToManualSequence(){\r\n    Kernel1D_F32 ker1 = FactoryKernel.random1D_F32(kernelWidth, radius, 0, 5, rand);\r\n    Kernel1D_F32 ker2 = FactoryKernel.random1D_F32(kernelWidth + 2, radius + 1, 0, 5, rand);\r\n    Kernel1D_F32 ker3 = FactoryKernel.random1D_F32(kernelWidth + 4, radius + 2, 0, 5, rand);\r\n    GrayF32 input = new GrayF32(width, height);\r\n    ImageMiscOps.fillUniform(input, rand, 0, 10);\r\n    GrayF32 found = new GrayF32(width, height);\r\n    GrayF32 expected = new GrayF32(width, height);\r\n    ImageType<GrayF32> imageType = ImageType.single(GrayF32.class);\r\n    FilterImageInterface f1 = FactoryConvolve.convolve(ker1, imageType, imageType, BorderType.SKIP, true);\r\n    FilterImageInterface f2 = FactoryConvolve.convolve(ker2, imageType, imageType, BorderType.SKIP, true);\r\n    FilterImageInterface f3 = FactoryConvolve.convolve(ker3, imageType, imageType, BorderType.SKIP, true);\r\n    FilterSequence sequence = new FilterSequence(f1, f2, f3);\r\n    sequence.process(input, found);\r\n    assertEquals(radius + 2, sequence.borderHorizontal);\r\n    assertEquals(radius + 2, sequence.borderVertical);\r\n    GrayF32 tmp1 = new GrayF32(width, height);\r\n    GrayF32 tmp2 = new GrayF32(width, height);\r\n    ConvolveImageNoBorder.horizontal(ker1, input, tmp1);\r\n    ConvolveImageNoBorder.horizontal(ker2, tmp1, tmp2);\r\n    ConvolveImageNoBorder.horizontal(ker3, tmp2, expected);\r\n    BoofTesting.assertEquals(expected, found, 1e-4f);\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.TestEpipolarMinimizeGeometricError.noisy",
	"Comment": "checks the solution given noisy pixel inputs. it should produce a solution which lies on the epipolar\tline perfectly and is close to the input",
	"Method": "void noisy(){\r\n    init(50, true);\r\n    DMatrixRMaj E = MultiViewOps.createEssential(a_to_b.R, a_to_b.T, null);\r\n    DMatrixRMaj F = MultiViewOps.createFundamental(E, intrinsic);\r\n    EpipolarMinimizeGeometricError alg = new EpipolarMinimizeGeometricError();\r\n    Point2D_F64 fa = new Point2D_F64();\r\n    Point2D_F64 fb = new Point2D_F64();\r\n    for (int i = 0; i < pairs.size(); i++) {\r\n        AssociatedPair p = pairs.get(i);\r\n        p.p1.x += rand.nextGaussian() * 0.5;\r\n        p.p1.x += rand.nextGaussian() * 0.5;\r\n        p.p2.y += rand.nextGaussian() * 0.5;\r\n        p.p2.y += rand.nextGaussian() * 0.5;\r\n        assertTrue(alg.process(F, p.p1.x, p.p1.y, p.p2.x, p.p2.y, fa, fb));\r\n        assertEquals(0, MultiViewOps.constraint(F, fa, fb), UtilEjml.TEST_F64);\r\n        assertEquals(0, p.p1.distance(fa), 2);\r\n        assertEquals(0, p.p2.distance(fb), 2);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.misc.HistogramStatistics.variance",
	"Comment": "computes the variance of pixel intensity values for a grayu8 image represented by the given histogram.",
	"Method": "double variance(int[] histogram,double mean,int N,double variance,int[] histogram,double mean,int counts,int N){\r\n    double sum = 0.0;\r\n    for (int i = 0; i < N; i++) {\r\n        double d = i - mean;\r\n        sum += (d * d) * histogram[i];\r\n    }\r\n    return sum / counts;\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.FitLinesToContour.linesIntoCorners",
	"Comment": "finds the intersection of a line and update the corner index",
	"Method": "boolean linesIntoCorners(int numLines,GrowQueue_I32 contourCorners){\r\n    skippedCorners.reset();\r\n    int contourIndexPrevious = contourCorners.get(anchor0);\r\n    for (int i = 1; i < numLines; i++) {\r\n        LineGeneral2D_F64 line0 = lines.get(i - 1);\r\n        LineGeneral2D_F64 line1 = lines.get(i);\r\n        int cornerIndex = CircularIndex.addOffset(anchor0, i, contourCorners.size);\r\n        boolean skipped = false;\r\n        if (null == Intersection2D_F64.intersection(line0, line1, intersection)) {\r\n            if (verbose)\r\n                System.out.println(\"  SKIPPING no intersection\");\r\n            skipped = true;\r\n        } else {\r\n            int contourIndex = closestPoint(intersection);\r\n            if (contourIndex != contourIndexPrevious) {\r\n                Point2D_I32 a = contour.get(contourIndexPrevious);\r\n                Point2D_I32 b = contour.get(contourIndex);\r\n                if (a.x == b.x && a.y == b.y) {\r\n                    if (verbose)\r\n                        System.out.println(\"  SKIPPING duplicate coordinate\");\r\n                    skipped = true;\r\n                } else {\r\n                    contourCorners.set(cornerIndex, contourIndex);\r\n                    contourIndexPrevious = contourIndex;\r\n                }\r\n            } else {\r\n                if (verbose)\r\n                    System.out.println(\"  SKIPPING duplicate corner index\");\r\n                skipped = true;\r\n            }\r\n        }\r\n        if (skipped) {\r\n            skippedCorners.add(cornerIndex);\r\n        }\r\n    }\r\n    int cornerIndex = CircularIndex.addOffset(anchor0, numLines, contourCorners.size);\r\n    Point2D_I32 a = contour.get(contourIndexPrevious);\r\n    Point2D_I32 b = contour.get(contourCorners.get(cornerIndex));\r\n    if (a.x == b.x && a.y == b.y) {\r\n        skippedCorners.add(cornerIndex);\r\n    }\r\n    Arrays.sort(skippedCorners.data, 0, skippedCorners.size);\r\n    for (int i = skippedCorners.size - 1; i >= 0; i--) {\r\n        int index = skippedCorners.get(i);\r\n        contourCorners.remove(index);\r\n        if (anchor0 >= index) {\r\n            anchor0--;\r\n        }\r\n        if (anchor1 >= index) {\r\n            anchor1--;\r\n        }\r\n    }\r\n    numLines -= skippedCorners.size;\r\n    for (int i = 0; i < numLines; i++) {\r\n        int c0 = CircularIndex.addOffset(anchor0, i, contourCorners.size);\r\n        int c1 = CircularIndex.addOffset(anchor0, i + 1, contourCorners.size);\r\n        a = contour.get(contourCorners.get(c0));\r\n        b = contour.get(contourCorners.get(c1));\r\n        if (a.x == b.x && a.y == b.y) {\r\n            throw new RuntimeException(\"Well I screwed up\");\r\n        }\r\n    }\r\n    return contourCorners.size() >= 3;\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernel.random2D_F32",
	"Comment": "creates a random 2d kernel drawn from a uniform distribution.",
	"Method": "Kernel2D_F32 random2D_F32(int width,int offset,float min,float max,Random rand){\r\n    Kernel2D_F32 ret = new Kernel2D_F32(width, offset);\r\n    float range = max - min;\r\n    for (int i = 0; i < ret.data.length; i++) {\r\n        ret.data[i] = rand.nextFloat() * range + min;\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.examples.enhance.ExampleImageEnhancement.sharpen",
	"Comment": "when an image is sharpened the intensity of edges are made more extreme while flat regions remain unchanged.",
	"Method": "void sharpen(){\r\n    BufferedImage buffered = UtilImageIO.loadImage(UtilIO.pathExample(imagePath));\r\n    GrayU8 gray = ConvertBufferedImage.convertFrom(buffered, (GrayU8) null);\r\n    GrayU8 adjusted = gray.createSameShape();\r\n    ListDisplayPanel panel = new ListDisplayPanel();\r\n    EnhanceImageOps.sharpen4(gray, adjusted);\r\n    panel.addImage(ConvertBufferedImage.convertTo(adjusted, null), \"Sharpen-4\");\r\n    EnhanceImageOps.sharpen8(gray, adjusted);\r\n    panel.addImage(ConvertBufferedImage.convertTo(adjusted, null), \"Sharpen-8\");\r\n    panel.addImage(ConvertBufferedImage.convertTo(gray, null), \"Original\");\r\n    panel.setPreferredSize(new Dimension(gray.width, gray.height));\r\n    mainPanel.addItem(panel, \"Sharpen\");\r\n}"
}, {
	"Path": "com.jolbox.bonecp.BoneCP.internalReleaseConnection",
	"Comment": "release a connection by placing the connection back in the pool.",
	"Method": "void internalReleaseConnection(ConnectionHandle connectionHandle){\r\n    if (!this.cachedPoolStrategy) {\r\n        connectionHandle.clearStatementCaches(false);\r\n    }\r\n    if (connectionHandle.getReplayLog() != null) {\r\n        connectionHandle.getReplayLog().clear();\r\n        connectionHandle.recoveryResult.getReplaceTarget().clear();\r\n    }\r\n    if (connectionHandle.isExpired() || (!this.poolShuttingDown && connectionHandle.isPossiblyBroken() && !isConnectionHandleAlive(connectionHandle))) {\r\n        if (connectionHandle.isExpired()) {\r\n            connectionHandle.internalClose();\r\n        }\r\n        ConnectionPartition connectionPartition = connectionHandle.getOriginatingPartition();\r\n        postDestroyConnection(connectionHandle);\r\n        maybeSignalForMoreConnections(connectionPartition);\r\n        connectionHandle.clearStatementCaches(true);\r\n        return;\r\n    }\r\n    connectionHandle.setConnectionLastUsedInMs(System.currentTimeMillis());\r\n    if (!this.poolShuttingDown) {\r\n        putConnectionBackInPartition(connectionHandle);\r\n    } else {\r\n        connectionHandle.internalClose();\r\n    }\r\n}"
}, {
	"Path": "test.me.corriekay.pokegoutil.gui.controller.LogControllerTest.linesIsAddedToTextArea",
	"Comment": "test for number of test lines matches number of lines in text area.",
	"Method": "void linesIsAddedToTextArea(){\r\n    printLines();\r\n    final int expectedLength = numOfLines;\r\n    final String[] textareaLines = getLines();\r\n    assertThat(textAreaHas(expectedLength), textareaLines.length, is(expectedLength));\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.fh04.SegmentFelzenszwalbHuttenlocher04.computeOutput",
	"Comment": "searches for root nodes in the graph and adds their size to the list of region sizes.makes sure all\tother nodes in the graph point directly at their root.",
	"Method": "void computeOutput(){\r\n    outputRegionId.reset();\r\n    outputRegionSizes.reset();\r\n    for (int y = 0; y < graph.height; y++) {\r\n        int indexGraph = graph.startIndex + y * graph.stride;\r\n        for (int x = 0; x < graph.width; x++, indexGraph++) {\r\n            int parent = graph.data[indexGraph];\r\n            if (parent == indexGraph) {\r\n                outputRegionId.add(indexGraph);\r\n                outputRegionSizes.add(regionSize.get(indexGraph));\r\n            } else {\r\n                int child = indexGraph;\r\n                while (parent != child) {\r\n                    child = parent;\r\n                    parent = graph.data[child];\r\n                }\r\n                graph.data[indexGraph] = parent;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.EllipseClustersIntoGrid.selectSeedCorner",
	"Comment": "pick the node in the contour with the largest angle. distortion tends to make the acute angle smaller.\twithout distortion it will be 270 degrees.",
	"Method": "NodeInfo selectSeedCorner(){\r\n    NodeInfo best = null;\r\n    double bestAngle = 0;\r\n    for (int i = 0; i < contour.size; i++) {\r\n        NodeInfo info = contour.get(i);\r\n        if (info.angleBetween > bestAngle) {\r\n            bestAngle = info.angleBetween;\r\n            best = info;\r\n        }\r\n    }\r\n    best.marked = true;\r\n    return best;\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.impl.TestImplSurfDescribeOps.naiveGradient",
	"Comment": "create an image which has a constant slope.see if\tthe wavelet correctly computes that slope.",
	"Method": "void naiveGradient(){\r\n    double scale = 1;\r\n    int r = 6;\r\n    checkNaiveGradient(scale, r);\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.TestSelectSparseStandardSubpixel_S32.addSubpixelBias",
	"Comment": "given different local error values see if it is closer to the value with a smaller error",
	"Method": "void addSubpixelBias(){\r\n    SelectSparseStandardSubpixel.S32 alg = new SelectSparseStandardSubpixel.S32(-1, -1);\r\n    int[] scores = new int[30];\r\n    Arrays.fill(scores, 0, 10, 500);\r\n    scores[4] = 100;\r\n    scores[5] = 50;\r\n    scores[6] = 200;\r\n    assertTrue(alg.select(scores, 10));\r\n    double found = alg.getDisparity();\r\n    assertTrue(found < 5 && found > 4);\r\n    scores[4] = 200;\r\n    scores[6] = 100;\r\n    assertTrue(alg.select(scores, 10));\r\n    found = alg.getDisparity();\r\n    assertTrue(found < 6 && found > 5);\r\n}"
}, {
	"Path": "org.boon.Boon.respondsTo",
	"Comment": "checks to see if an object responds to a method.helper facade over reflection library.",
	"Method": "boolean respondsTo(Object object,String method){\r\n    if (object instanceof Class) {\r\n        return Reflection.respondsTo((Class) object, method);\r\n    } else {\r\n        return Reflection.respondsTo(object, method);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.TestConnectLinesGrid.checkAngleTolerance",
	"Comment": "makes sure the angle tolerance parameter is correctly set and processed",
	"Method": "void checkAngleTolerance(){\r\n    MatrixOfList<LineSegment2D_F32> grid = new MatrixOfList(1, 1);\r\n    grid.get(0, 0).add(new LineSegment2D_F32(0, 0, 2, 0));\r\n    grid.get(0, 0).add(new LineSegment2D_F32(2, 0, 4, 4));\r\n    ConnectLinesGrid app = new ConnectLinesGrid(0.1, 1, 1);\r\n    app.process(grid);\r\n    assertEquals(2, grid.createSingleList().size());\r\n    app = new ConnectLinesGrid(Math.PI, 1, 1);\r\n    app.process(grid);\r\n    assertEquals(1, grid.createSingleList().size());\r\n}"
}, {
	"Path": "me.corriekay.pokegoutil.utils.ConfigNew.getBool",
	"Comment": "returns the boolean for given key. the one in the config, or if it does not exist, the given default value.",
	"Method": "boolean getBool(ConfigKey configKey,boolean getBool,ConfigKey configKey,boolean defaultValue){\r\n    try {\r\n        final FindResult res = findNode(configKey.keyName, false);\r\n        return res.getNode().getBoolean(res.getName());\r\n    } catch (final JSONException ignored) {\r\n        setBool(configKey, defaultValue);\r\n        return defaultValue;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.transform.wavelet.TestFactoryWaveletDaub.daubJ_F32_forward",
	"Comment": "sees if the standard daubj wavelets have the expected characteristics",
	"Method": "void daubJ_F32_forward(){\r\n    for (int i = 4; i <= 4; i += 2) {\r\n        WaveletDescription<WlCoef_F32> desc = FactoryWaveletDaub.daubJ_F32(i);\r\n        WlCoef_F32 forwardCoef = desc.forward;\r\n        double sumScaling = UtilWavelet.sumCoefficients(forwardCoef.scaling);\r\n        double sumWavelet = UtilWavelet.sumCoefficients(forwardCoef.wavelet);\r\n        assertEquals(Math.sqrt(2), sumScaling, 1e-4);\r\n        assertEquals(0, sumWavelet, 1e-4);\r\n        double energyScaling = UtilWavelet.computeEnergy(forwardCoef.scaling);\r\n        double energyWavelet = UtilWavelet.computeEnergy(forwardCoef.wavelet);\r\n        assertEquals(1, energyScaling, 1e-4);\r\n        assertEquals(1, energyWavelet, 1e-4);\r\n        int polyOrder = i / 2 - 1;\r\n        checkPolySumToZero(forwardCoef.wavelet, polyOrder, 0);\r\n        checkBiorthogonal_F32(desc);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.triangulate.PixelDepthLinear.depthNView",
	"Comment": "computes the pixel depth from n views of the same object.pixel depth in the first frame.",
	"Method": "double depthNView(List<Point2D_F64> obs,List<Se3_F64> motion){\r\n    double top = 0, bottom = 0;\r\n    Point2D_F64 a = obs.get(0);\r\n    for (int i = 1; i < obs.size(); i++) {\r\n        Se3_F64 se = motion.get(i - 1);\r\n        Point2D_F64 b = obs.get(i);\r\n        GeometryMath_F64.multCrossA(b, se.getR(), temp0);\r\n        GeometryMath_F64.mult(temp0, a, temp1);\r\n        GeometryMath_F64.cross(b, se.getT(), temp2);\r\n        top += temp2.x + temp2.y + temp2.z;\r\n        bottom += temp1.x + temp1.y + temp1.z;\r\n    }\r\n    return -top / bottom;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d2.UtilImageMotion.createPixelTransform",
	"Comment": "given a motion model create a pixeltransform used to distort the image",
	"Method": "PixelTransform2_F32 createPixelTransform(InvertibleTransform transform){\r\n    PixelTransform2_F32 pixelTran;\r\n    if (transform instanceof Homography2D_F64) {\r\n        Homography2D_F32 t = ConvertFloatType.convert((Homography2D_F64) transform, null);\r\n        pixelTran = new PixelTransformHomography_F32(t);\r\n    } else if (transform instanceof Homography2D_F32) {\r\n        pixelTran = new PixelTransformHomography_F32((Homography2D_F32) transform);\r\n    } else if (transform instanceof Affine2D_F64) {\r\n        Affine2D_F32 t = UtilAffine.convert((Affine2D_F64) transform, null);\r\n        pixelTran = new PixelTransformAffine_F32(t);\r\n    } else if (transform instanceof Affine2D_F32) {\r\n        pixelTran = new PixelTransformAffine_F32((Affine2D_F32) transform);\r\n    } else {\r\n        throw new RuntimeException(\"Unknown model type\");\r\n    }\r\n    return pixelTran;\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.MergeSmallRegions.process",
	"Comment": "merges together smaller regions.segmented image, region member count, and region color are all updated.",
	"Method": "void process(T image,GrayS32 pixelToRegion,GrowQueue_I32 regionMemberCount,FastQueue<float[]> regionColor){\r\n    stopRequested = false;\r\n    while (!stopRequested) {\r\n        regionColor.resize(regionMemberCount.size);\r\n        computeColor.process(image, pixelToRegion, regionMemberCount, regionColor);\r\n        initializeMerge(regionMemberCount.size);\r\n        if (!setupPruneList(regionMemberCount))\r\n            break;\r\n        findAdjacentRegions(pixelToRegion);\r\n        for (int i = 0; i < pruneGraph.size; i++) {\r\n            selectMerge(i, regionColor);\r\n        }\r\n        performMerge(pixelToRegion, regionMemberCount);\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.ClientConfigTest.setUp",
	"Comment": "generates a configuration and clears sharedprefs values to begin the test with a clean slate",
	"Method": "void setUp(){\r\n    Context context = InstrumentationRegistry.getContext();\r\n    config = new Configuration(\"api-key\");\r\n    client = new Client(context, config);\r\n}"
}, {
	"Path": "boofcv.alg.distort.universal.TestUniOmniStoP_F32.worldIsImageCenter",
	"Comment": "a point in the world center should appear in the image center",
	"Method": "void worldIsImageCenter(){\r\n    CameraUniversalOmni model = createModel(0.5f);\r\n    UniOmniStoP_F32 alg = new UniOmniStoP_F32();\r\n    alg.setModel(model);\r\n    Point2D_F32 found = new Point2D_F32(10, 10);\r\n    alg.compute(0, 0, 1, found);\r\n    assertEquals(320, found.x, GrlConstants.TEST_F32);\r\n    assertEquals(240, found.y, GrlConstants.TEST_F32);\r\n}"
}, {
	"Path": "org.bimserver.utils.IfcUtils.listProperties",
	"Comment": "lists all properties of a given ifcpopertyset that are of type\tifcpropertysinglevalue, all values are converted to the appropriate java",
	"Method": "Map<String, Object> listProperties(IfcObject ifcObject,String propertySetName){\r\n    Map<String, Object> result = new HashMap();\r\n    for (IfcRelDefines ifcRelDefines : ifcObject.getIsDefinedBy()) {\r\n        if (ifcRelDefines instanceof IfcRelDefinesByProperties) {\r\n            IfcRelDefinesByProperties ifcRelDefinesByProperties = (IfcRelDefinesByProperties) ifcRelDefines;\r\n            IfcPropertySetDefinition propertySetDefinition = ifcRelDefinesByProperties.getRelatingPropertyDefinition();\r\n            if (propertySetDefinition instanceof IfcPropertySet) {\r\n                IfcPropertySet ifcPropertySet = (IfcPropertySet) propertySetDefinition;\r\n                if (ifcPropertySet.getName() != null && ifcPropertySet.getName().equalsIgnoreCase(propertySetName)) {\r\n                    for (IfcProperty ifcProperty : ifcPropertySet.getHasProperties()) {\r\n                        if (ifcProperty instanceof IfcPropertySingleValue) {\r\n                            IfcPropertySingleValue propertyValue = (IfcPropertySingleValue) ifcProperty;\r\n                            result.put(propertyValue.getName(), nominalValueToObject(propertyValue.getNominalValue()));\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return result;\r\n}"
}, {
	"Path": "org.bimserver.tests.GuidCompressor.compressGuidString",
	"Comment": "converts an uncompressed string representation of a guid into a compressed one",
	"Method": "String compressGuidString(String uncompressedString){\r\n    Guid guid = getGuidFromUncompressedString(uncompressedString);\r\n    return getCompressedStringFromGuid(guid);\r\n}"
}, {
	"Path": "boofcv.abst.geo.calibration.CalibrateStereoPlanar.computeRightToLeft",
	"Comment": "creates two 3d point clouds for the left and right camera using the known calibration points and camera\tcalibration.then find the optimal rigid body transform going from the right to left views.",
	"Method": "Se3_F64 computeRightToLeft(){\r\n    List<Point2D_F64> points2D = layout;\r\n    List<Point3D_F64> points3D = new ArrayList();\r\n    for (Point2D_F64 p : points2D) {\r\n        points3D.add(new Point3D_F64(p.x, p.y, 0));\r\n    }\r\n    List<Point3D_F64> left = new ArrayList();\r\n    List<Point3D_F64> right = new ArrayList();\r\n    for (int i = 0; i < viewLeft.size(); i++) {\r\n        Se3_F64 worldToLeft = viewLeft.get(i);\r\n        Se3_F64 worldToRight = viewRight.get(i);\r\n        for (Point3D_F64 p : points3D) {\r\n            Point3D_F64 l = SePointOps_F64.transform(worldToLeft, p, null);\r\n            Point3D_F64 r = SePointOps_F64.transform(worldToRight, p, null);\r\n            left.add(l);\r\n            right.add(r);\r\n        }\r\n    }\r\n    return FitSpecialEuclideanOps_F64.fitPoints3D(right, left);\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.TestDescribePointBriefSO.testManualCheck",
	"Comment": "compute the brief descriptor manually and see if it gets the same answer",
	"Method": "void testManualCheck(){\r\n    GrayF32 input = createImage(width, height);\r\n    GrayF32 blurred = input.createNew(width, height);\r\n    filterBlur.process(input, blurred);\r\n    GImageGray a = FactoryGImageGray.wrap(blurred);\r\n    DescribePointBriefSO<GrayF32> alg = createAlg();\r\n    alg.setImage(input);\r\n    int c_x = input.width / 2;\r\n    int c_y = input.height / 2;\r\n    TupleDesc_B desc = alg.createFeature();\r\n    alg.process(c_x, c_y, 0, briefRadius, desc);\r\n    double s = briefRadius / BoofDefaults.BRIEF_SCALE_TO_RADIUS;\r\n    for (int i = 0; i < def.compare.length; i++) {\r\n        Point2D_I32 c = def.compare[i];\r\n        Point2D_I32 p0 = def.samplePoints[c.x];\r\n        Point2D_I32 p1 = def.samplePoints[c.y];\r\n        boolean expected = a.get((int) Math.round(c_x + p0.x * s), (int) Math.round(c_y + p0.y * s)).doubleValue() < a.get((int) Math.round(c_x + p1.x * s), (int) Math.round(c_y + p1.y * s)).doubleValue();\r\n        assertTrue(expected == desc.isBitTrue(i));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.ellipse.BinaryEllipseDetectorPixel.undistortContour",
	"Comment": "undistort the contour points and convert into a floating point format for the fitting operation",
	"Method": "void undistortContour(List<Point2D_I32> external,FastQueue<Point2D_F64> pointsF){\r\n    for (int j = 0; j < external.size(); j++) {\r\n        Point2D_I32 p = external.get(j);\r\n        if (distToUndist != null) {\r\n            distToUndist.compute(p.x, p.y);\r\n            pointsF.grow().set(distToUndist.distX, distToUndist.distY);\r\n        } else {\r\n            pointsF.grow().set(p.x, p.y);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.TestReidSolomonCodes.findErrorLocatorPolynomialBM_compareToDirect",
	"Comment": "compares the results from bm against an error locator polynomial computed directly given the known\terror locations",
	"Method": "void findErrorLocatorPolynomialBM_compareToDirect(){\r\n    GrowQueue_I8 found = new GrowQueue_I8();\r\n    GrowQueue_I8 expected = new GrowQueue_I8();\r\n    for (int i = 0; i < 30; i++) {\r\n        int N = 50;\r\n        GrowQueue_I8 message = randomMessage(N);\r\n        GrowQueue_I8 ecc = new GrowQueue_I8();\r\n        int nsyn = 10;\r\n        GrowQueue_I8 syndromes = GrowQueue_I8.zeros(nsyn);\r\n        ReidSolomonCodes alg = new ReidSolomonCodes(8, primitive8);\r\n        alg.generator(nsyn);\r\n        alg.computeECC(message, ecc);\r\n        int where = rand.nextInt(N);\r\n        message.data[where] ^= 0x12;\r\n        alg.computeSyndromes(message, ecc, syndromes);\r\n        GrowQueue_I32 whereList = new GrowQueue_I32(1);\r\n        whereList.add(where);\r\n        alg.findErrorLocatorPolynomialBM(syndromes, found);\r\n        alg.findErrorLocatorPolynomial(N + ecc.size, whereList, expected);\r\n        assertEquals(found.size, expected.size);\r\n        for (int j = 0; j < found.size; j++) {\r\n            assertEquals(found.get(j), expected.get(j));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.SelectAlgorithmAndInputPanel.getAlgorithmCookie",
	"Comment": "returns the cookie associated with the specified algorithm family.",
	"Method": "T getAlgorithmCookie(int indexFamily){\r\n    return (T) algCookies[indexFamily].get(algBoxes[indexFamily].getSelectedIndex());\r\n}"
}, {
	"Path": "boofcv.alg.sfm.overhead.CreateSyntheticOverheadViewPL.process",
	"Comment": "computes overhead view of input image.all pixels in input image are assumed to be on the ground plane.",
	"Method": "void process(Planar<T> input,Planar<T> output){\r\n    int N = input.getNumBands();\r\n    for (int i = 0; i < N; i++) {\r\n        this.output[i] = FactoryGImageGray.wrap(output.getBand(i), this.output[i]);\r\n        interp[i].setImage(input.getBand(i));\r\n    }\r\n    int indexMap = 0;\r\n    for (int i = 0; i < output.height; i++) {\r\n        int indexOut = output.startIndex + i * output.stride;\r\n        for (int j = 0; j < output.width; j++, indexOut++, indexMap++) {\r\n            Point2D_F32 p = mapPixels[indexMap];\r\n            if (p != null) {\r\n                for (int k = 0; k < N; k++) {\r\n                    this.output[k].set(indexOut, interp[k].get(p.x, p.y));\r\n                }\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodePositionPatternDetector.getPositionPatterns",
	"Comment": "returns a list of all the detected position pattern squares and the other pp that they are connected to.\tif a lens distortion model is provided then coordinates will be in an undistorted image.",
	"Method": "FastQueue<PositionPatternNode> getPositionPatterns(){\r\n    return positionPatterns;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.line.gridline.TestGridLineModelFitter.checkFailInCompatible",
	"Comment": "if only two points are passed in, they should fail if their orientations\tare more than the specified tolerance apart",
	"Method": "void checkFailInCompatible(){\r\n    GridLineModelFitter alg = new GridLineModelFitter(0.1f);\r\n    List<Edgel> l = new ArrayList();\r\n    l.add(new Edgel(0, 0, (float) Math.PI / 2f));\r\n    l.add(new Edgel(1, 0, (float) -Math.PI / 2f));\r\n    LinePolar2D_F32 model = new LinePolar2D_F32();\r\n    assertTrue(alg.generate(l, model));\r\n    l.clear();\r\n    l.add(new Edgel(0, 0, (float) Math.PI / 2f));\r\n    l.add(new Edgel(1, 0, (float) Math.PI / 2f - 0.5f));\r\n    assertFalse(alg.generate(l, model));\r\n}"
}, {
	"Path": "org.boon.core.reflection.Annotations.extractAllAnnotationsForProperty",
	"Comment": "extract all annotation for a given property.searches current class and if none found searchessuper class for annotation. we do this because the classcould be proxied with aop.",
	"Method": "Annotation[] extractAllAnnotationsForProperty(Class<?> clazz,String propertyName,boolean useRead){\r\n    try {\r\n        Annotation[] annotations = findPropertyAnnotations(clazz, propertyName, useRead);\r\n        if (annotations.length == 0) {\r\n            annotations = findPropertyAnnotations(clazz.getSuperclass(), propertyName, useRead);\r\n        }\r\n        return annotations;\r\n    } catch (Exception ex) {\r\n        return Exceptions.handle(Annotation[].class, sputs(\"Unable to extract annotation for property\", propertyName, \" of class \", clazz, \"  useRead \", useRead), ex);\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.DeliveryCompatTest.setUp",
	"Comment": "generates a delivery instance that increments a counter on each request",
	"Method": "void setUp(){\r\n    customCount = new AtomicInteger();\r\n    deliveryCompat = new DeliveryCompat();\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.PolylineSplitMerge.findCornerSeed",
	"Comment": "the seed corner is the point farther away from the first point. in a perfect polygon with no noise this should\tbe a corner.",
	"Method": "int findCornerSeed(List<Point2D_I32> contour){\r\n    Point2D_I32 a = contour.get(0);\r\n    int best = -1;\r\n    double bestDistance = -Double.MAX_VALUE;\r\n    for (int i = 1; i < contour.size(); i++) {\r\n        Point2D_I32 b = contour.get(i);\r\n        double d = distanceSq(a, b);\r\n        if (d > bestDistance) {\r\n            bestDistance = d;\r\n            best = i;\r\n        }\r\n    }\r\n    return best;\r\n}"
}, {
	"Path": "org.boon.datarepo.impl.RepoBuilderDefault.useFieldForAccess",
	"Comment": "turns on field access instead of property access.field is the default.",
	"Method": "RepoBuilder useFieldForAccess(boolean useField){\r\n    this.useField = useField;\r\n    return this;\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedF64.setBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "void setBand(int x,int y,int band,double value){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    data[getIndex(x, y, band)] = value;\r\n}"
}, {
	"Path": "com.bugsnag.android.SessionTrackerTest.setUp",
	"Comment": "configures a session tracker that automatically captures sessions",
	"Method": "void setUp(){\r\n    configuration = new Configuration(\"test\");\r\n    configuration.setDelivery(BugsnagTestUtils.generateDelivery());\r\n    sessionTracker = new SessionTracker(configuration, generateClient(), generateSessionStore());\r\n    configuration.setAutoCaptureSessions(true);\r\n    user = new User();\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomDualTrackPnP.dropUnusedTracks",
	"Comment": "removes tracks which have not been included in the inlier set recently",
	"Method": "int dropUnusedTracks(){\r\n    List<PointTrack> all = trackerLeft.getAllTracks(null);\r\n    int num = 0;\r\n    for (PointTrack t : all) {\r\n        LeftTrackInfo info = t.getCookie();\r\n        if (tick - info.lastInlier > thresholdRetire) {\r\n            if (!trackerLeft.dropTrack(t))\r\n                throw new IllegalArgumentException(\"failed to drop unused left track\");\r\n            if (!trackerRight.dropTrack(info.right))\r\n                throw new IllegalArgumentException(\"failed to drop unused right track\");\r\n            num++;\r\n        }\r\n    }\r\n    return num;\r\n}"
}, {
	"Path": "com.bugsnag.android.Bugsnag.setMetaData",
	"Comment": "set the global diagnostic information to be send with every error.",
	"Method": "void setMetaData(MetaData metaData){\r\n    getClient().setMetaData(metaData);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.edge.SnapToLineEdge.refine",
	"Comment": "fits a line defined by the two points. when fitting the line the weight of the edge is used to determine.\thow influential the point is.multiple calls might be required to get a perfect fit.",
	"Method": "boolean refine(Point2D_F64 a,Point2D_F64 b,LineGeneral2D_F64 found){\r\n    center.x = (a.x + b.x) / 2.0;\r\n    center.y = (a.y + b.y) / 2.0;\r\n    localScale = a.distance(center);\r\n    double slopeX = (b.x - a.x);\r\n    double slopeY = (b.y - a.y);\r\n    double r = Math.sqrt(slopeX * slopeX + slopeY * slopeY);\r\n    double tanX = slopeY / r;\r\n    double tanY = -slopeX / r;\r\n    computePointsAndWeights(slopeX, slopeY, a.x, a.y, tanX, tanY);\r\n    if (samplePts.size() >= 4) {\r\n        if (null == FitLine_F64.polar(samplePts.toList(), weights.data, polar)) {\r\n            throw new RuntimeException(\"All weights were zero, bug some place\");\r\n        }\r\n        UtilLine2D_F64.convert(polar, found);\r\n        localToGlobal(found);\r\n        return true;\r\n    } else {\r\n        return false;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.universal.TestUniOmniStoP_F64.worldIsImageCenter",
	"Comment": "a point in the world center should appear in the image center",
	"Method": "void worldIsImageCenter(){\r\n    CameraUniversalOmni model = createModel(0.5);\r\n    UniOmniStoP_F64 alg = new UniOmniStoP_F64();\r\n    alg.setModel(model);\r\n    Point2D_F64 found = new Point2D_F64(10, 10);\r\n    alg.compute(0, 0, 1, found);\r\n    assertEquals(320, found.x, GrlConstants.TEST_F64);\r\n    assertEquals(240, found.y, GrlConstants.TEST_F64);\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.AssociateUniqueByScoreAlg.processSource",
	"Comment": "selects a subset of matches that have at most one association for each source feature.",
	"Method": "void processSource(FastQueue<AssociatedIndex> matches,int numSource,FastQueue<AssociatedIndex> output){\r\n    scores.resize(numSource);\r\n    solutions.resize(numSource);\r\n    for (int i = 0; i < numSource; i++) {\r\n        solutions.data[i] = -1;\r\n    }\r\n    for (int i = 0; i < matches.size(); i++) {\r\n        AssociatedIndex a = matches.get(i);\r\n        int found = solutions.data[a.src];\r\n        if (found != -1) {\r\n            if (found == -2) {\r\n                double bestScore = scores.data[a.src];\r\n                int result = type.compareTo(bestScore, a.fitScore);\r\n                if (result < 0) {\r\n                    solutions.data[a.src] = i;\r\n                    scores.data[a.src] = a.fitScore;\r\n                }\r\n            } else {\r\n                AssociatedIndex currentBest = matches.get(found);\r\n                int result = type.compareTo(currentBest.fitScore, a.fitScore);\r\n                if (result < 0) {\r\n                    solutions.data[a.src] = i;\r\n                    scores.data[a.src] = a.fitScore;\r\n                } else if (result == 0) {\r\n                    solutions.data[a.src] = -2;\r\n                }\r\n            }\r\n        } else {\r\n            solutions.data[a.src] = i;\r\n            scores.data[a.src] = a.fitScore;\r\n        }\r\n    }\r\n    output.reset();\r\n    for (int i = 0; i < numSource; i++) {\r\n        int index = solutions.data[i];\r\n        if (index >= 0) {\r\n            output.add(matches.get(index));\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.JavaRuntimeLauncher.getDurationMilli",
	"Comment": "returns how long the operation took to complete. in milliseconds",
	"Method": "long getDurationMilli(){\r\n    return durationMilli;\r\n}"
}, {
	"Path": "boofcv.alg.feature.dense.DescribeDenseHogFastAlg.growCellArray",
	"Comment": "determines if the cell array needs to grow.if it does a new array is declared.old data is recycled when\tpossible",
	"Method": "void growCellArray(int imageWidth,int imageHeight){\r\n    cellCols = imageWidth / pixelsPerCell;\r\n    cellRows = imageHeight / pixelsPerCell;\r\n    if (cellRows * cellCols > cells.length) {\r\n        Cell[] a = new Cell[cellCols * cellRows];\r\n        System.arraycopy(cells, 0, a, 0, cells.length);\r\n        for (int i = cells.length; i < a.length; i++) {\r\n            a[i] = new Cell();\r\n            a[i].histogram = new float[orientationBins];\r\n        }\r\n        cells = a;\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Client.enableExceptionHandler",
	"Comment": "enable automatic reporting of unhandled exceptions.by default, this is automatically enabled in the constructor.",
	"Method": "void enableExceptionHandler(){\r\n    ExceptionHandler.enable(this);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polygon.AdjustPolygonForThresholdBias.process",
	"Comment": "processes and adjusts the polygon. if after adjustment a corner needs to be removed because two sides are\tparallel then the size of the polygon can be changed.",
	"Method": "void process(Polygon2D_F64 polygon,boolean clockwise){\r\n    int N = polygon.size();\r\n    segments.resize(N);\r\n    for (int i = N - 1, j = 0; j < N; i = j, j++) {\r\n        int ii, jj;\r\n        if (clockwise) {\r\n            ii = i;\r\n            jj = j;\r\n        } else {\r\n            ii = j;\r\n            jj = i;\r\n        }\r\n        Point2D_F64 a = polygon.get(ii), b = polygon.get(jj);\r\n        double dx = b.x - a.x;\r\n        double dy = b.y - a.y;\r\n        double l = Math.sqrt(dx * dx + dy * dy);\r\n        if (l == 0) {\r\n            throw new RuntimeException(\"Two identical corners!\");\r\n        }\r\n        if (dx < 0)\r\n            dx = 0;\r\n        if (dy > 0)\r\n            dy = 0;\r\n        LineSegment2D_F64 s = segments.get(ii);\r\n        s.a.x = a.x - dy / l;\r\n        s.a.y = a.y + dx / l;\r\n        s.b.x = b.x - dy / l;\r\n        s.b.y = b.y + dx / l;\r\n    }\r\n    for (int i = N - 1, j = 0; j < N; i = j, j++) {\r\n        int ii, jj;\r\n        if (clockwise) {\r\n            ii = i;\r\n            jj = j;\r\n        } else {\r\n            ii = j;\r\n            jj = i;\r\n        }\r\n        UtilLine2D_F64.convert(segments.get(ii), ga);\r\n        UtilLine2D_F64.convert(segments.get(jj), gb);\r\n        if (null != Intersection2D_F64.intersection(ga, gb, intersection)) {\r\n            if (intersection.distance2(polygon.get(jj)) < 20) {\r\n                polygon.get(jj).set(intersection);\r\n            }\r\n        }\r\n    }\r\n    UtilPolygons2D_F64.removeAdjacentDuplicates(polygon, 1e-8);\r\n}"
}, {
	"Path": "com.bugsnag.android.JsonWriter.open",
	"Comment": "enters a new scope by appending any necessary whitespace and the givenbracket.",
	"Method": "JsonWriter open(JsonScope empty,String openBracket){\r\n    beforeValue(true);\r\n    stack.add(empty);\r\n    out.write(openBracket);\r\n    return this;\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.ImplDisparityScoreSadRect_F32.computeFirstRow",
	"Comment": "initializes disparity calculation by finding the scores for the initial block of horizontal\trows.",
	"Method": "void computeFirstRow(GrayF32 left,GrayF32 right){\r\n    for (int row = 0; row < regionHeight; row++) {\r\n        float[] scores = horizontalScore[row];\r\n        UtilDisparityScore.computeScoreRow(left, right, row, scores, minDisparity, maxDisparity, regionWidth, elementScore);\r\n    }\r\n    for (int i = 0; i < lengthHorizontal; i++) {\r\n        float sum = 0;\r\n        for (int row = 0; row < regionHeight; row++) {\r\n            sum += horizontalScore[row][i];\r\n        }\r\n        verticalScore[i] = sum;\r\n    }\r\n    computeDisparity.process(radiusY, verticalScore);\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.TestFitLinesToContour.fitAnchored_easy_optimization",
	"Comment": "have only one corner off by a few pixels with extremely clean input data",
	"Method": "void fitAnchored_easy_optimization(){\r\n    FitLinesToContour alg = new FitLinesToContour();\r\n    alg.setContour(createSquare(10, 12, 30, 40));\r\n    GrowQueue_I32 expected = createSquareCorners(10, 12, 30, 40);\r\n    GrowQueue_I32 input = createSquareCorners(10, 12, 30, 40);\r\n    GrowQueue_I32 found = new GrowQueue_I32();\r\n    input.set(2, input.get(2) + 3);\r\n    alg.fitAnchored(1, 3, input, found);\r\n    for (int i = 0; i < found.size(); i++) {\r\n        assertEquals(expected.get(i), found.get(i));\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.tracker.tld.TldRegionTracker.declareDataStructures",
	"Comment": "declares internal data structures based on the input image pyramid",
	"Method": "void declareDataStructures(PyramidDiscrete<I> image){\r\n    numPyramidLayers = image.getNumLayers();\r\n    previousDerivX = (D[]) Array.newInstance(derivType, image.getNumLayers());\r\n    previousDerivY = (D[]) Array.newInstance(derivType, image.getNumLayers());\r\n    currentDerivX = (D[]) Array.newInstance(derivType, image.getNumLayers());\r\n    currentDerivY = (D[]) Array.newInstance(derivType, image.getNumLayers());\r\n    for (int i = 0; i < image.getNumLayers(); i++) {\r\n        int w = image.getWidth(i);\r\n        int h = image.getHeight(i);\r\n        previousDerivX[i] = GeneralizedImageOps.createSingleBand(derivType, w, h);\r\n        previousDerivY[i] = GeneralizedImageOps.createSingleBand(derivType, w, h);\r\n        currentDerivX[i] = GeneralizedImageOps.createSingleBand(derivType, w, h);\r\n        currentDerivY[i] = GeneralizedImageOps.createSingleBand(derivType, w, h);\r\n    }\r\n    Class imageClass = image.getImageType().getImageClass();\r\n    previousImage = FactoryPyramid.discreteGaussian(image.getScales(), -1, 1, false, ImageType.single(imageClass));\r\n    previousImage.initialize(image.getInputWidth(), image.getInputHeight());\r\n    for (int i = 0; i < tracks.length; i++) {\r\n        Track t = new Track();\r\n        t.klt = new PyramidKltFeature(numPyramidLayers, featureRadius);\r\n        tracks[i] = t;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.intensity.TestIntegralImageFeatureIntensity.hessian_S32",
	"Comment": "compares hessian intensity against a naive implementation",
	"Method": "void hessian_S32(){\r\n    GrayS32 original = new GrayS32(width, height);\r\n    GrayS32 integral = new GrayS32(width, height);\r\n    GrayF32 found = new GrayF32(width, height);\r\n    GrayF32 expected = new GrayF32(width, height);\r\n    GImageMiscOps.fillUniform(original, rand, 0, 50);\r\n    IntegralImageOps.transform(original, integral);\r\n    int size = 9;\r\n    for (int skip = 1; skip <= 4; skip++) {\r\n        found.reshape(width / skip, height / skip);\r\n        expected.reshape(width / skip, height / skip);\r\n        ImplIntegralImageFeatureIntensity.hessianNaive(integral, skip, size, expected);\r\n        IntegralImageFeatureIntensity.hessian(integral, skip, size, found);\r\n        BoofTesting.assertEquals(expected, found, 1e-4f);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.extract.NonMaxCandidate.process",
	"Comment": "checks to see if the specified candidates are local minimums or maximums.if a candidate list is\tnull then that test is skipped.",
	"Method": "void process(GrayF32 intensityImage,QueueCorner candidatesMin,QueueCorner candidatesMax,QueueCorner foundMin,QueueCorner foundMax){\r\n    this.input = intensityImage;\r\n    endBorderX = intensityImage.width - ignoreBorder;\r\n    endBorderY = intensityImage.height - ignoreBorder;\r\n    if (candidatesMin != null)\r\n        examineMinimum(intensityImage, candidatesMin, foundMin);\r\n    if (candidatesMax != null)\r\n        examineMaximum(intensityImage, candidatesMax, foundMax);\r\n}"
}, {
	"Path": "boofcv.alg.tracker.meanshift.TrackerMeanShiftLikelihood.setTrackLocation",
	"Comment": "used to set the location of the track without changing any appearance history.",
	"Method": "void setTrackLocation(RectangleLength2D_I32 location){\r\n    this.location.set(location);\r\n    this.location.width += 1 - this.location.width % 2;\r\n    this.location.height += 1 - this.location.height % 2;\r\n    failed = false;\r\n}"
}, {
	"Path": "com.bugsnag.android.Error.setDeviceId",
	"Comment": "sets the device id. this can be set to null for privacy concerns.",
	"Method": "void setDeviceId(String id){\r\n    deviceData.put(\"id\", id);\r\n}"
}, {
	"Path": "boofcv.alg.distort.impl.DistortSupport.transformScale",
	"Comment": "computes a transform which is used to rescale an image.the scale is computed\tdirectly from the size of the two input images and independently scales\tthe x and y axises.",
	"Method": "PixelTransformAffine_F32 transformScale(ImageBase from,ImageBase to,PixelTransformAffine_F32 distort){\r\n    if (distort == null)\r\n        distort = new PixelTransformAffine_F32();\r\n    float scaleX = (float) (to.width) / (float) (from.width);\r\n    float scaleY = (float) (to.height) / (float) (from.height);\r\n    Affine2D_F32 affine = distort.getModel();\r\n    affine.set(scaleX, 0, 0, scaleY, 0, 0);\r\n    return distort;\r\n}"
}, {
	"Path": "boofcv.abst.feature.associate.TestScoreAssociateHamming_B.testRandom",
	"Comment": "generate random descriptions and see two hamming distance calculations return the same result.",
	"Method": "void testRandom(){\r\n    ScoreAssociateHamming_B scorer = new ScoreAssociateHamming_B();\r\n    TupleDesc_B a = new TupleDesc_B(512);\r\n    TupleDesc_B b = new TupleDesc_B(512);\r\n    for (int numTries = 0; numTries < 20; numTries++) {\r\n        for (int i = 0; i < a.data.length; i++) {\r\n            a.data[i] = rand.nextInt();\r\n            b.data[i] = rand.nextInt();\r\n        }\r\n        int expected = DescriptorDistance.hamming(a, b);\r\n        assertEquals(expected, scorer.score(a, b), 1e-4);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.shapes.polyline.splitmerge.SplitMergeLineFitSegment.splitPixels",
	"Comment": "recursively splits pixels.used in the initial segmentation.only split points between\tthe two ends are added",
	"Method": "void splitPixels(int indexStart,int indexStop){\r\n    if (indexStart + 1 >= indexStop)\r\n        return;\r\n    int indexSplit = selectSplitBetween(indexStart, indexStop);\r\n    if (indexSplit >= 0) {\r\n        splitPixels(indexStart, indexSplit);\r\n        splits.add(indexSplit);\r\n        splitPixels(indexSplit, indexStop);\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.geo.bundle.ScaleSceneStructure.computePointStatistics",
	"Comment": "for 3d points, computes the median value and variance along each dimension.",
	"Method": "void computePointStatistics(Point[] points){\r\n    final int length = points.length;\r\n    double[] v = new double[length];\r\n    for (int axis = 0; axis < 3; axis++) {\r\n        double maxAbs = 0;\r\n        for (int i = 0; i < length; i++) {\r\n            v[i] = points[i].coordinate[axis];\r\n            maxAbs = Math.max(maxAbs, Math.abs(v[i]));\r\n        }\r\n        double median = QuickSelect.select(v, length / 2, length);\r\n        switch(axis) {\r\n            case 0:\r\n                medianPoint.x = median;\r\n                break;\r\n            case 1:\r\n                medianPoint.y = median;\r\n                break;\r\n            case 2:\r\n                medianPoint.z = median;\r\n                break;\r\n        }\r\n    }\r\n    for (int i = 0; i < length; i++) {\r\n        v[i] = points[i].distanceSq(medianPoint);\r\n    }\r\n    medianDistancePoint = Math.sqrt(QuickSelect.select(v, length / 2, length));\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.impl.TestImplSurfDescribeOps.naiveGradient_fraction",
	"Comment": "give it a scale factor which is a fraction and see if it blows up",
	"Method": "void naiveGradient_fraction(){\r\n    double scale = 1.5;\r\n    int r = 6;\r\n    checkNaiveGradient(scale, r);\r\n}"
}, {
	"Path": "boofcv.alg.geo.h.HomographyTotalLeastSquares.computePPXP",
	"Comment": "computes pp. takes in account the size of each matrix and does the multiplication in an order\tto minimize memory requirements. a naive implementation requires a temporary array of nxn",
	"Method": "void computePPXP(DMatrixRMaj P,DMatrixRMaj P_plus,DMatrixRMaj X,int offsetX,DMatrixRMaj output){\r\n    final int N = P.numRows;\r\n    output.reshape(N, 2);\r\n    for (int i = 0, index = 0; i < N; i++, index += 2) {\r\n        double x = -X.data[index + offsetX];\r\n        output.data[index] = x * P.data[index];\r\n        output.data[index + 1] = x * P.data[index + 1];\r\n    }\r\n    double a00 = 0, a01 = 0, a10 = 0, a11 = 0;\r\n    for (int i = 0, index = 0; i < N; i++, index += 2) {\r\n        a00 += P_plus.data[i] * output.data[index];\r\n        a01 += P_plus.data[i] * output.data[index + 1];\r\n        a10 += P_plus.data[i + N] * output.data[index];\r\n        a11 += P_plus.data[i + N] * output.data[index + 1];\r\n    }\r\n    for (int i = 0, index = 0; i < N; i++, index += 2) {\r\n        output.data[index] = P.data[index] * a00 + P.data[index + 1] * a10;\r\n        output.data[index + 1] = P.data[index] * a01 + P.data[index + 1] * a11;\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.sfm.FactoryVisualOdometry.monoPlaneOverhead",
	"Comment": "monocular plane based visual odometry algorithm which creates a synthetic overhead view and tracks image\tfeatures inside this synthetic view.",
	"Method": "MonocularPlaneVisualOdometry<T> monoPlaneOverhead(double cellSize,double maxCellsPerPixel,double mapHeightFraction,double inlierGroundTol,int ransacIterations,int thresholdRetire,int absoluteMinimumTracks,double respawnTrackFraction,double respawnCoverageFraction,PointTracker<T> tracker,ImageType<T> imageType){\r\n    ImageMotion2D<T, Se2_F64> motion2D = FactoryMotion2D.createMotion2D(ransacIterations, inlierGroundTol * inlierGroundTol, thresholdRetire, absoluteMinimumTracks, respawnTrackFraction, respawnCoverageFraction, false, tracker, new Se2_F64());\r\n    VisOdomMonoOverheadMotion2D<T> alg = new VisOdomMonoOverheadMotion2D(cellSize, maxCellsPerPixel, mapHeightFraction, motion2D, imageType);\r\n    return new MonoOverhead_to_MonocularPlaneVisualOdometry(alg, imageType);\r\n}"
}, {
	"Path": "org.boon.Boon.resourceFromHandleBarsTemplate",
	"Comment": "load a resource and apply the given template against it.if file resource is not found, tries to load the resource from classpath.",
	"Method": "String resourceFromHandleBarsTemplate(String path,Object context,String resourceFromHandleBarsTemplate,Path path,Object context){\r\n    String str = IO.read(path);\r\n    if (str != null) {\r\n        str = Boon.handlebars(str, context);\r\n    }\r\n    return str;\r\n}"
}, {
	"Path": "boofcv.abst.feature.interest.GeneralInterestPointDetectorChecks.checkDetect",
	"Comment": "detect features and see if all the expected parameters have been set",
	"Method": "void checkDetect(){\r\n    detector.detect(image);\r\n    assertTrue(detector.getNumberOfFeatures() > 0);\r\n    int numPoint = 0;\r\n    int numScale = 0;\r\n    int numYaw = 0;\r\n    for (int i = 0; i < detector.getNumberOfFeatures(); i++) {\r\n        Point2D_F64 p = detector.getLocation(i);\r\n        double radius = detector.getRadius(i);\r\n        double yaw = detector.getOrientation(i);\r\n        if (p.x != 0 && p.y != 0)\r\n            numPoint++;\r\n        if (radius != 1)\r\n            numScale++;\r\n        if (yaw != 0)\r\n            numYaw++;\r\n    }\r\n    assertTrue(numPoint > 0);\r\n    if (hasScale)\r\n        assertTrue(numScale > 0);\r\n    else\r\n        assertTrue(numScale == 0);\r\n    if (hasOrientation)\r\n        assertTrue(numYaw > 0);\r\n    else\r\n        assertTrue(numYaw == 0);\r\n}"
}, {
	"Path": "boofcv.alg.feature.associate.StereoConsistencyCheck.checkPixel",
	"Comment": "checks to see if the observations from the left and right camera are consistent.observations\tare assumed to be in the original image pixel coordinates.",
	"Method": "boolean checkPixel(Point2D_F64 left,Point2D_F64 right){\r\n    leftImageToRect.compute(left.x, left.y, rectLeft);\r\n    rightImageToRect.compute(right.x, right.y, rectRight);\r\n    return checkRectified(rectLeft, rectRight);\r\n}"
}, {
	"Path": "boofcv.abst.feature.detdesc.TestDetectDescribeFusion.checkFeatureNotInBounds",
	"Comment": "if a feature is not in bounds make sure everything is handled correctly",
	"Method": "void checkFeatureNotInBounds(){\r\n    InterestPointDetector detector = new DummyDetector();\r\n    DescribeRegionPoint describe = new DummyRegionPoint();\r\n    DetectDescribeFusion alg = new DetectDescribeFusion(detector, null, describe);\r\n    alg.detect(new GrayF32(2, 2));\r\n    assertEquals(9, alg.getNumberOfFeatures());\r\n    for (int i = 0; i < 9; i++) {\r\n        assertEquals(2, alg.getRadius(i), 1e-8);\r\n        assertEquals(1, alg.getOrientation(i), 1e-8);\r\n        assertTrue(alg.getDescription(i) != null);\r\n        assertTrue(alg.getLocation(i) != null);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.InputSanityCheck.checkReshapeB",
	"Comment": "throws exception if two images are the same instance. otherwise reshapes b to match a",
	"Method": "void checkReshapeB(ImageMultiBand<?> imgA,ImageMultiBand<?> imgB){\r\n    if (imgA == imgB)\r\n        throw new IllegalArgumentException(\"Image's can't be the same instance\");\r\n    imgB.reshape(imgA.width, imgA.height, imgA.getNumBands());\r\n}"
}, {
	"Path": "com.jolbox.bonecp.hooks.AcquireFailConfig.setAcquireRetryDelayInMs",
	"Comment": "sets the new acquireretrydelay. does not affect the global config.",
	"Method": "void setAcquireRetryDelayInMs(long acquireRetryDelayInMs){\r\n    this.acquireRetryDelayInMs = acquireRetryDelayInMs;\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.ms.RegionMergeTree.setToRootNodeNewID",
	"Comment": "does much of the work needed to remove the redundant segments that are being merged into their root node.\tthe list of member count is updated.mergelist is updated with the new segment ids.",
	"Method": "void setToRootNodeNewID(GrowQueue_I32 regionMemberCount){\r\n    tmpMemberCount.reset();\r\n    for (int i = 0; i < mergeList.size; i++) {\r\n        int p = mergeList.data[i];\r\n        if (p == i) {\r\n            mergeList.data[i] = rootID.data[i];\r\n            tmpMemberCount.add(regionMemberCount.data[i]);\r\n        } else {\r\n            mergeList.data[i] = rootID.data[mergeList.data[i]];\r\n        }\r\n    }\r\n    regionMemberCount.reset();\r\n    regionMemberCount.addAll(tmpMemberCount);\r\n}"
}, {
	"Path": "boofcv.examples.imageprocessing.ExamplePlanarImages.convertToGray",
	"Comment": "there is no real perfect way that everyone agrees on for converting color images into gray scale\timages.two examples of how to convert a planar image into a gray scale image are shown\tin this example.",
	"Method": "void convertToGray(BufferedImage input){\r\n    Planar<GrayU8> image = ConvertBufferedImage.convertFromPlanar(input, null, true, GrayU8.class);\r\n    GrayU8 gray = new GrayU8(image.width, image.height);\r\n    GPixelMath.averageBand(image, gray);\r\n    BufferedImage outputAve = ConvertBufferedImage.convertTo(gray, null);\r\n    ColorRgb.rgbToGray_Weighted(image, gray);\r\n    BufferedImage outputWeighted = ConvertBufferedImage.convertTo(gray, null);\r\n    BufferedImage outputBand0 = ConvertBufferedImage.convertTo(image.getBand(0), null);\r\n    gui.addImage(outputAve, \"Gray Averaged\");\r\n    gui.addImage(outputWeighted, \"Gray Weighted\");\r\n    gui.addImage(outputBand0, \"Band 0\");\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.square.QuadPoseEstimator.enlarge",
	"Comment": "enlarges the quadrilateral to make it more sensitive to changes in orientation",
	"Method": "void enlarge(Quadrilateral_F64 corners,double scale){\r\n    UtilPolygons2D_F64.center(corners, center);\r\n    extend(center, corners.a, scale);\r\n    extend(center, corners.b, scale);\r\n    extend(center, corners.c, scale);\r\n    extend(center, corners.d, scale);\r\n}"
}, {
	"Path": "boofcv.io.image.UtilImageIO.loadImages",
	"Comment": "loads all the image in the specified directory which match the provided regex",
	"Method": "List<BufferedImage> loadImages(String directory,String regex){\r\n    List<String> paths = UtilIO.listByRegex(directory, regex);\r\n    List<BufferedImage> ret = new ArrayList();\r\n    if (paths.size() == 0)\r\n        return ret;\r\n    Collections.sort(paths);\r\n    for (String path : paths) {\r\n        BufferedImage img = loadImage(path);\r\n        if (img != null)\r\n            ret.add(img);\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.alg.distort.mls.ImageDeformPointMLS_F32.computeAverageP",
	"Comment": "computes the average p given the weights at this cached point",
	"Method": "void computeAverageP(Cache cache){\r\n    float[] weights = cache.weights.data;\r\n    cache.aveP.set(0, 0);\r\n    for (int i = 0; i < controls.size(); i++) {\r\n        Control c = controls.get(i);\r\n        float w = weights[i];\r\n        cache.aveP.x += c.p.x * w;\r\n        cache.aveP.y += c.p.y * w;\r\n    }\r\n    cache.aveP.x /= cache.totalWeight;\r\n    cache.aveP.y /= cache.totalWeight;\r\n}"
}, {
	"Path": "boofcv.factory.feature.detect.interest.FactoryDetectPoint.createFast",
	"Comment": "creates a fast corner detector with feature intensity for additional pruning. fast features\thave minimums and maximums.",
	"Method": "GeneralFeatureDetector<T, D> createFast(ConfigFastCorner configFast,ConfigGeneralDetector configDetector,Class<T> imageType,PointDetector<T> createFast,ConfigFastCorner configFast,Class<T> imageType){\r\n    if (configFast == null)\r\n        configFast = new ConfigFastCorner();\r\n    configFast.checkValidity();\r\n    FastCornerDetector<T> alg = FactoryIntensityPointAlg.fast(configFast.pixelTol, configFast.minContinuous, imageType);\r\n    alg.setMaxFeaturesFraction(configFast.maxFeatures);\r\n    return new WrapFastToPointDetector(alg);\r\n}"
}, {
	"Path": "boofcv.alg.distort.mls.ImageDeformPointMLS_F32.computeAverageQ",
	"Comment": "computes the average q given the weights at this cached point",
	"Method": "void computeAverageQ(Cache cache){\r\n    float[] weights = cache.weights.data;\r\n    cache.aveQ.set(0, 0);\r\n    for (int i = 0; i < controls.size(); i++) {\r\n        Control c = controls.get(i);\r\n        float w = weights[i];\r\n        cache.aveQ.x += c.q.x * w;\r\n        cache.aveQ.y += c.q.y * w;\r\n    }\r\n    cache.aveQ.x /= cache.totalWeight;\r\n    cache.aveQ.y /= cache.totalWeight;\r\n}"
}, {
	"Path": "boofcv.alg.feature.orientation.GenericOrientationIntegralTests.setScale",
	"Comment": "estimate the direction at a couple of different scales and see if it produces the expected results.",
	"Method": "void setScale(){\r\n    int x = width / 2;\r\n    int y = height / 2;\r\n    int N = 2 * (int) (Math.PI / angleTolerance);\r\n    double angle = UtilAngle.bound((N / 2) * angleTolerance);\r\n    createOrientedImage(angle);\r\n    alg.setImage(ii);\r\n    alg.setObjectRadius(10);\r\n    double found = UtilAngle.bound(alg.compute(x, y));\r\n    assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n    alg.setObjectRadius(15);\r\n    found = UtilAngle.bound(alg.compute(x, y));\r\n    assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n    alg.setObjectRadius(7.5);\r\n    found = UtilAngle.bound(alg.compute(x, y));\r\n    assertTrue(UtilAngle.dist(angle, found) < angleTolerance);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.TestEllipsesIntoClusters.checkConnections",
	"Comment": "provide it a simple case to cluster and make sure everything is connected properly",
	"Method": "void checkConnections(){\r\n    EllipsesIntoClusters alg = new EllipsesIntoClusters(2.1, 0.5, 0.5);\r\n    List<EllipseInfo> input = new ArrayList();\r\n    input.add(create(0, 0, 1, 1, 0));\r\n    input.add(create(2.0, 0, 1, 1, 0));\r\n    input.add(create(4.0, 0, 1, 1, 0));\r\n    input.add(create(0, 2, 1, 1, 0));\r\n    input.add(create(2.0, 2, 1, 1, 0));\r\n    input.add(create(4.0, 2, 1, 1, 0));\r\n    List<List<EllipsesIntoClusters.Node>> output = new ArrayList();\r\n    alg.process(input, output);\r\n    assertEquals(1, output.size());\r\n    List<EllipsesIntoClusters.Node> found = output.get(0);\r\n    assertEquals(6, found.size());\r\n    int[] histogram = new int[5];\r\n    for (EllipsesIntoClusters.Node n : found) {\r\n        histogram[n.connections.size]++;\r\n    }\r\n    assertEquals(0, histogram[0]);\r\n    assertEquals(0, histogram[1]);\r\n    assertEquals(4, histogram[2]);\r\n    assertEquals(2, histogram[3]);\r\n    assertEquals(0, histogram[4]);\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.FundamentalLinear.isComputeFundamental",
	"Comment": "returns true if it is computing a fundamental matrix or false if it is an essential matrix.",
	"Method": "boolean isComputeFundamental(){\r\n    return computeFundamental;\r\n}"
}, {
	"Path": "org.boon.collections.DoubleList.reduceBy",
	"Comment": "this would be a good opportunity to reintroduce dynamic invoke",
	"Method": "double reduceBy(Object function,double reduceBy,Object function,String name,double reduceBy,Dbl.ReduceBy reduceBy){\r\n    return Dbl.reduceBy(values, end, reduceBy);\r\n}"
}, {
	"Path": "boofcv.abst.geo.TestGeoModelEstimatorNto1.checkSelectBestSolution",
	"Comment": "generate one matrix which should match the epipolar constraint and a bunch of random\tones.see if it selects the correct matrix",
	"Method": "void checkSelectBestSolution(){\r\n    DMatrixRMaj correct = createSolution();\r\n    GeoModelEstimatorNto1<DMatrixRMaj, AssociatedPair> alg = new DummyEstimator(new Dummy(correct, 7), distance, 2);\r\n    assertTrue(alg.process(obs, found));\r\n    assertTrue(MatrixFeatures_DDRM.isIdentical(found, correct, 1e-8));\r\n}"
}, {
	"Path": "boofcv.alg.denoise.wavelet.SubbandShrink.performShrinkage",
	"Comment": "performs wavelet shrinking using the specified rule and by computing a threshold\tfor each subband.",
	"Method": "void performShrinkage(I transform,int numLevels){\r\n    for (int i = 0; i < numLevels; i++) {\r\n        int w = transform.width;\r\n        int h = transform.height;\r\n        int ww = w / 2;\r\n        int hh = h / 2;\r\n        Number threshold;\r\n        I subband;\r\n        subband = transform.subimage(ww, 0, w, hh, null);\r\n        threshold = computeThreshold(subband);\r\n        rule.process(subband, threshold);\r\n        subband = transform.subimage(0, hh, ww, h, null);\r\n        threshold = computeThreshold(subband);\r\n        rule.process(subband, threshold);\r\n        subband = transform.subimage(ww, hh, w, h, null);\r\n        threshold = computeThreshold(subband);\r\n        rule.process(subband, threshold);\r\n        transform = transform.subimage(0, 0, ww, hh, null);\r\n    }\r\n}"
}, {
	"Path": "boofcv.factory.filter.kernel.FactoryKernelGaussian.gaussian1D_F32",
	"Comment": "creates a floating point gaussian kernel with the sigma and radius.\tif normalized is set to true then the elements in the kernel will sum up to one.",
	"Method": "Kernel1D_F32 gaussian1D_F32(double sigma,int radius,boolean odd,boolean normalize){\r\n    Kernel1D_F32 ret;\r\n    if (odd) {\r\n        ret = new Kernel1D_F32(radius * 2 + 1);\r\n        int index = 0;\r\n        for (int i = radius; i >= -radius; i--) {\r\n            ret.data[index++] = (float) UtilGaussian.computePDF(0, sigma, i);\r\n        }\r\n    } else {\r\n        ret = new Kernel1D_F32(radius * 2);\r\n        int index = 0;\r\n        for (int i = radius; i > -radius; i--) {\r\n            ret.data[index++] = (float) UtilGaussian.computePDF(0, sigma, i - 0.5);\r\n        }\r\n    }\r\n    if (normalize) {\r\n        KernelMath.normalizeSumToOne(ret);\r\n    }\r\n    return ret;\r\n}"
}, {
	"Path": "boofcv.examples.features.ExampleLineDetection.detectLines",
	"Comment": "detects lines inside the image using different types of hough detectors",
	"Method": "void detectLines(BufferedImage image,Class<T> imageType,Class<D> derivType){\r\n    T input = ConvertBufferedImage.convertFromSingle(image, null, imageType);\r\n    DetectLineHoughPolar<T, D> detector = FactoryDetectLineAlgs.houghPolar(new ConfigHoughPolar(3, 30, 2, Math.PI / 180, edgeThreshold, maxLines), imageType, derivType);\r\n    List<LineParametric2D_F32> found = detector.detect(input);\r\n    ImageLinePanel gui = new ImageLinePanel();\r\n    gui.setImage(image);\r\n    gui.setLines(found);\r\n    gui.setPreferredSize(new Dimension(image.getWidth(), image.getHeight()));\r\n    listPanel.addItem(gui, \"Found Lines\");\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.HysteresisEdgeTraceMark.check",
	"Comment": "checks to see if the given coordinate is above the lower threshold.if it is the point will be\tadded to the current segment or be the start of a new segment.",
	"Method": "boolean check(int x,int y,boolean match){\r\n    if (intensity.isInBounds(x, y)) {\r\n        int index = intensity.getIndex(x, y);\r\n        if (intensity.data[index] >= lower) {\r\n            intensity.data[index] = MARK_TRAVERSED;\r\n            output.unsafe_set(x, y, 1);\r\n            if (match) {\r\n                open.grow().set(x, y);\r\n            } else {\r\n                active.set(x, y);\r\n            }\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.struct.image.InterleavedS64.getBand",
	"Comment": "returns the value of the specified band in the specified pixel.",
	"Method": "long getBand(int x,int y,int band){\r\n    if (!isInBounds(x, y))\r\n        throw new ImageAccessException(\"Requested pixel is out of bounds.\");\r\n    if (band < 0 || band >= numBands)\r\n        throw new ImageAccessException(\"Invalid band requested.\");\r\n    return data[getIndex(x, y, band)];\r\n}"
}, {
	"Path": "boofcv.abst.fiducial.GenericFiducialDetectorChecks.clearLensDistortion",
	"Comment": "make sure lens distortion is removed if it was set previously and then removed",
	"Method": "void clearLensDistortion(){\r\n    for (ImageType type : types) {\r\n        ImageBase image = loadImage(type);\r\n        FiducialDetector detector = createDetector(type);\r\n        detector.setLensDistortion(loadDistortion(false), image.width, image.height);\r\n        detector.detect(image);\r\n        assertTrue(detector.totalFound() >= 1);\r\n        Results before = extractResults(detector);\r\n        detector.setLensDistortion(loadDistortion(true), image.width, image.height);\r\n        detector.detect(image);\r\n        detector.setLensDistortion(loadDistortion(false), image.width, image.height);\r\n        detector.detect(image);\r\n        Results after = extractResults(detector);\r\n        for (int i = 0; i < after.id.length; i++) {\r\n            assertEquals(before.id[i], after.id[i]);\r\n            assertEquals(0, before.pose.get(i).T.distance(after.pose.get(i).T), 1e-8);\r\n            assertTrue(MatrixFeatures_DDRM.isIdentical(before.pose.get(i).R, after.pose.get(i).R, 1e-8));\r\n            assertEquals(0, before.pixel.get(i).distance(after.pixel.get(i)), 1e-8);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.struct.image.Planar.setTo",
	"Comment": "sets the values of each pixel equal to the pixels in the specified matrix.\tautomatically resized to match the input image.",
	"Method": "void setTo(Planar<T> orig){\r\n    if (orig.width != width || orig.height != height)\r\n        reshape(orig.width, orig.height);\r\n    if (orig.getBandType() != getBandType())\r\n        throw new IllegalArgumentException(\"The band type must be the same\");\r\n    int N = orig.getNumBands();\r\n    if (N != getNumBands()) {\r\n        setNumberOfBands(orig.getNumBands());\r\n    }\r\n    for (int i = 0; i < N; i++) {\r\n        bands[i].setTo(orig.getBand(i));\r\n    }\r\n}"
}, {
	"Path": "org.boon.sort.Sorting.universalComparator",
	"Comment": "this creates the universal comparator object which is used by the sort work horse.",
	"Method": "Comparator universalComparator(FieldAccess field,boolean ascending,boolean nullsFirst){\r\n    return new Comparator() {\r\n        @Override\r\n        public int compare(Object o1, Object o2) {\r\n            Object value1 = null;\r\n            Object value2 = null;\r\n            if (ascending) {\r\n                value1 = field.getValue(o1);\r\n                value2 = field.getValue(o2);\r\n            } else {\r\n                value1 = field.getValue(o2);\r\n                value2 = field.getValue(o1);\r\n            }\r\n            return Sorting.compare(value1, value2, nullsFirst);\r\n        }\r\n    };\r\n}"
}, {
	"Path": "org.boon.sort.Sorting.universalComparator",
	"Comment": "this creates the universal comparator object which is used by the sort work horse.",
	"Method": "Comparator universalComparator(FieldAccess field,boolean ascending,boolean nullsFirst){\r\n    Object value1 = null;\r\n    Object value2 = null;\r\n    if (ascending) {\r\n        value1 = field.getValue(o1);\r\n        value2 = field.getValue(o2);\r\n    } else {\r\n        value1 = field.getValue(o2);\r\n        value2 = field.getValue(o1);\r\n    }\r\n    return Sorting.compare(value1, value2, nullsFirst);\r\n}"
}, {
	"Path": "boofcv.alg.geo.f.TestFundamentalResidualSampson.checkChangeInCost",
	"Comment": "first check to see if the error is very low for perfect parameters.then\tgive it incorrect parameters and make sure it is not zero.",
	"Method": "void checkChangeInCost(){\r\n    init(30, true);\r\n    DMatrixRMaj E = MultiViewOps.createEssential(a_to_b.getR(), a_to_b.getT(), null);\r\n    DMatrixRMaj F = MultiViewOps.createFundamental(E, K);\r\n    FundamentalResidualSampson alg = new FundamentalResidualSampson();\r\n    alg.setModel(F);\r\n    for (AssociatedPair p : pairs) {\r\n        assertEquals(0, alg.computeResidual(p), 1e-8);\r\n    }\r\n    assertEquals(0, MultiViewOps.constraint(F, pairs.get(0).p1, pairs.get(0).p2), UtilEjml.TEST_F64);\r\n    AssociatedPair tmpPair = pairs.get(0).copy();\r\n    tmpPair.p1.x += 2;\r\n    tmpPair.p1.y -= 2;\r\n    assertTrue(Math.abs(alg.computeResidual(tmpPair)) > 1);\r\n    F.data[1] += 0.1;\r\n    alg.setModel(F);\r\n    for (AssociatedPair p : pairs) {\r\n        assertTrue(Math.abs(alg.computeResidual(p)) > 1e-8);\r\n    }\r\n}"
}, {
	"Path": "boofcv.examples.stereo.ExampleStereoTwoViewsOneCamera.drawInliers",
	"Comment": "draw inliers for debugging purposes.need to convert from normalized to pixel coordinates.",
	"Method": "void drawInliers(BufferedImage left,BufferedImage right,CameraPinholeRadial intrinsic,List<AssociatedPair> normalized){\r\n    Point2Transform2_F64 n_to_p = LensDistortionOps.narrow(intrinsic).distort_F64(false, true);\r\n    List<AssociatedPair> pixels = new ArrayList();\r\n    for (AssociatedPair n : normalized) {\r\n        AssociatedPair p = new AssociatedPair();\r\n        n_to_p.compute(n.p1.x, n.p1.y, p.p1);\r\n        n_to_p.compute(n.p2.x, n.p2.y, p.p2);\r\n        pixels.add(p);\r\n    }\r\n    AssociationPanel panel = new AssociationPanel(20);\r\n    panel.setAssociation(pixels);\r\n    panel.setImages(left, right);\r\n    ShowImages.showWindow(panel, \"Inlier Features\", true);\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.interest.GenericFeatureDetectorTests.compareBlankImage",
	"Comment": "give it a blank image and one with random noise.the blank image should have very very few features",
	"Method": "void compareBlankImage(){\r\n    GrayF32 input = new GrayF32(width, height);\r\n    Object alg = createDetector(-1);\r\n    int firstFound = detectFeature(input, alg);\r\n    renderCheckered(input);\r\n    int secondFound = detectFeature(input, alg);\r\n    assertTrue(firstFound < secondFound);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomDualTrackPnP.mutualTrackDrop",
	"Comment": "if a track was dropped in one image make sure it was dropped in the other image",
	"Method": "void mutualTrackDrop(){\r\n    for (PointTrack t : trackerLeft.getDroppedTracks(null)) {\r\n        LeftTrackInfo info = t.getCookie();\r\n        trackerRight.dropTrack(info.right);\r\n    }\r\n    for (PointTrack t : trackerRight.getDroppedTracks(null)) {\r\n        RightTrackInfo info = t.getCookie();\r\n        trackerLeft.dropTrack(info.left);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.interpolate.TestImageLineIntegral.inside_nonZero",
	"Comment": "see if it calculates the integral correctly inside a single pixel",
	"Method": "void inside_nonZero(){\r\n    GrayU8 img = new GrayU8(10, 15);\r\n    ImageMiscOps.fill(img, 255);\r\n    img.set(6, 6, 100);\r\n    alg.setImage(FactoryGImageGray.wrap(img));\r\n    double r = Math.sqrt(0.1 * 0.1 + 0.2 * 0.2);\r\n    checkSolution(6.1, 6.2, 6.2, 6.4, r * 100);\r\n    checkSolution(6.2, 6.1, 6.4, 6.2, r * 100);\r\n    checkSolution(6, 6, 7, 7, sqrt(2) * 100);\r\n    checkSolution(6, 7, 7, 6, sqrt(2) * 100);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.ReidSolomonCodes.computeECC",
	"Comment": "given the input message compute the error correction code for it",
	"Method": "void computeECC(GrowQueue_I8 input,GrowQueue_I8 output){\r\n    int N = generator.size - 1;\r\n    input.extend(input.size + N);\r\n    Arrays.fill(input.data, input.size - N, input.size, (byte) 0);\r\n    math.polyDivide(input, generator, tmp0, output);\r\n    input.size -= N;\r\n}"
}, {
	"Path": "boofcv.alg.geo.PerspectiveOps.renderPixel",
	"Comment": "render a pixel in homogeneous coordinates from a 3x4 camera matrix and a 2d point.",
	"Method": "Point2D_F64 renderPixel(Se3_F64 worldToCamera,DMatrixRMaj K,Point3D_F64 X,Point2D_F64 renderPixel,Se3_F64 worldToCamera,CameraPinhole K,Point3D_F64 X,Point2D_F64 renderPixel,Se3_F64 worldToCamera,Point3D_F64 X,Point2D_F64 renderPixel,CameraPinhole intrinsic,Point3D_F64 X,Point2D_F64 renderPixel,DMatrixRMaj worldToCamera,Point3D_F64 X,Point2D_F64 renderPixel,DMatrixRMaj worldToCamera,Point3D_F64 X,Point2D_F64 pixel,Point3D_F64 renderPixel,DMatrixRMaj worldToCamera,Point3D_F64 X,Point3D_F64 pixel,Point3D_F64 renderPixel,DMatrixRMaj cameraMatrix,Point4D_F64 X,Point3D_F64 x,Point2D_F64 renderPixel,DMatrixRMaj cameraMatrix,Point4D_F64 X,Point2D_F64 x){\r\n    if (x == null)\r\n        x = new Point2D_F64();\r\n    ImplPerspectiveOps_F64.renderPixel(cameraMatrix, X, x);\r\n    return x;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.MemorizeTransactionProxy.runWithPossibleProxySwap",
	"Comment": "runs the given method with the specified arguments, substituting with proxies where necessary",
	"Method": "Object runWithPossibleProxySwap(Method method,Object target,Object[] args){\r\n    Object result;\r\n    if (method.getName().equals(\"createStatement\")) {\r\n        result = memorize((Statement) method.invoke(target, args), this.connectionHandle.get());\r\n    } else if (method.getName().equals(\"prepareStatement\")) {\r\n        result = memorize((PreparedStatement) method.invoke(target, args), this.connectionHandle.get());\r\n    } else if (method.getName().equals(\"prepareCall\")) {\r\n        result = memorize((CallableStatement) method.invoke(target, args), this.connectionHandle.get());\r\n    } else\r\n        result = method.invoke(target, args);\r\n    return result;\r\n}"
}, {
	"Path": "boofcv.alg.distort.spherical.EquirectangularTools_F32.equiToNorm",
	"Comment": "converts equirectangular into normalized pointing vector",
	"Method": "void equiToNorm(float x,float y,Point3D_F32 norm){\r\n    equiToLatLon(x, y, temp);\r\n    ConvertCoordinates3D_F32.latlonToUnitVector(temp.lat, temp.lon, norm);\r\n}"
}, {
	"Path": "org.boon.messages.MessageSpecification.getSubject",
	"Comment": "gets the current subject or the configured subject if thecurrent subject is not found.",
	"Method": "String getSubject(){\r\n    return ValidationContext.get().getCurrentSubject() == null ? this.subject : ValidationContext.get().getCurrentSubject();\r\n}"
}, {
	"Path": "org.boofcv.video.GradientActivity.processImage",
	"Comment": "this function is invoked in its own thread and can take as long as you want.",
	"Method": "void processImage(ImageBase image){\r\n    gradient.process((GrayU8) image, derivX, derivY);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.qrcode.QrCodeDecoderImage.extractFormatInfo",
	"Comment": "reads format info bits from the image and saves the results in qr",
	"Method": "boolean extractFormatInfo(QrCode qr){\r\n    for (int i = 0; i < 2; i++) {\r\n        if (i == 0)\r\n            readFormatRegion0(qr);\r\n        else\r\n            readFormatRegion1(qr);\r\n        int bitField = this.bits.read(0, 15, false);\r\n        bitField ^= QrCodePolynomialMath.FORMAT_MASK;\r\n        int message;\r\n        if (QrCodePolynomialMath.checkFormatBits(bitField)) {\r\n            message = bitField >> 10;\r\n        } else {\r\n            message = QrCodePolynomialMath.correctFormatBits(bitField);\r\n        }\r\n        if (message >= 0) {\r\n            QrCodePolynomialMath.decodeFormatMessage(message, qr);\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}"
}, {
	"Path": "boofcv.alg.sfm.d3.VisOdomPixelDepthPnP.process",
	"Comment": "estimates the motion given the left camera image.the latest information required by imagepixelto3d\tshould be passed to the class before invoking this function.",
	"Method": "boolean process(T image){\r\n    tracker.process(image);\r\n    tick++;\r\n    inlierTracks.clear();\r\n    if (first) {\r\n        addNewTracks();\r\n        first = false;\r\n    } else {\r\n        if (!estimateMotion()) {\r\n            return false;\r\n        }\r\n        dropUnusedTracks();\r\n        int N = motionEstimator.getMatchSet().size();\r\n        if (thresholdAdd <= 0 || N < thresholdAdd) {\r\n            changePoseToReference();\r\n            addNewTracks();\r\n        }\r\n    }\r\n    return true;\r\n}"
}, {
	"Path": "boofcv.gui.image.ShowImages.showDialog",
	"Comment": "creates a dialog window showing the specified image.the function will not\texit until the user clicks ok",
	"Method": "void showDialog(BufferedImage img){\r\n    ImageIcon icon = new ImageIcon();\r\n    icon.setImage(img);\r\n    JOptionPane.showMessageDialog(null, icon);\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.EllipseClustersIntoGrid.pruneNearlyIdenticalAngles",
	"Comment": "if there is a nearly perfect line a node farther down the line can come before.this just selects the closest",
	"Method": "void pruneNearlyIdenticalAngles(){\r\n    for (int i = 0; i < listInfo.size(); i++) {\r\n        NodeInfo infoN = listInfo.get(i);\r\n        for (int j = 0; j < infoN.edges.size(); ) {\r\n            int k = (j + 1) % infoN.edges.size;\r\n            double angularDiff = UtilAngle.dist(infoN.edges.get(j).angle, infoN.edges.get(k).angle);\r\n            if (angularDiff < UtilAngle.radian(5)) {\r\n                NodeInfo infoJ = infoN.edges.get(j).target;\r\n                NodeInfo infoK = infoN.edges.get(k).target;\r\n                double distJ = infoN.ellipse.center.distance(infoJ.ellipse.center);\r\n                double distK = infoN.ellipse.center.distance(infoK.ellipse.center);\r\n                if (distJ < distK) {\r\n                    infoN.edges.remove(k);\r\n                } else {\r\n                    infoN.edges.remove(j);\r\n                }\r\n            } else {\r\n                j++;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.update",
	"Comment": "respond to an update notification from observed objects, like metadata",
	"Method": "void update(Observable observable,Object arg){\r\n    if (arg instanceof NativeInterface.Message) {\r\n        setChanged();\r\n        notifyObservers(arg);\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.transform.ii.IntegralImageOps.convolve",
	"Comment": "general code for convolving a box filter across an image using the integral image.",
	"Method": "GrayF32 convolve(GrayF32 integral,IntegralKernel kernel,GrayF32 output,GrayF64 convolve,GrayF64 integral,IntegralKernel kernel,GrayF64 output,GrayS32 convolve,GrayS32 integral,IntegralKernel kernel,GrayS32 output,GrayS64 convolve,GrayS64 integral,IntegralKernel kernel,GrayS64 output){\r\n    output = InputSanityCheck.checkDeclare(integral, output);\r\n    ImplIntegralImageOps.convolve(integral, kernel, output);\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.GradientToEdgeFeatures.nonMaxSuppression8",
	"Comment": "sets edge intensities to zero if the pixel has an intensity which is less than either of\tthe two adjacent pixels.pixel adjacency is determined by the gradients discretized direction.",
	"Method": "GrayF32 nonMaxSuppression8(GrayF32 intensity,GrayS8 direction,GrayF32 output){\r\n    InputSanityCheck.checkSameShape(intensity, direction);\r\n    output = InputSanityCheck.checkDeclare(intensity, output);\r\n    ImplEdgeNonMaxSuppression.inner8(intensity, direction, output);\r\n    ImplEdgeNonMaxSuppression.border8(intensity, direction, output);\r\n    return output;\r\n}"
}, {
	"Path": "boofcv.alg.feature.detect.edge.GradientToEdgeFeatures.nonMaxSuppression4",
	"Comment": "sets edge intensities to zero if the pixel has an intensity which is less than either of\tthe two adjacent pixels.pixel adjacency is determined by the gradients discretized direction.",
	"Method": "GrayF32 nonMaxSuppression4(GrayF32 intensity,GrayS8 direction,GrayF32 output){\r\n    InputSanityCheck.checkSameShape(intensity, direction);\r\n    output = InputSanityCheck.checkDeclare(intensity, output);\r\n    ImplEdgeNonMaxSuppression.inner4(intensity, direction, output);\r\n    ImplEdgeNonMaxSuppression.border4(intensity, direction, output);\r\n    return output;\r\n}"
}, {
	"Path": "org.boon.cache.CacheEntry.compareTo",
	"Comment": "comparison of entries this determines what we will order the cache bywhich determines which type of cache it is.",
	"Method": "int compareTo(CacheEntry other){\r\n    switch(type) {\r\n        case LFU:\r\n            return compareToLFU(other);\r\n        case LRU:\r\n            return compareToLRU(other);\r\n        case FIFO:\r\n            return compareToFIFO(other);\r\n        default:\r\n            die();\r\n            return 0;\r\n    }\r\n}"
}, {
	"Path": "org.boofcv.video.GradientActivity.renderBitmapImage",
	"Comment": "override the default behavior and colorize gradient instead of converting input image.",
	"Method": "void renderBitmapImage(BitmapMode mode,ImageBase image){\r\n    switch(mode) {\r\n        case UNSAFE:\r\n            {\r\n                VisualizeImageData.colorizeGradient(derivX, derivY, -1, bitmap, bitmapTmp);\r\n            }\r\n            break;\r\n        case DOUBLE_BUFFER:\r\n            {\r\n                VisualizeImageData.colorizeGradient(derivX, derivY, -1, bitmapWork, bitmapTmp);\r\n                if (bitmapLock.tryLock()) {\r\n                    try {\r\n                        Bitmap tmp = bitmapWork;\r\n                        bitmapWork = bitmap;\r\n                        bitmap = tmp;\r\n                    } finally {\r\n                        bitmapLock.unlock();\r\n                    }\r\n                }\r\n            }\r\n            break;\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.filter.binary.TestLinearContourLabelChang2004.checkInnerOuterContour",
	"Comment": "check to see if inner and outer contours are being computed correctly",
	"Method": "void checkInnerOuterContour(){\r\n    GrayU8 input = TEST3.clone();\r\n    GrayS32 labeled = new GrayS32(input.width, input.height);\r\n    LinearContourLabelChang2004 alg = new LinearContourLabelChang2004(ConnectRule.EIGHT);\r\n    alg.process(input, labeled);\r\n    assertEquals(1, alg.getContours().size);\r\n    checkContour(alg, labeled, 8);\r\n    ContourPacked c = alg.getContours().get(0);\r\n    assertEquals(10, alg.packedPoints.sizeOfSet(c.externalIndex));\r\n    assertEquals(1, c.internalIndexes.size);\r\n    assertEquals(4, alg.packedPoints.sizeOfSet(c.externalIndex + 1));\r\n}"
}, {
	"Path": "com.jolbox.bonecp.hooks.AcquireFailConfig.getAcquireRetryAttempts",
	"Comment": "returns the acquireretryattemps. by default starts off with whatever is set in the config.",
	"Method": "AtomicInteger getAcquireRetryAttempts(){\r\n    return this.acquireRetryAttempts;\r\n}"
}, {
	"Path": "org.boon.datarepo.impl.FilterDefault.filter",
	"Comment": "seems innocent enough. give me some criteria expressions,and i will give you a nice results set.",
	"Method": "ResultSet filter(Criteria expressions){\r\n    try {\r\n        return mainQueryPlan(expressions);\r\n    } finally {\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.circle.TestEllipsesIntoClusters.noCluster_size",
	"Comment": "points should not be clustered together due difference in side lengths",
	"Method": "void noCluster_size(){\r\n    EllipsesIntoClusters alg = new EllipsesIntoClusters(2.0, 0.5, 0.5);\r\n    List<EllipseInfo> input = new ArrayList();\r\n    input.add(create(0, 0, 2, 1, 0));\r\n    input.add(create(2, 0, 0.999, 1, 0));\r\n    alg.init(input);\r\n    alg.connect(input);\r\n    assertEquals(2, alg.clusters.size());\r\n    input.get(1).ellipse.a = 1.0;\r\n    alg.init(input);\r\n    alg.connect(input);\r\n    assertEquals(1, alg.clusters.size());\r\n}"
}, {
	"Path": "boofcv.alg.fiducial.calib.chess.DetectChessboardSquarePoints.configureContourDetector",
	"Comment": "configures the contour detector based on the image size. setting a maximum contour and turning off recording\tof inner contours and improve speed and reduce the memory foot print significantly.",
	"Method": "void configureContourDetector(T gray){\r\n    int maxContourSize = Math.max(gray.width, gray.height) / Math.max(numCols, numRows);\r\n    BinaryContourFinder contourFinder = detectorSquare.getDetector().getContourFinder();\r\n    contourFinder.setMaxContour(maxContourSize * 4 * 2);\r\n    contourFinder.setSaveInnerContour(false);\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapObjectConversion.toMap",
	"Comment": "this could be refactored to use core.typetype class and it would run faster.converts an object into a map",
	"Method": "Map<String, Object> toMap(Object object,String ignore,Map<String, Object> toMap,Object object,Set<String> ignore,Map<String, Object> toMap,Object object){\r\n    return mapper.toMap(object);\r\n}"
}, {
	"Path": "com.bugsnag.android.Configuration.getSessionApiHeaders",
	"Comment": "supplies the headers which must be used in any request sent to the session tracking api.",
	"Method": "Map<String, String> getSessionApiHeaders(){\r\n    Map<String, String> map = new HashMap();\r\n    map.put(HEADER_API_PAYLOAD_VERSION, \"1.0\");\r\n    map.put(HEADER_API_KEY, apiKey);\r\n    map.put(HEADER_BUGSNAG_SENT_AT, DateUtils.toIso8601(new Date()));\r\n    return map;\r\n}"
}, {
	"Path": "boofcv.alg.tracker.klt.TestPyramidKltTracker.setDescription_border",
	"Comment": "test set description when a feature partially inside and outside of the image at all levels",
	"Method": "void setDescription_border(){\r\n    PyramidKltFeature feature = new PyramidKltFeature(pyramid.getNumLayers(), featureReadius);\r\n    feature.setPosition(featureReadius - 1, featureReadius - 1);\r\n    tracker.setImage(pyramid, derivX, derivY);\r\n    assertTrue(tracker.setDescription(feature));\r\n    for (int i = 0; i < pyramid.getNumLayers(); i++) {\r\n        assertTrue(feature.desc[i].x != 0);\r\n        assertTrue(feature.desc[i].y != 0);\r\n        assertTrue(feature.desc[i].Gxx != 0.0f);\r\n    }\r\n}"
}, {
	"Path": "org.boon.core.reflection.MapperSimple.convertListOfMapsToObjects",
	"Comment": "this converts a list of maps to objects.i always forget that this exists. i need to remember.",
	"Method": "List<T> convertListOfMapsToObjects(List<Map> list,Class<T> componentType){\r\n    List<Object> newList = new ArrayList(list.size());\r\n    for (Object obj : list) {\r\n        if (obj instanceof Value) {\r\n            obj = ((Value) obj).toValue();\r\n        }\r\n        if (obj instanceof Map) {\r\n            Map map = (Map) obj;\r\n            if (map instanceof ValueMapImpl) {\r\n                newList.add(fromValueMap((Map<String, Value>) map, componentType));\r\n            } else {\r\n                newList.add(fromMap(map, componentType));\r\n            }\r\n        } else {\r\n            newList.add(Conversions.coerce(componentType, obj));\r\n        }\r\n    }\r\n    return (List<T>) newList;\r\n}"
}, {
	"Path": "com.jolbox.bonecp.TestConnectionThreadTester.testIdleConnectionFailedKeepAlive",
	"Comment": "tests that an active connection that fails the connection is alive test will get closed.",
	"Method": "void testIdleConnectionFailedKeepAlive(){\r\n    LinkedBlockingQueue<ConnectionHandle> fakeFreeConnections = new LinkedBlockingQueue<ConnectionHandle>(100);\r\n    fakeFreeConnections.add(mockConnection);\r\n    BoneCPConfig localconfig = config.clone();\r\n    localconfig.setIdleConnectionTestPeriodInMinutes(1);\r\n    expect(mockPool.getConfig()).andReturn(localconfig).anyTimes();\r\n    expect(mockConnectionPartition.getFreeConnections()).andReturn(fakeFreeConnections).anyTimes();\r\n    expect(mockConnectionPartition.getAvailableConnections()).andReturn(1).anyTimes();\r\n    expect(mockConnection.isPossiblyBroken()).andReturn(false);\r\n    expect(mockConnection.getConnectionLastUsedInMs()).andReturn(System.currentTimeMillis());\r\n    expect(mockPool.isConnectionHandleAlive((ConnectionHandle) anyObject())).andReturn(false).anyTimes();\r\n    mockConnection.internalClose();\r\n    mockPool.postDestroyConnection(mockConnection);\r\n    expectLastCall().once();\r\n    replay(mockPool, mockConnection, mockConnectionPartition, mockExecutor);\r\n    this.testClass = new ConnectionTesterThread(mockConnectionPartition, mockExecutor, mockPool, localconfig.getIdleMaxAge(TimeUnit.MILLISECONDS), localconfig.getIdleConnectionTestPeriodInMinutes(), false);\r\n    this.testClass.run();\r\n    verify(mockPool, mockConnectionPartition, mockExecutor, mockConnection);\r\n}"
}, {
	"Path": "boofcv.alg.sfm.structure.GenericSceneStructureChecks.findViewable",
	"Comment": "finds a set of points which is viewed by all the cameras listed",
	"Method": "void findViewable(int[] cameras,List<Point3D_F64> viewable){\r\n    Point3D_F64 c = new Point3D_F64();\r\n    Point2D_F64 p = new Point2D_F64();\r\n    for (int i = 0; i < pointsWorld.size(); i++) {\r\n        Point3D_F64 w = pointsWorld.get(i);\r\n        boolean viewedAll = true;\r\n        for (int j = 0; j < cameras.length; j++) {\r\n            Se3_F64 cameraToWorld = listCameraToWorld.get(cameras[j]);\r\n            SePointOps_F64.transformReverse(cameraToWorld, w, c);\r\n            if (c.z <= 0) {\r\n                viewedAll = false;\r\n                break;\r\n            }\r\n            convertNormToPixel(intrinsic, c.x / c.z, c.y / c.z, p);\r\n            if (p.x < 0 || p.y < 0 || p.x >= intrinsic.width - 1 || p.y >= intrinsic.height - 1) {\r\n                viewedAll = false;\r\n                break;\r\n            }\r\n        }\r\n        if (viewedAll) {\r\n            viewable.add(w);\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.geo.PerspectiveOps.pinholeToMatrix",
	"Comment": "given the intrinsic parameters create a calibration matrix",
	"Method": "DMatrixRMaj pinholeToMatrix(double fx,double fy,double skew,double xc,double yc,FMatrixRMaj pinholeToMatrix,float fx,float fy,float skew,float xc,float yc,DMatrixRMaj pinholeToMatrix,CameraPinhole param,DMatrixRMaj K,FMatrixRMaj pinholeToMatrix,CameraPinhole param,FMatrixRMaj K,DMatrix3x3 pinholeToMatrix,CameraPinhole param,DMatrix3x3 K){\r\n    return ImplPerspectiveOps_F64.pinholeToMatrix(param, K);\r\n}"
}, {
	"Path": "boofcv.alg.filter.convolve.noborder.TestConvolveImageStandard_SB.checkAll",
	"Comment": "using reflections get a list of all the functions and test each of them",
	"Method": "void checkAll(){\r\n    int numExpected = 29;\r\n    Method[] methods = ConvolveImageStandard_SB.class.getMethods();\r\n    int numFound = 0;\r\n    for (Method m : methods) {\r\n        if (!isTestMethod(m)) {\r\n            continue;\r\n        }\r\n        testMethod(m);\r\n        numFound++;\r\n    }\r\n    if (numExpected != numFound)\r\n        throw new RuntimeException(\"Unexpected number of methods: Found \" + numFound + \"  expected \" + numExpected);\r\n}"
}, {
	"Path": "boofcv.alg.background.BackgroundGmmCommon.updateMixture",
	"Comment": "updates the mixtures of gaussian and determines if the pixel matches the background model",
	"Method": "int updateMixture(float[] pixelValue,float[] dataRow,int modelIndex,int updateMixture,float pixelValue,float[] dataRow,int modelIndex){\r\n    int index = modelIndex;\r\n    float bestDistance = maxDistance;\r\n    int bestIndex = -1;\r\n    int ng;\r\n    for (ng = 0; ng < maxGaussians; ng++, index += 3) {\r\n        float variance = dataRow[index + 1];\r\n        float mean = dataRow[index + 2];\r\n        if (variance <= 0) {\r\n            break;\r\n        }\r\n        float delta = pixelValue - mean;\r\n        float mahalanobis = delta * delta / variance;\r\n        if (mahalanobis < bestDistance) {\r\n            bestDistance = mahalanobis;\r\n            bestIndex = index;\r\n        }\r\n    }\r\n    if (bestDistance != maxDistance) {\r\n        float weight = dataRow[bestIndex];\r\n        float variance = dataRow[bestIndex + 1];\r\n        float mean = dataRow[bestIndex + 2];\r\n        float delta = pixelValue - mean;\r\n        weight += learningRate * (1f - weight);\r\n        dataRow[bestIndex] = 1;\r\n        dataRow[bestIndex + 1] = variance + (learningRate / weight) * (delta * delta * 1.2F - variance);\r\n        dataRow[bestIndex + 2] = mean + delta * learningRate / weight;\r\n        updateWeightAndPrune(dataRow, modelIndex, ng, bestIndex, weight);\r\n        return weight >= significantWeight ? 0 : 1;\r\n    } else if (ng < maxGaussians) {\r\n        bestIndex = modelIndex + ng * 3;\r\n        dataRow[bestIndex] = 1;\r\n        dataRow[bestIndex + 1] = initialVariance;\r\n        dataRow[bestIndex + 2] = pixelValue;\r\n        if (ng == 0)\r\n            return unknownValue;\r\n        updateWeightAndPrune(dataRow, modelIndex, ng + 1, bestIndex, learningRate);\r\n        return 1;\r\n    } else {\r\n        return 1;\r\n    }\r\n}"
}, {
	"Path": "boofcv.abst.filter.derivative.AnyImageDerivative.setInput",
	"Comment": "sets the new input image from which the image derivatives are computed from.",
	"Method": "void setInput(I input){\r\n    this.inputImage = input;\r\n    if (stale != null) {\r\n        for (int i = 0; i < stale.length; i++) {\r\n            boolean[] a = stale[i];\r\n            for (int j = 0; j < a.length; j++) {\r\n                a[j] = true;\r\n            }\r\n        }\r\n    }\r\n}"
}, {
	"Path": "boofcv.alg.distort.TestNarrowToWidePtoP_F64.checkFOVBounds",
	"Comment": "request points at the border and see if it has the expected vertical and horizontal fov",
	"Method": "void checkFOVBounds(){\r\n    NarrowToWidePtoP_F64 alg = createAlg();\r\n    Point2D_F64 foundA = new Point2D_F64();\r\n    Point2D_F64 foundB = new Point2D_F64();\r\n    Point3D_F64 vA = new Point3D_F64();\r\n    Point3D_F64 vB = new Point3D_F64();\r\n    alg.compute(0, 250, foundA);\r\n    alg.compute(500, 250, foundB);\r\n    Point2Transform3_F64 wideToSphere = createModelWide().undistortPtoS_F64();\r\n    wideToSphere.compute(foundA.x, foundA.y, vA);\r\n    wideToSphere.compute(foundB.x, foundB.y, vB);\r\n    double found = UtilVector3D_F64.acute(new Vector3D_F64(vA), new Vector3D_F64(vB));\r\n    double expected = 2.0 * Math.atan(250.0 / 400.0);\r\n    assertEquals(expected, found, 0.01);\r\n    alg.compute(250, 0, foundA);\r\n    alg.compute(250, 500, foundB);\r\n    wideToSphere.compute(foundA.x, foundA.y, vA);\r\n    wideToSphere.compute(foundB.x, foundB.y, vB);\r\n    found = UtilVector3D_F64.acute(new Vector3D_F64(vA), new Vector3D_F64(vB));\r\n    expected = 2.0 * Math.atan(250.0 / 400.0);\r\n    assertEquals(expected, found, 0.001);\r\n}"
}, {
	"Path": "boofcv.alg.feature.describe.DescribePointSurf.computeLaplaceSign",
	"Comment": "compute the sign of the laplacian using a sparse convolution.",
	"Method": "boolean computeLaplaceSign(int x,int y,double scale){\r\n    int s = (int) Math.ceil(scale);\r\n    kerXX = DerivativeIntegralImage.kernelDerivXX(9 * s, kerXX);\r\n    kerYY = DerivativeIntegralImage.kernelDerivYY(9 * s, kerYY);\r\n    double lap = GIntegralImageOps.convolveSparse(ii, kerXX, x, y);\r\n    lap += GIntegralImageOps.convolveSparse(ii, kerYY, x, y);\r\n    return lap > 0;\r\n}"
}, {
	"Path": "boofcv.factory.feature.orientation.FactoryOrientationAlgs.sliding_ii",
	"Comment": "estimates the orientation of a region by using a sliding window across the different potential\tangles.",
	"Method": "OrientationIntegral<II> sliding_ii(ConfigSlidingIntegral config,Class<II> integralType){\r\n    if (config == null)\r\n        config = new ConfigSlidingIntegral();\r\n    config.checkValidity();\r\n    return (OrientationIntegral<II>) new ImplOrientationSlidingWindowIntegral(config.objectRadiusToScale, config.samplePeriod, config.windowSize, config.radius, config.weightSigma, config.sampleWidth, integralType);\r\n}"
}, {
	"Path": "boofcv.alg.segmentation.fh04.SegmentFelzenszwalbHuttenlocher04.configureApproximateSort",
	"Comment": "if this function is called the exact sort routine will not be used and instead an approximate routine will\tbe used.",
	"Method": "void configureApproximateSort(int numBins){\r\n    sorterApprox = new ApproximateSort_F32(numBins);\r\n}"
}, {
	"Path": "boofcv.alg.geo.PerspectiveOps.createWorldToPixel",
	"Comment": "creates a transform from world coordinates into pixel coordinates.can handle lens distortion",
	"Method": "WorldToCameraToPixel createWorldToPixel(CameraPinholeRadial intrinsic,Se3_F64 worldToCamera,WorldToCameraToPixel createWorldToPixel,LensDistortionNarrowFOV distortion,Se3_F64 worldToCamera){\r\n    WorldToCameraToPixel alg = new WorldToCameraToPixel();\r\n    alg.configure(distortion, worldToCamera);\r\n    return alg;\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.SelectRectStandard.maxDisparityAtColumnL2R",
	"Comment": "returns the maximum allowed disparity for a particular column in left to right direction,\tas limited by the image border.",
	"Method": "int maxDisparityAtColumnL2R(int col){\r\n    return 1 + col - minDisparity - Math.max(0, col - maxDisparity + 1);\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.impl.ImplDisparityScoreSadRectFive_U8.computeFirstRow",
	"Comment": "initializes disparity calculation by finding the scores for the initial block of horizontal\trows.",
	"Method": "void computeFirstRow(GrayU8 left,GrayU8 right){\r\n    int[] firstRow = verticalScore[0];\r\n    activeVerticalScore = 1;\r\n    for (int row = 0; row < regionHeight; row++) {\r\n        int[] scores = horizontalScore[row];\r\n        UtilDisparityScore.computeScoreRow(left, right, row, scores, minDisparity, maxDisparity, regionWidth, elementScore);\r\n    }\r\n    for (int i = 0; i < lengthHorizontal; i++) {\r\n        int sum = 0;\r\n        for (int row = 0; row < regionHeight; row++) {\r\n            sum += horizontalScore[row][i];\r\n        }\r\n        firstRow[i] = sum;\r\n    }\r\n}"
}, {
	"Path": "boofcv.gui.image.ImagePanel.setImageRepaint",
	"Comment": "changes the buffered image and calls repaint.does not need to be called in the ui thread.",
	"Method": "void setImageRepaint(BufferedImage image){\r\n    ScaleOffset workspace;\r\n    if (SwingUtilities.isEventDispatchThread()) {\r\n        workspace = adjustmentGUI;\r\n    } else {\r\n        workspace = new ScaleOffset();\r\n    }\r\n    repaintJustImage(img, workspace);\r\n    this.img = image;\r\n    repaintJustImage(img, workspace);\r\n}"
}, {
	"Path": "boofcv.alg.feature.disparity.SelectRectBasicWta.maxDisparityAtColumnL2R",
	"Comment": "returns the maximum allowed disparity for a particular column in left to right direction,\tas limited by the image border.",
	"Method": "int maxDisparityAtColumnL2R(int col){\r\n    return 1 + col - minDisparity - Math.max(0, col - maxDisparity + 1);\r\n}"
}]